{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "n_hidden = 256\n",
    "n_input = 28*28 #image size\n",
    "n_noise = 128 # noise size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None, n_input]) # 원래 data\n",
    "Z = tf.placeholder(tf.float32,[None,n_noise]) # noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generat 변수들\n",
    "#은닉층 출력을 위한 가중치,편향\n",
    "G_W1 = tf.Variable(tf.random_normal([n_noise,n_hidden],stddev = 0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "#출력층 출력을 위한 가중치,편향\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden,n_input],stddev = 0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#difcriminator 변수들\n",
    "#은닉층 출력을 위한 가중치,편향\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input,n_hidden],stddev = 0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "#출력층 출력을 위한 가중치,편향\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden,1],stddev = 0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z,G_W1)+G_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden,G_W2)+G_b2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs,D_W1)+D_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden,D_W2)+D_b2) # output을 0과 1 사이의 값으로 만들어줌\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#무작위 noise를 batch_size만큼 만들어줌\n",
    "def get_noise(batch_size,n_noise):\n",
    "    return np.random.normal(size=(batch_size,n_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(Z)# noise로 부터 생성된 이미지\n",
    "D_gene = discriminator(G) #가짜 이미지 판별값\n",
    "D_real = discriminator(X) #진짜 이미지 판별값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator loss\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1-D_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator loss\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각각 신경망 변수들 구분해줌\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training 방법 설정\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D,var_list=D_var_list)#maximise 하기위해 loss에 음수 붙여줌\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G,var_list=G_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "loss_val_D,loss_val_G=0,0 #loss D와 loss_G의 결과값을 받을 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0000 D loss:-1.383 G loss:-0.7332\n",
      "Epoch:  0000 D loss:-1.351 G loss:-0.7623\n",
      "Epoch:  0000 D loss:-1.327 G loss:-0.7894\n",
      "Epoch:  0000 D loss:-1.306 G loss:-0.8159\n",
      "Epoch:  0000 D loss:-1.285 G loss:-0.843\n",
      "Epoch:  0000 D loss:-1.267 G loss:-0.8709\n",
      "Epoch:  0000 D loss:-1.245 G loss:-0.9\n",
      "Epoch:  0000 D loss:-1.225 G loss:-0.9301\n",
      "Epoch:  0000 D loss:-1.207 G loss:-0.9612\n",
      "Epoch:  0000 D loss:-1.185 G loss:-0.9939\n",
      "Epoch:  0000 D loss:-1.162 G loss:-1.027\n",
      "Epoch:  0000 D loss:-1.14 G loss:-1.061\n",
      "Epoch:  0000 D loss:-1.117 G loss:-1.097\n",
      "Epoch:  0000 D loss:-1.096 G loss:-1.134\n",
      "Epoch:  0000 D loss:-1.075 G loss:-1.171\n",
      "Epoch:  0000 D loss:-1.049 G loss:-1.21\n",
      "Epoch:  0000 D loss:-1.027 G loss:-1.249\n",
      "Epoch:  0000 D loss:-1.005 G loss:-1.287\n",
      "Epoch:  0000 D loss:-0.9751 G loss:-1.326\n",
      "Epoch:  0000 D loss:-0.9546 G loss:-1.365\n",
      "Epoch:  0000 D loss:-0.9295 G loss:-1.406\n",
      "Epoch:  0000 D loss:-0.9025 G loss:-1.446\n",
      "Epoch:  0000 D loss:-0.8735 G loss:-1.489\n",
      "Epoch:  0000 D loss:-0.8452 G loss:-1.532\n",
      "Epoch:  0000 D loss:-0.8273 G loss:-1.574\n",
      "Epoch:  0000 D loss:-0.7966 G loss:-1.616\n",
      "Epoch:  0000 D loss:-0.7719 G loss:-1.658\n",
      "Epoch:  0000 D loss:-0.7509 G loss:-1.697\n",
      "Epoch:  0000 D loss:-0.7335 G loss:-1.739\n",
      "Epoch:  0000 D loss:-0.6913 G loss:-1.781\n",
      "Epoch:  0000 D loss:-0.6805 G loss:-1.822\n",
      "Epoch:  0000 D loss:-0.649 G loss:-1.865\n",
      "Epoch:  0000 D loss:-0.6381 G loss:-1.904\n",
      "Epoch:  0000 D loss:-0.5997 G loss:-1.948\n",
      "Epoch:  0000 D loss:-0.5819 G loss:-1.992\n",
      "Epoch:  0000 D loss:-0.5562 G loss:-2.036\n",
      "Epoch:  0000 D loss:-0.5486 G loss:-2.083\n",
      "Epoch:  0000 D loss:-0.5128 G loss:-2.129\n",
      "Epoch:  0000 D loss:-0.5064 G loss:-2.175\n",
      "Epoch:  0000 D loss:-0.4871 G loss:-2.218\n",
      "Epoch:  0000 D loss:-0.4642 G loss:-2.265\n",
      "Epoch:  0000 D loss:-0.4499 G loss:-2.311\n",
      "Epoch:  0000 D loss:-0.431 G loss:-2.354\n",
      "Epoch:  0000 D loss:-0.4089 G loss:-2.397\n",
      "Epoch:  0000 D loss:-0.4044 G loss:-2.442\n",
      "Epoch:  0000 D loss:-0.3849 G loss:-2.472\n",
      "Epoch:  0000 D loss:-0.3676 G loss:-2.522\n",
      "Epoch:  0000 D loss:-0.3389 G loss:-2.578\n",
      "Epoch:  0000 D loss:-0.3505 G loss:-2.625\n",
      "Epoch:  0000 D loss:-0.3176 G loss:-2.656\n",
      "Epoch:  0000 D loss:-0.3147 G loss:-2.705\n",
      "Epoch:  0000 D loss:-0.301 G loss:-2.739\n",
      "Epoch:  0000 D loss:-0.287 G loss:-2.784\n",
      "Epoch:  0000 D loss:-0.277 G loss:-2.796\n",
      "Epoch:  0000 D loss:-0.2786 G loss:-2.866\n",
      "Epoch:  0000 D loss:-0.2618 G loss:-2.883\n",
      "Epoch:  0000 D loss:-0.2294 G loss:-2.916\n",
      "Epoch:  0000 D loss:-0.2298 G loss:-2.93\n",
      "Epoch:  0000 D loss:-0.2425 G loss:-2.97\n",
      "Epoch:  0000 D loss:-0.2209 G loss:-2.995\n",
      "Epoch:  0000 D loss:-0.2143 G loss:-3.053\n",
      "Epoch:  0000 D loss:-0.2044 G loss:-3.036\n",
      "Epoch:  0000 D loss:-0.2113 G loss:-3.053\n",
      "Epoch:  0000 D loss:-0.2015 G loss:-3.068\n",
      "Epoch:  0000 D loss:-0.1909 G loss:-3.165\n",
      "Epoch:  0000 D loss:-0.1849 G loss:-3.137\n",
      "Epoch:  0000 D loss:-0.1714 G loss:-3.158\n",
      "Epoch:  0000 D loss:-0.1731 G loss:-3.148\n",
      "Epoch:  0000 D loss:-0.1622 G loss:-3.163\n",
      "Epoch:  0000 D loss:-0.1659 G loss:-3.205\n",
      "Epoch:  0000 D loss:-0.1706 G loss:-3.278\n",
      "Epoch:  0000 D loss:-0.165 G loss:-3.277\n",
      "Epoch:  0000 D loss:-0.1585 G loss:-3.196\n",
      "Epoch:  0000 D loss:-0.1505 G loss:-3.318\n",
      "Epoch:  0000 D loss:-0.1379 G loss:-3.327\n",
      "Epoch:  0000 D loss:-0.1548 G loss:-3.331\n",
      "Epoch:  0000 D loss:-0.1445 G loss:-3.352\n",
      "Epoch:  0000 D loss:-0.1444 G loss:-3.257\n",
      "Epoch:  0000 D loss:-0.1366 G loss:-3.345\n",
      "Epoch:  0000 D loss:-0.1388 G loss:-3.36\n",
      "Epoch:  0000 D loss:-0.1417 G loss:-3.34\n",
      "Epoch:  0000 D loss:-0.1351 G loss:-3.305\n",
      "Epoch:  0000 D loss:-0.1458 G loss:-3.277\n",
      "Epoch:  0000 D loss:-0.1357 G loss:-3.419\n",
      "Epoch:  0000 D loss:-0.1213 G loss:-3.409\n",
      "Epoch:  0000 D loss:-0.1326 G loss:-3.384\n",
      "Epoch:  0000 D loss:-0.1395 G loss:-3.36\n",
      "Epoch:  0000 D loss:-0.1369 G loss:-3.5\n",
      "Epoch:  0000 D loss:-0.1351 G loss:-3.494\n",
      "Epoch:  0000 D loss:-0.1258 G loss:-3.49\n",
      "Epoch:  0000 D loss:-0.1379 G loss:-3.37\n",
      "Epoch:  0000 D loss:-0.14 G loss:-3.303\n",
      "Epoch:  0000 D loss:-0.1642 G loss:-3.464\n",
      "Epoch:  0000 D loss:-0.1317 G loss:-3.616\n",
      "Epoch:  0000 D loss:-0.1559 G loss:-3.418\n",
      "Epoch:  0000 D loss:-0.1354 G loss:-3.618\n",
      "Epoch:  0000 D loss:-0.1277 G loss:-3.719\n",
      "Epoch:  0000 D loss:-0.1633 G loss:-3.557\n",
      "Epoch:  0000 D loss:-0.1531 G loss:-3.616\n",
      "Epoch:  0000 D loss:-0.1327 G loss:-3.79\n",
      "Epoch:  0000 D loss:-0.1524 G loss:-3.455\n",
      "Epoch:  0000 D loss:-0.1388 G loss:-3.92\n",
      "Epoch:  0000 D loss:-0.1547 G loss:-3.68\n",
      "Epoch:  0000 D loss:-0.1797 G loss:-3.621\n",
      "Epoch:  0000 D loss:-0.1768 G loss:-3.609\n",
      "Epoch:  0000 D loss:-0.1576 G loss:-3.897\n",
      "Epoch:  0000 D loss:-0.1758 G loss:-3.816\n",
      "Epoch:  0000 D loss:-0.2015 G loss:-3.847\n",
      "Epoch:  0000 D loss:-0.1903 G loss:-3.812\n",
      "Epoch:  0000 D loss:-0.1779 G loss:-3.787\n",
      "Epoch:  0000 D loss:-0.1433 G loss:-3.987\n",
      "Epoch:  0000 D loss:-0.1855 G loss:-3.829\n",
      "Epoch:  0000 D loss:-0.1658 G loss:-4.022\n",
      "Epoch:  0000 D loss:-0.1437 G loss:-4.318\n",
      "Epoch:  0000 D loss:-0.1744 G loss:-3.853\n",
      "Epoch:  0000 D loss:-0.2248 G loss:-4.002\n",
      "Epoch:  0000 D loss:-0.2053 G loss:-3.948\n",
      "Epoch:  0000 D loss:-0.2153 G loss:-3.818\n",
      "Epoch:  0000 D loss:-0.1941 G loss:-4.048\n",
      "Epoch:  0000 D loss:-0.2154 G loss:-4.007\n",
      "Epoch:  0000 D loss:-0.1953 G loss:-4.202\n",
      "Epoch:  0000 D loss:-0.2169 G loss:-3.856\n",
      "Epoch:  0000 D loss:-0.246 G loss:-3.696\n",
      "Epoch:  0000 D loss:-0.2342 G loss:-3.872\n",
      "Epoch:  0000 D loss:-0.2263 G loss:-4.133\n",
      "Epoch:  0000 D loss:-0.2977 G loss:-3.904\n",
      "Epoch:  0000 D loss:-0.2252 G loss:-4.143\n",
      "Epoch:  0000 D loss:-0.2362 G loss:-3.907\n",
      "Epoch:  0000 D loss:-0.2624 G loss:-4.256\n",
      "Epoch:  0000 D loss:-0.2702 G loss:-4.143\n",
      "Epoch:  0000 D loss:-0.3193 G loss:-3.858\n",
      "Epoch:  0000 D loss:-0.2525 G loss:-4.416\n",
      "Epoch:  0000 D loss:-0.2651 G loss:-3.928\n",
      "Epoch:  0000 D loss:-0.2952 G loss:-3.64\n",
      "Epoch:  0000 D loss:-0.3272 G loss:-4.054\n",
      "Epoch:  0000 D loss:-0.2844 G loss:-4.133\n",
      "Epoch:  0000 D loss:-0.3017 G loss:-4.153\n",
      "Epoch:  0000 D loss:-0.2751 G loss:-4.139\n",
      "Epoch:  0000 D loss:-0.3458 G loss:-4.042\n",
      "Epoch:  0000 D loss:-0.3144 G loss:-4.232\n",
      "Epoch:  0000 D loss:-0.3073 G loss:-4.218\n",
      "Epoch:  0000 D loss:-0.3387 G loss:-4.066\n",
      "Epoch:  0000 D loss:-0.3392 G loss:-4.213\n",
      "Epoch:  0000 D loss:-0.3226 G loss:-4.292\n",
      "Epoch:  0000 D loss:-0.2897 G loss:-4.259\n",
      "Epoch:  0000 D loss:-0.306 G loss:-4.01\n",
      "Epoch:  0000 D loss:-0.3587 G loss:-3.637\n",
      "Epoch:  0000 D loss:-0.3882 G loss:-3.882\n",
      "Epoch:  0000 D loss:-0.4139 G loss:-3.594\n",
      "Epoch:  0000 D loss:-0.3726 G loss:-3.691\n",
      "Epoch:  0000 D loss:-0.382 G loss:-3.799\n",
      "Epoch:  0000 D loss:-0.3424 G loss:-4.171\n",
      "Epoch:  0000 D loss:-0.3596 G loss:-3.616\n",
      "Epoch:  0000 D loss:-0.3875 G loss:-3.938\n",
      "Epoch:  0000 D loss:-0.3507 G loss:-4.224\n",
      "Epoch:  0000 D loss:-0.3989 G loss:-3.5\n",
      "Epoch:  0000 D loss:-0.3265 G loss:-4.172\n",
      "Epoch:  0000 D loss:-0.4176 G loss:-3.769\n",
      "Epoch:  0000 D loss:-0.3571 G loss:-3.809\n",
      "Epoch:  0000 D loss:-0.3441 G loss:-4.117\n",
      "Epoch:  0000 D loss:-0.3446 G loss:-4.111\n",
      "Epoch:  0000 D loss:-0.4566 G loss:-4.016\n",
      "Epoch:  0000 D loss:-0.4042 G loss:-3.875\n",
      "Epoch:  0000 D loss:-0.4078 G loss:-3.878\n",
      "Epoch:  0000 D loss:-0.4315 G loss:-3.487\n",
      "Epoch:  0000 D loss:-0.4423 G loss:-3.681\n",
      "Epoch:  0000 D loss:-0.4173 G loss:-3.868\n",
      "Epoch:  0000 D loss:-0.4658 G loss:-3.428\n",
      "Epoch:  0000 D loss:-0.4745 G loss:-3.497\n",
      "Epoch:  0000 D loss:-0.4416 G loss:-3.784\n",
      "Epoch:  0000 D loss:-0.4797 G loss:-3.361\n",
      "Epoch:  0000 D loss:-0.4448 G loss:-3.476\n",
      "Epoch:  0000 D loss:-0.4647 G loss:-3.667\n",
      "Epoch:  0000 D loss:-0.3866 G loss:-3.478\n",
      "Epoch:  0000 D loss:-0.4589 G loss:-3.493\n",
      "Epoch:  0000 D loss:-0.4756 G loss:-3.517\n",
      "Epoch:  0000 D loss:-0.45 G loss:-3.521\n",
      "Epoch:  0000 D loss:-0.4403 G loss:-3.409\n",
      "Epoch:  0000 D loss:-0.4788 G loss:-3.245\n",
      "Epoch:  0000 D loss:-0.5008 G loss:-3.189\n",
      "Epoch:  0000 D loss:-0.4935 G loss:-3.212\n",
      "Epoch:  0000 D loss:-0.4829 G loss:-3.352\n",
      "Epoch:  0000 D loss:-0.4851 G loss:-3.028\n",
      "Epoch:  0000 D loss:-0.5366 G loss:-2.779\n",
      "Epoch:  0000 D loss:-0.4644 G loss:-3.03\n",
      "Epoch:  0000 D loss:-0.5651 G loss:-3.051\n",
      "Epoch:  0000 D loss:-0.549 G loss:-3.212\n",
      "Epoch:  0000 D loss:-0.523 G loss:-3.126\n",
      "Epoch:  0000 D loss:-0.5602 G loss:-2.771\n",
      "Epoch:  0000 D loss:-0.5431 G loss:-2.907\n",
      "Epoch:  0000 D loss:-0.6003 G loss:-2.829\n",
      "Epoch:  0000 D loss:-0.4959 G loss:-3.08\n",
      "Epoch:  0000 D loss:-0.6186 G loss:-2.831\n",
      "Epoch:  0000 D loss:-0.6187 G loss:-2.611\n",
      "Epoch:  0000 D loss:-0.6185 G loss:-2.537\n",
      "Epoch:  0000 D loss:-0.5757 G loss:-2.701\n",
      "Epoch:  0000 D loss:-0.6156 G loss:-2.558\n",
      "Epoch:  0000 D loss:-0.6453 G loss:-2.602\n",
      "Epoch:  0000 D loss:-0.5964 G loss:-2.808\n",
      "Epoch:  0000 D loss:-0.6068 G loss:-2.519\n",
      "Epoch:  0000 D loss:-0.6407 G loss:-2.476\n",
      "Epoch:  0000 D loss:-0.673 G loss:-2.517\n",
      "Epoch:  0000 D loss:-0.6251 G loss:-2.362\n",
      "Epoch:  0000 D loss:-0.6033 G loss:-2.602\n",
      "Epoch:  0000 D loss:-0.6745 G loss:-2.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0000 D loss:-0.7006 G loss:-2.332\n",
      "Epoch:  0000 D loss:-0.6765 G loss:-2.287\n",
      "Epoch:  0000 D loss:-0.6758 G loss:-2.349\n",
      "Epoch:  0000 D loss:-0.6999 G loss:-2.207\n",
      "Epoch:  0000 D loss:-0.6722 G loss:-2.263\n",
      "Epoch:  0000 D loss:-0.7229 G loss:-2.282\n",
      "Epoch:  0000 D loss:-0.6921 G loss:-2.432\n",
      "Epoch:  0000 D loss:-0.7788 G loss:-2.287\n",
      "Epoch:  0000 D loss:-0.7197 G loss:-2.148\n",
      "Epoch:  0000 D loss:-0.6887 G loss:-2.48\n",
      "Epoch:  0000 D loss:-0.7389 G loss:-1.997\n",
      "Epoch:  0000 D loss:-0.7233 G loss:-2.088\n",
      "Epoch:  0000 D loss:-0.6783 G loss:-2.181\n",
      "Epoch:  0000 D loss:-0.7812 G loss:-1.939\n",
      "Epoch:  0000 D loss:-0.8196 G loss:-1.982\n",
      "Epoch:  0000 D loss:-0.6878 G loss:-2.137\n",
      "Epoch:  0000 D loss:-0.7679 G loss:-2.025\n",
      "Epoch:  0000 D loss:-0.7143 G loss:-2.086\n",
      "Epoch:  0000 D loss:-0.7681 G loss:-1.859\n",
      "Epoch:  0000 D loss:-0.7853 G loss:-1.994\n",
      "Epoch:  0000 D loss:-0.7459 G loss:-2.111\n",
      "Epoch:  0000 D loss:-0.7427 G loss:-1.945\n",
      "Epoch:  0000 D loss:-0.7405 G loss:-1.965\n",
      "Epoch:  0000 D loss:-0.749 G loss:-2.088\n",
      "Epoch:  0000 D loss:-0.7665 G loss:-2.087\n",
      "Epoch:  0000 D loss:-0.7433 G loss:-1.998\n",
      "Epoch:  0000 D loss:-0.7444 G loss:-2.013\n",
      "Epoch:  0000 D loss:-0.807 G loss:-1.882\n",
      "Epoch:  0000 D loss:-0.7774 G loss:-1.8\n",
      "Epoch:  0000 D loss:-0.7598 G loss:-1.982\n",
      "Epoch:  0000 D loss:-0.8114 G loss:-1.896\n",
      "Epoch:  0000 D loss:-0.8854 G loss:-1.88\n",
      "Epoch:  0000 D loss:-0.7708 G loss:-1.921\n",
      "Epoch:  0000 D loss:-0.7671 G loss:-1.911\n",
      "Epoch:  0000 D loss:-0.777 G loss:-1.894\n",
      "Epoch:  0000 D loss:-0.7722 G loss:-1.877\n",
      "Epoch:  0000 D loss:-0.7389 G loss:-1.713\n",
      "Epoch:  0000 D loss:-0.8228 G loss:-1.67\n",
      "Epoch:  0000 D loss:-0.8725 G loss:-1.641\n",
      "Epoch:  0000 D loss:-0.8354 G loss:-1.756\n",
      "Epoch:  0000 D loss:-0.7845 G loss:-2.056\n",
      "Epoch:  0000 D loss:-0.7608 G loss:-1.86\n",
      "Epoch:  0000 D loss:-0.7908 G loss:-1.958\n",
      "Epoch:  0000 D loss:-0.7859 G loss:-1.899\n",
      "Epoch:  0000 D loss:-0.7668 G loss:-1.784\n",
      "Epoch:  0000 D loss:-0.7498 G loss:-1.758\n",
      "Epoch:  0000 D loss:-0.7006 G loss:-1.738\n",
      "Epoch:  0000 D loss:-0.7758 G loss:-1.803\n",
      "Epoch:  0000 D loss:-0.7243 G loss:-1.764\n",
      "Epoch:  0000 D loss:-0.8054 G loss:-1.843\n",
      "Epoch:  0000 D loss:-0.772 G loss:-1.785\n",
      "Epoch:  0000 D loss:-0.7437 G loss:-1.882\n",
      "Epoch:  0000 D loss:-0.7926 G loss:-1.871\n",
      "Epoch:  0000 D loss:-0.7756 G loss:-1.769\n",
      "Epoch:  0000 D loss:-0.7166 G loss:-1.924\n",
      "Epoch:  0000 D loss:-0.7683 G loss:-1.819\n",
      "Epoch:  0000 D loss:-0.7957 G loss:-1.737\n",
      "Epoch:  0000 D loss:-0.7671 G loss:-1.787\n",
      "Epoch:  0000 D loss:-0.7397 G loss:-1.777\n",
      "Epoch:  0000 D loss:-0.7299 G loss:-1.74\n",
      "Epoch:  0000 D loss:-0.7269 G loss:-1.697\n",
      "Epoch:  0000 D loss:-0.7519 G loss:-1.659\n",
      "Epoch:  0000 D loss:-0.7753 G loss:-1.719\n",
      "Epoch:  0000 D loss:-0.7891 G loss:-1.782\n",
      "Epoch:  0000 D loss:-0.7465 G loss:-1.783\n",
      "Epoch:  0000 D loss:-0.7446 G loss:-1.867\n",
      "Epoch:  0000 D loss:-0.7039 G loss:-1.862\n",
      "Epoch:  0000 D loss:-0.7231 G loss:-1.822\n",
      "Epoch:  0000 D loss:-0.7319 G loss:-1.877\n",
      "Epoch:  0000 D loss:-0.7502 G loss:-1.742\n",
      "Epoch:  0000 D loss:-0.7173 G loss:-1.836\n",
      "Epoch:  0000 D loss:-0.6736 G loss:-1.78\n",
      "Epoch:  0000 D loss:-0.7094 G loss:-1.765\n",
      "Epoch:  0000 D loss:-0.7428 G loss:-1.742\n",
      "Epoch:  0000 D loss:-0.703 G loss:-1.788\n",
      "Epoch:  0000 D loss:-0.7136 G loss:-1.831\n",
      "Epoch:  0000 D loss:-0.737 G loss:-1.732\n",
      "Epoch:  0000 D loss:-0.7223 G loss:-1.835\n",
      "Epoch:  0000 D loss:-0.7668 G loss:-1.737\n",
      "Epoch:  0000 D loss:-0.6907 G loss:-1.756\n",
      "Epoch:  0000 D loss:-0.7196 G loss:-1.776\n",
      "Epoch:  0000 D loss:-0.8046 G loss:-1.81\n",
      "Epoch:  0000 D loss:-0.7439 G loss:-1.741\n",
      "Epoch:  0000 D loss:-0.7431 G loss:-1.748\n",
      "Epoch:  0000 D loss:-0.6939 G loss:-1.761\n",
      "Epoch:  0000 D loss:-0.7431 G loss:-1.861\n",
      "Epoch:  0000 D loss:-0.7329 G loss:-1.861\n",
      "Epoch:  0000 D loss:-0.7981 G loss:-1.746\n",
      "Epoch:  0000 D loss:-0.8375 G loss:-1.755\n",
      "Epoch:  0000 D loss:-0.7466 G loss:-1.771\n",
      "Epoch:  0000 D loss:-0.8185 G loss:-1.737\n",
      "Epoch:  0000 D loss:-0.7491 G loss:-1.665\n",
      "Epoch:  0000 D loss:-0.808 G loss:-1.712\n",
      "Epoch:  0000 D loss:-0.7918 G loss:-1.673\n",
      "Epoch:  0000 D loss:-0.7609 G loss:-1.696\n",
      "Epoch:  0000 D loss:-0.8506 G loss:-1.704\n",
      "Epoch:  0000 D loss:-0.756 G loss:-1.824\n",
      "Epoch:  0000 D loss:-0.7785 G loss:-1.73\n",
      "Epoch:  0000 D loss:-0.7916 G loss:-1.784\n",
      "Epoch:  0000 D loss:-0.7965 G loss:-1.711\n",
      "Epoch:  0000 D loss:-0.8685 G loss:-1.688\n",
      "Epoch:  0000 D loss:-0.8085 G loss:-1.706\n",
      "Epoch:  0000 D loss:-0.8436 G loss:-1.673\n",
      "Epoch:  0000 D loss:-0.7899 G loss:-1.604\n",
      "Epoch:  0000 D loss:-0.879 G loss:-1.654\n",
      "Epoch:  0000 D loss:-0.7791 G loss:-1.742\n",
      "Epoch:  0000 D loss:-0.7956 G loss:-1.793\n",
      "Epoch:  0000 D loss:-0.8523 G loss:-1.72\n",
      "Epoch:  0000 D loss:-0.8548 G loss:-1.62\n",
      "Epoch:  0000 D loss:-0.8327 G loss:-1.679\n",
      "Epoch:  0000 D loss:-0.7981 G loss:-1.719\n",
      "Epoch:  0000 D loss:-0.8424 G loss:-1.716\n",
      "Epoch:  0000 D loss:-0.887 G loss:-1.688\n",
      "Epoch:  0000 D loss:-0.8715 G loss:-1.631\n",
      "Epoch:  0000 D loss:-0.8302 G loss:-1.713\n",
      "Epoch:  0000 D loss:-0.918 G loss:-1.625\n",
      "Epoch:  0000 D loss:-0.8652 G loss:-1.625\n",
      "Epoch:  0000 D loss:-0.8042 G loss:-1.666\n",
      "Epoch:  0000 D loss:-0.8018 G loss:-1.712\n",
      "Epoch:  0000 D loss:-0.8508 G loss:-1.611\n",
      "Epoch:  0000 D loss:-0.8034 G loss:-1.722\n",
      "Epoch:  0000 D loss:-0.8822 G loss:-1.755\n",
      "Epoch:  0000 D loss:-0.8471 G loss:-1.703\n",
      "Epoch:  0000 D loss:-0.9264 G loss:-1.686\n",
      "Epoch:  0000 D loss:-0.8884 G loss:-1.625\n",
      "Epoch:  0000 D loss:-0.8701 G loss:-1.573\n",
      "Epoch:  0000 D loss:-0.8288 G loss:-1.657\n",
      "Epoch:  0000 D loss:-0.9155 G loss:-1.553\n",
      "Epoch:  0000 D loss:-0.8535 G loss:-1.619\n",
      "Epoch:  0000 D loss:-0.8371 G loss:-1.62\n",
      "Epoch:  0000 D loss:-0.8941 G loss:-1.666\n",
      "Epoch:  0000 D loss:-0.9668 G loss:-1.61\n",
      "Epoch:  0000 D loss:-0.9033 G loss:-1.626\n",
      "Epoch:  0000 D loss:-0.8283 G loss:-1.611\n",
      "Epoch:  0000 D loss:-0.8511 G loss:-1.58\n",
      "Epoch:  0000 D loss:-0.8451 G loss:-1.67\n",
      "Epoch:  0000 D loss:-0.8664 G loss:-1.729\n",
      "Epoch:  0000 D loss:-0.8854 G loss:-1.748\n",
      "Epoch:  0000 D loss:-0.9251 G loss:-1.703\n",
      "Epoch:  0000 D loss:-0.9122 G loss:-1.715\n",
      "Epoch:  0000 D loss:-0.8515 G loss:-1.67\n",
      "Epoch:  0000 D loss:-0.8744 G loss:-1.639\n",
      "Epoch:  0000 D loss:-0.821 G loss:-1.602\n",
      "Epoch:  0000 D loss:-0.8878 G loss:-1.639\n",
      "Epoch:  0000 D loss:-0.9274 G loss:-1.636\n",
      "Epoch:  0000 D loss:-0.8351 G loss:-1.627\n",
      "Epoch:  0000 D loss:-0.8716 G loss:-1.653\n",
      "Epoch:  0000 D loss:-0.8584 G loss:-1.644\n",
      "Epoch:  0000 D loss:-0.8444 G loss:-1.637\n",
      "Epoch:  0000 D loss:-0.828 G loss:-1.671\n",
      "Epoch:  0000 D loss:-0.8238 G loss:-1.681\n",
      "Epoch:  0000 D loss:-0.8411 G loss:-1.625\n",
      "Epoch:  0000 D loss:-0.834 G loss:-1.633\n",
      "Epoch:  0000 D loss:-0.7772 G loss:-1.669\n",
      "Epoch:  0000 D loss:-0.8543 G loss:-1.669\n",
      "Epoch:  0000 D loss:-0.8124 G loss:-1.678\n",
      "Epoch:  0000 D loss:-0.8682 G loss:-1.668\n",
      "Epoch:  0000 D loss:-0.7956 G loss:-1.65\n",
      "Epoch:  0000 D loss:-0.8561 G loss:-1.69\n",
      "Epoch:  0000 D loss:-0.7796 G loss:-1.691\n",
      "Epoch:  0000 D loss:-0.9169 G loss:-1.661\n",
      "Epoch:  0000 D loss:-0.8398 G loss:-1.712\n",
      "Epoch:  0000 D loss:-0.8573 G loss:-1.677\n",
      "Epoch:  0000 D loss:-0.8292 G loss:-1.641\n",
      "Epoch:  0000 D loss:-0.8347 G loss:-1.69\n",
      "Epoch:  0000 D loss:-0.8715 G loss:-1.627\n",
      "Epoch:  0000 D loss:-0.7891 G loss:-1.628\n",
      "Epoch:  0000 D loss:-0.8148 G loss:-1.656\n",
      "Epoch:  0000 D loss:-0.8295 G loss:-1.678\n",
      "Epoch:  0000 D loss:-0.8885 G loss:-1.647\n",
      "Epoch:  0000 D loss:-0.8648 G loss:-1.613\n",
      "Epoch:  0000 D loss:-0.8381 G loss:-1.656\n",
      "Epoch:  0000 D loss:-0.8022 G loss:-1.647\n",
      "Epoch:  0000 D loss:-0.7527 G loss:-1.665\n",
      "Epoch:  0000 D loss:-0.8152 G loss:-1.706\n",
      "Epoch:  0000 D loss:-0.8092 G loss:-1.699\n",
      "Epoch:  0000 D loss:-0.7879 G loss:-1.706\n",
      "Epoch:  0000 D loss:-0.8 G loss:-1.695\n",
      "Epoch:  0000 D loss:-0.7728 G loss:-1.692\n",
      "Epoch:  0000 D loss:-0.7964 G loss:-1.718\n",
      "Epoch:  0000 D loss:-0.7959 G loss:-1.713\n",
      "Epoch:  0000 D loss:-0.8131 G loss:-1.684\n",
      "Epoch:  0000 D loss:-0.7413 G loss:-1.66\n",
      "Epoch:  0000 D loss:-0.8118 G loss:-1.649\n",
      "Epoch:  0000 D loss:-0.8248 G loss:-1.668\n",
      "Epoch:  0000 D loss:-0.7962 G loss:-1.685\n",
      "Epoch:  0000 D loss:-0.7934 G loss:-1.701\n",
      "Epoch:  0000 D loss:-0.7722 G loss:-1.72\n",
      "Epoch:  0000 D loss:-0.8345 G loss:-1.692\n",
      "Epoch:  0000 D loss:-0.8095 G loss:-1.701\n",
      "Epoch:  0000 D loss:-0.8111 G loss:-1.672\n",
      "Epoch:  0000 D loss:-0.7576 G loss:-1.636\n",
      "Epoch:  0000 D loss:-0.768 G loss:-1.646\n",
      "Epoch:  0000 D loss:-0.7575 G loss:-1.699\n",
      "Epoch:  0000 D loss:-0.7326 G loss:-1.702\n",
      "Epoch:  0000 D loss:-0.7105 G loss:-1.742\n",
      "Epoch:  0000 D loss:-0.745 G loss:-1.761\n",
      "Epoch:  0000 D loss:-0.7611 G loss:-1.752\n",
      "Epoch:  0000 D loss:-0.7435 G loss:-1.785\n",
      "Epoch:  0000 D loss:-0.7565 G loss:-1.765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0000 D loss:-0.7097 G loss:-1.74\n",
      "Epoch:  0000 D loss:-0.7043 G loss:-1.758\n",
      "Epoch:  0000 D loss:-0.6971 G loss:-1.786\n",
      "Epoch:  0000 D loss:-0.7517 G loss:-1.795\n",
      "Epoch:  0000 D loss:-0.7688 G loss:-1.795\n",
      "Epoch:  0000 D loss:-0.6887 G loss:-1.754\n",
      "Epoch:  0000 D loss:-0.726 G loss:-1.723\n",
      "Epoch:  0000 D loss:-0.667 G loss:-1.747\n",
      "Epoch:  0000 D loss:-0.682 G loss:-1.754\n",
      "Epoch:  0000 D loss:-0.7317 G loss:-1.779\n",
      "Epoch:  0000 D loss:-0.6954 G loss:-1.787\n",
      "Epoch:  0000 D loss:-0.7776 G loss:-1.788\n",
      "Epoch:  0000 D loss:-0.6738 G loss:-1.782\n",
      "Epoch:  0000 D loss:-0.699 G loss:-1.818\n",
      "Epoch:  0000 D loss:-0.6909 G loss:-1.8\n",
      "Epoch:  0000 D loss:-0.7364 G loss:-1.789\n",
      "Epoch:  0000 D loss:-0.6977 G loss:-1.755\n",
      "Epoch:  0000 D loss:-0.7279 G loss:-1.754\n",
      "Epoch:  0000 D loss:-0.72 G loss:-1.727\n",
      "Epoch:  0000 D loss:-0.7116 G loss:-1.766\n",
      "Epoch:  0000 D loss:-0.6679 G loss:-1.759\n",
      "Epoch:  0000 D loss:-0.7133 G loss:-1.759\n",
      "Epoch:  0000 D loss:-0.7067 G loss:-1.791\n",
      "Epoch:  0000 D loss:-0.7168 G loss:-1.789\n",
      "Epoch:  0000 D loss:-0.7412 G loss:-1.819\n",
      "Epoch:  0000 D loss:-0.7106 G loss:-1.809\n",
      "Epoch:  0000 D loss:-0.6381 G loss:-1.834\n",
      "Epoch:  0000 D loss:-0.7022 G loss:-1.834\n",
      "Epoch:  0000 D loss:-0.7455 G loss:-1.814\n",
      "Epoch:  0000 D loss:-0.6687 G loss:-1.807\n",
      "Epoch:  0000 D loss:-0.6685 G loss:-1.795\n",
      "Epoch:  0000 D loss:-0.6919 G loss:-1.809\n",
      "Epoch:  0000 D loss:-0.7296 G loss:-1.817\n",
      "Epoch:  0000 D loss:-0.6733 G loss:-1.774\n",
      "Epoch:  0000 D loss:-0.7075 G loss:-1.75\n",
      "Epoch:  0000 D loss:-0.7218 G loss:-1.737\n",
      "Epoch:  0000 D loss:-0.7354 G loss:-1.703\n",
      "Epoch:  0000 D loss:-0.6924 G loss:-1.741\n",
      "Epoch:  0000 D loss:-0.7087 G loss:-1.782\n",
      "Epoch:  0000 D loss:-0.6503 G loss:-1.817\n",
      "Epoch:  0000 D loss:-0.6415 G loss:-1.849\n",
      "Epoch:  0000 D loss:-0.6849 G loss:-1.862\n",
      "Epoch:  0000 D loss:-0.7649 G loss:-1.827\n",
      "Epoch:  0000 D loss:-0.7161 G loss:-1.803\n",
      "Epoch:  0000 D loss:-0.7219 G loss:-1.788\n",
      "Epoch:  0000 D loss:-0.7116 G loss:-1.755\n",
      "Epoch:  0000 D loss:-0.6764 G loss:-1.768\n",
      "Epoch:  0000 D loss:-0.7352 G loss:-1.805\n",
      "Epoch:  0000 D loss:-0.7218 G loss:-1.784\n",
      "Epoch:  0000 D loss:-0.7938 G loss:-1.78\n",
      "Epoch:  0000 D loss:-0.7203 G loss:-1.709\n",
      "Epoch:  0000 D loss:-0.6684 G loss:-1.731\n",
      "Epoch:  0000 D loss:-0.7881 G loss:-1.723\n",
      "Epoch:  0000 D loss:-0.693 G loss:-1.742\n",
      "Epoch:  0000 D loss:-0.7715 G loss:-1.758\n",
      "Epoch:  0000 D loss:-0.7085 G loss:-1.749\n",
      "Epoch:  0000 D loss:-0.6455 G loss:-1.797\n",
      "Epoch:  0000 D loss:-0.7104 G loss:-1.828\n",
      "Epoch:  0000 D loss:-0.6786 G loss:-1.862\n",
      "Epoch:  0000 D loss:-0.6837 G loss:-1.839\n",
      "Epoch:  0000 D loss:-0.6748 G loss:-1.847\n",
      "Epoch:  0000 D loss:-0.6432 G loss:-1.851\n",
      "Epoch:  0000 D loss:-0.719 G loss:-1.83\n",
      "Epoch:  0000 D loss:-0.7187 G loss:-1.789\n",
      "Epoch:  0000 D loss:-0.6694 G loss:-1.796\n",
      "Epoch:  0000 D loss:-0.734 G loss:-1.752\n",
      "Epoch:  0000 D loss:-0.6885 G loss:-1.724\n",
      "Epoch:  0000 D loss:-0.6615 G loss:-1.738\n",
      "Epoch:  0000 D loss:-0.6995 G loss:-1.741\n",
      "Epoch:  0000 D loss:-0.7569 G loss:-1.752\n",
      "Epoch:  0000 D loss:-0.7343 G loss:-1.761\n",
      "Epoch:  0000 D loss:-0.5889 G loss:-1.809\n",
      "Epoch:  0000 D loss:-0.688 G loss:-1.84\n",
      "Epoch:  0000 D loss:-0.7476 G loss:-1.871\n",
      "Epoch:  0000 D loss:-0.6166 G loss:-1.917\n",
      "Epoch:  0000 D loss:-0.6523 G loss:-1.91\n",
      "Epoch:  0000 D loss:-0.6385 G loss:-1.9\n",
      "Epoch:  0000 D loss:-0.7526 G loss:-1.878\n",
      "Epoch:  0000 D loss:-0.6046 G loss:-1.849\n",
      "Epoch:  0000 D loss:-0.676 G loss:-1.845\n",
      "Epoch:  0000 D loss:-0.6561 G loss:-1.819\n",
      "Epoch:  0000 D loss:-0.6456 G loss:-1.801\n",
      "Epoch:  0000 D loss:-0.6431 G loss:-1.839\n",
      "Epoch:  0000 D loss:-0.6186 G loss:-1.86\n",
      "Epoch:  0000 D loss:-0.6811 G loss:-1.849\n",
      "Epoch:  0000 D loss:-0.6181 G loss:-1.861\n",
      "Epoch:  0000 D loss:-0.6046 G loss:-1.862\n",
      "Epoch:  0000 D loss:-0.6515 G loss:-1.899\n",
      "Epoch:  0000 D loss:-0.6301 G loss:-1.9\n",
      "Epoch:  0000 D loss:-0.6306 G loss:-1.913\n",
      "Epoch:  0000 D loss:-0.6004 G loss:-1.918\n",
      "Epoch:  0000 D loss:-0.6316 G loss:-1.941\n",
      "Epoch:  0000 D loss:-0.5906 G loss:-1.974\n",
      "Epoch:  0000 D loss:-0.5989 G loss:-1.967\n",
      "Epoch:  0000 D loss:-0.5683 G loss:-1.989\n",
      "Epoch:  0000 D loss:-0.6192 G loss:-1.972\n",
      "Epoch:  0000 D loss:-0.5925 G loss:-1.934\n",
      "Epoch:  0000 D loss:-0.6558 G loss:-1.899\n",
      "Epoch:  0000 D loss:-0.5951 G loss:-1.888\n",
      "Epoch:  0000 D loss:-0.633 G loss:-1.861\n",
      "Epoch:  0000 D loss:-0.5939 G loss:-1.867\n",
      "Epoch:  0000 D loss:-0.6422 G loss:-1.852\n",
      "Epoch:  0000 D loss:-0.5804 G loss:-1.876\n",
      "Epoch:  0000 D loss:-0.6131 G loss:-1.892\n",
      "Epoch:  0000 D loss:-0.5643 G loss:-1.888\n",
      "Epoch:  0000 D loss:-0.5808 G loss:-1.939\n",
      "Epoch:  0000 D loss:-0.5271 G loss:-1.981\n",
      "Epoch:  0000 D loss:-0.5326 G loss:-2.012\n",
      "Epoch:  0000 D loss:-0.6026 G loss:-2.036\n",
      "Epoch:  0000 D loss:-0.5561 G loss:-2.035\n",
      "Epoch:  0000 D loss:-0.5959 G loss:-2.025\n",
      "Epoch:  0000 D loss:-0.5626 G loss:-2.006\n",
      "Epoch:  0000 D loss:-0.5372 G loss:-1.996\n",
      "Epoch:  0000 D loss:-0.5446 G loss:-1.956\n",
      "Epoch:  0000 D loss:-0.5609 G loss:-1.946\n",
      "Epoch:  0000 D loss:-0.5046 G loss:-1.953\n",
      "Epoch:  0000 D loss:-0.5603 G loss:-1.954\n",
      "Epoch:  0000 D loss:-0.5924 G loss:-1.948\n",
      "Epoch:  0000 D loss:-0.4741 G loss:-1.989\n",
      "Epoch:  0000 D loss:-0.5368 G loss:-1.997\n",
      "Epoch:  0000 D loss:-0.6207 G loss:-1.995\n",
      "Epoch:  0000 D loss:-0.5473 G loss:-1.992\n",
      "Epoch:  0000 D loss:-0.5353 G loss:-1.995\n",
      "Epoch:  0000 D loss:-0.5266 G loss:-1.984\n",
      "Epoch:  0000 D loss:-0.5493 G loss:-1.984\n",
      "Epoch:  0000 D loss:-0.5423 G loss:-1.983\n",
      "Epoch:  0000 D loss:-0.4756 G loss:-2.014\n",
      "Epoch:  0000 D loss:-0.5684 G loss:-2.016\n",
      "Epoch:  0000 D loss:-0.469 G loss:-2.041\n",
      "Epoch:  0000 D loss:-0.5059 G loss:-2.063\n",
      "Epoch:  0000 D loss:-0.4466 G loss:-2.108\n",
      "Epoch:  0000 D loss:-0.5024 G loss:-2.116\n",
      "Epoch:  0000 D loss:-0.4929 G loss:-2.138\n",
      "Epoch:  0000 D loss:-0.4877 G loss:-2.14\n",
      "Epoch:  0000 D loss:-0.5226 G loss:-2.139\n",
      "Epoch:  0000 D loss:-0.5272 G loss:-2.115\n",
      "Epoch:  0000 D loss:-0.5424 G loss:-2.059\n",
      "Epoch:  0000 D loss:-0.5173 G loss:-2.017\n",
      "Epoch:  0000 D loss:-0.5524 G loss:-1.979\n",
      "Epoch:  0000 D loss:-0.4902 G loss:-1.963\n",
      "Epoch:  0000 D loss:-0.4786 G loss:-1.985\n",
      "Epoch:  0000 D loss:-0.5075 G loss:-2.012\n",
      "Epoch:  0000 D loss:-0.4664 G loss:-2.055\n",
      "Epoch:  0000 D loss:-0.5402 G loss:-2.107\n",
      "Epoch:  0000 D loss:-0.4726 G loss:-2.142\n",
      "Epoch:  0001 D loss:-0.5634 G loss:-2.14\n",
      "Epoch:  0001 D loss:-0.5543 G loss:-2.115\n",
      "Epoch:  0001 D loss:-0.4624 G loss:-2.085\n",
      "Epoch:  0001 D loss:-0.5165 G loss:-2.064\n",
      "Epoch:  0001 D loss:-0.5526 G loss:-2.034\n",
      "Epoch:  0001 D loss:-0.5301 G loss:-2.016\n",
      "Epoch:  0001 D loss:-0.5463 G loss:-1.993\n",
      "Epoch:  0001 D loss:-0.5865 G loss:-1.976\n",
      "Epoch:  0001 D loss:-0.5221 G loss:-1.972\n",
      "Epoch:  0001 D loss:-0.4755 G loss:-1.996\n",
      "Epoch:  0001 D loss:-0.6075 G loss:-2.005\n",
      "Epoch:  0001 D loss:-0.5404 G loss:-2.004\n",
      "Epoch:  0001 D loss:-0.5183 G loss:-2.022\n",
      "Epoch:  0001 D loss:-0.4932 G loss:-2.063\n",
      "Epoch:  0001 D loss:-0.5654 G loss:-2.079\n",
      "Epoch:  0001 D loss:-0.5267 G loss:-2.064\n",
      "Epoch:  0001 D loss:-0.6493 G loss:-2.053\n",
      "Epoch:  0001 D loss:-0.5157 G loss:-2.021\n",
      "Epoch:  0001 D loss:-0.6009 G loss:-1.998\n",
      "Epoch:  0001 D loss:-0.5431 G loss:-1.964\n",
      "Epoch:  0001 D loss:-0.567 G loss:-1.973\n",
      "Epoch:  0001 D loss:-0.5826 G loss:-1.968\n",
      "Epoch:  0001 D loss:-0.5519 G loss:-1.962\n",
      "Epoch:  0001 D loss:-0.5535 G loss:-1.998\n",
      "Epoch:  0001 D loss:-0.5298 G loss:-2.024\n",
      "Epoch:  0001 D loss:-0.5604 G loss:-2.039\n",
      "Epoch:  0001 D loss:-0.5777 G loss:-2.041\n",
      "Epoch:  0001 D loss:-0.5688 G loss:-2.025\n",
      "Epoch:  0001 D loss:-0.5618 G loss:-2.02\n",
      "Epoch:  0001 D loss:-0.5113 G loss:-2.022\n",
      "Epoch:  0001 D loss:-0.5664 G loss:-2.033\n",
      "Epoch:  0001 D loss:-0.5474 G loss:-2.049\n",
      "Epoch:  0001 D loss:-0.557 G loss:-2.046\n",
      "Epoch:  0001 D loss:-0.5039 G loss:-2.064\n",
      "Epoch:  0001 D loss:-0.5626 G loss:-2.075\n",
      "Epoch:  0001 D loss:-0.5829 G loss:-2.076\n",
      "Epoch:  0001 D loss:-0.5471 G loss:-2.065\n",
      "Epoch:  0001 D loss:-0.4845 G loss:-2.044\n",
      "Epoch:  0001 D loss:-0.5178 G loss:-2.063\n",
      "Epoch:  0001 D loss:-0.5322 G loss:-2.087\n",
      "Epoch:  0001 D loss:-0.5661 G loss:-2.086\n",
      "Epoch:  0001 D loss:-0.6019 G loss:-2.074\n",
      "Epoch:  0001 D loss:-0.5793 G loss:-2.044\n",
      "Epoch:  0001 D loss:-0.4666 G loss:-2.056\n",
      "Epoch:  0001 D loss:-0.5159 G loss:-2.065\n",
      "Epoch:  0001 D loss:-0.4808 G loss:-2.106\n",
      "Epoch:  0001 D loss:-0.477 G loss:-2.131\n",
      "Epoch:  0001 D loss:-0.4813 G loss:-2.156\n",
      "Epoch:  0001 D loss:-0.4966 G loss:-2.162\n",
      "Epoch:  0001 D loss:-0.5199 G loss:-2.179\n",
      "Epoch:  0001 D loss:-0.4939 G loss:-2.156\n",
      "Epoch:  0001 D loss:-0.4928 G loss:-2.164\n",
      "Epoch:  0001 D loss:-0.5416 G loss:-2.145\n",
      "Epoch:  0001 D loss:-0.5139 G loss:-2.129\n",
      "Epoch:  0001 D loss:-0.5681 G loss:-2.107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 D loss:-0.5182 G loss:-2.085\n",
      "Epoch:  0001 D loss:-0.4874 G loss:-2.072\n",
      "Epoch:  0001 D loss:-0.4367 G loss:-2.08\n",
      "Epoch:  0001 D loss:-0.4107 G loss:-2.12\n",
      "Epoch:  0001 D loss:-0.472 G loss:-2.16\n",
      "Epoch:  0001 D loss:-0.4524 G loss:-2.187\n",
      "Epoch:  0001 D loss:-0.4336 G loss:-2.243\n",
      "Epoch:  0001 D loss:-0.5369 G loss:-2.245\n",
      "Epoch:  0001 D loss:-0.4037 G loss:-2.25\n",
      "Epoch:  0001 D loss:-0.4837 G loss:-2.265\n",
      "Epoch:  0001 D loss:-0.3923 G loss:-2.259\n",
      "Epoch:  0001 D loss:-0.4221 G loss:-2.278\n",
      "Epoch:  0001 D loss:-0.4662 G loss:-2.25\n",
      "Epoch:  0001 D loss:-0.3482 G loss:-2.269\n",
      "Epoch:  0001 D loss:-0.4645 G loss:-2.283\n",
      "Epoch:  0001 D loss:-0.4399 G loss:-2.256\n",
      "Epoch:  0001 D loss:-0.368 G loss:-2.283\n",
      "Epoch:  0001 D loss:-0.3938 G loss:-2.296\n",
      "Epoch:  0001 D loss:-0.4833 G loss:-2.282\n",
      "Epoch:  0001 D loss:-0.4119 G loss:-2.262\n",
      "Epoch:  0001 D loss:-0.4024 G loss:-2.278\n",
      "Epoch:  0001 D loss:-0.3458 G loss:-2.279\n",
      "Epoch:  0001 D loss:-0.3715 G loss:-2.294\n",
      "Epoch:  0001 D loss:-0.4228 G loss:-2.335\n",
      "Epoch:  0001 D loss:-0.4778 G loss:-2.29\n",
      "Epoch:  0001 D loss:-0.3565 G loss:-2.316\n",
      "Epoch:  0001 D loss:-0.4355 G loss:-2.331\n",
      "Epoch:  0001 D loss:-0.3424 G loss:-2.347\n",
      "Epoch:  0001 D loss:-0.3624 G loss:-2.348\n",
      "Epoch:  0001 D loss:-0.3747 G loss:-2.355\n",
      "Epoch:  0001 D loss:-0.4069 G loss:-2.364\n",
      "Epoch:  0001 D loss:-0.3919 G loss:-2.346\n",
      "Epoch:  0001 D loss:-0.3444 G loss:-2.36\n",
      "Epoch:  0001 D loss:-0.3321 G loss:-2.355\n",
      "Epoch:  0001 D loss:-0.3995 G loss:-2.353\n",
      "Epoch:  0001 D loss:-0.3228 G loss:-2.378\n",
      "Epoch:  0001 D loss:-0.4256 G loss:-2.362\n",
      "Epoch:  0001 D loss:-0.4043 G loss:-2.332\n",
      "Epoch:  0001 D loss:-0.4545 G loss:-2.307\n",
      "Epoch:  0001 D loss:-0.3973 G loss:-2.284\n",
      "Epoch:  0001 D loss:-0.3489 G loss:-2.27\n",
      "Epoch:  0001 D loss:-0.3971 G loss:-2.259\n",
      "Epoch:  0001 D loss:-0.3786 G loss:-2.25\n",
      "Epoch:  0001 D loss:-0.4377 G loss:-2.25\n",
      "Epoch:  0001 D loss:-0.4008 G loss:-2.296\n",
      "Epoch:  0001 D loss:-0.4073 G loss:-2.304\n",
      "Epoch:  0001 D loss:-0.3509 G loss:-2.289\n",
      "Epoch:  0001 D loss:-0.4483 G loss:-2.303\n",
      "Epoch:  0001 D loss:-0.4482 G loss:-2.303\n",
      "Epoch:  0001 D loss:-0.3715 G loss:-2.321\n",
      "Epoch:  0001 D loss:-0.4186 G loss:-2.238\n",
      "Epoch:  0001 D loss:-0.3891 G loss:-2.261\n",
      "Epoch:  0001 D loss:-0.4232 G loss:-2.245\n",
      "Epoch:  0001 D loss:-0.3383 G loss:-2.261\n",
      "Epoch:  0001 D loss:-0.4076 G loss:-2.274\n",
      "Epoch:  0001 D loss:-0.3893 G loss:-2.297\n",
      "Epoch:  0001 D loss:-0.446 G loss:-2.299\n",
      "Epoch:  0001 D loss:-0.4239 G loss:-2.288\n",
      "Epoch:  0001 D loss:-0.4082 G loss:-2.27\n",
      "Epoch:  0001 D loss:-0.399 G loss:-2.242\n",
      "Epoch:  0001 D loss:-0.4512 G loss:-2.224\n",
      "Epoch:  0001 D loss:-0.4577 G loss:-2.218\n",
      "Epoch:  0001 D loss:-0.3833 G loss:-2.22\n",
      "Epoch:  0001 D loss:-0.4344 G loss:-2.202\n",
      "Epoch:  0001 D loss:-0.4396 G loss:-2.184\n",
      "Epoch:  0001 D loss:-0.4245 G loss:-2.182\n",
      "Epoch:  0001 D loss:-0.4094 G loss:-2.174\n",
      "Epoch:  0001 D loss:-0.4146 G loss:-2.186\n",
      "Epoch:  0001 D loss:-0.4175 G loss:-2.225\n",
      "Epoch:  0001 D loss:-0.405 G loss:-2.242\n",
      "Epoch:  0001 D loss:-0.4395 G loss:-2.252\n",
      "Epoch:  0001 D loss:-0.4047 G loss:-2.245\n",
      "Epoch:  0001 D loss:-0.4392 G loss:-2.275\n",
      "Epoch:  0001 D loss:-0.3985 G loss:-2.27\n",
      "Epoch:  0001 D loss:-0.3949 G loss:-2.267\n",
      "Epoch:  0001 D loss:-0.4057 G loss:-2.305\n",
      "Epoch:  0001 D loss:-0.428 G loss:-2.276\n",
      "Epoch:  0001 D loss:-0.3709 G loss:-2.251\n",
      "Epoch:  0001 D loss:-0.4506 G loss:-2.255\n",
      "Epoch:  0001 D loss:-0.4229 G loss:-2.239\n",
      "Epoch:  0001 D loss:-0.4468 G loss:-2.221\n",
      "Epoch:  0001 D loss:-0.4398 G loss:-2.218\n",
      "Epoch:  0001 D loss:-0.3909 G loss:-2.219\n",
      "Epoch:  0001 D loss:-0.3615 G loss:-2.194\n",
      "Epoch:  0001 D loss:-0.3933 G loss:-2.212\n",
      "Epoch:  0001 D loss:-0.4112 G loss:-2.207\n",
      "Epoch:  0001 D loss:-0.4063 G loss:-2.224\n",
      "Epoch:  0001 D loss:-0.4186 G loss:-2.243\n",
      "Epoch:  0001 D loss:-0.429 G loss:-2.243\n",
      "Epoch:  0001 D loss:-0.363 G loss:-2.258\n",
      "Epoch:  0001 D loss:-0.3787 G loss:-2.298\n",
      "Epoch:  0001 D loss:-0.4076 G loss:-2.281\n",
      "Epoch:  0001 D loss:-0.3956 G loss:-2.302\n",
      "Epoch:  0001 D loss:-0.3659 G loss:-2.335\n",
      "Epoch:  0001 D loss:-0.3686 G loss:-2.34\n",
      "Epoch:  0001 D loss:-0.4291 G loss:-2.294\n",
      "Epoch:  0001 D loss:-0.336 G loss:-2.305\n",
      "Epoch:  0001 D loss:-0.3955 G loss:-2.302\n",
      "Epoch:  0001 D loss:-0.393 G loss:-2.304\n",
      "Epoch:  0001 D loss:-0.4243 G loss:-2.271\n",
      "Epoch:  0001 D loss:-0.4284 G loss:-2.263\n",
      "Epoch:  0001 D loss:-0.3862 G loss:-2.26\n",
      "Epoch:  0001 D loss:-0.4106 G loss:-2.239\n",
      "Epoch:  0001 D loss:-0.3926 G loss:-2.249\n",
      "Epoch:  0001 D loss:-0.3617 G loss:-2.226\n",
      "Epoch:  0001 D loss:-0.3852 G loss:-2.221\n",
      "Epoch:  0001 D loss:-0.3744 G loss:-2.244\n",
      "Epoch:  0001 D loss:-0.3746 G loss:-2.257\n",
      "Epoch:  0001 D loss:-0.332 G loss:-2.256\n",
      "Epoch:  0001 D loss:-0.3997 G loss:-2.298\n",
      "Epoch:  0001 D loss:-0.3836 G loss:-2.333\n",
      "Epoch:  0001 D loss:-0.3441 G loss:-2.337\n",
      "Epoch:  0001 D loss:-0.4054 G loss:-2.345\n",
      "Epoch:  0001 D loss:-0.3746 G loss:-2.347\n",
      "Epoch:  0001 D loss:-0.3611 G loss:-2.362\n",
      "Epoch:  0001 D loss:-0.3208 G loss:-2.329\n",
      "Epoch:  0001 D loss:-0.3711 G loss:-2.34\n",
      "Epoch:  0001 D loss:-0.3937 G loss:-2.317\n",
      "Epoch:  0001 D loss:-0.3518 G loss:-2.292\n",
      "Epoch:  0001 D loss:-0.3861 G loss:-2.32\n",
      "Epoch:  0001 D loss:-0.3376 G loss:-2.296\n",
      "Epoch:  0001 D loss:-0.3793 G loss:-2.279\n",
      "Epoch:  0001 D loss:-0.3742 G loss:-2.286\n",
      "Epoch:  0001 D loss:-0.3459 G loss:-2.265\n",
      "Epoch:  0001 D loss:-0.3355 G loss:-2.307\n",
      "Epoch:  0001 D loss:-0.3336 G loss:-2.32\n",
      "Epoch:  0001 D loss:-0.3925 G loss:-2.337\n",
      "Epoch:  0001 D loss:-0.3375 G loss:-2.357\n",
      "Epoch:  0001 D loss:-0.3381 G loss:-2.352\n",
      "Epoch:  0001 D loss:-0.3422 G loss:-2.365\n",
      "Epoch:  0001 D loss:-0.327 G loss:-2.366\n",
      "Epoch:  0001 D loss:-0.3353 G loss:-2.369\n",
      "Epoch:  0001 D loss:-0.3232 G loss:-2.414\n",
      "Epoch:  0001 D loss:-0.3382 G loss:-2.411\n",
      "Epoch:  0001 D loss:-0.3785 G loss:-2.377\n",
      "Epoch:  0001 D loss:-0.3867 G loss:-2.356\n",
      "Epoch:  0001 D loss:-0.3366 G loss:-2.344\n",
      "Epoch:  0001 D loss:-0.3262 G loss:-2.317\n",
      "Epoch:  0001 D loss:-0.4201 G loss:-2.278\n",
      "Epoch:  0001 D loss:-0.3675 G loss:-2.266\n",
      "Epoch:  0001 D loss:-0.3778 G loss:-2.283\n",
      "Epoch:  0001 D loss:-0.3415 G loss:-2.255\n",
      "Epoch:  0001 D loss:-0.3438 G loss:-2.227\n",
      "Epoch:  0001 D loss:-0.3537 G loss:-2.256\n",
      "Epoch:  0001 D loss:-0.3679 G loss:-2.285\n",
      "Epoch:  0001 D loss:-0.4044 G loss:-2.289\n",
      "Epoch:  0001 D loss:-0.3912 G loss:-2.281\n",
      "Epoch:  0001 D loss:-0.4058 G loss:-2.279\n",
      "Epoch:  0001 D loss:-0.3739 G loss:-2.243\n",
      "Epoch:  0001 D loss:-0.3445 G loss:-2.277\n",
      "Epoch:  0001 D loss:-0.3352 G loss:-2.267\n",
      "Epoch:  0001 D loss:-0.3759 G loss:-2.289\n",
      "Epoch:  0001 D loss:-0.3516 G loss:-2.29\n",
      "Epoch:  0001 D loss:-0.3575 G loss:-2.302\n",
      "Epoch:  0001 D loss:-0.3311 G loss:-2.32\n",
      "Epoch:  0001 D loss:-0.3559 G loss:-2.323\n",
      "Epoch:  0001 D loss:-0.3379 G loss:-2.354\n",
      "Epoch:  0001 D loss:-0.3606 G loss:-2.342\n",
      "Epoch:  0001 D loss:-0.3272 G loss:-2.367\n",
      "Epoch:  0001 D loss:-0.3393 G loss:-2.343\n",
      "Epoch:  0001 D loss:-0.3829 G loss:-2.363\n",
      "Epoch:  0001 D loss:-0.3592 G loss:-2.357\n",
      "Epoch:  0001 D loss:-0.3769 G loss:-2.332\n",
      "Epoch:  0001 D loss:-0.3673 G loss:-2.299\n",
      "Epoch:  0001 D loss:-0.3716 G loss:-2.291\n",
      "Epoch:  0001 D loss:-0.301 G loss:-2.308\n",
      "Epoch:  0001 D loss:-0.2764 G loss:-2.327\n",
      "Epoch:  0001 D loss:-0.3055 G loss:-2.341\n",
      "Epoch:  0001 D loss:-0.3101 G loss:-2.369\n",
      "Epoch:  0001 D loss:-0.3336 G loss:-2.4\n",
      "Epoch:  0001 D loss:-0.3449 G loss:-2.405\n",
      "Epoch:  0001 D loss:-0.3449 G loss:-2.409\n",
      "Epoch:  0001 D loss:-0.3208 G loss:-2.391\n",
      "Epoch:  0001 D loss:-0.3666 G loss:-2.387\n",
      "Epoch:  0001 D loss:-0.3444 G loss:-2.362\n",
      "Epoch:  0001 D loss:-0.2902 G loss:-2.361\n",
      "Epoch:  0001 D loss:-0.2994 G loss:-2.395\n",
      "Epoch:  0001 D loss:-0.2721 G loss:-2.366\n",
      "Epoch:  0001 D loss:-0.3104 G loss:-2.401\n",
      "Epoch:  0001 D loss:-0.3459 G loss:-2.388\n",
      "Epoch:  0001 D loss:-0.3263 G loss:-2.387\n",
      "Epoch:  0001 D loss:-0.3158 G loss:-2.379\n",
      "Epoch:  0001 D loss:-0.3241 G loss:-2.369\n",
      "Epoch:  0001 D loss:-0.3591 G loss:-2.404\n",
      "Epoch:  0001 D loss:-0.2802 G loss:-2.399\n",
      "Epoch:  0001 D loss:-0.2794 G loss:-2.414\n",
      "Epoch:  0001 D loss:-0.2918 G loss:-2.419\n",
      "Epoch:  0001 D loss:-0.3555 G loss:-2.432\n",
      "Epoch:  0001 D loss:-0.3164 G loss:-2.407\n",
      "Epoch:  0001 D loss:-0.2869 G loss:-2.426\n",
      "Epoch:  0001 D loss:-0.2837 G loss:-2.444\n",
      "Epoch:  0001 D loss:-0.3143 G loss:-2.42\n",
      "Epoch:  0001 D loss:-0.3021 G loss:-2.444\n",
      "Epoch:  0001 D loss:-0.259 G loss:-2.433\n",
      "Epoch:  0001 D loss:-0.3567 G loss:-2.443\n",
      "Epoch:  0001 D loss:-0.2477 G loss:-2.454\n",
      "Epoch:  0001 D loss:-0.316 G loss:-2.445\n",
      "Epoch:  0001 D loss:-0.3387 G loss:-2.458\n",
      "Epoch:  0001 D loss:-0.2953 G loss:-2.441\n",
      "Epoch:  0001 D loss:-0.2721 G loss:-2.412\n",
      "Epoch:  0001 D loss:-0.2422 G loss:-2.435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 D loss:-0.2678 G loss:-2.457\n",
      "Epoch:  0001 D loss:-0.3046 G loss:-2.465\n",
      "Epoch:  0001 D loss:-0.2545 G loss:-2.469\n",
      "Epoch:  0001 D loss:-0.2556 G loss:-2.512\n",
      "Epoch:  0001 D loss:-0.2843 G loss:-2.509\n",
      "Epoch:  0001 D loss:-0.2806 G loss:-2.537\n",
      "Epoch:  0001 D loss:-0.2767 G loss:-2.543\n",
      "Epoch:  0001 D loss:-0.2815 G loss:-2.535\n",
      "Epoch:  0001 D loss:-0.2491 G loss:-2.546\n",
      "Epoch:  0001 D loss:-0.2878 G loss:-2.549\n",
      "Epoch:  0001 D loss:-0.2607 G loss:-2.544\n",
      "Epoch:  0001 D loss:-0.2655 G loss:-2.549\n",
      "Epoch:  0001 D loss:-0.2567 G loss:-2.548\n",
      "Epoch:  0001 D loss:-0.2875 G loss:-2.562\n",
      "Epoch:  0001 D loss:-0.2706 G loss:-2.554\n",
      "Epoch:  0001 D loss:-0.2632 G loss:-2.55\n",
      "Epoch:  0001 D loss:-0.2622 G loss:-2.545\n",
      "Epoch:  0001 D loss:-0.2721 G loss:-2.535\n",
      "Epoch:  0001 D loss:-0.2719 G loss:-2.533\n",
      "Epoch:  0001 D loss:-0.2728 G loss:-2.532\n",
      "Epoch:  0001 D loss:-0.2608 G loss:-2.522\n",
      "Epoch:  0001 D loss:-0.2587 G loss:-2.536\n",
      "Epoch:  0001 D loss:-0.2378 G loss:-2.517\n",
      "Epoch:  0001 D loss:-0.2499 G loss:-2.527\n",
      "Epoch:  0001 D loss:-0.257 G loss:-2.544\n",
      "Epoch:  0001 D loss:-0.2056 G loss:-2.564\n",
      "Epoch:  0001 D loss:-0.2272 G loss:-2.587\n",
      "Epoch:  0001 D loss:-0.27 G loss:-2.593\n",
      "Epoch:  0001 D loss:-0.2989 G loss:-2.598\n",
      "Epoch:  0001 D loss:-0.272 G loss:-2.607\n",
      "Epoch:  0001 D loss:-0.2459 G loss:-2.594\n",
      "Epoch:  0001 D loss:-0.2472 G loss:-2.568\n",
      "Epoch:  0001 D loss:-0.2242 G loss:-2.588\n",
      "Epoch:  0001 D loss:-0.2512 G loss:-2.588\n",
      "Epoch:  0001 D loss:-0.254 G loss:-2.598\n",
      "Epoch:  0001 D loss:-0.2488 G loss:-2.59\n",
      "Epoch:  0001 D loss:-0.2581 G loss:-2.583\n",
      "Epoch:  0001 D loss:-0.2778 G loss:-2.586\n",
      "Epoch:  0001 D loss:-0.2217 G loss:-2.581\n",
      "Epoch:  0001 D loss:-0.2331 G loss:-2.578\n",
      "Epoch:  0001 D loss:-0.2258 G loss:-2.586\n",
      "Epoch:  0001 D loss:-0.2219 G loss:-2.595\n",
      "Epoch:  0001 D loss:-0.2559 G loss:-2.61\n",
      "Epoch:  0001 D loss:-0.2179 G loss:-2.622\n",
      "Epoch:  0001 D loss:-0.2274 G loss:-2.637\n",
      "Epoch:  0001 D loss:-0.233 G loss:-2.633\n",
      "Epoch:  0001 D loss:-0.2332 G loss:-2.644\n",
      "Epoch:  0001 D loss:-0.2319 G loss:-2.639\n",
      "Epoch:  0001 D loss:-0.2605 G loss:-2.655\n",
      "Epoch:  0001 D loss:-0.2215 G loss:-2.644\n",
      "Epoch:  0001 D loss:-0.2669 G loss:-2.628\n",
      "Epoch:  0001 D loss:-0.2319 G loss:-2.625\n",
      "Epoch:  0001 D loss:-0.2231 G loss:-2.609\n",
      "Epoch:  0001 D loss:-0.2318 G loss:-2.611\n",
      "Epoch:  0001 D loss:-0.2246 G loss:-2.614\n",
      "Epoch:  0001 D loss:-0.2548 G loss:-2.626\n",
      "Epoch:  0001 D loss:-0.2386 G loss:-2.631\n",
      "Epoch:  0001 D loss:-0.227 G loss:-2.636\n",
      "Epoch:  0001 D loss:-0.2623 G loss:-2.635\n",
      "Epoch:  0001 D loss:-0.2393 G loss:-2.647\n",
      "Epoch:  0001 D loss:-0.2402 G loss:-2.642\n",
      "Epoch:  0001 D loss:-0.2409 G loss:-2.632\n",
      "Epoch:  0001 D loss:-0.2673 G loss:-2.626\n",
      "Epoch:  0001 D loss:-0.2726 G loss:-2.592\n",
      "Epoch:  0001 D loss:-0.2226 G loss:-2.597\n",
      "Epoch:  0001 D loss:-0.2386 G loss:-2.589\n",
      "Epoch:  0001 D loss:-0.2643 G loss:-2.578\n",
      "Epoch:  0001 D loss:-0.2337 G loss:-2.582\n",
      "Epoch:  0001 D loss:-0.2203 G loss:-2.58\n",
      "Epoch:  0001 D loss:-0.2171 G loss:-2.603\n",
      "Epoch:  0001 D loss:-0.2122 G loss:-2.625\n",
      "Epoch:  0001 D loss:-0.2203 G loss:-2.652\n",
      "Epoch:  0001 D loss:-0.2253 G loss:-2.677\n",
      "Epoch:  0001 D loss:-0.2125 G loss:-2.693\n",
      "Epoch:  0001 D loss:-0.2155 G loss:-2.719\n",
      "Epoch:  0001 D loss:-0.2076 G loss:-2.745\n",
      "Epoch:  0001 D loss:-0.2099 G loss:-2.752\n",
      "Epoch:  0001 D loss:-0.2355 G loss:-2.765\n",
      "Epoch:  0001 D loss:-0.2676 G loss:-2.759\n",
      "Epoch:  0001 D loss:-0.2014 G loss:-2.751\n",
      "Epoch:  0001 D loss:-0.2038 G loss:-2.752\n",
      "Epoch:  0001 D loss:-0.2453 G loss:-2.727\n",
      "Epoch:  0001 D loss:-0.18 G loss:-2.722\n",
      "Epoch:  0001 D loss:-0.224 G loss:-2.714\n",
      "Epoch:  0001 D loss:-0.196 G loss:-2.718\n",
      "Epoch:  0001 D loss:-0.2231 G loss:-2.719\n",
      "Epoch:  0001 D loss:-0.2324 G loss:-2.709\n",
      "Epoch:  0001 D loss:-0.2222 G loss:-2.718\n",
      "Epoch:  0001 D loss:-0.1992 G loss:-2.72\n",
      "Epoch:  0001 D loss:-0.2038 G loss:-2.719\n",
      "Epoch:  0001 D loss:-0.1884 G loss:-2.738\n",
      "Epoch:  0001 D loss:-0.1842 G loss:-2.749\n",
      "Epoch:  0001 D loss:-0.2074 G loss:-2.757\n",
      "Epoch:  0001 D loss:-0.2203 G loss:-2.764\n",
      "Epoch:  0001 D loss:-0.2153 G loss:-2.762\n",
      "Epoch:  0001 D loss:-0.2036 G loss:-2.776\n",
      "Epoch:  0001 D loss:-0.1832 G loss:-2.768\n",
      "Epoch:  0001 D loss:-0.1899 G loss:-2.775\n",
      "Epoch:  0001 D loss:-0.2279 G loss:-2.766\n",
      "Epoch:  0001 D loss:-0.2275 G loss:-2.753\n",
      "Epoch:  0001 D loss:-0.2168 G loss:-2.744\n",
      "Epoch:  0001 D loss:-0.2122 G loss:-2.73\n",
      "Epoch:  0001 D loss:-0.2351 G loss:-2.707\n",
      "Epoch:  0001 D loss:-0.1867 G loss:-2.695\n",
      "Epoch:  0001 D loss:-0.2306 G loss:-2.675\n",
      "Epoch:  0001 D loss:-0.1969 G loss:-2.67\n",
      "Epoch:  0001 D loss:-0.2121 G loss:-2.667\n",
      "Epoch:  0001 D loss:-0.1838 G loss:-2.69\n",
      "Epoch:  0001 D loss:-0.2143 G loss:-2.715\n",
      "Epoch:  0001 D loss:-0.2019 G loss:-2.744\n",
      "Epoch:  0001 D loss:-0.2043 G loss:-2.755\n",
      "Epoch:  0001 D loss:-0.2103 G loss:-2.777\n",
      "Epoch:  0001 D loss:-0.1752 G loss:-2.789\n",
      "Epoch:  0001 D loss:-0.2012 G loss:-2.793\n",
      "Epoch:  0001 D loss:-0.2002 G loss:-2.804\n",
      "Epoch:  0001 D loss:-0.2122 G loss:-2.818\n",
      "Epoch:  0001 D loss:-0.2131 G loss:-2.8\n",
      "Epoch:  0001 D loss:-0.2182 G loss:-2.792\n",
      "Epoch:  0001 D loss:-0.215 G loss:-2.781\n",
      "Epoch:  0001 D loss:-0.2334 G loss:-2.78\n",
      "Epoch:  0001 D loss:-0.2122 G loss:-2.747\n",
      "Epoch:  0001 D loss:-0.246 G loss:-2.704\n",
      "Epoch:  0001 D loss:-0.2056 G loss:-2.681\n",
      "Epoch:  0001 D loss:-0.212 G loss:-2.677\n",
      "Epoch:  0001 D loss:-0.2028 G loss:-2.65\n",
      "Epoch:  0001 D loss:-0.2211 G loss:-2.65\n",
      "Epoch:  0001 D loss:-0.2299 G loss:-2.674\n",
      "Epoch:  0001 D loss:-0.1854 G loss:-2.677\n",
      "Epoch:  0001 D loss:-0.219 G loss:-2.708\n",
      "Epoch:  0001 D loss:-0.2234 G loss:-2.714\n",
      "Epoch:  0001 D loss:-0.229 G loss:-2.723\n",
      "Epoch:  0001 D loss:-0.1881 G loss:-2.739\n",
      "Epoch:  0001 D loss:-0.218 G loss:-2.761\n",
      "Epoch:  0001 D loss:-0.2252 G loss:-2.75\n",
      "Epoch:  0001 D loss:-0.2456 G loss:-2.754\n",
      "Epoch:  0001 D loss:-0.2231 G loss:-2.743\n",
      "Epoch:  0001 D loss:-0.2032 G loss:-2.738\n",
      "Epoch:  0001 D loss:-0.2512 G loss:-2.712\n",
      "Epoch:  0001 D loss:-0.2427 G loss:-2.7\n",
      "Epoch:  0001 D loss:-0.2475 G loss:-2.675\n",
      "Epoch:  0001 D loss:-0.2268 G loss:-2.669\n",
      "Epoch:  0001 D loss:-0.1985 G loss:-2.66\n",
      "Epoch:  0001 D loss:-0.2387 G loss:-2.641\n",
      "Epoch:  0001 D loss:-0.2364 G loss:-2.637\n",
      "Epoch:  0001 D loss:-0.2518 G loss:-2.629\n",
      "Epoch:  0001 D loss:-0.2202 G loss:-2.64\n",
      "Epoch:  0001 D loss:-0.311 G loss:-2.615\n",
      "Epoch:  0001 D loss:-0.2327 G loss:-2.595\n",
      "Epoch:  0001 D loss:-0.228 G loss:-2.6\n",
      "Epoch:  0001 D loss:-0.2322 G loss:-2.606\n",
      "Epoch:  0001 D loss:-0.2216 G loss:-2.616\n",
      "Epoch:  0001 D loss:-0.2253 G loss:-2.636\n",
      "Epoch:  0001 D loss:-0.1985 G loss:-2.667\n",
      "Epoch:  0001 D loss:-0.2506 G loss:-2.694\n",
      "Epoch:  0001 D loss:-0.231 G loss:-2.703\n",
      "Epoch:  0001 D loss:-0.2207 G loss:-2.711\n",
      "Epoch:  0001 D loss:-0.2345 G loss:-2.718\n",
      "Epoch:  0001 D loss:-0.2354 G loss:-2.72\n",
      "Epoch:  0001 D loss:-0.1774 G loss:-2.735\n",
      "Epoch:  0001 D loss:-0.192 G loss:-2.754\n",
      "Epoch:  0001 D loss:-0.2326 G loss:-2.749\n",
      "Epoch:  0001 D loss:-0.1842 G loss:-2.764\n",
      "Epoch:  0001 D loss:-0.2156 G loss:-2.774\n",
      "Epoch:  0001 D loss:-0.2063 G loss:-2.756\n",
      "Epoch:  0001 D loss:-0.2073 G loss:-2.773\n",
      "Epoch:  0001 D loss:-0.1962 G loss:-2.776\n",
      "Epoch:  0001 D loss:-0.2133 G loss:-2.773\n",
      "Epoch:  0001 D loss:-0.2173 G loss:-2.766\n",
      "Epoch:  0001 D loss:-0.1897 G loss:-2.768\n",
      "Epoch:  0001 D loss:-0.2124 G loss:-2.77\n",
      "Epoch:  0001 D loss:-0.1853 G loss:-2.777\n",
      "Epoch:  0001 D loss:-0.2072 G loss:-2.784\n",
      "Epoch:  0001 D loss:-0.2807 G loss:-2.771\n",
      "Epoch:  0001 D loss:-0.2183 G loss:-2.742\n",
      "Epoch:  0001 D loss:-0.2548 G loss:-2.743\n",
      "Epoch:  0001 D loss:-0.2051 G loss:-2.718\n",
      "Epoch:  0001 D loss:-0.1946 G loss:-2.704\n",
      "Epoch:  0001 D loss:-0.1951 G loss:-2.704\n",
      "Epoch:  0001 D loss:-0.2302 G loss:-2.714\n",
      "Epoch:  0001 D loss:-0.2259 G loss:-2.706\n",
      "Epoch:  0001 D loss:-0.2089 G loss:-2.724\n",
      "Epoch:  0001 D loss:-0.2221 G loss:-2.713\n",
      "Epoch:  0001 D loss:-0.2098 G loss:-2.728\n",
      "Epoch:  0001 D loss:-0.2448 G loss:-2.737\n",
      "Epoch:  0001 D loss:-0.2383 G loss:-2.737\n",
      "Epoch:  0001 D loss:-0.2378 G loss:-2.702\n",
      "Epoch:  0001 D loss:-0.2036 G loss:-2.687\n",
      "Epoch:  0001 D loss:-0.2086 G loss:-2.701\n",
      "Epoch:  0001 D loss:-0.219 G loss:-2.688\n",
      "Epoch:  0001 D loss:-0.2025 G loss:-2.694\n",
      "Epoch:  0001 D loss:-0.2016 G loss:-2.705\n",
      "Epoch:  0001 D loss:-0.2182 G loss:-2.727\n",
      "Epoch:  0001 D loss:-0.19 G loss:-2.743\n",
      "Epoch:  0001 D loss:-0.2043 G loss:-2.771\n",
      "Epoch:  0001 D loss:-0.21 G loss:-2.787\n",
      "Epoch:  0001 D loss:-0.2187 G loss:-2.794\n",
      "Epoch:  0001 D loss:-0.1779 G loss:-2.778\n",
      "Epoch:  0001 D loss:-0.1832 G loss:-2.797\n",
      "Epoch:  0001 D loss:-0.2296 G loss:-2.809\n",
      "Epoch:  0001 D loss:-0.1828 G loss:-2.809\n",
      "Epoch:  0001 D loss:-0.2069 G loss:-2.808\n",
      "Epoch:  0001 D loss:-0.2344 G loss:-2.795\n",
      "Epoch:  0001 D loss:-0.2272 G loss:-2.792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 D loss:-0.1967 G loss:-2.762\n",
      "Epoch:  0001 D loss:-0.1813 G loss:-2.753\n",
      "Epoch:  0001 D loss:-0.2169 G loss:-2.753\n",
      "Epoch:  0001 D loss:-0.2191 G loss:-2.749\n",
      "Epoch:  0001 D loss:-0.1967 G loss:-2.734\n",
      "Epoch:  0001 D loss:-0.2207 G loss:-2.739\n",
      "Epoch:  0001 D loss:-0.2289 G loss:-2.723\n",
      "Epoch:  0001 D loss:-0.1975 G loss:-2.724\n",
      "Epoch:  0001 D loss:-0.226 G loss:-2.708\n",
      "Epoch:  0001 D loss:-0.191 G loss:-2.739\n",
      "Epoch:  0001 D loss:-0.2477 G loss:-2.734\n",
      "Epoch:  0001 D loss:-0.2368 G loss:-2.721\n",
      "Epoch:  0001 D loss:-0.2325 G loss:-2.709\n",
      "Epoch:  0001 D loss:-0.2166 G loss:-2.69\n",
      "Epoch:  0001 D loss:-0.1842 G loss:-2.716\n",
      "Epoch:  0001 D loss:-0.238 G loss:-2.709\n",
      "Epoch:  0001 D loss:-0.2479 G loss:-2.698\n",
      "Epoch:  0001 D loss:-0.2481 G loss:-2.68\n",
      "Epoch:  0001 D loss:-0.2287 G loss:-2.67\n",
      "Epoch:  0001 D loss:-0.2565 G loss:-2.652\n",
      "Epoch:  0001 D loss:-0.2166 G loss:-2.648\n",
      "Epoch:  0001 D loss:-0.2132 G loss:-2.651\n",
      "Epoch:  0001 D loss:-0.2458 G loss:-2.638\n",
      "Epoch:  0001 D loss:-0.2493 G loss:-2.653\n",
      "Epoch:  0001 D loss:-0.2325 G loss:-2.646\n",
      "Epoch:  0001 D loss:-0.2348 G loss:-2.661\n",
      "Epoch:  0001 D loss:-0.2861 G loss:-2.668\n",
      "Epoch:  0001 D loss:-0.221 G loss:-2.669\n",
      "Epoch:  0001 D loss:-0.2667 G loss:-2.648\n",
      "Epoch:  0001 D loss:-0.3034 G loss:-2.642\n",
      "Epoch:  0001 D loss:-0.2196 G loss:-2.625\n",
      "Epoch:  0001 D loss:-0.2345 G loss:-2.621\n",
      "Epoch:  0001 D loss:-0.2525 G loss:-2.609\n",
      "Epoch:  0001 D loss:-0.2301 G loss:-2.598\n",
      "Epoch:  0001 D loss:-0.2495 G loss:-2.585\n",
      "Epoch:  0001 D loss:-0.2511 G loss:-2.585\n",
      "Epoch:  0001 D loss:-0.2702 G loss:-2.577\n",
      "Epoch:  0001 D loss:-0.2345 G loss:-2.598\n",
      "Epoch:  0001 D loss:-0.233 G loss:-2.603\n",
      "Epoch:  0001 D loss:-0.2816 G loss:-2.607\n",
      "Epoch:  0001 D loss:-0.2402 G loss:-2.631\n",
      "Epoch:  0001 D loss:-0.2568 G loss:-2.626\n",
      "Epoch:  0001 D loss:-0.2682 G loss:-2.634\n",
      "Epoch:  0001 D loss:-0.2721 G loss:-2.608\n",
      "Epoch:  0001 D loss:-0.3133 G loss:-2.604\n",
      "Epoch:  0001 D loss:-0.2546 G loss:-2.584\n",
      "Epoch:  0001 D loss:-0.2396 G loss:-2.575\n",
      "Epoch:  0001 D loss:-0.3001 G loss:-2.567\n",
      "Epoch:  0001 D loss:-0.2535 G loss:-2.585\n",
      "Epoch:  0001 D loss:-0.241 G loss:-2.582\n",
      "Epoch:  0001 D loss:-0.2686 G loss:-2.595\n",
      "Epoch:  0001 D loss:-0.2226 G loss:-2.614\n",
      "Epoch:  0001 D loss:-0.2342 G loss:-2.627\n",
      "Epoch:  0001 D loss:-0.2419 G loss:-2.684\n",
      "Epoch:  0001 D loss:-0.2179 G loss:-2.69\n",
      "Epoch:  0001 D loss:-0.2092 G loss:-2.746\n",
      "Epoch:  0001 D loss:-0.2389 G loss:-2.754\n",
      "Epoch:  0001 D loss:-0.2751 G loss:-2.755\n",
      "Epoch:  0001 D loss:-0.2149 G loss:-2.781\n",
      "Epoch:  0001 D loss:-0.2849 G loss:-2.745\n",
      "Epoch:  0001 D loss:-0.2426 G loss:-2.717\n",
      "Epoch:  0001 D loss:-0.2421 G loss:-2.675\n",
      "Epoch:  0001 D loss:-0.3033 G loss:-2.606\n",
      "Epoch:  0001 D loss:-0.2437 G loss:-2.58\n",
      "Epoch:  0001 D loss:-0.2467 G loss:-2.555\n",
      "Epoch:  0001 D loss:-0.2778 G loss:-2.527\n",
      "Epoch:  0001 D loss:-0.2606 G loss:-2.52\n",
      "Epoch:  0001 D loss:-0.2413 G loss:-2.504\n",
      "Epoch:  0001 D loss:-0.3367 G loss:-2.542\n",
      "Epoch:  0001 D loss:-0.2302 G loss:-2.58\n",
      "Epoch:  0001 D loss:-0.2316 G loss:-2.609\n",
      "Epoch:  0001 D loss:-0.2756 G loss:-2.627\n",
      "Epoch:  0001 D loss:-0.3261 G loss:-2.627\n",
      "Epoch:  0001 D loss:-0.3024 G loss:-2.627\n",
      "Epoch:  0001 D loss:-0.2627 G loss:-2.607\n",
      "Epoch:  0001 D loss:-0.2626 G loss:-2.614\n",
      "Epoch:  0001 D loss:-0.2738 G loss:-2.638\n",
      "Epoch:  0001 D loss:-0.2772 G loss:-2.609\n",
      "Epoch:  0001 D loss:-0.2543 G loss:-2.587\n",
      "Epoch:  0001 D loss:-0.2902 G loss:-2.584\n",
      "Epoch:  0001 D loss:-0.3305 G loss:-2.544\n",
      "Epoch:  0001 D loss:-0.2908 G loss:-2.54\n",
      "Epoch:  0001 D loss:-0.2899 G loss:-2.533\n",
      "Epoch:  0001 D loss:-0.2667 G loss:-2.508\n",
      "Epoch:  0001 D loss:-0.2832 G loss:-2.497\n",
      "Epoch:  0001 D loss:-0.2461 G loss:-2.528\n",
      "Epoch:  0001 D loss:-0.2421 G loss:-2.538\n",
      "Epoch:  0001 D loss:-0.2824 G loss:-2.588\n",
      "Epoch:  0001 D loss:-0.2832 G loss:-2.594\n",
      "Epoch:  0001 D loss:-0.2736 G loss:-2.644\n",
      "Epoch:  0001 D loss:-0.259 G loss:-2.657\n",
      "Epoch:  0002 D loss:-0.2893 G loss:-2.664\n",
      "Epoch:  0002 D loss:-0.241 G loss:-2.647\n",
      "Epoch:  0002 D loss:-0.2767 G loss:-2.668\n",
      "Epoch:  0002 D loss:-0.3002 G loss:-2.616\n",
      "Epoch:  0002 D loss:-0.2313 G loss:-2.597\n",
      "Epoch:  0002 D loss:-0.3092 G loss:-2.583\n",
      "Epoch:  0002 D loss:-0.267 G loss:-2.583\n",
      "Epoch:  0002 D loss:-0.2836 G loss:-2.549\n",
      "Epoch:  0002 D loss:-0.2709 G loss:-2.567\n",
      "Epoch:  0002 D loss:-0.3444 G loss:-2.581\n",
      "Epoch:  0002 D loss:-0.3287 G loss:-2.53\n",
      "Epoch:  0002 D loss:-0.3243 G loss:-2.506\n",
      "Epoch:  0002 D loss:-0.2783 G loss:-2.489\n",
      "Epoch:  0002 D loss:-0.2672 G loss:-2.509\n",
      "Epoch:  0002 D loss:-0.3129 G loss:-2.487\n",
      "Epoch:  0002 D loss:-0.3093 G loss:-2.515\n",
      "Epoch:  0002 D loss:-0.339 G loss:-2.453\n",
      "Epoch:  0002 D loss:-0.3131 G loss:-2.535\n",
      "Epoch:  0002 D loss:-0.3162 G loss:-2.488\n",
      "Epoch:  0002 D loss:-0.279 G loss:-2.539\n",
      "Epoch:  0002 D loss:-0.316 G loss:-2.553\n",
      "Epoch:  0002 D loss:-0.2868 G loss:-2.576\n",
      "Epoch:  0002 D loss:-0.2629 G loss:-2.547\n",
      "Epoch:  0002 D loss:-0.3338 G loss:-2.536\n",
      "Epoch:  0002 D loss:-0.3177 G loss:-2.595\n",
      "Epoch:  0002 D loss:-0.3374 G loss:-2.514\n",
      "Epoch:  0002 D loss:-0.3222 G loss:-2.526\n",
      "Epoch:  0002 D loss:-0.3025 G loss:-2.47\n",
      "Epoch:  0002 D loss:-0.2605 G loss:-2.591\n",
      "Epoch:  0002 D loss:-0.2941 G loss:-2.581\n",
      "Epoch:  0002 D loss:-0.2646 G loss:-2.63\n",
      "Epoch:  0002 D loss:-0.3116 G loss:-2.59\n",
      "Epoch:  0002 D loss:-0.2835 G loss:-2.593\n",
      "Epoch:  0002 D loss:-0.3565 G loss:-2.596\n",
      "Epoch:  0002 D loss:-0.348 G loss:-2.548\n",
      "Epoch:  0002 D loss:-0.3116 G loss:-2.454\n",
      "Epoch:  0002 D loss:-0.3915 G loss:-2.428\n",
      "Epoch:  0002 D loss:-0.3159 G loss:-2.4\n",
      "Epoch:  0002 D loss:-0.3183 G loss:-2.36\n",
      "Epoch:  0002 D loss:-0.3228 G loss:-2.388\n",
      "Epoch:  0002 D loss:-0.335 G loss:-2.405\n",
      "Epoch:  0002 D loss:-0.3747 G loss:-2.404\n",
      "Epoch:  0002 D loss:-0.3307 G loss:-2.373\n",
      "Epoch:  0002 D loss:-0.3068 G loss:-2.434\n",
      "Epoch:  0002 D loss:-0.3862 G loss:-2.496\n",
      "Epoch:  0002 D loss:-0.3261 G loss:-2.488\n",
      "Epoch:  0002 D loss:-0.3491 G loss:-2.532\n",
      "Epoch:  0002 D loss:-0.3567 G loss:-2.54\n",
      "Epoch:  0002 D loss:-0.3432 G loss:-2.437\n",
      "Epoch:  0002 D loss:-0.3646 G loss:-2.485\n",
      "Epoch:  0002 D loss:-0.3308 G loss:-2.397\n",
      "Epoch:  0002 D loss:-0.3732 G loss:-2.438\n",
      "Epoch:  0002 D loss:-0.3292 G loss:-2.455\n",
      "Epoch:  0002 D loss:-0.3697 G loss:-2.444\n",
      "Epoch:  0002 D loss:-0.3322 G loss:-2.391\n",
      "Epoch:  0002 D loss:-0.3555 G loss:-2.451\n",
      "Epoch:  0002 D loss:-0.3564 G loss:-2.434\n",
      "Epoch:  0002 D loss:-0.4693 G loss:-2.42\n",
      "Epoch:  0002 D loss:-0.333 G loss:-2.462\n",
      "Epoch:  0002 D loss:-0.4269 G loss:-2.412\n",
      "Epoch:  0002 D loss:-0.4362 G loss:-2.324\n",
      "Epoch:  0002 D loss:-0.4555 G loss:-2.304\n",
      "Epoch:  0002 D loss:-0.3636 G loss:-2.327\n",
      "Epoch:  0002 D loss:-0.348 G loss:-2.311\n",
      "Epoch:  0002 D loss:-0.3868 G loss:-2.297\n",
      "Epoch:  0002 D loss:-0.3817 G loss:-2.317\n",
      "Epoch:  0002 D loss:-0.4266 G loss:-2.34\n",
      "Epoch:  0002 D loss:-0.373 G loss:-2.383\n",
      "Epoch:  0002 D loss:-0.4323 G loss:-2.386\n",
      "Epoch:  0002 D loss:-0.3297 G loss:-2.504\n",
      "Epoch:  0002 D loss:-0.3999 G loss:-2.472\n",
      "Epoch:  0002 D loss:-0.3556 G loss:-2.469\n",
      "Epoch:  0002 D loss:-0.3479 G loss:-2.48\n",
      "Epoch:  0002 D loss:-0.371 G loss:-2.507\n",
      "Epoch:  0002 D loss:-0.3907 G loss:-2.477\n",
      "Epoch:  0002 D loss:-0.3838 G loss:-2.405\n",
      "Epoch:  0002 D loss:-0.3887 G loss:-2.414\n",
      "Epoch:  0002 D loss:-0.4239 G loss:-2.392\n",
      "Epoch:  0002 D loss:-0.3226 G loss:-2.304\n",
      "Epoch:  0002 D loss:-0.443 G loss:-2.292\n",
      "Epoch:  0002 D loss:-0.3666 G loss:-2.315\n",
      "Epoch:  0002 D loss:-0.4231 G loss:-2.218\n",
      "Epoch:  0002 D loss:-0.4111 G loss:-2.312\n",
      "Epoch:  0002 D loss:-0.3099 G loss:-2.308\n",
      "Epoch:  0002 D loss:-0.3535 G loss:-2.34\n",
      "Epoch:  0002 D loss:-0.4332 G loss:-2.327\n",
      "Epoch:  0002 D loss:-0.3705 G loss:-2.387\n",
      "Epoch:  0002 D loss:-0.469 G loss:-2.413\n",
      "Epoch:  0002 D loss:-0.4431 G loss:-2.362\n",
      "Epoch:  0002 D loss:-0.4171 G loss:-2.389\n",
      "Epoch:  0002 D loss:-0.3722 G loss:-2.273\n",
      "Epoch:  0002 D loss:-0.357 G loss:-2.285\n",
      "Epoch:  0002 D loss:-0.3516 G loss:-2.296\n",
      "Epoch:  0002 D loss:-0.3294 G loss:-2.269\n",
      "Epoch:  0002 D loss:-0.3854 G loss:-2.288\n",
      "Epoch:  0002 D loss:-0.3714 G loss:-2.306\n",
      "Epoch:  0002 D loss:-0.3707 G loss:-2.44\n",
      "Epoch:  0002 D loss:-0.3609 G loss:-2.4\n",
      "Epoch:  0002 D loss:-0.4047 G loss:-2.4\n",
      "Epoch:  0002 D loss:-0.3521 G loss:-2.44\n",
      "Epoch:  0002 D loss:-0.2907 G loss:-2.444\n",
      "Epoch:  0002 D loss:-0.3619 G loss:-2.435\n",
      "Epoch:  0002 D loss:-0.3776 G loss:-2.394\n",
      "Epoch:  0002 D loss:-0.3326 G loss:-2.415\n",
      "Epoch:  0002 D loss:-0.3743 G loss:-2.444\n",
      "Epoch:  0002 D loss:-0.3571 G loss:-2.428\n",
      "Epoch:  0002 D loss:-0.4057 G loss:-2.346\n",
      "Epoch:  0002 D loss:-0.3218 G loss:-2.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0002 D loss:-0.3434 G loss:-2.366\n",
      "Epoch:  0002 D loss:-0.3326 G loss:-2.307\n",
      "Epoch:  0002 D loss:-0.3299 G loss:-2.387\n",
      "Epoch:  0002 D loss:-0.3191 G loss:-2.403\n",
      "Epoch:  0002 D loss:-0.3192 G loss:-2.468\n",
      "Epoch:  0002 D loss:-0.359 G loss:-2.414\n",
      "Epoch:  0002 D loss:-0.3457 G loss:-2.44\n",
      "Epoch:  0002 D loss:-0.3172 G loss:-2.454\n",
      "Epoch:  0002 D loss:-0.3466 G loss:-2.501\n",
      "Epoch:  0002 D loss:-0.4009 G loss:-2.5\n",
      "Epoch:  0002 D loss:-0.3406 G loss:-2.435\n",
      "Epoch:  0002 D loss:-0.3866 G loss:-2.422\n",
      "Epoch:  0002 D loss:-0.375 G loss:-2.334\n",
      "Epoch:  0002 D loss:-0.3063 G loss:-2.389\n",
      "Epoch:  0002 D loss:-0.412 G loss:-2.328\n",
      "Epoch:  0002 D loss:-0.3582 G loss:-2.341\n",
      "Epoch:  0002 D loss:-0.4096 G loss:-2.303\n",
      "Epoch:  0002 D loss:-0.4193 G loss:-2.292\n",
      "Epoch:  0002 D loss:-0.3465 G loss:-2.316\n",
      "Epoch:  0002 D loss:-0.4464 G loss:-2.257\n",
      "Epoch:  0002 D loss:-0.3291 G loss:-2.299\n",
      "Epoch:  0002 D loss:-0.3218 G loss:-2.314\n",
      "Epoch:  0002 D loss:-0.3302 G loss:-2.406\n",
      "Epoch:  0002 D loss:-0.4137 G loss:-2.381\n",
      "Epoch:  0002 D loss:-0.3234 G loss:-2.469\n",
      "Epoch:  0002 D loss:-0.3424 G loss:-2.507\n",
      "Epoch:  0002 D loss:-0.371 G loss:-2.474\n",
      "Epoch:  0002 D loss:-0.2883 G loss:-2.526\n",
      "Epoch:  0002 D loss:-0.3121 G loss:-2.563\n",
      "Epoch:  0002 D loss:-0.3531 G loss:-2.496\n",
      "Epoch:  0002 D loss:-0.346 G loss:-2.465\n",
      "Epoch:  0002 D loss:-0.328 G loss:-2.507\n",
      "Epoch:  0002 D loss:-0.3213 G loss:-2.42\n",
      "Epoch:  0002 D loss:-0.3104 G loss:-2.379\n",
      "Epoch:  0002 D loss:-0.3525 G loss:-2.373\n",
      "Epoch:  0002 D loss:-0.3187 G loss:-2.375\n",
      "Epoch:  0002 D loss:-0.308 G loss:-2.302\n",
      "Epoch:  0002 D loss:-0.2866 G loss:-2.337\n",
      "Epoch:  0002 D loss:-0.3282 G loss:-2.373\n",
      "Epoch:  0002 D loss:-0.3392 G loss:-2.341\n",
      "Epoch:  0002 D loss:-0.3818 G loss:-2.393\n",
      "Epoch:  0002 D loss:-0.3225 G loss:-2.498\n",
      "Epoch:  0002 D loss:-0.2579 G loss:-2.525\n",
      "Epoch:  0002 D loss:-0.3043 G loss:-2.549\n",
      "Epoch:  0002 D loss:-0.3205 G loss:-2.539\n",
      "Epoch:  0002 D loss:-0.3173 G loss:-2.522\n",
      "Epoch:  0002 D loss:-0.2826 G loss:-2.568\n",
      "Epoch:  0002 D loss:-0.3183 G loss:-2.505\n",
      "Epoch:  0002 D loss:-0.3158 G loss:-2.558\n",
      "Epoch:  0002 D loss:-0.2518 G loss:-2.517\n",
      "Epoch:  0002 D loss:-0.3071 G loss:-2.475\n",
      "Epoch:  0002 D loss:-0.2943 G loss:-2.579\n",
      "Epoch:  0002 D loss:-0.259 G loss:-2.516\n",
      "Epoch:  0002 D loss:-0.2455 G loss:-2.573\n",
      "Epoch:  0002 D loss:-0.2703 G loss:-2.541\n",
      "Epoch:  0002 D loss:-0.3334 G loss:-2.612\n",
      "Epoch:  0002 D loss:-0.2587 G loss:-2.527\n",
      "Epoch:  0002 D loss:-0.2907 G loss:-2.511\n",
      "Epoch:  0002 D loss:-0.2319 G loss:-2.615\n",
      "Epoch:  0002 D loss:-0.2478 G loss:-2.565\n",
      "Epoch:  0002 D loss:-0.2523 G loss:-2.567\n",
      "Epoch:  0002 D loss:-0.2316 G loss:-2.599\n",
      "Epoch:  0002 D loss:-0.2463 G loss:-2.615\n",
      "Epoch:  0002 D loss:-0.3028 G loss:-2.579\n",
      "Epoch:  0002 D loss:-0.2503 G loss:-2.605\n",
      "Epoch:  0002 D loss:-0.2419 G loss:-2.603\n",
      "Epoch:  0002 D loss:-0.2876 G loss:-2.608\n",
      "Epoch:  0002 D loss:-0.2532 G loss:-2.666\n",
      "Epoch:  0002 D loss:-0.238 G loss:-2.667\n",
      "Epoch:  0002 D loss:-0.2362 G loss:-2.604\n",
      "Epoch:  0002 D loss:-0.2395 G loss:-2.646\n",
      "Epoch:  0002 D loss:-0.2106 G loss:-2.667\n",
      "Epoch:  0002 D loss:-0.2073 G loss:-2.607\n",
      "Epoch:  0002 D loss:-0.2538 G loss:-2.655\n",
      "Epoch:  0002 D loss:-0.2295 G loss:-2.631\n",
      "Epoch:  0002 D loss:-0.2511 G loss:-2.653\n",
      "Epoch:  0002 D loss:-0.2218 G loss:-2.656\n",
      "Epoch:  0002 D loss:-0.2696 G loss:-2.679\n",
      "Epoch:  0002 D loss:-0.2324 G loss:-2.595\n",
      "Epoch:  0002 D loss:-0.216 G loss:-2.628\n",
      "Epoch:  0002 D loss:-0.1914 G loss:-2.685\n",
      "Epoch:  0002 D loss:-0.2444 G loss:-2.693\n",
      "Epoch:  0002 D loss:-0.2216 G loss:-2.735\n",
      "Epoch:  0002 D loss:-0.2391 G loss:-2.742\n",
      "Epoch:  0002 D loss:-0.2281 G loss:-2.734\n",
      "Epoch:  0002 D loss:-0.2116 G loss:-2.719\n",
      "Epoch:  0002 D loss:-0.1872 G loss:-2.726\n",
      "Epoch:  0002 D loss:-0.1952 G loss:-2.761\n",
      "Epoch:  0002 D loss:-0.2083 G loss:-2.735\n",
      "Epoch:  0002 D loss:-0.2205 G loss:-2.708\n",
      "Epoch:  0002 D loss:-0.2117 G loss:-2.719\n",
      "Epoch:  0002 D loss:-0.1994 G loss:-2.705\n",
      "Epoch:  0002 D loss:-0.2129 G loss:-2.684\n",
      "Epoch:  0002 D loss:-0.2052 G loss:-2.671\n",
      "Epoch:  0002 D loss:-0.1988 G loss:-2.704\n",
      "Epoch:  0002 D loss:-0.1954 G loss:-2.677\n",
      "Epoch:  0002 D loss:-0.1966 G loss:-2.73\n",
      "Epoch:  0002 D loss:-0.2043 G loss:-2.698\n",
      "Epoch:  0002 D loss:-0.2064 G loss:-2.713\n",
      "Epoch:  0002 D loss:-0.2252 G loss:-2.713\n",
      "Epoch:  0002 D loss:-0.1975 G loss:-2.693\n",
      "Epoch:  0002 D loss:-0.1606 G loss:-2.744\n",
      "Epoch:  0002 D loss:-0.2329 G loss:-2.719\n",
      "Epoch:  0002 D loss:-0.1809 G loss:-2.772\n",
      "Epoch:  0002 D loss:-0.1729 G loss:-2.753\n",
      "Epoch:  0002 D loss:-0.2139 G loss:-2.807\n",
      "Epoch:  0002 D loss:-0.2074 G loss:-2.833\n",
      "Epoch:  0002 D loss:-0.1992 G loss:-2.829\n",
      "Epoch:  0002 D loss:-0.2222 G loss:-2.795\n",
      "Epoch:  0002 D loss:-0.1997 G loss:-2.789\n",
      "Epoch:  0002 D loss:-0.1851 G loss:-2.791\n",
      "Epoch:  0002 D loss:-0.1794 G loss:-2.773\n",
      "Epoch:  0002 D loss:-0.171 G loss:-2.769\n",
      "Epoch:  0002 D loss:-0.1718 G loss:-2.788\n",
      "Epoch:  0002 D loss:-0.1625 G loss:-2.741\n",
      "Epoch:  0002 D loss:-0.1965 G loss:-2.803\n",
      "Epoch:  0002 D loss:-0.1821 G loss:-2.753\n",
      "Epoch:  0002 D loss:-0.2257 G loss:-2.777\n",
      "Epoch:  0002 D loss:-0.1824 G loss:-2.806\n",
      "Epoch:  0002 D loss:-0.1485 G loss:-2.794\n",
      "Epoch:  0002 D loss:-0.2072 G loss:-2.809\n",
      "Epoch:  0002 D loss:-0.2 G loss:-2.82\n",
      "Epoch:  0002 D loss:-0.1999 G loss:-2.785\n",
      "Epoch:  0002 D loss:-0.1976 G loss:-2.833\n",
      "Epoch:  0002 D loss:-0.2196 G loss:-2.739\n",
      "Epoch:  0002 D loss:-0.1751 G loss:-2.704\n",
      "Epoch:  0002 D loss:-0.1521 G loss:-2.746\n",
      "Epoch:  0002 D loss:-0.1776 G loss:-2.779\n",
      "Epoch:  0002 D loss:-0.2116 G loss:-2.858\n",
      "Epoch:  0002 D loss:-0.2227 G loss:-2.757\n",
      "Epoch:  0002 D loss:-0.1751 G loss:-2.787\n",
      "Epoch:  0002 D loss:-0.1782 G loss:-2.786\n",
      "Epoch:  0002 D loss:-0.1583 G loss:-2.84\n",
      "Epoch:  0002 D loss:-0.1672 G loss:-2.814\n",
      "Epoch:  0002 D loss:-0.2085 G loss:-2.822\n",
      "Epoch:  0002 D loss:-0.146 G loss:-2.895\n",
      "Epoch:  0002 D loss:-0.1765 G loss:-2.956\n",
      "Epoch:  0002 D loss:-0.2126 G loss:-2.934\n",
      "Epoch:  0002 D loss:-0.1574 G loss:-2.882\n",
      "Epoch:  0002 D loss:-0.1819 G loss:-2.841\n",
      "Epoch:  0002 D loss:-0.1911 G loss:-2.91\n",
      "Epoch:  0002 D loss:-0.1556 G loss:-2.89\n",
      "Epoch:  0002 D loss:-0.1511 G loss:-2.858\n",
      "Epoch:  0002 D loss:-0.1516 G loss:-2.892\n",
      "Epoch:  0002 D loss:-0.1576 G loss:-2.941\n",
      "Epoch:  0002 D loss:-0.1523 G loss:-2.92\n",
      "Epoch:  0002 D loss:-0.1831 G loss:-2.94\n",
      "Epoch:  0002 D loss:-0.1631 G loss:-2.93\n",
      "Epoch:  0002 D loss:-0.1602 G loss:-2.903\n",
      "Epoch:  0002 D loss:-0.1572 G loss:-2.996\n",
      "Epoch:  0002 D loss:-0.1986 G loss:-2.909\n",
      "Epoch:  0002 D loss:-0.1795 G loss:-2.976\n",
      "Epoch:  0002 D loss:-0.1843 G loss:-2.912\n",
      "Epoch:  0002 D loss:-0.1881 G loss:-2.913\n",
      "Epoch:  0002 D loss:-0.1385 G loss:-2.878\n",
      "Epoch:  0002 D loss:-0.1774 G loss:-2.93\n",
      "Epoch:  0002 D loss:-0.1749 G loss:-2.862\n",
      "Epoch:  0002 D loss:-0.1714 G loss:-2.83\n",
      "Epoch:  0002 D loss:-0.1573 G loss:-2.905\n",
      "Epoch:  0002 D loss:-0.1688 G loss:-2.881\n",
      "Epoch:  0002 D loss:-0.1445 G loss:-2.87\n",
      "Epoch:  0002 D loss:-0.191 G loss:-2.892\n",
      "Epoch:  0002 D loss:-0.1398 G loss:-2.911\n",
      "Epoch:  0002 D loss:-0.1752 G loss:-2.869\n",
      "Epoch:  0002 D loss:-0.1442 G loss:-2.92\n",
      "Epoch:  0002 D loss:-0.1345 G loss:-2.992\n",
      "Epoch:  0002 D loss:-0.1748 G loss:-2.952\n",
      "Epoch:  0002 D loss:-0.1657 G loss:-2.915\n",
      "Epoch:  0002 D loss:-0.1601 G loss:-2.949\n",
      "Epoch:  0002 D loss:-0.175 G loss:-3.009\n",
      "Epoch:  0002 D loss:-0.1739 G loss:-3.006\n",
      "Epoch:  0002 D loss:-0.1674 G loss:-2.958\n",
      "Epoch:  0002 D loss:-0.1383 G loss:-2.904\n",
      "Epoch:  0002 D loss:-0.1622 G loss:-2.956\n",
      "Epoch:  0002 D loss:-0.1507 G loss:-2.943\n",
      "Epoch:  0002 D loss:-0.1686 G loss:-2.924\n",
      "Epoch:  0002 D loss:-0.1555 G loss:-2.962\n",
      "Epoch:  0002 D loss:-0.1607 G loss:-2.988\n",
      "Epoch:  0002 D loss:-0.1766 G loss:-2.918\n",
      "Epoch:  0002 D loss:-0.1845 G loss:-2.911\n",
      "Epoch:  0002 D loss:-0.2139 G loss:-2.907\n",
      "Epoch:  0002 D loss:-0.1759 G loss:-2.85\n",
      "Epoch:  0002 D loss:-0.1651 G loss:-2.891\n",
      "Epoch:  0002 D loss:-0.1381 G loss:-2.889\n",
      "Epoch:  0002 D loss:-0.2358 G loss:-2.838\n",
      "Epoch:  0002 D loss:-0.1774 G loss:-2.843\n",
      "Epoch:  0002 D loss:-0.1713 G loss:-2.789\n",
      "Epoch:  0002 D loss:-0.1704 G loss:-2.836\n",
      "Epoch:  0002 D loss:-0.1655 G loss:-2.842\n",
      "Epoch:  0002 D loss:-0.1513 G loss:-2.874\n",
      "Epoch:  0002 D loss:-0.1664 G loss:-2.901\n",
      "Epoch:  0002 D loss:-0.1759 G loss:-2.932\n",
      "Epoch:  0002 D loss:-0.1849 G loss:-2.997\n",
      "Epoch:  0002 D loss:-0.1632 G loss:-2.931\n",
      "Epoch:  0002 D loss:-0.164 G loss:-2.981\n",
      "Epoch:  0002 D loss:-0.1632 G loss:-2.919\n",
      "Epoch:  0002 D loss:-0.1746 G loss:-3.026\n",
      "Epoch:  0002 D loss:-0.1636 G loss:-2.973\n",
      "Epoch:  0002 D loss:-0.1627 G loss:-2.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0002 D loss:-0.1504 G loss:-2.975\n",
      "Epoch:  0002 D loss:-0.1618 G loss:-3.043\n",
      "Epoch:  0002 D loss:-0.1619 G loss:-2.935\n",
      "Epoch:  0002 D loss:-0.1726 G loss:-2.989\n",
      "Epoch:  0002 D loss:-0.1742 G loss:-2.954\n",
      "Epoch:  0002 D loss:-0.1732 G loss:-2.99\n",
      "Epoch:  0002 D loss:-0.1572 G loss:-2.967\n",
      "Epoch:  0002 D loss:-0.1786 G loss:-2.886\n",
      "Epoch:  0002 D loss:-0.1691 G loss:-2.943\n",
      "Epoch:  0002 D loss:-0.1658 G loss:-2.864\n",
      "Epoch:  0002 D loss:-0.1634 G loss:-2.973\n",
      "Epoch:  0002 D loss:-0.1667 G loss:-2.839\n",
      "Epoch:  0002 D loss:-0.1637 G loss:-2.955\n",
      "Epoch:  0002 D loss:-0.1647 G loss:-2.859\n",
      "Epoch:  0002 D loss:-0.1689 G loss:-2.962\n",
      "Epoch:  0002 D loss:-0.151 G loss:-2.969\n",
      "Epoch:  0002 D loss:-0.1828 G loss:-2.941\n",
      "Epoch:  0002 D loss:-0.1618 G loss:-2.84\n",
      "Epoch:  0002 D loss:-0.1523 G loss:-2.958\n",
      "Epoch:  0002 D loss:-0.1712 G loss:-2.858\n",
      "Epoch:  0002 D loss:-0.1677 G loss:-2.947\n",
      "Epoch:  0002 D loss:-0.1388 G loss:-2.928\n",
      "Epoch:  0002 D loss:-0.1564 G loss:-2.967\n",
      "Epoch:  0002 D loss:-0.1938 G loss:-2.959\n",
      "Epoch:  0002 D loss:-0.1623 G loss:-2.98\n",
      "Epoch:  0002 D loss:-0.1714 G loss:-3.045\n",
      "Epoch:  0002 D loss:-0.1659 G loss:-3.011\n",
      "Epoch:  0002 D loss:-0.1689 G loss:-2.959\n",
      "Epoch:  0002 D loss:-0.1824 G loss:-2.998\n",
      "Epoch:  0002 D loss:-0.1664 G loss:-2.886\n",
      "Epoch:  0002 D loss:-0.1625 G loss:-2.906\n",
      "Epoch:  0002 D loss:-0.161 G loss:-2.975\n",
      "Epoch:  0002 D loss:-0.1394 G loss:-2.925\n",
      "Epoch:  0002 D loss:-0.1645 G loss:-2.899\n",
      "Epoch:  0002 D loss:-0.1488 G loss:-2.874\n",
      "Epoch:  0002 D loss:-0.1302 G loss:-2.911\n",
      "Epoch:  0002 D loss:-0.1322 G loss:-2.983\n",
      "Epoch:  0002 D loss:-0.1391 G loss:-3.006\n",
      "Epoch:  0002 D loss:-0.1614 G loss:-2.994\n",
      "Epoch:  0002 D loss:-0.1649 G loss:-3.011\n",
      "Epoch:  0002 D loss:-0.1486 G loss:-3.048\n",
      "Epoch:  0002 D loss:-0.1673 G loss:-3.017\n",
      "Epoch:  0002 D loss:-0.1591 G loss:-3.055\n",
      "Epoch:  0002 D loss:-0.1339 G loss:-3.088\n",
      "Epoch:  0002 D loss:-0.1542 G loss:-3.024\n",
      "Epoch:  0002 D loss:-0.1439 G loss:-3.06\n",
      "Epoch:  0002 D loss:-0.1207 G loss:-3.081\n",
      "Epoch:  0002 D loss:-0.1423 G loss:-3.001\n",
      "Epoch:  0002 D loss:-0.1354 G loss:-3.092\n",
      "Epoch:  0002 D loss:-0.1506 G loss:-3.005\n",
      "Epoch:  0002 D loss:-0.139 G loss:-2.983\n",
      "Epoch:  0002 D loss:-0.152 G loss:-3.014\n",
      "Epoch:  0002 D loss:-0.1214 G loss:-2.995\n",
      "Epoch:  0002 D loss:-0.1381 G loss:-2.987\n",
      "Epoch:  0002 D loss:-0.1378 G loss:-3.063\n",
      "Epoch:  0002 D loss:-0.1235 G loss:-3.026\n",
      "Epoch:  0002 D loss:-0.1223 G loss:-3.1\n",
      "Epoch:  0002 D loss:-0.136 G loss:-3.02\n",
      "Epoch:  0002 D loss:-0.1343 G loss:-3.055\n",
      "Epoch:  0002 D loss:-0.1428 G loss:-3.097\n",
      "Epoch:  0002 D loss:-0.1101 G loss:-3.094\n",
      "Epoch:  0002 D loss:-0.1103 G loss:-3.16\n",
      "Epoch:  0002 D loss:-0.119 G loss:-3.182\n",
      "Epoch:  0002 D loss:-0.115 G loss:-3.192\n",
      "Epoch:  0002 D loss:-0.1284 G loss:-3.147\n",
      "Epoch:  0002 D loss:-0.1219 G loss:-3.189\n",
      "Epoch:  0002 D loss:-0.1216 G loss:-3.134\n",
      "Epoch:  0002 D loss:-0.1008 G loss:-3.221\n",
      "Epoch:  0002 D loss:-0.1117 G loss:-3.209\n",
      "Epoch:  0002 D loss:-0.1246 G loss:-3.221\n",
      "Epoch:  0002 D loss:-0.1232 G loss:-3.182\n",
      "Epoch:  0002 D loss:-0.1272 G loss:-3.171\n",
      "Epoch:  0002 D loss:-0.1189 G loss:-3.191\n",
      "Epoch:  0002 D loss:-0.114 G loss:-3.175\n",
      "Epoch:  0002 D loss:-0.1422 G loss:-3.174\n",
      "Epoch:  0002 D loss:-0.1149 G loss:-3.149\n",
      "Epoch:  0002 D loss:-0.105 G loss:-3.194\n",
      "Epoch:  0002 D loss:-0.1134 G loss:-3.218\n",
      "Epoch:  0002 D loss:-0.1274 G loss:-3.146\n",
      "Epoch:  0002 D loss:-0.1097 G loss:-3.192\n",
      "Epoch:  0002 D loss:-0.1279 G loss:-3.166\n",
      "Epoch:  0002 D loss:-0.138 G loss:-3.169\n",
      "Epoch:  0002 D loss:-0.1474 G loss:-3.142\n",
      "Epoch:  0002 D loss:-0.1364 G loss:-3.077\n",
      "Epoch:  0002 D loss:-0.1233 G loss:-3.095\n",
      "Epoch:  0002 D loss:-0.1459 G loss:-3.069\n",
      "Epoch:  0002 D loss:-0.1211 G loss:-3.082\n",
      "Epoch:  0002 D loss:-0.1311 G loss:-3.033\n",
      "Epoch:  0002 D loss:-0.1136 G loss:-3.04\n",
      "Epoch:  0002 D loss:-0.1151 G loss:-3.088\n",
      "Epoch:  0002 D loss:-0.1121 G loss:-3.064\n",
      "Epoch:  0002 D loss:-0.1211 G loss:-3.1\n",
      "Epoch:  0002 D loss:-0.1341 G loss:-3.114\n",
      "Epoch:  0002 D loss:-0.1441 G loss:-3.093\n",
      "Epoch:  0002 D loss:-0.1368 G loss:-3.092\n",
      "Epoch:  0002 D loss:-0.1143 G loss:-3.121\n",
      "Epoch:  0002 D loss:-0.1128 G loss:-3.134\n",
      "Epoch:  0002 D loss:-0.1314 G loss:-3.135\n",
      "Epoch:  0002 D loss:-0.1292 G loss:-3.149\n",
      "Epoch:  0002 D loss:-0.1232 G loss:-3.137\n",
      "Epoch:  0002 D loss:-0.1227 G loss:-3.143\n",
      "Epoch:  0002 D loss:-0.1324 G loss:-3.111\n",
      "Epoch:  0002 D loss:-0.1264 G loss:-3.121\n",
      "Epoch:  0002 D loss:-0.1236 G loss:-3.131\n",
      "Epoch:  0002 D loss:-0.1381 G loss:-3.125\n",
      "Epoch:  0002 D loss:-0.124 G loss:-3.139\n",
      "Epoch:  0002 D loss:-0.1263 G loss:-3.127\n",
      "Epoch:  0002 D loss:-0.1444 G loss:-3.065\n",
      "Epoch:  0002 D loss:-0.1492 G loss:-3.035\n",
      "Epoch:  0002 D loss:-0.1461 G loss:-3.033\n",
      "Epoch:  0002 D loss:-0.1839 G loss:-2.998\n",
      "Epoch:  0002 D loss:-0.1415 G loss:-2.931\n",
      "Epoch:  0002 D loss:-0.1249 G loss:-2.936\n",
      "Epoch:  0002 D loss:-0.1368 G loss:-2.903\n",
      "Epoch:  0002 D loss:-0.1547 G loss:-2.941\n",
      "Epoch:  0002 D loss:-0.1316 G loss:-2.967\n",
      "Epoch:  0002 D loss:-0.1762 G loss:-2.901\n",
      "Epoch:  0002 D loss:-0.1697 G loss:-2.925\n",
      "Epoch:  0002 D loss:-0.1226 G loss:-2.936\n",
      "Epoch:  0002 D loss:-0.1185 G loss:-2.984\n",
      "Epoch:  0002 D loss:-0.1284 G loss:-2.972\n",
      "Epoch:  0002 D loss:-0.1339 G loss:-3.001\n",
      "Epoch:  0002 D loss:-0.1452 G loss:-3.045\n",
      "Epoch:  0002 D loss:-0.1456 G loss:-3.089\n",
      "Epoch:  0002 D loss:-0.1234 G loss:-3.123\n",
      "Epoch:  0002 D loss:-0.1326 G loss:-3.151\n",
      "Epoch:  0002 D loss:-0.1494 G loss:-3.172\n",
      "Epoch:  0002 D loss:-0.156 G loss:-3.129\n",
      "Epoch:  0002 D loss:-0.1441 G loss:-3.12\n",
      "Epoch:  0002 D loss:-0.1439 G loss:-3.08\n",
      "Epoch:  0002 D loss:-0.1298 G loss:-3.082\n",
      "Epoch:  0002 D loss:-0.1316 G loss:-3.056\n",
      "Epoch:  0002 D loss:-0.1438 G loss:-3.077\n",
      "Epoch:  0002 D loss:-0.1288 G loss:-3.039\n",
      "Epoch:  0002 D loss:-0.1532 G loss:-3.008\n",
      "Epoch:  0002 D loss:-0.1259 G loss:-3.005\n",
      "Epoch:  0002 D loss:-0.1319 G loss:-2.999\n",
      "Epoch:  0002 D loss:-0.1351 G loss:-3.023\n",
      "Epoch:  0002 D loss:-0.1675 G loss:-2.976\n",
      "Epoch:  0002 D loss:-0.1785 G loss:-2.969\n",
      "Epoch:  0002 D loss:-0.1407 G loss:-2.988\n",
      "Epoch:  0002 D loss:-0.1391 G loss:-3.01\n",
      "Epoch:  0002 D loss:-0.1352 G loss:-2.956\n",
      "Epoch:  0002 D loss:-0.1449 G loss:-2.996\n",
      "Epoch:  0002 D loss:-0.1504 G loss:-2.98\n",
      "Epoch:  0002 D loss:-0.168 G loss:-3.011\n",
      "Epoch:  0002 D loss:-0.1749 G loss:-2.98\n",
      "Epoch:  0002 D loss:-0.1396 G loss:-2.999\n",
      "Epoch:  0002 D loss:-0.1677 G loss:-2.99\n",
      "Epoch:  0002 D loss:-0.1491 G loss:-3.009\n",
      "Epoch:  0002 D loss:-0.1421 G loss:-2.985\n",
      "Epoch:  0002 D loss:-0.1443 G loss:-2.992\n",
      "Epoch:  0002 D loss:-0.1565 G loss:-2.98\n",
      "Epoch:  0002 D loss:-0.1685 G loss:-2.974\n",
      "Epoch:  0002 D loss:-0.1617 G loss:-2.988\n",
      "Epoch:  0002 D loss:-0.1317 G loss:-2.998\n",
      "Epoch:  0002 D loss:-0.1619 G loss:-2.964\n",
      "Epoch:  0002 D loss:-0.1541 G loss:-2.973\n",
      "Epoch:  0002 D loss:-0.1618 G loss:-2.986\n",
      "Epoch:  0002 D loss:-0.1238 G loss:-2.984\n",
      "Epoch:  0002 D loss:-0.1653 G loss:-3.01\n",
      "Epoch:  0002 D loss:-0.1234 G loss:-3.05\n",
      "Epoch:  0002 D loss:-0.1233 G loss:-3.066\n",
      "Epoch:  0002 D loss:-0.1273 G loss:-3.09\n",
      "Epoch:  0002 D loss:-0.1475 G loss:-3.113\n",
      "Epoch:  0002 D loss:-0.1316 G loss:-3.1\n",
      "Epoch:  0002 D loss:-0.1428 G loss:-3.117\n",
      "Epoch:  0002 D loss:-0.1721 G loss:-3.113\n",
      "Epoch:  0002 D loss:-0.1267 G loss:-3.107\n",
      "Epoch:  0002 D loss:-0.1272 G loss:-3.104\n",
      "Epoch:  0002 D loss:-0.1177 G loss:-3.104\n",
      "Epoch:  0002 D loss:-0.1637 G loss:-3.12\n",
      "Epoch:  0002 D loss:-0.1489 G loss:-3.106\n",
      "Epoch:  0002 D loss:-0.1219 G loss:-3.064\n",
      "Epoch:  0002 D loss:-0.1099 G loss:-3.145\n",
      "Epoch:  0002 D loss:-0.1317 G loss:-3.057\n",
      "Epoch:  0002 D loss:-0.1256 G loss:-3.114\n",
      "Epoch:  0002 D loss:-0.131 G loss:-3.126\n",
      "Epoch:  0002 D loss:-0.155 G loss:-3.078\n",
      "Epoch:  0002 D loss:-0.132 G loss:-3.072\n",
      "Epoch:  0002 D loss:-0.1412 G loss:-3.097\n",
      "Epoch:  0002 D loss:-0.1224 G loss:-3.09\n",
      "Epoch:  0002 D loss:-0.1517 G loss:-3.1\n",
      "Epoch:  0002 D loss:-0.1504 G loss:-3.083\n",
      "Epoch:  0002 D loss:-0.1555 G loss:-3.082\n",
      "Epoch:  0002 D loss:-0.1495 G loss:-3.064\n",
      "Epoch:  0002 D loss:-0.1291 G loss:-3.03\n",
      "Epoch:  0002 D loss:-0.1128 G loss:-3.041\n",
      "Epoch:  0002 D loss:-0.1621 G loss:-3.064\n",
      "Epoch:  0002 D loss:-0.1331 G loss:-3.073\n",
      "Epoch:  0002 D loss:-0.1833 G loss:-3.08\n",
      "Epoch:  0002 D loss:-0.1396 G loss:-2.985\n",
      "Epoch:  0002 D loss:-0.1429 G loss:-3.022\n",
      "Epoch:  0002 D loss:-0.1578 G loss:-2.935\n",
      "Epoch:  0002 D loss:-0.1499 G loss:-2.976\n",
      "Epoch:  0002 D loss:-0.1475 G loss:-2.976\n",
      "Epoch:  0002 D loss:-0.1369 G loss:-2.978\n",
      "Epoch:  0002 D loss:-0.1537 G loss:-2.991\n",
      "Epoch:  0002 D loss:-0.1795 G loss:-3.017\n",
      "Epoch:  0002 D loss:-0.1933 G loss:-2.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0002 D loss:-0.1636 G loss:-2.953\n",
      "Epoch:  0002 D loss:-0.153 G loss:-2.906\n",
      "Epoch:  0002 D loss:-0.1721 G loss:-2.915\n",
      "Epoch:  0002 D loss:-0.1327 G loss:-2.922\n",
      "Epoch:  0002 D loss:-0.1705 G loss:-2.85\n",
      "Epoch:  0002 D loss:-0.1422 G loss:-2.913\n",
      "Epoch:  0002 D loss:-0.1634 G loss:-2.876\n",
      "Epoch:  0002 D loss:-0.1224 G loss:-2.968\n",
      "Epoch:  0002 D loss:-0.162 G loss:-3.015\n",
      "Epoch:  0002 D loss:-0.1763 G loss:-3.076\n",
      "Epoch:  0002 D loss:-0.1814 G loss:-3.026\n",
      "Epoch:  0002 D loss:-0.16 G loss:-3.054\n",
      "Epoch:  0002 D loss:-0.1549 G loss:-3.073\n",
      "Epoch:  0002 D loss:-0.1698 G loss:-3.042\n",
      "Epoch:  0002 D loss:-0.1365 G loss:-3.002\n",
      "Epoch:  0002 D loss:-0.141 G loss:-3.018\n",
      "Epoch:  0002 D loss:-0.1605 G loss:-3.05\n",
      "Epoch:  0002 D loss:-0.1642 G loss:-2.994\n",
      "Epoch:  0002 D loss:-0.1703 G loss:-2.954\n",
      "Epoch:  0002 D loss:-0.1399 G loss:-2.989\n",
      "Epoch:  0002 D loss:-0.1548 G loss:-2.948\n",
      "Epoch:  0002 D loss:-0.1457 G loss:-2.954\n",
      "Epoch:  0002 D loss:-0.1381 G loss:-2.996\n",
      "Epoch:  0002 D loss:-0.1676 G loss:-2.961\n",
      "Epoch:  0002 D loss:-0.1637 G loss:-2.95\n",
      "Epoch:  0002 D loss:-0.1445 G loss:-3.0\n",
      "Epoch:  0002 D loss:-0.1556 G loss:-2.988\n",
      "Epoch:  0002 D loss:-0.1606 G loss:-2.996\n",
      "Epoch:  0002 D loss:-0.1414 G loss:-3.056\n",
      "Epoch:  0002 D loss:-0.2079 G loss:-3.014\n",
      "Epoch:  0002 D loss:-0.1583 G loss:-3.04\n",
      "Epoch:  0002 D loss:-0.153 G loss:-2.975\n",
      "Epoch:  0002 D loss:-0.1405 G loss:-2.984\n",
      "Epoch:  0002 D loss:-0.1305 G loss:-3.057\n",
      "Epoch:  0002 D loss:-0.1298 G loss:-3.079\n",
      "Epoch:  0002 D loss:-0.1418 G loss:-3.087\n",
      "Epoch:  0002 D loss:-0.1206 G loss:-3.139\n",
      "Epoch:  0002 D loss:-0.1441 G loss:-3.184\n",
      "Epoch:  0002 D loss:-0.119 G loss:-3.161\n",
      "Epoch:  0002 D loss:-0.1425 G loss:-3.185\n",
      "Epoch:  0002 D loss:-0.144 G loss:-3.222\n",
      "Epoch:  0002 D loss:-0.09582 G loss:-3.218\n",
      "Epoch:  0002 D loss:-0.1212 G loss:-3.266\n",
      "Epoch:  0003 D loss:-0.1196 G loss:-3.225\n",
      "Epoch:  0003 D loss:-0.1307 G loss:-3.265\n",
      "Epoch:  0003 D loss:-0.1089 G loss:-3.237\n",
      "Epoch:  0003 D loss:-0.1225 G loss:-3.24\n",
      "Epoch:  0003 D loss:-0.1077 G loss:-3.344\n",
      "Epoch:  0003 D loss:-0.1446 G loss:-3.264\n",
      "Epoch:  0003 D loss:-0.1237 G loss:-3.276\n",
      "Epoch:  0003 D loss:-0.1296 G loss:-3.236\n",
      "Epoch:  0003 D loss:-0.1122 G loss:-3.241\n",
      "Epoch:  0003 D loss:-0.1129 G loss:-3.253\n",
      "Epoch:  0003 D loss:-0.1136 G loss:-3.278\n",
      "Epoch:  0003 D loss:-0.1148 G loss:-3.179\n",
      "Epoch:  0003 D loss:-0.1068 G loss:-3.268\n",
      "Epoch:  0003 D loss:-0.112 G loss:-3.314\n",
      "Epoch:  0003 D loss:-0.1285 G loss:-3.28\n",
      "Epoch:  0003 D loss:-0.09441 G loss:-3.297\n",
      "Epoch:  0003 D loss:-0.1089 G loss:-3.268\n",
      "Epoch:  0003 D loss:-0.127 G loss:-3.317\n",
      "Epoch:  0003 D loss:-0.1058 G loss:-3.32\n",
      "Epoch:  0003 D loss:-0.09288 G loss:-3.322\n",
      "Epoch:  0003 D loss:-0.1004 G loss:-3.341\n",
      "Epoch:  0003 D loss:-0.08438 G loss:-3.425\n",
      "Epoch:  0003 D loss:-0.08884 G loss:-3.393\n",
      "Epoch:  0003 D loss:-0.1132 G loss:-3.379\n",
      "Epoch:  0003 D loss:-0.09184 G loss:-3.391\n",
      "Epoch:  0003 D loss:-0.08231 G loss:-3.474\n",
      "Epoch:  0003 D loss:-0.1038 G loss:-3.468\n",
      "Epoch:  0003 D loss:-0.1001 G loss:-3.42\n",
      "Epoch:  0003 D loss:-0.08849 G loss:-3.444\n",
      "Epoch:  0003 D loss:-0.09353 G loss:-3.475\n",
      "Epoch:  0003 D loss:-0.08426 G loss:-3.442\n",
      "Epoch:  0003 D loss:-0.07484 G loss:-3.443\n",
      "Epoch:  0003 D loss:-0.08359 G loss:-3.514\n",
      "Epoch:  0003 D loss:-0.09129 G loss:-3.465\n",
      "Epoch:  0003 D loss:-0.08328 G loss:-3.503\n",
      "Epoch:  0003 D loss:-0.09575 G loss:-3.517\n",
      "Epoch:  0003 D loss:-0.08423 G loss:-3.54\n",
      "Epoch:  0003 D loss:-0.08368 G loss:-3.553\n",
      "Epoch:  0003 D loss:-0.09443 G loss:-3.48\n",
      "Epoch:  0003 D loss:-0.09409 G loss:-3.5\n",
      "Epoch:  0003 D loss:-0.09417 G loss:-3.466\n",
      "Epoch:  0003 D loss:-0.08378 G loss:-3.525\n",
      "Epoch:  0003 D loss:-0.1127 G loss:-3.477\n",
      "Epoch:  0003 D loss:-0.1008 G loss:-3.432\n",
      "Epoch:  0003 D loss:-0.09027 G loss:-3.449\n",
      "Epoch:  0003 D loss:-0.102 G loss:-3.415\n",
      "Epoch:  0003 D loss:-0.0871 G loss:-3.436\n",
      "Epoch:  0003 D loss:-0.08609 G loss:-3.459\n",
      "Epoch:  0003 D loss:-0.08509 G loss:-3.424\n",
      "Epoch:  0003 D loss:-0.09078 G loss:-3.379\n",
      "Epoch:  0003 D loss:-0.1039 G loss:-3.396\n",
      "Epoch:  0003 D loss:-0.09367 G loss:-3.457\n",
      "Epoch:  0003 D loss:-0.08695 G loss:-3.372\n",
      "Epoch:  0003 D loss:-0.1009 G loss:-3.294\n",
      "Epoch:  0003 D loss:-0.1012 G loss:-3.35\n",
      "Epoch:  0003 D loss:-0.08682 G loss:-3.391\n",
      "Epoch:  0003 D loss:-0.0868 G loss:-3.43\n",
      "Epoch:  0003 D loss:-0.08886 G loss:-3.398\n",
      "Epoch:  0003 D loss:-0.1234 G loss:-3.465\n",
      "Epoch:  0003 D loss:-0.105 G loss:-3.425\n",
      "Epoch:  0003 D loss:-0.07826 G loss:-3.449\n",
      "Epoch:  0003 D loss:-0.09935 G loss:-3.433\n",
      "Epoch:  0003 D loss:-0.1096 G loss:-3.382\n",
      "Epoch:  0003 D loss:-0.09312 G loss:-3.401\n",
      "Epoch:  0003 D loss:-0.07184 G loss:-3.432\n",
      "Epoch:  0003 D loss:-0.1192 G loss:-3.389\n",
      "Epoch:  0003 D loss:-0.09382 G loss:-3.412\n",
      "Epoch:  0003 D loss:-0.09985 G loss:-3.437\n",
      "Epoch:  0003 D loss:-0.08266 G loss:-3.389\n",
      "Epoch:  0003 D loss:-0.09708 G loss:-3.416\n",
      "Epoch:  0003 D loss:-0.1007 G loss:-3.379\n",
      "Epoch:  0003 D loss:-0.08029 G loss:-3.473\n",
      "Epoch:  0003 D loss:-0.09028 G loss:-3.466\n",
      "Epoch:  0003 D loss:-0.08874 G loss:-3.461\n",
      "Epoch:  0003 D loss:-0.106 G loss:-3.403\n",
      "Epoch:  0003 D loss:-0.09918 G loss:-3.424\n",
      "Epoch:  0003 D loss:-0.1074 G loss:-3.441\n",
      "Epoch:  0003 D loss:-0.07994 G loss:-3.453\n",
      "Epoch:  0003 D loss:-0.08584 G loss:-3.376\n",
      "Epoch:  0003 D loss:-0.0876 G loss:-3.411\n",
      "Epoch:  0003 D loss:-0.1053 G loss:-3.417\n",
      "Epoch:  0003 D loss:-0.1011 G loss:-3.384\n",
      "Epoch:  0003 D loss:-0.09381 G loss:-3.358\n",
      "Epoch:  0003 D loss:-0.1188 G loss:-3.331\n",
      "Epoch:  0003 D loss:-0.124 G loss:-3.247\n",
      "Epoch:  0003 D loss:-0.09765 G loss:-3.309\n",
      "Epoch:  0003 D loss:-0.08765 G loss:-3.239\n",
      "Epoch:  0003 D loss:-0.1114 G loss:-3.223\n",
      "Epoch:  0003 D loss:-0.08934 G loss:-3.297\n",
      "Epoch:  0003 D loss:-0.09293 G loss:-3.222\n",
      "Epoch:  0003 D loss:-0.1076 G loss:-3.257\n",
      "Epoch:  0003 D loss:-0.1008 G loss:-3.221\n",
      "Epoch:  0003 D loss:-0.0973 G loss:-3.272\n",
      "Epoch:  0003 D loss:-0.09842 G loss:-3.31\n",
      "Epoch:  0003 D loss:-0.1092 G loss:-3.281\n",
      "Epoch:  0003 D loss:-0.1464 G loss:-3.271\n",
      "Epoch:  0003 D loss:-0.09536 G loss:-3.263\n",
      "Epoch:  0003 D loss:-0.1179 G loss:-3.251\n",
      "Epoch:  0003 D loss:-0.1009 G loss:-3.188\n",
      "Epoch:  0003 D loss:-0.1022 G loss:-3.211\n",
      "Epoch:  0003 D loss:-0.118 G loss:-3.234\n",
      "Epoch:  0003 D loss:-0.09125 G loss:-3.19\n",
      "Epoch:  0003 D loss:-0.1022 G loss:-3.256\n",
      "Epoch:  0003 D loss:-0.1254 G loss:-3.248\n",
      "Epoch:  0003 D loss:-0.1141 G loss:-3.233\n",
      "Epoch:  0003 D loss:-0.09912 G loss:-3.236\n",
      "Epoch:  0003 D loss:-0.1012 G loss:-3.244\n",
      "Epoch:  0003 D loss:-0.1098 G loss:-3.243\n",
      "Epoch:  0003 D loss:-0.1146 G loss:-3.221\n",
      "Epoch:  0003 D loss:-0.1047 G loss:-3.26\n",
      "Epoch:  0003 D loss:-0.1114 G loss:-3.31\n",
      "Epoch:  0003 D loss:-0.1142 G loss:-3.244\n",
      "Epoch:  0003 D loss:-0.1291 G loss:-3.205\n",
      "Epoch:  0003 D loss:-0.1245 G loss:-3.182\n",
      "Epoch:  0003 D loss:-0.1021 G loss:-3.192\n",
      "Epoch:  0003 D loss:-0.133 G loss:-3.15\n",
      "Epoch:  0003 D loss:-0.1086 G loss:-3.171\n",
      "Epoch:  0003 D loss:-0.1226 G loss:-3.146\n",
      "Epoch:  0003 D loss:-0.1455 G loss:-3.114\n",
      "Epoch:  0003 D loss:-0.1291 G loss:-3.098\n",
      "Epoch:  0003 D loss:-0.125 G loss:-3.078\n",
      "Epoch:  0003 D loss:-0.1338 G loss:-3.1\n",
      "Epoch:  0003 D loss:-0.1324 G loss:-2.999\n",
      "Epoch:  0003 D loss:-0.1098 G loss:-3.032\n",
      "Epoch:  0003 D loss:-0.1262 G loss:-3.033\n",
      "Epoch:  0003 D loss:-0.1038 G loss:-2.987\n",
      "Epoch:  0003 D loss:-0.1358 G loss:-3.002\n",
      "Epoch:  0003 D loss:-0.1423 G loss:-3.005\n",
      "Epoch:  0003 D loss:-0.1135 G loss:-3.042\n",
      "Epoch:  0003 D loss:-0.1472 G loss:-3.003\n",
      "Epoch:  0003 D loss:-0.1384 G loss:-3.054\n",
      "Epoch:  0003 D loss:-0.1397 G loss:-2.958\n",
      "Epoch:  0003 D loss:-0.1548 G loss:-2.997\n",
      "Epoch:  0003 D loss:-0.1496 G loss:-2.978\n",
      "Epoch:  0003 D loss:-0.1454 G loss:-2.94\n",
      "Epoch:  0003 D loss:-0.1305 G loss:-3.003\n",
      "Epoch:  0003 D loss:-0.1453 G loss:-2.996\n",
      "Epoch:  0003 D loss:-0.14 G loss:-2.957\n",
      "Epoch:  0003 D loss:-0.1547 G loss:-2.903\n",
      "Epoch:  0003 D loss:-0.128 G loss:-2.954\n",
      "Epoch:  0003 D loss:-0.1717 G loss:-2.91\n",
      "Epoch:  0003 D loss:-0.1782 G loss:-2.926\n",
      "Epoch:  0003 D loss:-0.174 G loss:-2.849\n",
      "Epoch:  0003 D loss:-0.1619 G loss:-2.835\n",
      "Epoch:  0003 D loss:-0.1443 G loss:-2.888\n",
      "Epoch:  0003 D loss:-0.1733 G loss:-2.856\n",
      "Epoch:  0003 D loss:-0.1586 G loss:-2.833\n",
      "Epoch:  0003 D loss:-0.1466 G loss:-2.781\n",
      "Epoch:  0003 D loss:-0.1951 G loss:-2.829\n",
      "Epoch:  0003 D loss:-0.202 G loss:-2.746\n",
      "Epoch:  0003 D loss:-0.187 G loss:-2.804\n",
      "Epoch:  0003 D loss:-0.2104 G loss:-2.734\n",
      "Epoch:  0003 D loss:-0.1827 G loss:-2.706\n",
      "Epoch:  0003 D loss:-0.2162 G loss:-2.661\n",
      "Epoch:  0003 D loss:-0.2193 G loss:-2.576\n",
      "Epoch:  0003 D loss:-0.199 G loss:-2.491\n",
      "Epoch:  0003 D loss:-0.226 G loss:-2.532\n",
      "Epoch:  0003 D loss:-0.2166 G loss:-2.562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0003 D loss:-0.2105 G loss:-2.591\n",
      "Epoch:  0003 D loss:-0.2168 G loss:-2.591\n",
      "Epoch:  0003 D loss:-0.2437 G loss:-2.543\n",
      "Epoch:  0003 D loss:-0.2498 G loss:-2.564\n",
      "Epoch:  0003 D loss:-0.211 G loss:-2.537\n",
      "Epoch:  0003 D loss:-0.2304 G loss:-2.506\n",
      "Epoch:  0003 D loss:-0.2234 G loss:-2.578\n",
      "Epoch:  0003 D loss:-0.2807 G loss:-2.531\n",
      "Epoch:  0003 D loss:-0.2444 G loss:-2.512\n",
      "Epoch:  0003 D loss:-0.2281 G loss:-2.485\n",
      "Epoch:  0003 D loss:-0.2392 G loss:-2.434\n",
      "Epoch:  0003 D loss:-0.2594 G loss:-2.353\n",
      "Epoch:  0003 D loss:-0.2235 G loss:-2.422\n",
      "Epoch:  0003 D loss:-0.2409 G loss:-2.405\n",
      "Epoch:  0003 D loss:-0.2174 G loss:-2.46\n",
      "Epoch:  0003 D loss:-0.2778 G loss:-2.402\n",
      "Epoch:  0003 D loss:-0.2586 G loss:-2.42\n",
      "Epoch:  0003 D loss:-0.2804 G loss:-2.478\n",
      "Epoch:  0003 D loss:-0.2535 G loss:-2.481\n",
      "Epoch:  0003 D loss:-0.2524 G loss:-2.473\n",
      "Epoch:  0003 D loss:-0.2422 G loss:-2.454\n",
      "Epoch:  0003 D loss:-0.2181 G loss:-2.508\n",
      "Epoch:  0003 D loss:-0.2386 G loss:-2.514\n",
      "Epoch:  0003 D loss:-0.1878 G loss:-2.552\n",
      "Epoch:  0003 D loss:-0.2537 G loss:-2.527\n",
      "Epoch:  0003 D loss:-0.2102 G loss:-2.538\n",
      "Epoch:  0003 D loss:-0.2785 G loss:-2.588\n",
      "Epoch:  0003 D loss:-0.227 G loss:-2.548\n",
      "Epoch:  0003 D loss:-0.195 G loss:-2.558\n",
      "Epoch:  0003 D loss:-0.2264 G loss:-2.545\n",
      "Epoch:  0003 D loss:-0.2831 G loss:-2.527\n",
      "Epoch:  0003 D loss:-0.232 G loss:-2.602\n",
      "Epoch:  0003 D loss:-0.2193 G loss:-2.538\n",
      "Epoch:  0003 D loss:-0.2788 G loss:-2.406\n",
      "Epoch:  0003 D loss:-0.2417 G loss:-2.524\n",
      "Epoch:  0003 D loss:-0.2138 G loss:-2.49\n",
      "Epoch:  0003 D loss:-0.2451 G loss:-2.471\n",
      "Epoch:  0003 D loss:-0.222 G loss:-2.44\n",
      "Epoch:  0003 D loss:-0.2405 G loss:-2.488\n",
      "Epoch:  0003 D loss:-0.2584 G loss:-2.502\n",
      "Epoch:  0003 D loss:-0.2436 G loss:-2.445\n",
      "Epoch:  0003 D loss:-0.2779 G loss:-2.407\n",
      "Epoch:  0003 D loss:-0.2637 G loss:-2.388\n",
      "Epoch:  0003 D loss:-0.2832 G loss:-2.405\n",
      "Epoch:  0003 D loss:-0.2305 G loss:-2.46\n",
      "Epoch:  0003 D loss:-0.2766 G loss:-2.413\n",
      "Epoch:  0003 D loss:-0.2784 G loss:-2.39\n",
      "Epoch:  0003 D loss:-0.2417 G loss:-2.433\n",
      "Epoch:  0003 D loss:-0.2916 G loss:-2.446\n",
      "Epoch:  0003 D loss:-0.2827 G loss:-2.403\n",
      "Epoch:  0003 D loss:-0.293 G loss:-2.426\n",
      "Epoch:  0003 D loss:-0.2722 G loss:-2.392\n",
      "Epoch:  0003 D loss:-0.305 G loss:-2.44\n",
      "Epoch:  0003 D loss:-0.2803 G loss:-2.28\n",
      "Epoch:  0003 D loss:-0.2652 G loss:-2.393\n",
      "Epoch:  0003 D loss:-0.3244 G loss:-2.277\n",
      "Epoch:  0003 D loss:-0.2846 G loss:-2.294\n",
      "Epoch:  0003 D loss:-0.2289 G loss:-2.373\n",
      "Epoch:  0003 D loss:-0.265 G loss:-2.352\n",
      "Epoch:  0003 D loss:-0.332 G loss:-2.31\n",
      "Epoch:  0003 D loss:-0.2813 G loss:-2.27\n",
      "Epoch:  0003 D loss:-0.2548 G loss:-2.38\n",
      "Epoch:  0003 D loss:-0.3187 G loss:-2.417\n",
      "Epoch:  0003 D loss:-0.3104 G loss:-2.293\n",
      "Epoch:  0003 D loss:-0.3645 G loss:-2.326\n",
      "Epoch:  0003 D loss:-0.308 G loss:-2.34\n",
      "Epoch:  0003 D loss:-0.2858 G loss:-2.341\n",
      "Epoch:  0003 D loss:-0.3339 G loss:-2.284\n",
      "Epoch:  0003 D loss:-0.3972 G loss:-2.299\n",
      "Epoch:  0003 D loss:-0.3096 G loss:-2.324\n",
      "Epoch:  0003 D loss:-0.3276 G loss:-2.362\n",
      "Epoch:  0003 D loss:-0.3421 G loss:-2.265\n",
      "Epoch:  0003 D loss:-0.3526 G loss:-2.249\n",
      "Epoch:  0003 D loss:-0.3448 G loss:-2.087\n",
      "Epoch:  0003 D loss:-0.3097 G loss:-2.151\n",
      "Epoch:  0003 D loss:-0.3648 G loss:-2.053\n",
      "Epoch:  0003 D loss:-0.3572 G loss:-2.133\n",
      "Epoch:  0003 D loss:-0.3002 G loss:-2.141\n",
      "Epoch:  0003 D loss:-0.4555 G loss:-2.061\n",
      "Epoch:  0003 D loss:-0.3439 G loss:-2.115\n",
      "Epoch:  0003 D loss:-0.3409 G loss:-2.169\n",
      "Epoch:  0003 D loss:-0.3383 G loss:-2.154\n",
      "Epoch:  0003 D loss:-0.3768 G loss:-2.186\n",
      "Epoch:  0003 D loss:-0.348 G loss:-2.258\n",
      "Epoch:  0003 D loss:-0.3505 G loss:-2.281\n",
      "Epoch:  0003 D loss:-0.3663 G loss:-2.252\n",
      "Epoch:  0003 D loss:-0.3345 G loss:-2.223\n",
      "Epoch:  0003 D loss:-0.3688 G loss:-2.17\n",
      "Epoch:  0003 D loss:-0.3353 G loss:-2.211\n",
      "Epoch:  0003 D loss:-0.3749 G loss:-2.249\n",
      "Epoch:  0003 D loss:-0.2908 G loss:-2.292\n",
      "Epoch:  0003 D loss:-0.3433 G loss:-2.267\n",
      "Epoch:  0003 D loss:-0.3412 G loss:-2.238\n",
      "Epoch:  0003 D loss:-0.3071 G loss:-2.22\n",
      "Epoch:  0003 D loss:-0.2658 G loss:-2.327\n",
      "Epoch:  0003 D loss:-0.3163 G loss:-2.324\n",
      "Epoch:  0003 D loss:-0.3016 G loss:-2.352\n",
      "Epoch:  0003 D loss:-0.3202 G loss:-2.364\n",
      "Epoch:  0003 D loss:-0.2689 G loss:-2.376\n",
      "Epoch:  0003 D loss:-0.2995 G loss:-2.417\n",
      "Epoch:  0003 D loss:-0.2765 G loss:-2.381\n",
      "Epoch:  0003 D loss:-0.2449 G loss:-2.473\n",
      "Epoch:  0003 D loss:-0.2739 G loss:-2.454\n",
      "Epoch:  0003 D loss:-0.2438 G loss:-2.515\n",
      "Epoch:  0003 D loss:-0.2657 G loss:-2.5\n",
      "Epoch:  0003 D loss:-0.2817 G loss:-2.516\n",
      "Epoch:  0003 D loss:-0.2558 G loss:-2.519\n",
      "Epoch:  0003 D loss:-0.2028 G loss:-2.527\n",
      "Epoch:  0003 D loss:-0.2517 G loss:-2.494\n",
      "Epoch:  0003 D loss:-0.1931 G loss:-2.563\n",
      "Epoch:  0003 D loss:-0.1979 G loss:-2.727\n",
      "Epoch:  0003 D loss:-0.2194 G loss:-2.698\n",
      "Epoch:  0003 D loss:-0.2447 G loss:-2.606\n",
      "Epoch:  0003 D loss:-0.2199 G loss:-2.728\n",
      "Epoch:  0003 D loss:-0.2711 G loss:-2.665\n",
      "Epoch:  0003 D loss:-0.1944 G loss:-2.7\n",
      "Epoch:  0003 D loss:-0.2132 G loss:-2.622\n",
      "Epoch:  0003 D loss:-0.2173 G loss:-2.701\n",
      "Epoch:  0003 D loss:-0.2419 G loss:-2.628\n",
      "Epoch:  0003 D loss:-0.2481 G loss:-2.603\n",
      "Epoch:  0003 D loss:-0.2373 G loss:-2.599\n",
      "Epoch:  0003 D loss:-0.2185 G loss:-2.572\n",
      "Epoch:  0003 D loss:-0.2192 G loss:-2.665\n",
      "Epoch:  0003 D loss:-0.2176 G loss:-2.53\n",
      "Epoch:  0003 D loss:-0.2184 G loss:-2.639\n",
      "Epoch:  0003 D loss:-0.2098 G loss:-2.661\n",
      "Epoch:  0003 D loss:-0.2231 G loss:-2.63\n",
      "Epoch:  0003 D loss:-0.2125 G loss:-2.656\n",
      "Epoch:  0003 D loss:-0.2967 G loss:-2.54\n",
      "Epoch:  0003 D loss:-0.2063 G loss:-2.664\n",
      "Epoch:  0003 D loss:-0.2161 G loss:-2.696\n",
      "Epoch:  0003 D loss:-0.2437 G loss:-2.557\n",
      "Epoch:  0003 D loss:-0.2125 G loss:-2.662\n",
      "Epoch:  0003 D loss:-0.2258 G loss:-2.615\n",
      "Epoch:  0003 D loss:-0.2571 G loss:-2.493\n",
      "Epoch:  0003 D loss:-0.2348 G loss:-2.525\n",
      "Epoch:  0003 D loss:-0.2245 G loss:-2.537\n",
      "Epoch:  0003 D loss:-0.228 G loss:-2.642\n",
      "Epoch:  0003 D loss:-0.229 G loss:-2.456\n",
      "Epoch:  0003 D loss:-0.2127 G loss:-2.713\n",
      "Epoch:  0003 D loss:-0.2972 G loss:-2.471\n",
      "Epoch:  0003 D loss:-0.2605 G loss:-2.605\n",
      "Epoch:  0003 D loss:-0.2361 G loss:-2.544\n",
      "Epoch:  0003 D loss:-0.2664 G loss:-2.68\n",
      "Epoch:  0003 D loss:-0.2699 G loss:-2.608\n",
      "Epoch:  0003 D loss:-0.2637 G loss:-2.598\n",
      "Epoch:  0003 D loss:-0.2984 G loss:-2.724\n",
      "Epoch:  0003 D loss:-0.3034 G loss:-2.583\n",
      "Epoch:  0003 D loss:-0.2954 G loss:-2.34\n",
      "Epoch:  0003 D loss:-0.286 G loss:-2.533\n",
      "Epoch:  0003 D loss:-0.2402 G loss:-2.358\n",
      "Epoch:  0003 D loss:-0.2593 G loss:-2.393\n",
      "Epoch:  0003 D loss:-0.2635 G loss:-2.392\n",
      "Epoch:  0003 D loss:-0.2969 G loss:-2.418\n",
      "Epoch:  0003 D loss:-0.3228 G loss:-2.376\n",
      "Epoch:  0003 D loss:-0.3152 G loss:-2.412\n",
      "Epoch:  0003 D loss:-0.349 G loss:-2.458\n",
      "Epoch:  0003 D loss:-0.3075 G loss:-2.529\n",
      "Epoch:  0003 D loss:-0.3454 G loss:-2.346\n",
      "Epoch:  0003 D loss:-0.3913 G loss:-2.374\n",
      "Epoch:  0003 D loss:-0.4317 G loss:-2.187\n",
      "Epoch:  0003 D loss:-0.4152 G loss:-2.147\n",
      "Epoch:  0003 D loss:-0.3792 G loss:-2.269\n",
      "Epoch:  0003 D loss:-0.4394 G loss:-2.139\n",
      "Epoch:  0003 D loss:-0.3748 G loss:-2.225\n",
      "Epoch:  0003 D loss:-0.3932 G loss:-2.245\n",
      "Epoch:  0003 D loss:-0.3888 G loss:-2.174\n",
      "Epoch:  0003 D loss:-0.4572 G loss:-2.042\n",
      "Epoch:  0003 D loss:-0.4756 G loss:-2.3\n",
      "Epoch:  0003 D loss:-0.4152 G loss:-2.199\n",
      "Epoch:  0003 D loss:-0.5128 G loss:-2.137\n",
      "Epoch:  0003 D loss:-0.477 G loss:-2.056\n",
      "Epoch:  0003 D loss:-0.4273 G loss:-2.026\n",
      "Epoch:  0003 D loss:-0.5024 G loss:-1.909\n",
      "Epoch:  0003 D loss:-0.5344 G loss:-1.973\n",
      "Epoch:  0003 D loss:-0.4527 G loss:-2.004\n",
      "Epoch:  0003 D loss:-0.5529 G loss:-2.047\n",
      "Epoch:  0003 D loss:-0.4924 G loss:-1.928\n",
      "Epoch:  0003 D loss:-0.4777 G loss:-2.004\n",
      "Epoch:  0003 D loss:-0.478 G loss:-1.986\n",
      "Epoch:  0003 D loss:-0.5593 G loss:-1.923\n",
      "Epoch:  0003 D loss:-0.5235 G loss:-2.085\n",
      "Epoch:  0003 D loss:-0.533 G loss:-2.11\n",
      "Epoch:  0003 D loss:-0.6019 G loss:-2.024\n",
      "Epoch:  0003 D loss:-0.6122 G loss:-2.0\n",
      "Epoch:  0003 D loss:-0.4699 G loss:-2.003\n",
      "Epoch:  0003 D loss:-0.6085 G loss:-1.911\n",
      "Epoch:  0003 D loss:-0.5747 G loss:-1.898\n",
      "Epoch:  0003 D loss:-0.6273 G loss:-1.98\n",
      "Epoch:  0003 D loss:-0.5895 G loss:-1.905\n",
      "Epoch:  0003 D loss:-0.548 G loss:-1.929\n",
      "Epoch:  0003 D loss:-0.6312 G loss:-2.052\n",
      "Epoch:  0003 D loss:-0.5498 G loss:-2.002\n",
      "Epoch:  0003 D loss:-0.5317 G loss:-1.814\n",
      "Epoch:  0003 D loss:-0.528 G loss:-2.055\n",
      "Epoch:  0003 D loss:-0.6183 G loss:-2.024\n",
      "Epoch:  0003 D loss:-0.6327 G loss:-1.964\n",
      "Epoch:  0003 D loss:-0.6255 G loss:-1.944\n",
      "Epoch:  0003 D loss:-0.566 G loss:-1.831\n",
      "Epoch:  0003 D loss:-0.5909 G loss:-1.919\n",
      "Epoch:  0003 D loss:-0.6168 G loss:-1.852\n",
      "Epoch:  0003 D loss:-0.6825 G loss:-1.824\n",
      "Epoch:  0003 D loss:-0.6422 G loss:-1.765\n",
      "Epoch:  0003 D loss:-0.5974 G loss:-1.945\n",
      "Epoch:  0003 D loss:-0.5509 G loss:-1.919\n",
      "Epoch:  0003 D loss:-0.5634 G loss:-2.036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0003 D loss:-0.6676 G loss:-2.044\n",
      "Epoch:  0003 D loss:-0.5961 G loss:-2.029\n",
      "Epoch:  0003 D loss:-0.6165 G loss:-1.916\n",
      "Epoch:  0003 D loss:-0.6728 G loss:-1.774\n",
      "Epoch:  0003 D loss:-0.6654 G loss:-1.703\n",
      "Epoch:  0003 D loss:-0.6321 G loss:-1.686\n",
      "Epoch:  0003 D loss:-0.7124 G loss:-1.656\n",
      "Epoch:  0003 D loss:-0.607 G loss:-1.658\n",
      "Epoch:  0003 D loss:-0.593 G loss:-1.725\n",
      "Epoch:  0003 D loss:-0.6732 G loss:-1.677\n",
      "Epoch:  0003 D loss:-0.5561 G loss:-1.656\n",
      "Epoch:  0003 D loss:-0.5987 G loss:-1.813\n",
      "Epoch:  0003 D loss:-0.5045 G loss:-1.832\n",
      "Epoch:  0003 D loss:-0.7052 G loss:-1.933\n",
      "Epoch:  0003 D loss:-0.5555 G loss:-1.919\n",
      "Epoch:  0003 D loss:-0.6306 G loss:-1.965\n",
      "Epoch:  0003 D loss:-0.4938 G loss:-2.019\n",
      "Epoch:  0003 D loss:-0.5681 G loss:-1.858\n",
      "Epoch:  0003 D loss:-0.6237 G loss:-1.924\n",
      "Epoch:  0003 D loss:-0.5129 G loss:-2.015\n",
      "Epoch:  0003 D loss:-0.5923 G loss:-1.896\n",
      "Epoch:  0003 D loss:-0.5904 G loss:-1.835\n",
      "Epoch:  0003 D loss:-0.5224 G loss:-1.838\n",
      "Epoch:  0003 D loss:-0.5321 G loss:-1.761\n",
      "Epoch:  0003 D loss:-0.5226 G loss:-1.803\n",
      "Epoch:  0003 D loss:-0.4323 G loss:-1.925\n",
      "Epoch:  0003 D loss:-0.5605 G loss:-1.843\n",
      "Epoch:  0003 D loss:-0.4346 G loss:-1.927\n",
      "Epoch:  0003 D loss:-0.5199 G loss:-2.023\n",
      "Epoch:  0003 D loss:-0.4399 G loss:-2.039\n",
      "Epoch:  0003 D loss:-0.4342 G loss:-2.231\n",
      "Epoch:  0003 D loss:-0.4246 G loss:-2.16\n",
      "Epoch:  0003 D loss:-0.3877 G loss:-2.104\n",
      "Epoch:  0003 D loss:-0.4569 G loss:-2.083\n",
      "Epoch:  0003 D loss:-0.3931 G loss:-2.127\n",
      "Epoch:  0003 D loss:-0.4123 G loss:-2.029\n",
      "Epoch:  0003 D loss:-0.4239 G loss:-2.196\n",
      "Epoch:  0003 D loss:-0.4331 G loss:-1.949\n",
      "Epoch:  0003 D loss:-0.4176 G loss:-2.07\n",
      "Epoch:  0003 D loss:-0.4668 G loss:-1.979\n",
      "Epoch:  0003 D loss:-0.457 G loss:-2.04\n",
      "Epoch:  0003 D loss:-0.4288 G loss:-2.013\n",
      "Epoch:  0003 D loss:-0.3688 G loss:-2.069\n",
      "Epoch:  0003 D loss:-0.4053 G loss:-2.013\n",
      "Epoch:  0003 D loss:-0.367 G loss:-1.987\n",
      "Epoch:  0003 D loss:-0.4845 G loss:-1.905\n",
      "Epoch:  0003 D loss:-0.3984 G loss:-1.936\n",
      "Epoch:  0003 D loss:-0.4419 G loss:-1.965\n",
      "Epoch:  0003 D loss:-0.3512 G loss:-2.02\n",
      "Epoch:  0003 D loss:-0.4269 G loss:-2.033\n",
      "Epoch:  0003 D loss:-0.3788 G loss:-2.025\n",
      "Epoch:  0003 D loss:-0.5018 G loss:-1.879\n",
      "Epoch:  0003 D loss:-0.448 G loss:-1.943\n",
      "Epoch:  0003 D loss:-0.5023 G loss:-1.869\n",
      "Epoch:  0003 D loss:-0.6139 G loss:-1.963\n",
      "Epoch:  0003 D loss:-0.4738 G loss:-1.765\n",
      "Epoch:  0003 D loss:-0.4944 G loss:-1.76\n",
      "Epoch:  0003 D loss:-0.514 G loss:-1.785\n",
      "Epoch:  0003 D loss:-0.5558 G loss:-1.681\n",
      "Epoch:  0003 D loss:-0.5657 G loss:-1.709\n",
      "Epoch:  0003 D loss:-0.5217 G loss:-1.692\n",
      "Epoch:  0003 D loss:-0.5251 G loss:-1.614\n",
      "Epoch:  0003 D loss:-0.5402 G loss:-1.661\n",
      "Epoch:  0003 D loss:-0.553 G loss:-1.659\n",
      "Epoch:  0003 D loss:-0.6085 G loss:-1.741\n",
      "Epoch:  0003 D loss:-0.5996 G loss:-1.69\n",
      "Epoch:  0003 D loss:-0.6626 G loss:-1.675\n",
      "Epoch:  0003 D loss:-0.5707 G loss:-1.802\n",
      "Epoch:  0003 D loss:-0.604 G loss:-1.762\n",
      "Epoch:  0003 D loss:-0.729 G loss:-1.561\n",
      "Epoch:  0003 D loss:-0.7621 G loss:-1.585\n",
      "Epoch:  0003 D loss:-0.5715 G loss:-1.662\n",
      "Epoch:  0003 D loss:-0.7908 G loss:-1.508\n",
      "Epoch:  0003 D loss:-0.7609 G loss:-1.446\n",
      "Epoch:  0003 D loss:-0.7392 G loss:-1.472\n",
      "Epoch:  0003 D loss:-0.7129 G loss:-1.327\n",
      "Epoch:  0003 D loss:-0.8198 G loss:-1.33\n",
      "Epoch:  0003 D loss:-0.6846 G loss:-1.36\n",
      "Epoch:  0003 D loss:-0.9762 G loss:-1.274\n",
      "Epoch:  0003 D loss:-0.6479 G loss:-1.359\n",
      "Epoch:  0003 D loss:-0.7438 G loss:-1.296\n",
      "Epoch:  0003 D loss:-0.7881 G loss:-1.332\n",
      "Epoch:  0003 D loss:-0.7438 G loss:-1.364\n",
      "Epoch:  0003 D loss:-0.6144 G loss:-1.525\n",
      "Epoch:  0003 D loss:-0.6102 G loss:-1.47\n",
      "Epoch:  0003 D loss:-0.59 G loss:-1.507\n",
      "Epoch:  0003 D loss:-0.5396 G loss:-1.579\n",
      "Epoch:  0003 D loss:-0.6139 G loss:-1.681\n",
      "Epoch:  0003 D loss:-0.5584 G loss:-1.727\n",
      "Epoch:  0003 D loss:-0.617 G loss:-1.731\n",
      "Epoch:  0003 D loss:-0.5767 G loss:-1.763\n",
      "Epoch:  0003 D loss:-0.4807 G loss:-1.694\n",
      "Epoch:  0003 D loss:-0.5392 G loss:-1.681\n",
      "Epoch:  0003 D loss:-0.4989 G loss:-1.678\n",
      "Epoch:  0003 D loss:-0.48 G loss:-1.704\n",
      "Epoch:  0003 D loss:-0.4968 G loss:-1.669\n",
      "Epoch:  0003 D loss:-0.5247 G loss:-1.644\n",
      "Epoch:  0003 D loss:-0.4601 G loss:-1.695\n",
      "Epoch:  0003 D loss:-0.4952 G loss:-1.567\n",
      "Epoch:  0003 D loss:-0.4782 G loss:-1.594\n",
      "Epoch:  0003 D loss:-0.443 G loss:-1.69\n",
      "Epoch:  0003 D loss:-0.456 G loss:-1.617\n",
      "Epoch:  0003 D loss:-0.4641 G loss:-1.665\n",
      "Epoch:  0003 D loss:-0.4736 G loss:-1.724\n",
      "Epoch:  0003 D loss:-0.4965 G loss:-1.713\n",
      "Epoch:  0003 D loss:-0.411 G loss:-1.76\n",
      "Epoch:  0003 D loss:-0.451 G loss:-1.768\n",
      "Epoch:  0003 D loss:-0.4122 G loss:-1.747\n",
      "Epoch:  0003 D loss:-0.3933 G loss:-1.762\n",
      "Epoch:  0003 D loss:-0.3987 G loss:-1.868\n",
      "Epoch:  0003 D loss:-0.3854 G loss:-1.848\n",
      "Epoch:  0003 D loss:-0.3782 G loss:-1.863\n",
      "Epoch:  0003 D loss:-0.3998 G loss:-1.848\n",
      "Epoch:  0003 D loss:-0.3554 G loss:-1.896\n",
      "Epoch:  0003 D loss:-0.3553 G loss:-1.919\n",
      "Epoch:  0003 D loss:-0.4299 G loss:-1.86\n",
      "Epoch:  0003 D loss:-0.3646 G loss:-1.89\n",
      "Epoch:  0003 D loss:-0.4124 G loss:-1.821\n",
      "Epoch:  0003 D loss:-0.3682 G loss:-1.869\n",
      "Epoch:  0003 D loss:-0.3787 G loss:-1.869\n",
      "Epoch:  0003 D loss:-0.3759 G loss:-1.912\n",
      "Epoch:  0003 D loss:-0.404 G loss:-1.89\n",
      "Epoch:  0003 D loss:-0.426 G loss:-1.79\n",
      "Epoch:  0003 D loss:-0.4457 G loss:-1.761\n",
      "Epoch:  0003 D loss:-0.4127 G loss:-1.88\n",
      "Epoch:  0003 D loss:-0.4117 G loss:-1.784\n",
      "Epoch:  0003 D loss:-0.4938 G loss:-1.793\n",
      "Epoch:  0003 D loss:-0.4974 G loss:-1.629\n",
      "Epoch:  0003 D loss:-0.469 G loss:-1.668\n",
      "Epoch:  0003 D loss:-0.5191 G loss:-1.602\n",
      "Epoch:  0003 D loss:-0.4618 G loss:-1.623\n",
      "Epoch:  0003 D loss:-0.4502 G loss:-1.679\n",
      "Epoch:  0003 D loss:-0.5017 G loss:-1.564\n",
      "Epoch:  0003 D loss:-0.4493 G loss:-1.619\n",
      "Epoch:  0003 D loss:-0.5039 G loss:-1.613\n",
      "Epoch:  0003 D loss:-0.5904 G loss:-1.589\n",
      "Epoch:  0003 D loss:-0.6279 G loss:-1.675\n",
      "Epoch:  0003 D loss:-0.5518 G loss:-1.496\n",
      "Epoch:  0003 D loss:-0.5197 G loss:-1.616\n",
      "Epoch:  0003 D loss:-0.508 G loss:-1.637\n",
      "Epoch:  0003 D loss:-0.5734 G loss:-1.586\n",
      "Epoch:  0003 D loss:-0.5942 G loss:-1.642\n",
      "Epoch:  0003 D loss:-0.5823 G loss:-1.602\n",
      "Epoch:  0003 D loss:-0.6231 G loss:-1.545\n",
      "Epoch:  0003 D loss:-0.5709 G loss:-1.548\n",
      "Epoch:  0003 D loss:-0.7101 G loss:-1.44\n",
      "Epoch:  0003 D loss:-0.667 G loss:-1.375\n",
      "Epoch:  0003 D loss:-0.6933 G loss:-1.415\n",
      "Epoch:  0003 D loss:-0.689 G loss:-1.512\n",
      "Epoch:  0003 D loss:-0.7254 G loss:-1.43\n",
      "Epoch:  0003 D loss:-0.6589 G loss:-1.41\n",
      "Epoch:  0003 D loss:-0.667 G loss:-1.388\n",
      "Epoch:  0003 D loss:-0.6876 G loss:-1.372\n",
      "Epoch:  0003 D loss:-0.7185 G loss:-1.4\n",
      "Epoch:  0003 D loss:-0.7804 G loss:-1.387\n",
      "Epoch:  0003 D loss:-0.6767 G loss:-1.531\n",
      "Epoch:  0003 D loss:-0.6996 G loss:-1.374\n",
      "Epoch:  0003 D loss:-0.6756 G loss:-1.396\n",
      "Epoch:  0003 D loss:-0.7497 G loss:-1.427\n",
      "Epoch:  0003 D loss:-0.757 G loss:-1.364\n",
      "Epoch:  0003 D loss:-0.7078 G loss:-1.408\n",
      "Epoch:  0003 D loss:-0.7219 G loss:-1.334\n",
      "Epoch:  0003 D loss:-0.7521 G loss:-1.362\n",
      "Epoch:  0003 D loss:-0.7554 G loss:-1.338\n",
      "Epoch:  0003 D loss:-0.7012 G loss:-1.402\n",
      "Epoch:  0003 D loss:-0.8566 G loss:-1.367\n",
      "Epoch:  0003 D loss:-0.8793 G loss:-1.399\n",
      "Epoch:  0003 D loss:-0.7343 G loss:-1.343\n",
      "Epoch:  0003 D loss:-0.8335 G loss:-1.332\n",
      "Epoch:  0003 D loss:-0.6454 G loss:-1.433\n",
      "Epoch:  0003 D loss:-0.7341 G loss:-1.372\n",
      "Epoch:  0003 D loss:-0.8715 G loss:-1.4\n",
      "Epoch:  0003 D loss:-0.6825 G loss:-1.489\n",
      "Epoch:  0003 D loss:-0.7904 G loss:-1.41\n",
      "Epoch:  0003 D loss:-0.8146 G loss:-1.395\n",
      "Epoch:  0003 D loss:-0.6923 G loss:-1.445\n",
      "Epoch:  0003 D loss:-0.6552 G loss:-1.441\n",
      "Epoch:  0003 D loss:-0.7276 G loss:-1.384\n",
      "Epoch:  0003 D loss:-0.6347 G loss:-1.422\n",
      "Epoch:  0003 D loss:-0.7056 G loss:-1.433\n",
      "Epoch:  0003 D loss:-0.7019 G loss:-1.393\n",
      "Epoch:  0003 D loss:-0.7089 G loss:-1.421\n",
      "Epoch:  0003 D loss:-0.6077 G loss:-1.396\n",
      "Epoch:  0003 D loss:-0.8075 G loss:-1.421\n",
      "Epoch:  0003 D loss:-0.6094 G loss:-1.445\n",
      "Epoch:  0003 D loss:-0.5977 G loss:-1.478\n",
      "Epoch:  0004 D loss:-0.7189 G loss:-1.452\n",
      "Epoch:  0004 D loss:-0.7304 G loss:-1.452\n",
      "Epoch:  0004 D loss:-0.5977 G loss:-1.475\n",
      "Epoch:  0004 D loss:-0.637 G loss:-1.508\n",
      "Epoch:  0004 D loss:-0.6635 G loss:-1.487\n",
      "Epoch:  0004 D loss:-0.5618 G loss:-1.49\n",
      "Epoch:  0004 D loss:-0.6713 G loss:-1.497\n",
      "Epoch:  0004 D loss:-0.6769 G loss:-1.494\n",
      "Epoch:  0004 D loss:-0.6554 G loss:-1.443\n",
      "Epoch:  0004 D loss:-0.6652 G loss:-1.423\n",
      "Epoch:  0004 D loss:-0.5876 G loss:-1.558\n",
      "Epoch:  0004 D loss:-0.5917 G loss:-1.505\n",
      "Epoch:  0004 D loss:-0.5735 G loss:-1.47\n",
      "Epoch:  0004 D loss:-0.6124 G loss:-1.511\n",
      "Epoch:  0004 D loss:-0.6278 G loss:-1.45\n",
      "Epoch:  0004 D loss:-0.5575 G loss:-1.528\n",
      "Epoch:  0004 D loss:-0.6271 G loss:-1.482\n",
      "Epoch:  0004 D loss:-0.5658 G loss:-1.429\n",
      "Epoch:  0004 D loss:-0.5091 G loss:-1.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0004 D loss:-0.4798 G loss:-1.537\n",
      "Epoch:  0004 D loss:-0.5181 G loss:-1.548\n",
      "Epoch:  0004 D loss:-0.5711 G loss:-1.594\n",
      "Epoch:  0004 D loss:-0.5593 G loss:-1.653\n",
      "Epoch:  0004 D loss:-0.4902 G loss:-1.592\n",
      "Epoch:  0004 D loss:-0.5794 G loss:-1.653\n",
      "Epoch:  0004 D loss:-0.5796 G loss:-1.648\n",
      "Epoch:  0004 D loss:-0.5456 G loss:-1.573\n",
      "Epoch:  0004 D loss:-0.5667 G loss:-1.546\n",
      "Epoch:  0004 D loss:-0.5624 G loss:-1.469\n",
      "Epoch:  0004 D loss:-0.5135 G loss:-1.517\n",
      "Epoch:  0004 D loss:-0.5846 G loss:-1.466\n",
      "Epoch:  0004 D loss:-0.571 G loss:-1.485\n",
      "Epoch:  0004 D loss:-0.5527 G loss:-1.442\n",
      "Epoch:  0004 D loss:-0.5775 G loss:-1.421\n",
      "Epoch:  0004 D loss:-0.6169 G loss:-1.464\n",
      "Epoch:  0004 D loss:-0.6474 G loss:-1.456\n",
      "Epoch:  0004 D loss:-0.6093 G loss:-1.426\n",
      "Epoch:  0004 D loss:-0.5825 G loss:-1.474\n",
      "Epoch:  0004 D loss:-0.6146 G loss:-1.48\n",
      "Epoch:  0004 D loss:-0.6954 G loss:-1.442\n",
      "Epoch:  0004 D loss:-0.6895 G loss:-1.482\n",
      "Epoch:  0004 D loss:-0.6692 G loss:-1.395\n",
      "Epoch:  0004 D loss:-0.5482 G loss:-1.36\n",
      "Epoch:  0004 D loss:-0.6581 G loss:-1.355\n",
      "Epoch:  0004 D loss:-0.6091 G loss:-1.352\n",
      "Epoch:  0004 D loss:-0.5893 G loss:-1.364\n",
      "Epoch:  0004 D loss:-0.7087 G loss:-1.306\n",
      "Epoch:  0004 D loss:-0.6049 G loss:-1.363\n",
      "Epoch:  0004 D loss:-0.7131 G loss:-1.361\n",
      "Epoch:  0004 D loss:-0.6507 G loss:-1.422\n",
      "Epoch:  0004 D loss:-0.6123 G loss:-1.413\n",
      "Epoch:  0004 D loss:-0.6559 G loss:-1.459\n",
      "Epoch:  0004 D loss:-0.6329 G loss:-1.409\n",
      "Epoch:  0004 D loss:-0.6391 G loss:-1.431\n",
      "Epoch:  0004 D loss:-0.5924 G loss:-1.432\n",
      "Epoch:  0004 D loss:-0.626 G loss:-1.42\n",
      "Epoch:  0004 D loss:-0.6445 G loss:-1.417\n",
      "Epoch:  0004 D loss:-0.6433 G loss:-1.486\n",
      "Epoch:  0004 D loss:-0.6315 G loss:-1.403\n",
      "Epoch:  0004 D loss:-0.576 G loss:-1.432\n",
      "Epoch:  0004 D loss:-0.6447 G loss:-1.388\n",
      "Epoch:  0004 D loss:-0.6004 G loss:-1.477\n",
      "Epoch:  0004 D loss:-0.5179 G loss:-1.476\n",
      "Epoch:  0004 D loss:-0.6048 G loss:-1.477\n",
      "Epoch:  0004 D loss:-0.5671 G loss:-1.457\n",
      "Epoch:  0004 D loss:-0.4924 G loss:-1.445\n",
      "Epoch:  0004 D loss:-0.4095 G loss:-1.561\n",
      "Epoch:  0004 D loss:-0.511 G loss:-1.523\n",
      "Epoch:  0004 D loss:-0.5266 G loss:-1.559\n",
      "Epoch:  0004 D loss:-0.56 G loss:-1.585\n",
      "Epoch:  0004 D loss:-0.5564 G loss:-1.54\n",
      "Epoch:  0004 D loss:-0.4609 G loss:-1.628\n",
      "Epoch:  0004 D loss:-0.5195 G loss:-1.596\n",
      "Epoch:  0004 D loss:-0.4708 G loss:-1.517\n",
      "Epoch:  0004 D loss:-0.5426 G loss:-1.602\n",
      "Epoch:  0004 D loss:-0.4269 G loss:-1.661\n",
      "Epoch:  0004 D loss:-0.4796 G loss:-1.623\n",
      "Epoch:  0004 D loss:-0.5732 G loss:-1.584\n",
      "Epoch:  0004 D loss:-0.4899 G loss:-1.631\n",
      "Epoch:  0004 D loss:-0.4645 G loss:-1.639\n",
      "Epoch:  0004 D loss:-0.4361 G loss:-1.616\n",
      "Epoch:  0004 D loss:-0.5748 G loss:-1.572\n",
      "Epoch:  0004 D loss:-0.5875 G loss:-1.541\n",
      "Epoch:  0004 D loss:-0.516 G loss:-1.532\n",
      "Epoch:  0004 D loss:-0.5152 G loss:-1.573\n",
      "Epoch:  0004 D loss:-0.5495 G loss:-1.395\n",
      "Epoch:  0004 D loss:-0.5696 G loss:-1.463\n",
      "Epoch:  0004 D loss:-0.5273 G loss:-1.435\n",
      "Epoch:  0004 D loss:-0.6201 G loss:-1.39\n",
      "Epoch:  0004 D loss:-0.6042 G loss:-1.392\n",
      "Epoch:  0004 D loss:-0.5962 G loss:-1.43\n",
      "Epoch:  0004 D loss:-0.5283 G loss:-1.433\n",
      "Epoch:  0004 D loss:-0.65 G loss:-1.374\n",
      "Epoch:  0004 D loss:-0.5424 G loss:-1.418\n",
      "Epoch:  0004 D loss:-0.5293 G loss:-1.466\n",
      "Epoch:  0004 D loss:-0.6721 G loss:-1.425\n",
      "Epoch:  0004 D loss:-0.5653 G loss:-1.405\n",
      "Epoch:  0004 D loss:-0.6257 G loss:-1.348\n",
      "Epoch:  0004 D loss:-0.6165 G loss:-1.423\n",
      "Epoch:  0004 D loss:-0.6408 G loss:-1.496\n",
      "Epoch:  0004 D loss:-0.7141 G loss:-1.35\n",
      "Epoch:  0004 D loss:-0.6669 G loss:-1.411\n",
      "Epoch:  0004 D loss:-0.6972 G loss:-1.359\n",
      "Epoch:  0004 D loss:-0.5958 G loss:-1.386\n",
      "Epoch:  0004 D loss:-0.6383 G loss:-1.349\n",
      "Epoch:  0004 D loss:-0.563 G loss:-1.371\n",
      "Epoch:  0004 D loss:-0.7019 G loss:-1.389\n",
      "Epoch:  0004 D loss:-0.5296 G loss:-1.435\n",
      "Epoch:  0004 D loss:-0.6938 G loss:-1.339\n",
      "Epoch:  0004 D loss:-0.5682 G loss:-1.373\n",
      "Epoch:  0004 D loss:-0.6284 G loss:-1.332\n",
      "Epoch:  0004 D loss:-0.5382 G loss:-1.41\n",
      "Epoch:  0004 D loss:-0.6398 G loss:-1.396\n",
      "Epoch:  0004 D loss:-0.6382 G loss:-1.417\n",
      "Epoch:  0004 D loss:-0.6366 G loss:-1.439\n",
      "Epoch:  0004 D loss:-0.5169 G loss:-1.52\n",
      "Epoch:  0004 D loss:-0.665 G loss:-1.511\n",
      "Epoch:  0004 D loss:-0.617 G loss:-1.487\n",
      "Epoch:  0004 D loss:-0.5858 G loss:-1.449\n",
      "Epoch:  0004 D loss:-0.6341 G loss:-1.437\n",
      "Epoch:  0004 D loss:-0.6176 G loss:-1.453\n",
      "Epoch:  0004 D loss:-0.4976 G loss:-1.478\n",
      "Epoch:  0004 D loss:-0.5821 G loss:-1.48\n",
      "Epoch:  0004 D loss:-0.6442 G loss:-1.431\n",
      "Epoch:  0004 D loss:-0.6887 G loss:-1.495\n",
      "Epoch:  0004 D loss:-0.6149 G loss:-1.41\n",
      "Epoch:  0004 D loss:-0.5038 G loss:-1.504\n",
      "Epoch:  0004 D loss:-0.5036 G loss:-1.466\n",
      "Epoch:  0004 D loss:-0.5769 G loss:-1.488\n",
      "Epoch:  0004 D loss:-0.6429 G loss:-1.438\n",
      "Epoch:  0004 D loss:-0.5485 G loss:-1.497\n",
      "Epoch:  0004 D loss:-0.5993 G loss:-1.506\n",
      "Epoch:  0004 D loss:-0.5716 G loss:-1.435\n",
      "Epoch:  0004 D loss:-0.6434 G loss:-1.394\n",
      "Epoch:  0004 D loss:-0.6414 G loss:-1.357\n",
      "Epoch:  0004 D loss:-0.5948 G loss:-1.325\n",
      "Epoch:  0004 D loss:-0.6261 G loss:-1.358\n",
      "Epoch:  0004 D loss:-0.5828 G loss:-1.387\n",
      "Epoch:  0004 D loss:-0.592 G loss:-1.434\n",
      "Epoch:  0004 D loss:-0.6974 G loss:-1.401\n",
      "Epoch:  0004 D loss:-0.6387 G loss:-1.391\n",
      "Epoch:  0004 D loss:-0.6111 G loss:-1.428\n",
      "Epoch:  0004 D loss:-0.7521 G loss:-1.452\n",
      "Epoch:  0004 D loss:-0.6803 G loss:-1.38\n",
      "Epoch:  0004 D loss:-0.6897 G loss:-1.326\n",
      "Epoch:  0004 D loss:-0.7208 G loss:-1.318\n",
      "Epoch:  0004 D loss:-0.6845 G loss:-1.351\n",
      "Epoch:  0004 D loss:-0.7391 G loss:-1.286\n",
      "Epoch:  0004 D loss:-0.6006 G loss:-1.342\n",
      "Epoch:  0004 D loss:-0.7166 G loss:-1.28\n",
      "Epoch:  0004 D loss:-0.6121 G loss:-1.313\n",
      "Epoch:  0004 D loss:-0.5991 G loss:-1.308\n",
      "Epoch:  0004 D loss:-0.6759 G loss:-1.263\n",
      "Epoch:  0004 D loss:-0.7994 G loss:-1.326\n",
      "Epoch:  0004 D loss:-0.7878 G loss:-1.366\n",
      "Epoch:  0004 D loss:-0.708 G loss:-1.334\n",
      "Epoch:  0004 D loss:-0.6426 G loss:-1.326\n",
      "Epoch:  0004 D loss:-0.6799 G loss:-1.287\n",
      "Epoch:  0004 D loss:-0.7806 G loss:-1.286\n",
      "Epoch:  0004 D loss:-0.6855 G loss:-1.341\n",
      "Epoch:  0004 D loss:-0.6983 G loss:-1.326\n",
      "Epoch:  0004 D loss:-0.832 G loss:-1.224\n",
      "Epoch:  0004 D loss:-0.7506 G loss:-1.265\n",
      "Epoch:  0004 D loss:-0.7046 G loss:-1.301\n",
      "Epoch:  0004 D loss:-0.6814 G loss:-1.315\n",
      "Epoch:  0004 D loss:-0.7074 G loss:-1.322\n",
      "Epoch:  0004 D loss:-0.7923 G loss:-1.262\n",
      "Epoch:  0004 D loss:-0.7568 G loss:-1.247\n",
      "Epoch:  0004 D loss:-0.8252 G loss:-1.32\n",
      "Epoch:  0004 D loss:-0.6417 G loss:-1.327\n",
      "Epoch:  0004 D loss:-0.732 G loss:-1.377\n",
      "Epoch:  0004 D loss:-0.6408 G loss:-1.291\n",
      "Epoch:  0004 D loss:-0.6656 G loss:-1.284\n",
      "Epoch:  0004 D loss:-0.7125 G loss:-1.361\n",
      "Epoch:  0004 D loss:-0.6942 G loss:-1.317\n",
      "Epoch:  0004 D loss:-0.7349 G loss:-1.308\n",
      "Epoch:  0004 D loss:-0.8168 G loss:-1.27\n",
      "Epoch:  0004 D loss:-0.7329 G loss:-1.327\n",
      "Epoch:  0004 D loss:-0.7349 G loss:-1.403\n",
      "Epoch:  0004 D loss:-0.6254 G loss:-1.295\n",
      "Epoch:  0004 D loss:-0.6684 G loss:-1.362\n",
      "Epoch:  0004 D loss:-0.6446 G loss:-1.384\n",
      "Epoch:  0004 D loss:-0.7832 G loss:-1.414\n",
      "Epoch:  0004 D loss:-0.6826 G loss:-1.402\n",
      "Epoch:  0004 D loss:-0.6692 G loss:-1.424\n",
      "Epoch:  0004 D loss:-0.6528 G loss:-1.461\n",
      "Epoch:  0004 D loss:-0.6755 G loss:-1.407\n",
      "Epoch:  0004 D loss:-0.6756 G loss:-1.379\n",
      "Epoch:  0004 D loss:-0.6257 G loss:-1.399\n",
      "Epoch:  0004 D loss:-0.6809 G loss:-1.379\n",
      "Epoch:  0004 D loss:-0.6647 G loss:-1.48\n",
      "Epoch:  0004 D loss:-0.7176 G loss:-1.372\n",
      "Epoch:  0004 D loss:-0.5534 G loss:-1.401\n",
      "Epoch:  0004 D loss:-0.7871 G loss:-1.402\n",
      "Epoch:  0004 D loss:-0.7152 G loss:-1.36\n",
      "Epoch:  0004 D loss:-0.6056 G loss:-1.391\n",
      "Epoch:  0004 D loss:-0.6183 G loss:-1.298\n",
      "Epoch:  0004 D loss:-0.7535 G loss:-1.353\n",
      "Epoch:  0004 D loss:-0.6645 G loss:-1.303\n",
      "Epoch:  0004 D loss:-0.6579 G loss:-1.363\n",
      "Epoch:  0004 D loss:-0.6505 G loss:-1.364\n",
      "Epoch:  0004 D loss:-0.7074 G loss:-1.33\n",
      "Epoch:  0004 D loss:-0.7086 G loss:-1.314\n",
      "Epoch:  0004 D loss:-0.861 G loss:-1.23\n",
      "Epoch:  0004 D loss:-0.6623 G loss:-1.354\n",
      "Epoch:  0004 D loss:-0.7854 G loss:-1.332\n",
      "Epoch:  0004 D loss:-0.6754 G loss:-1.369\n",
      "Epoch:  0004 D loss:-0.7603 G loss:-1.222\n",
      "Epoch:  0004 D loss:-0.6832 G loss:-1.277\n",
      "Epoch:  0004 D loss:-0.7396 G loss:-1.276\n",
      "Epoch:  0004 D loss:-0.6084 G loss:-1.399\n",
      "Epoch:  0004 D loss:-0.6982 G loss:-1.261\n",
      "Epoch:  0004 D loss:-0.7694 G loss:-1.328\n",
      "Epoch:  0004 D loss:-0.8187 G loss:-1.207\n",
      "Epoch:  0004 D loss:-0.8416 G loss:-1.284\n",
      "Epoch:  0004 D loss:-0.7185 G loss:-1.375\n",
      "Epoch:  0004 D loss:-0.8114 G loss:-1.313\n",
      "Epoch:  0004 D loss:-0.84 G loss:-1.267\n",
      "Epoch:  0004 D loss:-0.758 G loss:-1.2\n",
      "Epoch:  0004 D loss:-0.7301 G loss:-1.254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0004 D loss:-0.7616 G loss:-1.222\n",
      "Epoch:  0004 D loss:-0.7797 G loss:-1.219\n",
      "Epoch:  0004 D loss:-0.7143 G loss:-1.261\n",
      "Epoch:  0004 D loss:-0.767 G loss:-1.317\n",
      "Epoch:  0004 D loss:-0.8079 G loss:-1.22\n",
      "Epoch:  0004 D loss:-0.666 G loss:-1.324\n",
      "Epoch:  0004 D loss:-0.7405 G loss:-1.316\n",
      "Epoch:  0004 D loss:-0.7372 G loss:-1.344\n",
      "Epoch:  0004 D loss:-0.7459 G loss:-1.294\n",
      "Epoch:  0004 D loss:-0.717 G loss:-1.296\n",
      "Epoch:  0004 D loss:-0.7282 G loss:-1.3\n",
      "Epoch:  0004 D loss:-0.7028 G loss:-1.264\n",
      "Epoch:  0004 D loss:-0.8007 G loss:-1.221\n",
      "Epoch:  0004 D loss:-0.7398 G loss:-1.274\n",
      "Epoch:  0004 D loss:-0.7224 G loss:-1.238\n",
      "Epoch:  0004 D loss:-0.6837 G loss:-1.332\n",
      "Epoch:  0004 D loss:-0.8374 G loss:-1.228\n",
      "Epoch:  0004 D loss:-0.7794 G loss:-1.238\n",
      "Epoch:  0004 D loss:-0.7127 G loss:-1.343\n",
      "Epoch:  0004 D loss:-0.6966 G loss:-1.329\n",
      "Epoch:  0004 D loss:-0.724 G loss:-1.316\n",
      "Epoch:  0004 D loss:-0.64 G loss:-1.292\n",
      "Epoch:  0004 D loss:-0.706 G loss:-1.231\n",
      "Epoch:  0004 D loss:-0.7009 G loss:-1.313\n",
      "Epoch:  0004 D loss:-0.6783 G loss:-1.282\n",
      "Epoch:  0004 D loss:-0.8016 G loss:-1.305\n",
      "Epoch:  0004 D loss:-0.63 G loss:-1.368\n",
      "Epoch:  0004 D loss:-0.7945 G loss:-1.41\n",
      "Epoch:  0004 D loss:-0.6468 G loss:-1.466\n",
      "Epoch:  0004 D loss:-0.6559 G loss:-1.399\n",
      "Epoch:  0004 D loss:-0.5734 G loss:-1.431\n",
      "Epoch:  0004 D loss:-0.6778 G loss:-1.366\n",
      "Epoch:  0004 D loss:-0.6445 G loss:-1.432\n",
      "Epoch:  0004 D loss:-0.535 G loss:-1.451\n",
      "Epoch:  0004 D loss:-0.5956 G loss:-1.415\n",
      "Epoch:  0004 D loss:-0.5508 G loss:-1.509\n",
      "Epoch:  0004 D loss:-0.633 G loss:-1.462\n",
      "Epoch:  0004 D loss:-0.6059 G loss:-1.354\n",
      "Epoch:  0004 D loss:-0.635 G loss:-1.429\n",
      "Epoch:  0004 D loss:-0.6884 G loss:-1.397\n",
      "Epoch:  0004 D loss:-0.6367 G loss:-1.385\n",
      "Epoch:  0004 D loss:-0.6141 G loss:-1.425\n",
      "Epoch:  0004 D loss:-0.5742 G loss:-1.409\n",
      "Epoch:  0004 D loss:-0.6076 G loss:-1.412\n",
      "Epoch:  0004 D loss:-0.6231 G loss:-1.38\n",
      "Epoch:  0004 D loss:-0.5449 G loss:-1.366\n",
      "Epoch:  0004 D loss:-0.587 G loss:-1.384\n",
      "Epoch:  0004 D loss:-0.6021 G loss:-1.398\n",
      "Epoch:  0004 D loss:-0.6352 G loss:-1.343\n",
      "Epoch:  0004 D loss:-0.6533 G loss:-1.254\n",
      "Epoch:  0004 D loss:-0.5707 G loss:-1.451\n",
      "Epoch:  0004 D loss:-0.5941 G loss:-1.368\n",
      "Epoch:  0004 D loss:-0.5556 G loss:-1.539\n",
      "Epoch:  0004 D loss:-0.6093 G loss:-1.468\n",
      "Epoch:  0004 D loss:-0.5495 G loss:-1.481\n",
      "Epoch:  0004 D loss:-0.7127 G loss:-1.415\n",
      "Epoch:  0004 D loss:-0.5624 G loss:-1.412\n",
      "Epoch:  0004 D loss:-0.5585 G loss:-1.446\n",
      "Epoch:  0004 D loss:-0.5331 G loss:-1.464\n",
      "Epoch:  0004 D loss:-0.6033 G loss:-1.445\n",
      "Epoch:  0004 D loss:-0.5701 G loss:-1.417\n",
      "Epoch:  0004 D loss:-0.544 G loss:-1.408\n",
      "Epoch:  0004 D loss:-0.5384 G loss:-1.481\n",
      "Epoch:  0004 D loss:-0.5375 G loss:-1.462\n",
      "Epoch:  0004 D loss:-0.4947 G loss:-1.519\n",
      "Epoch:  0004 D loss:-0.5092 G loss:-1.452\n",
      "Epoch:  0004 D loss:-0.518 G loss:-1.532\n",
      "Epoch:  0004 D loss:-0.5841 G loss:-1.589\n",
      "Epoch:  0004 D loss:-0.6144 G loss:-1.551\n",
      "Epoch:  0004 D loss:-0.4961 G loss:-1.461\n",
      "Epoch:  0004 D loss:-0.4997 G loss:-1.462\n",
      "Epoch:  0004 D loss:-0.4266 G loss:-1.54\n",
      "Epoch:  0004 D loss:-0.5028 G loss:-1.524\n",
      "Epoch:  0004 D loss:-0.5675 G loss:-1.593\n",
      "Epoch:  0004 D loss:-0.4713 G loss:-1.603\n",
      "Epoch:  0004 D loss:-0.5108 G loss:-1.577\n",
      "Epoch:  0004 D loss:-0.4836 G loss:-1.633\n",
      "Epoch:  0004 D loss:-0.4759 G loss:-1.65\n",
      "Epoch:  0004 D loss:-0.4346 G loss:-1.651\n",
      "Epoch:  0004 D loss:-0.5674 G loss:-1.694\n",
      "Epoch:  0004 D loss:-0.5145 G loss:-1.576\n",
      "Epoch:  0004 D loss:-0.5292 G loss:-1.629\n",
      "Epoch:  0004 D loss:-0.4281 G loss:-1.614\n",
      "Epoch:  0004 D loss:-0.4518 G loss:-1.627\n",
      "Epoch:  0004 D loss:-0.4343 G loss:-1.705\n",
      "Epoch:  0004 D loss:-0.3913 G loss:-1.669\n",
      "Epoch:  0004 D loss:-0.4336 G loss:-1.686\n",
      "Epoch:  0004 D loss:-0.4919 G loss:-1.598\n",
      "Epoch:  0004 D loss:-0.533 G loss:-1.684\n",
      "Epoch:  0004 D loss:-0.4591 G loss:-1.665\n",
      "Epoch:  0004 D loss:-0.4895 G loss:-1.689\n",
      "Epoch:  0004 D loss:-0.4932 G loss:-1.638\n",
      "Epoch:  0004 D loss:-0.4908 G loss:-1.633\n",
      "Epoch:  0004 D loss:-0.4132 G loss:-1.624\n",
      "Epoch:  0004 D loss:-0.3729 G loss:-1.739\n",
      "Epoch:  0004 D loss:-0.465 G loss:-1.703\n",
      "Epoch:  0004 D loss:-0.5269 G loss:-1.65\n",
      "Epoch:  0004 D loss:-0.4815 G loss:-1.652\n",
      "Epoch:  0004 D loss:-0.4414 G loss:-1.661\n",
      "Epoch:  0004 D loss:-0.4638 G loss:-1.563\n",
      "Epoch:  0004 D loss:-0.4573 G loss:-1.624\n",
      "Epoch:  0004 D loss:-0.477 G loss:-1.618\n",
      "Epoch:  0004 D loss:-0.4746 G loss:-1.66\n",
      "Epoch:  0004 D loss:-0.4427 G loss:-1.601\n",
      "Epoch:  0004 D loss:-0.4705 G loss:-1.601\n",
      "Epoch:  0004 D loss:-0.4755 G loss:-1.618\n",
      "Epoch:  0004 D loss:-0.5211 G loss:-1.586\n",
      "Epoch:  0004 D loss:-0.4838 G loss:-1.601\n",
      "Epoch:  0004 D loss:-0.4701 G loss:-1.65\n",
      "Epoch:  0004 D loss:-0.5046 G loss:-1.639\n",
      "Epoch:  0004 D loss:-0.4467 G loss:-1.657\n",
      "Epoch:  0004 D loss:-0.4442 G loss:-1.722\n",
      "Epoch:  0004 D loss:-0.3964 G loss:-1.678\n",
      "Epoch:  0004 D loss:-0.4512 G loss:-1.596\n",
      "Epoch:  0004 D loss:-0.4551 G loss:-1.695\n",
      "Epoch:  0004 D loss:-0.5035 G loss:-1.676\n",
      "Epoch:  0004 D loss:-0.4972 G loss:-1.735\n",
      "Epoch:  0004 D loss:-0.4414 G loss:-1.648\n",
      "Epoch:  0004 D loss:-0.4657 G loss:-1.697\n",
      "Epoch:  0004 D loss:-0.4757 G loss:-1.627\n",
      "Epoch:  0004 D loss:-0.426 G loss:-1.665\n",
      "Epoch:  0004 D loss:-0.4349 G loss:-1.591\n",
      "Epoch:  0004 D loss:-0.4734 G loss:-1.476\n",
      "Epoch:  0004 D loss:-0.4889 G loss:-1.59\n",
      "Epoch:  0004 D loss:-0.4599 G loss:-1.606\n",
      "Epoch:  0004 D loss:-0.4872 G loss:-1.609\n",
      "Epoch:  0004 D loss:-0.5114 G loss:-1.625\n",
      "Epoch:  0004 D loss:-0.5046 G loss:-1.64\n",
      "Epoch:  0004 D loss:-0.5 G loss:-1.63\n",
      "Epoch:  0004 D loss:-0.4631 G loss:-1.606\n",
      "Epoch:  0004 D loss:-0.4934 G loss:-1.667\n",
      "Epoch:  0004 D loss:-0.5476 G loss:-1.587\n",
      "Epoch:  0004 D loss:-0.5388 G loss:-1.585\n",
      "Epoch:  0004 D loss:-0.6059 G loss:-1.472\n",
      "Epoch:  0004 D loss:-0.5966 G loss:-1.57\n",
      "Epoch:  0004 D loss:-0.6248 G loss:-1.426\n",
      "Epoch:  0004 D loss:-0.5795 G loss:-1.489\n",
      "Epoch:  0004 D loss:-0.6094 G loss:-1.378\n",
      "Epoch:  0004 D loss:-0.613 G loss:-1.338\n",
      "Epoch:  0004 D loss:-0.5305 G loss:-1.535\n",
      "Epoch:  0004 D loss:-0.5854 G loss:-1.405\n",
      "Epoch:  0004 D loss:-0.5808 G loss:-1.44\n",
      "Epoch:  0004 D loss:-0.6664 G loss:-1.392\n",
      "Epoch:  0004 D loss:-0.6375 G loss:-1.388\n",
      "Epoch:  0004 D loss:-0.5447 G loss:-1.421\n",
      "Epoch:  0004 D loss:-0.6772 G loss:-1.376\n",
      "Epoch:  0004 D loss:-0.5822 G loss:-1.566\n",
      "Epoch:  0004 D loss:-0.6221 G loss:-1.46\n",
      "Epoch:  0004 D loss:-0.6359 G loss:-1.482\n",
      "Epoch:  0004 D loss:-0.5955 G loss:-1.432\n",
      "Epoch:  0004 D loss:-0.7486 G loss:-1.354\n",
      "Epoch:  0004 D loss:-0.5528 G loss:-1.491\n",
      "Epoch:  0004 D loss:-0.6757 G loss:-1.389\n",
      "Epoch:  0004 D loss:-0.662 G loss:-1.348\n",
      "Epoch:  0004 D loss:-0.666 G loss:-1.35\n",
      "Epoch:  0004 D loss:-0.5239 G loss:-1.441\n",
      "Epoch:  0004 D loss:-0.6526 G loss:-1.388\n",
      "Epoch:  0004 D loss:-0.6863 G loss:-1.283\n",
      "Epoch:  0004 D loss:-0.7158 G loss:-1.288\n",
      "Epoch:  0004 D loss:-0.6469 G loss:-1.3\n",
      "Epoch:  0004 D loss:-0.6169 G loss:-1.395\n",
      "Epoch:  0004 D loss:-0.7206 G loss:-1.275\n",
      "Epoch:  0004 D loss:-0.6379 G loss:-1.4\n",
      "Epoch:  0004 D loss:-0.696 G loss:-1.358\n",
      "Epoch:  0004 D loss:-0.6011 G loss:-1.449\n",
      "Epoch:  0004 D loss:-0.6366 G loss:-1.293\n",
      "Epoch:  0004 D loss:-0.5732 G loss:-1.421\n",
      "Epoch:  0004 D loss:-0.5829 G loss:-1.487\n",
      "Epoch:  0004 D loss:-0.6129 G loss:-1.456\n",
      "Epoch:  0004 D loss:-0.6348 G loss:-1.339\n",
      "Epoch:  0004 D loss:-0.6993 G loss:-1.364\n",
      "Epoch:  0004 D loss:-0.6144 G loss:-1.423\n",
      "Epoch:  0004 D loss:-0.6416 G loss:-1.304\n",
      "Epoch:  0004 D loss:-0.6065 G loss:-1.381\n",
      "Epoch:  0004 D loss:-0.6466 G loss:-1.415\n",
      "Epoch:  0004 D loss:-0.5471 G loss:-1.428\n",
      "Epoch:  0004 D loss:-0.6885 G loss:-1.375\n",
      "Epoch:  0004 D loss:-0.619 G loss:-1.356\n",
      "Epoch:  0004 D loss:-0.5508 G loss:-1.436\n",
      "Epoch:  0004 D loss:-0.6102 G loss:-1.446\n",
      "Epoch:  0004 D loss:-0.6046 G loss:-1.418\n",
      "Epoch:  0004 D loss:-0.6059 G loss:-1.402\n",
      "Epoch:  0004 D loss:-0.5838 G loss:-1.418\n",
      "Epoch:  0004 D loss:-0.6603 G loss:-1.364\n",
      "Epoch:  0004 D loss:-0.6123 G loss:-1.35\n",
      "Epoch:  0004 D loss:-0.6065 G loss:-1.427\n",
      "Epoch:  0004 D loss:-0.6425 G loss:-1.406\n",
      "Epoch:  0004 D loss:-0.6495 G loss:-1.398\n",
      "Epoch:  0004 D loss:-0.5566 G loss:-1.413\n",
      "Epoch:  0004 D loss:-0.7388 G loss:-1.317\n",
      "Epoch:  0004 D loss:-0.6955 G loss:-1.364\n",
      "Epoch:  0004 D loss:-0.6559 G loss:-1.347\n",
      "Epoch:  0004 D loss:-0.6117 G loss:-1.356\n",
      "Epoch:  0004 D loss:-0.5946 G loss:-1.292\n",
      "Epoch:  0004 D loss:-0.6391 G loss:-1.3\n",
      "Epoch:  0004 D loss:-0.6721 G loss:-1.23\n",
      "Epoch:  0004 D loss:-0.6176 G loss:-1.353\n",
      "Epoch:  0004 D loss:-0.5411 G loss:-1.414\n",
      "Epoch:  0004 D loss:-0.6659 G loss:-1.313\n",
      "Epoch:  0004 D loss:-0.711 G loss:-1.336\n",
      "Epoch:  0004 D loss:-0.6046 G loss:-1.356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0004 D loss:-0.6582 G loss:-1.342\n",
      "Epoch:  0004 D loss:-0.6086 G loss:-1.372\n",
      "Epoch:  0004 D loss:-0.6743 G loss:-1.258\n",
      "Epoch:  0004 D loss:-0.5901 G loss:-1.359\n",
      "Epoch:  0004 D loss:-0.6151 G loss:-1.301\n",
      "Epoch:  0004 D loss:-0.6419 G loss:-1.274\n",
      "Epoch:  0004 D loss:-0.5757 G loss:-1.356\n",
      "Epoch:  0004 D loss:-0.5721 G loss:-1.389\n",
      "Epoch:  0004 D loss:-0.5471 G loss:-1.387\n",
      "Epoch:  0004 D loss:-0.5033 G loss:-1.426\n",
      "Epoch:  0004 D loss:-0.5985 G loss:-1.445\n",
      "Epoch:  0004 D loss:-0.4967 G loss:-1.52\n",
      "Epoch:  0004 D loss:-0.5719 G loss:-1.473\n",
      "Epoch:  0004 D loss:-0.5822 G loss:-1.51\n",
      "Epoch:  0004 D loss:-0.5723 G loss:-1.571\n",
      "Epoch:  0004 D loss:-0.5238 G loss:-1.453\n",
      "Epoch:  0004 D loss:-0.4868 G loss:-1.558\n",
      "Epoch:  0004 D loss:-0.4784 G loss:-1.643\n",
      "Epoch:  0004 D loss:-0.4832 G loss:-1.588\n",
      "Epoch:  0004 D loss:-0.5567 G loss:-1.514\n",
      "Epoch:  0004 D loss:-0.4993 G loss:-1.588\n",
      "Epoch:  0004 D loss:-0.4711 G loss:-1.535\n",
      "Epoch:  0004 D loss:-0.512 G loss:-1.512\n",
      "Epoch:  0004 D loss:-0.4901 G loss:-1.449\n",
      "Epoch:  0004 D loss:-0.4985 G loss:-1.502\n",
      "Epoch:  0004 D loss:-0.4252 G loss:-1.592\n",
      "Epoch:  0004 D loss:-0.4342 G loss:-1.547\n",
      "Epoch:  0004 D loss:-0.4922 G loss:-1.47\n",
      "Epoch:  0004 D loss:-0.4893 G loss:-1.535\n",
      "Epoch:  0004 D loss:-0.5007 G loss:-1.624\n",
      "Epoch:  0004 D loss:-0.4369 G loss:-1.63\n",
      "Epoch:  0004 D loss:-0.5396 G loss:-1.505\n",
      "Epoch:  0004 D loss:-0.4436 G loss:-1.631\n",
      "Epoch:  0004 D loss:-0.479 G loss:-1.518\n",
      "Epoch:  0004 D loss:-0.4628 G loss:-1.54\n",
      "Epoch:  0004 D loss:-0.5032 G loss:-1.657\n",
      "Epoch:  0004 D loss:-0.5223 G loss:-1.604\n",
      "Epoch:  0004 D loss:-0.5063 G loss:-1.539\n",
      "Epoch:  0004 D loss:-0.4722 G loss:-1.57\n",
      "Epoch:  0004 D loss:-0.4826 G loss:-1.545\n",
      "Epoch:  0004 D loss:-0.5654 G loss:-1.549\n",
      "Epoch:  0004 D loss:-0.5118 G loss:-1.512\n",
      "Epoch:  0004 D loss:-0.4947 G loss:-1.504\n",
      "Epoch:  0004 D loss:-0.5077 G loss:-1.489\n",
      "Epoch:  0004 D loss:-0.5658 G loss:-1.475\n",
      "Epoch:  0004 D loss:-0.4922 G loss:-1.5\n",
      "Epoch:  0004 D loss:-0.4659 G loss:-1.546\n",
      "Epoch:  0004 D loss:-0.4651 G loss:-1.544\n",
      "Epoch:  0004 D loss:-0.4957 G loss:-1.475\n",
      "Epoch:  0004 D loss:-0.4678 G loss:-1.652\n",
      "Epoch:  0004 D loss:-0.4663 G loss:-1.582\n",
      "Epoch:  0004 D loss:-0.4833 G loss:-1.701\n",
      "Epoch:  0004 D loss:-0.5601 G loss:-1.523\n",
      "Epoch:  0004 D loss:-0.5476 G loss:-1.549\n",
      "Epoch:  0004 D loss:-0.534 G loss:-1.499\n",
      "Epoch:  0004 D loss:-0.5443 G loss:-1.527\n",
      "Epoch:  0004 D loss:-0.5342 G loss:-1.495\n",
      "Epoch:  0004 D loss:-0.5049 G loss:-1.541\n",
      "Epoch:  0004 D loss:-0.6093 G loss:-1.435\n",
      "Epoch:  0004 D loss:-0.4583 G loss:-1.515\n",
      "Epoch:  0004 D loss:-0.5122 G loss:-1.435\n",
      "Epoch:  0004 D loss:-0.5597 G loss:-1.501\n",
      "Epoch:  0004 D loss:-0.5043 G loss:-1.406\n",
      "Epoch:  0004 D loss:-0.5575 G loss:-1.426\n",
      "Epoch:  0004 D loss:-0.5773 G loss:-1.58\n",
      "Epoch:  0004 D loss:-0.4994 G loss:-1.535\n",
      "Epoch:  0004 D loss:-0.5519 G loss:-1.524\n",
      "Epoch:  0004 D loss:-0.5988 G loss:-1.51\n",
      "Epoch:  0004 D loss:-0.4623 G loss:-1.571\n",
      "Epoch:  0004 D loss:-0.5039 G loss:-1.517\n",
      "Epoch:  0004 D loss:-0.5666 G loss:-1.51\n",
      "Epoch:  0004 D loss:-0.5123 G loss:-1.606\n",
      "Epoch:  0004 D loss:-0.6118 G loss:-1.523\n",
      "Epoch:  0004 D loss:-0.5472 G loss:-1.532\n",
      "Epoch:  0004 D loss:-0.6195 G loss:-1.468\n",
      "Epoch:  0004 D loss:-0.5808 G loss:-1.495\n",
      "Epoch:  0004 D loss:-0.4911 G loss:-1.474\n",
      "Epoch:  0004 D loss:-0.6684 G loss:-1.458\n",
      "Epoch:  0004 D loss:-0.5715 G loss:-1.391\n",
      "Epoch:  0004 D loss:-0.5278 G loss:-1.384\n",
      "Epoch:  0004 D loss:-0.5883 G loss:-1.408\n",
      "Epoch:  0004 D loss:-0.488 G loss:-1.481\n",
      "Epoch:  0004 D loss:-0.4987 G loss:-1.445\n",
      "Epoch:  0004 D loss:-0.4989 G loss:-1.436\n",
      "Epoch:  0004 D loss:-0.4649 G loss:-1.541\n",
      "Epoch:  0004 D loss:-0.4884 G loss:-1.555\n",
      "Epoch:  0004 D loss:-0.5128 G loss:-1.58\n",
      "Epoch:  0004 D loss:-0.4993 G loss:-1.66\n",
      "Epoch:  0004 D loss:-0.5114 G loss:-1.678\n",
      "Epoch:  0004 D loss:-0.4677 G loss:-1.752\n",
      "Epoch:  0004 D loss:-0.5324 G loss:-1.698\n",
      "Epoch:  0004 D loss:-0.4598 G loss:-1.837\n",
      "Epoch:  0004 D loss:-0.4699 G loss:-1.743\n",
      "Epoch:  0004 D loss:-0.4178 G loss:-1.722\n",
      "Epoch:  0004 D loss:-0.4259 G loss:-1.735\n",
      "Epoch:  0004 D loss:-0.447 G loss:-1.766\n",
      "Epoch:  0004 D loss:-0.4634 G loss:-1.635\n",
      "Epoch:  0004 D loss:-0.4071 G loss:-1.732\n",
      "Epoch:  0004 D loss:-0.3652 G loss:-1.685\n",
      "Epoch:  0004 D loss:-0.3935 G loss:-1.723\n",
      "Epoch:  0004 D loss:-0.3747 G loss:-1.714\n",
      "Epoch:  0004 D loss:-0.4246 G loss:-1.712\n",
      "Epoch:  0004 D loss:-0.3422 G loss:-1.83\n",
      "Epoch:  0004 D loss:-0.3585 G loss:-1.809\n",
      "Epoch:  0004 D loss:-0.3767 G loss:-1.914\n",
      "Epoch:  0004 D loss:-0.4175 G loss:-1.859\n",
      "Epoch:  0004 D loss:-0.3987 G loss:-1.893\n",
      "Epoch:  0004 D loss:-0.3943 G loss:-1.846\n",
      "Epoch:  0004 D loss:-0.3508 G loss:-1.854\n",
      "Epoch:  0004 D loss:-0.2974 G loss:-1.929\n",
      "Epoch:  0004 D loss:-0.354 G loss:-1.92\n",
      "Epoch:  0004 D loss:-0.3377 G loss:-1.896\n",
      "Epoch:  0004 D loss:-0.3355 G loss:-1.935\n",
      "Epoch:  0004 D loss:-0.3376 G loss:-2.003\n",
      "Epoch:  0004 D loss:-0.3395 G loss:-2.067\n",
      "Epoch:  0004 D loss:-0.3697 G loss:-1.976\n",
      "Epoch:  0004 D loss:-0.3446 G loss:-2.038\n",
      "Epoch:  0004 D loss:-0.3602 G loss:-1.944\n",
      "Epoch:  0004 D loss:-0.3296 G loss:-1.934\n",
      "Epoch:  0004 D loss:-0.3369 G loss:-2.001\n",
      "Epoch:  0004 D loss:-0.3904 G loss:-1.908\n",
      "Epoch:  0004 D loss:-0.3058 G loss:-1.916\n",
      "Epoch:  0004 D loss:-0.3212 G loss:-1.924\n",
      "Epoch:  0004 D loss:-0.3289 G loss:-1.817\n",
      "Epoch:  0004 D loss:-0.3749 G loss:-1.871\n",
      "Epoch:  0004 D loss:-0.3397 G loss:-1.852\n",
      "Epoch:  0004 D loss:-0.3057 G loss:-1.903\n",
      "Epoch:  0004 D loss:-0.3491 G loss:-1.838\n",
      "Epoch:  0004 D loss:-0.3404 G loss:-1.794\n",
      "Epoch:  0005 D loss:-0.3086 G loss:-1.85\n",
      "Epoch:  0005 D loss:-0.3299 G loss:-1.901\n",
      "Epoch:  0005 D loss:-0.3629 G loss:-1.854\n",
      "Epoch:  0005 D loss:-0.3632 G loss:-1.904\n",
      "Epoch:  0005 D loss:-0.3577 G loss:-1.844\n",
      "Epoch:  0005 D loss:-0.3724 G loss:-1.953\n",
      "Epoch:  0005 D loss:-0.337 G loss:-1.865\n",
      "Epoch:  0005 D loss:-0.349 G loss:-1.934\n",
      "Epoch:  0005 D loss:-0.3499 G loss:-1.879\n",
      "Epoch:  0005 D loss:-0.3521 G loss:-1.928\n",
      "Epoch:  0005 D loss:-0.3096 G loss:-1.991\n",
      "Epoch:  0005 D loss:-0.3804 G loss:-1.908\n",
      "Epoch:  0005 D loss:-0.379 G loss:-1.923\n",
      "Epoch:  0005 D loss:-0.3658 G loss:-1.869\n",
      "Epoch:  0005 D loss:-0.3677 G loss:-1.792\n",
      "Epoch:  0005 D loss:-0.4286 G loss:-1.789\n",
      "Epoch:  0005 D loss:-0.3726 G loss:-1.774\n",
      "Epoch:  0005 D loss:-0.4031 G loss:-1.799\n",
      "Epoch:  0005 D loss:-0.4061 G loss:-1.788\n",
      "Epoch:  0005 D loss:-0.3809 G loss:-1.742\n",
      "Epoch:  0005 D loss:-0.3336 G loss:-1.821\n",
      "Epoch:  0005 D loss:-0.3676 G loss:-1.744\n",
      "Epoch:  0005 D loss:-0.4123 G loss:-1.699\n",
      "Epoch:  0005 D loss:-0.3777 G loss:-1.701\n",
      "Epoch:  0005 D loss:-0.408 G loss:-1.724\n",
      "Epoch:  0005 D loss:-0.4032 G loss:-1.771\n",
      "Epoch:  0005 D loss:-0.4106 G loss:-1.767\n",
      "Epoch:  0005 D loss:-0.4012 G loss:-1.783\n",
      "Epoch:  0005 D loss:-0.4427 G loss:-1.807\n",
      "Epoch:  0005 D loss:-0.3826 G loss:-1.805\n",
      "Epoch:  0005 D loss:-0.3835 G loss:-1.81\n",
      "Epoch:  0005 D loss:-0.4198 G loss:-1.817\n",
      "Epoch:  0005 D loss:-0.4634 G loss:-1.724\n",
      "Epoch:  0005 D loss:-0.4401 G loss:-1.679\n",
      "Epoch:  0005 D loss:-0.4844 G loss:-1.7\n",
      "Epoch:  0005 D loss:-0.4838 G loss:-1.671\n",
      "Epoch:  0005 D loss:-0.4624 G loss:-1.662\n",
      "Epoch:  0005 D loss:-0.4599 G loss:-1.693\n",
      "Epoch:  0005 D loss:-0.4605 G loss:-1.668\n",
      "Epoch:  0005 D loss:-0.3936 G loss:-1.654\n",
      "Epoch:  0005 D loss:-0.4441 G loss:-1.673\n",
      "Epoch:  0005 D loss:-0.497 G loss:-1.672\n",
      "Epoch:  0005 D loss:-0.4026 G loss:-1.695\n",
      "Epoch:  0005 D loss:-0.4499 G loss:-1.632\n",
      "Epoch:  0005 D loss:-0.414 G loss:-1.615\n",
      "Epoch:  0005 D loss:-0.4388 G loss:-1.666\n",
      "Epoch:  0005 D loss:-0.4621 G loss:-1.638\n",
      "Epoch:  0005 D loss:-0.4199 G loss:-1.71\n",
      "Epoch:  0005 D loss:-0.4297 G loss:-1.742\n",
      "Epoch:  0005 D loss:-0.4431 G loss:-1.74\n",
      "Epoch:  0005 D loss:-0.473 G loss:-1.689\n",
      "Epoch:  0005 D loss:-0.4676 G loss:-1.7\n",
      "Epoch:  0005 D loss:-0.4433 G loss:-1.76\n",
      "Epoch:  0005 D loss:-0.4321 G loss:-1.719\n",
      "Epoch:  0005 D loss:-0.4434 G loss:-1.695\n",
      "Epoch:  0005 D loss:-0.51 G loss:-1.587\n",
      "Epoch:  0005 D loss:-0.4418 G loss:-1.647\n",
      "Epoch:  0005 D loss:-0.3811 G loss:-1.711\n",
      "Epoch:  0005 D loss:-0.5024 G loss:-1.666\n",
      "Epoch:  0005 D loss:-0.5151 G loss:-1.77\n",
      "Epoch:  0005 D loss:-0.4305 G loss:-1.621\n",
      "Epoch:  0005 D loss:-0.4414 G loss:-1.678\n",
      "Epoch:  0005 D loss:-0.51 G loss:-1.601\n",
      "Epoch:  0005 D loss:-0.4568 G loss:-1.582\n",
      "Epoch:  0005 D loss:-0.46 G loss:-1.559\n",
      "Epoch:  0005 D loss:-0.4489 G loss:-1.677\n",
      "Epoch:  0005 D loss:-0.5346 G loss:-1.584\n",
      "Epoch:  0005 D loss:-0.3699 G loss:-1.657\n",
      "Epoch:  0005 D loss:-0.4443 G loss:-1.622\n",
      "Epoch:  0005 D loss:-0.4696 G loss:-1.627\n",
      "Epoch:  0005 D loss:-0.4428 G loss:-1.692\n",
      "Epoch:  0005 D loss:-0.4383 G loss:-1.692\n",
      "Epoch:  0005 D loss:-0.4617 G loss:-1.665\n",
      "Epoch:  0005 D loss:-0.4527 G loss:-1.735\n",
      "Epoch:  0005 D loss:-0.4735 G loss:-1.659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0005 D loss:-0.4951 G loss:-1.659\n",
      "Epoch:  0005 D loss:-0.3969 G loss:-1.723\n",
      "Epoch:  0005 D loss:-0.4398 G loss:-1.784\n",
      "Epoch:  0005 D loss:-0.3838 G loss:-1.805\n",
      "Epoch:  0005 D loss:-0.3977 G loss:-1.796\n",
      "Epoch:  0005 D loss:-0.4696 G loss:-1.792\n",
      "Epoch:  0005 D loss:-0.4833 G loss:-1.839\n",
      "Epoch:  0005 D loss:-0.3928 G loss:-1.736\n",
      "Epoch:  0005 D loss:-0.4063 G loss:-1.842\n",
      "Epoch:  0005 D loss:-0.4714 G loss:-1.757\n",
      "Epoch:  0005 D loss:-0.4076 G loss:-1.905\n",
      "Epoch:  0005 D loss:-0.3759 G loss:-1.831\n",
      "Epoch:  0005 D loss:-0.4146 G loss:-1.82\n",
      "Epoch:  0005 D loss:-0.4069 G loss:-1.763\n",
      "Epoch:  0005 D loss:-0.3703 G loss:-1.815\n",
      "Epoch:  0005 D loss:-0.384 G loss:-1.869\n",
      "Epoch:  0005 D loss:-0.3688 G loss:-1.876\n",
      "Epoch:  0005 D loss:-0.3539 G loss:-1.922\n",
      "Epoch:  0005 D loss:-0.4099 G loss:-1.976\n",
      "Epoch:  0005 D loss:-0.3716 G loss:-1.871\n",
      "Epoch:  0005 D loss:-0.3996 G loss:-1.947\n",
      "Epoch:  0005 D loss:-0.3883 G loss:-1.828\n",
      "Epoch:  0005 D loss:-0.3924 G loss:-1.84\n",
      "Epoch:  0005 D loss:-0.4011 G loss:-1.901\n",
      "Epoch:  0005 D loss:-0.398 G loss:-1.844\n",
      "Epoch:  0005 D loss:-0.4064 G loss:-1.88\n",
      "Epoch:  0005 D loss:-0.3792 G loss:-1.807\n",
      "Epoch:  0005 D loss:-0.4212 G loss:-1.834\n",
      "Epoch:  0005 D loss:-0.3553 G loss:-1.866\n",
      "Epoch:  0005 D loss:-0.3497 G loss:-1.917\n",
      "Epoch:  0005 D loss:-0.4108 G loss:-1.86\n",
      "Epoch:  0005 D loss:-0.3448 G loss:-1.896\n",
      "Epoch:  0005 D loss:-0.4165 G loss:-1.935\n",
      "Epoch:  0005 D loss:-0.3603 G loss:-1.886\n",
      "Epoch:  0005 D loss:-0.3963 G loss:-1.82\n",
      "Epoch:  0005 D loss:-0.4243 G loss:-1.944\n",
      "Epoch:  0005 D loss:-0.4036 G loss:-1.845\n",
      "Epoch:  0005 D loss:-0.3818 G loss:-1.817\n",
      "Epoch:  0005 D loss:-0.4068 G loss:-1.824\n",
      "Epoch:  0005 D loss:-0.3765 G loss:-1.761\n",
      "Epoch:  0005 D loss:-0.3434 G loss:-1.802\n",
      "Epoch:  0005 D loss:-0.365 G loss:-1.824\n",
      "Epoch:  0005 D loss:-0.3351 G loss:-1.932\n",
      "Epoch:  0005 D loss:-0.4108 G loss:-1.816\n",
      "Epoch:  0005 D loss:-0.3527 G loss:-1.905\n",
      "Epoch:  0005 D loss:-0.3771 G loss:-1.907\n",
      "Epoch:  0005 D loss:-0.3552 G loss:-1.946\n",
      "Epoch:  0005 D loss:-0.4299 G loss:-1.928\n",
      "Epoch:  0005 D loss:-0.3947 G loss:-1.927\n",
      "Epoch:  0005 D loss:-0.3628 G loss:-1.933\n",
      "Epoch:  0005 D loss:-0.3593 G loss:-1.913\n",
      "Epoch:  0005 D loss:-0.3299 G loss:-1.918\n",
      "Epoch:  0005 D loss:-0.3892 G loss:-1.934\n",
      "Epoch:  0005 D loss:-0.378 G loss:-1.984\n",
      "Epoch:  0005 D loss:-0.3908 G loss:-1.914\n",
      "Epoch:  0005 D loss:-0.417 G loss:-1.883\n",
      "Epoch:  0005 D loss:-0.3494 G loss:-1.846\n",
      "Epoch:  0005 D loss:-0.426 G loss:-1.883\n",
      "Epoch:  0005 D loss:-0.4284 G loss:-1.848\n",
      "Epoch:  0005 D loss:-0.3755 G loss:-1.833\n",
      "Epoch:  0005 D loss:-0.3638 G loss:-1.778\n",
      "Epoch:  0005 D loss:-0.3305 G loss:-1.874\n",
      "Epoch:  0005 D loss:-0.3809 G loss:-1.755\n",
      "Epoch:  0005 D loss:-0.3784 G loss:-1.821\n",
      "Epoch:  0005 D loss:-0.3433 G loss:-1.822\n",
      "Epoch:  0005 D loss:-0.4147 G loss:-1.786\n",
      "Epoch:  0005 D loss:-0.334 G loss:-1.887\n",
      "Epoch:  0005 D loss:-0.3289 G loss:-1.914\n",
      "Epoch:  0005 D loss:-0.348 G loss:-1.892\n",
      "Epoch:  0005 D loss:-0.3314 G loss:-1.894\n",
      "Epoch:  0005 D loss:-0.3559 G loss:-1.906\n",
      "Epoch:  0005 D loss:-0.3221 G loss:-2.034\n",
      "Epoch:  0005 D loss:-0.3531 G loss:-1.998\n",
      "Epoch:  0005 D loss:-0.328 G loss:-2.025\n",
      "Epoch:  0005 D loss:-0.3195 G loss:-2.055\n",
      "Epoch:  0005 D loss:-0.2686 G loss:-2.093\n",
      "Epoch:  0005 D loss:-0.312 G loss:-2.03\n",
      "Epoch:  0005 D loss:-0.3201 G loss:-2.051\n",
      "Epoch:  0005 D loss:-0.3696 G loss:-1.957\n",
      "Epoch:  0005 D loss:-0.3696 G loss:-1.949\n",
      "Epoch:  0005 D loss:-0.3363 G loss:-1.994\n",
      "Epoch:  0005 D loss:-0.3874 G loss:-1.937\n",
      "Epoch:  0005 D loss:-0.3449 G loss:-1.958\n",
      "Epoch:  0005 D loss:-0.336 G loss:-1.972\n",
      "Epoch:  0005 D loss:-0.3148 G loss:-1.882\n",
      "Epoch:  0005 D loss:-0.3415 G loss:-1.856\n",
      "Epoch:  0005 D loss:-0.2958 G loss:-1.891\n",
      "Epoch:  0005 D loss:-0.3248 G loss:-1.897\n",
      "Epoch:  0005 D loss:-0.2947 G loss:-2.01\n",
      "Epoch:  0005 D loss:-0.3428 G loss:-1.964\n",
      "Epoch:  0005 D loss:-0.3314 G loss:-1.977\n",
      "Epoch:  0005 D loss:-0.2838 G loss:-2.003\n",
      "Epoch:  0005 D loss:-0.317 G loss:-2.015\n",
      "Epoch:  0005 D loss:-0.3689 G loss:-2.027\n",
      "Epoch:  0005 D loss:-0.3434 G loss:-1.992\n",
      "Epoch:  0005 D loss:-0.3785 G loss:-1.994\n",
      "Epoch:  0005 D loss:-0.3329 G loss:-2.033\n",
      "Epoch:  0005 D loss:-0.2861 G loss:-2.067\n",
      "Epoch:  0005 D loss:-0.2985 G loss:-2.046\n",
      "Epoch:  0005 D loss:-0.3517 G loss:-2.013\n",
      "Epoch:  0005 D loss:-0.3478 G loss:-2.018\n",
      "Epoch:  0005 D loss:-0.278 G loss:-2.05\n",
      "Epoch:  0005 D loss:-0.3789 G loss:-1.939\n",
      "Epoch:  0005 D loss:-0.3296 G loss:-1.97\n",
      "Epoch:  0005 D loss:-0.3389 G loss:-1.965\n",
      "Epoch:  0005 D loss:-0.3853 G loss:-1.906\n",
      "Epoch:  0005 D loss:-0.3276 G loss:-1.942\n",
      "Epoch:  0005 D loss:-0.3457 G loss:-1.966\n",
      "Epoch:  0005 D loss:-0.385 G loss:-2.003\n",
      "Epoch:  0005 D loss:-0.3831 G loss:-1.925\n",
      "Epoch:  0005 D loss:-0.3663 G loss:-1.884\n",
      "Epoch:  0005 D loss:-0.3219 G loss:-1.888\n",
      "Epoch:  0005 D loss:-0.3781 G loss:-1.839\n",
      "Epoch:  0005 D loss:-0.3271 G loss:-1.866\n",
      "Epoch:  0005 D loss:-0.3616 G loss:-1.823\n",
      "Epoch:  0005 D loss:-0.3866 G loss:-1.891\n",
      "Epoch:  0005 D loss:-0.3931 G loss:-1.896\n",
      "Epoch:  0005 D loss:-0.4095 G loss:-1.889\n",
      "Epoch:  0005 D loss:-0.4182 G loss:-1.75\n",
      "Epoch:  0005 D loss:-0.3665 G loss:-1.849\n",
      "Epoch:  0005 D loss:-0.4274 G loss:-1.782\n",
      "Epoch:  0005 D loss:-0.4427 G loss:-1.793\n",
      "Epoch:  0005 D loss:-0.4179 G loss:-1.78\n",
      "Epoch:  0005 D loss:-0.3796 G loss:-1.758\n",
      "Epoch:  0005 D loss:-0.3829 G loss:-1.706\n",
      "Epoch:  0005 D loss:-0.4644 G loss:-1.775\n",
      "Epoch:  0005 D loss:-0.4781 G loss:-1.715\n",
      "Epoch:  0005 D loss:-0.4483 G loss:-1.724\n",
      "Epoch:  0005 D loss:-0.5144 G loss:-1.676\n",
      "Epoch:  0005 D loss:-0.5432 G loss:-1.651\n",
      "Epoch:  0005 D loss:-0.4525 G loss:-1.667\n",
      "Epoch:  0005 D loss:-0.4285 G loss:-1.692\n",
      "Epoch:  0005 D loss:-0.5025 G loss:-1.632\n",
      "Epoch:  0005 D loss:-0.473 G loss:-1.659\n",
      "Epoch:  0005 D loss:-0.4951 G loss:-1.636\n",
      "Epoch:  0005 D loss:-0.5739 G loss:-1.534\n",
      "Epoch:  0005 D loss:-0.5203 G loss:-1.566\n",
      "Epoch:  0005 D loss:-0.5411 G loss:-1.635\n",
      "Epoch:  0005 D loss:-0.4471 G loss:-1.548\n",
      "Epoch:  0005 D loss:-0.5184 G loss:-1.574\n",
      "Epoch:  0005 D loss:-0.522 G loss:-1.537\n",
      "Epoch:  0005 D loss:-0.4766 G loss:-1.57\n",
      "Epoch:  0005 D loss:-0.4333 G loss:-1.637\n",
      "Epoch:  0005 D loss:-0.5291 G loss:-1.595\n",
      "Epoch:  0005 D loss:-0.5012 G loss:-1.607\n",
      "Epoch:  0005 D loss:-0.5699 G loss:-1.682\n",
      "Epoch:  0005 D loss:-0.4697 G loss:-1.756\n",
      "Epoch:  0005 D loss:-0.4883 G loss:-1.741\n",
      "Epoch:  0005 D loss:-0.5567 G loss:-1.665\n",
      "Epoch:  0005 D loss:-0.5257 G loss:-1.681\n",
      "Epoch:  0005 D loss:-0.6097 G loss:-1.543\n",
      "Epoch:  0005 D loss:-0.5255 G loss:-1.633\n",
      "Epoch:  0005 D loss:-0.5425 G loss:-1.557\n",
      "Epoch:  0005 D loss:-0.536 G loss:-1.588\n",
      "Epoch:  0005 D loss:-0.5173 G loss:-1.52\n",
      "Epoch:  0005 D loss:-0.5754 G loss:-1.541\n",
      "Epoch:  0005 D loss:-0.6443 G loss:-1.607\n",
      "Epoch:  0005 D loss:-0.5851 G loss:-1.545\n",
      "Epoch:  0005 D loss:-0.5167 G loss:-1.581\n",
      "Epoch:  0005 D loss:-0.4963 G loss:-1.576\n",
      "Epoch:  0005 D loss:-0.5825 G loss:-1.541\n",
      "Epoch:  0005 D loss:-0.4672 G loss:-1.603\n",
      "Epoch:  0005 D loss:-0.4311 G loss:-1.669\n",
      "Epoch:  0005 D loss:-0.4854 G loss:-1.567\n",
      "Epoch:  0005 D loss:-0.4721 G loss:-1.643\n",
      "Epoch:  0005 D loss:-0.504 G loss:-1.531\n",
      "Epoch:  0005 D loss:-0.4847 G loss:-1.647\n",
      "Epoch:  0005 D loss:-0.4823 G loss:-1.688\n",
      "Epoch:  0005 D loss:-0.5048 G loss:-1.674\n",
      "Epoch:  0005 D loss:-0.5051 G loss:-1.708\n",
      "Epoch:  0005 D loss:-0.4961 G loss:-1.709\n",
      "Epoch:  0005 D loss:-0.4201 G loss:-1.664\n",
      "Epoch:  0005 D loss:-0.4904 G loss:-1.674\n",
      "Epoch:  0005 D loss:-0.4638 G loss:-1.75\n",
      "Epoch:  0005 D loss:-0.5066 G loss:-1.729\n",
      "Epoch:  0005 D loss:-0.3969 G loss:-1.768\n",
      "Epoch:  0005 D loss:-0.4413 G loss:-1.753\n",
      "Epoch:  0005 D loss:-0.3665 G loss:-1.785\n",
      "Epoch:  0005 D loss:-0.5273 G loss:-1.679\n",
      "Epoch:  0005 D loss:-0.4351 G loss:-1.759\n",
      "Epoch:  0005 D loss:-0.4649 G loss:-1.744\n",
      "Epoch:  0005 D loss:-0.3902 G loss:-1.695\n",
      "Epoch:  0005 D loss:-0.4186 G loss:-1.787\n",
      "Epoch:  0005 D loss:-0.4285 G loss:-1.757\n",
      "Epoch:  0005 D loss:-0.3906 G loss:-1.74\n",
      "Epoch:  0005 D loss:-0.3571 G loss:-1.868\n",
      "Epoch:  0005 D loss:-0.4126 G loss:-1.82\n",
      "Epoch:  0005 D loss:-0.4269 G loss:-1.857\n",
      "Epoch:  0005 D loss:-0.4531 G loss:-1.834\n",
      "Epoch:  0005 D loss:-0.4173 G loss:-1.854\n",
      "Epoch:  0005 D loss:-0.4473 G loss:-1.872\n",
      "Epoch:  0005 D loss:-0.4108 G loss:-1.81\n",
      "Epoch:  0005 D loss:-0.4112 G loss:-1.84\n",
      "Epoch:  0005 D loss:-0.3501 G loss:-1.804\n",
      "Epoch:  0005 D loss:-0.3673 G loss:-1.84\n",
      "Epoch:  0005 D loss:-0.4255 G loss:-1.855\n",
      "Epoch:  0005 D loss:-0.4021 G loss:-1.759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0005 D loss:-0.3637 G loss:-1.801\n",
      "Epoch:  0005 D loss:-0.3504 G loss:-1.881\n",
      "Epoch:  0005 D loss:-0.4186 G loss:-1.802\n",
      "Epoch:  0005 D loss:-0.3842 G loss:-1.893\n",
      "Epoch:  0005 D loss:-0.3948 G loss:-1.874\n",
      "Epoch:  0005 D loss:-0.3587 G loss:-1.921\n",
      "Epoch:  0005 D loss:-0.3734 G loss:-1.905\n",
      "Epoch:  0005 D loss:-0.4292 G loss:-1.875\n",
      "Epoch:  0005 D loss:-0.4471 G loss:-1.858\n",
      "Epoch:  0005 D loss:-0.375 G loss:-1.916\n",
      "Epoch:  0005 D loss:-0.3807 G loss:-1.871\n",
      "Epoch:  0005 D loss:-0.3547 G loss:-1.842\n",
      "Epoch:  0005 D loss:-0.3927 G loss:-1.854\n",
      "Epoch:  0005 D loss:-0.3956 G loss:-1.866\n",
      "Epoch:  0005 D loss:-0.4277 G loss:-1.825\n",
      "Epoch:  0005 D loss:-0.4062 G loss:-1.784\n",
      "Epoch:  0005 D loss:-0.4139 G loss:-1.794\n",
      "Epoch:  0005 D loss:-0.4172 G loss:-1.812\n",
      "Epoch:  0005 D loss:-0.429 G loss:-1.817\n",
      "Epoch:  0005 D loss:-0.4006 G loss:-1.756\n",
      "Epoch:  0005 D loss:-0.4607 G loss:-1.781\n",
      "Epoch:  0005 D loss:-0.3764 G loss:-1.804\n",
      "Epoch:  0005 D loss:-0.3788 G loss:-1.81\n",
      "Epoch:  0005 D loss:-0.431 G loss:-1.773\n",
      "Epoch:  0005 D loss:-0.4091 G loss:-1.806\n",
      "Epoch:  0005 D loss:-0.3607 G loss:-1.875\n",
      "Epoch:  0005 D loss:-0.3979 G loss:-1.869\n",
      "Epoch:  0005 D loss:-0.399 G loss:-1.919\n",
      "Epoch:  0005 D loss:-0.3697 G loss:-1.908\n",
      "Epoch:  0005 D loss:-0.3814 G loss:-1.903\n",
      "Epoch:  0005 D loss:-0.4447 G loss:-1.882\n",
      "Epoch:  0005 D loss:-0.3696 G loss:-1.959\n",
      "Epoch:  0005 D loss:-0.3666 G loss:-1.889\n",
      "Epoch:  0005 D loss:-0.3815 G loss:-1.899\n",
      "Epoch:  0005 D loss:-0.4209 G loss:-1.882\n",
      "Epoch:  0005 D loss:-0.4362 G loss:-1.889\n",
      "Epoch:  0005 D loss:-0.3719 G loss:-1.89\n",
      "Epoch:  0005 D loss:-0.4116 G loss:-1.901\n",
      "Epoch:  0005 D loss:-0.4102 G loss:-1.879\n",
      "Epoch:  0005 D loss:-0.4166 G loss:-1.778\n",
      "Epoch:  0005 D loss:-0.4052 G loss:-1.811\n",
      "Epoch:  0005 D loss:-0.4174 G loss:-1.858\n",
      "Epoch:  0005 D loss:-0.4007 G loss:-1.818\n",
      "Epoch:  0005 D loss:-0.4292 G loss:-1.823\n",
      "Epoch:  0005 D loss:-0.3592 G loss:-1.871\n",
      "Epoch:  0005 D loss:-0.3865 G loss:-1.807\n",
      "Epoch:  0005 D loss:-0.4588 G loss:-1.798\n",
      "Epoch:  0005 D loss:-0.3939 G loss:-1.839\n",
      "Epoch:  0005 D loss:-0.4305 G loss:-1.825\n",
      "Epoch:  0005 D loss:-0.4208 G loss:-1.866\n",
      "Epoch:  0005 D loss:-0.4551 G loss:-1.825\n",
      "Epoch:  0005 D loss:-0.4807 G loss:-1.806\n",
      "Epoch:  0005 D loss:-0.4237 G loss:-1.805\n",
      "Epoch:  0005 D loss:-0.4529 G loss:-1.755\n",
      "Epoch:  0005 D loss:-0.3839 G loss:-1.839\n",
      "Epoch:  0005 D loss:-0.3769 G loss:-1.782\n",
      "Epoch:  0005 D loss:-0.4567 G loss:-1.778\n",
      "Epoch:  0005 D loss:-0.407 G loss:-1.807\n",
      "Epoch:  0005 D loss:-0.4834 G loss:-1.802\n",
      "Epoch:  0005 D loss:-0.4359 G loss:-1.713\n",
      "Epoch:  0005 D loss:-0.444 G loss:-1.792\n",
      "Epoch:  0005 D loss:-0.5106 G loss:-1.8\n",
      "Epoch:  0005 D loss:-0.4229 G loss:-1.802\n",
      "Epoch:  0005 D loss:-0.4067 G loss:-1.816\n",
      "Epoch:  0005 D loss:-0.489 G loss:-1.718\n",
      "Epoch:  0005 D loss:-0.4829 G loss:-1.75\n",
      "Epoch:  0005 D loss:-0.4991 G loss:-1.706\n",
      "Epoch:  0005 D loss:-0.4575 G loss:-1.73\n",
      "Epoch:  0005 D loss:-0.4596 G loss:-1.785\n",
      "Epoch:  0005 D loss:-0.4883 G loss:-1.694\n",
      "Epoch:  0005 D loss:-0.4894 G loss:-1.769\n",
      "Epoch:  0005 D loss:-0.4009 G loss:-1.765\n",
      "Epoch:  0005 D loss:-0.4628 G loss:-1.708\n",
      "Epoch:  0005 D loss:-0.4988 G loss:-1.775\n",
      "Epoch:  0005 D loss:-0.4913 G loss:-1.733\n",
      "Epoch:  0005 D loss:-0.4501 G loss:-1.753\n",
      "Epoch:  0005 D loss:-0.4837 G loss:-1.765\n",
      "Epoch:  0005 D loss:-0.5501 G loss:-1.774\n",
      "Epoch:  0005 D loss:-0.4879 G loss:-1.757\n",
      "Epoch:  0005 D loss:-0.4155 G loss:-1.716\n",
      "Epoch:  0005 D loss:-0.4278 G loss:-1.763\n",
      "Epoch:  0005 D loss:-0.4285 G loss:-1.803\n",
      "Epoch:  0005 D loss:-0.4979 G loss:-1.77\n",
      "Epoch:  0005 D loss:-0.4494 G loss:-1.774\n",
      "Epoch:  0005 D loss:-0.467 G loss:-1.78\n",
      "Epoch:  0005 D loss:-0.538 G loss:-1.805\n",
      "Epoch:  0005 D loss:-0.4969 G loss:-1.755\n",
      "Epoch:  0005 D loss:-0.5029 G loss:-1.716\n",
      "Epoch:  0005 D loss:-0.5077 G loss:-1.723\n",
      "Epoch:  0005 D loss:-0.5163 G loss:-1.672\n",
      "Epoch:  0005 D loss:-0.4059 G loss:-1.725\n",
      "Epoch:  0005 D loss:-0.5367 G loss:-1.691\n",
      "Epoch:  0005 D loss:-0.4481 G loss:-1.693\n",
      "Epoch:  0005 D loss:-0.4568 G loss:-1.733\n",
      "Epoch:  0005 D loss:-0.5226 G loss:-1.722\n",
      "Epoch:  0005 D loss:-0.4568 G loss:-1.748\n",
      "Epoch:  0005 D loss:-0.4556 G loss:-1.734\n",
      "Epoch:  0005 D loss:-0.4167 G loss:-1.744\n",
      "Epoch:  0005 D loss:-0.483 G loss:-1.798\n",
      "Epoch:  0005 D loss:-0.4183 G loss:-1.808\n",
      "Epoch:  0005 D loss:-0.4048 G loss:-1.873\n",
      "Epoch:  0005 D loss:-0.4226 G loss:-1.875\n",
      "Epoch:  0005 D loss:-0.4263 G loss:-1.925\n",
      "Epoch:  0005 D loss:-0.4504 G loss:-1.936\n",
      "Epoch:  0005 D loss:-0.5062 G loss:-1.864\n",
      "Epoch:  0005 D loss:-0.4166 G loss:-1.907\n",
      "Epoch:  0005 D loss:-0.4272 G loss:-1.902\n",
      "Epoch:  0005 D loss:-0.3972 G loss:-1.887\n",
      "Epoch:  0005 D loss:-0.3757 G loss:-1.935\n",
      "Epoch:  0005 D loss:-0.4837 G loss:-1.905\n",
      "Epoch:  0005 D loss:-0.43 G loss:-1.918\n",
      "Epoch:  0005 D loss:-0.3961 G loss:-1.89\n",
      "Epoch:  0005 D loss:-0.3711 G loss:-1.891\n",
      "Epoch:  0005 D loss:-0.4535 G loss:-1.887\n",
      "Epoch:  0005 D loss:-0.3866 G loss:-1.849\n",
      "Epoch:  0005 D loss:-0.3982 G loss:-1.873\n",
      "Epoch:  0005 D loss:-0.4313 G loss:-1.898\n",
      "Epoch:  0005 D loss:-0.4357 G loss:-1.94\n",
      "Epoch:  0005 D loss:-0.3401 G loss:-1.894\n",
      "Epoch:  0005 D loss:-0.3733 G loss:-1.906\n",
      "Epoch:  0005 D loss:-0.4538 G loss:-1.913\n",
      "Epoch:  0005 D loss:-0.4232 G loss:-1.893\n",
      "Epoch:  0005 D loss:-0.3432 G loss:-1.87\n",
      "Epoch:  0005 D loss:-0.3296 G loss:-1.892\n",
      "Epoch:  0005 D loss:-0.435 G loss:-1.904\n",
      "Epoch:  0005 D loss:-0.3345 G loss:-1.929\n",
      "Epoch:  0005 D loss:-0.4605 G loss:-1.932\n",
      "Epoch:  0005 D loss:-0.3622 G loss:-1.964\n",
      "Epoch:  0005 D loss:-0.3102 G loss:-1.961\n",
      "Epoch:  0005 D loss:-0.3639 G loss:-1.973\n",
      "Epoch:  0005 D loss:-0.4067 G loss:-2.072\n",
      "Epoch:  0005 D loss:-0.4233 G loss:-2.022\n",
      "Epoch:  0005 D loss:-0.3824 G loss:-2.019\n",
      "Epoch:  0005 D loss:-0.2958 G loss:-2.008\n",
      "Epoch:  0005 D loss:-0.3144 G loss:-2.029\n",
      "Epoch:  0005 D loss:-0.3178 G loss:-2.042\n",
      "Epoch:  0005 D loss:-0.3973 G loss:-2.061\n",
      "Epoch:  0005 D loss:-0.3561 G loss:-2.03\n",
      "Epoch:  0005 D loss:-0.328 G loss:-2.049\n",
      "Epoch:  0005 D loss:-0.3753 G loss:-1.999\n",
      "Epoch:  0005 D loss:-0.3524 G loss:-2.013\n",
      "Epoch:  0005 D loss:-0.3586 G loss:-1.987\n",
      "Epoch:  0005 D loss:-0.3171 G loss:-1.99\n",
      "Epoch:  0005 D loss:-0.3199 G loss:-1.995\n",
      "Epoch:  0005 D loss:-0.3623 G loss:-2.037\n",
      "Epoch:  0005 D loss:-0.277 G loss:-2.06\n",
      "Epoch:  0005 D loss:-0.3215 G loss:-2.126\n",
      "Epoch:  0005 D loss:-0.3296 G loss:-2.154\n",
      "Epoch:  0005 D loss:-0.3477 G loss:-2.139\n",
      "Epoch:  0005 D loss:-0.4127 G loss:-2.12\n",
      "Epoch:  0005 D loss:-0.3503 G loss:-2.095\n",
      "Epoch:  0005 D loss:-0.3652 G loss:-2.036\n",
      "Epoch:  0005 D loss:-0.3192 G loss:-2.111\n",
      "Epoch:  0005 D loss:-0.3772 G loss:-2.056\n",
      "Epoch:  0005 D loss:-0.3177 G loss:-2.057\n",
      "Epoch:  0005 D loss:-0.322 G loss:-2.031\n",
      "Epoch:  0005 D loss:-0.3512 G loss:-2.044\n",
      "Epoch:  0005 D loss:-0.3293 G loss:-2.004\n",
      "Epoch:  0005 D loss:-0.3558 G loss:-2.071\n",
      "Epoch:  0005 D loss:-0.322 G loss:-2.018\n",
      "Epoch:  0005 D loss:-0.3303 G loss:-2.136\n",
      "Epoch:  0005 D loss:-0.291 G loss:-2.113\n",
      "Epoch:  0005 D loss:-0.3877 G loss:-2.014\n",
      "Epoch:  0005 D loss:-0.344 G loss:-2.089\n",
      "Epoch:  0005 D loss:-0.3523 G loss:-2.101\n",
      "Epoch:  0005 D loss:-0.2867 G loss:-2.092\n",
      "Epoch:  0005 D loss:-0.3436 G loss:-2.09\n",
      "Epoch:  0005 D loss:-0.3324 G loss:-2.057\n",
      "Epoch:  0005 D loss:-0.3864 G loss:-2.114\n",
      "Epoch:  0005 D loss:-0.342 G loss:-2.126\n",
      "Epoch:  0005 D loss:-0.3629 G loss:-2.128\n",
      "Epoch:  0005 D loss:-0.4067 G loss:-2.035\n",
      "Epoch:  0005 D loss:-0.3762 G loss:-2.069\n",
      "Epoch:  0005 D loss:-0.4049 G loss:-2.032\n",
      "Epoch:  0005 D loss:-0.393 G loss:-2.063\n",
      "Epoch:  0005 D loss:-0.4084 G loss:-2.001\n",
      "Epoch:  0005 D loss:-0.3343 G loss:-2.017\n",
      "Epoch:  0005 D loss:-0.3167 G loss:-1.974\n",
      "Epoch:  0005 D loss:-0.3804 G loss:-1.873\n",
      "Epoch:  0005 D loss:-0.394 G loss:-2.002\n",
      "Epoch:  0005 D loss:-0.4206 G loss:-1.935\n",
      "Epoch:  0005 D loss:-0.3497 G loss:-1.984\n",
      "Epoch:  0005 D loss:-0.3412 G loss:-2.017\n",
      "Epoch:  0005 D loss:-0.3794 G loss:-2.052\n",
      "Epoch:  0005 D loss:-0.3714 G loss:-2.021\n",
      "Epoch:  0005 D loss:-0.3931 G loss:-2.089\n",
      "Epoch:  0005 D loss:-0.3815 G loss:-2.082\n",
      "Epoch:  0005 D loss:-0.3667 G loss:-2.07\n",
      "Epoch:  0005 D loss:-0.3847 G loss:-2.093\n",
      "Epoch:  0005 D loss:-0.3838 G loss:-2.123\n",
      "Epoch:  0005 D loss:-0.4202 G loss:-2.071\n",
      "Epoch:  0005 D loss:-0.3503 G loss:-1.996\n",
      "Epoch:  0005 D loss:-0.3702 G loss:-2.004\n",
      "Epoch:  0005 D loss:-0.3663 G loss:-2.039\n",
      "Epoch:  0005 D loss:-0.397 G loss:-1.946\n",
      "Epoch:  0005 D loss:-0.3261 G loss:-2.01\n",
      "Epoch:  0005 D loss:-0.3621 G loss:-2.017\n",
      "Epoch:  0005 D loss:-0.3894 G loss:-2.049\n",
      "Epoch:  0005 D loss:-0.3389 G loss:-2.063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0005 D loss:-0.3407 G loss:-2.051\n",
      "Epoch:  0005 D loss:-0.3862 G loss:-2.099\n",
      "Epoch:  0005 D loss:-0.3296 G loss:-2.088\n",
      "Epoch:  0005 D loss:-0.3407 G loss:-2.009\n",
      "Epoch:  0005 D loss:-0.454 G loss:-2.038\n",
      "Epoch:  0005 D loss:-0.3678 G loss:-2.057\n",
      "Epoch:  0005 D loss:-0.4104 G loss:-2.025\n",
      "Epoch:  0005 D loss:-0.3492 G loss:-1.963\n",
      "Epoch:  0005 D loss:-0.3282 G loss:-1.934\n",
      "Epoch:  0005 D loss:-0.3872 G loss:-1.968\n",
      "Epoch:  0005 D loss:-0.3839 G loss:-2.022\n",
      "Epoch:  0005 D loss:-0.4232 G loss:-1.966\n",
      "Epoch:  0005 D loss:-0.3485 G loss:-2.019\n",
      "Epoch:  0005 D loss:-0.3328 G loss:-1.973\n",
      "Epoch:  0005 D loss:-0.3892 G loss:-1.997\n",
      "Epoch:  0005 D loss:-0.3775 G loss:-1.976\n",
      "Epoch:  0005 D loss:-0.342 G loss:-2.033\n",
      "Epoch:  0005 D loss:-0.3691 G loss:-2.112\n",
      "Epoch:  0005 D loss:-0.3927 G loss:-2.164\n",
      "Epoch:  0005 D loss:-0.426 G loss:-2.016\n",
      "Epoch:  0005 D loss:-0.3708 G loss:-2.155\n",
      "Epoch:  0005 D loss:-0.35 G loss:-2.054\n",
      "Epoch:  0005 D loss:-0.3723 G loss:-2.112\n",
      "Epoch:  0005 D loss:-0.3752 G loss:-2.006\n",
      "Epoch:  0005 D loss:-0.4343 G loss:-2.104\n",
      "Epoch:  0005 D loss:-0.4916 G loss:-1.964\n",
      "Epoch:  0005 D loss:-0.3682 G loss:-1.941\n",
      "Epoch:  0005 D loss:-0.3852 G loss:-1.939\n",
      "Epoch:  0005 D loss:-0.3969 G loss:-1.898\n",
      "Epoch:  0005 D loss:-0.3848 G loss:-1.925\n",
      "Epoch:  0005 D loss:-0.3388 G loss:-1.933\n",
      "Epoch:  0005 D loss:-0.4033 G loss:-1.953\n",
      "Epoch:  0005 D loss:-0.358 G loss:-1.944\n",
      "Epoch:  0005 D loss:-0.3512 G loss:-2.033\n",
      "Epoch:  0005 D loss:-0.4185 G loss:-1.989\n",
      "Epoch:  0005 D loss:-0.3921 G loss:-1.968\n",
      "Epoch:  0005 D loss:-0.3422 G loss:-2.089\n",
      "Epoch:  0005 D loss:-0.4039 G loss:-2.024\n",
      "Epoch:  0005 D loss:-0.3949 G loss:-2.028\n",
      "Epoch:  0005 D loss:-0.3847 G loss:-2.113\n",
      "Epoch:  0005 D loss:-0.3753 G loss:-1.985\n",
      "Epoch:  0005 D loss:-0.4145 G loss:-2.028\n",
      "Epoch:  0005 D loss:-0.3628 G loss:-2.147\n",
      "Epoch:  0005 D loss:-0.4062 G loss:-2.089\n",
      "Epoch:  0005 D loss:-0.4001 G loss:-2.0\n",
      "Epoch:  0005 D loss:-0.3558 G loss:-2.019\n",
      "Epoch:  0005 D loss:-0.3926 G loss:-2.02\n",
      "Epoch:  0005 D loss:-0.3426 G loss:-1.957\n",
      "Epoch:  0005 D loss:-0.4649 G loss:-1.961\n",
      "Epoch:  0005 D loss:-0.4677 G loss:-1.801\n",
      "Epoch:  0005 D loss:-0.385 G loss:-1.929\n",
      "Epoch:  0005 D loss:-0.36 G loss:-1.937\n",
      "Epoch:  0005 D loss:-0.4372 G loss:-1.905\n",
      "Epoch:  0005 D loss:-0.3907 G loss:-1.876\n",
      "Epoch:  0005 D loss:-0.4262 G loss:-1.867\n",
      "Epoch:  0005 D loss:-0.3878 G loss:-1.937\n",
      "Epoch:  0005 D loss:-0.4207 G loss:-1.954\n",
      "Epoch:  0005 D loss:-0.4388 G loss:-1.933\n",
      "Epoch:  0005 D loss:-0.4433 G loss:-1.883\n",
      "Epoch:  0005 D loss:-0.5239 G loss:-1.866\n",
      "Epoch:  0005 D loss:-0.3778 G loss:-1.845\n",
      "Epoch:  0005 D loss:-0.438 G loss:-1.777\n",
      "Epoch:  0005 D loss:-0.5143 G loss:-1.775\n",
      "Epoch:  0005 D loss:-0.4889 G loss:-1.813\n",
      "Epoch:  0005 D loss:-0.4598 G loss:-1.762\n",
      "Epoch:  0005 D loss:-0.4621 G loss:-1.738\n",
      "Epoch:  0005 D loss:-0.4902 G loss:-1.72\n",
      "Epoch:  0005 D loss:-0.4172 G loss:-1.783\n",
      "Epoch:  0005 D loss:-0.5298 G loss:-1.739\n",
      "Epoch:  0005 D loss:-0.3928 G loss:-1.829\n",
      "Epoch:  0005 D loss:-0.4869 G loss:-1.845\n",
      "Epoch:  0005 D loss:-0.4756 G loss:-1.825\n",
      "Epoch:  0005 D loss:-0.4543 G loss:-1.828\n",
      "Epoch:  0005 D loss:-0.4379 G loss:-1.854\n",
      "Epoch:  0005 D loss:-0.4559 G loss:-1.867\n",
      "Epoch:  0005 D loss:-0.468 G loss:-1.96\n",
      "Epoch:  0005 D loss:-0.4418 G loss:-1.9\n",
      "Epoch:  0005 D loss:-0.413 G loss:-1.851\n",
      "Epoch:  0005 D loss:-0.4002 G loss:-1.853\n",
      "Epoch:  0006 D loss:-0.4017 G loss:-1.933\n",
      "Epoch:  0006 D loss:-0.4699 G loss:-1.911\n",
      "Epoch:  0006 D loss:-0.5417 G loss:-1.878\n",
      "Epoch:  0006 D loss:-0.5193 G loss:-1.874\n",
      "Epoch:  0006 D loss:-0.4118 G loss:-1.782\n",
      "Epoch:  0006 D loss:-0.4426 G loss:-1.761\n",
      "Epoch:  0006 D loss:-0.5324 G loss:-1.779\n",
      "Epoch:  0006 D loss:-0.5484 G loss:-1.773\n",
      "Epoch:  0006 D loss:-0.5894 G loss:-1.764\n",
      "Epoch:  0006 D loss:-0.5169 G loss:-1.742\n",
      "Epoch:  0006 D loss:-0.4915 G loss:-1.744\n",
      "Epoch:  0006 D loss:-0.4808 G loss:-1.745\n",
      "Epoch:  0006 D loss:-0.4618 G loss:-1.772\n",
      "Epoch:  0006 D loss:-0.4634 G loss:-1.767\n",
      "Epoch:  0006 D loss:-0.5635 G loss:-1.754\n",
      "Epoch:  0006 D loss:-0.5017 G loss:-1.813\n",
      "Epoch:  0006 D loss:-0.3927 G loss:-1.799\n",
      "Epoch:  0006 D loss:-0.5195 G loss:-1.832\n",
      "Epoch:  0006 D loss:-0.43 G loss:-1.83\n",
      "Epoch:  0006 D loss:-0.424 G loss:-1.868\n",
      "Epoch:  0006 D loss:-0.4483 G loss:-1.866\n",
      "Epoch:  0006 D loss:-0.3851 G loss:-1.926\n",
      "Epoch:  0006 D loss:-0.4582 G loss:-1.943\n",
      "Epoch:  0006 D loss:-0.5056 G loss:-1.917\n",
      "Epoch:  0006 D loss:-0.4033 G loss:-1.928\n",
      "Epoch:  0006 D loss:-0.4092 G loss:-1.978\n",
      "Epoch:  0006 D loss:-0.4601 G loss:-2.076\n",
      "Epoch:  0006 D loss:-0.4127 G loss:-2.037\n",
      "Epoch:  0006 D loss:-0.4319 G loss:-2.072\n",
      "Epoch:  0006 D loss:-0.3726 G loss:-2.021\n",
      "Epoch:  0006 D loss:-0.5313 G loss:-1.956\n",
      "Epoch:  0006 D loss:-0.4469 G loss:-1.916\n",
      "Epoch:  0006 D loss:-0.4825 G loss:-1.927\n",
      "Epoch:  0006 D loss:-0.4545 G loss:-1.874\n",
      "Epoch:  0006 D loss:-0.4747 G loss:-1.838\n",
      "Epoch:  0006 D loss:-0.399 G loss:-1.848\n",
      "Epoch:  0006 D loss:-0.4391 G loss:-1.812\n",
      "Epoch:  0006 D loss:-0.4243 G loss:-1.859\n",
      "Epoch:  0006 D loss:-0.4982 G loss:-1.883\n",
      "Epoch:  0006 D loss:-0.4147 G loss:-1.862\n",
      "Epoch:  0006 D loss:-0.4459 G loss:-1.876\n",
      "Epoch:  0006 D loss:-0.4781 G loss:-2.02\n",
      "Epoch:  0006 D loss:-0.4315 G loss:-1.93\n",
      "Epoch:  0006 D loss:-0.5071 G loss:-1.945\n",
      "Epoch:  0006 D loss:-0.5248 G loss:-1.982\n",
      "Epoch:  0006 D loss:-0.4114 G loss:-1.968\n",
      "Epoch:  0006 D loss:-0.4588 G loss:-1.989\n",
      "Epoch:  0006 D loss:-0.4279 G loss:-1.988\n",
      "Epoch:  0006 D loss:-0.4679 G loss:-1.921\n",
      "Epoch:  0006 D loss:-0.3868 G loss:-1.999\n",
      "Epoch:  0006 D loss:-0.4892 G loss:-1.967\n",
      "Epoch:  0006 D loss:-0.3824 G loss:-1.983\n",
      "Epoch:  0006 D loss:-0.4644 G loss:-2.042\n",
      "Epoch:  0006 D loss:-0.471 G loss:-1.979\n",
      "Epoch:  0006 D loss:-0.4349 G loss:-1.941\n",
      "Epoch:  0006 D loss:-0.4224 G loss:-1.992\n",
      "Epoch:  0006 D loss:-0.4058 G loss:-2.057\n",
      "Epoch:  0006 D loss:-0.3706 G loss:-1.985\n",
      "Epoch:  0006 D loss:-0.3853 G loss:-1.991\n",
      "Epoch:  0006 D loss:-0.3705 G loss:-1.999\n",
      "Epoch:  0006 D loss:-0.3494 G loss:-2.046\n",
      "Epoch:  0006 D loss:-0.4093 G loss:-2.008\n",
      "Epoch:  0006 D loss:-0.4031 G loss:-2.021\n",
      "Epoch:  0006 D loss:-0.3854 G loss:-2.141\n",
      "Epoch:  0006 D loss:-0.3851 G loss:-2.046\n",
      "Epoch:  0006 D loss:-0.3946 G loss:-2.137\n",
      "Epoch:  0006 D loss:-0.409 G loss:-2.094\n",
      "Epoch:  0006 D loss:-0.3942 G loss:-2.093\n",
      "Epoch:  0006 D loss:-0.3556 G loss:-2.045\n",
      "Epoch:  0006 D loss:-0.4899 G loss:-2.065\n",
      "Epoch:  0006 D loss:-0.43 G loss:-2.021\n",
      "Epoch:  0006 D loss:-0.4037 G loss:-1.938\n",
      "Epoch:  0006 D loss:-0.4183 G loss:-1.958\n",
      "Epoch:  0006 D loss:-0.4005 G loss:-1.974\n",
      "Epoch:  0006 D loss:-0.3406 G loss:-2.037\n",
      "Epoch:  0006 D loss:-0.4074 G loss:-1.956\n",
      "Epoch:  0006 D loss:-0.3385 G loss:-2.096\n",
      "Epoch:  0006 D loss:-0.3436 G loss:-2.056\n",
      "Epoch:  0006 D loss:-0.4131 G loss:-2.069\n",
      "Epoch:  0006 D loss:-0.3947 G loss:-2.094\n",
      "Epoch:  0006 D loss:-0.3982 G loss:-2.147\n",
      "Epoch:  0006 D loss:-0.4175 G loss:-2.129\n",
      "Epoch:  0006 D loss:-0.3987 G loss:-2.091\n",
      "Epoch:  0006 D loss:-0.4018 G loss:-2.155\n",
      "Epoch:  0006 D loss:-0.3474 G loss:-2.182\n",
      "Epoch:  0006 D loss:-0.43 G loss:-2.169\n",
      "Epoch:  0006 D loss:-0.3994 G loss:-2.108\n",
      "Epoch:  0006 D loss:-0.3815 G loss:-2.089\n",
      "Epoch:  0006 D loss:-0.4208 G loss:-1.982\n",
      "Epoch:  0006 D loss:-0.397 G loss:-1.964\n",
      "Epoch:  0006 D loss:-0.4393 G loss:-1.989\n",
      "Epoch:  0006 D loss:-0.3739 G loss:-1.892\n",
      "Epoch:  0006 D loss:-0.4248 G loss:-2.013\n",
      "Epoch:  0006 D loss:-0.4824 G loss:-2.02\n",
      "Epoch:  0006 D loss:-0.4508 G loss:-2.002\n",
      "Epoch:  0006 D loss:-0.4656 G loss:-1.933\n",
      "Epoch:  0006 D loss:-0.4759 G loss:-1.916\n",
      "Epoch:  0006 D loss:-0.5166 G loss:-1.954\n",
      "Epoch:  0006 D loss:-0.4481 G loss:-1.885\n",
      "Epoch:  0006 D loss:-0.4692 G loss:-1.909\n",
      "Epoch:  0006 D loss:-0.4651 G loss:-1.919\n",
      "Epoch:  0006 D loss:-0.5285 G loss:-1.826\n",
      "Epoch:  0006 D loss:-0.4845 G loss:-1.877\n",
      "Epoch:  0006 D loss:-0.4732 G loss:-1.806\n",
      "Epoch:  0006 D loss:-0.4756 G loss:-1.925\n",
      "Epoch:  0006 D loss:-0.4671 G loss:-1.907\n",
      "Epoch:  0006 D loss:-0.5123 G loss:-1.912\n",
      "Epoch:  0006 D loss:-0.4939 G loss:-1.829\n",
      "Epoch:  0006 D loss:-0.4284 G loss:-1.932\n",
      "Epoch:  0006 D loss:-0.5432 G loss:-1.941\n",
      "Epoch:  0006 D loss:-0.4926 G loss:-1.978\n",
      "Epoch:  0006 D loss:-0.5031 G loss:-1.926\n",
      "Epoch:  0006 D loss:-0.5273 G loss:-1.903\n",
      "Epoch:  0006 D loss:-0.5516 G loss:-1.85\n",
      "Epoch:  0006 D loss:-0.4129 G loss:-1.777\n",
      "Epoch:  0006 D loss:-0.4582 G loss:-1.862\n",
      "Epoch:  0006 D loss:-0.5548 G loss:-1.82\n",
      "Epoch:  0006 D loss:-0.4613 G loss:-1.868\n",
      "Epoch:  0006 D loss:-0.5483 G loss:-1.926\n",
      "Epoch:  0006 D loss:-0.4642 G loss:-1.916\n",
      "Epoch:  0006 D loss:-0.5269 G loss:-1.824\n",
      "Epoch:  0006 D loss:-0.5164 G loss:-1.889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0006 D loss:-0.5309 G loss:-1.875\n",
      "Epoch:  0006 D loss:-0.5488 G loss:-1.884\n",
      "Epoch:  0006 D loss:-0.5527 G loss:-1.982\n",
      "Epoch:  0006 D loss:-0.4754 G loss:-1.951\n",
      "Epoch:  0006 D loss:-0.5246 G loss:-1.824\n",
      "Epoch:  0006 D loss:-0.4804 G loss:-1.861\n",
      "Epoch:  0006 D loss:-0.3927 G loss:-1.855\n",
      "Epoch:  0006 D loss:-0.5875 G loss:-1.902\n",
      "Epoch:  0006 D loss:-0.5442 G loss:-1.895\n",
      "Epoch:  0006 D loss:-0.6468 G loss:-1.863\n",
      "Epoch:  0006 D loss:-0.4538 G loss:-1.899\n",
      "Epoch:  0006 D loss:-0.4203 G loss:-1.909\n",
      "Epoch:  0006 D loss:-0.4439 G loss:-1.931\n",
      "Epoch:  0006 D loss:-0.4794 G loss:-1.969\n",
      "Epoch:  0006 D loss:-0.4411 G loss:-1.936\n",
      "Epoch:  0006 D loss:-0.3477 G loss:-2.002\n",
      "Epoch:  0006 D loss:-0.4279 G loss:-2.026\n",
      "Epoch:  0006 D loss:-0.4007 G loss:-1.986\n",
      "Epoch:  0006 D loss:-0.3603 G loss:-2.052\n",
      "Epoch:  0006 D loss:-0.4377 G loss:-2.054\n",
      "Epoch:  0006 D loss:-0.4945 G loss:-2.128\n",
      "Epoch:  0006 D loss:-0.3463 G loss:-2.071\n",
      "Epoch:  0006 D loss:-0.3498 G loss:-2.129\n",
      "Epoch:  0006 D loss:-0.4097 G loss:-2.134\n",
      "Epoch:  0006 D loss:-0.4585 G loss:-2.135\n",
      "Epoch:  0006 D loss:-0.3636 G loss:-2.057\n",
      "Epoch:  0006 D loss:-0.3669 G loss:-2.096\n",
      "Epoch:  0006 D loss:-0.451 G loss:-2.033\n",
      "Epoch:  0006 D loss:-0.4251 G loss:-2.061\n",
      "Epoch:  0006 D loss:-0.436 G loss:-2.05\n",
      "Epoch:  0006 D loss:-0.3159 G loss:-2.077\n",
      "Epoch:  0006 D loss:-0.3794 G loss:-2.085\n",
      "Epoch:  0006 D loss:-0.3286 G loss:-2.106\n",
      "Epoch:  0006 D loss:-0.3729 G loss:-2.136\n",
      "Epoch:  0006 D loss:-0.3702 G loss:-2.216\n",
      "Epoch:  0006 D loss:-0.3595 G loss:-2.169\n",
      "Epoch:  0006 D loss:-0.3642 G loss:-2.256\n",
      "Epoch:  0006 D loss:-0.3809 G loss:-2.112\n",
      "Epoch:  0006 D loss:-0.2859 G loss:-2.252\n",
      "Epoch:  0006 D loss:-0.3297 G loss:-2.253\n",
      "Epoch:  0006 D loss:-0.3868 G loss:-2.284\n",
      "Epoch:  0006 D loss:-0.3315 G loss:-2.265\n",
      "Epoch:  0006 D loss:-0.2726 G loss:-2.332\n",
      "Epoch:  0006 D loss:-0.276 G loss:-2.354\n",
      "Epoch:  0006 D loss:-0.3431 G loss:-2.358\n",
      "Epoch:  0006 D loss:-0.345 G loss:-2.391\n",
      "Epoch:  0006 D loss:-0.3065 G loss:-2.422\n",
      "Epoch:  0006 D loss:-0.3307 G loss:-2.404\n",
      "Epoch:  0006 D loss:-0.2659 G loss:-2.336\n",
      "Epoch:  0006 D loss:-0.3879 G loss:-2.351\n",
      "Epoch:  0006 D loss:-0.2687 G loss:-2.418\n",
      "Epoch:  0006 D loss:-0.3492 G loss:-2.337\n",
      "Epoch:  0006 D loss:-0.3421 G loss:-2.223\n",
      "Epoch:  0006 D loss:-0.3216 G loss:-2.362\n",
      "Epoch:  0006 D loss:-0.3604 G loss:-2.257\n",
      "Epoch:  0006 D loss:-0.3016 G loss:-2.272\n",
      "Epoch:  0006 D loss:-0.2528 G loss:-2.33\n",
      "Epoch:  0006 D loss:-0.332 G loss:-2.299\n",
      "Epoch:  0006 D loss:-0.4066 G loss:-2.247\n",
      "Epoch:  0006 D loss:-0.3372 G loss:-2.305\n",
      "Epoch:  0006 D loss:-0.3599 G loss:-2.227\n",
      "Epoch:  0006 D loss:-0.2928 G loss:-2.2\n",
      "Epoch:  0006 D loss:-0.3426 G loss:-2.225\n",
      "Epoch:  0006 D loss:-0.318 G loss:-2.321\n",
      "Epoch:  0006 D loss:-0.3173 G loss:-2.31\n",
      "Epoch:  0006 D loss:-0.3108 G loss:-2.315\n",
      "Epoch:  0006 D loss:-0.2542 G loss:-2.349\n",
      "Epoch:  0006 D loss:-0.2987 G loss:-2.399\n",
      "Epoch:  0006 D loss:-0.3129 G loss:-2.382\n",
      "Epoch:  0006 D loss:-0.3956 G loss:-2.482\n",
      "Epoch:  0006 D loss:-0.2966 G loss:-2.371\n",
      "Epoch:  0006 D loss:-0.2867 G loss:-2.392\n",
      "Epoch:  0006 D loss:-0.3314 G loss:-2.323\n",
      "Epoch:  0006 D loss:-0.27 G loss:-2.383\n",
      "Epoch:  0006 D loss:-0.3917 G loss:-2.296\n",
      "Epoch:  0006 D loss:-0.3219 G loss:-2.32\n",
      "Epoch:  0006 D loss:-0.2771 G loss:-2.279\n",
      "Epoch:  0006 D loss:-0.2988 G loss:-2.262\n",
      "Epoch:  0006 D loss:-0.3149 G loss:-2.304\n",
      "Epoch:  0006 D loss:-0.3022 G loss:-2.365\n",
      "Epoch:  0006 D loss:-0.3241 G loss:-2.22\n",
      "Epoch:  0006 D loss:-0.4348 G loss:-2.296\n",
      "Epoch:  0006 D loss:-0.3544 G loss:-2.162\n",
      "Epoch:  0006 D loss:-0.3599 G loss:-2.234\n",
      "Epoch:  0006 D loss:-0.2763 G loss:-2.249\n",
      "Epoch:  0006 D loss:-0.3652 G loss:-2.2\n",
      "Epoch:  0006 D loss:-0.3298 G loss:-2.266\n",
      "Epoch:  0006 D loss:-0.3543 G loss:-2.315\n",
      "Epoch:  0006 D loss:-0.2819 G loss:-2.357\n",
      "Epoch:  0006 D loss:-0.3926 G loss:-2.233\n",
      "Epoch:  0006 D loss:-0.3266 G loss:-2.251\n",
      "Epoch:  0006 D loss:-0.3357 G loss:-2.315\n",
      "Epoch:  0006 D loss:-0.3278 G loss:-2.31\n",
      "Epoch:  0006 D loss:-0.3968 G loss:-2.231\n",
      "Epoch:  0006 D loss:-0.2799 G loss:-2.158\n",
      "Epoch:  0006 D loss:-0.3317 G loss:-2.207\n",
      "Epoch:  0006 D loss:-0.3124 G loss:-2.28\n",
      "Epoch:  0006 D loss:-0.4176 G loss:-2.188\n",
      "Epoch:  0006 D loss:-0.3397 G loss:-2.241\n",
      "Epoch:  0006 D loss:-0.2973 G loss:-2.228\n",
      "Epoch:  0006 D loss:-0.3737 G loss:-2.123\n",
      "Epoch:  0006 D loss:-0.3448 G loss:-2.224\n",
      "Epoch:  0006 D loss:-0.3015 G loss:-2.339\n",
      "Epoch:  0006 D loss:-0.4235 G loss:-2.256\n",
      "Epoch:  0006 D loss:-0.4017 G loss:-2.268\n",
      "Epoch:  0006 D loss:-0.3522 G loss:-2.226\n",
      "Epoch:  0006 D loss:-0.3406 G loss:-2.269\n",
      "Epoch:  0006 D loss:-0.3941 G loss:-2.179\n",
      "Epoch:  0006 D loss:-0.3521 G loss:-2.17\n",
      "Epoch:  0006 D loss:-0.4284 G loss:-2.03\n",
      "Epoch:  0006 D loss:-0.3829 G loss:-2.134\n",
      "Epoch:  0006 D loss:-0.3755 G loss:-2.078\n",
      "Epoch:  0006 D loss:-0.3366 G loss:-2.075\n",
      "Epoch:  0006 D loss:-0.412 G loss:-2.094\n",
      "Epoch:  0006 D loss:-0.3745 G loss:-2.107\n",
      "Epoch:  0006 D loss:-0.4157 G loss:-2.215\n",
      "Epoch:  0006 D loss:-0.2593 G loss:-2.389\n",
      "Epoch:  0006 D loss:-0.378 G loss:-2.301\n",
      "Epoch:  0006 D loss:-0.3871 G loss:-2.233\n",
      "Epoch:  0006 D loss:-0.3157 G loss:-2.386\n",
      "Epoch:  0006 D loss:-0.3128 G loss:-2.38\n",
      "Epoch:  0006 D loss:-0.4152 G loss:-2.284\n",
      "Epoch:  0006 D loss:-0.3914 G loss:-2.314\n",
      "Epoch:  0006 D loss:-0.4304 G loss:-2.288\n",
      "Epoch:  0006 D loss:-0.3803 G loss:-2.218\n",
      "Epoch:  0006 D loss:-0.4401 G loss:-2.215\n",
      "Epoch:  0006 D loss:-0.464 G loss:-2.229\n",
      "Epoch:  0006 D loss:-0.3932 G loss:-2.057\n",
      "Epoch:  0006 D loss:-0.4141 G loss:-2.128\n",
      "Epoch:  0006 D loss:-0.3827 G loss:-2.037\n",
      "Epoch:  0006 D loss:-0.3776 G loss:-2.069\n",
      "Epoch:  0006 D loss:-0.4218 G loss:-2.169\n",
      "Epoch:  0006 D loss:-0.4273 G loss:-2.131\n",
      "Epoch:  0006 D loss:-0.3655 G loss:-2.279\n",
      "Epoch:  0006 D loss:-0.3943 G loss:-2.206\n",
      "Epoch:  0006 D loss:-0.4657 G loss:-2.32\n",
      "Epoch:  0006 D loss:-0.3387 G loss:-2.272\n",
      "Epoch:  0006 D loss:-0.3381 G loss:-2.341\n",
      "Epoch:  0006 D loss:-0.3972 G loss:-2.181\n",
      "Epoch:  0006 D loss:-0.3383 G loss:-2.343\n",
      "Epoch:  0006 D loss:-0.3463 G loss:-2.234\n",
      "Epoch:  0006 D loss:-0.3586 G loss:-2.3\n",
      "Epoch:  0006 D loss:-0.4172 G loss:-2.206\n",
      "Epoch:  0006 D loss:-0.3785 G loss:-2.233\n",
      "Epoch:  0006 D loss:-0.4461 G loss:-2.224\n",
      "Epoch:  0006 D loss:-0.4533 G loss:-2.262\n",
      "Epoch:  0006 D loss:-0.3972 G loss:-2.21\n",
      "Epoch:  0006 D loss:-0.4544 G loss:-2.135\n",
      "Epoch:  0006 D loss:-0.3394 G loss:-2.147\n",
      "Epoch:  0006 D loss:-0.4111 G loss:-2.132\n",
      "Epoch:  0006 D loss:-0.3234 G loss:-2.143\n",
      "Epoch:  0006 D loss:-0.3948 G loss:-2.135\n",
      "Epoch:  0006 D loss:-0.469 G loss:-2.154\n",
      "Epoch:  0006 D loss:-0.4243 G loss:-2.079\n",
      "Epoch:  0006 D loss:-0.4662 G loss:-2.121\n",
      "Epoch:  0006 D loss:-0.3763 G loss:-2.097\n",
      "Epoch:  0006 D loss:-0.4079 G loss:-2.036\n",
      "Epoch:  0006 D loss:-0.41 G loss:-2.071\n",
      "Epoch:  0006 D loss:-0.3948 G loss:-2.172\n",
      "Epoch:  0006 D loss:-0.3975 G loss:-2.149\n",
      "Epoch:  0006 D loss:-0.4022 G loss:-2.197\n",
      "Epoch:  0006 D loss:-0.4418 G loss:-2.22\n",
      "Epoch:  0006 D loss:-0.5266 G loss:-2.128\n",
      "Epoch:  0006 D loss:-0.3583 G loss:-2.168\n",
      "Epoch:  0006 D loss:-0.4328 G loss:-2.11\n",
      "Epoch:  0006 D loss:-0.3915 G loss:-2.129\n",
      "Epoch:  0006 D loss:-0.4008 G loss:-2.151\n",
      "Epoch:  0006 D loss:-0.3573 G loss:-2.147\n",
      "Epoch:  0006 D loss:-0.4129 G loss:-2.228\n",
      "Epoch:  0006 D loss:-0.4041 G loss:-2.183\n",
      "Epoch:  0006 D loss:-0.4728 G loss:-2.209\n",
      "Epoch:  0006 D loss:-0.3571 G loss:-2.197\n",
      "Epoch:  0006 D loss:-0.5458 G loss:-2.125\n",
      "Epoch:  0006 D loss:-0.327 G loss:-2.096\n",
      "Epoch:  0006 D loss:-0.4219 G loss:-2.145\n",
      "Epoch:  0006 D loss:-0.3826 G loss:-2.18\n",
      "Epoch:  0006 D loss:-0.3865 G loss:-2.105\n",
      "Epoch:  0006 D loss:-0.3841 G loss:-2.25\n",
      "Epoch:  0006 D loss:-0.4063 G loss:-2.218\n",
      "Epoch:  0006 D loss:-0.3535 G loss:-2.271\n",
      "Epoch:  0006 D loss:-0.4466 G loss:-2.253\n",
      "Epoch:  0006 D loss:-0.4243 G loss:-2.214\n",
      "Epoch:  0006 D loss:-0.4039 G loss:-2.147\n",
      "Epoch:  0006 D loss:-0.3661 G loss:-2.196\n",
      "Epoch:  0006 D loss:-0.4062 G loss:-2.117\n",
      "Epoch:  0006 D loss:-0.3327 G loss:-2.163\n",
      "Epoch:  0006 D loss:-0.4055 G loss:-2.14\n",
      "Epoch:  0006 D loss:-0.4212 G loss:-2.188\n",
      "Epoch:  0006 D loss:-0.3034 G loss:-2.215\n",
      "Epoch:  0006 D loss:-0.3476 G loss:-2.286\n",
      "Epoch:  0006 D loss:-0.4578 G loss:-2.397\n",
      "Epoch:  0006 D loss:-0.3897 G loss:-2.259\n",
      "Epoch:  0006 D loss:-0.4428 G loss:-2.206\n",
      "Epoch:  0006 D loss:-0.3692 G loss:-2.214\n",
      "Epoch:  0006 D loss:-0.442 G loss:-2.315\n",
      "Epoch:  0006 D loss:-0.3125 G loss:-2.284\n",
      "Epoch:  0006 D loss:-0.3779 G loss:-2.2\n",
      "Epoch:  0006 D loss:-0.4207 G loss:-2.196\n",
      "Epoch:  0006 D loss:-0.3121 G loss:-2.268\n",
      "Epoch:  0006 D loss:-0.3438 G loss:-2.209\n",
      "Epoch:  0006 D loss:-0.3716 G loss:-2.143\n",
      "Epoch:  0006 D loss:-0.3278 G loss:-2.191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0006 D loss:-0.4121 G loss:-2.159\n",
      "Epoch:  0006 D loss:-0.3807 G loss:-2.333\n",
      "Epoch:  0006 D loss:-0.4419 G loss:-2.359\n",
      "Epoch:  0006 D loss:-0.3501 G loss:-2.412\n",
      "Epoch:  0006 D loss:-0.3488 G loss:-2.4\n",
      "Epoch:  0006 D loss:-0.3271 G loss:-2.361\n",
      "Epoch:  0006 D loss:-0.3243 G loss:-2.44\n",
      "Epoch:  0006 D loss:-0.4092 G loss:-2.525\n",
      "Epoch:  0006 D loss:-0.3329 G loss:-2.392\n",
      "Epoch:  0006 D loss:-0.2961 G loss:-2.419\n",
      "Epoch:  0006 D loss:-0.3576 G loss:-2.495\n",
      "Epoch:  0006 D loss:-0.2299 G loss:-2.422\n",
      "Epoch:  0006 D loss:-0.312 G loss:-2.466\n",
      "Epoch:  0006 D loss:-0.3174 G loss:-2.424\n",
      "Epoch:  0006 D loss:-0.3608 G loss:-2.458\n",
      "Epoch:  0006 D loss:-0.3484 G loss:-2.448\n",
      "Epoch:  0006 D loss:-0.2729 G loss:-2.414\n",
      "Epoch:  0006 D loss:-0.3373 G loss:-2.386\n",
      "Epoch:  0006 D loss:-0.3731 G loss:-2.369\n",
      "Epoch:  0006 D loss:-0.3318 G loss:-2.439\n",
      "Epoch:  0006 D loss:-0.2707 G loss:-2.421\n",
      "Epoch:  0006 D loss:-0.2815 G loss:-2.376\n",
      "Epoch:  0006 D loss:-0.3727 G loss:-2.339\n",
      "Epoch:  0006 D loss:-0.2382 G loss:-2.533\n",
      "Epoch:  0006 D loss:-0.2763 G loss:-2.456\n",
      "Epoch:  0006 D loss:-0.2714 G loss:-2.507\n",
      "Epoch:  0006 D loss:-0.3399 G loss:-2.5\n",
      "Epoch:  0006 D loss:-0.2593 G loss:-2.389\n",
      "Epoch:  0006 D loss:-0.3595 G loss:-2.589\n",
      "Epoch:  0006 D loss:-0.2349 G loss:-2.526\n",
      "Epoch:  0006 D loss:-0.2455 G loss:-2.539\n",
      "Epoch:  0006 D loss:-0.2846 G loss:-2.513\n",
      "Epoch:  0006 D loss:-0.2475 G loss:-2.578\n",
      "Epoch:  0006 D loss:-0.2614 G loss:-2.575\n",
      "Epoch:  0006 D loss:-0.2895 G loss:-2.64\n",
      "Epoch:  0006 D loss:-0.2537 G loss:-2.605\n",
      "Epoch:  0006 D loss:-0.2562 G loss:-2.556\n",
      "Epoch:  0006 D loss:-0.2498 G loss:-2.553\n",
      "Epoch:  0006 D loss:-0.3347 G loss:-2.484\n",
      "Epoch:  0006 D loss:-0.3615 G loss:-2.532\n",
      "Epoch:  0006 D loss:-0.2615 G loss:-2.434\n",
      "Epoch:  0006 D loss:-0.3056 G loss:-2.409\n",
      "Epoch:  0006 D loss:-0.2944 G loss:-2.482\n",
      "Epoch:  0006 D loss:-0.3488 G loss:-2.394\n",
      "Epoch:  0006 D loss:-0.4918 G loss:-2.376\n",
      "Epoch:  0006 D loss:-0.2652 G loss:-2.345\n",
      "Epoch:  0006 D loss:-0.3231 G loss:-2.249\n",
      "Epoch:  0006 D loss:-0.3211 G loss:-2.231\n",
      "Epoch:  0006 D loss:-0.3136 G loss:-2.258\n",
      "Epoch:  0006 D loss:-0.3452 G loss:-2.318\n",
      "Epoch:  0006 D loss:-0.3467 G loss:-2.294\n",
      "Epoch:  0006 D loss:-0.282 G loss:-2.278\n",
      "Epoch:  0006 D loss:-0.3639 G loss:-2.366\n",
      "Epoch:  0006 D loss:-0.2922 G loss:-2.458\n",
      "Epoch:  0006 D loss:-0.2969 G loss:-2.428\n",
      "Epoch:  0006 D loss:-0.3137 G loss:-2.396\n",
      "Epoch:  0006 D loss:-0.3164 G loss:-2.468\n",
      "Epoch:  0006 D loss:-0.2742 G loss:-2.51\n",
      "Epoch:  0006 D loss:-0.3233 G loss:-2.477\n",
      "Epoch:  0006 D loss:-0.3729 G loss:-2.56\n",
      "Epoch:  0006 D loss:-0.3059 G loss:-2.627\n",
      "Epoch:  0006 D loss:-0.2685 G loss:-2.392\n",
      "Epoch:  0006 D loss:-0.2709 G loss:-2.531\n",
      "Epoch:  0006 D loss:-0.2944 G loss:-2.423\n",
      "Epoch:  0006 D loss:-0.243 G loss:-2.437\n",
      "Epoch:  0006 D loss:-0.3593 G loss:-2.592\n",
      "Epoch:  0006 D loss:-0.2793 G loss:-2.546\n",
      "Epoch:  0006 D loss:-0.2447 G loss:-2.434\n",
      "Epoch:  0006 D loss:-0.3123 G loss:-2.577\n",
      "Epoch:  0006 D loss:-0.3466 G loss:-2.544\n",
      "Epoch:  0006 D loss:-0.2391 G loss:-2.552\n",
      "Epoch:  0006 D loss:-0.349 G loss:-2.589\n",
      "Epoch:  0006 D loss:-0.3001 G loss:-2.433\n",
      "Epoch:  0006 D loss:-0.3305 G loss:-2.373\n",
      "Epoch:  0006 D loss:-0.3137 G loss:-2.407\n",
      "Epoch:  0006 D loss:-0.3565 G loss:-2.296\n",
      "Epoch:  0006 D loss:-0.3357 G loss:-2.332\n",
      "Epoch:  0006 D loss:-0.3104 G loss:-2.36\n",
      "Epoch:  0006 D loss:-0.3031 G loss:-2.341\n",
      "Epoch:  0006 D loss:-0.3449 G loss:-2.356\n",
      "Epoch:  0006 D loss:-0.3436 G loss:-2.197\n",
      "Epoch:  0006 D loss:-0.3349 G loss:-2.281\n",
      "Epoch:  0006 D loss:-0.2992 G loss:-2.259\n",
      "Epoch:  0006 D loss:-0.4139 G loss:-2.193\n",
      "Epoch:  0006 D loss:-0.3307 G loss:-2.304\n",
      "Epoch:  0006 D loss:-0.3078 G loss:-2.286\n",
      "Epoch:  0006 D loss:-0.3268 G loss:-2.279\n",
      "Epoch:  0006 D loss:-0.3419 G loss:-2.393\n",
      "Epoch:  0006 D loss:-0.3926 G loss:-2.317\n",
      "Epoch:  0006 D loss:-0.4033 G loss:-2.504\n",
      "Epoch:  0006 D loss:-0.3243 G loss:-2.537\n",
      "Epoch:  0006 D loss:-0.3849 G loss:-2.405\n",
      "Epoch:  0006 D loss:-0.4473 G loss:-2.38\n",
      "Epoch:  0006 D loss:-0.3456 G loss:-2.383\n",
      "Epoch:  0006 D loss:-0.372 G loss:-2.307\n",
      "Epoch:  0006 D loss:-0.38 G loss:-2.12\n",
      "Epoch:  0006 D loss:-0.4424 G loss:-2.108\n",
      "Epoch:  0006 D loss:-0.3623 G loss:-2.128\n",
      "Epoch:  0006 D loss:-0.3863 G loss:-2.143\n",
      "Epoch:  0006 D loss:-0.3182 G loss:-2.13\n",
      "Epoch:  0006 D loss:-0.4004 G loss:-2.245\n",
      "Epoch:  0006 D loss:-0.3744 G loss:-2.116\n",
      "Epoch:  0006 D loss:-0.3763 G loss:-2.239\n",
      "Epoch:  0006 D loss:-0.3624 G loss:-2.34\n",
      "Epoch:  0006 D loss:-0.2845 G loss:-2.24\n",
      "Epoch:  0006 D loss:-0.354 G loss:-2.369\n",
      "Epoch:  0006 D loss:-0.3941 G loss:-2.37\n",
      "Epoch:  0006 D loss:-0.303 G loss:-2.505\n",
      "Epoch:  0006 D loss:-0.4229 G loss:-2.361\n",
      "Epoch:  0006 D loss:-0.3559 G loss:-2.361\n",
      "Epoch:  0006 D loss:-0.3222 G loss:-2.433\n",
      "Epoch:  0006 D loss:-0.4371 G loss:-2.318\n",
      "Epoch:  0006 D loss:-0.3578 G loss:-2.339\n",
      "Epoch:  0006 D loss:-0.4768 G loss:-2.354\n",
      "Epoch:  0006 D loss:-0.4791 G loss:-2.231\n",
      "Epoch:  0006 D loss:-0.4473 G loss:-2.118\n",
      "Epoch:  0006 D loss:-0.3722 G loss:-2.117\n",
      "Epoch:  0006 D loss:-0.3754 G loss:-2.028\n",
      "Epoch:  0006 D loss:-0.3874 G loss:-2.143\n",
      "Epoch:  0006 D loss:-0.3481 G loss:-2.172\n",
      "Epoch:  0006 D loss:-0.3695 G loss:-2.17\n",
      "Epoch:  0006 D loss:-0.4399 G loss:-2.311\n",
      "Epoch:  0006 D loss:-0.3023 G loss:-2.228\n",
      "Epoch:  0006 D loss:-0.4918 G loss:-2.339\n",
      "Epoch:  0006 D loss:-0.3631 G loss:-2.421\n",
      "Epoch:  0006 D loss:-0.4298 G loss:-2.364\n",
      "Epoch:  0006 D loss:-0.5427 G loss:-2.397\n",
      "Epoch:  0006 D loss:-0.4447 G loss:-2.231\n",
      "Epoch:  0006 D loss:-0.4334 G loss:-2.23\n",
      "Epoch:  0006 D loss:-0.3868 G loss:-2.307\n",
      "Epoch:  0006 D loss:-0.4226 G loss:-2.281\n",
      "Epoch:  0006 D loss:-0.4034 G loss:-2.19\n",
      "Epoch:  0006 D loss:-0.3871 G loss:-2.207\n",
      "Epoch:  0006 D loss:-0.3837 G loss:-2.231\n",
      "Epoch:  0006 D loss:-0.4157 G loss:-2.202\n",
      "Epoch:  0006 D loss:-0.3013 G loss:-2.261\n",
      "Epoch:  0006 D loss:-0.3026 G loss:-2.363\n",
      "Epoch:  0006 D loss:-0.3124 G loss:-2.399\n",
      "Epoch:  0006 D loss:-0.373 G loss:-2.409\n",
      "Epoch:  0006 D loss:-0.3515 G loss:-2.479\n",
      "Epoch:  0006 D loss:-0.4095 G loss:-2.492\n",
      "Epoch:  0006 D loss:-0.3372 G loss:-2.503\n",
      "Epoch:  0006 D loss:-0.3545 G loss:-2.496\n",
      "Epoch:  0006 D loss:-0.3245 G loss:-2.427\n",
      "Epoch:  0006 D loss:-0.2548 G loss:-2.539\n",
      "Epoch:  0006 D loss:-0.3297 G loss:-2.545\n",
      "Epoch:  0006 D loss:-0.2684 G loss:-2.492\n",
      "Epoch:  0006 D loss:-0.2679 G loss:-2.406\n",
      "Epoch:  0006 D loss:-0.2697 G loss:-2.517\n",
      "Epoch:  0006 D loss:-0.3171 G loss:-2.521\n",
      "Epoch:  0006 D loss:-0.3275 G loss:-2.487\n",
      "Epoch:  0006 D loss:-0.2715 G loss:-2.417\n",
      "Epoch:  0006 D loss:-0.3244 G loss:-2.525\n",
      "Epoch:  0006 D loss:-0.3061 G loss:-2.399\n",
      "Epoch:  0006 D loss:-0.396 G loss:-2.421\n",
      "Epoch:  0006 D loss:-0.3157 G loss:-2.387\n",
      "Epoch:  0006 D loss:-0.4506 G loss:-2.353\n",
      "Epoch:  0006 D loss:-0.323 G loss:-2.354\n",
      "Epoch:  0006 D loss:-0.3125 G loss:-2.328\n",
      "Epoch:  0006 D loss:-0.3365 G loss:-2.312\n",
      "Epoch:  0006 D loss:-0.2208 G loss:-2.347\n",
      "Epoch:  0006 D loss:-0.3487 G loss:-2.303\n",
      "Epoch:  0006 D loss:-0.3527 G loss:-2.365\n",
      "Epoch:  0006 D loss:-0.2678 G loss:-2.38\n",
      "Epoch:  0006 D loss:-0.2183 G loss:-2.51\n",
      "Epoch:  0006 D loss:-0.3175 G loss:-2.432\n",
      "Epoch:  0006 D loss:-0.3567 G loss:-2.498\n",
      "Epoch:  0006 D loss:-0.2466 G loss:-2.523\n",
      "Epoch:  0006 D loss:-0.3507 G loss:-2.447\n",
      "Epoch:  0006 D loss:-0.2449 G loss:-2.513\n",
      "Epoch:  0006 D loss:-0.3015 G loss:-2.505\n",
      "Epoch:  0006 D loss:-0.3411 G loss:-2.549\n",
      "Epoch:  0006 D loss:-0.3386 G loss:-2.515\n",
      "Epoch:  0006 D loss:-0.3497 G loss:-2.407\n",
      "Epoch:  0006 D loss:-0.2909 G loss:-2.384\n",
      "Epoch:  0006 D loss:-0.3066 G loss:-2.43\n",
      "Epoch:  0006 D loss:-0.2773 G loss:-2.376\n",
      "Epoch:  0006 D loss:-0.3008 G loss:-2.371\n",
      "Epoch:  0006 D loss:-0.3046 G loss:-2.372\n",
      "Epoch:  0006 D loss:-0.3432 G loss:-2.379\n",
      "Epoch:  0006 D loss:-0.2468 G loss:-2.471\n",
      "Epoch:  0006 D loss:-0.2781 G loss:-2.37\n",
      "Epoch:  0006 D loss:-0.3461 G loss:-2.432\n",
      "Epoch:  0006 D loss:-0.3018 G loss:-2.557\n",
      "Epoch:  0006 D loss:-0.3369 G loss:-2.544\n",
      "Epoch:  0006 D loss:-0.3317 G loss:-2.567\n",
      "Epoch:  0006 D loss:-0.353 G loss:-2.419\n",
      "Epoch:  0006 D loss:-0.3443 G loss:-2.577\n",
      "Epoch:  0006 D loss:-0.2578 G loss:-2.547\n",
      "Epoch:  0006 D loss:-0.3425 G loss:-2.52\n",
      "Epoch:  0006 D loss:-0.2983 G loss:-2.477\n",
      "Epoch:  0006 D loss:-0.3387 G loss:-2.45\n",
      "Epoch:  0006 D loss:-0.3442 G loss:-2.328\n",
      "Epoch:  0006 D loss:-0.2852 G loss:-2.302\n",
      "Epoch:  0006 D loss:-0.3258 G loss:-2.321\n",
      "Epoch:  0006 D loss:-0.3396 G loss:-2.402\n",
      "Epoch:  0006 D loss:-0.272 G loss:-2.53\n",
      "Epoch:  0006 D loss:-0.3324 G loss:-2.427\n",
      "Epoch:  0006 D loss:-0.3005 G loss:-2.595\n",
      "Epoch:  0006 D loss:-0.2895 G loss:-2.511\n",
      "Epoch:  0006 D loss:-0.293 G loss:-2.525\n",
      "Epoch:  0006 D loss:-0.263 G loss:-2.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0006 D loss:-0.2393 G loss:-2.518\n",
      "Epoch:  0006 D loss:-0.2328 G loss:-2.62\n",
      "Epoch:  0006 D loss:-0.2688 G loss:-2.617\n",
      "Epoch:  0006 D loss:-0.2716 G loss:-2.633\n",
      "Epoch:  0006 D loss:-0.2348 G loss:-2.644\n",
      "Epoch:  0006 D loss:-0.2695 G loss:-2.585\n",
      "Epoch:  0006 D loss:-0.2738 G loss:-2.655\n",
      "Epoch:  0006 D loss:-0.2766 G loss:-2.663\n",
      "Epoch:  0006 D loss:-0.2861 G loss:-2.725\n",
      "Epoch:  0006 D loss:-0.2331 G loss:-2.807\n",
      "Epoch:  0006 D loss:-0.2625 G loss:-2.724\n",
      "Epoch:  0006 D loss:-0.2566 G loss:-2.585\n",
      "Epoch:  0006 D loss:-0.302 G loss:-2.646\n",
      "Epoch:  0006 D loss:-0.2559 G loss:-2.584\n",
      "Epoch:  0006 D loss:-0.283 G loss:-2.585\n",
      "Epoch:  0006 D loss:-0.3402 G loss:-2.566\n",
      "Epoch:  0006 D loss:-0.2684 G loss:-2.571\n",
      "Epoch:  0006 D loss:-0.2383 G loss:-2.589\n",
      "Epoch:  0006 D loss:-0.2308 G loss:-2.627\n",
      "Epoch:  0006 D loss:-0.2358 G loss:-2.464\n",
      "Epoch:  0006 D loss:-0.2453 G loss:-2.584\n",
      "Epoch:  0006 D loss:-0.2769 G loss:-2.509\n",
      "Epoch:  0006 D loss:-0.2828 G loss:-2.71\n",
      "Epoch:  0006 D loss:-0.2672 G loss:-2.658\n",
      "Epoch:  0007 D loss:-0.2633 G loss:-2.626\n",
      "Epoch:  0007 D loss:-0.2649 G loss:-2.593\n",
      "Epoch:  0007 D loss:-0.2185 G loss:-2.681\n",
      "Epoch:  0007 D loss:-0.2025 G loss:-2.621\n",
      "Epoch:  0007 D loss:-0.2468 G loss:-2.665\n",
      "Epoch:  0007 D loss:-0.2195 G loss:-2.761\n",
      "Epoch:  0007 D loss:-0.2717 G loss:-2.673\n",
      "Epoch:  0007 D loss:-0.1932 G loss:-2.827\n",
      "Epoch:  0007 D loss:-0.3523 G loss:-2.689\n",
      "Epoch:  0007 D loss:-0.1993 G loss:-2.747\n",
      "Epoch:  0007 D loss:-0.305 G loss:-2.695\n",
      "Epoch:  0007 D loss:-0.3337 G loss:-2.686\n",
      "Epoch:  0007 D loss:-0.2741 G loss:-2.593\n",
      "Epoch:  0007 D loss:-0.2152 G loss:-2.641\n",
      "Epoch:  0007 D loss:-0.2863 G loss:-2.609\n",
      "Epoch:  0007 D loss:-0.1999 G loss:-2.624\n",
      "Epoch:  0007 D loss:-0.2256 G loss:-2.692\n",
      "Epoch:  0007 D loss:-0.2899 G loss:-2.653\n",
      "Epoch:  0007 D loss:-0.3397 G loss:-2.554\n",
      "Epoch:  0007 D loss:-0.2394 G loss:-2.595\n",
      "Epoch:  0007 D loss:-0.2722 G loss:-2.618\n",
      "Epoch:  0007 D loss:-0.2689 G loss:-2.59\n",
      "Epoch:  0007 D loss:-0.1927 G loss:-2.665\n",
      "Epoch:  0007 D loss:-0.2154 G loss:-2.654\n",
      "Epoch:  0007 D loss:-0.2101 G loss:-2.668\n",
      "Epoch:  0007 D loss:-0.2275 G loss:-2.605\n",
      "Epoch:  0007 D loss:-0.2742 G loss:-2.662\n",
      "Epoch:  0007 D loss:-0.2778 G loss:-2.816\n",
      "Epoch:  0007 D loss:-0.2796 G loss:-2.704\n",
      "Epoch:  0007 D loss:-0.2557 G loss:-2.796\n",
      "Epoch:  0007 D loss:-0.2446 G loss:-2.65\n",
      "Epoch:  0007 D loss:-0.2466 G loss:-2.609\n",
      "Epoch:  0007 D loss:-0.3108 G loss:-2.527\n",
      "Epoch:  0007 D loss:-0.2292 G loss:-2.69\n",
      "Epoch:  0007 D loss:-0.3043 G loss:-2.666\n",
      "Epoch:  0007 D loss:-0.2423 G loss:-2.607\n",
      "Epoch:  0007 D loss:-0.2834 G loss:-2.527\n",
      "Epoch:  0007 D loss:-0.3063 G loss:-2.484\n",
      "Epoch:  0007 D loss:-0.2977 G loss:-2.42\n",
      "Epoch:  0007 D loss:-0.2677 G loss:-2.406\n",
      "Epoch:  0007 D loss:-0.2662 G loss:-2.565\n",
      "Epoch:  0007 D loss:-0.3123 G loss:-2.544\n",
      "Epoch:  0007 D loss:-0.211 G loss:-2.583\n",
      "Epoch:  0007 D loss:-0.2766 G loss:-2.498\n",
      "Epoch:  0007 D loss:-0.2412 G loss:-2.561\n",
      "Epoch:  0007 D loss:-0.2513 G loss:-2.507\n",
      "Epoch:  0007 D loss:-0.2478 G loss:-2.691\n",
      "Epoch:  0007 D loss:-0.2315 G loss:-2.679\n",
      "Epoch:  0007 D loss:-0.2221 G loss:-2.798\n",
      "Epoch:  0007 D loss:-0.347 G loss:-2.763\n",
      "Epoch:  0007 D loss:-0.2221 G loss:-2.825\n",
      "Epoch:  0007 D loss:-0.2694 G loss:-2.646\n",
      "Epoch:  0007 D loss:-0.2519 G loss:-2.786\n",
      "Epoch:  0007 D loss:-0.2599 G loss:-2.633\n",
      "Epoch:  0007 D loss:-0.3108 G loss:-2.568\n",
      "Epoch:  0007 D loss:-0.2475 G loss:-2.602\n",
      "Epoch:  0007 D loss:-0.3063 G loss:-2.438\n",
      "Epoch:  0007 D loss:-0.219 G loss:-2.611\n",
      "Epoch:  0007 D loss:-0.2366 G loss:-2.499\n",
      "Epoch:  0007 D loss:-0.2731 G loss:-2.532\n",
      "Epoch:  0007 D loss:-0.3284 G loss:-2.446\n",
      "Epoch:  0007 D loss:-0.2559 G loss:-2.572\n",
      "Epoch:  0007 D loss:-0.2748 G loss:-2.591\n",
      "Epoch:  0007 D loss:-0.3035 G loss:-2.521\n",
      "Epoch:  0007 D loss:-0.2878 G loss:-2.606\n",
      "Epoch:  0007 D loss:-0.2665 G loss:-2.531\n",
      "Epoch:  0007 D loss:-0.3335 G loss:-2.678\n",
      "Epoch:  0007 D loss:-0.3115 G loss:-2.692\n",
      "Epoch:  0007 D loss:-0.2337 G loss:-2.66\n",
      "Epoch:  0007 D loss:-0.2425 G loss:-2.664\n",
      "Epoch:  0007 D loss:-0.245 G loss:-2.691\n",
      "Epoch:  0007 D loss:-0.2682 G loss:-2.705\n",
      "Epoch:  0007 D loss:-0.3172 G loss:-2.648\n",
      "Epoch:  0007 D loss:-0.2634 G loss:-2.605\n",
      "Epoch:  0007 D loss:-0.237 G loss:-2.629\n",
      "Epoch:  0007 D loss:-0.257 G loss:-2.709\n",
      "Epoch:  0007 D loss:-0.2242 G loss:-2.717\n",
      "Epoch:  0007 D loss:-0.3419 G loss:-2.609\n",
      "Epoch:  0007 D loss:-0.2013 G loss:-2.533\n",
      "Epoch:  0007 D loss:-0.2486 G loss:-2.759\n",
      "Epoch:  0007 D loss:-0.3003 G loss:-2.689\n",
      "Epoch:  0007 D loss:-0.2096 G loss:-2.698\n",
      "Epoch:  0007 D loss:-0.2604 G loss:-2.632\n",
      "Epoch:  0007 D loss:-0.2864 G loss:-2.657\n",
      "Epoch:  0007 D loss:-0.3425 G loss:-2.534\n",
      "Epoch:  0007 D loss:-0.3266 G loss:-2.614\n",
      "Epoch:  0007 D loss:-0.3137 G loss:-2.677\n",
      "Epoch:  0007 D loss:-0.3087 G loss:-2.552\n",
      "Epoch:  0007 D loss:-0.2435 G loss:-2.529\n",
      "Epoch:  0007 D loss:-0.2444 G loss:-2.5\n",
      "Epoch:  0007 D loss:-0.2946 G loss:-2.375\n",
      "Epoch:  0007 D loss:-0.2673 G loss:-2.545\n",
      "Epoch:  0007 D loss:-0.2207 G loss:-2.482\n",
      "Epoch:  0007 D loss:-0.2258 G loss:-2.662\n",
      "Epoch:  0007 D loss:-0.2137 G loss:-2.683\n",
      "Epoch:  0007 D loss:-0.343 G loss:-2.72\n",
      "Epoch:  0007 D loss:-0.3117 G loss:-2.614\n",
      "Epoch:  0007 D loss:-0.2891 G loss:-2.576\n",
      "Epoch:  0007 D loss:-0.27 G loss:-2.684\n",
      "Epoch:  0007 D loss:-0.2379 G loss:-2.739\n",
      "Epoch:  0007 D loss:-0.3788 G loss:-2.603\n",
      "Epoch:  0007 D loss:-0.2631 G loss:-2.727\n",
      "Epoch:  0007 D loss:-0.2724 G loss:-2.564\n",
      "Epoch:  0007 D loss:-0.3057 G loss:-2.539\n",
      "Epoch:  0007 D loss:-0.2941 G loss:-2.595\n",
      "Epoch:  0007 D loss:-0.3066 G loss:-2.509\n",
      "Epoch:  0007 D loss:-0.2834 G loss:-2.469\n",
      "Epoch:  0007 D loss:-0.2297 G loss:-2.593\n",
      "Epoch:  0007 D loss:-0.3965 G loss:-2.574\n",
      "Epoch:  0007 D loss:-0.2901 G loss:-2.489\n",
      "Epoch:  0007 D loss:-0.3109 G loss:-2.392\n",
      "Epoch:  0007 D loss:-0.2919 G loss:-2.486\n",
      "Epoch:  0007 D loss:-0.3013 G loss:-2.437\n",
      "Epoch:  0007 D loss:-0.2663 G loss:-2.581\n",
      "Epoch:  0007 D loss:-0.3213 G loss:-2.657\n",
      "Epoch:  0007 D loss:-0.2511 G loss:-2.733\n",
      "Epoch:  0007 D loss:-0.2885 G loss:-2.689\n",
      "Epoch:  0007 D loss:-0.2903 G loss:-2.866\n",
      "Epoch:  0007 D loss:-0.3701 G loss:-2.635\n",
      "Epoch:  0007 D loss:-0.3079 G loss:-2.603\n",
      "Epoch:  0007 D loss:-0.2238 G loss:-2.795\n",
      "Epoch:  0007 D loss:-0.2348 G loss:-2.663\n",
      "Epoch:  0007 D loss:-0.3011 G loss:-2.742\n",
      "Epoch:  0007 D loss:-0.2743 G loss:-2.573\n",
      "Epoch:  0007 D loss:-0.2544 G loss:-2.545\n",
      "Epoch:  0007 D loss:-0.2307 G loss:-2.642\n",
      "Epoch:  0007 D loss:-0.3049 G loss:-2.693\n",
      "Epoch:  0007 D loss:-0.2984 G loss:-2.594\n",
      "Epoch:  0007 D loss:-0.3144 G loss:-2.664\n",
      "Epoch:  0007 D loss:-0.3617 G loss:-2.642\n",
      "Epoch:  0007 D loss:-0.2663 G loss:-2.657\n",
      "Epoch:  0007 D loss:-0.2477 G loss:-2.684\n",
      "Epoch:  0007 D loss:-0.2816 G loss:-2.599\n",
      "Epoch:  0007 D loss:-0.2436 G loss:-2.675\n",
      "Epoch:  0007 D loss:-0.2974 G loss:-2.571\n",
      "Epoch:  0007 D loss:-0.2029 G loss:-2.727\n",
      "Epoch:  0007 D loss:-0.247 G loss:-2.694\n",
      "Epoch:  0007 D loss:-0.2682 G loss:-2.71\n",
      "Epoch:  0007 D loss:-0.3048 G loss:-2.709\n",
      "Epoch:  0007 D loss:-0.2525 G loss:-2.822\n",
      "Epoch:  0007 D loss:-0.22 G loss:-2.695\n",
      "Epoch:  0007 D loss:-0.313 G loss:-2.71\n",
      "Epoch:  0007 D loss:-0.3095 G loss:-2.714\n",
      "Epoch:  0007 D loss:-0.3064 G loss:-2.637\n",
      "Epoch:  0007 D loss:-0.2577 G loss:-2.605\n",
      "Epoch:  0007 D loss:-0.279 G loss:-2.66\n",
      "Epoch:  0007 D loss:-0.29 G loss:-2.586\n",
      "Epoch:  0007 D loss:-0.2378 G loss:-2.542\n",
      "Epoch:  0007 D loss:-0.2234 G loss:-2.664\n",
      "Epoch:  0007 D loss:-0.2399 G loss:-2.538\n",
      "Epoch:  0007 D loss:-0.2913 G loss:-2.601\n",
      "Epoch:  0007 D loss:-0.2589 G loss:-2.622\n",
      "Epoch:  0007 D loss:-0.2552 G loss:-2.827\n",
      "Epoch:  0007 D loss:-0.3004 G loss:-2.636\n",
      "Epoch:  0007 D loss:-0.2856 G loss:-2.677\n",
      "Epoch:  0007 D loss:-0.3399 G loss:-2.708\n",
      "Epoch:  0007 D loss:-0.2725 G loss:-2.6\n",
      "Epoch:  0007 D loss:-0.3324 G loss:-2.525\n",
      "Epoch:  0007 D loss:-0.2784 G loss:-2.563\n",
      "Epoch:  0007 D loss:-0.2579 G loss:-2.672\n",
      "Epoch:  0007 D loss:-0.3157 G loss:-2.559\n",
      "Epoch:  0007 D loss:-0.3223 G loss:-2.665\n",
      "Epoch:  0007 D loss:-0.2633 G loss:-2.568\n",
      "Epoch:  0007 D loss:-0.2347 G loss:-2.544\n",
      "Epoch:  0007 D loss:-0.2842 G loss:-2.496\n",
      "Epoch:  0007 D loss:-0.3015 G loss:-2.475\n",
      "Epoch:  0007 D loss:-0.299 G loss:-2.637\n",
      "Epoch:  0007 D loss:-0.2799 G loss:-2.512\n",
      "Epoch:  0007 D loss:-0.2431 G loss:-2.649\n",
      "Epoch:  0007 D loss:-0.2311 G loss:-2.68\n",
      "Epoch:  0007 D loss:-0.3059 G loss:-2.69\n",
      "Epoch:  0007 D loss:-0.2586 G loss:-2.603\n",
      "Epoch:  0007 D loss:-0.2582 G loss:-2.576\n",
      "Epoch:  0007 D loss:-0.2519 G loss:-2.68\n",
      "Epoch:  0007 D loss:-0.2794 G loss:-2.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0007 D loss:-0.243 G loss:-2.674\n",
      "Epoch:  0007 D loss:-0.2204 G loss:-2.764\n",
      "Epoch:  0007 D loss:-0.285 G loss:-2.903\n",
      "Epoch:  0007 D loss:-0.2821 G loss:-2.863\n",
      "Epoch:  0007 D loss:-0.1912 G loss:-2.893\n",
      "Epoch:  0007 D loss:-0.2115 G loss:-3.093\n",
      "Epoch:  0007 D loss:-0.2791 G loss:-2.854\n",
      "Epoch:  0007 D loss:-0.1943 G loss:-2.853\n",
      "Epoch:  0007 D loss:-0.2445 G loss:-2.85\n",
      "Epoch:  0007 D loss:-0.269 G loss:-2.796\n",
      "Epoch:  0007 D loss:-0.2469 G loss:-2.848\n",
      "Epoch:  0007 D loss:-0.2271 G loss:-2.85\n",
      "Epoch:  0007 D loss:-0.1796 G loss:-2.876\n",
      "Epoch:  0007 D loss:-0.2431 G loss:-2.835\n",
      "Epoch:  0007 D loss:-0.2211 G loss:-2.812\n",
      "Epoch:  0007 D loss:-0.2248 G loss:-2.894\n",
      "Epoch:  0007 D loss:-0.1665 G loss:-3.052\n",
      "Epoch:  0007 D loss:-0.2753 G loss:-2.819\n",
      "Epoch:  0007 D loss:-0.274 G loss:-2.968\n",
      "Epoch:  0007 D loss:-0.1647 G loss:-2.998\n",
      "Epoch:  0007 D loss:-0.2022 G loss:-2.995\n",
      "Epoch:  0007 D loss:-0.2194 G loss:-2.964\n",
      "Epoch:  0007 D loss:-0.2037 G loss:-3.006\n",
      "Epoch:  0007 D loss:-0.2161 G loss:-3.002\n",
      "Epoch:  0007 D loss:-0.2134 G loss:-3.021\n",
      "Epoch:  0007 D loss:-0.2358 G loss:-3.027\n",
      "Epoch:  0007 D loss:-0.262 G loss:-3.06\n",
      "Epoch:  0007 D loss:-0.2402 G loss:-2.971\n",
      "Epoch:  0007 D loss:-0.2117 G loss:-3.011\n",
      "Epoch:  0007 D loss:-0.1728 G loss:-2.817\n",
      "Epoch:  0007 D loss:-0.2792 G loss:-2.774\n",
      "Epoch:  0007 D loss:-0.2206 G loss:-2.785\n",
      "Epoch:  0007 D loss:-0.1903 G loss:-2.909\n",
      "Epoch:  0007 D loss:-0.2317 G loss:-2.943\n",
      "Epoch:  0007 D loss:-0.1733 G loss:-2.86\n",
      "Epoch:  0007 D loss:-0.2266 G loss:-2.93\n",
      "Epoch:  0007 D loss:-0.2543 G loss:-2.926\n",
      "Epoch:  0007 D loss:-0.1946 G loss:-2.936\n",
      "Epoch:  0007 D loss:-0.2719 G loss:-2.815\n",
      "Epoch:  0007 D loss:-0.2533 G loss:-2.795\n",
      "Epoch:  0007 D loss:-0.2189 G loss:-2.813\n",
      "Epoch:  0007 D loss:-0.1807 G loss:-2.739\n",
      "Epoch:  0007 D loss:-0.2396 G loss:-2.89\n",
      "Epoch:  0007 D loss:-0.2065 G loss:-2.856\n",
      "Epoch:  0007 D loss:-0.2048 G loss:-2.939\n",
      "Epoch:  0007 D loss:-0.2467 G loss:-2.905\n",
      "Epoch:  0007 D loss:-0.2448 G loss:-2.893\n",
      "Epoch:  0007 D loss:-0.2458 G loss:-2.895\n",
      "Epoch:  0007 D loss:-0.2125 G loss:-2.776\n",
      "Epoch:  0007 D loss:-0.1894 G loss:-2.841\n",
      "Epoch:  0007 D loss:-0.1934 G loss:-3.03\n",
      "Epoch:  0007 D loss:-0.218 G loss:-2.952\n",
      "Epoch:  0007 D loss:-0.1992 G loss:-2.991\n",
      "Epoch:  0007 D loss:-0.243 G loss:-2.897\n",
      "Epoch:  0007 D loss:-0.2112 G loss:-2.915\n",
      "Epoch:  0007 D loss:-0.3532 G loss:-2.878\n",
      "Epoch:  0007 D loss:-0.4414 G loss:-2.649\n",
      "Epoch:  0007 D loss:-0.2497 G loss:-2.518\n",
      "Epoch:  0007 D loss:-0.2907 G loss:-2.523\n",
      "Epoch:  0007 D loss:-0.2025 G loss:-2.629\n",
      "Epoch:  0007 D loss:-0.2913 G loss:-2.542\n",
      "Epoch:  0007 D loss:-0.2528 G loss:-2.64\n",
      "Epoch:  0007 D loss:-0.2735 G loss:-2.549\n",
      "Epoch:  0007 D loss:-0.2638 G loss:-2.738\n",
      "Epoch:  0007 D loss:-0.3515 G loss:-2.777\n",
      "Epoch:  0007 D loss:-0.2592 G loss:-2.747\n",
      "Epoch:  0007 D loss:-0.27 G loss:-2.955\n",
      "Epoch:  0007 D loss:-0.2485 G loss:-2.931\n",
      "Epoch:  0007 D loss:-0.237 G loss:-2.763\n",
      "Epoch:  0007 D loss:-0.2236 G loss:-2.786\n",
      "Epoch:  0007 D loss:-0.2102 G loss:-2.822\n",
      "Epoch:  0007 D loss:-0.3731 G loss:-2.76\n",
      "Epoch:  0007 D loss:-0.3226 G loss:-2.662\n",
      "Epoch:  0007 D loss:-0.2428 G loss:-2.733\n",
      "Epoch:  0007 D loss:-0.2505 G loss:-2.764\n",
      "Epoch:  0007 D loss:-0.3045 G loss:-2.619\n",
      "Epoch:  0007 D loss:-0.2284 G loss:-2.744\n",
      "Epoch:  0007 D loss:-0.2737 G loss:-2.67\n",
      "Epoch:  0007 D loss:-0.2312 G loss:-2.616\n",
      "Epoch:  0007 D loss:-0.2361 G loss:-2.542\n",
      "Epoch:  0007 D loss:-0.2374 G loss:-2.716\n",
      "Epoch:  0007 D loss:-0.2153 G loss:-2.751\n",
      "Epoch:  0007 D loss:-0.1847 G loss:-2.809\n",
      "Epoch:  0007 D loss:-0.4099 G loss:-2.813\n",
      "Epoch:  0007 D loss:-0.3213 G loss:-2.925\n",
      "Epoch:  0007 D loss:-0.2765 G loss:-2.81\n",
      "Epoch:  0007 D loss:-0.1936 G loss:-2.819\n",
      "Epoch:  0007 D loss:-0.276 G loss:-2.713\n",
      "Epoch:  0007 D loss:-0.1929 G loss:-2.701\n",
      "Epoch:  0007 D loss:-0.1562 G loss:-2.774\n",
      "Epoch:  0007 D loss:-0.2299 G loss:-2.628\n",
      "Epoch:  0007 D loss:-0.2804 G loss:-2.639\n",
      "Epoch:  0007 D loss:-0.2563 G loss:-2.816\n",
      "Epoch:  0007 D loss:-0.2318 G loss:-2.699\n",
      "Epoch:  0007 D loss:-0.2375 G loss:-2.704\n",
      "Epoch:  0007 D loss:-0.2561 G loss:-2.751\n",
      "Epoch:  0007 D loss:-0.2283 G loss:-2.723\n",
      "Epoch:  0007 D loss:-0.2473 G loss:-2.794\n",
      "Epoch:  0007 D loss:-0.2231 G loss:-2.811\n",
      "Epoch:  0007 D loss:-0.1861 G loss:-2.839\n",
      "Epoch:  0007 D loss:-0.2696 G loss:-2.824\n",
      "Epoch:  0007 D loss:-0.2127 G loss:-2.827\n",
      "Epoch:  0007 D loss:-0.2185 G loss:-2.812\n",
      "Epoch:  0007 D loss:-0.2083 G loss:-2.813\n",
      "Epoch:  0007 D loss:-0.1911 G loss:-2.806\n",
      "Epoch:  0007 D loss:-0.2632 G loss:-2.834\n",
      "Epoch:  0007 D loss:-0.1808 G loss:-2.796\n",
      "Epoch:  0007 D loss:-0.2099 G loss:-2.798\n",
      "Epoch:  0007 D loss:-0.2548 G loss:-2.812\n",
      "Epoch:  0007 D loss:-0.1929 G loss:-2.77\n",
      "Epoch:  0007 D loss:-0.2365 G loss:-2.76\n",
      "Epoch:  0007 D loss:-0.2493 G loss:-2.86\n",
      "Epoch:  0007 D loss:-0.2761 G loss:-2.757\n",
      "Epoch:  0007 D loss:-0.2733 G loss:-2.761\n",
      "Epoch:  0007 D loss:-0.2755 G loss:-2.651\n",
      "Epoch:  0007 D loss:-0.2059 G loss:-2.756\n",
      "Epoch:  0007 D loss:-0.2602 G loss:-2.658\n",
      "Epoch:  0007 D loss:-0.2513 G loss:-2.682\n",
      "Epoch:  0007 D loss:-0.2246 G loss:-2.597\n",
      "Epoch:  0007 D loss:-0.3053 G loss:-2.628\n",
      "Epoch:  0007 D loss:-0.3026 G loss:-2.727\n",
      "Epoch:  0007 D loss:-0.2331 G loss:-2.749\n",
      "Epoch:  0007 D loss:-0.2477 G loss:-2.754\n",
      "Epoch:  0007 D loss:-0.2374 G loss:-2.707\n",
      "Epoch:  0007 D loss:-0.2291 G loss:-2.734\n",
      "Epoch:  0007 D loss:-0.2619 G loss:-2.764\n",
      "Epoch:  0007 D loss:-0.1852 G loss:-2.79\n",
      "Epoch:  0007 D loss:-0.2679 G loss:-2.812\n",
      "Epoch:  0007 D loss:-0.2066 G loss:-2.881\n",
      "Epoch:  0007 D loss:-0.2348 G loss:-2.888\n",
      "Epoch:  0007 D loss:-0.3336 G loss:-2.905\n",
      "Epoch:  0007 D loss:-0.3255 G loss:-2.761\n",
      "Epoch:  0007 D loss:-0.2128 G loss:-2.937\n",
      "Epoch:  0007 D loss:-0.2468 G loss:-2.888\n",
      "Epoch:  0007 D loss:-0.2437 G loss:-2.824\n",
      "Epoch:  0007 D loss:-0.2615 G loss:-2.888\n",
      "Epoch:  0007 D loss:-0.2239 G loss:-2.726\n",
      "Epoch:  0007 D loss:-0.2895 G loss:-2.743\n",
      "Epoch:  0007 D loss:-0.2091 G loss:-2.827\n",
      "Epoch:  0007 D loss:-0.3095 G loss:-2.674\n",
      "Epoch:  0007 D loss:-0.2685 G loss:-2.53\n",
      "Epoch:  0007 D loss:-0.2426 G loss:-2.534\n",
      "Epoch:  0007 D loss:-0.271 G loss:-2.561\n",
      "Epoch:  0007 D loss:-0.2145 G loss:-2.612\n",
      "Epoch:  0007 D loss:-0.2173 G loss:-2.737\n",
      "Epoch:  0007 D loss:-0.2568 G loss:-2.643\n",
      "Epoch:  0007 D loss:-0.2422 G loss:-2.727\n",
      "Epoch:  0007 D loss:-0.1907 G loss:-2.733\n",
      "Epoch:  0007 D loss:-0.2685 G loss:-2.886\n",
      "Epoch:  0007 D loss:-0.2496 G loss:-2.785\n",
      "Epoch:  0007 D loss:-0.2959 G loss:-2.755\n",
      "Epoch:  0007 D loss:-0.2738 G loss:-2.877\n",
      "Epoch:  0007 D loss:-0.2334 G loss:-2.859\n",
      "Epoch:  0007 D loss:-0.2368 G loss:-2.669\n",
      "Epoch:  0007 D loss:-0.234 G loss:-2.666\n",
      "Epoch:  0007 D loss:-0.2647 G loss:-2.745\n",
      "Epoch:  0007 D loss:-0.2581 G loss:-2.612\n",
      "Epoch:  0007 D loss:-0.3154 G loss:-2.59\n",
      "Epoch:  0007 D loss:-0.3172 G loss:-2.647\n",
      "Epoch:  0007 D loss:-0.2662 G loss:-2.459\n",
      "Epoch:  0007 D loss:-0.2774 G loss:-2.528\n",
      "Epoch:  0007 D loss:-0.2408 G loss:-2.475\n",
      "Epoch:  0007 D loss:-0.2501 G loss:-2.639\n",
      "Epoch:  0007 D loss:-0.2493 G loss:-2.489\n",
      "Epoch:  0007 D loss:-0.2693 G loss:-2.558\n",
      "Epoch:  0007 D loss:-0.2636 G loss:-2.618\n",
      "Epoch:  0007 D loss:-0.2159 G loss:-2.784\n",
      "Epoch:  0007 D loss:-0.3557 G loss:-2.669\n",
      "Epoch:  0007 D loss:-0.2914 G loss:-2.601\n",
      "Epoch:  0007 D loss:-0.36 G loss:-2.535\n",
      "Epoch:  0007 D loss:-0.3701 G loss:-2.521\n",
      "Epoch:  0007 D loss:-0.274 G loss:-2.48\n",
      "Epoch:  0007 D loss:-0.3393 G loss:-2.585\n",
      "Epoch:  0007 D loss:-0.2573 G loss:-2.507\n",
      "Epoch:  0007 D loss:-0.342 G loss:-2.406\n",
      "Epoch:  0007 D loss:-0.3248 G loss:-2.491\n",
      "Epoch:  0007 D loss:-0.245 G loss:-2.531\n",
      "Epoch:  0007 D loss:-0.2984 G loss:-2.467\n",
      "Epoch:  0007 D loss:-0.3166 G loss:-2.494\n",
      "Epoch:  0007 D loss:-0.2767 G loss:-2.542\n",
      "Epoch:  0007 D loss:-0.2595 G loss:-2.713\n",
      "Epoch:  0007 D loss:-0.2616 G loss:-2.631\n",
      "Epoch:  0007 D loss:-0.2961 G loss:-2.742\n",
      "Epoch:  0007 D loss:-0.2536 G loss:-2.759\n",
      "Epoch:  0007 D loss:-0.2542 G loss:-2.682\n",
      "Epoch:  0007 D loss:-0.308 G loss:-2.663\n",
      "Epoch:  0007 D loss:-0.2532 G loss:-2.673\n",
      "Epoch:  0007 D loss:-0.2878 G loss:-2.714\n",
      "Epoch:  0007 D loss:-0.2108 G loss:-2.74\n",
      "Epoch:  0007 D loss:-0.2835 G loss:-2.658\n",
      "Epoch:  0007 D loss:-0.2708 G loss:-2.81\n",
      "Epoch:  0007 D loss:-0.3012 G loss:-2.617\n",
      "Epoch:  0007 D loss:-0.247 G loss:-2.736\n",
      "Epoch:  0007 D loss:-0.2873 G loss:-2.639\n",
      "Epoch:  0007 D loss:-0.3753 G loss:-2.733\n",
      "Epoch:  0007 D loss:-0.3292 G loss:-2.715\n",
      "Epoch:  0007 D loss:-0.2504 G loss:-2.66\n",
      "Epoch:  0007 D loss:-0.228 G loss:-2.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0007 D loss:-0.2492 G loss:-2.626\n",
      "Epoch:  0007 D loss:-0.2819 G loss:-2.75\n",
      "Epoch:  0007 D loss:-0.2349 G loss:-2.661\n",
      "Epoch:  0007 D loss:-0.2187 G loss:-2.83\n",
      "Epoch:  0007 D loss:-0.2175 G loss:-2.804\n",
      "Epoch:  0007 D loss:-0.2773 G loss:-2.663\n",
      "Epoch:  0007 D loss:-0.2959 G loss:-2.717\n",
      "Epoch:  0007 D loss:-0.3088 G loss:-2.671\n",
      "Epoch:  0007 D loss:-0.236 G loss:-2.609\n",
      "Epoch:  0007 D loss:-0.2655 G loss:-2.631\n",
      "Epoch:  0007 D loss:-0.2917 G loss:-2.707\n",
      "Epoch:  0007 D loss:-0.2242 G loss:-2.787\n",
      "Epoch:  0007 D loss:-0.3259 G loss:-2.705\n",
      "Epoch:  0007 D loss:-0.2455 G loss:-2.662\n",
      "Epoch:  0007 D loss:-0.2884 G loss:-2.695\n",
      "Epoch:  0007 D loss:-0.2925 G loss:-2.599\n",
      "Epoch:  0007 D loss:-0.2274 G loss:-2.72\n",
      "Epoch:  0007 D loss:-0.2901 G loss:-2.674\n",
      "Epoch:  0007 D loss:-0.2466 G loss:-2.819\n",
      "Epoch:  0007 D loss:-0.2624 G loss:-2.774\n",
      "Epoch:  0007 D loss:-0.2806 G loss:-2.691\n",
      "Epoch:  0007 D loss:-0.2658 G loss:-2.711\n",
      "Epoch:  0007 D loss:-0.2421 G loss:-2.745\n",
      "Epoch:  0007 D loss:-0.2821 G loss:-2.811\n",
      "Epoch:  0007 D loss:-0.3011 G loss:-2.726\n",
      "Epoch:  0007 D loss:-0.3576 G loss:-2.815\n",
      "Epoch:  0007 D loss:-0.323 G loss:-2.563\n",
      "Epoch:  0007 D loss:-0.2506 G loss:-2.525\n",
      "Epoch:  0007 D loss:-0.2994 G loss:-2.548\n",
      "Epoch:  0007 D loss:-0.3062 G loss:-2.545\n",
      "Epoch:  0007 D loss:-0.281 G loss:-2.665\n",
      "Epoch:  0007 D loss:-0.2638 G loss:-2.745\n",
      "Epoch:  0007 D loss:-0.2715 G loss:-2.623\n",
      "Epoch:  0007 D loss:-0.3461 G loss:-2.659\n",
      "Epoch:  0007 D loss:-0.3517 G loss:-2.674\n",
      "Epoch:  0007 D loss:-0.332 G loss:-2.744\n",
      "Epoch:  0007 D loss:-0.3561 G loss:-2.667\n",
      "Epoch:  0007 D loss:-0.321 G loss:-2.788\n",
      "Epoch:  0007 D loss:-0.2855 G loss:-2.815\n",
      "Epoch:  0007 D loss:-0.3547 G loss:-2.662\n",
      "Epoch:  0007 D loss:-0.3263 G loss:-2.664\n",
      "Epoch:  0007 D loss:-0.2719 G loss:-2.623\n",
      "Epoch:  0007 D loss:-0.2613 G loss:-2.646\n",
      "Epoch:  0007 D loss:-0.385 G loss:-2.554\n",
      "Epoch:  0007 D loss:-0.2568 G loss:-2.71\n",
      "Epoch:  0007 D loss:-0.296 G loss:-2.58\n",
      "Epoch:  0007 D loss:-0.2784 G loss:-2.53\n",
      "Epoch:  0007 D loss:-0.2081 G loss:-2.72\n",
      "Epoch:  0007 D loss:-0.251 G loss:-2.769\n",
      "Epoch:  0007 D loss:-0.2471 G loss:-2.844\n",
      "Epoch:  0007 D loss:-0.2322 G loss:-2.799\n",
      "Epoch:  0007 D loss:-0.2741 G loss:-2.906\n",
      "Epoch:  0007 D loss:-0.2159 G loss:-2.816\n",
      "Epoch:  0007 D loss:-0.3083 G loss:-2.903\n",
      "Epoch:  0007 D loss:-0.1959 G loss:-2.945\n",
      "Epoch:  0007 D loss:-0.2047 G loss:-2.972\n",
      "Epoch:  0007 D loss:-0.217 G loss:-3.023\n",
      "Epoch:  0007 D loss:-0.2702 G loss:-2.856\n",
      "Epoch:  0007 D loss:-0.2528 G loss:-2.697\n",
      "Epoch:  0007 D loss:-0.2238 G loss:-2.716\n",
      "Epoch:  0007 D loss:-0.2198 G loss:-2.887\n",
      "Epoch:  0007 D loss:-0.1936 G loss:-2.787\n",
      "Epoch:  0007 D loss:-0.1851 G loss:-2.884\n",
      "Epoch:  0007 D loss:-0.2399 G loss:-2.677\n",
      "Epoch:  0007 D loss:-0.251 G loss:-2.691\n",
      "Epoch:  0007 D loss:-0.208 G loss:-2.797\n",
      "Epoch:  0007 D loss:-0.2534 G loss:-2.817\n",
      "Epoch:  0007 D loss:-0.1716 G loss:-2.898\n",
      "Epoch:  0007 D loss:-0.2007 G loss:-2.898\n",
      "Epoch:  0007 D loss:-0.2313 G loss:-2.824\n",
      "Epoch:  0007 D loss:-0.2084 G loss:-2.853\n",
      "Epoch:  0007 D loss:-0.1858 G loss:-3.009\n",
      "Epoch:  0007 D loss:-0.2108 G loss:-3.089\n",
      "Epoch:  0007 D loss:-0.2885 G loss:-3.075\n",
      "Epoch:  0007 D loss:-0.2031 G loss:-3.087\n",
      "Epoch:  0007 D loss:-0.1845 G loss:-2.977\n",
      "Epoch:  0007 D loss:-0.1818 G loss:-3.112\n",
      "Epoch:  0007 D loss:-0.209 G loss:-2.916\n",
      "Epoch:  0007 D loss:-0.2094 G loss:-2.815\n",
      "Epoch:  0007 D loss:-0.2122 G loss:-2.882\n",
      "Epoch:  0007 D loss:-0.2059 G loss:-2.791\n",
      "Epoch:  0007 D loss:-0.193 G loss:-2.901\n",
      "Epoch:  0007 D loss:-0.2048 G loss:-2.797\n",
      "Epoch:  0007 D loss:-0.221 G loss:-2.808\n",
      "Epoch:  0007 D loss:-0.2074 G loss:-2.865\n",
      "Epoch:  0007 D loss:-0.1738 G loss:-2.988\n",
      "Epoch:  0007 D loss:-0.2056 G loss:-2.907\n",
      "Epoch:  0007 D loss:-0.1639 G loss:-2.911\n",
      "Epoch:  0007 D loss:-0.1575 G loss:-3.056\n",
      "Epoch:  0007 D loss:-0.2093 G loss:-3.055\n",
      "Epoch:  0007 D loss:-0.2448 G loss:-3.078\n",
      "Epoch:  0007 D loss:-0.1953 G loss:-3.07\n",
      "Epoch:  0007 D loss:-0.2149 G loss:-3.039\n",
      "Epoch:  0007 D loss:-0.2235 G loss:-2.972\n",
      "Epoch:  0007 D loss:-0.2588 G loss:-2.885\n",
      "Epoch:  0007 D loss:-0.2182 G loss:-2.875\n",
      "Epoch:  0007 D loss:-0.2935 G loss:-2.674\n",
      "Epoch:  0007 D loss:-0.2707 G loss:-2.649\n",
      "Epoch:  0007 D loss:-0.2222 G loss:-2.472\n",
      "Epoch:  0007 D loss:-0.2582 G loss:-2.66\n",
      "Epoch:  0007 D loss:-0.2898 G loss:-2.7\n",
      "Epoch:  0007 D loss:-0.2201 G loss:-2.663\n",
      "Epoch:  0007 D loss:-0.2468 G loss:-2.703\n",
      "Epoch:  0007 D loss:-0.2517 G loss:-2.915\n",
      "Epoch:  0007 D loss:-0.2061 G loss:-2.799\n",
      "Epoch:  0007 D loss:-0.2319 G loss:-2.883\n",
      "Epoch:  0007 D loss:-0.2822 G loss:-2.826\n",
      "Epoch:  0007 D loss:-0.2547 G loss:-2.88\n",
      "Epoch:  0007 D loss:-0.2835 G loss:-2.747\n",
      "Epoch:  0007 D loss:-0.2682 G loss:-2.802\n",
      "Epoch:  0007 D loss:-0.2187 G loss:-2.84\n",
      "Epoch:  0007 D loss:-0.2252 G loss:-2.808\n",
      "Epoch:  0007 D loss:-0.2502 G loss:-2.686\n",
      "Epoch:  0007 D loss:-0.2523 G loss:-2.787\n",
      "Epoch:  0007 D loss:-0.3184 G loss:-2.691\n",
      "Epoch:  0007 D loss:-0.1887 G loss:-2.704\n",
      "Epoch:  0007 D loss:-0.2115 G loss:-2.739\n",
      "Epoch:  0007 D loss:-0.2307 G loss:-2.732\n",
      "Epoch:  0007 D loss:-0.3317 G loss:-2.758\n",
      "Epoch:  0007 D loss:-0.2614 G loss:-2.656\n",
      "Epoch:  0007 D loss:-0.2877 G loss:-2.767\n",
      "Epoch:  0007 D loss:-0.2875 G loss:-2.765\n",
      "Epoch:  0007 D loss:-0.2009 G loss:-2.682\n",
      "Epoch:  0007 D loss:-0.2297 G loss:-2.721\n",
      "Epoch:  0007 D loss:-0.2785 G loss:-2.708\n",
      "Epoch:  0007 D loss:-0.2081 G loss:-2.793\n",
      "Epoch:  0007 D loss:-0.2387 G loss:-2.756\n",
      "Epoch:  0007 D loss:-0.2904 G loss:-2.791\n",
      "Epoch:  0007 D loss:-0.2653 G loss:-2.825\n",
      "Epoch:  0007 D loss:-0.3198 G loss:-2.726\n",
      "Epoch:  0007 D loss:-0.2523 G loss:-2.813\n",
      "Epoch:  0007 D loss:-0.2654 G loss:-2.741\n",
      "Epoch:  0007 D loss:-0.3071 G loss:-2.695\n",
      "Epoch:  0007 D loss:-0.3029 G loss:-2.613\n",
      "Epoch:  0007 D loss:-0.2913 G loss:-2.699\n",
      "Epoch:  0007 D loss:-0.2917 G loss:-2.669\n",
      "Epoch:  0007 D loss:-0.2804 G loss:-2.551\n",
      "Epoch:  0007 D loss:-0.2867 G loss:-2.645\n",
      "Epoch:  0007 D loss:-0.3115 G loss:-2.7\n",
      "Epoch:  0007 D loss:-0.2874 G loss:-2.572\n",
      "Epoch:  0007 D loss:-0.3101 G loss:-2.592\n",
      "Epoch:  0007 D loss:-0.329 G loss:-2.55\n",
      "Epoch:  0007 D loss:-0.2569 G loss:-2.656\n",
      "Epoch:  0007 D loss:-0.349 G loss:-2.524\n",
      "Epoch:  0007 D loss:-0.3164 G loss:-2.583\n",
      "Epoch:  0007 D loss:-0.2989 G loss:-2.614\n",
      "Epoch:  0007 D loss:-0.2926 G loss:-2.657\n",
      "Epoch:  0007 D loss:-0.3382 G loss:-2.638\n",
      "Epoch:  0007 D loss:-0.3428 G loss:-2.618\n",
      "Epoch:  0007 D loss:-0.3249 G loss:-2.521\n",
      "Epoch:  0007 D loss:-0.4704 G loss:-2.594\n",
      "Epoch:  0007 D loss:-0.3481 G loss:-2.36\n",
      "Epoch:  0007 D loss:-0.2921 G loss:-2.432\n",
      "Epoch:  0007 D loss:-0.3344 G loss:-2.409\n",
      "Epoch:  0007 D loss:-0.3763 G loss:-2.511\n",
      "Epoch:  0007 D loss:-0.4494 G loss:-2.505\n",
      "Epoch:  0007 D loss:-0.3984 G loss:-2.475\n",
      "Epoch:  0007 D loss:-0.2932 G loss:-2.429\n",
      "Epoch:  0007 D loss:-0.3143 G loss:-2.436\n",
      "Epoch:  0007 D loss:-0.3234 G loss:-2.472\n",
      "Epoch:  0007 D loss:-0.3238 G loss:-2.495\n",
      "Epoch:  0007 D loss:-0.3693 G loss:-2.594\n",
      "Epoch:  0007 D loss:-0.3339 G loss:-2.652\n",
      "Epoch:  0007 D loss:-0.4514 G loss:-2.638\n",
      "Epoch:  0007 D loss:-0.3488 G loss:-2.556\n",
      "Epoch:  0007 D loss:-0.3893 G loss:-2.551\n",
      "Epoch:  0007 D loss:-0.3468 G loss:-2.444\n",
      "Epoch:  0007 D loss:-0.3059 G loss:-2.524\n",
      "Epoch:  0007 D loss:-0.3177 G loss:-2.428\n",
      "Epoch:  0007 D loss:-0.3522 G loss:-2.457\n",
      "Epoch:  0007 D loss:-0.3591 G loss:-2.437\n",
      "Epoch:  0007 D loss:-0.4051 G loss:-2.358\n",
      "Epoch:  0007 D loss:-0.3464 G loss:-2.44\n",
      "Epoch:  0007 D loss:-0.3704 G loss:-2.4\n",
      "Epoch:  0007 D loss:-0.3879 G loss:-2.521\n",
      "Epoch:  0007 D loss:-0.3173 G loss:-2.45\n",
      "Epoch:  0007 D loss:-0.293 G loss:-2.562\n",
      "Epoch:  0008 D loss:-0.337 G loss:-2.597\n",
      "Epoch:  0008 D loss:-0.3778 G loss:-2.63\n",
      "Epoch:  0008 D loss:-0.3977 G loss:-2.616\n",
      "Epoch:  0008 D loss:-0.4318 G loss:-2.7\n",
      "Epoch:  0008 D loss:-0.2757 G loss:-2.639\n",
      "Epoch:  0008 D loss:-0.3497 G loss:-2.594\n",
      "Epoch:  0008 D loss:-0.4323 G loss:-2.722\n",
      "Epoch:  0008 D loss:-0.365 G loss:-2.454\n",
      "Epoch:  0008 D loss:-0.4147 G loss:-2.495\n",
      "Epoch:  0008 D loss:-0.4726 G loss:-2.285\n",
      "Epoch:  0008 D loss:-0.4508 G loss:-2.296\n",
      "Epoch:  0008 D loss:-0.3387 G loss:-2.232\n",
      "Epoch:  0008 D loss:-0.3296 G loss:-2.231\n",
      "Epoch:  0008 D loss:-0.3839 G loss:-2.327\n",
      "Epoch:  0008 D loss:-0.4065 G loss:-2.411\n",
      "Epoch:  0008 D loss:-0.3232 G loss:-2.448\n",
      "Epoch:  0008 D loss:-0.2878 G loss:-2.604\n",
      "Epoch:  0008 D loss:-0.3184 G loss:-2.57\n",
      "Epoch:  0008 D loss:-0.4039 G loss:-2.604\n",
      "Epoch:  0008 D loss:-0.3236 G loss:-2.74\n",
      "Epoch:  0008 D loss:-0.2773 G loss:-2.841\n",
      "Epoch:  0008 D loss:-0.363 G loss:-2.632\n",
      "Epoch:  0008 D loss:-0.3626 G loss:-2.669\n",
      "Epoch:  0008 D loss:-0.2792 G loss:-2.664\n",
      "Epoch:  0008 D loss:-0.347 G loss:-2.79\n",
      "Epoch:  0008 D loss:-0.3231 G loss:-2.602\n",
      "Epoch:  0008 D loss:-0.3461 G loss:-2.576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0008 D loss:-0.2953 G loss:-2.541\n",
      "Epoch:  0008 D loss:-0.2972 G loss:-2.677\n",
      "Epoch:  0008 D loss:-0.2566 G loss:-2.689\n",
      "Epoch:  0008 D loss:-0.2912 G loss:-2.665\n",
      "Epoch:  0008 D loss:-0.2717 G loss:-2.857\n",
      "Epoch:  0008 D loss:-0.2664 G loss:-2.869\n",
      "Epoch:  0008 D loss:-0.2776 G loss:-2.8\n",
      "Epoch:  0008 D loss:-0.3317 G loss:-2.848\n",
      "Epoch:  0008 D loss:-0.2997 G loss:-2.881\n",
      "Epoch:  0008 D loss:-0.2637 G loss:-2.98\n",
      "Epoch:  0008 D loss:-0.2034 G loss:-3.011\n",
      "Epoch:  0008 D loss:-0.2132 G loss:-3.065\n",
      "Epoch:  0008 D loss:-0.2073 G loss:-3.142\n",
      "Epoch:  0008 D loss:-0.2775 G loss:-2.961\n",
      "Epoch:  0008 D loss:-0.2152 G loss:-3.016\n",
      "Epoch:  0008 D loss:-0.2338 G loss:-3.107\n",
      "Epoch:  0008 D loss:-0.1833 G loss:-3.048\n",
      "Epoch:  0008 D loss:-0.2148 G loss:-3.117\n",
      "Epoch:  0008 D loss:-0.2945 G loss:-3.091\n",
      "Epoch:  0008 D loss:-0.3058 G loss:-2.904\n",
      "Epoch:  0008 D loss:-0.2717 G loss:-2.901\n",
      "Epoch:  0008 D loss:-0.2526 G loss:-2.766\n",
      "Epoch:  0008 D loss:-0.2327 G loss:-2.788\n",
      "Epoch:  0008 D loss:-0.2726 G loss:-2.765\n",
      "Epoch:  0008 D loss:-0.2481 G loss:-2.711\n",
      "Epoch:  0008 D loss:-0.2084 G loss:-2.69\n",
      "Epoch:  0008 D loss:-0.2485 G loss:-2.728\n",
      "Epoch:  0008 D loss:-0.2491 G loss:-2.82\n",
      "Epoch:  0008 D loss:-0.2837 G loss:-2.84\n",
      "Epoch:  0008 D loss:-0.2314 G loss:-2.967\n",
      "Epoch:  0008 D loss:-0.3035 G loss:-2.972\n",
      "Epoch:  0008 D loss:-0.219 G loss:-2.956\n",
      "Epoch:  0008 D loss:-0.2593 G loss:-2.91\n",
      "Epoch:  0008 D loss:-0.256 G loss:-2.851\n",
      "Epoch:  0008 D loss:-0.2639 G loss:-3.051\n",
      "Epoch:  0008 D loss:-0.2269 G loss:-2.761\n",
      "Epoch:  0008 D loss:-0.2587 G loss:-2.758\n",
      "Epoch:  0008 D loss:-0.3073 G loss:-2.658\n",
      "Epoch:  0008 D loss:-0.285 G loss:-2.786\n",
      "Epoch:  0008 D loss:-0.2479 G loss:-2.772\n",
      "Epoch:  0008 D loss:-0.221 G loss:-2.721\n",
      "Epoch:  0008 D loss:-0.3044 G loss:-2.779\n",
      "Epoch:  0008 D loss:-0.274 G loss:-2.545\n",
      "Epoch:  0008 D loss:-0.2464 G loss:-2.658\n",
      "Epoch:  0008 D loss:-0.3381 G loss:-2.661\n",
      "Epoch:  0008 D loss:-0.2481 G loss:-2.637\n",
      "Epoch:  0008 D loss:-0.2688 G loss:-2.613\n",
      "Epoch:  0008 D loss:-0.3219 G loss:-2.554\n",
      "Epoch:  0008 D loss:-0.3113 G loss:-2.635\n",
      "Epoch:  0008 D loss:-0.2514 G loss:-2.761\n",
      "Epoch:  0008 D loss:-0.2881 G loss:-2.666\n",
      "Epoch:  0008 D loss:-0.3139 G loss:-2.618\n",
      "Epoch:  0008 D loss:-0.2434 G loss:-2.704\n",
      "Epoch:  0008 D loss:-0.2636 G loss:-2.719\n",
      "Epoch:  0008 D loss:-0.2164 G loss:-2.744\n",
      "Epoch:  0008 D loss:-0.3164 G loss:-2.829\n",
      "Epoch:  0008 D loss:-0.2982 G loss:-2.932\n",
      "Epoch:  0008 D loss:-0.2874 G loss:-2.782\n",
      "Epoch:  0008 D loss:-0.2918 G loss:-2.658\n",
      "Epoch:  0008 D loss:-0.2963 G loss:-2.803\n",
      "Epoch:  0008 D loss:-0.3197 G loss:-2.769\n",
      "Epoch:  0008 D loss:-0.2901 G loss:-2.701\n",
      "Epoch:  0008 D loss:-0.321 G loss:-2.645\n",
      "Epoch:  0008 D loss:-0.2452 G loss:-2.601\n",
      "Epoch:  0008 D loss:-0.2576 G loss:-2.579\n",
      "Epoch:  0008 D loss:-0.2533 G loss:-2.674\n",
      "Epoch:  0008 D loss:-0.2645 G loss:-2.708\n",
      "Epoch:  0008 D loss:-0.2559 G loss:-2.714\n",
      "Epoch:  0008 D loss:-0.3671 G loss:-2.606\n",
      "Epoch:  0008 D loss:-0.2877 G loss:-2.765\n",
      "Epoch:  0008 D loss:-0.2656 G loss:-2.862\n",
      "Epoch:  0008 D loss:-0.2459 G loss:-2.75\n",
      "Epoch:  0008 D loss:-0.2662 G loss:-2.739\n",
      "Epoch:  0008 D loss:-0.2769 G loss:-2.799\n",
      "Epoch:  0008 D loss:-0.3728 G loss:-2.756\n",
      "Epoch:  0008 D loss:-0.262 G loss:-2.694\n",
      "Epoch:  0008 D loss:-0.2631 G loss:-2.773\n",
      "Epoch:  0008 D loss:-0.2647 G loss:-2.881\n",
      "Epoch:  0008 D loss:-0.2655 G loss:-2.83\n",
      "Epoch:  0008 D loss:-0.2482 G loss:-2.829\n",
      "Epoch:  0008 D loss:-0.2648 G loss:-2.809\n",
      "Epoch:  0008 D loss:-0.3017 G loss:-2.804\n",
      "Epoch:  0008 D loss:-0.3164 G loss:-2.658\n",
      "Epoch:  0008 D loss:-0.2987 G loss:-2.67\n",
      "Epoch:  0008 D loss:-0.3394 G loss:-2.544\n",
      "Epoch:  0008 D loss:-0.2662 G loss:-2.858\n",
      "Epoch:  0008 D loss:-0.3803 G loss:-2.704\n",
      "Epoch:  0008 D loss:-0.2937 G loss:-2.787\n",
      "Epoch:  0008 D loss:-0.224 G loss:-2.747\n",
      "Epoch:  0008 D loss:-0.2764 G loss:-2.688\n",
      "Epoch:  0008 D loss:-0.2843 G loss:-2.861\n",
      "Epoch:  0008 D loss:-0.2529 G loss:-2.834\n",
      "Epoch:  0008 D loss:-0.3515 G loss:-2.824\n",
      "Epoch:  0008 D loss:-0.223 G loss:-2.837\n",
      "Epoch:  0008 D loss:-0.2218 G loss:-2.929\n",
      "Epoch:  0008 D loss:-0.3417 G loss:-2.9\n",
      "Epoch:  0008 D loss:-0.3175 G loss:-2.73\n",
      "Epoch:  0008 D loss:-0.234 G loss:-2.918\n",
      "Epoch:  0008 D loss:-0.3042 G loss:-2.737\n",
      "Epoch:  0008 D loss:-0.3049 G loss:-2.75\n",
      "Epoch:  0008 D loss:-0.2724 G loss:-2.803\n",
      "Epoch:  0008 D loss:-0.2775 G loss:-2.704\n",
      "Epoch:  0008 D loss:-0.2559 G loss:-2.675\n",
      "Epoch:  0008 D loss:-0.2061 G loss:-2.756\n",
      "Epoch:  0008 D loss:-0.2699 G loss:-2.837\n",
      "Epoch:  0008 D loss:-0.2931 G loss:-2.714\n",
      "Epoch:  0008 D loss:-0.2463 G loss:-2.791\n",
      "Epoch:  0008 D loss:-0.3244 G loss:-2.713\n",
      "Epoch:  0008 D loss:-0.2615 G loss:-2.883\n",
      "Epoch:  0008 D loss:-0.2706 G loss:-2.749\n",
      "Epoch:  0008 D loss:-0.2828 G loss:-2.72\n",
      "Epoch:  0008 D loss:-0.3338 G loss:-2.827\n",
      "Epoch:  0008 D loss:-0.2402 G loss:-2.965\n",
      "Epoch:  0008 D loss:-0.326 G loss:-2.69\n",
      "Epoch:  0008 D loss:-0.2593 G loss:-2.71\n",
      "Epoch:  0008 D loss:-0.2857 G loss:-2.63\n",
      "Epoch:  0008 D loss:-0.2909 G loss:-2.824\n",
      "Epoch:  0008 D loss:-0.3147 G loss:-2.86\n",
      "Epoch:  0008 D loss:-0.2985 G loss:-3.026\n",
      "Epoch:  0008 D loss:-0.3019 G loss:-2.8\n",
      "Epoch:  0008 D loss:-0.2127 G loss:-2.869\n",
      "Epoch:  0008 D loss:-0.2739 G loss:-2.714\n",
      "Epoch:  0008 D loss:-0.2894 G loss:-2.799\n",
      "Epoch:  0008 D loss:-0.2923 G loss:-2.746\n",
      "Epoch:  0008 D loss:-0.2026 G loss:-2.933\n",
      "Epoch:  0008 D loss:-0.2667 G loss:-2.937\n",
      "Epoch:  0008 D loss:-0.34 G loss:-2.938\n",
      "Epoch:  0008 D loss:-0.2825 G loss:-2.739\n",
      "Epoch:  0008 D loss:-0.2605 G loss:-2.993\n",
      "Epoch:  0008 D loss:-0.2374 G loss:-2.905\n",
      "Epoch:  0008 D loss:-0.2622 G loss:-2.912\n",
      "Epoch:  0008 D loss:-0.2062 G loss:-3.13\n",
      "Epoch:  0008 D loss:-0.2895 G loss:-3.082\n",
      "Epoch:  0008 D loss:-0.2473 G loss:-3.033\n",
      "Epoch:  0008 D loss:-0.3346 G loss:-2.796\n",
      "Epoch:  0008 D loss:-0.2895 G loss:-3.004\n",
      "Epoch:  0008 D loss:-0.2299 G loss:-3.058\n",
      "Epoch:  0008 D loss:-0.2002 G loss:-3.085\n",
      "Epoch:  0008 D loss:-0.2471 G loss:-3.0\n",
      "Epoch:  0008 D loss:-0.2389 G loss:-2.866\n",
      "Epoch:  0008 D loss:-0.2487 G loss:-2.838\n",
      "Epoch:  0008 D loss:-0.1976 G loss:-2.829\n",
      "Epoch:  0008 D loss:-0.2219 G loss:-2.956\n",
      "Epoch:  0008 D loss:-0.2812 G loss:-2.942\n",
      "Epoch:  0008 D loss:-0.285 G loss:-2.928\n",
      "Epoch:  0008 D loss:-0.225 G loss:-2.947\n",
      "Epoch:  0008 D loss:-0.1901 G loss:-3.219\n",
      "Epoch:  0008 D loss:-0.2173 G loss:-3.054\n",
      "Epoch:  0008 D loss:-0.2511 G loss:-3.324\n",
      "Epoch:  0008 D loss:-0.2239 G loss:-3.21\n",
      "Epoch:  0008 D loss:-0.2478 G loss:-3.069\n",
      "Epoch:  0008 D loss:-0.2461 G loss:-3.054\n",
      "Epoch:  0008 D loss:-0.2848 G loss:-2.973\n",
      "Epoch:  0008 D loss:-0.2253 G loss:-2.968\n",
      "Epoch:  0008 D loss:-0.2656 G loss:-2.904\n",
      "Epoch:  0008 D loss:-0.2466 G loss:-2.975\n",
      "Epoch:  0008 D loss:-0.2294 G loss:-2.977\n",
      "Epoch:  0008 D loss:-0.2984 G loss:-2.735\n",
      "Epoch:  0008 D loss:-0.3268 G loss:-2.592\n",
      "Epoch:  0008 D loss:-0.303 G loss:-2.77\n",
      "Epoch:  0008 D loss:-0.2924 G loss:-2.743\n",
      "Epoch:  0008 D loss:-0.2534 G loss:-2.73\n",
      "Epoch:  0008 D loss:-0.2579 G loss:-2.682\n",
      "Epoch:  0008 D loss:-0.2786 G loss:-2.809\n",
      "Epoch:  0008 D loss:-0.2707 G loss:-2.862\n",
      "Epoch:  0008 D loss:-0.2347 G loss:-3.034\n",
      "Epoch:  0008 D loss:-0.3844 G loss:-2.793\n",
      "Epoch:  0008 D loss:-0.2981 G loss:-2.837\n",
      "Epoch:  0008 D loss:-0.3635 G loss:-2.758\n",
      "Epoch:  0008 D loss:-0.2869 G loss:-2.717\n",
      "Epoch:  0008 D loss:-0.3168 G loss:-2.618\n",
      "Epoch:  0008 D loss:-0.2859 G loss:-2.702\n",
      "Epoch:  0008 D loss:-0.3197 G loss:-2.672\n",
      "Epoch:  0008 D loss:-0.3735 G loss:-2.738\n",
      "Epoch:  0008 D loss:-0.3563 G loss:-2.594\n",
      "Epoch:  0008 D loss:-0.3331 G loss:-2.533\n",
      "Epoch:  0008 D loss:-0.3359 G loss:-2.645\n",
      "Epoch:  0008 D loss:-0.418 G loss:-2.615\n",
      "Epoch:  0008 D loss:-0.2869 G loss:-2.648\n",
      "Epoch:  0008 D loss:-0.2984 G loss:-2.692\n",
      "Epoch:  0008 D loss:-0.3605 G loss:-2.655\n",
      "Epoch:  0008 D loss:-0.3256 G loss:-2.662\n",
      "Epoch:  0008 D loss:-0.3745 G loss:-2.709\n",
      "Epoch:  0008 D loss:-0.4479 G loss:-2.551\n",
      "Epoch:  0008 D loss:-0.355 G loss:-2.577\n",
      "Epoch:  0008 D loss:-0.4571 G loss:-2.685\n",
      "Epoch:  0008 D loss:-0.34 G loss:-2.609\n",
      "Epoch:  0008 D loss:-0.3353 G loss:-2.683\n",
      "Epoch:  0008 D loss:-0.3734 G loss:-2.652\n",
      "Epoch:  0008 D loss:-0.3667 G loss:-2.55\n",
      "Epoch:  0008 D loss:-0.3512 G loss:-2.496\n",
      "Epoch:  0008 D loss:-0.3647 G loss:-2.638\n",
      "Epoch:  0008 D loss:-0.2921 G loss:-2.62\n",
      "Epoch:  0008 D loss:-0.3536 G loss:-2.717\n",
      "Epoch:  0008 D loss:-0.3683 G loss:-2.668\n",
      "Epoch:  0008 D loss:-0.3715 G loss:-2.772\n",
      "Epoch:  0008 D loss:-0.3403 G loss:-2.658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0008 D loss:-0.3187 G loss:-2.663\n",
      "Epoch:  0008 D loss:-0.2891 G loss:-2.883\n",
      "Epoch:  0008 D loss:-0.2768 G loss:-2.602\n",
      "Epoch:  0008 D loss:-0.3874 G loss:-2.481\n",
      "Epoch:  0008 D loss:-0.3983 G loss:-2.412\n",
      "Epoch:  0008 D loss:-0.3514 G loss:-2.54\n",
      "Epoch:  0008 D loss:-0.3798 G loss:-2.572\n",
      "Epoch:  0008 D loss:-0.2906 G loss:-2.687\n",
      "Epoch:  0008 D loss:-0.2935 G loss:-2.57\n",
      "Epoch:  0008 D loss:-0.3875 G loss:-2.716\n",
      "Epoch:  0008 D loss:-0.288 G loss:-2.767\n",
      "Epoch:  0008 D loss:-0.3045 G loss:-2.665\n",
      "Epoch:  0008 D loss:-0.2727 G loss:-2.925\n",
      "Epoch:  0008 D loss:-0.3581 G loss:-2.646\n",
      "Epoch:  0008 D loss:-0.3091 G loss:-2.885\n",
      "Epoch:  0008 D loss:-0.2857 G loss:-2.674\n",
      "Epoch:  0008 D loss:-0.2932 G loss:-2.715\n",
      "Epoch:  0008 D loss:-0.2986 G loss:-2.774\n",
      "Epoch:  0008 D loss:-0.2697 G loss:-2.702\n",
      "Epoch:  0008 D loss:-0.3642 G loss:-2.561\n",
      "Epoch:  0008 D loss:-0.2197 G loss:-2.609\n",
      "Epoch:  0008 D loss:-0.2862 G loss:-2.605\n",
      "Epoch:  0008 D loss:-0.3137 G loss:-2.568\n",
      "Epoch:  0008 D loss:-0.31 G loss:-2.456\n",
      "Epoch:  0008 D loss:-0.4869 G loss:-2.418\n",
      "Epoch:  0008 D loss:-0.3177 G loss:-2.558\n",
      "Epoch:  0008 D loss:-0.3461 G loss:-2.467\n",
      "Epoch:  0008 D loss:-0.3727 G loss:-2.369\n",
      "Epoch:  0008 D loss:-0.3594 G loss:-2.459\n",
      "Epoch:  0008 D loss:-0.423 G loss:-2.48\n",
      "Epoch:  0008 D loss:-0.2984 G loss:-2.752\n",
      "Epoch:  0008 D loss:-0.241 G loss:-2.737\n",
      "Epoch:  0008 D loss:-0.2741 G loss:-2.57\n",
      "Epoch:  0008 D loss:-0.3427 G loss:-2.52\n",
      "Epoch:  0008 D loss:-0.3532 G loss:-2.616\n",
      "Epoch:  0008 D loss:-0.3183 G loss:-2.597\n",
      "Epoch:  0008 D loss:-0.2858 G loss:-2.68\n",
      "Epoch:  0008 D loss:-0.3466 G loss:-2.503\n",
      "Epoch:  0008 D loss:-0.239 G loss:-2.677\n",
      "Epoch:  0008 D loss:-0.2659 G loss:-2.738\n",
      "Epoch:  0008 D loss:-0.2612 G loss:-2.855\n",
      "Epoch:  0008 D loss:-0.3541 G loss:-2.718\n",
      "Epoch:  0008 D loss:-0.3602 G loss:-2.778\n",
      "Epoch:  0008 D loss:-0.2929 G loss:-2.794\n",
      "Epoch:  0008 D loss:-0.2787 G loss:-2.728\n",
      "Epoch:  0008 D loss:-0.2809 G loss:-2.66\n",
      "Epoch:  0008 D loss:-0.259 G loss:-2.624\n",
      "Epoch:  0008 D loss:-0.3287 G loss:-2.644\n",
      "Epoch:  0008 D loss:-0.3184 G loss:-2.492\n",
      "Epoch:  0008 D loss:-0.2492 G loss:-2.556\n",
      "Epoch:  0008 D loss:-0.3592 G loss:-2.469\n",
      "Epoch:  0008 D loss:-0.2673 G loss:-2.695\n",
      "Epoch:  0008 D loss:-0.283 G loss:-2.701\n",
      "Epoch:  0008 D loss:-0.263 G loss:-2.706\n",
      "Epoch:  0008 D loss:-0.3698 G loss:-2.877\n",
      "Epoch:  0008 D loss:-0.3271 G loss:-2.805\n",
      "Epoch:  0008 D loss:-0.3027 G loss:-2.693\n",
      "Epoch:  0008 D loss:-0.3144 G loss:-2.528\n",
      "Epoch:  0008 D loss:-0.285 G loss:-2.64\n",
      "Epoch:  0008 D loss:-0.2712 G loss:-2.641\n",
      "Epoch:  0008 D loss:-0.2678 G loss:-2.556\n",
      "Epoch:  0008 D loss:-0.2568 G loss:-2.801\n",
      "Epoch:  0008 D loss:-0.2653 G loss:-2.746\n",
      "Epoch:  0008 D loss:-0.2742 G loss:-2.693\n",
      "Epoch:  0008 D loss:-0.2809 G loss:-2.68\n",
      "Epoch:  0008 D loss:-0.2794 G loss:-2.671\n",
      "Epoch:  0008 D loss:-0.3161 G loss:-2.731\n",
      "Epoch:  0008 D loss:-0.2828 G loss:-2.583\n",
      "Epoch:  0008 D loss:-0.308 G loss:-2.643\n",
      "Epoch:  0008 D loss:-0.2057 G loss:-2.594\n",
      "Epoch:  0008 D loss:-0.2577 G loss:-2.79\n",
      "Epoch:  0008 D loss:-0.2651 G loss:-2.707\n",
      "Epoch:  0008 D loss:-0.2635 G loss:-2.82\n",
      "Epoch:  0008 D loss:-0.2841 G loss:-2.699\n",
      "Epoch:  0008 D loss:-0.2752 G loss:-2.794\n",
      "Epoch:  0008 D loss:-0.288 G loss:-2.825\n",
      "Epoch:  0008 D loss:-0.3504 G loss:-2.783\n",
      "Epoch:  0008 D loss:-0.3253 G loss:-2.679\n",
      "Epoch:  0008 D loss:-0.2772 G loss:-2.631\n",
      "Epoch:  0008 D loss:-0.2253 G loss:-2.663\n",
      "Epoch:  0008 D loss:-0.3391 G loss:-2.535\n",
      "Epoch:  0008 D loss:-0.3051 G loss:-2.436\n",
      "Epoch:  0008 D loss:-0.2822 G loss:-2.529\n",
      "Epoch:  0008 D loss:-0.3456 G loss:-2.508\n",
      "Epoch:  0008 D loss:-0.361 G loss:-2.493\n",
      "Epoch:  0008 D loss:-0.2725 G loss:-2.489\n",
      "Epoch:  0008 D loss:-0.2854 G loss:-2.615\n",
      "Epoch:  0008 D loss:-0.3012 G loss:-2.614\n",
      "Epoch:  0008 D loss:-0.3325 G loss:-2.599\n",
      "Epoch:  0008 D loss:-0.3 G loss:-2.671\n",
      "Epoch:  0008 D loss:-0.3027 G loss:-2.754\n",
      "Epoch:  0008 D loss:-0.3349 G loss:-2.633\n",
      "Epoch:  0008 D loss:-0.2893 G loss:-2.68\n",
      "Epoch:  0008 D loss:-0.299 G loss:-2.552\n",
      "Epoch:  0008 D loss:-0.2759 G loss:-2.501\n",
      "Epoch:  0008 D loss:-0.3242 G loss:-2.41\n",
      "Epoch:  0008 D loss:-0.3452 G loss:-2.555\n",
      "Epoch:  0008 D loss:-0.3175 G loss:-2.437\n",
      "Epoch:  0008 D loss:-0.2696 G loss:-2.522\n",
      "Epoch:  0008 D loss:-0.2898 G loss:-2.391\n",
      "Epoch:  0008 D loss:-0.3253 G loss:-2.474\n",
      "Epoch:  0008 D loss:-0.3609 G loss:-2.349\n",
      "Epoch:  0008 D loss:-0.3507 G loss:-2.364\n",
      "Epoch:  0008 D loss:-0.3463 G loss:-2.404\n",
      "Epoch:  0008 D loss:-0.3668 G loss:-2.342\n",
      "Epoch:  0008 D loss:-0.3196 G loss:-2.449\n",
      "Epoch:  0008 D loss:-0.2955 G loss:-2.503\n",
      "Epoch:  0008 D loss:-0.3278 G loss:-2.308\n",
      "Epoch:  0008 D loss:-0.3747 G loss:-2.417\n",
      "Epoch:  0008 D loss:-0.2837 G loss:-2.578\n",
      "Epoch:  0008 D loss:-0.3672 G loss:-2.452\n",
      "Epoch:  0008 D loss:-0.3017 G loss:-2.581\n",
      "Epoch:  0008 D loss:-0.3028 G loss:-2.638\n",
      "Epoch:  0008 D loss:-0.3275 G loss:-2.72\n",
      "Epoch:  0008 D loss:-0.3398 G loss:-2.749\n",
      "Epoch:  0008 D loss:-0.3598 G loss:-2.576\n",
      "Epoch:  0008 D loss:-0.3546 G loss:-2.434\n",
      "Epoch:  0008 D loss:-0.3533 G loss:-2.566\n",
      "Epoch:  0008 D loss:-0.3416 G loss:-2.439\n",
      "Epoch:  0008 D loss:-0.294 G loss:-2.351\n",
      "Epoch:  0008 D loss:-0.3933 G loss:-2.382\n",
      "Epoch:  0008 D loss:-0.307 G loss:-2.632\n",
      "Epoch:  0008 D loss:-0.3341 G loss:-2.49\n",
      "Epoch:  0008 D loss:-0.4285 G loss:-2.474\n",
      "Epoch:  0008 D loss:-0.32 G loss:-2.563\n",
      "Epoch:  0008 D loss:-0.4087 G loss:-2.451\n",
      "Epoch:  0008 D loss:-0.3483 G loss:-2.559\n",
      "Epoch:  0008 D loss:-0.3088 G loss:-2.594\n",
      "Epoch:  0008 D loss:-0.3321 G loss:-2.564\n",
      "Epoch:  0008 D loss:-0.2554 G loss:-2.576\n",
      "Epoch:  0008 D loss:-0.2754 G loss:-2.564\n",
      "Epoch:  0008 D loss:-0.293 G loss:-2.453\n",
      "Epoch:  0008 D loss:-0.2456 G loss:-2.594\n",
      "Epoch:  0008 D loss:-0.2507 G loss:-2.614\n",
      "Epoch:  0008 D loss:-0.2862 G loss:-2.697\n",
      "Epoch:  0008 D loss:-0.3888 G loss:-2.661\n",
      "Epoch:  0008 D loss:-0.305 G loss:-2.689\n",
      "Epoch:  0008 D loss:-0.3652 G loss:-2.729\n",
      "Epoch:  0008 D loss:-0.3039 G loss:-2.653\n",
      "Epoch:  0008 D loss:-0.4073 G loss:-2.817\n",
      "Epoch:  0008 D loss:-0.308 G loss:-2.651\n",
      "Epoch:  0008 D loss:-0.3101 G loss:-2.485\n",
      "Epoch:  0008 D loss:-0.3373 G loss:-2.393\n",
      "Epoch:  0008 D loss:-0.3393 G loss:-2.453\n",
      "Epoch:  0008 D loss:-0.2872 G loss:-2.461\n",
      "Epoch:  0008 D loss:-0.3886 G loss:-2.424\n",
      "Epoch:  0008 D loss:-0.3011 G loss:-2.436\n",
      "Epoch:  0008 D loss:-0.3544 G loss:-2.38\n",
      "Epoch:  0008 D loss:-0.3337 G loss:-2.388\n",
      "Epoch:  0008 D loss:-0.3225 G loss:-2.537\n",
      "Epoch:  0008 D loss:-0.3781 G loss:-2.625\n",
      "Epoch:  0008 D loss:-0.3347 G loss:-2.688\n",
      "Epoch:  0008 D loss:-0.341 G loss:-2.785\n",
      "Epoch:  0008 D loss:-0.4174 G loss:-2.806\n",
      "Epoch:  0008 D loss:-0.3147 G loss:-2.635\n",
      "Epoch:  0008 D loss:-0.324 G loss:-2.82\n",
      "Epoch:  0008 D loss:-0.3974 G loss:-2.664\n",
      "Epoch:  0008 D loss:-0.383 G loss:-2.338\n",
      "Epoch:  0008 D loss:-0.4049 G loss:-2.358\n",
      "Epoch:  0008 D loss:-0.2922 G loss:-2.396\n",
      "Epoch:  0008 D loss:-0.2693 G loss:-2.65\n",
      "Epoch:  0008 D loss:-0.3711 G loss:-2.438\n",
      "Epoch:  0008 D loss:-0.2917 G loss:-2.513\n",
      "Epoch:  0008 D loss:-0.3859 G loss:-2.467\n",
      "Epoch:  0008 D loss:-0.3425 G loss:-2.436\n",
      "Epoch:  0008 D loss:-0.3385 G loss:-2.691\n",
      "Epoch:  0008 D loss:-0.3384 G loss:-2.62\n",
      "Epoch:  0008 D loss:-0.3604 G loss:-2.75\n",
      "Epoch:  0008 D loss:-0.3151 G loss:-2.602\n",
      "Epoch:  0008 D loss:-0.3504 G loss:-2.556\n",
      "Epoch:  0008 D loss:-0.2918 G loss:-2.643\n",
      "Epoch:  0008 D loss:-0.3961 G loss:-2.398\n",
      "Epoch:  0008 D loss:-0.317 G loss:-2.594\n",
      "Epoch:  0008 D loss:-0.3625 G loss:-2.547\n",
      "Epoch:  0008 D loss:-0.3416 G loss:-2.473\n",
      "Epoch:  0008 D loss:-0.3637 G loss:-2.532\n",
      "Epoch:  0008 D loss:-0.3531 G loss:-2.54\n",
      "Epoch:  0008 D loss:-0.3031 G loss:-2.586\n",
      "Epoch:  0008 D loss:-0.3011 G loss:-2.489\n",
      "Epoch:  0008 D loss:-0.3164 G loss:-2.484\n",
      "Epoch:  0008 D loss:-0.3427 G loss:-2.46\n",
      "Epoch:  0008 D loss:-0.3518 G loss:-2.555\n",
      "Epoch:  0008 D loss:-0.3532 G loss:-2.57\n",
      "Epoch:  0008 D loss:-0.3408 G loss:-2.57\n",
      "Epoch:  0008 D loss:-0.3632 G loss:-2.662\n",
      "Epoch:  0008 D loss:-0.3117 G loss:-2.676\n",
      "Epoch:  0008 D loss:-0.3773 G loss:-2.684\n",
      "Epoch:  0008 D loss:-0.3326 G loss:-2.654\n",
      "Epoch:  0008 D loss:-0.3991 G loss:-2.487\n",
      "Epoch:  0008 D loss:-0.3502 G loss:-2.582\n",
      "Epoch:  0008 D loss:-0.3421 G loss:-2.502\n",
      "Epoch:  0008 D loss:-0.338 G loss:-2.453\n",
      "Epoch:  0008 D loss:-0.3838 G loss:-2.364\n",
      "Epoch:  0008 D loss:-0.3617 G loss:-2.291\n",
      "Epoch:  0008 D loss:-0.3571 G loss:-2.277\n",
      "Epoch:  0008 D loss:-0.3264 G loss:-2.288\n",
      "Epoch:  0008 D loss:-0.371 G loss:-2.244\n",
      "Epoch:  0008 D loss:-0.3931 G loss:-2.399\n",
      "Epoch:  0008 D loss:-0.3539 G loss:-2.497\n",
      "Epoch:  0008 D loss:-0.371 G loss:-2.455\n",
      "Epoch:  0008 D loss:-0.3567 G loss:-2.6\n",
      "Epoch:  0008 D loss:-0.4599 G loss:-2.627\n",
      "Epoch:  0008 D loss:-0.4379 G loss:-2.488\n",
      "Epoch:  0008 D loss:-0.4699 G loss:-2.444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0008 D loss:-0.2912 G loss:-2.426\n",
      "Epoch:  0008 D loss:-0.4081 G loss:-2.315\n",
      "Epoch:  0008 D loss:-0.4049 G loss:-2.386\n",
      "Epoch:  0008 D loss:-0.4426 G loss:-2.217\n",
      "Epoch:  0008 D loss:-0.3689 G loss:-2.478\n",
      "Epoch:  0008 D loss:-0.3807 G loss:-2.304\n",
      "Epoch:  0008 D loss:-0.3799 G loss:-2.339\n",
      "Epoch:  0008 D loss:-0.5014 G loss:-2.278\n",
      "Epoch:  0008 D loss:-0.3895 G loss:-2.431\n",
      "Epoch:  0008 D loss:-0.3984 G loss:-2.421\n",
      "Epoch:  0008 D loss:-0.3743 G loss:-2.448\n",
      "Epoch:  0008 D loss:-0.355 G loss:-2.44\n",
      "Epoch:  0008 D loss:-0.3485 G loss:-2.316\n",
      "Epoch:  0008 D loss:-0.4198 G loss:-2.34\n",
      "Epoch:  0008 D loss:-0.4449 G loss:-2.484\n",
      "Epoch:  0008 D loss:-0.3586 G loss:-2.368\n",
      "Epoch:  0008 D loss:-0.4358 G loss:-2.248\n",
      "Epoch:  0008 D loss:-0.445 G loss:-2.406\n",
      "Epoch:  0008 D loss:-0.3549 G loss:-2.445\n",
      "Epoch:  0008 D loss:-0.3667 G loss:-2.565\n",
      "Epoch:  0008 D loss:-0.4063 G loss:-2.43\n",
      "Epoch:  0008 D loss:-0.5006 G loss:-2.328\n",
      "Epoch:  0008 D loss:-0.4491 G loss:-2.143\n",
      "Epoch:  0008 D loss:-0.5226 G loss:-2.079\n",
      "Epoch:  0008 D loss:-0.3619 G loss:-2.1\n",
      "Epoch:  0008 D loss:-0.3909 G loss:-2.167\n",
      "Epoch:  0008 D loss:-0.4292 G loss:-2.062\n",
      "Epoch:  0008 D loss:-0.3763 G loss:-2.308\n",
      "Epoch:  0008 D loss:-0.4644 G loss:-2.359\n",
      "Epoch:  0008 D loss:-0.419 G loss:-2.432\n",
      "Epoch:  0008 D loss:-0.4157 G loss:-2.601\n",
      "Epoch:  0008 D loss:-0.4208 G loss:-2.531\n",
      "Epoch:  0008 D loss:-0.4292 G loss:-2.75\n",
      "Epoch:  0008 D loss:-0.3767 G loss:-2.577\n",
      "Epoch:  0008 D loss:-0.4234 G loss:-2.506\n",
      "Epoch:  0008 D loss:-0.4942 G loss:-2.415\n",
      "Epoch:  0008 D loss:-0.4426 G loss:-2.463\n",
      "Epoch:  0008 D loss:-0.431 G loss:-2.231\n",
      "Epoch:  0008 D loss:-0.4058 G loss:-2.216\n",
      "Epoch:  0008 D loss:-0.3899 G loss:-2.352\n",
      "Epoch:  0008 D loss:-0.3793 G loss:-2.03\n",
      "Epoch:  0008 D loss:-0.4442 G loss:-2.255\n",
      "Epoch:  0008 D loss:-0.3883 G loss:-2.223\n",
      "Epoch:  0008 D loss:-0.4158 G loss:-2.213\n",
      "Epoch:  0008 D loss:-0.4311 G loss:-2.314\n",
      "Epoch:  0008 D loss:-0.3948 G loss:-2.34\n",
      "Epoch:  0008 D loss:-0.4689 G loss:-2.453\n",
      "Epoch:  0008 D loss:-0.4029 G loss:-2.465\n",
      "Epoch:  0008 D loss:-0.3793 G loss:-2.583\n",
      "Epoch:  0008 D loss:-0.3883 G loss:-2.524\n",
      "Epoch:  0008 D loss:-0.3166 G loss:-2.693\n",
      "Epoch:  0008 D loss:-0.4097 G loss:-2.47\n",
      "Epoch:  0008 D loss:-0.3958 G loss:-2.54\n",
      "Epoch:  0008 D loss:-0.4119 G loss:-2.31\n",
      "Epoch:  0008 D loss:-0.4798 G loss:-2.342\n",
      "Epoch:  0008 D loss:-0.406 G loss:-2.25\n",
      "Epoch:  0008 D loss:-0.4645 G loss:-2.147\n",
      "Epoch:  0008 D loss:-0.4146 G loss:-2.126\n",
      "Epoch:  0008 D loss:-0.4185 G loss:-2.001\n",
      "Epoch:  0008 D loss:-0.3775 G loss:-2.108\n",
      "Epoch:  0008 D loss:-0.488 G loss:-2.061\n",
      "Epoch:  0008 D loss:-0.4783 G loss:-2.127\n",
      "Epoch:  0008 D loss:-0.4141 G loss:-2.162\n",
      "Epoch:  0008 D loss:-0.4773 G loss:-2.169\n",
      "Epoch:  0008 D loss:-0.3224 G loss:-2.282\n",
      "Epoch:  0008 D loss:-0.4254 G loss:-2.366\n",
      "Epoch:  0008 D loss:-0.3672 G loss:-2.303\n",
      "Epoch:  0008 D loss:-0.4184 G loss:-2.417\n",
      "Epoch:  0008 D loss:-0.3266 G loss:-2.641\n",
      "Epoch:  0008 D loss:-0.4099 G loss:-2.595\n",
      "Epoch:  0008 D loss:-0.3716 G loss:-2.478\n",
      "Epoch:  0008 D loss:-0.3876 G loss:-2.441\n",
      "Epoch:  0008 D loss:-0.3347 G loss:-2.459\n",
      "Epoch:  0008 D loss:-0.3322 G loss:-2.343\n",
      "Epoch:  0008 D loss:-0.3546 G loss:-2.263\n",
      "Epoch:  0008 D loss:-0.3726 G loss:-2.368\n",
      "Epoch:  0008 D loss:-0.3584 G loss:-2.291\n",
      "Epoch:  0008 D loss:-0.4143 G loss:-2.377\n",
      "Epoch:  0008 D loss:-0.333 G loss:-2.257\n",
      "Epoch:  0008 D loss:-0.3907 G loss:-2.213\n",
      "Epoch:  0008 D loss:-0.391 G loss:-2.095\n",
      "Epoch:  0008 D loss:-0.3793 G loss:-2.341\n",
      "Epoch:  0008 D loss:-0.3565 G loss:-2.23\n",
      "Epoch:  0008 D loss:-0.3518 G loss:-2.392\n",
      "Epoch:  0008 D loss:-0.3238 G loss:-2.404\n",
      "Epoch:  0008 D loss:-0.4203 G loss:-2.555\n",
      "Epoch:  0008 D loss:-0.3046 G loss:-2.452\n",
      "Epoch:  0008 D loss:-0.4302 G loss:-2.457\n",
      "Epoch:  0008 D loss:-0.4097 G loss:-2.481\n",
      "Epoch:  0008 D loss:-0.3227 G loss:-2.426\n",
      "Epoch:  0008 D loss:-0.3652 G loss:-2.419\n",
      "Epoch:  0008 D loss:-0.3202 G loss:-2.536\n",
      "Epoch:  0008 D loss:-0.3879 G loss:-2.477\n",
      "Epoch:  0008 D loss:-0.3435 G loss:-2.424\n",
      "Epoch:  0008 D loss:-0.4026 G loss:-2.399\n",
      "Epoch:  0008 D loss:-0.3667 G loss:-2.411\n",
      "Epoch:  0008 D loss:-0.386 G loss:-2.249\n",
      "Epoch:  0008 D loss:-0.3547 G loss:-2.318\n",
      "Epoch:  0008 D loss:-0.3367 G loss:-2.292\n",
      "Epoch:  0008 D loss:-0.4261 G loss:-2.308\n",
      "Epoch:  0008 D loss:-0.4079 G loss:-2.383\n",
      "Epoch:  0008 D loss:-0.4096 G loss:-2.301\n",
      "Epoch:  0008 D loss:-0.3368 G loss:-2.347\n",
      "Epoch:  0008 D loss:-0.3365 G loss:-2.307\n",
      "Epoch:  0008 D loss:-0.4516 G loss:-2.314\n",
      "Epoch:  0008 D loss:-0.4321 G loss:-2.476\n",
      "Epoch:  0008 D loss:-0.3212 G loss:-2.489\n",
      "Epoch:  0008 D loss:-0.3944 G loss:-2.507\n",
      "Epoch:  0008 D loss:-0.4489 G loss:-2.498\n",
      "Epoch:  0008 D loss:-0.4546 G loss:-2.429\n",
      "Epoch:  0008 D loss:-0.4202 G loss:-2.444\n",
      "Epoch:  0008 D loss:-0.3738 G loss:-2.492\n",
      "Epoch:  0008 D loss:-0.437 G loss:-2.276\n",
      "Epoch:  0008 D loss:-0.3286 G loss:-2.306\n",
      "Epoch:  0008 D loss:-0.3874 G loss:-2.178\n",
      "Epoch:  0008 D loss:-0.4961 G loss:-2.097\n",
      "Epoch:  0008 D loss:-0.3368 G loss:-2.262\n",
      "Epoch:  0008 D loss:-0.3821 G loss:-2.292\n",
      "Epoch:  0008 D loss:-0.3845 G loss:-2.32\n",
      "Epoch:  0008 D loss:-0.4213 G loss:-2.393\n",
      "Epoch:  0008 D loss:-0.3594 G loss:-2.537\n",
      "Epoch:  0008 D loss:-0.4672 G loss:-2.369\n",
      "Epoch:  0009 D loss:-0.3478 G loss:-2.496\n",
      "Epoch:  0009 D loss:-0.448 G loss:-2.466\n",
      "Epoch:  0009 D loss:-0.3006 G loss:-2.474\n",
      "Epoch:  0009 D loss:-0.3928 G loss:-2.378\n",
      "Epoch:  0009 D loss:-0.356 G loss:-2.608\n",
      "Epoch:  0009 D loss:-0.3774 G loss:-2.583\n",
      "Epoch:  0009 D loss:-0.3239 G loss:-2.699\n",
      "Epoch:  0009 D loss:-0.3453 G loss:-2.662\n",
      "Epoch:  0009 D loss:-0.3441 G loss:-2.62\n",
      "Epoch:  0009 D loss:-0.3086 G loss:-2.63\n",
      "Epoch:  0009 D loss:-0.2775 G loss:-2.59\n",
      "Epoch:  0009 D loss:-0.3295 G loss:-2.472\n",
      "Epoch:  0009 D loss:-0.3467 G loss:-2.522\n",
      "Epoch:  0009 D loss:-0.2595 G loss:-2.697\n",
      "Epoch:  0009 D loss:-0.3514 G loss:-2.676\n",
      "Epoch:  0009 D loss:-0.3296 G loss:-2.64\n",
      "Epoch:  0009 D loss:-0.3183 G loss:-2.521\n",
      "Epoch:  0009 D loss:-0.286 G loss:-2.524\n",
      "Epoch:  0009 D loss:-0.2584 G loss:-2.572\n",
      "Epoch:  0009 D loss:-0.3162 G loss:-2.502\n",
      "Epoch:  0009 D loss:-0.2823 G loss:-2.636\n",
      "Epoch:  0009 D loss:-0.376 G loss:-2.755\n",
      "Epoch:  0009 D loss:-0.3411 G loss:-2.664\n",
      "Epoch:  0009 D loss:-0.3436 G loss:-2.96\n",
      "Epoch:  0009 D loss:-0.3775 G loss:-2.717\n",
      "Epoch:  0009 D loss:-0.2849 G loss:-2.818\n",
      "Epoch:  0009 D loss:-0.3127 G loss:-2.779\n",
      "Epoch:  0009 D loss:-0.3021 G loss:-2.491\n",
      "Epoch:  0009 D loss:-0.3176 G loss:-2.575\n",
      "Epoch:  0009 D loss:-0.2351 G loss:-2.596\n",
      "Epoch:  0009 D loss:-0.2967 G loss:-2.632\n",
      "Epoch:  0009 D loss:-0.2686 G loss:-2.574\n",
      "Epoch:  0009 D loss:-0.32 G loss:-2.623\n",
      "Epoch:  0009 D loss:-0.3116 G loss:-2.534\n",
      "Epoch:  0009 D loss:-0.275 G loss:-2.735\n",
      "Epoch:  0009 D loss:-0.3123 G loss:-2.85\n",
      "Epoch:  0009 D loss:-0.2978 G loss:-2.783\n",
      "Epoch:  0009 D loss:-0.2942 G loss:-2.696\n",
      "Epoch:  0009 D loss:-0.3379 G loss:-2.672\n",
      "Epoch:  0009 D loss:-0.2954 G loss:-2.791\n",
      "Epoch:  0009 D loss:-0.2909 G loss:-2.745\n",
      "Epoch:  0009 D loss:-0.2687 G loss:-2.634\n",
      "Epoch:  0009 D loss:-0.3398 G loss:-2.556\n",
      "Epoch:  0009 D loss:-0.2995 G loss:-2.681\n",
      "Epoch:  0009 D loss:-0.3489 G loss:-2.644\n",
      "Epoch:  0009 D loss:-0.2299 G loss:-2.754\n",
      "Epoch:  0009 D loss:-0.3257 G loss:-2.552\n",
      "Epoch:  0009 D loss:-0.2953 G loss:-2.615\n",
      "Epoch:  0009 D loss:-0.2908 G loss:-2.475\n",
      "Epoch:  0009 D loss:-0.2606 G loss:-2.766\n",
      "Epoch:  0009 D loss:-0.2188 G loss:-2.717\n",
      "Epoch:  0009 D loss:-0.2664 G loss:-2.836\n",
      "Epoch:  0009 D loss:-0.2417 G loss:-2.864\n",
      "Epoch:  0009 D loss:-0.266 G loss:-2.876\n",
      "Epoch:  0009 D loss:-0.2742 G loss:-2.835\n",
      "Epoch:  0009 D loss:-0.2711 G loss:-2.889\n",
      "Epoch:  0009 D loss:-0.2328 G loss:-2.931\n",
      "Epoch:  0009 D loss:-0.3774 G loss:-2.804\n",
      "Epoch:  0009 D loss:-0.3121 G loss:-2.787\n",
      "Epoch:  0009 D loss:-0.2791 G loss:-2.61\n",
      "Epoch:  0009 D loss:-0.2595 G loss:-2.732\n",
      "Epoch:  0009 D loss:-0.3143 G loss:-2.806\n",
      "Epoch:  0009 D loss:-0.2617 G loss:-2.633\n",
      "Epoch:  0009 D loss:-0.252 G loss:-2.611\n",
      "Epoch:  0009 D loss:-0.2708 G loss:-2.671\n",
      "Epoch:  0009 D loss:-0.24 G loss:-2.71\n",
      "Epoch:  0009 D loss:-0.2529 G loss:-2.74\n",
      "Epoch:  0009 D loss:-0.2859 G loss:-2.672\n",
      "Epoch:  0009 D loss:-0.2962 G loss:-2.681\n",
      "Epoch:  0009 D loss:-0.2511 G loss:-2.717\n",
      "Epoch:  0009 D loss:-0.2316 G loss:-2.618\n",
      "Epoch:  0009 D loss:-0.2651 G loss:-2.837\n",
      "Epoch:  0009 D loss:-0.2413 G loss:-2.729\n",
      "Epoch:  0009 D loss:-0.2497 G loss:-2.842\n",
      "Epoch:  0009 D loss:-0.2442 G loss:-2.796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0009 D loss:-0.2562 G loss:-2.848\n",
      "Epoch:  0009 D loss:-0.2625 G loss:-2.752\n",
      "Epoch:  0009 D loss:-0.2666 G loss:-2.778\n",
      "Epoch:  0009 D loss:-0.242 G loss:-2.804\n",
      "Epoch:  0009 D loss:-0.2555 G loss:-2.792\n",
      "Epoch:  0009 D loss:-0.3128 G loss:-2.672\n",
      "Epoch:  0009 D loss:-0.233 G loss:-2.823\n",
      "Epoch:  0009 D loss:-0.226 G loss:-2.893\n",
      "Epoch:  0009 D loss:-0.239 G loss:-2.655\n",
      "Epoch:  0009 D loss:-0.2883 G loss:-2.598\n",
      "Epoch:  0009 D loss:-0.2694 G loss:-2.689\n",
      "Epoch:  0009 D loss:-0.2707 G loss:-2.507\n",
      "Epoch:  0009 D loss:-0.2394 G loss:-2.643\n",
      "Epoch:  0009 D loss:-0.3345 G loss:-2.654\n",
      "Epoch:  0009 D loss:-0.2521 G loss:-2.616\n",
      "Epoch:  0009 D loss:-0.2419 G loss:-2.772\n",
      "Epoch:  0009 D loss:-0.2855 G loss:-2.601\n",
      "Epoch:  0009 D loss:-0.2584 G loss:-2.613\n",
      "Epoch:  0009 D loss:-0.3359 G loss:-2.678\n",
      "Epoch:  0009 D loss:-0.2433 G loss:-2.7\n",
      "Epoch:  0009 D loss:-0.2986 G loss:-2.626\n",
      "Epoch:  0009 D loss:-0.2733 G loss:-2.614\n",
      "Epoch:  0009 D loss:-0.2646 G loss:-2.704\n",
      "Epoch:  0009 D loss:-0.2833 G loss:-2.63\n",
      "Epoch:  0009 D loss:-0.2503 G loss:-2.681\n",
      "Epoch:  0009 D loss:-0.2839 G loss:-2.502\n",
      "Epoch:  0009 D loss:-0.3092 G loss:-2.504\n",
      "Epoch:  0009 D loss:-0.2876 G loss:-2.527\n",
      "Epoch:  0009 D loss:-0.2805 G loss:-2.59\n",
      "Epoch:  0009 D loss:-0.2691 G loss:-2.561\n",
      "Epoch:  0009 D loss:-0.2985 G loss:-2.544\n",
      "Epoch:  0009 D loss:-0.2187 G loss:-2.685\n",
      "Epoch:  0009 D loss:-0.3171 G loss:-2.695\n",
      "Epoch:  0009 D loss:-0.328 G loss:-2.773\n",
      "Epoch:  0009 D loss:-0.2983 G loss:-2.644\n",
      "Epoch:  0009 D loss:-0.3083 G loss:-2.585\n",
      "Epoch:  0009 D loss:-0.2726 G loss:-2.589\n",
      "Epoch:  0009 D loss:-0.3357 G loss:-2.399\n",
      "Epoch:  0009 D loss:-0.2795 G loss:-2.605\n",
      "Epoch:  0009 D loss:-0.2495 G loss:-2.66\n",
      "Epoch:  0009 D loss:-0.34 G loss:-2.592\n",
      "Epoch:  0009 D loss:-0.2993 G loss:-2.669\n",
      "Epoch:  0009 D loss:-0.262 G loss:-2.608\n",
      "Epoch:  0009 D loss:-0.3312 G loss:-2.55\n",
      "Epoch:  0009 D loss:-0.3116 G loss:-2.635\n",
      "Epoch:  0009 D loss:-0.3856 G loss:-2.598\n",
      "Epoch:  0009 D loss:-0.2962 G loss:-2.675\n",
      "Epoch:  0009 D loss:-0.3339 G loss:-2.626\n",
      "Epoch:  0009 D loss:-0.2891 G loss:-2.527\n",
      "Epoch:  0009 D loss:-0.3066 G loss:-2.482\n",
      "Epoch:  0009 D loss:-0.3353 G loss:-2.606\n",
      "Epoch:  0009 D loss:-0.3209 G loss:-2.543\n",
      "Epoch:  0009 D loss:-0.3156 G loss:-2.515\n",
      "Epoch:  0009 D loss:-0.2864 G loss:-2.537\n",
      "Epoch:  0009 D loss:-0.3604 G loss:-2.478\n",
      "Epoch:  0009 D loss:-0.2957 G loss:-2.612\n",
      "Epoch:  0009 D loss:-0.3312 G loss:-2.566\n",
      "Epoch:  0009 D loss:-0.3057 G loss:-2.633\n",
      "Epoch:  0009 D loss:-0.2461 G loss:-2.788\n",
      "Epoch:  0009 D loss:-0.2842 G loss:-2.752\n",
      "Epoch:  0009 D loss:-0.265 G loss:-2.713\n",
      "Epoch:  0009 D loss:-0.3094 G loss:-2.907\n",
      "Epoch:  0009 D loss:-0.4165 G loss:-2.752\n",
      "Epoch:  0009 D loss:-0.2407 G loss:-2.872\n",
      "Epoch:  0009 D loss:-0.2724 G loss:-2.758\n",
      "Epoch:  0009 D loss:-0.3135 G loss:-2.678\n",
      "Epoch:  0009 D loss:-0.3018 G loss:-2.661\n",
      "Epoch:  0009 D loss:-0.359 G loss:-2.65\n",
      "Epoch:  0009 D loss:-0.2552 G loss:-2.512\n",
      "Epoch:  0009 D loss:-0.2588 G loss:-2.644\n",
      "Epoch:  0009 D loss:-0.3068 G loss:-2.717\n",
      "Epoch:  0009 D loss:-0.2579 G loss:-2.713\n",
      "Epoch:  0009 D loss:-0.2721 G loss:-2.669\n",
      "Epoch:  0009 D loss:-0.2909 G loss:-2.664\n",
      "Epoch:  0009 D loss:-0.389 G loss:-2.842\n",
      "Epoch:  0009 D loss:-0.2681 G loss:-2.813\n",
      "Epoch:  0009 D loss:-0.3176 G loss:-2.756\n",
      "Epoch:  0009 D loss:-0.2517 G loss:-2.785\n",
      "Epoch:  0009 D loss:-0.3006 G loss:-2.575\n",
      "Epoch:  0009 D loss:-0.2314 G loss:-2.822\n",
      "Epoch:  0009 D loss:-0.3172 G loss:-2.584\n",
      "Epoch:  0009 D loss:-0.2715 G loss:-2.614\n",
      "Epoch:  0009 D loss:-0.3047 G loss:-2.694\n",
      "Epoch:  0009 D loss:-0.3273 G loss:-2.735\n",
      "Epoch:  0009 D loss:-0.2805 G loss:-2.64\n",
      "Epoch:  0009 D loss:-0.2567 G loss:-2.776\n",
      "Epoch:  0009 D loss:-0.3246 G loss:-2.739\n",
      "Epoch:  0009 D loss:-0.2948 G loss:-2.764\n",
      "Epoch:  0009 D loss:-0.3263 G loss:-2.547\n",
      "Epoch:  0009 D loss:-0.261 G loss:-2.635\n",
      "Epoch:  0009 D loss:-0.2492 G loss:-2.784\n",
      "Epoch:  0009 D loss:-0.3135 G loss:-2.749\n",
      "Epoch:  0009 D loss:-0.2602 G loss:-2.801\n",
      "Epoch:  0009 D loss:-0.2585 G loss:-2.732\n",
      "Epoch:  0009 D loss:-0.3004 G loss:-2.535\n",
      "Epoch:  0009 D loss:-0.283 G loss:-2.721\n",
      "Epoch:  0009 D loss:-0.2818 G loss:-2.718\n",
      "Epoch:  0009 D loss:-0.3142 G loss:-2.593\n",
      "Epoch:  0009 D loss:-0.2913 G loss:-2.607\n",
      "Epoch:  0009 D loss:-0.312 G loss:-2.661\n",
      "Epoch:  0009 D loss:-0.2596 G loss:-2.851\n",
      "Epoch:  0009 D loss:-0.2206 G loss:-2.638\n",
      "Epoch:  0009 D loss:-0.3147 G loss:-2.689\n",
      "Epoch:  0009 D loss:-0.3139 G loss:-2.487\n",
      "Epoch:  0009 D loss:-0.3017 G loss:-2.58\n",
      "Epoch:  0009 D loss:-0.3808 G loss:-2.598\n",
      "Epoch:  0009 D loss:-0.2959 G loss:-2.665\n",
      "Epoch:  0009 D loss:-0.3128 G loss:-2.448\n",
      "Epoch:  0009 D loss:-0.2734 G loss:-2.586\n",
      "Epoch:  0009 D loss:-0.2791 G loss:-2.659\n",
      "Epoch:  0009 D loss:-0.2501 G loss:-2.471\n",
      "Epoch:  0009 D loss:-0.2201 G loss:-2.668\n",
      "Epoch:  0009 D loss:-0.2686 G loss:-2.58\n",
      "Epoch:  0009 D loss:-0.266 G loss:-2.705\n",
      "Epoch:  0009 D loss:-0.3816 G loss:-2.755\n",
      "Epoch:  0009 D loss:-0.3181 G loss:-2.816\n",
      "Epoch:  0009 D loss:-0.243 G loss:-2.56\n",
      "Epoch:  0009 D loss:-0.2445 G loss:-2.581\n",
      "Epoch:  0009 D loss:-0.3161 G loss:-2.668\n",
      "Epoch:  0009 D loss:-0.2422 G loss:-2.739\n",
      "Epoch:  0009 D loss:-0.3617 G loss:-2.356\n",
      "Epoch:  0009 D loss:-0.3605 G loss:-2.567\n",
      "Epoch:  0009 D loss:-0.2808 G loss:-2.527\n",
      "Epoch:  0009 D loss:-0.2791 G loss:-2.591\n",
      "Epoch:  0009 D loss:-0.3579 G loss:-2.448\n",
      "Epoch:  0009 D loss:-0.345 G loss:-2.403\n",
      "Epoch:  0009 D loss:-0.3127 G loss:-2.335\n",
      "Epoch:  0009 D loss:-0.2849 G loss:-2.412\n",
      "Epoch:  0009 D loss:-0.3285 G loss:-2.481\n",
      "Epoch:  0009 D loss:-0.3022 G loss:-2.521\n",
      "Epoch:  0009 D loss:-0.3152 G loss:-2.496\n",
      "Epoch:  0009 D loss:-0.4274 G loss:-2.566\n",
      "Epoch:  0009 D loss:-0.2583 G loss:-2.666\n",
      "Epoch:  0009 D loss:-0.3072 G loss:-2.5\n",
      "Epoch:  0009 D loss:-0.3149 G loss:-2.459\n",
      "Epoch:  0009 D loss:-0.2994 G loss:-2.495\n",
      "Epoch:  0009 D loss:-0.3495 G loss:-2.569\n",
      "Epoch:  0009 D loss:-0.4532 G loss:-2.305\n",
      "Epoch:  0009 D loss:-0.3344 G loss:-2.471\n",
      "Epoch:  0009 D loss:-0.267 G loss:-2.506\n",
      "Epoch:  0009 D loss:-0.3032 G loss:-2.427\n",
      "Epoch:  0009 D loss:-0.3297 G loss:-2.46\n",
      "Epoch:  0009 D loss:-0.3558 G loss:-2.268\n",
      "Epoch:  0009 D loss:-0.3192 G loss:-2.43\n",
      "Epoch:  0009 D loss:-0.2953 G loss:-2.467\n",
      "Epoch:  0009 D loss:-0.3498 G loss:-2.294\n",
      "Epoch:  0009 D loss:-0.3721 G loss:-2.385\n",
      "Epoch:  0009 D loss:-0.3219 G loss:-2.418\n",
      "Epoch:  0009 D loss:-0.2968 G loss:-2.436\n",
      "Epoch:  0009 D loss:-0.3049 G loss:-2.489\n",
      "Epoch:  0009 D loss:-0.4106 G loss:-2.548\n",
      "Epoch:  0009 D loss:-0.3809 G loss:-2.468\n",
      "Epoch:  0009 D loss:-0.4002 G loss:-2.46\n",
      "Epoch:  0009 D loss:-0.3604 G loss:-2.499\n",
      "Epoch:  0009 D loss:-0.2872 G loss:-2.388\n",
      "Epoch:  0009 D loss:-0.2453 G loss:-2.519\n",
      "Epoch:  0009 D loss:-0.3328 G loss:-2.292\n",
      "Epoch:  0009 D loss:-0.36 G loss:-2.364\n",
      "Epoch:  0009 D loss:-0.3032 G loss:-2.239\n",
      "Epoch:  0009 D loss:-0.3023 G loss:-2.462\n",
      "Epoch:  0009 D loss:-0.3361 G loss:-2.411\n",
      "Epoch:  0009 D loss:-0.3143 G loss:-2.439\n",
      "Epoch:  0009 D loss:-0.3723 G loss:-2.433\n",
      "Epoch:  0009 D loss:-0.2778 G loss:-2.534\n",
      "Epoch:  0009 D loss:-0.2953 G loss:-2.528\n",
      "Epoch:  0009 D loss:-0.317 G loss:-2.526\n",
      "Epoch:  0009 D loss:-0.3155 G loss:-2.618\n",
      "Epoch:  0009 D loss:-0.2914 G loss:-2.545\n",
      "Epoch:  0009 D loss:-0.3035 G loss:-2.678\n",
      "Epoch:  0009 D loss:-0.3161 G loss:-2.65\n",
      "Epoch:  0009 D loss:-0.3607 G loss:-2.559\n",
      "Epoch:  0009 D loss:-0.3169 G loss:-2.488\n",
      "Epoch:  0009 D loss:-0.3329 G loss:-2.387\n",
      "Epoch:  0009 D loss:-0.2472 G loss:-2.476\n",
      "Epoch:  0009 D loss:-0.2522 G loss:-2.464\n",
      "Epoch:  0009 D loss:-0.3035 G loss:-2.548\n",
      "Epoch:  0009 D loss:-0.2575 G loss:-2.655\n",
      "Epoch:  0009 D loss:-0.2652 G loss:-2.627\n",
      "Epoch:  0009 D loss:-0.2448 G loss:-2.635\n",
      "Epoch:  0009 D loss:-0.2431 G loss:-2.715\n",
      "Epoch:  0009 D loss:-0.2236 G loss:-2.719\n",
      "Epoch:  0009 D loss:-0.2257 G loss:-2.771\n",
      "Epoch:  0009 D loss:-0.2041 G loss:-2.86\n",
      "Epoch:  0009 D loss:-0.2592 G loss:-2.745\n",
      "Epoch:  0009 D loss:-0.3277 G loss:-2.674\n",
      "Epoch:  0009 D loss:-0.2475 G loss:-2.687\n",
      "Epoch:  0009 D loss:-0.2072 G loss:-2.701\n",
      "Epoch:  0009 D loss:-0.2337 G loss:-2.758\n",
      "Epoch:  0009 D loss:-0.229 G loss:-2.735\n",
      "Epoch:  0009 D loss:-0.2183 G loss:-2.74\n",
      "Epoch:  0009 D loss:-0.2486 G loss:-2.636\n",
      "Epoch:  0009 D loss:-0.2423 G loss:-2.661\n",
      "Epoch:  0009 D loss:-0.2228 G loss:-2.607\n",
      "Epoch:  0009 D loss:-0.2882 G loss:-2.575\n",
      "Epoch:  0009 D loss:-0.2094 G loss:-2.612\n",
      "Epoch:  0009 D loss:-0.2499 G loss:-2.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0009 D loss:-0.2595 G loss:-2.805\n",
      "Epoch:  0009 D loss:-0.259 G loss:-2.774\n",
      "Epoch:  0009 D loss:-0.2563 G loss:-2.715\n",
      "Epoch:  0009 D loss:-0.2262 G loss:-2.846\n",
      "Epoch:  0009 D loss:-0.2479 G loss:-2.793\n",
      "Epoch:  0009 D loss:-0.2329 G loss:-2.823\n",
      "Epoch:  0009 D loss:-0.2173 G loss:-2.838\n",
      "Epoch:  0009 D loss:-0.2096 G loss:-2.814\n",
      "Epoch:  0009 D loss:-0.244 G loss:-2.833\n",
      "Epoch:  0009 D loss:-0.2285 G loss:-2.732\n",
      "Epoch:  0009 D loss:-0.2125 G loss:-2.682\n",
      "Epoch:  0009 D loss:-0.2508 G loss:-2.785\n",
      "Epoch:  0009 D loss:-0.2519 G loss:-2.636\n",
      "Epoch:  0009 D loss:-0.3019 G loss:-2.729\n",
      "Epoch:  0009 D loss:-0.2613 G loss:-2.784\n",
      "Epoch:  0009 D loss:-0.2422 G loss:-2.706\n",
      "Epoch:  0009 D loss:-0.3168 G loss:-2.606\n",
      "Epoch:  0009 D loss:-0.3198 G loss:-2.634\n",
      "Epoch:  0009 D loss:-0.2388 G loss:-2.565\n",
      "Epoch:  0009 D loss:-0.217 G loss:-2.654\n",
      "Epoch:  0009 D loss:-0.2357 G loss:-2.65\n",
      "Epoch:  0009 D loss:-0.2053 G loss:-2.748\n",
      "Epoch:  0009 D loss:-0.2128 G loss:-2.873\n",
      "Epoch:  0009 D loss:-0.2701 G loss:-2.846\n",
      "Epoch:  0009 D loss:-0.2038 G loss:-2.897\n",
      "Epoch:  0009 D loss:-0.2474 G loss:-2.97\n",
      "Epoch:  0009 D loss:-0.2743 G loss:-2.789\n",
      "Epoch:  0009 D loss:-0.2027 G loss:-2.854\n",
      "Epoch:  0009 D loss:-0.2025 G loss:-2.84\n",
      "Epoch:  0009 D loss:-0.2025 G loss:-2.873\n",
      "Epoch:  0009 D loss:-0.25 G loss:-2.872\n",
      "Epoch:  0009 D loss:-0.2479 G loss:-2.864\n",
      "Epoch:  0009 D loss:-0.2061 G loss:-2.79\n",
      "Epoch:  0009 D loss:-0.2859 G loss:-2.71\n",
      "Epoch:  0009 D loss:-0.2345 G loss:-2.749\n",
      "Epoch:  0009 D loss:-0.2286 G loss:-2.628\n",
      "Epoch:  0009 D loss:-0.2485 G loss:-2.679\n",
      "Epoch:  0009 D loss:-0.2187 G loss:-2.757\n",
      "Epoch:  0009 D loss:-0.2543 G loss:-2.717\n",
      "Epoch:  0009 D loss:-0.2706 G loss:-2.845\n",
      "Epoch:  0009 D loss:-0.2594 G loss:-2.766\n",
      "Epoch:  0009 D loss:-0.2406 G loss:-2.652\n",
      "Epoch:  0009 D loss:-0.1826 G loss:-2.963\n",
      "Epoch:  0009 D loss:-0.2338 G loss:-2.796\n",
      "Epoch:  0009 D loss:-0.2839 G loss:-2.716\n",
      "Epoch:  0009 D loss:-0.2916 G loss:-2.956\n",
      "Epoch:  0009 D loss:-0.2888 G loss:-2.98\n",
      "Epoch:  0009 D loss:-0.2561 G loss:-2.768\n",
      "Epoch:  0009 D loss:-0.2504 G loss:-2.782\n",
      "Epoch:  0009 D loss:-0.2581 G loss:-2.662\n",
      "Epoch:  0009 D loss:-0.293 G loss:-2.568\n",
      "Epoch:  0009 D loss:-0.25 G loss:-2.601\n",
      "Epoch:  0009 D loss:-0.2491 G loss:-2.67\n",
      "Epoch:  0009 D loss:-0.2439 G loss:-2.637\n",
      "Epoch:  0009 D loss:-0.2421 G loss:-2.757\n",
      "Epoch:  0009 D loss:-0.2473 G loss:-2.78\n",
      "Epoch:  0009 D loss:-0.2459 G loss:-2.843\n",
      "Epoch:  0009 D loss:-0.3004 G loss:-2.799\n",
      "Epoch:  0009 D loss:-0.236 G loss:-2.778\n",
      "Epoch:  0009 D loss:-0.2491 G loss:-2.678\n",
      "Epoch:  0009 D loss:-0.1993 G loss:-2.741\n",
      "Epoch:  0009 D loss:-0.2217 G loss:-2.753\n",
      "Epoch:  0009 D loss:-0.3093 G loss:-2.692\n",
      "Epoch:  0009 D loss:-0.2764 G loss:-2.781\n",
      "Epoch:  0009 D loss:-0.227 G loss:-2.726\n",
      "Epoch:  0009 D loss:-0.2649 G loss:-2.645\n",
      "Epoch:  0009 D loss:-0.2661 G loss:-2.655\n",
      "Epoch:  0009 D loss:-0.311 G loss:-2.793\n",
      "Epoch:  0009 D loss:-0.2872 G loss:-2.61\n",
      "Epoch:  0009 D loss:-0.2243 G loss:-2.725\n",
      "Epoch:  0009 D loss:-0.2931 G loss:-2.622\n",
      "Epoch:  0009 D loss:-0.2901 G loss:-2.543\n",
      "Epoch:  0009 D loss:-0.2852 G loss:-2.484\n",
      "Epoch:  0009 D loss:-0.3273 G loss:-2.45\n",
      "Epoch:  0009 D loss:-0.268 G loss:-2.585\n",
      "Epoch:  0009 D loss:-0.2901 G loss:-2.457\n",
      "Epoch:  0009 D loss:-0.3175 G loss:-2.478\n",
      "Epoch:  0009 D loss:-0.2463 G loss:-2.594\n",
      "Epoch:  0009 D loss:-0.2265 G loss:-2.589\n",
      "Epoch:  0009 D loss:-0.2588 G loss:-2.609\n",
      "Epoch:  0009 D loss:-0.2284 G loss:-2.865\n",
      "Epoch:  0009 D loss:-0.2529 G loss:-2.895\n",
      "Epoch:  0009 D loss:-0.2768 G loss:-2.712\n",
      "Epoch:  0009 D loss:-0.2499 G loss:-2.886\n",
      "Epoch:  0009 D loss:-0.2826 G loss:-2.803\n",
      "Epoch:  0009 D loss:-0.2951 G loss:-2.76\n",
      "Epoch:  0009 D loss:-0.2498 G loss:-2.711\n",
      "Epoch:  0009 D loss:-0.2206 G loss:-2.773\n",
      "Epoch:  0009 D loss:-0.2836 G loss:-2.856\n",
      "Epoch:  0009 D loss:-0.2778 G loss:-2.615\n",
      "Epoch:  0009 D loss:-0.2305 G loss:-2.621\n",
      "Epoch:  0009 D loss:-0.2141 G loss:-2.621\n",
      "Epoch:  0009 D loss:-0.2868 G loss:-2.598\n",
      "Epoch:  0009 D loss:-0.2745 G loss:-2.732\n",
      "Epoch:  0009 D loss:-0.3186 G loss:-2.906\n",
      "Epoch:  0009 D loss:-0.2371 G loss:-2.815\n",
      "Epoch:  0009 D loss:-0.2768 G loss:-2.734\n",
      "Epoch:  0009 D loss:-0.2603 G loss:-2.677\n",
      "Epoch:  0009 D loss:-0.2589 G loss:-2.803\n",
      "Epoch:  0009 D loss:-0.2597 G loss:-2.594\n",
      "Epoch:  0009 D loss:-0.2789 G loss:-2.703\n",
      "Epoch:  0009 D loss:-0.3219 G loss:-2.739\n",
      "Epoch:  0009 D loss:-0.2408 G loss:-2.693\n",
      "Epoch:  0009 D loss:-0.2352 G loss:-2.733\n",
      "Epoch:  0009 D loss:-0.2412 G loss:-2.681\n",
      "Epoch:  0009 D loss:-0.3375 G loss:-2.581\n",
      "Epoch:  0009 D loss:-0.2835 G loss:-2.914\n",
      "Epoch:  0009 D loss:-0.2558 G loss:-2.786\n",
      "Epoch:  0009 D loss:-0.2563 G loss:-2.851\n",
      "Epoch:  0009 D loss:-0.3012 G loss:-2.741\n",
      "Epoch:  0009 D loss:-0.375 G loss:-2.64\n",
      "Epoch:  0009 D loss:-0.2403 G loss:-2.755\n",
      "Epoch:  0009 D loss:-0.2433 G loss:-2.579\n",
      "Epoch:  0009 D loss:-0.2977 G loss:-2.617\n",
      "Epoch:  0009 D loss:-0.321 G loss:-2.514\n",
      "Epoch:  0009 D loss:-0.3705 G loss:-2.481\n",
      "Epoch:  0009 D loss:-0.3016 G loss:-2.452\n",
      "Epoch:  0009 D loss:-0.3324 G loss:-2.592\n",
      "Epoch:  0009 D loss:-0.3258 G loss:-2.582\n",
      "Epoch:  0009 D loss:-0.347 G loss:-2.529\n",
      "Epoch:  0009 D loss:-0.3412 G loss:-2.518\n",
      "Epoch:  0009 D loss:-0.2759 G loss:-2.654\n",
      "Epoch:  0009 D loss:-0.2538 G loss:-2.536\n",
      "Epoch:  0009 D loss:-0.2874 G loss:-2.631\n",
      "Epoch:  0009 D loss:-0.2371 G loss:-2.78\n",
      "Epoch:  0009 D loss:-0.3225 G loss:-2.771\n",
      "Epoch:  0009 D loss:-0.4204 G loss:-2.619\n",
      "Epoch:  0009 D loss:-0.2879 G loss:-2.707\n",
      "Epoch:  0009 D loss:-0.3764 G loss:-2.668\n",
      "Epoch:  0009 D loss:-0.2633 G loss:-2.745\n",
      "Epoch:  0009 D loss:-0.2846 G loss:-2.614\n",
      "Epoch:  0009 D loss:-0.2693 G loss:-2.49\n",
      "Epoch:  0009 D loss:-0.3181 G loss:-2.482\n",
      "Epoch:  0009 D loss:-0.2714 G loss:-2.539\n",
      "Epoch:  0009 D loss:-0.2984 G loss:-2.482\n",
      "Epoch:  0009 D loss:-0.3171 G loss:-2.584\n",
      "Epoch:  0009 D loss:-0.3106 G loss:-2.638\n",
      "Epoch:  0009 D loss:-0.2351 G loss:-2.699\n",
      "Epoch:  0009 D loss:-0.2828 G loss:-2.626\n",
      "Epoch:  0009 D loss:-0.2775 G loss:-2.725\n",
      "Epoch:  0009 D loss:-0.2466 G loss:-2.695\n",
      "Epoch:  0009 D loss:-0.3084 G loss:-2.652\n",
      "Epoch:  0009 D loss:-0.2885 G loss:-2.689\n",
      "Epoch:  0009 D loss:-0.3188 G loss:-2.658\n",
      "Epoch:  0009 D loss:-0.2671 G loss:-2.563\n",
      "Epoch:  0009 D loss:-0.3567 G loss:-2.436\n",
      "Epoch:  0009 D loss:-0.3283 G loss:-2.524\n",
      "Epoch:  0009 D loss:-0.286 G loss:-2.548\n",
      "Epoch:  0009 D loss:-0.2723 G loss:-2.45\n",
      "Epoch:  0009 D loss:-0.2512 G loss:-2.477\n",
      "Epoch:  0009 D loss:-0.3613 G loss:-2.508\n",
      "Epoch:  0009 D loss:-0.3982 G loss:-2.53\n",
      "Epoch:  0009 D loss:-0.346 G loss:-2.586\n",
      "Epoch:  0009 D loss:-0.3014 G loss:-2.506\n",
      "Epoch:  0009 D loss:-0.3506 G loss:-2.558\n",
      "Epoch:  0009 D loss:-0.2937 G loss:-2.528\n",
      "Epoch:  0009 D loss:-0.2963 G loss:-2.474\n",
      "Epoch:  0009 D loss:-0.3372 G loss:-2.421\n",
      "Epoch:  0009 D loss:-0.361 G loss:-2.428\n",
      "Epoch:  0009 D loss:-0.3227 G loss:-2.455\n",
      "Epoch:  0009 D loss:-0.3449 G loss:-2.571\n",
      "Epoch:  0009 D loss:-0.3553 G loss:-2.433\n",
      "Epoch:  0009 D loss:-0.2865 G loss:-2.454\n",
      "Epoch:  0009 D loss:-0.2993 G loss:-2.358\n",
      "Epoch:  0009 D loss:-0.2716 G loss:-2.478\n",
      "Epoch:  0009 D loss:-0.2368 G loss:-2.398\n",
      "Epoch:  0009 D loss:-0.3228 G loss:-2.557\n",
      "Epoch:  0009 D loss:-0.2458 G loss:-2.58\n",
      "Epoch:  0009 D loss:-0.2843 G loss:-2.638\n",
      "Epoch:  0009 D loss:-0.2483 G loss:-2.812\n",
      "Epoch:  0009 D loss:-0.3332 G loss:-2.68\n",
      "Epoch:  0009 D loss:-0.2831 G loss:-2.841\n",
      "Epoch:  0009 D loss:-0.2341 G loss:-2.695\n",
      "Epoch:  0009 D loss:-0.2509 G loss:-2.852\n",
      "Epoch:  0009 D loss:-0.2344 G loss:-2.697\n",
      "Epoch:  0009 D loss:-0.2725 G loss:-2.671\n",
      "Epoch:  0009 D loss:-0.287 G loss:-2.655\n",
      "Epoch:  0009 D loss:-0.2639 G loss:-2.585\n",
      "Epoch:  0009 D loss:-0.3086 G loss:-2.569\n",
      "Epoch:  0009 D loss:-0.2725 G loss:-2.53\n",
      "Epoch:  0009 D loss:-0.2654 G loss:-2.562\n",
      "Epoch:  0009 D loss:-0.3226 G loss:-2.621\n",
      "Epoch:  0009 D loss:-0.2735 G loss:-2.543\n",
      "Epoch:  0009 D loss:-0.2395 G loss:-2.456\n",
      "Epoch:  0009 D loss:-0.3815 G loss:-2.523\n",
      "Epoch:  0009 D loss:-0.2599 G loss:-2.573\n",
      "Epoch:  0009 D loss:-0.3193 G loss:-2.561\n",
      "Epoch:  0009 D loss:-0.2956 G loss:-2.519\n",
      "Epoch:  0009 D loss:-0.2731 G loss:-2.525\n",
      "Epoch:  0009 D loss:-0.3793 G loss:-2.49\n",
      "Epoch:  0009 D loss:-0.2638 G loss:-2.509\n",
      "Epoch:  0009 D loss:-0.3163 G loss:-2.578\n",
      "Epoch:  0009 D loss:-0.3626 G loss:-2.49\n",
      "Epoch:  0009 D loss:-0.3639 G loss:-2.424\n",
      "Epoch:  0009 D loss:-0.2613 G loss:-2.45\n",
      "Epoch:  0009 D loss:-0.3261 G loss:-2.425\n",
      "Epoch:  0009 D loss:-0.2853 G loss:-2.402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0009 D loss:-0.224 G loss:-2.482\n",
      "Epoch:  0009 D loss:-0.2584 G loss:-2.511\n",
      "Epoch:  0009 D loss:-0.2688 G loss:-2.547\n",
      "Epoch:  0009 D loss:-0.2885 G loss:-2.588\n",
      "Epoch:  0009 D loss:-0.3025 G loss:-2.64\n",
      "Epoch:  0009 D loss:-0.2412 G loss:-2.647\n",
      "Epoch:  0009 D loss:-0.2181 G loss:-2.707\n",
      "Epoch:  0009 D loss:-0.3121 G loss:-2.665\n",
      "Epoch:  0009 D loss:-0.2658 G loss:-2.614\n",
      "Epoch:  0009 D loss:-0.2274 G loss:-2.647\n",
      "Epoch:  0009 D loss:-0.3343 G loss:-2.701\n",
      "Epoch:  0009 D loss:-0.2328 G loss:-2.569\n",
      "Epoch:  0009 D loss:-0.3105 G loss:-2.481\n",
      "Epoch:  0009 D loss:-0.2381 G loss:-2.554\n",
      "Epoch:  0009 D loss:-0.2284 G loss:-2.521\n",
      "Epoch:  0009 D loss:-0.2408 G loss:-2.537\n",
      "Epoch:  0009 D loss:-0.2684 G loss:-2.536\n",
      "Epoch:  0009 D loss:-0.2251 G loss:-2.59\n",
      "Epoch:  0009 D loss:-0.2935 G loss:-2.691\n",
      "Epoch:  0009 D loss:-0.2473 G loss:-2.616\n",
      "Epoch:  0009 D loss:-0.2231 G loss:-2.758\n",
      "Epoch:  0009 D loss:-0.232 G loss:-2.772\n",
      "Epoch:  0009 D loss:-0.1902 G loss:-2.864\n",
      "Epoch:  0009 D loss:-0.2391 G loss:-2.847\n",
      "Epoch:  0009 D loss:-0.2702 G loss:-2.768\n",
      "Epoch:  0009 D loss:-0.2341 G loss:-2.796\n",
      "Epoch:  0009 D loss:-0.162 G loss:-2.835\n",
      "Epoch:  0009 D loss:-0.2401 G loss:-2.715\n",
      "Epoch:  0009 D loss:-0.1984 G loss:-2.75\n",
      "Epoch:  0009 D loss:-0.2336 G loss:-2.719\n",
      "Epoch:  0009 D loss:-0.211 G loss:-2.716\n",
      "Epoch:  0009 D loss:-0.1888 G loss:-2.771\n",
      "Epoch:  0009 D loss:-0.2422 G loss:-2.733\n",
      "Epoch:  0009 D loss:-0.263 G loss:-2.68\n",
      "Epoch:  0009 D loss:-0.246 G loss:-2.716\n",
      "Epoch:  0009 D loss:-0.234 G loss:-2.659\n",
      "Epoch:  0009 D loss:-0.1985 G loss:-2.646\n",
      "Epoch:  0009 D loss:-0.2371 G loss:-2.695\n",
      "Epoch:  0009 D loss:-0.2123 G loss:-2.647\n",
      "Epoch:  0009 D loss:-0.2318 G loss:-2.599\n",
      "Epoch:  0009 D loss:-0.2387 G loss:-2.618\n",
      "Epoch:  0009 D loss:-0.2392 G loss:-2.575\n",
      "Epoch:  0009 D loss:-0.2465 G loss:-2.485\n",
      "Epoch:  0009 D loss:-0.2705 G loss:-2.709\n",
      "Epoch:  0009 D loss:-0.2927 G loss:-2.635\n",
      "Epoch:  0009 D loss:-0.1802 G loss:-2.814\n",
      "Epoch:  0009 D loss:-0.2635 G loss:-2.89\n",
      "Epoch:  0009 D loss:-0.2112 G loss:-2.773\n",
      "Epoch:  0009 D loss:-0.2394 G loss:-2.774\n",
      "Epoch:  0009 D loss:-0.2103 G loss:-2.69\n",
      "Epoch:  0009 D loss:-0.2366 G loss:-2.705\n",
      "Epoch:  0009 D loss:-0.2061 G loss:-2.677\n",
      "Epoch:  0009 D loss:-0.2609 G loss:-2.696\n",
      "Epoch:  0009 D loss:-0.284 G loss:-2.63\n",
      "Epoch:  0009 D loss:-0.237 G loss:-2.642\n",
      "Epoch:  0009 D loss:-0.2395 G loss:-2.607\n",
      "Epoch:  0009 D loss:-0.2463 G loss:-2.702\n",
      "Epoch:  0009 D loss:-0.2564 G loss:-2.694\n",
      "Epoch:  0009 D loss:-0.2831 G loss:-2.686\n",
      "Epoch:  0009 D loss:-0.2955 G loss:-2.422\n",
      "Epoch:  0009 D loss:-0.2638 G loss:-2.497\n",
      "Epoch:  0009 D loss:-0.2385 G loss:-2.469\n",
      "Epoch:  0009 D loss:-0.2667 G loss:-2.538\n",
      "Epoch:  0009 D loss:-0.2752 G loss:-2.399\n",
      "Epoch:  0009 D loss:-0.2666 G loss:-2.552\n",
      "Epoch:  0009 D loss:-0.2695 G loss:-2.512\n",
      "Epoch:  0009 D loss:-0.201 G loss:-2.662\n",
      "Epoch:  0009 D loss:-0.268 G loss:-2.534\n",
      "Epoch:  0009 D loss:-0.2463 G loss:-2.685\n",
      "Epoch:  0009 D loss:-0.2452 G loss:-2.763\n",
      "Epoch:  0009 D loss:-0.2417 G loss:-2.761\n",
      "Epoch:  0009 D loss:-0.288 G loss:-2.774\n",
      "Epoch:  0009 D loss:-0.2972 G loss:-2.667\n",
      "Epoch:  0009 D loss:-0.2962 G loss:-2.559\n",
      "Epoch:  0009 D loss:-0.2303 G loss:-2.667\n",
      "Epoch:  0009 D loss:-0.2963 G loss:-2.465\n",
      "Epoch:  0009 D loss:-0.2317 G loss:-2.525\n",
      "Epoch:  0009 D loss:-0.2133 G loss:-2.412\n",
      "Epoch:  0009 D loss:-0.2354 G loss:-2.344\n",
      "Epoch:  0009 D loss:-0.2435 G loss:-2.504\n",
      "Epoch:  0009 D loss:-0.2595 G loss:-2.562\n",
      "Epoch:  0009 D loss:-0.2324 G loss:-2.597\n",
      "Epoch:  0010 D loss:-0.2227 G loss:-2.722\n",
      "Epoch:  0010 D loss:-0.216 G loss:-2.813\n",
      "Epoch:  0010 D loss:-0.2522 G loss:-2.793\n",
      "Epoch:  0010 D loss:-0.2731 G loss:-2.657\n",
      "Epoch:  0010 D loss:-0.2625 G loss:-2.779\n",
      "Epoch:  0010 D loss:-0.3076 G loss:-2.696\n",
      "Epoch:  0010 D loss:-0.2639 G loss:-2.613\n",
      "Epoch:  0010 D loss:-0.1947 G loss:-2.821\n",
      "Epoch:  0010 D loss:-0.2451 G loss:-2.599\n",
      "Epoch:  0010 D loss:-0.2835 G loss:-2.609\n",
      "Epoch:  0010 D loss:-0.2694 G loss:-2.514\n",
      "Epoch:  0010 D loss:-0.2512 G loss:-2.602\n",
      "Epoch:  0010 D loss:-0.241 G loss:-2.467\n",
      "Epoch:  0010 D loss:-0.2888 G loss:-2.57\n",
      "Epoch:  0010 D loss:-0.2575 G loss:-2.53\n",
      "Epoch:  0010 D loss:-0.231 G loss:-2.53\n",
      "Epoch:  0010 D loss:-0.2258 G loss:-2.582\n",
      "Epoch:  0010 D loss:-0.2869 G loss:-2.581\n",
      "Epoch:  0010 D loss:-0.2602 G loss:-2.551\n",
      "Epoch:  0010 D loss:-0.2573 G loss:-2.668\n",
      "Epoch:  0010 D loss:-0.2219 G loss:-2.769\n",
      "Epoch:  0010 D loss:-0.205 G loss:-2.759\n",
      "Epoch:  0010 D loss:-0.2457 G loss:-2.762\n",
      "Epoch:  0010 D loss:-0.285 G loss:-2.834\n",
      "Epoch:  0010 D loss:-0.2928 G loss:-2.751\n",
      "Epoch:  0010 D loss:-0.2061 G loss:-2.771\n",
      "Epoch:  0010 D loss:-0.2131 G loss:-2.724\n",
      "Epoch:  0010 D loss:-0.2419 G loss:-2.629\n",
      "Epoch:  0010 D loss:-0.225 G loss:-2.6\n",
      "Epoch:  0010 D loss:-0.2746 G loss:-2.589\n",
      "Epoch:  0010 D loss:-0.2126 G loss:-2.665\n",
      "Epoch:  0010 D loss:-0.2467 G loss:-2.576\n",
      "Epoch:  0010 D loss:-0.2759 G loss:-2.513\n",
      "Epoch:  0010 D loss:-0.2206 G loss:-2.614\n",
      "Epoch:  0010 D loss:-0.249 G loss:-2.597\n",
      "Epoch:  0010 D loss:-0.2558 G loss:-2.549\n",
      "Epoch:  0010 D loss:-0.2794 G loss:-2.638\n",
      "Epoch:  0010 D loss:-0.2536 G loss:-2.609\n",
      "Epoch:  0010 D loss:-0.2331 G loss:-2.73\n",
      "Epoch:  0010 D loss:-0.268 G loss:-2.713\n",
      "Epoch:  0010 D loss:-0.2785 G loss:-2.669\n",
      "Epoch:  0010 D loss:-0.2228 G loss:-2.703\n",
      "Epoch:  0010 D loss:-0.2601 G loss:-2.63\n",
      "Epoch:  0010 D loss:-0.2819 G loss:-2.614\n",
      "Epoch:  0010 D loss:-0.2541 G loss:-2.613\n",
      "Epoch:  0010 D loss:-0.311 G loss:-2.616\n",
      "Epoch:  0010 D loss:-0.2959 G loss:-2.459\n",
      "Epoch:  0010 D loss:-0.264 G loss:-2.624\n",
      "Epoch:  0010 D loss:-0.2945 G loss:-2.416\n",
      "Epoch:  0010 D loss:-0.251 G loss:-2.44\n",
      "Epoch:  0010 D loss:-0.3002 G loss:-2.539\n",
      "Epoch:  0010 D loss:-0.2558 G loss:-2.453\n",
      "Epoch:  0010 D loss:-0.2154 G loss:-2.545\n",
      "Epoch:  0010 D loss:-0.3089 G loss:-2.473\n",
      "Epoch:  0010 D loss:-0.277 G loss:-2.492\n",
      "Epoch:  0010 D loss:-0.3038 G loss:-2.524\n",
      "Epoch:  0010 D loss:-0.2999 G loss:-2.471\n",
      "Epoch:  0010 D loss:-0.2739 G loss:-2.572\n",
      "Epoch:  0010 D loss:-0.2672 G loss:-2.585\n",
      "Epoch:  0010 D loss:-0.2855 G loss:-2.535\n",
      "Epoch:  0010 D loss:-0.2743 G loss:-2.62\n",
      "Epoch:  0010 D loss:-0.2964 G loss:-2.596\n",
      "Epoch:  0010 D loss:-0.2774 G loss:-2.647\n",
      "Epoch:  0010 D loss:-0.2119 G loss:-2.694\n",
      "Epoch:  0010 D loss:-0.2322 G loss:-2.695\n",
      "Epoch:  0010 D loss:-0.2808 G loss:-2.627\n",
      "Epoch:  0010 D loss:-0.2635 G loss:-2.597\n",
      "Epoch:  0010 D loss:-0.2808 G loss:-2.55\n",
      "Epoch:  0010 D loss:-0.2593 G loss:-2.587\n",
      "Epoch:  0010 D loss:-0.2859 G loss:-2.5\n",
      "Epoch:  0010 D loss:-0.2933 G loss:-2.497\n",
      "Epoch:  0010 D loss:-0.3287 G loss:-2.514\n",
      "Epoch:  0010 D loss:-0.2554 G loss:-2.399\n",
      "Epoch:  0010 D loss:-0.3254 G loss:-2.34\n",
      "Epoch:  0010 D loss:-0.2617 G loss:-2.437\n",
      "Epoch:  0010 D loss:-0.3868 G loss:-2.321\n",
      "Epoch:  0010 D loss:-0.3315 G loss:-2.453\n",
      "Epoch:  0010 D loss:-0.2654 G loss:-2.433\n",
      "Epoch:  0010 D loss:-0.3009 G loss:-2.444\n",
      "Epoch:  0010 D loss:-0.2854 G loss:-2.458\n",
      "Epoch:  0010 D loss:-0.3913 G loss:-2.365\n",
      "Epoch:  0010 D loss:-0.2725 G loss:-2.521\n",
      "Epoch:  0010 D loss:-0.3387 G loss:-2.48\n",
      "Epoch:  0010 D loss:-0.3128 G loss:-2.484\n",
      "Epoch:  0010 D loss:-0.3503 G loss:-2.56\n",
      "Epoch:  0010 D loss:-0.3439 G loss:-2.434\n",
      "Epoch:  0010 D loss:-0.3415 G loss:-2.403\n",
      "Epoch:  0010 D loss:-0.3746 G loss:-2.237\n",
      "Epoch:  0010 D loss:-0.3371 G loss:-2.314\n",
      "Epoch:  0010 D loss:-0.3753 G loss:-2.235\n",
      "Epoch:  0010 D loss:-0.4723 G loss:-2.091\n",
      "Epoch:  0010 D loss:-0.2888 G loss:-2.226\n",
      "Epoch:  0010 D loss:-0.3542 G loss:-2.239\n",
      "Epoch:  0010 D loss:-0.2977 G loss:-2.408\n",
      "Epoch:  0010 D loss:-0.382 G loss:-2.373\n",
      "Epoch:  0010 D loss:-0.3415 G loss:-2.371\n",
      "Epoch:  0010 D loss:-0.2845 G loss:-2.4\n",
      "Epoch:  0010 D loss:-0.317 G loss:-2.473\n",
      "Epoch:  0010 D loss:-0.3915 G loss:-2.385\n",
      "Epoch:  0010 D loss:-0.3265 G loss:-2.396\n",
      "Epoch:  0010 D loss:-0.31 G loss:-2.654\n",
      "Epoch:  0010 D loss:-0.3543 G loss:-2.306\n",
      "Epoch:  0010 D loss:-0.3519 G loss:-2.456\n",
      "Epoch:  0010 D loss:-0.348 G loss:-2.307\n",
      "Epoch:  0010 D loss:-0.2779 G loss:-2.46\n",
      "Epoch:  0010 D loss:-0.3247 G loss:-2.392\n",
      "Epoch:  0010 D loss:-0.3339 G loss:-2.358\n",
      "Epoch:  0010 D loss:-0.3935 G loss:-2.218\n",
      "Epoch:  0010 D loss:-0.345 G loss:-2.306\n",
      "Epoch:  0010 D loss:-0.3515 G loss:-2.207\n",
      "Epoch:  0010 D loss:-0.4329 G loss:-2.176\n",
      "Epoch:  0010 D loss:-0.2895 G loss:-2.327\n",
      "Epoch:  0010 D loss:-0.3266 G loss:-2.446\n",
      "Epoch:  0010 D loss:-0.3729 G loss:-2.31\n",
      "Epoch:  0010 D loss:-0.3906 G loss:-2.362\n",
      "Epoch:  0010 D loss:-0.3432 G loss:-2.362\n",
      "Epoch:  0010 D loss:-0.3792 G loss:-2.44\n",
      "Epoch:  0010 D loss:-0.3323 G loss:-2.337\n",
      "Epoch:  0010 D loss:-0.3667 G loss:-2.353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0010 D loss:-0.3617 G loss:-2.289\n",
      "Epoch:  0010 D loss:-0.3596 G loss:-2.253\n",
      "Epoch:  0010 D loss:-0.3492 G loss:-2.272\n",
      "Epoch:  0010 D loss:-0.4129 G loss:-2.199\n",
      "Epoch:  0010 D loss:-0.3651 G loss:-2.188\n",
      "Epoch:  0010 D loss:-0.3321 G loss:-2.265\n",
      "Epoch:  0010 D loss:-0.3844 G loss:-2.242\n",
      "Epoch:  0010 D loss:-0.3158 G loss:-2.266\n",
      "Epoch:  0010 D loss:-0.4018 G loss:-2.244\n",
      "Epoch:  0010 D loss:-0.3459 G loss:-2.277\n",
      "Epoch:  0010 D loss:-0.3018 G loss:-2.408\n",
      "Epoch:  0010 D loss:-0.3097 G loss:-2.431\n",
      "Epoch:  0010 D loss:-0.3467 G loss:-2.418\n",
      "Epoch:  0010 D loss:-0.3789 G loss:-2.286\n",
      "Epoch:  0010 D loss:-0.2891 G loss:-2.418\n",
      "Epoch:  0010 D loss:-0.3468 G loss:-2.405\n",
      "Epoch:  0010 D loss:-0.3208 G loss:-2.409\n",
      "Epoch:  0010 D loss:-0.3509 G loss:-2.478\n",
      "Epoch:  0010 D loss:-0.3201 G loss:-2.444\n",
      "Epoch:  0010 D loss:-0.3526 G loss:-2.428\n",
      "Epoch:  0010 D loss:-0.3192 G loss:-2.417\n",
      "Epoch:  0010 D loss:-0.3909 G loss:-2.176\n",
      "Epoch:  0010 D loss:-0.3825 G loss:-2.191\n",
      "Epoch:  0010 D loss:-0.3638 G loss:-2.261\n",
      "Epoch:  0010 D loss:-0.3557 G loss:-2.332\n",
      "Epoch:  0010 D loss:-0.3657 G loss:-2.284\n",
      "Epoch:  0010 D loss:-0.3389 G loss:-2.257\n",
      "Epoch:  0010 D loss:-0.3428 G loss:-2.221\n",
      "Epoch:  0010 D loss:-0.345 G loss:-2.171\n",
      "Epoch:  0010 D loss:-0.421 G loss:-2.07\n",
      "Epoch:  0010 D loss:-0.3421 G loss:-2.422\n",
      "Epoch:  0010 D loss:-0.3844 G loss:-2.341\n",
      "Epoch:  0010 D loss:-0.5538 G loss:-2.255\n",
      "Epoch:  0010 D loss:-0.3979 G loss:-2.334\n",
      "Epoch:  0010 D loss:-0.4093 G loss:-2.289\n",
      "Epoch:  0010 D loss:-0.3743 G loss:-2.273\n",
      "Epoch:  0010 D loss:-0.3993 G loss:-2.15\n",
      "Epoch:  0010 D loss:-0.4514 G loss:-2.124\n",
      "Epoch:  0010 D loss:-0.3598 G loss:-2.286\n",
      "Epoch:  0010 D loss:-0.4589 G loss:-2.105\n",
      "Epoch:  0010 D loss:-0.4024 G loss:-2.111\n",
      "Epoch:  0010 D loss:-0.4126 G loss:-2.065\n",
      "Epoch:  0010 D loss:-0.4829 G loss:-2.018\n",
      "Epoch:  0010 D loss:-0.3737 G loss:-2.197\n",
      "Epoch:  0010 D loss:-0.451 G loss:-2.279\n",
      "Epoch:  0010 D loss:-0.4244 G loss:-2.135\n",
      "Epoch:  0010 D loss:-0.4042 G loss:-2.299\n",
      "Epoch:  0010 D loss:-0.4847 G loss:-2.175\n",
      "Epoch:  0010 D loss:-0.4942 G loss:-2.21\n",
      "Epoch:  0010 D loss:-0.5258 G loss:-2.117\n",
      "Epoch:  0010 D loss:-0.4803 G loss:-2.094\n",
      "Epoch:  0010 D loss:-0.4664 G loss:-2.212\n",
      "Epoch:  0010 D loss:-0.5014 G loss:-2.065\n",
      "Epoch:  0010 D loss:-0.4025 G loss:-2.125\n",
      "Epoch:  0010 D loss:-0.4519 G loss:-2.009\n",
      "Epoch:  0010 D loss:-0.4802 G loss:-2.167\n",
      "Epoch:  0010 D loss:-0.4103 G loss:-2.219\n",
      "Epoch:  0010 D loss:-0.4007 G loss:-2.291\n",
      "Epoch:  0010 D loss:-0.4758 G loss:-2.264\n",
      "Epoch:  0010 D loss:-0.3929 G loss:-2.329\n",
      "Epoch:  0010 D loss:-0.5102 G loss:-2.315\n",
      "Epoch:  0010 D loss:-0.5402 G loss:-2.079\n",
      "Epoch:  0010 D loss:-0.5144 G loss:-2.332\n",
      "Epoch:  0010 D loss:-0.4756 G loss:-2.293\n",
      "Epoch:  0010 D loss:-0.3804 G loss:-2.329\n",
      "Epoch:  0010 D loss:-0.404 G loss:-2.281\n",
      "Epoch:  0010 D loss:-0.4585 G loss:-2.303\n",
      "Epoch:  0010 D loss:-0.449 G loss:-2.306\n",
      "Epoch:  0010 D loss:-0.3703 G loss:-2.373\n",
      "Epoch:  0010 D loss:-0.4155 G loss:-2.428\n",
      "Epoch:  0010 D loss:-0.3652 G loss:-2.449\n",
      "Epoch:  0010 D loss:-0.3862 G loss:-2.433\n",
      "Epoch:  0010 D loss:-0.4822 G loss:-2.271\n",
      "Epoch:  0010 D loss:-0.3664 G loss:-2.449\n",
      "Epoch:  0010 D loss:-0.3315 G loss:-2.448\n",
      "Epoch:  0010 D loss:-0.4029 G loss:-2.591\n",
      "Epoch:  0010 D loss:-0.4397 G loss:-2.475\n",
      "Epoch:  0010 D loss:-0.5377 G loss:-2.479\n",
      "Epoch:  0010 D loss:-0.3757 G loss:-2.463\n",
      "Epoch:  0010 D loss:-0.3691 G loss:-2.383\n",
      "Epoch:  0010 D loss:-0.3211 G loss:-2.523\n",
      "Epoch:  0010 D loss:-0.3336 G loss:-2.512\n",
      "Epoch:  0010 D loss:-0.2909 G loss:-2.533\n",
      "Epoch:  0010 D loss:-0.3416 G loss:-2.482\n",
      "Epoch:  0010 D loss:-0.3036 G loss:-2.666\n",
      "Epoch:  0010 D loss:-0.3112 G loss:-2.66\n",
      "Epoch:  0010 D loss:-0.3409 G loss:-2.591\n",
      "Epoch:  0010 D loss:-0.317 G loss:-2.624\n",
      "Epoch:  0010 D loss:-0.3494 G loss:-2.61\n",
      "Epoch:  0010 D loss:-0.2802 G loss:-2.95\n",
      "Epoch:  0010 D loss:-0.3163 G loss:-2.803\n",
      "Epoch:  0010 D loss:-0.3903 G loss:-2.841\n",
      "Epoch:  0010 D loss:-0.333 G loss:-2.554\n",
      "Epoch:  0010 D loss:-0.2621 G loss:-2.913\n",
      "Epoch:  0010 D loss:-0.3209 G loss:-2.68\n",
      "Epoch:  0010 D loss:-0.3525 G loss:-2.572\n",
      "Epoch:  0010 D loss:-0.3357 G loss:-2.646\n",
      "Epoch:  0010 D loss:-0.3661 G loss:-2.595\n",
      "Epoch:  0010 D loss:-0.3245 G loss:-2.526\n",
      "Epoch:  0010 D loss:-0.3231 G loss:-2.524\n",
      "Epoch:  0010 D loss:-0.4652 G loss:-2.353\n",
      "Epoch:  0010 D loss:-0.4273 G loss:-2.456\n",
      "Epoch:  0010 D loss:-0.4193 G loss:-2.387\n",
      "Epoch:  0010 D loss:-0.3884 G loss:-2.381\n",
      "Epoch:  0010 D loss:-0.3726 G loss:-2.386\n",
      "Epoch:  0010 D loss:-0.2851 G loss:-2.369\n",
      "Epoch:  0010 D loss:-0.4195 G loss:-2.117\n",
      "Epoch:  0010 D loss:-0.3574 G loss:-2.565\n",
      "Epoch:  0010 D loss:-0.4324 G loss:-2.442\n",
      "Epoch:  0010 D loss:-0.2355 G loss:-2.668\n",
      "Epoch:  0010 D loss:-0.3552 G loss:-2.715\n",
      "Epoch:  0010 D loss:-0.4311 G loss:-2.706\n",
      "Epoch:  0010 D loss:-0.3366 G loss:-2.543\n",
      "Epoch:  0010 D loss:-0.3619 G loss:-2.372\n",
      "Epoch:  0010 D loss:-0.2989 G loss:-2.647\n",
      "Epoch:  0010 D loss:-0.2913 G loss:-2.522\n",
      "Epoch:  0010 D loss:-0.3087 G loss:-2.513\n",
      "Epoch:  0010 D loss:-0.3026 G loss:-2.42\n",
      "Epoch:  0010 D loss:-0.362 G loss:-2.435\n",
      "Epoch:  0010 D loss:-0.3389 G loss:-2.565\n",
      "Epoch:  0010 D loss:-0.383 G loss:-2.529\n",
      "Epoch:  0010 D loss:-0.301 G loss:-2.555\n",
      "Epoch:  0010 D loss:-0.327 G loss:-2.538\n",
      "Epoch:  0010 D loss:-0.3564 G loss:-2.59\n",
      "Epoch:  0010 D loss:-0.4227 G loss:-2.337\n",
      "Epoch:  0010 D loss:-0.4941 G loss:-2.385\n",
      "Epoch:  0010 D loss:-0.3718 G loss:-2.256\n",
      "Epoch:  0010 D loss:-0.3806 G loss:-2.176\n",
      "Epoch:  0010 D loss:-0.4228 G loss:-2.17\n",
      "Epoch:  0010 D loss:-0.3558 G loss:-2.209\n",
      "Epoch:  0010 D loss:-0.4148 G loss:-2.121\n",
      "Epoch:  0010 D loss:-0.4716 G loss:-2.156\n",
      "Epoch:  0010 D loss:-0.3611 G loss:-2.328\n",
      "Epoch:  0010 D loss:-0.5193 G loss:-2.279\n",
      "Epoch:  0010 D loss:-0.3857 G loss:-2.486\n",
      "Epoch:  0010 D loss:-0.3951 G loss:-2.24\n",
      "Epoch:  0010 D loss:-0.3995 G loss:-2.371\n",
      "Epoch:  0010 D loss:-0.4484 G loss:-2.29\n",
      "Epoch:  0010 D loss:-0.4826 G loss:-2.371\n",
      "Epoch:  0010 D loss:-0.4143 G loss:-2.351\n",
      "Epoch:  0010 D loss:-0.428 G loss:-2.27\n",
      "Epoch:  0010 D loss:-0.5273 G loss:-2.203\n",
      "Epoch:  0010 D loss:-0.4262 G loss:-2.03\n",
      "Epoch:  0010 D loss:-0.435 G loss:-2.242\n",
      "Epoch:  0010 D loss:-0.4106 G loss:-2.004\n",
      "Epoch:  0010 D loss:-0.4519 G loss:-2.062\n",
      "Epoch:  0010 D loss:-0.389 G loss:-2.136\n",
      "Epoch:  0010 D loss:-0.4153 G loss:-2.166\n",
      "Epoch:  0010 D loss:-0.5399 G loss:-2.108\n",
      "Epoch:  0010 D loss:-0.518 G loss:-2.046\n",
      "Epoch:  0010 D loss:-0.4521 G loss:-2.171\n",
      "Epoch:  0010 D loss:-0.4253 G loss:-2.219\n",
      "Epoch:  0010 D loss:-0.4656 G loss:-2.238\n",
      "Epoch:  0010 D loss:-0.4527 G loss:-2.373\n",
      "Epoch:  0010 D loss:-0.5253 G loss:-2.474\n",
      "Epoch:  0010 D loss:-0.3818 G loss:-2.483\n",
      "Epoch:  0010 D loss:-0.4015 G loss:-2.529\n",
      "Epoch:  0010 D loss:-0.4356 G loss:-2.49\n",
      "Epoch:  0010 D loss:-0.3953 G loss:-2.646\n",
      "Epoch:  0010 D loss:-0.4054 G loss:-2.404\n",
      "Epoch:  0010 D loss:-0.4481 G loss:-2.313\n",
      "Epoch:  0010 D loss:-0.4049 G loss:-2.258\n",
      "Epoch:  0010 D loss:-0.3823 G loss:-2.33\n",
      "Epoch:  0010 D loss:-0.4318 G loss:-2.059\n",
      "Epoch:  0010 D loss:-0.4536 G loss:-2.085\n",
      "Epoch:  0010 D loss:-0.4102 G loss:-2.125\n",
      "Epoch:  0010 D loss:-0.4665 G loss:-2.073\n",
      "Epoch:  0010 D loss:-0.5101 G loss:-2.283\n",
      "Epoch:  0010 D loss:-0.4524 G loss:-2.27\n",
      "Epoch:  0010 D loss:-0.4929 G loss:-2.261\n",
      "Epoch:  0010 D loss:-0.5358 G loss:-2.198\n",
      "Epoch:  0010 D loss:-0.3687 G loss:-2.431\n",
      "Epoch:  0010 D loss:-0.4735 G loss:-2.219\n",
      "Epoch:  0010 D loss:-0.4218 G loss:-2.225\n",
      "Epoch:  0010 D loss:-0.4138 G loss:-2.247\n",
      "Epoch:  0010 D loss:-0.5506 G loss:-2.188\n",
      "Epoch:  0010 D loss:-0.4661 G loss:-2.063\n",
      "Epoch:  0010 D loss:-0.4831 G loss:-2.179\n",
      "Epoch:  0010 D loss:-0.4913 G loss:-2.081\n",
      "Epoch:  0010 D loss:-0.4982 G loss:-2.101\n",
      "Epoch:  0010 D loss:-0.423 G loss:-2.016\n",
      "Epoch:  0010 D loss:-0.4532 G loss:-2.132\n",
      "Epoch:  0010 D loss:-0.4854 G loss:-2.012\n",
      "Epoch:  0010 D loss:-0.5906 G loss:-2.107\n",
      "Epoch:  0010 D loss:-0.5139 G loss:-2.05\n",
      "Epoch:  0010 D loss:-0.6141 G loss:-1.881\n",
      "Epoch:  0010 D loss:-0.5597 G loss:-2.016\n",
      "Epoch:  0010 D loss:-0.4807 G loss:-2.033\n",
      "Epoch:  0010 D loss:-0.5913 G loss:-1.928\n",
      "Epoch:  0010 D loss:-0.5109 G loss:-1.954\n",
      "Epoch:  0010 D loss:-0.5828 G loss:-1.868\n",
      "Epoch:  0010 D loss:-0.5337 G loss:-1.9\n",
      "Epoch:  0010 D loss:-0.56 G loss:-1.955\n",
      "Epoch:  0010 D loss:-0.5526 G loss:-2.028\n",
      "Epoch:  0010 D loss:-0.5528 G loss:-1.975\n",
      "Epoch:  0010 D loss:-0.6236 G loss:-1.902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0010 D loss:-0.5043 G loss:-2.174\n",
      "Epoch:  0010 D loss:-0.5292 G loss:-2.006\n",
      "Epoch:  0010 D loss:-0.6236 G loss:-2.023\n",
      "Epoch:  0010 D loss:-0.4869 G loss:-2.121\n",
      "Epoch:  0010 D loss:-0.4488 G loss:-2.071\n",
      "Epoch:  0010 D loss:-0.5174 G loss:-2.097\n",
      "Epoch:  0010 D loss:-0.547 G loss:-1.987\n",
      "Epoch:  0010 D loss:-0.5853 G loss:-2.073\n",
      "Epoch:  0010 D loss:-0.5599 G loss:-1.933\n",
      "Epoch:  0010 D loss:-0.5382 G loss:-1.882\n",
      "Epoch:  0010 D loss:-0.5885 G loss:-1.962\n",
      "Epoch:  0010 D loss:-0.5599 G loss:-1.827\n",
      "Epoch:  0010 D loss:-0.5663 G loss:-1.864\n",
      "Epoch:  0010 D loss:-0.5674 G loss:-1.89\n",
      "Epoch:  0010 D loss:-0.5325 G loss:-2.022\n",
      "Epoch:  0010 D loss:-0.5369 G loss:-1.92\n",
      "Epoch:  0010 D loss:-0.5167 G loss:-1.96\n",
      "Epoch:  0010 D loss:-0.4276 G loss:-2.084\n",
      "Epoch:  0010 D loss:-0.534 G loss:-2.052\n",
      "Epoch:  0010 D loss:-0.5933 G loss:-2.216\n",
      "Epoch:  0010 D loss:-0.5933 G loss:-2.118\n",
      "Epoch:  0010 D loss:-0.5095 G loss:-2.048\n",
      "Epoch:  0010 D loss:-0.4562 G loss:-2.19\n",
      "Epoch:  0010 D loss:-0.4058 G loss:-2.229\n",
      "Epoch:  0010 D loss:-0.4983 G loss:-2.056\n",
      "Epoch:  0010 D loss:-0.4624 G loss:-2.064\n",
      "Epoch:  0010 D loss:-0.4643 G loss:-1.953\n",
      "Epoch:  0010 D loss:-0.573 G loss:-1.944\n",
      "Epoch:  0010 D loss:-0.4503 G loss:-1.998\n",
      "Epoch:  0010 D loss:-0.4705 G loss:-2.104\n",
      "Epoch:  0010 D loss:-0.5543 G loss:-1.923\n",
      "Epoch:  0010 D loss:-0.5693 G loss:-2.025\n",
      "Epoch:  0010 D loss:-0.5106 G loss:-2.052\n",
      "Epoch:  0010 D loss:-0.4471 G loss:-2.027\n",
      "Epoch:  0010 D loss:-0.5108 G loss:-2.194\n",
      "Epoch:  0010 D loss:-0.5913 G loss:-2.167\n",
      "Epoch:  0010 D loss:-0.5047 G loss:-2.096\n",
      "Epoch:  0010 D loss:-0.487 G loss:-1.963\n",
      "Epoch:  0010 D loss:-0.4791 G loss:-2.165\n",
      "Epoch:  0010 D loss:-0.4943 G loss:-2.091\n",
      "Epoch:  0010 D loss:-0.5074 G loss:-2.13\n",
      "Epoch:  0010 D loss:-0.4942 G loss:-2.17\n",
      "Epoch:  0010 D loss:-0.4952 G loss:-2.069\n",
      "Epoch:  0010 D loss:-0.5035 G loss:-2.084\n",
      "Epoch:  0010 D loss:-0.4716 G loss:-2.004\n",
      "Epoch:  0010 D loss:-0.5847 G loss:-2.026\n",
      "Epoch:  0010 D loss:-0.4979 G loss:-2.076\n",
      "Epoch:  0010 D loss:-0.4564 G loss:-1.976\n",
      "Epoch:  0010 D loss:-0.4914 G loss:-2.145\n",
      "Epoch:  0010 D loss:-0.4945 G loss:-1.991\n",
      "Epoch:  0010 D loss:-0.4253 G loss:-2.089\n",
      "Epoch:  0010 D loss:-0.4794 G loss:-1.997\n",
      "Epoch:  0010 D loss:-0.465 G loss:-2.088\n",
      "Epoch:  0010 D loss:-0.4502 G loss:-2.003\n",
      "Epoch:  0010 D loss:-0.4095 G loss:-2.161\n",
      "Epoch:  0010 D loss:-0.4944 G loss:-2.283\n",
      "Epoch:  0010 D loss:-0.5211 G loss:-2.155\n",
      "Epoch:  0010 D loss:-0.5032 G loss:-2.068\n",
      "Epoch:  0010 D loss:-0.4277 G loss:-2.251\n",
      "Epoch:  0010 D loss:-0.4955 G loss:-2.25\n",
      "Epoch:  0010 D loss:-0.4797 G loss:-2.361\n",
      "Epoch:  0010 D loss:-0.5336 G loss:-2.106\n",
      "Epoch:  0010 D loss:-0.4525 G loss:-2.171\n",
      "Epoch:  0010 D loss:-0.5466 G loss:-2.077\n",
      "Epoch:  0010 D loss:-0.4124 G loss:-2.101\n",
      "Epoch:  0010 D loss:-0.4352 G loss:-2.0\n",
      "Epoch:  0010 D loss:-0.4653 G loss:-2.047\n",
      "Epoch:  0010 D loss:-0.4965 G loss:-1.853\n",
      "Epoch:  0010 D loss:-0.377 G loss:-2.019\n",
      "Epoch:  0010 D loss:-0.3609 G loss:-2.158\n",
      "Epoch:  0010 D loss:-0.4272 G loss:-2.351\n",
      "Epoch:  0010 D loss:-0.4542 G loss:-2.294\n",
      "Epoch:  0010 D loss:-0.4252 G loss:-2.317\n",
      "Epoch:  0010 D loss:-0.4127 G loss:-2.291\n",
      "Epoch:  0010 D loss:-0.432 G loss:-2.443\n",
      "Epoch:  0010 D loss:-0.4238 G loss:-2.193\n",
      "Epoch:  0010 D loss:-0.365 G loss:-2.307\n",
      "Epoch:  0010 D loss:-0.3806 G loss:-2.332\n",
      "Epoch:  0010 D loss:-0.365 G loss:-2.374\n",
      "Epoch:  0010 D loss:-0.31 G loss:-2.491\n",
      "Epoch:  0010 D loss:-0.3378 G loss:-2.385\n",
      "Epoch:  0010 D loss:-0.4141 G loss:-2.212\n",
      "Epoch:  0010 D loss:-0.458 G loss:-2.106\n",
      "Epoch:  0010 D loss:-0.334 G loss:-2.217\n",
      "Epoch:  0010 D loss:-0.3989 G loss:-2.343\n",
      "Epoch:  0010 D loss:-0.3818 G loss:-2.129\n",
      "Epoch:  0010 D loss:-0.3801 G loss:-2.345\n",
      "Epoch:  0010 D loss:-0.3726 G loss:-2.266\n",
      "Epoch:  0010 D loss:-0.331 G loss:-2.357\n",
      "Epoch:  0010 D loss:-0.3562 G loss:-2.311\n",
      "Epoch:  0010 D loss:-0.394 G loss:-2.346\n",
      "Epoch:  0010 D loss:-0.3854 G loss:-2.239\n",
      "Epoch:  0010 D loss:-0.3558 G loss:-2.247\n",
      "Epoch:  0010 D loss:-0.4095 G loss:-2.361\n",
      "Epoch:  0010 D loss:-0.3564 G loss:-2.226\n",
      "Epoch:  0010 D loss:-0.4 G loss:-2.23\n",
      "Epoch:  0010 D loss:-0.3612 G loss:-2.371\n",
      "Epoch:  0010 D loss:-0.3451 G loss:-2.266\n",
      "Epoch:  0010 D loss:-0.3694 G loss:-2.26\n",
      "Epoch:  0010 D loss:-0.3659 G loss:-2.223\n",
      "Epoch:  0010 D loss:-0.3586 G loss:-2.2\n",
      "Epoch:  0010 D loss:-0.4528 G loss:-2.417\n",
      "Epoch:  0010 D loss:-0.3861 G loss:-2.333\n",
      "Epoch:  0010 D loss:-0.3579 G loss:-2.278\n",
      "Epoch:  0010 D loss:-0.3756 G loss:-2.243\n",
      "Epoch:  0010 D loss:-0.3617 G loss:-2.232\n",
      "Epoch:  0010 D loss:-0.4334 G loss:-2.151\n",
      "Epoch:  0010 D loss:-0.4053 G loss:-2.22\n",
      "Epoch:  0010 D loss:-0.428 G loss:-2.276\n",
      "Epoch:  0010 D loss:-0.3407 G loss:-2.228\n",
      "Epoch:  0010 D loss:-0.3571 G loss:-2.313\n",
      "Epoch:  0010 D loss:-0.4318 G loss:-2.3\n",
      "Epoch:  0010 D loss:-0.4238 G loss:-2.231\n",
      "Epoch:  0010 D loss:-0.4404 G loss:-2.201\n",
      "Epoch:  0010 D loss:-0.4462 G loss:-2.137\n",
      "Epoch:  0010 D loss:-0.4034 G loss:-2.192\n",
      "Epoch:  0010 D loss:-0.5011 G loss:-2.02\n",
      "Epoch:  0010 D loss:-0.3797 G loss:-2.006\n",
      "Epoch:  0010 D loss:-0.4479 G loss:-1.995\n",
      "Epoch:  0010 D loss:-0.4298 G loss:-2.026\n",
      "Epoch:  0010 D loss:-0.4886 G loss:-1.952\n",
      "Epoch:  0010 D loss:-0.4938 G loss:-1.942\n",
      "Epoch:  0010 D loss:-0.4459 G loss:-1.991\n",
      "Epoch:  0010 D loss:-0.4322 G loss:-2.049\n",
      "Epoch:  0010 D loss:-0.3998 G loss:-2.118\n",
      "Epoch:  0010 D loss:-0.4868 G loss:-1.969\n",
      "Epoch:  0010 D loss:-0.4204 G loss:-2.114\n",
      "Epoch:  0010 D loss:-0.3883 G loss:-2.153\n",
      "Epoch:  0010 D loss:-0.4079 G loss:-2.147\n",
      "Epoch:  0010 D loss:-0.4249 G loss:-2.044\n",
      "Epoch:  0010 D loss:-0.4039 G loss:-2.13\n",
      "Epoch:  0010 D loss:-0.4685 G loss:-2.054\n",
      "Epoch:  0010 D loss:-0.5164 G loss:-2.111\n",
      "Epoch:  0010 D loss:-0.4692 G loss:-2.053\n",
      "Epoch:  0010 D loss:-0.4425 G loss:-2.071\n",
      "Epoch:  0010 D loss:-0.5042 G loss:-1.961\n",
      "Epoch:  0010 D loss:-0.4586 G loss:-1.893\n",
      "Epoch:  0010 D loss:-0.4068 G loss:-1.899\n",
      "Epoch:  0010 D loss:-0.509 G loss:-1.825\n",
      "Epoch:  0010 D loss:-0.5056 G loss:-1.875\n",
      "Epoch:  0010 D loss:-0.4937 G loss:-1.948\n",
      "Epoch:  0010 D loss:-0.4896 G loss:-1.968\n",
      "Epoch:  0010 D loss:-0.5113 G loss:-1.909\n",
      "Epoch:  0010 D loss:-0.5371 G loss:-1.966\n",
      "Epoch:  0010 D loss:-0.4261 G loss:-1.927\n",
      "Epoch:  0010 D loss:-0.4325 G loss:-2.045\n",
      "Epoch:  0010 D loss:-0.5456 G loss:-2.042\n",
      "Epoch:  0010 D loss:-0.6366 G loss:-1.888\n",
      "Epoch:  0010 D loss:-0.5329 G loss:-1.904\n",
      "Epoch:  0010 D loss:-0.4945 G loss:-1.886\n",
      "Epoch:  0010 D loss:-0.5071 G loss:-1.742\n",
      "Epoch:  0010 D loss:-0.4776 G loss:-1.909\n",
      "Epoch:  0010 D loss:-0.5208 G loss:-1.775\n",
      "Epoch:  0010 D loss:-0.6003 G loss:-1.774\n",
      "Epoch:  0010 D loss:-0.597 G loss:-1.82\n",
      "Epoch:  0010 D loss:-0.6188 G loss:-1.875\n",
      "Epoch:  0010 D loss:-0.5117 G loss:-1.786\n",
      "Epoch:  0010 D loss:-0.5625 G loss:-1.82\n",
      "Epoch:  0010 D loss:-0.5364 G loss:-1.788\n",
      "Epoch:  0010 D loss:-0.5468 G loss:-1.86\n",
      "Epoch:  0010 D loss:-0.5339 G loss:-1.981\n",
      "Epoch:  0010 D loss:-0.5084 G loss:-2.055\n",
      "Epoch:  0010 D loss:-0.5691 G loss:-1.843\n",
      "Epoch:  0010 D loss:-0.5124 G loss:-1.981\n",
      "Epoch:  0010 D loss:-0.5929 G loss:-1.864\n",
      "Epoch:  0010 D loss:-0.5101 G loss:-1.946\n",
      "Epoch:  0010 D loss:-0.5663 G loss:-1.915\n",
      "Epoch:  0010 D loss:-0.5344 G loss:-1.82\n",
      "Epoch:  0010 D loss:-0.5222 G loss:-1.8\n",
      "Epoch:  0010 D loss:-0.5404 G loss:-1.754\n",
      "Epoch:  0010 D loss:-0.492 G loss:-1.876\n",
      "Epoch:  0010 D loss:-0.5438 G loss:-1.88\n",
      "Epoch:  0010 D loss:-0.5866 G loss:-2.058\n",
      "Epoch:  0010 D loss:-0.4775 G loss:-2.048\n",
      "Epoch:  0010 D loss:-0.4896 G loss:-2.07\n",
      "Epoch:  0010 D loss:-0.5689 G loss:-1.997\n",
      "Epoch:  0010 D loss:-0.5308 G loss:-2.047\n",
      "Epoch:  0010 D loss:-0.5168 G loss:-1.972\n",
      "Epoch:  0010 D loss:-0.5117 G loss:-1.902\n",
      "Epoch:  0010 D loss:-0.5103 G loss:-1.927\n",
      "Epoch:  0010 D loss:-0.4837 G loss:-1.937\n",
      "Epoch:  0010 D loss:-0.5131 G loss:-1.873\n",
      "Epoch:  0010 D loss:-0.4175 G loss:-1.993\n",
      "Epoch:  0010 D loss:-0.4291 G loss:-2.065\n",
      "Epoch:  0010 D loss:-0.5189 G loss:-1.992\n",
      "Epoch:  0010 D loss:-0.4198 G loss:-2.118\n",
      "Epoch:  0010 D loss:-0.4752 G loss:-2.048\n",
      "Epoch:  0010 D loss:-0.488 G loss:-1.974\n",
      "Epoch:  0010 D loss:-0.4513 G loss:-2.155\n",
      "Epoch:  0010 D loss:-0.3987 G loss:-2.294\n",
      "Epoch:  0010 D loss:-0.4864 G loss:-2.244\n",
      "Epoch:  0010 D loss:-0.4808 G loss:-2.129\n",
      "Epoch:  0010 D loss:-0.5379 G loss:-2.118\n",
      "Epoch:  0010 D loss:-0.5989 G loss:-2.074\n",
      "Epoch:  0010 D loss:-0.432 G loss:-1.962\n",
      "Epoch:  0010 D loss:-0.5607 G loss:-1.835\n",
      "Epoch:  0010 D loss:-0.5008 G loss:-1.86\n",
      "Epoch:  0010 D loss:-0.4971 G loss:-1.882\n",
      "Epoch:  0010 D loss:-0.481 G loss:-2.067\n",
      "Epoch:  0010 D loss:-0.4449 G loss:-2.0\n",
      "Epoch:  0010 D loss:-0.4842 G loss:-2.077\n",
      "Epoch:  0010 D loss:-0.503 G loss:-2.128\n",
      "Epoch:  0010 D loss:-0.5079 G loss:-1.976\n",
      "Epoch:  0010 D loss:-0.4554 G loss:-2.189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0010 D loss:-0.48 G loss:-2.14\n",
      "Epoch:  0010 D loss:-0.4624 G loss:-2.18\n",
      "Epoch:  0010 D loss:-0.4125 G loss:-2.217\n",
      "Epoch:  0010 D loss:-0.407 G loss:-2.337\n",
      "Epoch:  0010 D loss:-0.432 G loss:-2.274\n",
      "Epoch:  0010 D loss:-0.4355 G loss:-2.033\n",
      "Epoch:  0010 D loss:-0.4455 G loss:-2.154\n",
      "Epoch:  0010 D loss:-0.4544 G loss:-2.1\n",
      "Epoch:  0010 D loss:-0.4884 G loss:-2.209\n",
      "Epoch:  0010 D loss:-0.4472 G loss:-2.242\n",
      "Epoch:  0010 D loss:-0.4001 G loss:-2.165\n",
      "Epoch:  0010 D loss:-0.3646 G loss:-2.196\n",
      "Epoch:  0010 D loss:-0.4403 G loss:-2.301\n",
      "Epoch:  0010 D loss:-0.3491 G loss:-2.358\n",
      "Epoch:  0010 D loss:-0.3057 G loss:-2.322\n",
      "Epoch:  0010 D loss:-0.3592 G loss:-2.344\n",
      "Epoch:  0010 D loss:-0.4089 G loss:-2.473\n",
      "Epoch:  0010 D loss:-0.403 G loss:-2.365\n",
      "Epoch:  0010 D loss:-0.3605 G loss:-2.369\n",
      "Epoch:  0010 D loss:-0.3374 G loss:-2.458\n",
      "Epoch:  0010 D loss:-0.3845 G loss:-2.435\n",
      "Epoch:  0010 D loss:-0.32 G loss:-2.41\n",
      "Epoch:  0010 D loss:-0.3191 G loss:-2.474\n",
      "Epoch:  0010 D loss:-0.3508 G loss:-2.495\n",
      "Epoch:  0010 D loss:-0.3371 G loss:-2.467\n",
      "Epoch:  0010 D loss:-0.4048 G loss:-2.335\n",
      "Epoch:  0010 D loss:-0.3382 G loss:-2.436\n",
      "Epoch:  0010 D loss:-0.355 G loss:-2.35\n",
      "Epoch:  0010 D loss:-0.3338 G loss:-2.399\n",
      "Epoch:  0010 D loss:-0.3169 G loss:-2.363\n",
      "Epoch:  0010 D loss:-0.2457 G loss:-2.59\n",
      "Epoch:  0011 D loss:-0.3033 G loss:-2.413\n",
      "Epoch:  0011 D loss:-0.3796 G loss:-2.497\n",
      "Epoch:  0011 D loss:-0.2794 G loss:-2.879\n",
      "Epoch:  0011 D loss:-0.2311 G loss:-2.821\n",
      "Epoch:  0011 D loss:-0.3161 G loss:-2.897\n",
      "Epoch:  0011 D loss:-0.2746 G loss:-2.791\n",
      "Epoch:  0011 D loss:-0.3371 G loss:-2.711\n",
      "Epoch:  0011 D loss:-0.2706 G loss:-2.714\n",
      "Epoch:  0011 D loss:-0.2938 G loss:-2.741\n",
      "Epoch:  0011 D loss:-0.2798 G loss:-2.653\n",
      "Epoch:  0011 D loss:-0.289 G loss:-2.535\n",
      "Epoch:  0011 D loss:-0.2792 G loss:-2.45\n",
      "Epoch:  0011 D loss:-0.3274 G loss:-2.472\n",
      "Epoch:  0011 D loss:-0.3124 G loss:-2.464\n",
      "Epoch:  0011 D loss:-0.2513 G loss:-2.38\n",
      "Epoch:  0011 D loss:-0.2504 G loss:-2.381\n",
      "Epoch:  0011 D loss:-0.3699 G loss:-2.223\n",
      "Epoch:  0011 D loss:-0.3118 G loss:-2.386\n",
      "Epoch:  0011 D loss:-0.3606 G loss:-2.434\n",
      "Epoch:  0011 D loss:-0.3038 G loss:-2.469\n",
      "Epoch:  0011 D loss:-0.3461 G loss:-2.584\n",
      "Epoch:  0011 D loss:-0.3497 G loss:-2.491\n",
      "Epoch:  0011 D loss:-0.3049 G loss:-2.539\n",
      "Epoch:  0011 D loss:-0.3576 G loss:-2.405\n",
      "Epoch:  0011 D loss:-0.3286 G loss:-2.418\n",
      "Epoch:  0011 D loss:-0.4164 G loss:-2.369\n",
      "Epoch:  0011 D loss:-0.3955 G loss:-2.219\n",
      "Epoch:  0011 D loss:-0.4032 G loss:-2.402\n",
      "Epoch:  0011 D loss:-0.3893 G loss:-2.351\n",
      "Epoch:  0011 D loss:-0.4604 G loss:-2.107\n",
      "Epoch:  0011 D loss:-0.3642 G loss:-2.129\n",
      "Epoch:  0011 D loss:-0.4058 G loss:-2.117\n",
      "Epoch:  0011 D loss:-0.3448 G loss:-2.2\n",
      "Epoch:  0011 D loss:-0.398 G loss:-2.228\n",
      "Epoch:  0011 D loss:-0.3772 G loss:-2.167\n",
      "Epoch:  0011 D loss:-0.4324 G loss:-2.206\n",
      "Epoch:  0011 D loss:-0.4645 G loss:-2.213\n",
      "Epoch:  0011 D loss:-0.3889 G loss:-2.311\n",
      "Epoch:  0011 D loss:-0.4081 G loss:-2.287\n",
      "Epoch:  0011 D loss:-0.3772 G loss:-2.26\n",
      "Epoch:  0011 D loss:-0.373 G loss:-2.2\n",
      "Epoch:  0011 D loss:-0.3922 G loss:-2.246\n",
      "Epoch:  0011 D loss:-0.351 G loss:-2.214\n",
      "Epoch:  0011 D loss:-0.4961 G loss:-2.184\n",
      "Epoch:  0011 D loss:-0.4232 G loss:-2.036\n",
      "Epoch:  0011 D loss:-0.4258 G loss:-2.1\n",
      "Epoch:  0011 D loss:-0.4238 G loss:-2.099\n",
      "Epoch:  0011 D loss:-0.5117 G loss:-2.006\n",
      "Epoch:  0011 D loss:-0.4445 G loss:-1.904\n",
      "Epoch:  0011 D loss:-0.4337 G loss:-2.046\n",
      "Epoch:  0011 D loss:-0.3253 G loss:-2.077\n",
      "Epoch:  0011 D loss:-0.3904 G loss:-2.062\n",
      "Epoch:  0011 D loss:-0.4837 G loss:-2.158\n",
      "Epoch:  0011 D loss:-0.4489 G loss:-2.122\n",
      "Epoch:  0011 D loss:-0.4259 G loss:-2.213\n",
      "Epoch:  0011 D loss:-0.4868 G loss:-2.139\n",
      "Epoch:  0011 D loss:-0.5089 G loss:-2.167\n",
      "Epoch:  0011 D loss:-0.5577 G loss:-2.146\n",
      "Epoch:  0011 D loss:-0.4859 G loss:-1.941\n",
      "Epoch:  0011 D loss:-0.4217 G loss:-1.96\n",
      "Epoch:  0011 D loss:-0.4485 G loss:-1.893\n",
      "Epoch:  0011 D loss:-0.502 G loss:-1.861\n",
      "Epoch:  0011 D loss:-0.5911 G loss:-1.977\n",
      "Epoch:  0011 D loss:-0.4555 G loss:-2.038\n",
      "Epoch:  0011 D loss:-0.6144 G loss:-1.957\n",
      "Epoch:  0011 D loss:-0.5005 G loss:-2.056\n",
      "Epoch:  0011 D loss:-0.4729 G loss:-2.102\n",
      "Epoch:  0011 D loss:-0.5241 G loss:-1.964\n",
      "Epoch:  0011 D loss:-0.5371 G loss:-2.003\n",
      "Epoch:  0011 D loss:-0.4559 G loss:-2.084\n",
      "Epoch:  0011 D loss:-0.4554 G loss:-2.104\n",
      "Epoch:  0011 D loss:-0.4048 G loss:-2.086\n",
      "Epoch:  0011 D loss:-0.5638 G loss:-2.082\n",
      "Epoch:  0011 D loss:-0.5171 G loss:-1.991\n",
      "Epoch:  0011 D loss:-0.4692 G loss:-2.015\n",
      "Epoch:  0011 D loss:-0.5546 G loss:-1.905\n",
      "Epoch:  0011 D loss:-0.5053 G loss:-1.894\n",
      "Epoch:  0011 D loss:-0.5429 G loss:-1.832\n",
      "Epoch:  0011 D loss:-0.4636 G loss:-1.772\n",
      "Epoch:  0011 D loss:-0.5139 G loss:-1.871\n",
      "Epoch:  0011 D loss:-0.455 G loss:-1.957\n",
      "Epoch:  0011 D loss:-0.5577 G loss:-1.951\n",
      "Epoch:  0011 D loss:-0.6886 G loss:-1.934\n",
      "Epoch:  0011 D loss:-0.5854 G loss:-2.017\n",
      "Epoch:  0011 D loss:-0.5287 G loss:-2.094\n",
      "Epoch:  0011 D loss:-0.5658 G loss:-1.947\n",
      "Epoch:  0011 D loss:-0.4942 G loss:-1.968\n",
      "Epoch:  0011 D loss:-0.4352 G loss:-1.972\n",
      "Epoch:  0011 D loss:-0.4589 G loss:-1.969\n",
      "Epoch:  0011 D loss:-0.4252 G loss:-2.035\n",
      "Epoch:  0011 D loss:-0.4213 G loss:-2.103\n",
      "Epoch:  0011 D loss:-0.479 G loss:-2.141\n",
      "Epoch:  0011 D loss:-0.4542 G loss:-2.102\n",
      "Epoch:  0011 D loss:-0.559 G loss:-1.917\n",
      "Epoch:  0011 D loss:-0.5629 G loss:-1.928\n",
      "Epoch:  0011 D loss:-0.5427 G loss:-1.846\n",
      "Epoch:  0011 D loss:-0.4516 G loss:-1.873\n",
      "Epoch:  0011 D loss:-0.4786 G loss:-1.819\n",
      "Epoch:  0011 D loss:-0.461 G loss:-1.856\n",
      "Epoch:  0011 D loss:-0.4715 G loss:-1.973\n",
      "Epoch:  0011 D loss:-0.4 G loss:-2.026\n",
      "Epoch:  0011 D loss:-0.4387 G loss:-2.092\n",
      "Epoch:  0011 D loss:-0.4469 G loss:-2.138\n",
      "Epoch:  0011 D loss:-0.4115 G loss:-2.179\n",
      "Epoch:  0011 D loss:-0.6199 G loss:-2.085\n",
      "Epoch:  0011 D loss:-0.4397 G loss:-2.125\n",
      "Epoch:  0011 D loss:-0.3774 G loss:-2.181\n",
      "Epoch:  0011 D loss:-0.3944 G loss:-2.115\n",
      "Epoch:  0011 D loss:-0.4443 G loss:-2.089\n",
      "Epoch:  0011 D loss:-0.4342 G loss:-2.135\n",
      "Epoch:  0011 D loss:-0.4944 G loss:-1.972\n",
      "Epoch:  0011 D loss:-0.4431 G loss:-2.106\n",
      "Epoch:  0011 D loss:-0.3924 G loss:-2.066\n",
      "Epoch:  0011 D loss:-0.521 G loss:-2.033\n",
      "Epoch:  0011 D loss:-0.4154 G loss:-2.023\n",
      "Epoch:  0011 D loss:-0.4614 G loss:-2.007\n",
      "Epoch:  0011 D loss:-0.3644 G loss:-2.074\n",
      "Epoch:  0011 D loss:-0.4682 G loss:-2.076\n",
      "Epoch:  0011 D loss:-0.4248 G loss:-2.049\n",
      "Epoch:  0011 D loss:-0.5015 G loss:-2.119\n",
      "Epoch:  0011 D loss:-0.4309 G loss:-2.142\n",
      "Epoch:  0011 D loss:-0.4389 G loss:-2.187\n",
      "Epoch:  0011 D loss:-0.5293 G loss:-2.114\n",
      "Epoch:  0011 D loss:-0.4428 G loss:-2.13\n",
      "Epoch:  0011 D loss:-0.4845 G loss:-2.089\n",
      "Epoch:  0011 D loss:-0.5142 G loss:-2.05\n",
      "Epoch:  0011 D loss:-0.4854 G loss:-2.003\n",
      "Epoch:  0011 D loss:-0.4412 G loss:-2.004\n",
      "Epoch:  0011 D loss:-0.5058 G loss:-1.914\n",
      "Epoch:  0011 D loss:-0.4614 G loss:-1.892\n",
      "Epoch:  0011 D loss:-0.4541 G loss:-2.036\n",
      "Epoch:  0011 D loss:-0.4206 G loss:-1.933\n",
      "Epoch:  0011 D loss:-0.4111 G loss:-2.074\n",
      "Epoch:  0011 D loss:-0.441 G loss:-2.226\n",
      "Epoch:  0011 D loss:-0.3869 G loss:-2.347\n",
      "Epoch:  0011 D loss:-0.4522 G loss:-2.341\n",
      "Epoch:  0011 D loss:-0.4065 G loss:-2.303\n",
      "Epoch:  0011 D loss:-0.3704 G loss:-2.36\n",
      "Epoch:  0011 D loss:-0.3735 G loss:-2.378\n",
      "Epoch:  0011 D loss:-0.4825 G loss:-2.308\n",
      "Epoch:  0011 D loss:-0.4179 G loss:-2.154\n",
      "Epoch:  0011 D loss:-0.4246 G loss:-2.31\n",
      "Epoch:  0011 D loss:-0.4671 G loss:-2.02\n",
      "Epoch:  0011 D loss:-0.4091 G loss:-2.043\n",
      "Epoch:  0011 D loss:-0.375 G loss:-2.006\n",
      "Epoch:  0011 D loss:-0.425 G loss:-2.004\n",
      "Epoch:  0011 D loss:-0.4447 G loss:-1.979\n",
      "Epoch:  0011 D loss:-0.3806 G loss:-2.054\n",
      "Epoch:  0011 D loss:-0.3838 G loss:-2.016\n",
      "Epoch:  0011 D loss:-0.4102 G loss:-2.27\n",
      "Epoch:  0011 D loss:-0.3369 G loss:-2.252\n",
      "Epoch:  0011 D loss:-0.3388 G loss:-2.348\n",
      "Epoch:  0011 D loss:-0.3435 G loss:-2.389\n",
      "Epoch:  0011 D loss:-0.3409 G loss:-2.444\n",
      "Epoch:  0011 D loss:-0.2309 G loss:-2.636\n",
      "Epoch:  0011 D loss:-0.4028 G loss:-2.648\n",
      "Epoch:  0011 D loss:-0.3462 G loss:-2.676\n",
      "Epoch:  0011 D loss:-0.293 G loss:-2.669\n",
      "Epoch:  0011 D loss:-0.3703 G loss:-2.35\n",
      "Epoch:  0011 D loss:-0.36 G loss:-2.42\n",
      "Epoch:  0011 D loss:-0.3434 G loss:-2.275\n",
      "Epoch:  0011 D loss:-0.2875 G loss:-2.252\n",
      "Epoch:  0011 D loss:-0.2979 G loss:-2.164\n",
      "Epoch:  0011 D loss:-0.2931 G loss:-2.198\n",
      "Epoch:  0011 D loss:-0.3537 G loss:-1.988\n",
      "Epoch:  0011 D loss:-0.2597 G loss:-2.268\n",
      "Epoch:  0011 D loss:-0.3567 G loss:-2.398\n",
      "Epoch:  0011 D loss:-0.292 G loss:-2.559\n",
      "Epoch:  0011 D loss:-0.3528 G loss:-2.462\n",
      "Epoch:  0011 D loss:-0.3066 G loss:-2.485\n",
      "Epoch:  0011 D loss:-0.2463 G loss:-2.519\n",
      "Epoch:  0011 D loss:-0.266 G loss:-2.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0011 D loss:-0.2961 G loss:-2.592\n",
      "Epoch:  0011 D loss:-0.2763 G loss:-2.527\n",
      "Epoch:  0011 D loss:-0.2197 G loss:-2.681\n",
      "Epoch:  0011 D loss:-0.2739 G loss:-2.644\n",
      "Epoch:  0011 D loss:-0.3186 G loss:-2.645\n",
      "Epoch:  0011 D loss:-0.3179 G loss:-2.448\n",
      "Epoch:  0011 D loss:-0.3947 G loss:-2.288\n",
      "Epoch:  0011 D loss:-0.319 G loss:-2.287\n",
      "Epoch:  0011 D loss:-0.3074 G loss:-2.254\n",
      "Epoch:  0011 D loss:-0.3489 G loss:-2.195\n",
      "Epoch:  0011 D loss:-0.3611 G loss:-2.084\n",
      "Epoch:  0011 D loss:-0.3624 G loss:-2.155\n",
      "Epoch:  0011 D loss:-0.3405 G loss:-2.134\n",
      "Epoch:  0011 D loss:-0.3613 G loss:-2.181\n",
      "Epoch:  0011 D loss:-0.3701 G loss:-2.189\n",
      "Epoch:  0011 D loss:-0.332 G loss:-2.384\n",
      "Epoch:  0011 D loss:-0.3588 G loss:-2.282\n",
      "Epoch:  0011 D loss:-0.3661 G loss:-2.332\n",
      "Epoch:  0011 D loss:-0.3801 G loss:-2.251\n",
      "Epoch:  0011 D loss:-0.3731 G loss:-2.313\n",
      "Epoch:  0011 D loss:-0.4325 G loss:-2.353\n",
      "Epoch:  0011 D loss:-0.4451 G loss:-2.217\n",
      "Epoch:  0011 D loss:-0.4456 G loss:-2.197\n",
      "Epoch:  0011 D loss:-0.3781 G loss:-2.177\n",
      "Epoch:  0011 D loss:-0.3734 G loss:-2.081\n",
      "Epoch:  0011 D loss:-0.3709 G loss:-2.139\n",
      "Epoch:  0011 D loss:-0.508 G loss:-2.02\n",
      "Epoch:  0011 D loss:-0.4343 G loss:-2.015\n",
      "Epoch:  0011 D loss:-0.4385 G loss:-2.131\n",
      "Epoch:  0011 D loss:-0.3839 G loss:-2.02\n",
      "Epoch:  0011 D loss:-0.391 G loss:-2.041\n",
      "Epoch:  0011 D loss:-0.4009 G loss:-2.107\n",
      "Epoch:  0011 D loss:-0.4201 G loss:-2.193\n",
      "Epoch:  0011 D loss:-0.5023 G loss:-2.191\n",
      "Epoch:  0011 D loss:-0.4901 G loss:-2.168\n",
      "Epoch:  0011 D loss:-0.4114 G loss:-2.214\n",
      "Epoch:  0011 D loss:-0.5113 G loss:-2.124\n",
      "Epoch:  0011 D loss:-0.4533 G loss:-1.996\n",
      "Epoch:  0011 D loss:-0.445 G loss:-1.968\n",
      "Epoch:  0011 D loss:-0.5345 G loss:-1.87\n",
      "Epoch:  0011 D loss:-0.5024 G loss:-1.967\n",
      "Epoch:  0011 D loss:-0.462 G loss:-1.974\n",
      "Epoch:  0011 D loss:-0.4951 G loss:-1.894\n",
      "Epoch:  0011 D loss:-0.4292 G loss:-2.041\n",
      "Epoch:  0011 D loss:-0.4633 G loss:-1.988\n",
      "Epoch:  0011 D loss:-0.5004 G loss:-2.006\n",
      "Epoch:  0011 D loss:-0.4051 G loss:-2.048\n",
      "Epoch:  0011 D loss:-0.4413 G loss:-2.167\n",
      "Epoch:  0011 D loss:-0.4509 G loss:-2.148\n",
      "Epoch:  0011 D loss:-0.471 G loss:-2.156\n",
      "Epoch:  0011 D loss:-0.4064 G loss:-2.199\n",
      "Epoch:  0011 D loss:-0.4811 G loss:-2.164\n",
      "Epoch:  0011 D loss:-0.413 G loss:-2.143\n",
      "Epoch:  0011 D loss:-0.4329 G loss:-2.228\n",
      "Epoch:  0011 D loss:-0.5932 G loss:-2.13\n",
      "Epoch:  0011 D loss:-0.4338 G loss:-1.999\n",
      "Epoch:  0011 D loss:-0.4422 G loss:-2.095\n",
      "Epoch:  0011 D loss:-0.4776 G loss:-1.988\n",
      "Epoch:  0011 D loss:-0.4408 G loss:-1.973\n",
      "Epoch:  0011 D loss:-0.4617 G loss:-2.031\n",
      "Epoch:  0011 D loss:-0.4201 G loss:-2.062\n",
      "Epoch:  0011 D loss:-0.4367 G loss:-2.128\n",
      "Epoch:  0011 D loss:-0.4633 G loss:-2.129\n",
      "Epoch:  0011 D loss:-0.5516 G loss:-2.106\n",
      "Epoch:  0011 D loss:-0.4805 G loss:-1.963\n",
      "Epoch:  0011 D loss:-0.4922 G loss:-2.074\n",
      "Epoch:  0011 D loss:-0.4124 G loss:-2.109\n",
      "Epoch:  0011 D loss:-0.4936 G loss:-2.018\n",
      "Epoch:  0011 D loss:-0.3522 G loss:-2.19\n",
      "Epoch:  0011 D loss:-0.4075 G loss:-2.106\n",
      "Epoch:  0011 D loss:-0.4616 G loss:-2.045\n",
      "Epoch:  0011 D loss:-0.501 G loss:-1.988\n",
      "Epoch:  0011 D loss:-0.4422 G loss:-1.913\n",
      "Epoch:  0011 D loss:-0.3536 G loss:-2.098\n",
      "Epoch:  0011 D loss:-0.4501 G loss:-2.161\n",
      "Epoch:  0011 D loss:-0.5056 G loss:-2.04\n",
      "Epoch:  0011 D loss:-0.4719 G loss:-2.066\n",
      "Epoch:  0011 D loss:-0.5651 G loss:-2.039\n",
      "Epoch:  0011 D loss:-0.43 G loss:-1.951\n",
      "Epoch:  0011 D loss:-0.5471 G loss:-1.901\n",
      "Epoch:  0011 D loss:-0.5151 G loss:-2.003\n",
      "Epoch:  0011 D loss:-0.4117 G loss:-1.946\n",
      "Epoch:  0011 D loss:-0.473 G loss:-1.809\n",
      "Epoch:  0011 D loss:-0.4845 G loss:-1.84\n",
      "Epoch:  0011 D loss:-0.5272 G loss:-1.968\n",
      "Epoch:  0011 D loss:-0.5441 G loss:-1.979\n",
      "Epoch:  0011 D loss:-0.4884 G loss:-2.016\n",
      "Epoch:  0011 D loss:-0.4053 G loss:-2.047\n",
      "Epoch:  0011 D loss:-0.4807 G loss:-2.203\n",
      "Epoch:  0011 D loss:-0.5682 G loss:-1.998\n",
      "Epoch:  0011 D loss:-0.5687 G loss:-2.053\n",
      "Epoch:  0011 D loss:-0.4335 G loss:-2.021\n",
      "Epoch:  0011 D loss:-0.5397 G loss:-1.868\n",
      "Epoch:  0011 D loss:-0.4796 G loss:-1.891\n",
      "Epoch:  0011 D loss:-0.5113 G loss:-1.807\n",
      "Epoch:  0011 D loss:-0.5047 G loss:-1.891\n",
      "Epoch:  0011 D loss:-0.5 G loss:-1.863\n",
      "Epoch:  0011 D loss:-0.4067 G loss:-2.014\n",
      "Epoch:  0011 D loss:-0.4394 G loss:-2.104\n",
      "Epoch:  0011 D loss:-0.5172 G loss:-2.038\n",
      "Epoch:  0011 D loss:-0.4441 G loss:-2.081\n",
      "Epoch:  0011 D loss:-0.4629 G loss:-2.211\n",
      "Epoch:  0011 D loss:-0.4714 G loss:-2.293\n",
      "Epoch:  0011 D loss:-0.5864 G loss:-2.173\n",
      "Epoch:  0011 D loss:-0.4247 G loss:-2.096\n",
      "Epoch:  0011 D loss:-0.43 G loss:-2.119\n",
      "Epoch:  0011 D loss:-0.4322 G loss:-2.008\n",
      "Epoch:  0011 D loss:-0.4835 G loss:-1.971\n",
      "Epoch:  0011 D loss:-0.4041 G loss:-2.061\n",
      "Epoch:  0011 D loss:-0.4821 G loss:-1.987\n",
      "Epoch:  0011 D loss:-0.4273 G loss:-2.146\n",
      "Epoch:  0011 D loss:-0.4081 G loss:-1.877\n",
      "Epoch:  0011 D loss:-0.4159 G loss:-2.044\n",
      "Epoch:  0011 D loss:-0.3621 G loss:-2.161\n",
      "Epoch:  0011 D loss:-0.3974 G loss:-2.159\n",
      "Epoch:  0011 D loss:-0.4505 G loss:-2.057\n",
      "Epoch:  0011 D loss:-0.4579 G loss:-2.306\n",
      "Epoch:  0011 D loss:-0.4454 G loss:-2.197\n",
      "Epoch:  0011 D loss:-0.4306 G loss:-2.177\n",
      "Epoch:  0011 D loss:-0.4246 G loss:-2.388\n",
      "Epoch:  0011 D loss:-0.4 G loss:-2.245\n",
      "Epoch:  0011 D loss:-0.384 G loss:-2.275\n",
      "Epoch:  0011 D loss:-0.3504 G loss:-2.337\n",
      "Epoch:  0011 D loss:-0.3632 G loss:-2.229\n",
      "Epoch:  0011 D loss:-0.3177 G loss:-2.265\n",
      "Epoch:  0011 D loss:-0.352 G loss:-2.137\n",
      "Epoch:  0011 D loss:-0.3688 G loss:-2.155\n",
      "Epoch:  0011 D loss:-0.3768 G loss:-2.224\n",
      "Epoch:  0011 D loss:-0.3078 G loss:-2.269\n",
      "Epoch:  0011 D loss:-0.4218 G loss:-2.126\n",
      "Epoch:  0011 D loss:-0.4203 G loss:-2.149\n",
      "Epoch:  0011 D loss:-0.3333 G loss:-2.203\n",
      "Epoch:  0011 D loss:-0.3682 G loss:-2.294\n",
      "Epoch:  0011 D loss:-0.3407 G loss:-2.244\n",
      "Epoch:  0011 D loss:-0.3768 G loss:-2.32\n",
      "Epoch:  0011 D loss:-0.3108 G loss:-2.29\n",
      "Epoch:  0011 D loss:-0.352 G loss:-2.353\n",
      "Epoch:  0011 D loss:-0.3357 G loss:-2.381\n",
      "Epoch:  0011 D loss:-0.3397 G loss:-2.46\n",
      "Epoch:  0011 D loss:-0.3566 G loss:-2.397\n",
      "Epoch:  0011 D loss:-0.3307 G loss:-2.403\n",
      "Epoch:  0011 D loss:-0.3494 G loss:-2.391\n",
      "Epoch:  0011 D loss:-0.3615 G loss:-2.247\n",
      "Epoch:  0011 D loss:-0.3189 G loss:-2.278\n",
      "Epoch:  0011 D loss:-0.3016 G loss:-2.363\n",
      "Epoch:  0011 D loss:-0.3035 G loss:-2.299\n",
      "Epoch:  0011 D loss:-0.2957 G loss:-2.211\n",
      "Epoch:  0011 D loss:-0.3226 G loss:-2.327\n",
      "Epoch:  0011 D loss:-0.2861 G loss:-2.436\n",
      "Epoch:  0011 D loss:-0.3678 G loss:-2.294\n",
      "Epoch:  0011 D loss:-0.3194 G loss:-2.254\n",
      "Epoch:  0011 D loss:-0.3009 G loss:-2.383\n",
      "Epoch:  0011 D loss:-0.2894 G loss:-2.528\n",
      "Epoch:  0011 D loss:-0.2991 G loss:-2.608\n",
      "Epoch:  0011 D loss:-0.3093 G loss:-2.472\n",
      "Epoch:  0011 D loss:-0.3518 G loss:-2.437\n",
      "Epoch:  0011 D loss:-0.2834 G loss:-2.4\n",
      "Epoch:  0011 D loss:-0.2975 G loss:-2.454\n",
      "Epoch:  0011 D loss:-0.3301 G loss:-2.421\n",
      "Epoch:  0011 D loss:-0.2929 G loss:-2.406\n",
      "Epoch:  0011 D loss:-0.295 G loss:-2.448\n",
      "Epoch:  0011 D loss:-0.3337 G loss:-2.28\n",
      "Epoch:  0011 D loss:-0.2984 G loss:-2.377\n",
      "Epoch:  0011 D loss:-0.3535 G loss:-2.375\n",
      "Epoch:  0011 D loss:-0.3438 G loss:-2.319\n",
      "Epoch:  0011 D loss:-0.3185 G loss:-2.325\n",
      "Epoch:  0011 D loss:-0.3053 G loss:-2.364\n",
      "Epoch:  0011 D loss:-0.2663 G loss:-2.39\n",
      "Epoch:  0011 D loss:-0.329 G loss:-2.445\n",
      "Epoch:  0011 D loss:-0.2812 G loss:-2.405\n",
      "Epoch:  0011 D loss:-0.3132 G loss:-2.51\n",
      "Epoch:  0011 D loss:-0.2962 G loss:-2.358\n",
      "Epoch:  0011 D loss:-0.358 G loss:-2.386\n",
      "Epoch:  0011 D loss:-0.326 G loss:-2.358\n",
      "Epoch:  0011 D loss:-0.2917 G loss:-2.492\n",
      "Epoch:  0011 D loss:-0.3049 G loss:-2.351\n",
      "Epoch:  0011 D loss:-0.3584 G loss:-2.312\n",
      "Epoch:  0011 D loss:-0.2763 G loss:-2.545\n",
      "Epoch:  0011 D loss:-0.284 G loss:-2.387\n",
      "Epoch:  0011 D loss:-0.2646 G loss:-2.524\n",
      "Epoch:  0011 D loss:-0.3172 G loss:-2.479\n",
      "Epoch:  0011 D loss:-0.2971 G loss:-2.478\n",
      "Epoch:  0011 D loss:-0.2827 G loss:-2.636\n",
      "Epoch:  0011 D loss:-0.3522 G loss:-2.498\n",
      "Epoch:  0011 D loss:-0.264 G loss:-2.402\n",
      "Epoch:  0011 D loss:-0.2413 G loss:-2.509\n",
      "Epoch:  0011 D loss:-0.3361 G loss:-2.331\n",
      "Epoch:  0011 D loss:-0.3332 G loss:-2.312\n",
      "Epoch:  0011 D loss:-0.289 G loss:-2.302\n",
      "Epoch:  0011 D loss:-0.3232 G loss:-2.339\n",
      "Epoch:  0011 D loss:-0.3281 G loss:-2.36\n",
      "Epoch:  0011 D loss:-0.2327 G loss:-2.404\n",
      "Epoch:  0011 D loss:-0.2565 G loss:-2.353\n",
      "Epoch:  0011 D loss:-0.2741 G loss:-2.296\n",
      "Epoch:  0011 D loss:-0.2819 G loss:-2.359\n",
      "Epoch:  0011 D loss:-0.2336 G loss:-2.55\n",
      "Epoch:  0011 D loss:-0.2324 G loss:-2.703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0011 D loss:-0.2577 G loss:-2.711\n",
      "Epoch:  0011 D loss:-0.2801 G loss:-2.679\n",
      "Epoch:  0011 D loss:-0.3154 G loss:-2.707\n",
      "Epoch:  0011 D loss:-0.2886 G loss:-2.642\n",
      "Epoch:  0011 D loss:-0.2998 G loss:-2.703\n",
      "Epoch:  0011 D loss:-0.3419 G loss:-2.467\n",
      "Epoch:  0011 D loss:-0.2788 G loss:-2.387\n",
      "Epoch:  0011 D loss:-0.325 G loss:-2.471\n",
      "Epoch:  0011 D loss:-0.345 G loss:-2.367\n",
      "Epoch:  0011 D loss:-0.3365 G loss:-2.365\n",
      "Epoch:  0011 D loss:-0.3321 G loss:-2.251\n",
      "Epoch:  0011 D loss:-0.2984 G loss:-2.245\n",
      "Epoch:  0011 D loss:-0.3173 G loss:-2.097\n",
      "Epoch:  0011 D loss:-0.3304 G loss:-2.145\n",
      "Epoch:  0011 D loss:-0.3147 G loss:-2.229\n",
      "Epoch:  0011 D loss:-0.3231 G loss:-2.458\n",
      "Epoch:  0011 D loss:-0.3113 G loss:-2.303\n",
      "Epoch:  0011 D loss:-0.3461 G loss:-2.341\n",
      "Epoch:  0011 D loss:-0.4319 G loss:-2.287\n",
      "Epoch:  0011 D loss:-0.3378 G loss:-2.351\n",
      "Epoch:  0011 D loss:-0.2882 G loss:-2.396\n",
      "Epoch:  0011 D loss:-0.3772 G loss:-2.273\n",
      "Epoch:  0011 D loss:-0.3007 G loss:-2.443\n",
      "Epoch:  0011 D loss:-0.3837 G loss:-2.374\n",
      "Epoch:  0011 D loss:-0.3984 G loss:-2.433\n",
      "Epoch:  0011 D loss:-0.3949 G loss:-2.368\n",
      "Epoch:  0011 D loss:-0.3795 G loss:-2.056\n",
      "Epoch:  0011 D loss:-0.4315 G loss:-2.178\n",
      "Epoch:  0011 D loss:-0.3188 G loss:-2.13\n",
      "Epoch:  0011 D loss:-0.3824 G loss:-2.118\n",
      "Epoch:  0011 D loss:-0.3705 G loss:-2.232\n",
      "Epoch:  0011 D loss:-0.3381 G loss:-2.239\n",
      "Epoch:  0011 D loss:-0.4432 G loss:-2.163\n",
      "Epoch:  0011 D loss:-0.3437 G loss:-2.242\n",
      "Epoch:  0011 D loss:-0.3851 G loss:-2.284\n",
      "Epoch:  0011 D loss:-0.4245 G loss:-2.142\n",
      "Epoch:  0011 D loss:-0.3925 G loss:-2.366\n",
      "Epoch:  0011 D loss:-0.3628 G loss:-2.271\n",
      "Epoch:  0011 D loss:-0.3583 G loss:-2.258\n",
      "Epoch:  0011 D loss:-0.3922 G loss:-2.227\n",
      "Epoch:  0011 D loss:-0.3727 G loss:-2.275\n",
      "Epoch:  0011 D loss:-0.3645 G loss:-2.343\n",
      "Epoch:  0011 D loss:-0.3466 G loss:-2.386\n",
      "Epoch:  0011 D loss:-0.3293 G loss:-2.323\n",
      "Epoch:  0011 D loss:-0.3151 G loss:-2.311\n",
      "Epoch:  0011 D loss:-0.3664 G loss:-2.314\n",
      "Epoch:  0011 D loss:-0.428 G loss:-2.22\n",
      "Epoch:  0011 D loss:-0.3936 G loss:-2.052\n",
      "Epoch:  0011 D loss:-0.4353 G loss:-2.114\n",
      "Epoch:  0011 D loss:-0.3717 G loss:-2.22\n",
      "Epoch:  0011 D loss:-0.3991 G loss:-2.175\n",
      "Epoch:  0011 D loss:-0.3954 G loss:-2.175\n",
      "Epoch:  0011 D loss:-0.3782 G loss:-2.281\n",
      "Epoch:  0011 D loss:-0.4163 G loss:-2.118\n",
      "Epoch:  0011 D loss:-0.4228 G loss:-2.153\n",
      "Epoch:  0011 D loss:-0.3375 G loss:-2.2\n",
      "Epoch:  0011 D loss:-0.3686 G loss:-2.276\n",
      "Epoch:  0011 D loss:-0.4136 G loss:-2.289\n",
      "Epoch:  0011 D loss:-0.4578 G loss:-2.258\n",
      "Epoch:  0011 D loss:-0.4102 G loss:-2.213\n",
      "Epoch:  0011 D loss:-0.328 G loss:-2.195\n",
      "Epoch:  0011 D loss:-0.4482 G loss:-1.962\n",
      "Epoch:  0011 D loss:-0.4638 G loss:-2.014\n",
      "Epoch:  0011 D loss:-0.3888 G loss:-2.048\n",
      "Epoch:  0011 D loss:-0.4028 G loss:-2.066\n",
      "Epoch:  0011 D loss:-0.3689 G loss:-2.185\n",
      "Epoch:  0011 D loss:-0.4629 G loss:-2.231\n",
      "Epoch:  0011 D loss:-0.5296 G loss:-2.362\n",
      "Epoch:  0011 D loss:-0.3956 G loss:-2.241\n",
      "Epoch:  0011 D loss:-0.4183 G loss:-2.242\n",
      "Epoch:  0011 D loss:-0.3889 G loss:-2.261\n",
      "Epoch:  0011 D loss:-0.4802 G loss:-2.111\n",
      "Epoch:  0011 D loss:-0.4108 G loss:-2.169\n",
      "Epoch:  0011 D loss:-0.5084 G loss:-2.1\n",
      "Epoch:  0011 D loss:-0.4727 G loss:-2.093\n",
      "Epoch:  0011 D loss:-0.4306 G loss:-2.157\n",
      "Epoch:  0011 D loss:-0.4071 G loss:-2.002\n",
      "Epoch:  0011 D loss:-0.5078 G loss:-2.08\n",
      "Epoch:  0011 D loss:-0.4515 G loss:-2.131\n",
      "Epoch:  0011 D loss:-0.3731 G loss:-2.12\n",
      "Epoch:  0011 D loss:-0.4163 G loss:-2.1\n",
      "Epoch:  0011 D loss:-0.4191 G loss:-2.141\n",
      "Epoch:  0011 D loss:-0.3399 G loss:-2.318\n",
      "Epoch:  0011 D loss:-0.4343 G loss:-2.3\n",
      "Epoch:  0011 D loss:-0.4243 G loss:-2.299\n",
      "Epoch:  0011 D loss:-0.5065 G loss:-2.197\n",
      "Epoch:  0011 D loss:-0.4614 G loss:-2.343\n",
      "Epoch:  0011 D loss:-0.3619 G loss:-2.094\n",
      "Epoch:  0011 D loss:-0.3639 G loss:-2.292\n",
      "Epoch:  0011 D loss:-0.3915 G loss:-2.271\n",
      "Epoch:  0011 D loss:-0.4306 G loss:-2.138\n",
      "Epoch:  0011 D loss:-0.4366 G loss:-2.193\n",
      "Epoch:  0011 D loss:-0.4563 G loss:-2.108\n",
      "Epoch:  0011 D loss:-0.4131 G loss:-2.144\n",
      "Epoch:  0011 D loss:-0.4271 G loss:-2.083\n",
      "Epoch:  0011 D loss:-0.3937 G loss:-2.101\n",
      "Epoch:  0011 D loss:-0.4636 G loss:-2.058\n",
      "Epoch:  0011 D loss:-0.39 G loss:-2.235\n",
      "Epoch:  0011 D loss:-0.421 G loss:-2.232\n",
      "Epoch:  0011 D loss:-0.3587 G loss:-2.248\n",
      "Epoch:  0011 D loss:-0.4055 G loss:-2.128\n",
      "Epoch:  0011 D loss:-0.4149 G loss:-2.175\n",
      "Epoch:  0011 D loss:-0.416 G loss:-2.133\n",
      "Epoch:  0011 D loss:-0.3805 G loss:-2.259\n",
      "Epoch:  0011 D loss:-0.4379 G loss:-2.254\n",
      "Epoch:  0011 D loss:-0.4116 G loss:-2.087\n",
      "Epoch:  0011 D loss:-0.4873 G loss:-2.28\n",
      "Epoch:  0011 D loss:-0.4266 G loss:-2.277\n",
      "Epoch:  0011 D loss:-0.3463 G loss:-2.165\n",
      "Epoch:  0011 D loss:-0.3861 G loss:-2.18\n",
      "Epoch:  0011 D loss:-0.3878 G loss:-2.176\n",
      "Epoch:  0011 D loss:-0.3438 G loss:-2.246\n",
      "Epoch:  0011 D loss:-0.4048 G loss:-2.179\n",
      "Epoch:  0011 D loss:-0.3755 G loss:-2.287\n",
      "Epoch:  0011 D loss:-0.3365 G loss:-2.356\n",
      "Epoch:  0011 D loss:-0.3623 G loss:-2.447\n",
      "Epoch:  0011 D loss:-0.3226 G loss:-2.273\n",
      "Epoch:  0011 D loss:-0.3699 G loss:-2.294\n",
      "Epoch:  0011 D loss:-0.3566 G loss:-2.316\n",
      "Epoch:  0011 D loss:-0.4493 G loss:-2.185\n",
      "Epoch:  0011 D loss:-0.4137 G loss:-2.19\n",
      "Epoch:  0011 D loss:-0.4819 G loss:-2.155\n",
      "Epoch:  0011 D loss:-0.4216 G loss:-2.196\n",
      "Epoch:  0011 D loss:-0.4383 G loss:-2.049\n",
      "Epoch:  0011 D loss:-0.34 G loss:-2.15\n",
      "Epoch:  0011 D loss:-0.4156 G loss:-2.174\n",
      "Epoch:  0011 D loss:-0.4083 G loss:-2.171\n",
      "Epoch:  0011 D loss:-0.3757 G loss:-2.157\n",
      "Epoch:  0011 D loss:-0.3872 G loss:-2.276\n",
      "Epoch:  0011 D loss:-0.3868 G loss:-2.362\n",
      "Epoch:  0011 D loss:-0.3076 G loss:-2.442\n",
      "Epoch:  0011 D loss:-0.3608 G loss:-2.46\n",
      "Epoch:  0011 D loss:-0.3454 G loss:-2.45\n",
      "Epoch:  0011 D loss:-0.3375 G loss:-2.5\n",
      "Epoch:  0011 D loss:-0.365 G loss:-2.556\n",
      "Epoch:  0011 D loss:-0.4423 G loss:-2.268\n",
      "Epoch:  0011 D loss:-0.4494 G loss:-2.233\n",
      "Epoch:  0011 D loss:-0.4095 G loss:-2.221\n",
      "Epoch:  0011 D loss:-0.4632 G loss:-2.106\n",
      "Epoch:  0011 D loss:-0.2852 G loss:-2.321\n",
      "Epoch:  0011 D loss:-0.3439 G loss:-2.327\n",
      "Epoch:  0011 D loss:-0.4173 G loss:-2.106\n",
      "Epoch:  0011 D loss:-0.3787 G loss:-2.053\n",
      "Epoch:  0011 D loss:-0.3735 G loss:-2.087\n",
      "Epoch:  0011 D loss:-0.4171 G loss:-2.23\n",
      "Epoch:  0011 D loss:-0.4413 G loss:-2.144\n",
      "Epoch:  0011 D loss:-0.4034 G loss:-2.257\n",
      "Epoch:  0011 D loss:-0.3765 G loss:-2.296\n",
      "Epoch:  0011 D loss:-0.4649 G loss:-2.26\n",
      "Epoch:  0011 D loss:-0.348 G loss:-2.304\n",
      "Epoch:  0011 D loss:-0.3582 G loss:-2.27\n",
      "Epoch:  0011 D loss:-0.3685 G loss:-2.197\n",
      "Epoch:  0011 D loss:-0.3435 G loss:-2.292\n",
      "Epoch:  0011 D loss:-0.4204 G loss:-2.134\n",
      "Epoch:  0011 D loss:-0.3508 G loss:-2.333\n",
      "Epoch:  0011 D loss:-0.3357 G loss:-2.288\n",
      "Epoch:  0011 D loss:-0.3842 G loss:-2.282\n",
      "Epoch:  0011 D loss:-0.4499 G loss:-2.391\n",
      "Epoch:  0011 D loss:-0.3066 G loss:-2.436\n",
      "Epoch:  0011 D loss:-0.3461 G loss:-2.347\n",
      "Epoch:  0011 D loss:-0.3528 G loss:-2.377\n",
      "Epoch:  0011 D loss:-0.3784 G loss:-2.443\n",
      "Epoch:  0011 D loss:-0.4084 G loss:-2.4\n",
      "Epoch:  0011 D loss:-0.3821 G loss:-2.343\n",
      "Epoch:  0011 D loss:-0.3646 G loss:-2.582\n",
      "Epoch:  0011 D loss:-0.3545 G loss:-2.304\n",
      "Epoch:  0011 D loss:-0.3649 G loss:-2.288\n",
      "Epoch:  0011 D loss:-0.4339 G loss:-2.161\n",
      "Epoch:  0011 D loss:-0.3917 G loss:-2.371\n",
      "Epoch:  0011 D loss:-0.4119 G loss:-2.265\n",
      "Epoch:  0011 D loss:-0.4303 G loss:-2.236\n",
      "Epoch:  0011 D loss:-0.4257 G loss:-2.216\n",
      "Epoch:  0011 D loss:-0.3109 G loss:-2.397\n",
      "Epoch:  0011 D loss:-0.4232 G loss:-2.332\n",
      "Epoch:  0011 D loss:-0.3993 G loss:-2.376\n",
      "Epoch:  0011 D loss:-0.3449 G loss:-2.277\n",
      "Epoch:  0011 D loss:-0.3456 G loss:-2.32\n",
      "Epoch:  0011 D loss:-0.3409 G loss:-2.481\n",
      "Epoch:  0011 D loss:-0.3857 G loss:-2.401\n",
      "Epoch:  0011 D loss:-0.3207 G loss:-2.437\n",
      "Epoch:  0011 D loss:-0.3475 G loss:-2.424\n",
      "Epoch:  0012 D loss:-0.2637 G loss:-2.494\n",
      "Epoch:  0012 D loss:-0.3078 G loss:-2.471\n",
      "Epoch:  0012 D loss:-0.2632 G loss:-2.682\n",
      "Epoch:  0012 D loss:-0.3162 G loss:-2.473\n",
      "Epoch:  0012 D loss:-0.2982 G loss:-2.459\n",
      "Epoch:  0012 D loss:-0.3219 G loss:-2.55\n",
      "Epoch:  0012 D loss:-0.3268 G loss:-2.321\n",
      "Epoch:  0012 D loss:-0.3568 G loss:-2.592\n",
      "Epoch:  0012 D loss:-0.393 G loss:-2.318\n",
      "Epoch:  0012 D loss:-0.3581 G loss:-2.294\n",
      "Epoch:  0012 D loss:-0.3763 G loss:-2.257\n",
      "Epoch:  0012 D loss:-0.3668 G loss:-2.384\n",
      "Epoch:  0012 D loss:-0.3573 G loss:-2.218\n",
      "Epoch:  0012 D loss:-0.3622 G loss:-2.248\n",
      "Epoch:  0012 D loss:-0.3291 G loss:-2.279\n",
      "Epoch:  0012 D loss:-0.3723 G loss:-2.223\n",
      "Epoch:  0012 D loss:-0.3374 G loss:-2.309\n",
      "Epoch:  0012 D loss:-0.3694 G loss:-2.432\n",
      "Epoch:  0012 D loss:-0.3778 G loss:-2.363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0012 D loss:-0.4007 G loss:-2.302\n",
      "Epoch:  0012 D loss:-0.4256 G loss:-2.263\n",
      "Epoch:  0012 D loss:-0.3241 G loss:-2.548\n",
      "Epoch:  0012 D loss:-0.5021 G loss:-2.294\n",
      "Epoch:  0012 D loss:-0.4051 G loss:-2.32\n",
      "Epoch:  0012 D loss:-0.369 G loss:-2.385\n",
      "Epoch:  0012 D loss:-0.4214 G loss:-2.256\n",
      "Epoch:  0012 D loss:-0.3821 G loss:-2.263\n",
      "Epoch:  0012 D loss:-0.3785 G loss:-2.259\n",
      "Epoch:  0012 D loss:-0.4164 G loss:-2.273\n",
      "Epoch:  0012 D loss:-0.4386 G loss:-2.013\n",
      "Epoch:  0012 D loss:-0.4218 G loss:-2.139\n",
      "Epoch:  0012 D loss:-0.4535 G loss:-2.109\n",
      "Epoch:  0012 D loss:-0.4646 G loss:-2.139\n",
      "Epoch:  0012 D loss:-0.535 G loss:-2.15\n",
      "Epoch:  0012 D loss:-0.4766 G loss:-2.158\n",
      "Epoch:  0012 D loss:-0.3985 G loss:-2.157\n",
      "Epoch:  0012 D loss:-0.4113 G loss:-2.122\n",
      "Epoch:  0012 D loss:-0.5703 G loss:-2.14\n",
      "Epoch:  0012 D loss:-0.4047 G loss:-2.324\n",
      "Epoch:  0012 D loss:-0.378 G loss:-2.148\n",
      "Epoch:  0012 D loss:-0.4167 G loss:-2.276\n",
      "Epoch:  0012 D loss:-0.4177 G loss:-2.34\n",
      "Epoch:  0012 D loss:-0.4327 G loss:-2.163\n",
      "Epoch:  0012 D loss:-0.3904 G loss:-2.182\n",
      "Epoch:  0012 D loss:-0.3724 G loss:-2.342\n",
      "Epoch:  0012 D loss:-0.5207 G loss:-2.129\n",
      "Epoch:  0012 D loss:-0.3842 G loss:-2.162\n",
      "Epoch:  0012 D loss:-0.4717 G loss:-2.247\n",
      "Epoch:  0012 D loss:-0.4559 G loss:-2.326\n",
      "Epoch:  0012 D loss:-0.4328 G loss:-2.259\n",
      "Epoch:  0012 D loss:-0.3537 G loss:-2.327\n",
      "Epoch:  0012 D loss:-0.4705 G loss:-2.167\n",
      "Epoch:  0012 D loss:-0.3949 G loss:-2.283\n",
      "Epoch:  0012 D loss:-0.4175 G loss:-2.128\n",
      "Epoch:  0012 D loss:-0.3613 G loss:-2.374\n",
      "Epoch:  0012 D loss:-0.4136 G loss:-2.321\n",
      "Epoch:  0012 D loss:-0.4981 G loss:-2.225\n",
      "Epoch:  0012 D loss:-0.4445 G loss:-2.304\n",
      "Epoch:  0012 D loss:-0.3424 G loss:-2.318\n",
      "Epoch:  0012 D loss:-0.4444 G loss:-2.183\n",
      "Epoch:  0012 D loss:-0.404 G loss:-2.12\n",
      "Epoch:  0012 D loss:-0.4517 G loss:-2.256\n",
      "Epoch:  0012 D loss:-0.3976 G loss:-2.168\n",
      "Epoch:  0012 D loss:-0.4502 G loss:-2.227\n",
      "Epoch:  0012 D loss:-0.41 G loss:-2.269\n",
      "Epoch:  0012 D loss:-0.469 G loss:-2.18\n",
      "Epoch:  0012 D loss:-0.3775 G loss:-2.231\n",
      "Epoch:  0012 D loss:-0.4158 G loss:-2.237\n",
      "Epoch:  0012 D loss:-0.3527 G loss:-2.328\n",
      "Epoch:  0012 D loss:-0.4322 G loss:-2.241\n",
      "Epoch:  0012 D loss:-0.4318 G loss:-2.211\n",
      "Epoch:  0012 D loss:-0.4072 G loss:-2.416\n",
      "Epoch:  0012 D loss:-0.4657 G loss:-2.328\n",
      "Epoch:  0012 D loss:-0.4114 G loss:-2.341\n",
      "Epoch:  0012 D loss:-0.4608 G loss:-2.405\n",
      "Epoch:  0012 D loss:-0.3859 G loss:-2.284\n",
      "Epoch:  0012 D loss:-0.3852 G loss:-2.261\n",
      "Epoch:  0012 D loss:-0.3653 G loss:-2.266\n",
      "Epoch:  0012 D loss:-0.3944 G loss:-2.395\n",
      "Epoch:  0012 D loss:-0.3817 G loss:-2.407\n",
      "Epoch:  0012 D loss:-0.5248 G loss:-2.274\n",
      "Epoch:  0012 D loss:-0.448 G loss:-2.261\n",
      "Epoch:  0012 D loss:-0.4942 G loss:-2.152\n",
      "Epoch:  0012 D loss:-0.3969 G loss:-2.21\n",
      "Epoch:  0012 D loss:-0.4367 G loss:-2.216\n",
      "Epoch:  0012 D loss:-0.4807 G loss:-2.052\n",
      "Epoch:  0012 D loss:-0.4829 G loss:-2.036\n",
      "Epoch:  0012 D loss:-0.4733 G loss:-1.928\n",
      "Epoch:  0012 D loss:-0.3895 G loss:-2.148\n",
      "Epoch:  0012 D loss:-0.381 G loss:-2.157\n",
      "Epoch:  0012 D loss:-0.3026 G loss:-2.42\n",
      "Epoch:  0012 D loss:-0.4749 G loss:-2.272\n",
      "Epoch:  0012 D loss:-0.3382 G loss:-2.394\n",
      "Epoch:  0012 D loss:-0.379 G loss:-2.473\n",
      "Epoch:  0012 D loss:-0.3752 G loss:-2.25\n",
      "Epoch:  0012 D loss:-0.3878 G loss:-2.467\n",
      "Epoch:  0012 D loss:-0.4777 G loss:-2.436\n",
      "Epoch:  0012 D loss:-0.4821 G loss:-2.252\n",
      "Epoch:  0012 D loss:-0.4015 G loss:-2.138\n",
      "Epoch:  0012 D loss:-0.3728 G loss:-2.252\n",
      "Epoch:  0012 D loss:-0.4428 G loss:-2.259\n",
      "Epoch:  0012 D loss:-0.3271 G loss:-2.407\n",
      "Epoch:  0012 D loss:-0.4255 G loss:-2.314\n",
      "Epoch:  0012 D loss:-0.3761 G loss:-2.247\n",
      "Epoch:  0012 D loss:-0.4305 G loss:-2.316\n",
      "Epoch:  0012 D loss:-0.4228 G loss:-2.502\n",
      "Epoch:  0012 D loss:-0.4309 G loss:-2.267\n",
      "Epoch:  0012 D loss:-0.3492 G loss:-2.487\n",
      "Epoch:  0012 D loss:-0.3698 G loss:-2.392\n",
      "Epoch:  0012 D loss:-0.3856 G loss:-2.444\n",
      "Epoch:  0012 D loss:-0.4611 G loss:-2.368\n",
      "Epoch:  0012 D loss:-0.4033 G loss:-2.264\n",
      "Epoch:  0012 D loss:-0.3557 G loss:-2.449\n",
      "Epoch:  0012 D loss:-0.4195 G loss:-2.156\n",
      "Epoch:  0012 D loss:-0.2959 G loss:-2.408\n",
      "Epoch:  0012 D loss:-0.403 G loss:-2.259\n",
      "Epoch:  0012 D loss:-0.3738 G loss:-2.527\n",
      "Epoch:  0012 D loss:-0.425 G loss:-2.288\n",
      "Epoch:  0012 D loss:-0.3041 G loss:-2.549\n",
      "Epoch:  0012 D loss:-0.3686 G loss:-2.415\n",
      "Epoch:  0012 D loss:-0.3942 G loss:-2.454\n",
      "Epoch:  0012 D loss:-0.3731 G loss:-2.277\n",
      "Epoch:  0012 D loss:-0.487 G loss:-2.278\n",
      "Epoch:  0012 D loss:-0.3228 G loss:-2.527\n",
      "Epoch:  0012 D loss:-0.3827 G loss:-2.376\n",
      "Epoch:  0012 D loss:-0.4163 G loss:-2.344\n",
      "Epoch:  0012 D loss:-0.3111 G loss:-2.432\n",
      "Epoch:  0012 D loss:-0.3952 G loss:-2.35\n",
      "Epoch:  0012 D loss:-0.3889 G loss:-2.374\n",
      "Epoch:  0012 D loss:-0.3879 G loss:-2.278\n",
      "Epoch:  0012 D loss:-0.4656 G loss:-2.203\n",
      "Epoch:  0012 D loss:-0.3373 G loss:-2.301\n",
      "Epoch:  0012 D loss:-0.3902 G loss:-2.194\n",
      "Epoch:  0012 D loss:-0.3531 G loss:-2.302\n",
      "Epoch:  0012 D loss:-0.3174 G loss:-2.451\n",
      "Epoch:  0012 D loss:-0.3458 G loss:-2.58\n",
      "Epoch:  0012 D loss:-0.4072 G loss:-2.451\n",
      "Epoch:  0012 D loss:-0.3827 G loss:-2.389\n",
      "Epoch:  0012 D loss:-0.3761 G loss:-2.438\n",
      "Epoch:  0012 D loss:-0.3463 G loss:-2.472\n",
      "Epoch:  0012 D loss:-0.4636 G loss:-2.446\n",
      "Epoch:  0012 D loss:-0.3709 G loss:-2.613\n",
      "Epoch:  0012 D loss:-0.402 G loss:-2.433\n",
      "Epoch:  0012 D loss:-0.425 G loss:-2.433\n",
      "Epoch:  0012 D loss:-0.4066 G loss:-2.354\n",
      "Epoch:  0012 D loss:-0.3443 G loss:-2.393\n",
      "Epoch:  0012 D loss:-0.4215 G loss:-2.191\n",
      "Epoch:  0012 D loss:-0.3608 G loss:-2.318\n",
      "Epoch:  0012 D loss:-0.433 G loss:-2.18\n",
      "Epoch:  0012 D loss:-0.3764 G loss:-2.498\n",
      "Epoch:  0012 D loss:-0.346 G loss:-2.51\n",
      "Epoch:  0012 D loss:-0.3874 G loss:-2.37\n",
      "Epoch:  0012 D loss:-0.3941 G loss:-2.446\n",
      "Epoch:  0012 D loss:-0.3623 G loss:-2.427\n",
      "Epoch:  0012 D loss:-0.4002 G loss:-2.258\n",
      "Epoch:  0012 D loss:-0.4105 G loss:-2.238\n",
      "Epoch:  0012 D loss:-0.4214 G loss:-2.412\n",
      "Epoch:  0012 D loss:-0.3466 G loss:-2.349\n",
      "Epoch:  0012 D loss:-0.4691 G loss:-2.339\n",
      "Epoch:  0012 D loss:-0.3182 G loss:-2.29\n",
      "Epoch:  0012 D loss:-0.5133 G loss:-2.222\n",
      "Epoch:  0012 D loss:-0.5472 G loss:-2.153\n",
      "Epoch:  0012 D loss:-0.467 G loss:-2.222\n",
      "Epoch:  0012 D loss:-0.538 G loss:-2.088\n",
      "Epoch:  0012 D loss:-0.4278 G loss:-2.252\n",
      "Epoch:  0012 D loss:-0.5337 G loss:-2.041\n",
      "Epoch:  0012 D loss:-0.3862 G loss:-2.318\n",
      "Epoch:  0012 D loss:-0.3923 G loss:-2.31\n",
      "Epoch:  0012 D loss:-0.3652 G loss:-2.392\n",
      "Epoch:  0012 D loss:-0.5002 G loss:-2.274\n",
      "Epoch:  0012 D loss:-0.3676 G loss:-2.29\n",
      "Epoch:  0012 D loss:-0.5097 G loss:-2.156\n",
      "Epoch:  0012 D loss:-0.4897 G loss:-2.137\n",
      "Epoch:  0012 D loss:-0.4117 G loss:-2.062\n",
      "Epoch:  0012 D loss:-0.4182 G loss:-2.101\n",
      "Epoch:  0012 D loss:-0.4611 G loss:-1.989\n",
      "Epoch:  0012 D loss:-0.378 G loss:-2.227\n",
      "Epoch:  0012 D loss:-0.4897 G loss:-2.149\n",
      "Epoch:  0012 D loss:-0.4958 G loss:-2.393\n",
      "Epoch:  0012 D loss:-0.3978 G loss:-2.262\n",
      "Epoch:  0012 D loss:-0.44 G loss:-2.311\n",
      "Epoch:  0012 D loss:-0.5134 G loss:-2.276\n",
      "Epoch:  0012 D loss:-0.4117 G loss:-2.285\n",
      "Epoch:  0012 D loss:-0.5329 G loss:-2.169\n",
      "Epoch:  0012 D loss:-0.4969 G loss:-2.008\n",
      "Epoch:  0012 D loss:-0.4463 G loss:-2.045\n",
      "Epoch:  0012 D loss:-0.4264 G loss:-2.024\n",
      "Epoch:  0012 D loss:-0.5184 G loss:-2.101\n",
      "Epoch:  0012 D loss:-0.3395 G loss:-2.032\n",
      "Epoch:  0012 D loss:-0.4666 G loss:-2.282\n",
      "Epoch:  0012 D loss:-0.4686 G loss:-2.211\n",
      "Epoch:  0012 D loss:-0.4024 G loss:-2.22\n",
      "Epoch:  0012 D loss:-0.4964 G loss:-2.078\n",
      "Epoch:  0012 D loss:-0.4539 G loss:-2.049\n",
      "Epoch:  0012 D loss:-0.4924 G loss:-2.09\n",
      "Epoch:  0012 D loss:-0.3853 G loss:-2.143\n",
      "Epoch:  0012 D loss:-0.465 G loss:-2.23\n",
      "Epoch:  0012 D loss:-0.5646 G loss:-2.208\n",
      "Epoch:  0012 D loss:-0.481 G loss:-2.315\n",
      "Epoch:  0012 D loss:-0.5478 G loss:-2.065\n",
      "Epoch:  0012 D loss:-0.5307 G loss:-2.167\n",
      "Epoch:  0012 D loss:-0.5506 G loss:-2.018\n",
      "Epoch:  0012 D loss:-0.5364 G loss:-1.881\n",
      "Epoch:  0012 D loss:-0.4844 G loss:-1.941\n",
      "Epoch:  0012 D loss:-0.5302 G loss:-1.983\n",
      "Epoch:  0012 D loss:-0.4402 G loss:-1.849\n",
      "Epoch:  0012 D loss:-0.5664 G loss:-1.854\n",
      "Epoch:  0012 D loss:-0.5758 G loss:-1.856\n",
      "Epoch:  0012 D loss:-0.5068 G loss:-2.097\n",
      "Epoch:  0012 D loss:-0.5621 G loss:-1.985\n",
      "Epoch:  0012 D loss:-0.4762 G loss:-2.089\n",
      "Epoch:  0012 D loss:-0.6279 G loss:-2.074\n",
      "Epoch:  0012 D loss:-0.4545 G loss:-2.093\n",
      "Epoch:  0012 D loss:-0.5024 G loss:-1.927\n",
      "Epoch:  0012 D loss:-0.5921 G loss:-1.927\n",
      "Epoch:  0012 D loss:-0.5704 G loss:-2.06\n",
      "Epoch:  0012 D loss:-0.5019 G loss:-2.039\n",
      "Epoch:  0012 D loss:-0.5361 G loss:-2.061\n",
      "Epoch:  0012 D loss:-0.5513 G loss:-2.011\n",
      "Epoch:  0012 D loss:-0.5382 G loss:-1.824\n",
      "Epoch:  0012 D loss:-0.5128 G loss:-1.966\n",
      "Epoch:  0012 D loss:-0.6454 G loss:-1.836\n",
      "Epoch:  0012 D loss:-0.5876 G loss:-1.795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0012 D loss:-0.5229 G loss:-1.944\n",
      "Epoch:  0012 D loss:-0.5321 G loss:-1.854\n",
      "Epoch:  0012 D loss:-0.618 G loss:-1.888\n",
      "Epoch:  0012 D loss:-0.6182 G loss:-1.979\n",
      "Epoch:  0012 D loss:-0.5549 G loss:-1.948\n",
      "Epoch:  0012 D loss:-0.5183 G loss:-1.981\n",
      "Epoch:  0012 D loss:-0.7336 G loss:-1.816\n",
      "Epoch:  0012 D loss:-0.6777 G loss:-1.91\n",
      "Epoch:  0012 D loss:-0.6014 G loss:-1.881\n",
      "Epoch:  0012 D loss:-0.6541 G loss:-1.819\n",
      "Epoch:  0012 D loss:-0.6205 G loss:-1.827\n",
      "Epoch:  0012 D loss:-0.4401 G loss:-1.877\n",
      "Epoch:  0012 D loss:-0.5598 G loss:-1.912\n",
      "Epoch:  0012 D loss:-0.6112 G loss:-1.778\n",
      "Epoch:  0012 D loss:-0.6098 G loss:-1.864\n",
      "Epoch:  0012 D loss:-0.635 G loss:-1.838\n",
      "Epoch:  0012 D loss:-0.6382 G loss:-1.852\n",
      "Epoch:  0012 D loss:-0.6013 G loss:-1.914\n",
      "Epoch:  0012 D loss:-0.5317 G loss:-1.998\n",
      "Epoch:  0012 D loss:-0.5614 G loss:-2.036\n",
      "Epoch:  0012 D loss:-0.5079 G loss:-2.059\n",
      "Epoch:  0012 D loss:-0.6527 G loss:-1.884\n",
      "Epoch:  0012 D loss:-0.5555 G loss:-2.048\n",
      "Epoch:  0012 D loss:-0.4811 G loss:-1.996\n",
      "Epoch:  0012 D loss:-0.5133 G loss:-2.04\n",
      "Epoch:  0012 D loss:-0.5634 G loss:-2.046\n",
      "Epoch:  0012 D loss:-0.5018 G loss:-2.141\n",
      "Epoch:  0012 D loss:-0.5173 G loss:-1.951\n",
      "Epoch:  0012 D loss:-0.5465 G loss:-1.853\n",
      "Epoch:  0012 D loss:-0.555 G loss:-1.862\n",
      "Epoch:  0012 D loss:-0.5037 G loss:-1.859\n",
      "Epoch:  0012 D loss:-0.4769 G loss:-1.919\n",
      "Epoch:  0012 D loss:-0.4386 G loss:-2.079\n",
      "Epoch:  0012 D loss:-0.5001 G loss:-2.103\n",
      "Epoch:  0012 D loss:-0.5393 G loss:-1.958\n",
      "Epoch:  0012 D loss:-0.5679 G loss:-2.109\n",
      "Epoch:  0012 D loss:-0.478 G loss:-2.074\n",
      "Epoch:  0012 D loss:-0.3915 G loss:-2.167\n",
      "Epoch:  0012 D loss:-0.4646 G loss:-2.157\n",
      "Epoch:  0012 D loss:-0.5715 G loss:-2.144\n",
      "Epoch:  0012 D loss:-0.4037 G loss:-2.083\n",
      "Epoch:  0012 D loss:-0.461 G loss:-1.983\n",
      "Epoch:  0012 D loss:-0.4475 G loss:-1.991\n",
      "Epoch:  0012 D loss:-0.4617 G loss:-2.124\n",
      "Epoch:  0012 D loss:-0.442 G loss:-2.159\n",
      "Epoch:  0012 D loss:-0.3828 G loss:-2.209\n",
      "Epoch:  0012 D loss:-0.4015 G loss:-2.247\n",
      "Epoch:  0012 D loss:-0.3937 G loss:-2.166\n",
      "Epoch:  0012 D loss:-0.4974 G loss:-2.276\n",
      "Epoch:  0012 D loss:-0.4305 G loss:-2.232\n",
      "Epoch:  0012 D loss:-0.3158 G loss:-2.272\n",
      "Epoch:  0012 D loss:-0.397 G loss:-2.261\n",
      "Epoch:  0012 D loss:-0.3683 G loss:-2.246\n",
      "Epoch:  0012 D loss:-0.3575 G loss:-2.199\n",
      "Epoch:  0012 D loss:-0.3815 G loss:-2.133\n",
      "Epoch:  0012 D loss:-0.4069 G loss:-2.201\n",
      "Epoch:  0012 D loss:-0.3625 G loss:-2.077\n",
      "Epoch:  0012 D loss:-0.372 G loss:-2.262\n",
      "Epoch:  0012 D loss:-0.433 G loss:-2.179\n",
      "Epoch:  0012 D loss:-0.449 G loss:-2.076\n",
      "Epoch:  0012 D loss:-0.3921 G loss:-2.213\n",
      "Epoch:  0012 D loss:-0.3052 G loss:-2.206\n",
      "Epoch:  0012 D loss:-0.374 G loss:-2.135\n",
      "Epoch:  0012 D loss:-0.3623 G loss:-2.124\n",
      "Epoch:  0012 D loss:-0.443 G loss:-2.177\n",
      "Epoch:  0012 D loss:-0.3777 G loss:-2.155\n",
      "Epoch:  0012 D loss:-0.34 G loss:-2.077\n",
      "Epoch:  0012 D loss:-0.4116 G loss:-2.127\n",
      "Epoch:  0012 D loss:-0.3419 G loss:-2.068\n",
      "Epoch:  0012 D loss:-0.3936 G loss:-2.235\n",
      "Epoch:  0012 D loss:-0.3818 G loss:-2.32\n",
      "Epoch:  0012 D loss:-0.4356 G loss:-2.185\n",
      "Epoch:  0012 D loss:-0.4312 G loss:-2.268\n",
      "Epoch:  0012 D loss:-0.3178 G loss:-2.302\n",
      "Epoch:  0012 D loss:-0.4198 G loss:-2.212\n",
      "Epoch:  0012 D loss:-0.3991 G loss:-2.195\n",
      "Epoch:  0012 D loss:-0.3883 G loss:-2.316\n",
      "Epoch:  0012 D loss:-0.4027 G loss:-2.229\n",
      "Epoch:  0012 D loss:-0.4063 G loss:-2.276\n",
      "Epoch:  0012 D loss:-0.3386 G loss:-2.083\n",
      "Epoch:  0012 D loss:-0.4008 G loss:-2.249\n",
      "Epoch:  0012 D loss:-0.4336 G loss:-2.128\n",
      "Epoch:  0012 D loss:-0.3826 G loss:-2.168\n",
      "Epoch:  0012 D loss:-0.3643 G loss:-2.035\n",
      "Epoch:  0012 D loss:-0.4075 G loss:-2.067\n",
      "Epoch:  0012 D loss:-0.4083 G loss:-1.961\n",
      "Epoch:  0012 D loss:-0.4535 G loss:-2.113\n",
      "Epoch:  0012 D loss:-0.3618 G loss:-2.317\n",
      "Epoch:  0012 D loss:-0.4161 G loss:-2.281\n",
      "Epoch:  0012 D loss:-0.3744 G loss:-2.225\n",
      "Epoch:  0012 D loss:-0.3964 G loss:-2.32\n",
      "Epoch:  0012 D loss:-0.4278 G loss:-2.3\n",
      "Epoch:  0012 D loss:-0.4357 G loss:-2.233\n",
      "Epoch:  0012 D loss:-0.4601 G loss:-2.232\n",
      "Epoch:  0012 D loss:-0.4536 G loss:-2.143\n",
      "Epoch:  0012 D loss:-0.389 G loss:-2.023\n",
      "Epoch:  0012 D loss:-0.4203 G loss:-2.062\n",
      "Epoch:  0012 D loss:-0.3711 G loss:-2.012\n",
      "Epoch:  0012 D loss:-0.347 G loss:-2.07\n",
      "Epoch:  0012 D loss:-0.4726 G loss:-2.176\n",
      "Epoch:  0012 D loss:-0.3637 G loss:-2.18\n",
      "Epoch:  0012 D loss:-0.3509 G loss:-2.145\n",
      "Epoch:  0012 D loss:-0.4431 G loss:-2.094\n",
      "Epoch:  0012 D loss:-0.3568 G loss:-2.217\n",
      "Epoch:  0012 D loss:-0.3701 G loss:-2.377\n",
      "Epoch:  0012 D loss:-0.3665 G loss:-2.201\n",
      "Epoch:  0012 D loss:-0.3699 G loss:-2.359\n",
      "Epoch:  0012 D loss:-0.4258 G loss:-2.288\n",
      "Epoch:  0012 D loss:-0.3465 G loss:-2.219\n",
      "Epoch:  0012 D loss:-0.4131 G loss:-2.414\n",
      "Epoch:  0012 D loss:-0.3731 G loss:-2.262\n",
      "Epoch:  0012 D loss:-0.4125 G loss:-2.241\n",
      "Epoch:  0012 D loss:-0.3849 G loss:-2.267\n",
      "Epoch:  0012 D loss:-0.3604 G loss:-2.248\n",
      "Epoch:  0012 D loss:-0.4581 G loss:-2.218\n",
      "Epoch:  0012 D loss:-0.4863 G loss:-2.174\n",
      "Epoch:  0012 D loss:-0.4688 G loss:-1.936\n",
      "Epoch:  0012 D loss:-0.4115 G loss:-2.038\n",
      "Epoch:  0012 D loss:-0.3884 G loss:-2.088\n",
      "Epoch:  0012 D loss:-0.3502 G loss:-2.22\n",
      "Epoch:  0012 D loss:-0.4706 G loss:-2.194\n",
      "Epoch:  0012 D loss:-0.4632 G loss:-2.284\n",
      "Epoch:  0012 D loss:-0.4534 G loss:-2.121\n",
      "Epoch:  0012 D loss:-0.41 G loss:-2.165\n",
      "Epoch:  0012 D loss:-0.4667 G loss:-2.26\n",
      "Epoch:  0012 D loss:-0.3934 G loss:-2.175\n",
      "Epoch:  0012 D loss:-0.3693 G loss:-2.195\n",
      "Epoch:  0012 D loss:-0.4653 G loss:-2.05\n",
      "Epoch:  0012 D loss:-0.395 G loss:-2.112\n",
      "Epoch:  0012 D loss:-0.4271 G loss:-2.122\n",
      "Epoch:  0012 D loss:-0.4547 G loss:-2.066\n",
      "Epoch:  0012 D loss:-0.4197 G loss:-2.231\n",
      "Epoch:  0012 D loss:-0.4878 G loss:-2.018\n",
      "Epoch:  0012 D loss:-0.4122 G loss:-2.15\n",
      "Epoch:  0012 D loss:-0.3987 G loss:-2.062\n",
      "Epoch:  0012 D loss:-0.416 G loss:-2.194\n",
      "Epoch:  0012 D loss:-0.3783 G loss:-2.043\n",
      "Epoch:  0012 D loss:-0.4329 G loss:-2.211\n",
      "Epoch:  0012 D loss:-0.4213 G loss:-2.122\n",
      "Epoch:  0012 D loss:-0.4209 G loss:-2.245\n",
      "Epoch:  0012 D loss:-0.4843 G loss:-2.084\n",
      "Epoch:  0012 D loss:-0.5489 G loss:-2.169\n",
      "Epoch:  0012 D loss:-0.3587 G loss:-2.283\n",
      "Epoch:  0012 D loss:-0.4806 G loss:-2.239\n",
      "Epoch:  0012 D loss:-0.46 G loss:-2.133\n",
      "Epoch:  0012 D loss:-0.5493 G loss:-2.249\n",
      "Epoch:  0012 D loss:-0.4359 G loss:-2.073\n",
      "Epoch:  0012 D loss:-0.4444 G loss:-2.096\n",
      "Epoch:  0012 D loss:-0.4315 G loss:-2.115\n",
      "Epoch:  0012 D loss:-0.4882 G loss:-1.977\n",
      "Epoch:  0012 D loss:-0.5024 G loss:-1.92\n",
      "Epoch:  0012 D loss:-0.4924 G loss:-2.052\n",
      "Epoch:  0012 D loss:-0.3937 G loss:-2.158\n",
      "Epoch:  0012 D loss:-0.3912 G loss:-2.116\n",
      "Epoch:  0012 D loss:-0.4559 G loss:-2.154\n",
      "Epoch:  0012 D loss:-0.4635 G loss:-2.21\n",
      "Epoch:  0012 D loss:-0.4476 G loss:-2.129\n",
      "Epoch:  0012 D loss:-0.4163 G loss:-2.123\n",
      "Epoch:  0012 D loss:-0.4034 G loss:-2.319\n",
      "Epoch:  0012 D loss:-0.4435 G loss:-2.222\n",
      "Epoch:  0012 D loss:-0.4167 G loss:-2.239\n",
      "Epoch:  0012 D loss:-0.3939 G loss:-2.18\n",
      "Epoch:  0012 D loss:-0.4053 G loss:-2.118\n",
      "Epoch:  0012 D loss:-0.5306 G loss:-2.088\n",
      "Epoch:  0012 D loss:-0.4242 G loss:-2.249\n",
      "Epoch:  0012 D loss:-0.5608 G loss:-2.087\n",
      "Epoch:  0012 D loss:-0.3797 G loss:-2.142\n",
      "Epoch:  0012 D loss:-0.4238 G loss:-1.99\n",
      "Epoch:  0012 D loss:-0.3199 G loss:-2.16\n",
      "Epoch:  0012 D loss:-0.5057 G loss:-2.052\n",
      "Epoch:  0012 D loss:-0.359 G loss:-2.133\n",
      "Epoch:  0012 D loss:-0.4573 G loss:-2.109\n",
      "Epoch:  0012 D loss:-0.395 G loss:-2.201\n",
      "Epoch:  0012 D loss:-0.3329 G loss:-2.27\n",
      "Epoch:  0012 D loss:-0.3765 G loss:-2.301\n",
      "Epoch:  0012 D loss:-0.4087 G loss:-2.277\n",
      "Epoch:  0012 D loss:-0.3745 G loss:-2.301\n",
      "Epoch:  0012 D loss:-0.395 G loss:-2.381\n",
      "Epoch:  0012 D loss:-0.3898 G loss:-2.284\n",
      "Epoch:  0012 D loss:-0.4128 G loss:-2.241\n",
      "Epoch:  0012 D loss:-0.3292 G loss:-2.278\n",
      "Epoch:  0012 D loss:-0.3465 G loss:-2.333\n",
      "Epoch:  0012 D loss:-0.3538 G loss:-2.357\n",
      "Epoch:  0012 D loss:-0.3725 G loss:-2.173\n",
      "Epoch:  0012 D loss:-0.3384 G loss:-2.27\n",
      "Epoch:  0012 D loss:-0.2814 G loss:-2.374\n",
      "Epoch:  0012 D loss:-0.3504 G loss:-2.271\n",
      "Epoch:  0012 D loss:-0.3222 G loss:-2.265\n",
      "Epoch:  0012 D loss:-0.3453 G loss:-2.366\n",
      "Epoch:  0012 D loss:-0.3543 G loss:-2.193\n",
      "Epoch:  0012 D loss:-0.4055 G loss:-2.282\n",
      "Epoch:  0012 D loss:-0.3654 G loss:-2.405\n",
      "Epoch:  0012 D loss:-0.3936 G loss:-2.262\n",
      "Epoch:  0012 D loss:-0.3586 G loss:-2.251\n",
      "Epoch:  0012 D loss:-0.3459 G loss:-2.304\n",
      "Epoch:  0012 D loss:-0.3212 G loss:-2.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0012 D loss:-0.3953 G loss:-2.354\n",
      "Epoch:  0012 D loss:-0.2909 G loss:-2.456\n",
      "Epoch:  0012 D loss:-0.3927 G loss:-2.398\n",
      "Epoch:  0012 D loss:-0.4278 G loss:-2.338\n",
      "Epoch:  0012 D loss:-0.3828 G loss:-2.309\n",
      "Epoch:  0012 D loss:-0.3758 G loss:-2.286\n",
      "Epoch:  0012 D loss:-0.3311 G loss:-2.333\n",
      "Epoch:  0012 D loss:-0.3693 G loss:-2.17\n",
      "Epoch:  0012 D loss:-0.4305 G loss:-2.103\n",
      "Epoch:  0012 D loss:-0.3763 G loss:-2.01\n",
      "Epoch:  0012 D loss:-0.3946 G loss:-2.081\n",
      "Epoch:  0012 D loss:-0.3567 G loss:-2.206\n",
      "Epoch:  0012 D loss:-0.4874 G loss:-2.079\n",
      "Epoch:  0012 D loss:-0.3948 G loss:-2.11\n",
      "Epoch:  0012 D loss:-0.3661 G loss:-2.184\n",
      "Epoch:  0012 D loss:-0.4374 G loss:-2.17\n",
      "Epoch:  0012 D loss:-0.3953 G loss:-2.189\n",
      "Epoch:  0012 D loss:-0.4128 G loss:-2.125\n",
      "Epoch:  0012 D loss:-0.4082 G loss:-2.127\n",
      "Epoch:  0012 D loss:-0.3698 G loss:-2.364\n",
      "Epoch:  0012 D loss:-0.337 G loss:-2.498\n",
      "Epoch:  0012 D loss:-0.3807 G loss:-2.371\n",
      "Epoch:  0012 D loss:-0.4121 G loss:-2.373\n",
      "Epoch:  0012 D loss:-0.3935 G loss:-2.302\n",
      "Epoch:  0012 D loss:-0.4118 G loss:-2.113\n",
      "Epoch:  0012 D loss:-0.3913 G loss:-2.181\n",
      "Epoch:  0012 D loss:-0.4304 G loss:-1.925\n",
      "Epoch:  0012 D loss:-0.3904 G loss:-2.1\n",
      "Epoch:  0012 D loss:-0.3916 G loss:-2.091\n",
      "Epoch:  0012 D loss:-0.3907 G loss:-2.327\n",
      "Epoch:  0012 D loss:-0.3421 G loss:-2.288\n",
      "Epoch:  0012 D loss:-0.3668 G loss:-2.224\n",
      "Epoch:  0012 D loss:-0.431 G loss:-2.144\n",
      "Epoch:  0012 D loss:-0.4258 G loss:-2.165\n",
      "Epoch:  0012 D loss:-0.3854 G loss:-2.162\n",
      "Epoch:  0012 D loss:-0.4552 G loss:-2.265\n",
      "Epoch:  0012 D loss:-0.4063 G loss:-2.136\n",
      "Epoch:  0012 D loss:-0.4625 G loss:-2.158\n",
      "Epoch:  0012 D loss:-0.388 G loss:-2.163\n",
      "Epoch:  0012 D loss:-0.4398 G loss:-2.181\n",
      "Epoch:  0012 D loss:-0.4281 G loss:-2.088\n",
      "Epoch:  0012 D loss:-0.3545 G loss:-2.119\n",
      "Epoch:  0012 D loss:-0.4903 G loss:-2.019\n",
      "Epoch:  0012 D loss:-0.3795 G loss:-2.116\n",
      "Epoch:  0012 D loss:-0.3719 G loss:-2.06\n",
      "Epoch:  0012 D loss:-0.3403 G loss:-2.221\n",
      "Epoch:  0012 D loss:-0.3703 G loss:-2.188\n",
      "Epoch:  0012 D loss:-0.386 G loss:-2.36\n",
      "Epoch:  0012 D loss:-0.3338 G loss:-2.449\n",
      "Epoch:  0012 D loss:-0.3454 G loss:-2.275\n",
      "Epoch:  0012 D loss:-0.3741 G loss:-2.24\n",
      "Epoch:  0012 D loss:-0.3806 G loss:-2.311\n",
      "Epoch:  0012 D loss:-0.3624 G loss:-2.333\n",
      "Epoch:  0012 D loss:-0.4241 G loss:-2.227\n",
      "Epoch:  0012 D loss:-0.4203 G loss:-2.223\n",
      "Epoch:  0012 D loss:-0.3276 G loss:-2.22\n",
      "Epoch:  0012 D loss:-0.388 G loss:-2.156\n",
      "Epoch:  0012 D loss:-0.4507 G loss:-2.159\n",
      "Epoch:  0012 D loss:-0.4342 G loss:-1.992\n",
      "Epoch:  0012 D loss:-0.4861 G loss:-2.114\n",
      "Epoch:  0012 D loss:-0.4315 G loss:-2.036\n",
      "Epoch:  0012 D loss:-0.3698 G loss:-2.048\n",
      "Epoch:  0012 D loss:-0.4712 G loss:-2.118\n",
      "Epoch:  0012 D loss:-0.3808 G loss:-2.09\n",
      "Epoch:  0012 D loss:-0.4095 G loss:-2.244\n",
      "Epoch:  0012 D loss:-0.4044 G loss:-2.049\n",
      "Epoch:  0012 D loss:-0.4685 G loss:-2.15\n",
      "Epoch:  0012 D loss:-0.3991 G loss:-2.081\n",
      "Epoch:  0012 D loss:-0.3985 G loss:-2.095\n",
      "Epoch:  0012 D loss:-0.4138 G loss:-2.132\n",
      "Epoch:  0012 D loss:-0.3796 G loss:-2.048\n",
      "Epoch:  0012 D loss:-0.3885 G loss:-2.079\n",
      "Epoch:  0012 D loss:-0.5022 G loss:-2.038\n",
      "Epoch:  0012 D loss:-0.3803 G loss:-2.167\n",
      "Epoch:  0012 D loss:-0.5026 G loss:-2.064\n",
      "Epoch:  0012 D loss:-0.4167 G loss:-2.063\n",
      "Epoch:  0012 D loss:-0.4089 G loss:-2.043\n",
      "Epoch:  0012 D loss:-0.3508 G loss:-2.131\n",
      "Epoch:  0012 D loss:-0.5189 G loss:-1.951\n",
      "Epoch:  0012 D loss:-0.3753 G loss:-2.039\n",
      "Epoch:  0012 D loss:-0.3899 G loss:-2.031\n",
      "Epoch:  0012 D loss:-0.4377 G loss:-1.978\n",
      "Epoch:  0012 D loss:-0.4543 G loss:-2.03\n",
      "Epoch:  0012 D loss:-0.4452 G loss:-2.145\n",
      "Epoch:  0012 D loss:-0.4751 G loss:-1.927\n",
      "Epoch:  0012 D loss:-0.526 G loss:-2.03\n",
      "Epoch:  0012 D loss:-0.4538 G loss:-2.082\n",
      "Epoch:  0012 D loss:-0.4516 G loss:-2.027\n",
      "Epoch:  0012 D loss:-0.4293 G loss:-2.062\n",
      "Epoch:  0012 D loss:-0.4767 G loss:-1.948\n",
      "Epoch:  0012 D loss:-0.3475 G loss:-2.125\n",
      "Epoch:  0012 D loss:-0.4936 G loss:-2.017\n",
      "Epoch:  0012 D loss:-0.4045 G loss:-2.197\n",
      "Epoch:  0012 D loss:-0.4185 G loss:-2.104\n",
      "Epoch:  0012 D loss:-0.4699 G loss:-2.072\n",
      "Epoch:  0012 D loss:-0.4851 G loss:-2.052\n",
      "Epoch:  0012 D loss:-0.4214 G loss:-2.041\n",
      "Epoch:  0012 D loss:-0.4486 G loss:-2.112\n",
      "Epoch:  0012 D loss:-0.4277 G loss:-1.952\n",
      "Epoch:  0012 D loss:-0.434 G loss:-2.09\n",
      "Epoch:  0012 D loss:-0.4013 G loss:-2.064\n",
      "Epoch:  0012 D loss:-0.4182 G loss:-2.162\n",
      "Epoch:  0012 D loss:-0.496 G loss:-1.931\n",
      "Epoch:  0012 D loss:-0.4413 G loss:-2.066\n",
      "Epoch:  0012 D loss:-0.5083 G loss:-2.071\n",
      "Epoch:  0012 D loss:-0.4314 G loss:-1.971\n",
      "Epoch:  0012 D loss:-0.4439 G loss:-2.152\n",
      "Epoch:  0012 D loss:-0.4457 G loss:-2.092\n",
      "Epoch:  0012 D loss:-0.3871 G loss:-2.117\n",
      "Epoch:  0012 D loss:-0.4513 G loss:-2.088\n",
      "Epoch:  0012 D loss:-0.3595 G loss:-2.125\n",
      "Epoch:  0012 D loss:-0.3838 G loss:-2.133\n",
      "Epoch:  0012 D loss:-0.4042 G loss:-2.263\n",
      "Epoch:  0012 D loss:-0.4675 G loss:-2.119\n",
      "Epoch:  0012 D loss:-0.4366 G loss:-2.143\n",
      "Epoch:  0012 D loss:-0.384 G loss:-2.213\n",
      "Epoch:  0012 D loss:-0.3617 G loss:-2.211\n",
      "Epoch:  0012 D loss:-0.4204 G loss:-2.16\n",
      "Epoch:  0012 D loss:-0.3864 G loss:-2.059\n",
      "Epoch:  0012 D loss:-0.3561 G loss:-2.207\n",
      "Epoch:  0012 D loss:-0.3422 G loss:-2.177\n",
      "Epoch:  0012 D loss:-0.4936 G loss:-2.085\n",
      "Epoch:  0012 D loss:-0.3507 G loss:-2.145\n",
      "Epoch:  0012 D loss:-0.4287 G loss:-2.259\n",
      "Epoch:  0012 D loss:-0.4379 G loss:-2.263\n",
      "Epoch:  0012 D loss:-0.407 G loss:-2.164\n",
      "Epoch:  0012 D loss:-0.3917 G loss:-2.176\n",
      "Epoch:  0012 D loss:-0.3708 G loss:-2.136\n",
      "Epoch:  0012 D loss:-0.371 G loss:-2.014\n",
      "Epoch:  0012 D loss:-0.4268 G loss:-2.136\n",
      "Epoch:  0012 D loss:-0.366 G loss:-2.181\n",
      "Epoch:  0013 D loss:-0.385 G loss:-2.098\n",
      "Epoch:  0013 D loss:-0.3704 G loss:-2.209\n",
      "Epoch:  0013 D loss:-0.3239 G loss:-2.318\n",
      "Epoch:  0013 D loss:-0.423 G loss:-2.224\n",
      "Epoch:  0013 D loss:-0.4059 G loss:-2.269\n",
      "Epoch:  0013 D loss:-0.3766 G loss:-2.374\n",
      "Epoch:  0013 D loss:-0.3612 G loss:-2.26\n",
      "Epoch:  0013 D loss:-0.3088 G loss:-2.271\n",
      "Epoch:  0013 D loss:-0.3387 G loss:-2.19\n",
      "Epoch:  0013 D loss:-0.3415 G loss:-2.235\n",
      "Epoch:  0013 D loss:-0.2642 G loss:-2.354\n",
      "Epoch:  0013 D loss:-0.3164 G loss:-2.414\n",
      "Epoch:  0013 D loss:-0.2917 G loss:-2.448\n",
      "Epoch:  0013 D loss:-0.301 G loss:-2.403\n",
      "Epoch:  0013 D loss:-0.3556 G loss:-2.286\n",
      "Epoch:  0013 D loss:-0.3155 G loss:-2.409\n",
      "Epoch:  0013 D loss:-0.2966 G loss:-2.253\n",
      "Epoch:  0013 D loss:-0.3726 G loss:-2.344\n",
      "Epoch:  0013 D loss:-0.3712 G loss:-2.199\n",
      "Epoch:  0013 D loss:-0.3286 G loss:-2.356\n",
      "Epoch:  0013 D loss:-0.3239 G loss:-2.26\n",
      "Epoch:  0013 D loss:-0.3826 G loss:-2.274\n",
      "Epoch:  0013 D loss:-0.3411 G loss:-2.266\n",
      "Epoch:  0013 D loss:-0.4231 G loss:-2.256\n",
      "Epoch:  0013 D loss:-0.3622 G loss:-2.237\n",
      "Epoch:  0013 D loss:-0.3108 G loss:-2.295\n",
      "Epoch:  0013 D loss:-0.4111 G loss:-2.192\n",
      "Epoch:  0013 D loss:-0.348 G loss:-2.098\n",
      "Epoch:  0013 D loss:-0.2673 G loss:-2.19\n",
      "Epoch:  0013 D loss:-0.4154 G loss:-2.226\n",
      "Epoch:  0013 D loss:-0.3549 G loss:-2.224\n",
      "Epoch:  0013 D loss:-0.336 G loss:-2.24\n",
      "Epoch:  0013 D loss:-0.406 G loss:-2.193\n",
      "Epoch:  0013 D loss:-0.3316 G loss:-2.334\n",
      "Epoch:  0013 D loss:-0.3218 G loss:-2.259\n",
      "Epoch:  0013 D loss:-0.3428 G loss:-2.167\n",
      "Epoch:  0013 D loss:-0.3111 G loss:-2.324\n",
      "Epoch:  0013 D loss:-0.3118 G loss:-2.37\n",
      "Epoch:  0013 D loss:-0.3019 G loss:-2.414\n",
      "Epoch:  0013 D loss:-0.341 G loss:-2.42\n",
      "Epoch:  0013 D loss:-0.4076 G loss:-2.339\n",
      "Epoch:  0013 D loss:-0.3571 G loss:-2.428\n",
      "Epoch:  0013 D loss:-0.4053 G loss:-2.361\n",
      "Epoch:  0013 D loss:-0.314 G loss:-2.261\n",
      "Epoch:  0013 D loss:-0.3544 G loss:-2.261\n",
      "Epoch:  0013 D loss:-0.3578 G loss:-2.096\n",
      "Epoch:  0013 D loss:-0.3602 G loss:-2.173\n",
      "Epoch:  0013 D loss:-0.3109 G loss:-2.157\n",
      "Epoch:  0013 D loss:-0.3688 G loss:-2.06\n",
      "Epoch:  0013 D loss:-0.3116 G loss:-2.186\n",
      "Epoch:  0013 D loss:-0.3716 G loss:-2.182\n",
      "Epoch:  0013 D loss:-0.315 G loss:-2.188\n",
      "Epoch:  0013 D loss:-0.3829 G loss:-2.249\n",
      "Epoch:  0013 D loss:-0.4262 G loss:-2.125\n",
      "Epoch:  0013 D loss:-0.3525 G loss:-2.172\n",
      "Epoch:  0013 D loss:-0.3409 G loss:-2.191\n",
      "Epoch:  0013 D loss:-0.3409 G loss:-2.221\n",
      "Epoch:  0013 D loss:-0.351 G loss:-2.322\n",
      "Epoch:  0013 D loss:-0.3013 G loss:-2.34\n",
      "Epoch:  0013 D loss:-0.3629 G loss:-2.276\n",
      "Epoch:  0013 D loss:-0.4171 G loss:-2.268\n",
      "Epoch:  0013 D loss:-0.3077 G loss:-2.256\n",
      "Epoch:  0013 D loss:-0.2981 G loss:-2.373\n",
      "Epoch:  0013 D loss:-0.4064 G loss:-2.306\n",
      "Epoch:  0013 D loss:-0.3338 G loss:-2.214\n",
      "Epoch:  0013 D loss:-0.341 G loss:-2.169\n",
      "Epoch:  0013 D loss:-0.4308 G loss:-2.125\n",
      "Epoch:  0013 D loss:-0.3982 G loss:-1.998\n",
      "Epoch:  0013 D loss:-0.2967 G loss:-2.18\n",
      "Epoch:  0013 D loss:-0.3083 G loss:-2.186\n",
      "Epoch:  0013 D loss:-0.3407 G loss:-2.309\n",
      "Epoch:  0013 D loss:-0.3695 G loss:-2.257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0013 D loss:-0.3602 G loss:-2.169\n",
      "Epoch:  0013 D loss:-0.3406 G loss:-2.201\n",
      "Epoch:  0013 D loss:-0.3516 G loss:-2.203\n",
      "Epoch:  0013 D loss:-0.3511 G loss:-2.167\n",
      "Epoch:  0013 D loss:-0.4422 G loss:-2.25\n",
      "Epoch:  0013 D loss:-0.3101 G loss:-2.205\n",
      "Epoch:  0013 D loss:-0.3812 G loss:-2.129\n",
      "Epoch:  0013 D loss:-0.3217 G loss:-2.28\n",
      "Epoch:  0013 D loss:-0.3464 G loss:-2.288\n",
      "Epoch:  0013 D loss:-0.3229 G loss:-2.212\n",
      "Epoch:  0013 D loss:-0.2867 G loss:-2.421\n",
      "Epoch:  0013 D loss:-0.3295 G loss:-2.301\n",
      "Epoch:  0013 D loss:-0.3537 G loss:-2.213\n",
      "Epoch:  0013 D loss:-0.3716 G loss:-2.184\n",
      "Epoch:  0013 D loss:-0.296 G loss:-2.282\n",
      "Epoch:  0013 D loss:-0.3713 G loss:-2.187\n",
      "Epoch:  0013 D loss:-0.3413 G loss:-2.307\n",
      "Epoch:  0013 D loss:-0.3145 G loss:-2.22\n",
      "Epoch:  0013 D loss:-0.3159 G loss:-2.125\n",
      "Epoch:  0013 D loss:-0.3523 G loss:-2.157\n",
      "Epoch:  0013 D loss:-0.2912 G loss:-2.312\n",
      "Epoch:  0013 D loss:-0.3474 G loss:-2.267\n",
      "Epoch:  0013 D loss:-0.3389 G loss:-2.272\n",
      "Epoch:  0013 D loss:-0.364 G loss:-2.238\n",
      "Epoch:  0013 D loss:-0.3545 G loss:-2.187\n",
      "Epoch:  0013 D loss:-0.3117 G loss:-2.188\n",
      "Epoch:  0013 D loss:-0.3894 G loss:-2.209\n",
      "Epoch:  0013 D loss:-0.4502 G loss:-2.196\n",
      "Epoch:  0013 D loss:-0.3962 G loss:-2.256\n",
      "Epoch:  0013 D loss:-0.4279 G loss:-2.063\n",
      "Epoch:  0013 D loss:-0.4073 G loss:-2.146\n",
      "Epoch:  0013 D loss:-0.3906 G loss:-2.056\n",
      "Epoch:  0013 D loss:-0.3272 G loss:-2.053\n",
      "Epoch:  0013 D loss:-0.3822 G loss:-2.098\n",
      "Epoch:  0013 D loss:-0.3337 G loss:-2.114\n",
      "Epoch:  0013 D loss:-0.3443 G loss:-2.136\n",
      "Epoch:  0013 D loss:-0.3551 G loss:-2.197\n",
      "Epoch:  0013 D loss:-0.3916 G loss:-2.142\n",
      "Epoch:  0013 D loss:-0.4072 G loss:-2.22\n",
      "Epoch:  0013 D loss:-0.3262 G loss:-2.15\n",
      "Epoch:  0013 D loss:-0.2993 G loss:-2.268\n",
      "Epoch:  0013 D loss:-0.3256 G loss:-2.238\n",
      "Epoch:  0013 D loss:-0.3502 G loss:-2.173\n",
      "Epoch:  0013 D loss:-0.3411 G loss:-2.351\n",
      "Epoch:  0013 D loss:-0.4012 G loss:-2.442\n",
      "Epoch:  0013 D loss:-0.3391 G loss:-2.396\n",
      "Epoch:  0013 D loss:-0.334 G loss:-2.353\n",
      "Epoch:  0013 D loss:-0.4005 G loss:-2.245\n",
      "Epoch:  0013 D loss:-0.3283 G loss:-2.27\n",
      "Epoch:  0013 D loss:-0.3947 G loss:-2.188\n",
      "Epoch:  0013 D loss:-0.396 G loss:-2.196\n",
      "Epoch:  0013 D loss:-0.4719 G loss:-2.063\n",
      "Epoch:  0013 D loss:-0.3954 G loss:-1.943\n",
      "Epoch:  0013 D loss:-0.3758 G loss:-1.847\n",
      "Epoch:  0013 D loss:-0.3925 G loss:-1.964\n",
      "Epoch:  0013 D loss:-0.4368 G loss:-1.928\n",
      "Epoch:  0013 D loss:-0.3628 G loss:-1.948\n",
      "Epoch:  0013 D loss:-0.4073 G loss:-2.032\n",
      "Epoch:  0013 D loss:-0.3933 G loss:-2.207\n",
      "Epoch:  0013 D loss:-0.339 G loss:-2.153\n",
      "Epoch:  0013 D loss:-0.4376 G loss:-2.198\n",
      "Epoch:  0013 D loss:-0.3605 G loss:-2.229\n",
      "Epoch:  0013 D loss:-0.381 G loss:-2.249\n",
      "Epoch:  0013 D loss:-0.3864 G loss:-2.203\n",
      "Epoch:  0013 D loss:-0.3919 G loss:-2.198\n",
      "Epoch:  0013 D loss:-0.424 G loss:-2.177\n",
      "Epoch:  0013 D loss:-0.3718 G loss:-2.16\n",
      "Epoch:  0013 D loss:-0.3933 G loss:-2.233\n",
      "Epoch:  0013 D loss:-0.4283 G loss:-1.985\n",
      "Epoch:  0013 D loss:-0.4513 G loss:-1.934\n",
      "Epoch:  0013 D loss:-0.4263 G loss:-2.001\n",
      "Epoch:  0013 D loss:-0.37 G loss:-2.099\n",
      "Epoch:  0013 D loss:-0.3465 G loss:-2.176\n",
      "Epoch:  0013 D loss:-0.435 G loss:-2.144\n",
      "Epoch:  0013 D loss:-0.3627 G loss:-2.298\n",
      "Epoch:  0013 D loss:-0.3662 G loss:-2.339\n",
      "Epoch:  0013 D loss:-0.3473 G loss:-2.407\n",
      "Epoch:  0013 D loss:-0.4378 G loss:-2.311\n",
      "Epoch:  0013 D loss:-0.374 G loss:-2.21\n",
      "Epoch:  0013 D loss:-0.3259 G loss:-2.266\n",
      "Epoch:  0013 D loss:-0.4192 G loss:-2.13\n",
      "Epoch:  0013 D loss:-0.4527 G loss:-2.138\n",
      "Epoch:  0013 D loss:-0.3916 G loss:-2.056\n",
      "Epoch:  0013 D loss:-0.3876 G loss:-2.075\n",
      "Epoch:  0013 D loss:-0.4149 G loss:-2.048\n",
      "Epoch:  0013 D loss:-0.4829 G loss:-1.842\n",
      "Epoch:  0013 D loss:-0.3627 G loss:-1.958\n",
      "Epoch:  0013 D loss:-0.4585 G loss:-1.988\n",
      "Epoch:  0013 D loss:-0.3664 G loss:-2.028\n",
      "Epoch:  0013 D loss:-0.4127 G loss:-2.054\n",
      "Epoch:  0013 D loss:-0.4929 G loss:-2.05\n",
      "Epoch:  0013 D loss:-0.4107 G loss:-2.027\n",
      "Epoch:  0013 D loss:-0.3677 G loss:-2.189\n",
      "Epoch:  0013 D loss:-0.52 G loss:-2.194\n",
      "Epoch:  0013 D loss:-0.4062 G loss:-2.205\n",
      "Epoch:  0013 D loss:-0.3776 G loss:-2.077\n",
      "Epoch:  0013 D loss:-0.4339 G loss:-2.149\n",
      "Epoch:  0013 D loss:-0.4564 G loss:-2.172\n",
      "Epoch:  0013 D loss:-0.3771 G loss:-2.065\n",
      "Epoch:  0013 D loss:-0.3118 G loss:-2.119\n",
      "Epoch:  0013 D loss:-0.3863 G loss:-2.12\n",
      "Epoch:  0013 D loss:-0.4424 G loss:-2.077\n",
      "Epoch:  0013 D loss:-0.4347 G loss:-1.981\n",
      "Epoch:  0013 D loss:-0.3337 G loss:-2.128\n",
      "Epoch:  0013 D loss:-0.3424 G loss:-2.143\n",
      "Epoch:  0013 D loss:-0.3557 G loss:-2.245\n",
      "Epoch:  0013 D loss:-0.3904 G loss:-2.355\n",
      "Epoch:  0013 D loss:-0.4678 G loss:-2.194\n",
      "Epoch:  0013 D loss:-0.4161 G loss:-2.123\n",
      "Epoch:  0013 D loss:-0.4889 G loss:-2.275\n",
      "Epoch:  0013 D loss:-0.3602 G loss:-2.091\n",
      "Epoch:  0013 D loss:-0.4221 G loss:-2.14\n",
      "Epoch:  0013 D loss:-0.3619 G loss:-2.1\n",
      "Epoch:  0013 D loss:-0.4113 G loss:-2.129\n",
      "Epoch:  0013 D loss:-0.3801 G loss:-2.121\n",
      "Epoch:  0013 D loss:-0.3725 G loss:-2.267\n",
      "Epoch:  0013 D loss:-0.42 G loss:-2.15\n",
      "Epoch:  0013 D loss:-0.3856 G loss:-2.252\n",
      "Epoch:  0013 D loss:-0.4161 G loss:-2.281\n",
      "Epoch:  0013 D loss:-0.3258 G loss:-2.096\n",
      "Epoch:  0013 D loss:-0.3534 G loss:-2.209\n",
      "Epoch:  0013 D loss:-0.3441 G loss:-2.291\n",
      "Epoch:  0013 D loss:-0.4026 G loss:-2.288\n",
      "Epoch:  0013 D loss:-0.358 G loss:-2.205\n",
      "Epoch:  0013 D loss:-0.3806 G loss:-2.299\n",
      "Epoch:  0013 D loss:-0.3843 G loss:-2.276\n",
      "Epoch:  0013 D loss:-0.3845 G loss:-2.18\n",
      "Epoch:  0013 D loss:-0.3985 G loss:-2.259\n",
      "Epoch:  0013 D loss:-0.3838 G loss:-2.379\n",
      "Epoch:  0013 D loss:-0.3878 G loss:-2.217\n",
      "Epoch:  0013 D loss:-0.3788 G loss:-2.244\n",
      "Epoch:  0013 D loss:-0.4436 G loss:-2.143\n",
      "Epoch:  0013 D loss:-0.373 G loss:-2.018\n",
      "Epoch:  0013 D loss:-0.4062 G loss:-2.01\n",
      "Epoch:  0013 D loss:-0.3845 G loss:-2.011\n",
      "Epoch:  0013 D loss:-0.4314 G loss:-1.993\n",
      "Epoch:  0013 D loss:-0.3976 G loss:-2.083\n",
      "Epoch:  0013 D loss:-0.412 G loss:-2.18\n",
      "Epoch:  0013 D loss:-0.3383 G loss:-2.198\n",
      "Epoch:  0013 D loss:-0.3525 G loss:-2.39\n",
      "Epoch:  0013 D loss:-0.4308 G loss:-2.291\n",
      "Epoch:  0013 D loss:-0.3349 G loss:-2.354\n",
      "Epoch:  0013 D loss:-0.3655 G loss:-2.439\n",
      "Epoch:  0013 D loss:-0.3926 G loss:-2.531\n",
      "Epoch:  0013 D loss:-0.3962 G loss:-2.376\n",
      "Epoch:  0013 D loss:-0.4249 G loss:-2.353\n",
      "Epoch:  0013 D loss:-0.4099 G loss:-2.194\n",
      "Epoch:  0013 D loss:-0.4502 G loss:-2.177\n",
      "Epoch:  0013 D loss:-0.3379 G loss:-2.187\n",
      "Epoch:  0013 D loss:-0.4232 G loss:-2.012\n",
      "Epoch:  0013 D loss:-0.331 G loss:-2.002\n",
      "Epoch:  0013 D loss:-0.5102 G loss:-1.982\n",
      "Epoch:  0013 D loss:-0.3844 G loss:-2.217\n",
      "Epoch:  0013 D loss:-0.3747 G loss:-2.246\n",
      "Epoch:  0013 D loss:-0.3444 G loss:-2.245\n",
      "Epoch:  0013 D loss:-0.4293 G loss:-2.231\n",
      "Epoch:  0013 D loss:-0.3279 G loss:-2.287\n",
      "Epoch:  0013 D loss:-0.3915 G loss:-2.313\n",
      "Epoch:  0013 D loss:-0.3636 G loss:-2.438\n",
      "Epoch:  0013 D loss:-0.3251 G loss:-2.34\n",
      "Epoch:  0013 D loss:-0.3592 G loss:-2.408\n",
      "Epoch:  0013 D loss:-0.3103 G loss:-2.462\n",
      "Epoch:  0013 D loss:-0.3394 G loss:-2.295\n",
      "Epoch:  0013 D loss:-0.3974 G loss:-2.368\n",
      "Epoch:  0013 D loss:-0.3787 G loss:-2.246\n",
      "Epoch:  0013 D loss:-0.3487 G loss:-2.217\n",
      "Epoch:  0013 D loss:-0.3158 G loss:-2.246\n",
      "Epoch:  0013 D loss:-0.3699 G loss:-2.291\n",
      "Epoch:  0013 D loss:-0.2547 G loss:-2.448\n",
      "Epoch:  0013 D loss:-0.3322 G loss:-2.348\n",
      "Epoch:  0013 D loss:-0.3434 G loss:-2.47\n",
      "Epoch:  0013 D loss:-0.3839 G loss:-2.359\n",
      "Epoch:  0013 D loss:-0.3509 G loss:-2.237\n",
      "Epoch:  0013 D loss:-0.2896 G loss:-2.269\n",
      "Epoch:  0013 D loss:-0.3027 G loss:-2.372\n",
      "Epoch:  0013 D loss:-0.2993 G loss:-2.311\n",
      "Epoch:  0013 D loss:-0.3849 G loss:-2.33\n",
      "Epoch:  0013 D loss:-0.3548 G loss:-2.21\n",
      "Epoch:  0013 D loss:-0.3808 G loss:-2.218\n",
      "Epoch:  0013 D loss:-0.3054 G loss:-2.268\n",
      "Epoch:  0013 D loss:-0.3626 G loss:-2.143\n",
      "Epoch:  0013 D loss:-0.3393 G loss:-2.203\n",
      "Epoch:  0013 D loss:-0.3346 G loss:-2.203\n",
      "Epoch:  0013 D loss:-0.3387 G loss:-2.387\n",
      "Epoch:  0013 D loss:-0.3228 G loss:-2.375\n",
      "Epoch:  0013 D loss:-0.3864 G loss:-2.29\n",
      "Epoch:  0013 D loss:-0.3289 G loss:-2.373\n",
      "Epoch:  0013 D loss:-0.3746 G loss:-2.35\n",
      "Epoch:  0013 D loss:-0.273 G loss:-2.321\n",
      "Epoch:  0013 D loss:-0.3296 G loss:-2.334\n",
      "Epoch:  0013 D loss:-0.2998 G loss:-2.307\n",
      "Epoch:  0013 D loss:-0.3686 G loss:-2.377\n",
      "Epoch:  0013 D loss:-0.2973 G loss:-2.39\n",
      "Epoch:  0013 D loss:-0.3432 G loss:-2.297\n",
      "Epoch:  0013 D loss:-0.3524 G loss:-2.371\n",
      "Epoch:  0013 D loss:-0.3203 G loss:-2.257\n",
      "Epoch:  0013 D loss:-0.3302 G loss:-2.4\n",
      "Epoch:  0013 D loss:-0.4608 G loss:-2.207\n",
      "Epoch:  0013 D loss:-0.3335 G loss:-2.375\n",
      "Epoch:  0013 D loss:-0.2659 G loss:-2.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0013 D loss:-0.332 G loss:-2.224\n",
      "Epoch:  0013 D loss:-0.3491 G loss:-2.197\n",
      "Epoch:  0013 D loss:-0.3052 G loss:-2.346\n",
      "Epoch:  0013 D loss:-0.3538 G loss:-2.277\n",
      "Epoch:  0013 D loss:-0.2636 G loss:-2.294\n",
      "Epoch:  0013 D loss:-0.3301 G loss:-2.336\n",
      "Epoch:  0013 D loss:-0.3478 G loss:-2.304\n",
      "Epoch:  0013 D loss:-0.3463 G loss:-2.35\n",
      "Epoch:  0013 D loss:-0.3845 G loss:-2.468\n",
      "Epoch:  0013 D loss:-0.338 G loss:-2.386\n",
      "Epoch:  0013 D loss:-0.3951 G loss:-2.308\n",
      "Epoch:  0013 D loss:-0.3354 G loss:-2.307\n",
      "Epoch:  0013 D loss:-0.3904 G loss:-2.27\n",
      "Epoch:  0013 D loss:-0.3439 G loss:-2.238\n",
      "Epoch:  0013 D loss:-0.3576 G loss:-2.143\n",
      "Epoch:  0013 D loss:-0.3171 G loss:-2.114\n",
      "Epoch:  0013 D loss:-0.3813 G loss:-2.175\n",
      "Epoch:  0013 D loss:-0.3511 G loss:-2.181\n",
      "Epoch:  0013 D loss:-0.2991 G loss:-2.29\n",
      "Epoch:  0013 D loss:-0.3017 G loss:-2.305\n",
      "Epoch:  0013 D loss:-0.3347 G loss:-2.303\n",
      "Epoch:  0013 D loss:-0.3325 G loss:-2.307\n",
      "Epoch:  0013 D loss:-0.3043 G loss:-2.455\n",
      "Epoch:  0013 D loss:-0.3357 G loss:-2.569\n",
      "Epoch:  0013 D loss:-0.3315 G loss:-2.457\n",
      "Epoch:  0013 D loss:-0.3074 G loss:-2.497\n",
      "Epoch:  0013 D loss:-0.3255 G loss:-2.487\n",
      "Epoch:  0013 D loss:-0.3326 G loss:-2.486\n",
      "Epoch:  0013 D loss:-0.3008 G loss:-2.308\n",
      "Epoch:  0013 D loss:-0.3587 G loss:-2.262\n",
      "Epoch:  0013 D loss:-0.2603 G loss:-2.298\n",
      "Epoch:  0013 D loss:-0.4783 G loss:-2.196\n",
      "Epoch:  0013 D loss:-0.3859 G loss:-2.109\n",
      "Epoch:  0013 D loss:-0.3684 G loss:-2.108\n",
      "Epoch:  0013 D loss:-0.357 G loss:-2.21\n",
      "Epoch:  0013 D loss:-0.3297 G loss:-2.272\n",
      "Epoch:  0013 D loss:-0.3691 G loss:-2.148\n",
      "Epoch:  0013 D loss:-0.3351 G loss:-2.233\n",
      "Epoch:  0013 D loss:-0.3626 G loss:-2.302\n",
      "Epoch:  0013 D loss:-0.3465 G loss:-2.372\n",
      "Epoch:  0013 D loss:-0.3479 G loss:-2.382\n",
      "Epoch:  0013 D loss:-0.2858 G loss:-2.383\n",
      "Epoch:  0013 D loss:-0.3698 G loss:-2.317\n",
      "Epoch:  0013 D loss:-0.3259 G loss:-2.42\n",
      "Epoch:  0013 D loss:-0.2646 G loss:-2.414\n",
      "Epoch:  0013 D loss:-0.3003 G loss:-2.369\n",
      "Epoch:  0013 D loss:-0.3561 G loss:-2.408\n",
      "Epoch:  0013 D loss:-0.31 G loss:-2.504\n",
      "Epoch:  0013 D loss:-0.2814 G loss:-2.67\n",
      "Epoch:  0013 D loss:-0.3627 G loss:-2.407\n",
      "Epoch:  0013 D loss:-0.2518 G loss:-2.532\n",
      "Epoch:  0013 D loss:-0.3301 G loss:-2.515\n",
      "Epoch:  0013 D loss:-0.3694 G loss:-2.498\n",
      "Epoch:  0013 D loss:-0.3245 G loss:-2.317\n",
      "Epoch:  0013 D loss:-0.3679 G loss:-2.309\n",
      "Epoch:  0013 D loss:-0.3236 G loss:-2.384\n",
      "Epoch:  0013 D loss:-0.3097 G loss:-2.298\n",
      "Epoch:  0013 D loss:-0.3136 G loss:-2.334\n",
      "Epoch:  0013 D loss:-0.3115 G loss:-2.177\n",
      "Epoch:  0013 D loss:-0.3806 G loss:-2.071\n",
      "Epoch:  0013 D loss:-0.3504 G loss:-2.203\n",
      "Epoch:  0013 D loss:-0.3441 G loss:-2.263\n",
      "Epoch:  0013 D loss:-0.3318 G loss:-2.229\n",
      "Epoch:  0013 D loss:-0.3852 G loss:-2.279\n",
      "Epoch:  0013 D loss:-0.283 G loss:-2.341\n",
      "Epoch:  0013 D loss:-0.3126 G loss:-2.276\n",
      "Epoch:  0013 D loss:-0.3427 G loss:-2.302\n",
      "Epoch:  0013 D loss:-0.3329 G loss:-2.371\n",
      "Epoch:  0013 D loss:-0.3665 G loss:-2.416\n",
      "Epoch:  0013 D loss:-0.3528 G loss:-2.402\n",
      "Epoch:  0013 D loss:-0.3411 G loss:-2.372\n",
      "Epoch:  0013 D loss:-0.2985 G loss:-2.433\n",
      "Epoch:  0013 D loss:-0.3052 G loss:-2.355\n",
      "Epoch:  0013 D loss:-0.3329 G loss:-2.262\n",
      "Epoch:  0013 D loss:-0.4215 G loss:-2.131\n",
      "Epoch:  0013 D loss:-0.362 G loss:-2.276\n",
      "Epoch:  0013 D loss:-0.3751 G loss:-2.162\n",
      "Epoch:  0013 D loss:-0.4196 G loss:-2.256\n",
      "Epoch:  0013 D loss:-0.3194 G loss:-2.163\n",
      "Epoch:  0013 D loss:-0.3913 G loss:-2.157\n",
      "Epoch:  0013 D loss:-0.3892 G loss:-2.211\n",
      "Epoch:  0013 D loss:-0.4492 G loss:-2.07\n",
      "Epoch:  0013 D loss:-0.3698 G loss:-2.291\n",
      "Epoch:  0013 D loss:-0.3797 G loss:-2.179\n",
      "Epoch:  0013 D loss:-0.423 G loss:-2.176\n",
      "Epoch:  0013 D loss:-0.4803 G loss:-2.196\n",
      "Epoch:  0013 D loss:-0.502 G loss:-2.157\n",
      "Epoch:  0013 D loss:-0.4395 G loss:-2.098\n",
      "Epoch:  0013 D loss:-0.4502 G loss:-2.007\n",
      "Epoch:  0013 D loss:-0.384 G loss:-2.029\n",
      "Epoch:  0013 D loss:-0.4645 G loss:-2.138\n",
      "Epoch:  0013 D loss:-0.4036 G loss:-2.053\n",
      "Epoch:  0013 D loss:-0.4257 G loss:-2.103\n",
      "Epoch:  0013 D loss:-0.4083 G loss:-2.151\n",
      "Epoch:  0013 D loss:-0.4195 G loss:-2.081\n",
      "Epoch:  0013 D loss:-0.3875 G loss:-2.291\n",
      "Epoch:  0013 D loss:-0.3716 G loss:-2.099\n",
      "Epoch:  0013 D loss:-0.4991 G loss:-2.025\n",
      "Epoch:  0013 D loss:-0.4094 G loss:-2.112\n",
      "Epoch:  0013 D loss:-0.4172 G loss:-2.141\n",
      "Epoch:  0013 D loss:-0.5347 G loss:-2.166\n",
      "Epoch:  0013 D loss:-0.4568 G loss:-2.012\n",
      "Epoch:  0013 D loss:-0.5242 G loss:-2.044\n",
      "Epoch:  0013 D loss:-0.4005 G loss:-2.023\n",
      "Epoch:  0013 D loss:-0.4995 G loss:-1.979\n",
      "Epoch:  0013 D loss:-0.3659 G loss:-2.111\n",
      "Epoch:  0013 D loss:-0.3927 G loss:-2.21\n",
      "Epoch:  0013 D loss:-0.45 G loss:-2.277\n",
      "Epoch:  0013 D loss:-0.3639 G loss:-2.378\n",
      "Epoch:  0013 D loss:-0.4079 G loss:-2.343\n",
      "Epoch:  0013 D loss:-0.409 G loss:-2.387\n",
      "Epoch:  0013 D loss:-0.4623 G loss:-2.364\n",
      "Epoch:  0013 D loss:-0.3807 G loss:-2.319\n",
      "Epoch:  0013 D loss:-0.4522 G loss:-2.201\n",
      "Epoch:  0013 D loss:-0.4049 G loss:-2.138\n",
      "Epoch:  0013 D loss:-0.3908 G loss:-2.208\n",
      "Epoch:  0013 D loss:-0.4046 G loss:-2.255\n",
      "Epoch:  0013 D loss:-0.4583 G loss:-2.058\n",
      "Epoch:  0013 D loss:-0.3249 G loss:-2.222\n",
      "Epoch:  0013 D loss:-0.4064 G loss:-2.197\n",
      "Epoch:  0013 D loss:-0.4616 G loss:-2.207\n",
      "Epoch:  0013 D loss:-0.2882 G loss:-2.32\n",
      "Epoch:  0013 D loss:-0.3304 G loss:-2.288\n",
      "Epoch:  0013 D loss:-0.3798 G loss:-2.309\n",
      "Epoch:  0013 D loss:-0.4157 G loss:-2.418\n",
      "Epoch:  0013 D loss:-0.3904 G loss:-2.236\n",
      "Epoch:  0013 D loss:-0.293 G loss:-2.443\n",
      "Epoch:  0013 D loss:-0.415 G loss:-2.307\n",
      "Epoch:  0013 D loss:-0.3704 G loss:-2.322\n",
      "Epoch:  0013 D loss:-0.3331 G loss:-2.482\n",
      "Epoch:  0013 D loss:-0.3494 G loss:-2.421\n",
      "Epoch:  0013 D loss:-0.3397 G loss:-2.417\n",
      "Epoch:  0013 D loss:-0.3074 G loss:-2.44\n",
      "Epoch:  0013 D loss:-0.3431 G loss:-2.509\n",
      "Epoch:  0013 D loss:-0.4039 G loss:-2.375\n",
      "Epoch:  0013 D loss:-0.3731 G loss:-2.361\n",
      "Epoch:  0013 D loss:-0.3905 G loss:-2.291\n",
      "Epoch:  0013 D loss:-0.3842 G loss:-2.097\n",
      "Epoch:  0013 D loss:-0.348 G loss:-2.234\n",
      "Epoch:  0013 D loss:-0.2992 G loss:-2.184\n",
      "Epoch:  0013 D loss:-0.3211 G loss:-2.237\n",
      "Epoch:  0013 D loss:-0.3909 G loss:-2.319\n",
      "Epoch:  0013 D loss:-0.3769 G loss:-2.24\n",
      "Epoch:  0013 D loss:-0.3887 G loss:-2.281\n",
      "Epoch:  0013 D loss:-0.3526 G loss:-2.305\n",
      "Epoch:  0013 D loss:-0.3447 G loss:-2.353\n",
      "Epoch:  0013 D loss:-0.3671 G loss:-2.419\n",
      "Epoch:  0013 D loss:-0.2942 G loss:-2.438\n",
      "Epoch:  0013 D loss:-0.4421 G loss:-2.397\n",
      "Epoch:  0013 D loss:-0.3842 G loss:-2.473\n",
      "Epoch:  0013 D loss:-0.3193 G loss:-2.397\n",
      "Epoch:  0013 D loss:-0.3208 G loss:-2.293\n",
      "Epoch:  0013 D loss:-0.4039 G loss:-2.189\n",
      "Epoch:  0013 D loss:-0.302 G loss:-2.312\n",
      "Epoch:  0013 D loss:-0.3746 G loss:-2.32\n",
      "Epoch:  0013 D loss:-0.3379 G loss:-2.234\n",
      "Epoch:  0013 D loss:-0.3124 G loss:-2.369\n",
      "Epoch:  0013 D loss:-0.4027 G loss:-2.349\n",
      "Epoch:  0013 D loss:-0.3685 G loss:-2.309\n",
      "Epoch:  0013 D loss:-0.3594 G loss:-2.357\n",
      "Epoch:  0013 D loss:-0.437 G loss:-2.228\n",
      "Epoch:  0013 D loss:-0.4166 G loss:-2.075\n",
      "Epoch:  0013 D loss:-0.3091 G loss:-2.273\n",
      "Epoch:  0013 D loss:-0.3572 G loss:-2.269\n",
      "Epoch:  0013 D loss:-0.4057 G loss:-2.267\n",
      "Epoch:  0013 D loss:-0.3402 G loss:-2.239\n",
      "Epoch:  0013 D loss:-0.3773 G loss:-2.395\n",
      "Epoch:  0013 D loss:-0.3601 G loss:-2.341\n",
      "Epoch:  0013 D loss:-0.3577 G loss:-2.396\n",
      "Epoch:  0013 D loss:-0.3203 G loss:-2.396\n",
      "Epoch:  0013 D loss:-0.3355 G loss:-2.344\n",
      "Epoch:  0013 D loss:-0.3217 G loss:-2.267\n",
      "Epoch:  0013 D loss:-0.4185 G loss:-2.212\n",
      "Epoch:  0013 D loss:-0.3162 G loss:-2.256\n",
      "Epoch:  0013 D loss:-0.3523 G loss:-2.27\n",
      "Epoch:  0013 D loss:-0.3176 G loss:-2.311\n",
      "Epoch:  0013 D loss:-0.3991 G loss:-2.309\n",
      "Epoch:  0013 D loss:-0.3063 G loss:-2.302\n",
      "Epoch:  0013 D loss:-0.3856 G loss:-2.266\n",
      "Epoch:  0013 D loss:-0.3166 G loss:-2.31\n",
      "Epoch:  0013 D loss:-0.3752 G loss:-2.449\n",
      "Epoch:  0013 D loss:-0.3839 G loss:-2.285\n",
      "Epoch:  0013 D loss:-0.3736 G loss:-2.288\n",
      "Epoch:  0013 D loss:-0.408 G loss:-2.382\n",
      "Epoch:  0013 D loss:-0.3646 G loss:-2.206\n",
      "Epoch:  0013 D loss:-0.351 G loss:-2.238\n",
      "Epoch:  0013 D loss:-0.2876 G loss:-2.237\n",
      "Epoch:  0013 D loss:-0.4049 G loss:-2.338\n",
      "Epoch:  0013 D loss:-0.345 G loss:-2.363\n",
      "Epoch:  0013 D loss:-0.3017 G loss:-2.47\n",
      "Epoch:  0013 D loss:-0.3546 G loss:-2.374\n",
      "Epoch:  0013 D loss:-0.3118 G loss:-2.333\n",
      "Epoch:  0013 D loss:-0.2861 G loss:-2.52\n",
      "Epoch:  0013 D loss:-0.3504 G loss:-2.28\n",
      "Epoch:  0013 D loss:-0.2911 G loss:-2.402\n",
      "Epoch:  0013 D loss:-0.361 G loss:-2.361\n",
      "Epoch:  0013 D loss:-0.2827 G loss:-2.421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0013 D loss:-0.3251 G loss:-2.434\n",
      "Epoch:  0013 D loss:-0.3675 G loss:-2.414\n",
      "Epoch:  0013 D loss:-0.3954 G loss:-2.339\n",
      "Epoch:  0013 D loss:-0.3013 G loss:-2.36\n",
      "Epoch:  0013 D loss:-0.3545 G loss:-2.248\n",
      "Epoch:  0013 D loss:-0.3418 G loss:-2.294\n",
      "Epoch:  0013 D loss:-0.3828 G loss:-2.172\n",
      "Epoch:  0013 D loss:-0.4054 G loss:-2.167\n",
      "Epoch:  0013 D loss:-0.3824 G loss:-2.079\n",
      "Epoch:  0013 D loss:-0.368 G loss:-2.113\n",
      "Epoch:  0013 D loss:-0.3531 G loss:-2.225\n",
      "Epoch:  0013 D loss:-0.2773 G loss:-2.154\n",
      "Epoch:  0013 D loss:-0.3278 G loss:-2.258\n",
      "Epoch:  0013 D loss:-0.3528 G loss:-2.307\n",
      "Epoch:  0013 D loss:-0.2753 G loss:-2.427\n",
      "Epoch:  0013 D loss:-0.304 G loss:-2.426\n",
      "Epoch:  0013 D loss:-0.3322 G loss:-2.349\n",
      "Epoch:  0013 D loss:-0.4295 G loss:-2.523\n",
      "Epoch:  0013 D loss:-0.2645 G loss:-2.543\n",
      "Epoch:  0013 D loss:-0.3705 G loss:-2.422\n",
      "Epoch:  0013 D loss:-0.4045 G loss:-2.29\n",
      "Epoch:  0013 D loss:-0.2945 G loss:-2.345\n",
      "Epoch:  0013 D loss:-0.3247 G loss:-2.269\n",
      "Epoch:  0013 D loss:-0.3781 G loss:-2.266\n",
      "Epoch:  0013 D loss:-0.376 G loss:-2.133\n",
      "Epoch:  0013 D loss:-0.3716 G loss:-2.12\n",
      "Epoch:  0013 D loss:-0.3676 G loss:-2.078\n",
      "Epoch:  0013 D loss:-0.3487 G loss:-2.102\n",
      "Epoch:  0013 D loss:-0.4291 G loss:-2.132\n",
      "Epoch:  0013 D loss:-0.2877 G loss:-2.265\n",
      "Epoch:  0013 D loss:-0.3262 G loss:-2.253\n",
      "Epoch:  0013 D loss:-0.2858 G loss:-2.308\n",
      "Epoch:  0013 D loss:-0.297 G loss:-2.364\n",
      "Epoch:  0013 D loss:-0.3582 G loss:-2.41\n",
      "Epoch:  0013 D loss:-0.3699 G loss:-2.472\n",
      "Epoch:  0013 D loss:-0.2604 G loss:-2.607\n",
      "Epoch:  0013 D loss:-0.2323 G loss:-2.525\n",
      "Epoch:  0013 D loss:-0.2773 G loss:-2.544\n",
      "Epoch:  0013 D loss:-0.3025 G loss:-2.536\n",
      "Epoch:  0013 D loss:-0.3365 G loss:-2.45\n",
      "Epoch:  0013 D loss:-0.3202 G loss:-2.595\n",
      "Epoch:  0013 D loss:-0.2913 G loss:-2.407\n",
      "Epoch:  0013 D loss:-0.2471 G loss:-2.449\n",
      "Epoch:  0013 D loss:-0.2334 G loss:-2.349\n",
      "Epoch:  0013 D loss:-0.277 G loss:-2.333\n",
      "Epoch:  0013 D loss:-0.2767 G loss:-2.41\n",
      "Epoch:  0013 D loss:-0.2597 G loss:-2.327\n",
      "Epoch:  0013 D loss:-0.2578 G loss:-2.533\n",
      "Epoch:  0013 D loss:-0.3371 G loss:-2.395\n",
      "Epoch:  0013 D loss:-0.3043 G loss:-2.4\n",
      "Epoch:  0013 D loss:-0.3252 G loss:-2.395\n",
      "Epoch:  0013 D loss:-0.3002 G loss:-2.354\n",
      "Epoch:  0013 D loss:-0.3273 G loss:-2.381\n",
      "Epoch:  0013 D loss:-0.3075 G loss:-2.332\n",
      "Epoch:  0013 D loss:-0.2636 G loss:-2.51\n",
      "Epoch:  0013 D loss:-0.2555 G loss:-2.461\n",
      "Epoch:  0013 D loss:-0.3195 G loss:-2.425\n",
      "Epoch:  0013 D loss:-0.2604 G loss:-2.505\n",
      "Epoch:  0013 D loss:-0.2803 G loss:-2.518\n",
      "Epoch:  0013 D loss:-0.3189 G loss:-2.4\n",
      "Epoch:  0013 D loss:-0.279 G loss:-2.514\n",
      "Epoch:  0013 D loss:-0.3136 G loss:-2.465\n",
      "Epoch:  0013 D loss:-0.3176 G loss:-2.253\n",
      "Epoch:  0013 D loss:-0.2918 G loss:-2.487\n",
      "Epoch:  0013 D loss:-0.265 G loss:-2.386\n",
      "Epoch:  0013 D loss:-0.3325 G loss:-2.288\n",
      "Epoch:  0013 D loss:-0.2744 G loss:-2.507\n",
      "Epoch:  0013 D loss:-0.3684 G loss:-2.43\n",
      "Epoch:  0013 D loss:-0.3394 G loss:-2.435\n",
      "Epoch:  0013 D loss:-0.377 G loss:-2.519\n",
      "Epoch:  0013 D loss:-0.2688 G loss:-2.414\n",
      "Epoch:  0013 D loss:-0.3475 G loss:-2.153\n",
      "Epoch:  0013 D loss:-0.3321 G loss:-2.249\n",
      "Epoch:  0013 D loss:-0.321 G loss:-2.322\n",
      "Epoch:  0013 D loss:-0.3701 G loss:-2.22\n",
      "Epoch:  0013 D loss:-0.3269 G loss:-2.18\n",
      "Epoch:  0013 D loss:-0.3249 G loss:-2.311\n",
      "Epoch:  0013 D loss:-0.3035 G loss:-2.341\n",
      "Epoch:  0013 D loss:-0.4103 G loss:-2.169\n",
      "Epoch:  0013 D loss:-0.4169 G loss:-2.201\n",
      "Epoch:  0013 D loss:-0.4416 G loss:-2.244\n",
      "Epoch:  0014 D loss:-0.3977 G loss:-2.396\n",
      "Epoch:  0014 D loss:-0.3317 G loss:-2.209\n",
      "Epoch:  0014 D loss:-0.367 G loss:-2.217\n",
      "Epoch:  0014 D loss:-0.434 G loss:-2.175\n",
      "Epoch:  0014 D loss:-0.2862 G loss:-2.321\n",
      "Epoch:  0014 D loss:-0.4824 G loss:-2.235\n",
      "Epoch:  0014 D loss:-0.406 G loss:-2.088\n",
      "Epoch:  0014 D loss:-0.3616 G loss:-2.056\n",
      "Epoch:  0014 D loss:-0.4151 G loss:-2.022\n",
      "Epoch:  0014 D loss:-0.4394 G loss:-1.947\n",
      "Epoch:  0014 D loss:-0.3854 G loss:-2.056\n",
      "Epoch:  0014 D loss:-0.3715 G loss:-2.083\n",
      "Epoch:  0014 D loss:-0.4162 G loss:-2.135\n",
      "Epoch:  0014 D loss:-0.5304 G loss:-2.203\n",
      "Epoch:  0014 D loss:-0.4057 G loss:-2.194\n",
      "Epoch:  0014 D loss:-0.4616 G loss:-2.074\n",
      "Epoch:  0014 D loss:-0.4942 G loss:-2.047\n",
      "Epoch:  0014 D loss:-0.3477 G loss:-2.054\n",
      "Epoch:  0014 D loss:-0.5239 G loss:-2.056\n",
      "Epoch:  0014 D loss:-0.4196 G loss:-2.006\n",
      "Epoch:  0014 D loss:-0.4681 G loss:-1.972\n",
      "Epoch:  0014 D loss:-0.502 G loss:-1.958\n",
      "Epoch:  0014 D loss:-0.3797 G loss:-1.991\n",
      "Epoch:  0014 D loss:-0.5121 G loss:-2.089\n",
      "Epoch:  0014 D loss:-0.5106 G loss:-1.997\n",
      "Epoch:  0014 D loss:-0.4991 G loss:-2.0\n",
      "Epoch:  0014 D loss:-0.4211 G loss:-2.041\n",
      "Epoch:  0014 D loss:-0.4334 G loss:-2.01\n",
      "Epoch:  0014 D loss:-0.4835 G loss:-1.998\n",
      "Epoch:  0014 D loss:-0.4945 G loss:-1.929\n",
      "Epoch:  0014 D loss:-0.4564 G loss:-2.077\n",
      "Epoch:  0014 D loss:-0.434 G loss:-1.974\n",
      "Epoch:  0014 D loss:-0.4112 G loss:-2.152\n",
      "Epoch:  0014 D loss:-0.4723 G loss:-2.035\n",
      "Epoch:  0014 D loss:-0.3444 G loss:-2.151\n",
      "Epoch:  0014 D loss:-0.4589 G loss:-2.093\n",
      "Epoch:  0014 D loss:-0.3841 G loss:-2.138\n",
      "Epoch:  0014 D loss:-0.4763 G loss:-2.048\n",
      "Epoch:  0014 D loss:-0.4967 G loss:-2.066\n",
      "Epoch:  0014 D loss:-0.4098 G loss:-2.096\n",
      "Epoch:  0014 D loss:-0.3996 G loss:-2.18\n",
      "Epoch:  0014 D loss:-0.4052 G loss:-2.092\n",
      "Epoch:  0014 D loss:-0.3947 G loss:-2.109\n",
      "Epoch:  0014 D loss:-0.378 G loss:-2.144\n",
      "Epoch:  0014 D loss:-0.3922 G loss:-2.13\n",
      "Epoch:  0014 D loss:-0.3529 G loss:-2.18\n",
      "Epoch:  0014 D loss:-0.4055 G loss:-2.284\n",
      "Epoch:  0014 D loss:-0.4122 G loss:-2.246\n",
      "Epoch:  0014 D loss:-0.4186 G loss:-2.353\n",
      "Epoch:  0014 D loss:-0.3455 G loss:-2.282\n",
      "Epoch:  0014 D loss:-0.3421 G loss:-2.308\n",
      "Epoch:  0014 D loss:-0.3595 G loss:-2.289\n",
      "Epoch:  0014 D loss:-0.4108 G loss:-2.289\n",
      "Epoch:  0014 D loss:-0.339 G loss:-2.445\n",
      "Epoch:  0014 D loss:-0.3194 G loss:-2.333\n",
      "Epoch:  0014 D loss:-0.3997 G loss:-2.263\n",
      "Epoch:  0014 D loss:-0.3287 G loss:-2.328\n",
      "Epoch:  0014 D loss:-0.3936 G loss:-2.17\n",
      "Epoch:  0014 D loss:-0.4246 G loss:-2.261\n",
      "Epoch:  0014 D loss:-0.3186 G loss:-2.311\n",
      "Epoch:  0014 D loss:-0.3081 G loss:-2.306\n",
      "Epoch:  0014 D loss:-0.3904 G loss:-2.236\n",
      "Epoch:  0014 D loss:-0.4054 G loss:-2.192\n",
      "Epoch:  0014 D loss:-0.3669 G loss:-2.271\n",
      "Epoch:  0014 D loss:-0.3253 G loss:-2.389\n",
      "Epoch:  0014 D loss:-0.4105 G loss:-2.188\n",
      "Epoch:  0014 D loss:-0.4436 G loss:-2.091\n",
      "Epoch:  0014 D loss:-0.3892 G loss:-2.133\n",
      "Epoch:  0014 D loss:-0.405 G loss:-2.192\n",
      "Epoch:  0014 D loss:-0.4057 G loss:-2.081\n",
      "Epoch:  0014 D loss:-0.4131 G loss:-2.341\n",
      "Epoch:  0014 D loss:-0.3776 G loss:-2.199\n",
      "Epoch:  0014 D loss:-0.3858 G loss:-2.342\n",
      "Epoch:  0014 D loss:-0.4021 G loss:-2.155\n",
      "Epoch:  0014 D loss:-0.383 G loss:-2.296\n",
      "Epoch:  0014 D loss:-0.3259 G loss:-2.243\n",
      "Epoch:  0014 D loss:-0.348 G loss:-2.223\n",
      "Epoch:  0014 D loss:-0.4268 G loss:-2.183\n",
      "Epoch:  0014 D loss:-0.3176 G loss:-2.391\n",
      "Epoch:  0014 D loss:-0.3934 G loss:-2.365\n",
      "Epoch:  0014 D loss:-0.4348 G loss:-2.232\n",
      "Epoch:  0014 D loss:-0.4193 G loss:-2.23\n",
      "Epoch:  0014 D loss:-0.4172 G loss:-2.221\n",
      "Epoch:  0014 D loss:-0.4907 G loss:-2.007\n",
      "Epoch:  0014 D loss:-0.4906 G loss:-2.034\n",
      "Epoch:  0014 D loss:-0.3767 G loss:-1.935\n",
      "Epoch:  0014 D loss:-0.4355 G loss:-1.982\n",
      "Epoch:  0014 D loss:-0.3959 G loss:-1.939\n",
      "Epoch:  0014 D loss:-0.424 G loss:-2.112\n",
      "Epoch:  0014 D loss:-0.4023 G loss:-2.137\n",
      "Epoch:  0014 D loss:-0.3567 G loss:-2.133\n",
      "Epoch:  0014 D loss:-0.3554 G loss:-2.219\n",
      "Epoch:  0014 D loss:-0.3952 G loss:-2.246\n",
      "Epoch:  0014 D loss:-0.4556 G loss:-2.384\n",
      "Epoch:  0014 D loss:-0.3708 G loss:-2.265\n",
      "Epoch:  0014 D loss:-0.4906 G loss:-2.118\n",
      "Epoch:  0014 D loss:-0.3856 G loss:-2.239\n",
      "Epoch:  0014 D loss:-0.3904 G loss:-2.169\n",
      "Epoch:  0014 D loss:-0.4035 G loss:-2.134\n",
      "Epoch:  0014 D loss:-0.3605 G loss:-2.401\n",
      "Epoch:  0014 D loss:-0.3835 G loss:-2.358\n",
      "Epoch:  0014 D loss:-0.4119 G loss:-2.288\n",
      "Epoch:  0014 D loss:-0.4073 G loss:-2.281\n",
      "Epoch:  0014 D loss:-0.382 G loss:-2.194\n",
      "Epoch:  0014 D loss:-0.3334 G loss:-2.244\n",
      "Epoch:  0014 D loss:-0.4298 G loss:-2.18\n",
      "Epoch:  0014 D loss:-0.4258 G loss:-2.063\n",
      "Epoch:  0014 D loss:-0.4083 G loss:-2.13\n",
      "Epoch:  0014 D loss:-0.42 G loss:-1.941\n",
      "Epoch:  0014 D loss:-0.4335 G loss:-2.161\n",
      "Epoch:  0014 D loss:-0.3671 G loss:-2.165\n",
      "Epoch:  0014 D loss:-0.368 G loss:-2.149\n",
      "Epoch:  0014 D loss:-0.3384 G loss:-2.29\n",
      "Epoch:  0014 D loss:-0.3489 G loss:-2.242\n",
      "Epoch:  0014 D loss:-0.3079 G loss:-2.341\n",
      "Epoch:  0014 D loss:-0.4233 G loss:-2.508\n",
      "Epoch:  0014 D loss:-0.3413 G loss:-2.467\n",
      "Epoch:  0014 D loss:-0.3493 G loss:-2.42\n",
      "Epoch:  0014 D loss:-0.3843 G loss:-2.373\n",
      "Epoch:  0014 D loss:-0.3044 G loss:-2.612\n",
      "Epoch:  0014 D loss:-0.3799 G loss:-2.374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0014 D loss:-0.3622 G loss:-2.367\n",
      "Epoch:  0014 D loss:-0.3671 G loss:-2.537\n",
      "Epoch:  0014 D loss:-0.3153 G loss:-2.341\n",
      "Epoch:  0014 D loss:-0.3336 G loss:-2.314\n",
      "Epoch:  0014 D loss:-0.3294 G loss:-2.303\n",
      "Epoch:  0014 D loss:-0.325 G loss:-2.262\n",
      "Epoch:  0014 D loss:-0.3034 G loss:-2.345\n",
      "Epoch:  0014 D loss:-0.2785 G loss:-2.299\n",
      "Epoch:  0014 D loss:-0.3668 G loss:-2.309\n",
      "Epoch:  0014 D loss:-0.3174 G loss:-2.348\n",
      "Epoch:  0014 D loss:-0.3455 G loss:-2.433\n",
      "Epoch:  0014 D loss:-0.3157 G loss:-2.315\n",
      "Epoch:  0014 D loss:-0.261 G loss:-2.351\n",
      "Epoch:  0014 D loss:-0.3773 G loss:-2.388\n",
      "Epoch:  0014 D loss:-0.3479 G loss:-2.424\n",
      "Epoch:  0014 D loss:-0.3404 G loss:-2.37\n",
      "Epoch:  0014 D loss:-0.3333 G loss:-2.452\n",
      "Epoch:  0014 D loss:-0.3534 G loss:-2.37\n",
      "Epoch:  0014 D loss:-0.3227 G loss:-2.31\n",
      "Epoch:  0014 D loss:-0.278 G loss:-2.484\n",
      "Epoch:  0014 D loss:-0.3435 G loss:-2.517\n",
      "Epoch:  0014 D loss:-0.3168 G loss:-2.526\n",
      "Epoch:  0014 D loss:-0.3233 G loss:-2.437\n",
      "Epoch:  0014 D loss:-0.3346 G loss:-2.37\n",
      "Epoch:  0014 D loss:-0.3492 G loss:-2.332\n",
      "Epoch:  0014 D loss:-0.3068 G loss:-2.277\n",
      "Epoch:  0014 D loss:-0.2599 G loss:-2.503\n",
      "Epoch:  0014 D loss:-0.2978 G loss:-2.381\n",
      "Epoch:  0014 D loss:-0.3148 G loss:-2.312\n",
      "Epoch:  0014 D loss:-0.3083 G loss:-2.395\n",
      "Epoch:  0014 D loss:-0.2544 G loss:-2.463\n",
      "Epoch:  0014 D loss:-0.3783 G loss:-2.331\n",
      "Epoch:  0014 D loss:-0.328 G loss:-2.433\n",
      "Epoch:  0014 D loss:-0.2868 G loss:-2.446\n",
      "Epoch:  0014 D loss:-0.3405 G loss:-2.364\n",
      "Epoch:  0014 D loss:-0.379 G loss:-2.251\n",
      "Epoch:  0014 D loss:-0.3658 G loss:-2.268\n",
      "Epoch:  0014 D loss:-0.3836 G loss:-2.152\n",
      "Epoch:  0014 D loss:-0.3604 G loss:-2.275\n",
      "Epoch:  0014 D loss:-0.3749 G loss:-2.178\n",
      "Epoch:  0014 D loss:-0.3415 G loss:-2.226\n",
      "Epoch:  0014 D loss:-0.3849 G loss:-2.115\n",
      "Epoch:  0014 D loss:-0.3723 G loss:-2.151\n",
      "Epoch:  0014 D loss:-0.3692 G loss:-2.303\n",
      "Epoch:  0014 D loss:-0.4521 G loss:-2.213\n",
      "Epoch:  0014 D loss:-0.4053 G loss:-2.218\n",
      "Epoch:  0014 D loss:-0.3272 G loss:-2.205\n",
      "Epoch:  0014 D loss:-0.4635 G loss:-2.197\n",
      "Epoch:  0014 D loss:-0.4153 G loss:-2.19\n",
      "Epoch:  0014 D loss:-0.3983 G loss:-2.139\n",
      "Epoch:  0014 D loss:-0.3903 G loss:-2.236\n",
      "Epoch:  0014 D loss:-0.4104 G loss:-2.178\n",
      "Epoch:  0014 D loss:-0.4032 G loss:-2.116\n",
      "Epoch:  0014 D loss:-0.487 G loss:-2.113\n",
      "Epoch:  0014 D loss:-0.3976 G loss:-2.144\n",
      "Epoch:  0014 D loss:-0.4466 G loss:-1.97\n",
      "Epoch:  0014 D loss:-0.479 G loss:-2.062\n",
      "Epoch:  0014 D loss:-0.3574 G loss:-1.957\n",
      "Epoch:  0014 D loss:-0.4112 G loss:-2.052\n",
      "Epoch:  0014 D loss:-0.4478 G loss:-1.986\n",
      "Epoch:  0014 D loss:-0.4352 G loss:-1.874\n",
      "Epoch:  0014 D loss:-0.5115 G loss:-1.846\n",
      "Epoch:  0014 D loss:-0.457 G loss:-1.962\n",
      "Epoch:  0014 D loss:-0.4564 G loss:-1.925\n",
      "Epoch:  0014 D loss:-0.4597 G loss:-2.043\n",
      "Epoch:  0014 D loss:-0.4444 G loss:-1.976\n",
      "Epoch:  0014 D loss:-0.4799 G loss:-2.11\n",
      "Epoch:  0014 D loss:-0.4866 G loss:-2.027\n",
      "Epoch:  0014 D loss:-0.5302 G loss:-2.055\n",
      "Epoch:  0014 D loss:-0.5422 G loss:-1.974\n",
      "Epoch:  0014 D loss:-0.5516 G loss:-1.947\n",
      "Epoch:  0014 D loss:-0.4916 G loss:-2.031\n",
      "Epoch:  0014 D loss:-0.5031 G loss:-2.024\n",
      "Epoch:  0014 D loss:-0.5469 G loss:-1.864\n",
      "Epoch:  0014 D loss:-0.5018 G loss:-1.865\n",
      "Epoch:  0014 D loss:-0.4743 G loss:-1.864\n",
      "Epoch:  0014 D loss:-0.5622 G loss:-1.84\n",
      "Epoch:  0014 D loss:-0.4894 G loss:-1.825\n",
      "Epoch:  0014 D loss:-0.544 G loss:-1.826\n",
      "Epoch:  0014 D loss:-0.4552 G loss:-1.733\n",
      "Epoch:  0014 D loss:-0.5193 G loss:-1.911\n",
      "Epoch:  0014 D loss:-0.5224 G loss:-1.928\n",
      "Epoch:  0014 D loss:-0.5049 G loss:-2.027\n",
      "Epoch:  0014 D loss:-0.524 G loss:-2.044\n",
      "Epoch:  0014 D loss:-0.4799 G loss:-2.114\n",
      "Epoch:  0014 D loss:-0.5481 G loss:-2.04\n",
      "Epoch:  0014 D loss:-0.4858 G loss:-2.055\n",
      "Epoch:  0014 D loss:-0.5663 G loss:-1.964\n",
      "Epoch:  0014 D loss:-0.4939 G loss:-1.906\n",
      "Epoch:  0014 D loss:-0.4791 G loss:-1.919\n",
      "Epoch:  0014 D loss:-0.5644 G loss:-1.913\n",
      "Epoch:  0014 D loss:-0.5247 G loss:-1.938\n",
      "Epoch:  0014 D loss:-0.4516 G loss:-1.935\n",
      "Epoch:  0014 D loss:-0.5074 G loss:-1.937\n",
      "Epoch:  0014 D loss:-0.4897 G loss:-1.89\n",
      "Epoch:  0014 D loss:-0.4495 G loss:-2.048\n",
      "Epoch:  0014 D loss:-0.431 G loss:-2.006\n",
      "Epoch:  0014 D loss:-0.4992 G loss:-2.108\n",
      "Epoch:  0014 D loss:-0.4329 G loss:-1.983\n",
      "Epoch:  0014 D loss:-0.4594 G loss:-2.033\n",
      "Epoch:  0014 D loss:-0.4578 G loss:-2.052\n",
      "Epoch:  0014 D loss:-0.4739 G loss:-2.114\n",
      "Epoch:  0014 D loss:-0.4231 G loss:-2.223\n",
      "Epoch:  0014 D loss:-0.4113 G loss:-2.205\n",
      "Epoch:  0014 D loss:-0.4174 G loss:-2.159\n",
      "Epoch:  0014 D loss:-0.4403 G loss:-2.127\n",
      "Epoch:  0014 D loss:-0.3627 G loss:-2.099\n",
      "Epoch:  0014 D loss:-0.3865 G loss:-2.113\n",
      "Epoch:  0014 D loss:-0.4744 G loss:-2.022\n",
      "Epoch:  0014 D loss:-0.4828 G loss:-1.949\n",
      "Epoch:  0014 D loss:-0.4106 G loss:-2.137\n",
      "Epoch:  0014 D loss:-0.4173 G loss:-2.136\n",
      "Epoch:  0014 D loss:-0.3891 G loss:-2.054\n",
      "Epoch:  0014 D loss:-0.435 G loss:-2.156\n",
      "Epoch:  0014 D loss:-0.342 G loss:-2.167\n",
      "Epoch:  0014 D loss:-0.4865 G loss:-1.937\n",
      "Epoch:  0014 D loss:-0.4735 G loss:-2.089\n",
      "Epoch:  0014 D loss:-0.5012 G loss:-2.18\n",
      "Epoch:  0014 D loss:-0.3897 G loss:-2.027\n",
      "Epoch:  0014 D loss:-0.4361 G loss:-2.017\n",
      "Epoch:  0014 D loss:-0.4241 G loss:-2.052\n",
      "Epoch:  0014 D loss:-0.3869 G loss:-2.116\n",
      "Epoch:  0014 D loss:-0.4134 G loss:-2.098\n",
      "Epoch:  0014 D loss:-0.3557 G loss:-2.207\n",
      "Epoch:  0014 D loss:-0.417 G loss:-2.2\n",
      "Epoch:  0014 D loss:-0.3855 G loss:-2.138\n",
      "Epoch:  0014 D loss:-0.4096 G loss:-2.228\n",
      "Epoch:  0014 D loss:-0.3846 G loss:-2.181\n",
      "Epoch:  0014 D loss:-0.3826 G loss:-2.27\n",
      "Epoch:  0014 D loss:-0.4328 G loss:-2.233\n",
      "Epoch:  0014 D loss:-0.4298 G loss:-2.308\n",
      "Epoch:  0014 D loss:-0.3797 G loss:-2.143\n",
      "Epoch:  0014 D loss:-0.5049 G loss:-2.213\n",
      "Epoch:  0014 D loss:-0.5007 G loss:-2.212\n",
      "Epoch:  0014 D loss:-0.4499 G loss:-2.028\n",
      "Epoch:  0014 D loss:-0.4987 G loss:-1.979\n",
      "Epoch:  0014 D loss:-0.4417 G loss:-1.897\n",
      "Epoch:  0014 D loss:-0.3724 G loss:-2.079\n",
      "Epoch:  0014 D loss:-0.4785 G loss:-1.999\n",
      "Epoch:  0014 D loss:-0.4562 G loss:-1.957\n",
      "Epoch:  0014 D loss:-0.3982 G loss:-2.156\n",
      "Epoch:  0014 D loss:-0.4823 G loss:-2.18\n",
      "Epoch:  0014 D loss:-0.3827 G loss:-2.119\n",
      "Epoch:  0014 D loss:-0.3772 G loss:-2.177\n",
      "Epoch:  0014 D loss:-0.4332 G loss:-2.199\n",
      "Epoch:  0014 D loss:-0.3709 G loss:-2.21\n",
      "Epoch:  0014 D loss:-0.4932 G loss:-2.165\n",
      "Epoch:  0014 D loss:-0.4199 G loss:-2.173\n",
      "Epoch:  0014 D loss:-0.3558 G loss:-2.268\n",
      "Epoch:  0014 D loss:-0.3629 G loss:-2.155\n",
      "Epoch:  0014 D loss:-0.4244 G loss:-2.107\n",
      "Epoch:  0014 D loss:-0.3357 G loss:-2.241\n",
      "Epoch:  0014 D loss:-0.3625 G loss:-2.156\n",
      "Epoch:  0014 D loss:-0.4467 G loss:-2.07\n",
      "Epoch:  0014 D loss:-0.398 G loss:-2.16\n",
      "Epoch:  0014 D loss:-0.4213 G loss:-2.086\n",
      "Epoch:  0014 D loss:-0.4342 G loss:-2.046\n",
      "Epoch:  0014 D loss:-0.4039 G loss:-2.227\n",
      "Epoch:  0014 D loss:-0.3692 G loss:-2.166\n",
      "Epoch:  0014 D loss:-0.3466 G loss:-2.242\n",
      "Epoch:  0014 D loss:-0.4525 G loss:-2.117\n",
      "Epoch:  0014 D loss:-0.3319 G loss:-2.191\n",
      "Epoch:  0014 D loss:-0.3589 G loss:-2.182\n",
      "Epoch:  0014 D loss:-0.4446 G loss:-2.12\n",
      "Epoch:  0014 D loss:-0.4341 G loss:-2.241\n",
      "Epoch:  0014 D loss:-0.4253 G loss:-2.104\n",
      "Epoch:  0014 D loss:-0.3777 G loss:-2.195\n",
      "Epoch:  0014 D loss:-0.3066 G loss:-2.26\n",
      "Epoch:  0014 D loss:-0.3588 G loss:-2.101\n",
      "Epoch:  0014 D loss:-0.3833 G loss:-2.36\n",
      "Epoch:  0014 D loss:-0.3306 G loss:-2.341\n",
      "Epoch:  0014 D loss:-0.4583 G loss:-2.245\n",
      "Epoch:  0014 D loss:-0.3365 G loss:-2.351\n",
      "Epoch:  0014 D loss:-0.4098 G loss:-2.346\n",
      "Epoch:  0014 D loss:-0.3757 G loss:-2.267\n",
      "Epoch:  0014 D loss:-0.3658 G loss:-2.282\n",
      "Epoch:  0014 D loss:-0.3845 G loss:-2.356\n",
      "Epoch:  0014 D loss:-0.4124 G loss:-2.261\n",
      "Epoch:  0014 D loss:-0.2647 G loss:-2.383\n",
      "Epoch:  0014 D loss:-0.3543 G loss:-2.149\n",
      "Epoch:  0014 D loss:-0.3502 G loss:-2.214\n",
      "Epoch:  0014 D loss:-0.3732 G loss:-2.319\n",
      "Epoch:  0014 D loss:-0.2862 G loss:-2.437\n",
      "Epoch:  0014 D loss:-0.3343 G loss:-2.433\n",
      "Epoch:  0014 D loss:-0.403 G loss:-2.258\n",
      "Epoch:  0014 D loss:-0.3149 G loss:-2.203\n",
      "Epoch:  0014 D loss:-0.3605 G loss:-2.215\n",
      "Epoch:  0014 D loss:-0.3696 G loss:-2.176\n",
      "Epoch:  0014 D loss:-0.4094 G loss:-2.319\n",
      "Epoch:  0014 D loss:-0.3866 G loss:-2.331\n",
      "Epoch:  0014 D loss:-0.4258 G loss:-2.096\n",
      "Epoch:  0014 D loss:-0.4098 G loss:-2.352\n",
      "Epoch:  0014 D loss:-0.34 G loss:-2.265\n",
      "Epoch:  0014 D loss:-0.3572 G loss:-2.257\n",
      "Epoch:  0014 D loss:-0.3735 G loss:-2.212\n",
      "Epoch:  0014 D loss:-0.3946 G loss:-2.307\n",
      "Epoch:  0014 D loss:-0.3468 G loss:-2.202\n",
      "Epoch:  0014 D loss:-0.3024 G loss:-2.259\n",
      "Epoch:  0014 D loss:-0.3772 G loss:-2.117\n",
      "Epoch:  0014 D loss:-0.392 G loss:-2.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0014 D loss:-0.4219 G loss:-2.018\n",
      "Epoch:  0014 D loss:-0.4546 G loss:-2.114\n",
      "Epoch:  0014 D loss:-0.4805 G loss:-2.008\n",
      "Epoch:  0014 D loss:-0.3418 G loss:-2.206\n",
      "Epoch:  0014 D loss:-0.4022 G loss:-2.097\n",
      "Epoch:  0014 D loss:-0.3227 G loss:-2.336\n",
      "Epoch:  0014 D loss:-0.4303 G loss:-2.068\n",
      "Epoch:  0014 D loss:-0.3594 G loss:-2.222\n",
      "Epoch:  0014 D loss:-0.3948 G loss:-2.256\n",
      "Epoch:  0014 D loss:-0.4114 G loss:-2.054\n",
      "Epoch:  0014 D loss:-0.4414 G loss:-2.155\n",
      "Epoch:  0014 D loss:-0.4839 G loss:-2.117\n",
      "Epoch:  0014 D loss:-0.4223 G loss:-2.04\n",
      "Epoch:  0014 D loss:-0.507 G loss:-1.995\n",
      "Epoch:  0014 D loss:-0.4637 G loss:-2.074\n",
      "Epoch:  0014 D loss:-0.3812 G loss:-2.139\n",
      "Epoch:  0014 D loss:-0.4864 G loss:-2.142\n",
      "Epoch:  0014 D loss:-0.4293 G loss:-2.123\n",
      "Epoch:  0014 D loss:-0.4447 G loss:-2.04\n",
      "Epoch:  0014 D loss:-0.4643 G loss:-2.055\n",
      "Epoch:  0014 D loss:-0.4654 G loss:-2.102\n",
      "Epoch:  0014 D loss:-0.4299 G loss:-2.064\n",
      "Epoch:  0014 D loss:-0.5125 G loss:-1.994\n",
      "Epoch:  0014 D loss:-0.4188 G loss:-2.07\n",
      "Epoch:  0014 D loss:-0.4386 G loss:-2.023\n",
      "Epoch:  0014 D loss:-0.4559 G loss:-2.074\n",
      "Epoch:  0014 D loss:-0.4506 G loss:-2.074\n",
      "Epoch:  0014 D loss:-0.4495 G loss:-2.068\n",
      "Epoch:  0014 D loss:-0.4391 G loss:-2.101\n",
      "Epoch:  0014 D loss:-0.3726 G loss:-2.26\n",
      "Epoch:  0014 D loss:-0.4815 G loss:-2.049\n",
      "Epoch:  0014 D loss:-0.451 G loss:-2.089\n",
      "Epoch:  0014 D loss:-0.4446 G loss:-2.129\n",
      "Epoch:  0014 D loss:-0.33 G loss:-2.237\n",
      "Epoch:  0014 D loss:-0.3962 G loss:-2.201\n",
      "Epoch:  0014 D loss:-0.4182 G loss:-2.172\n",
      "Epoch:  0014 D loss:-0.3649 G loss:-2.071\n",
      "Epoch:  0014 D loss:-0.4364 G loss:-2.2\n",
      "Epoch:  0014 D loss:-0.5258 G loss:-2.197\n",
      "Epoch:  0014 D loss:-0.4162 G loss:-2.181\n",
      "Epoch:  0014 D loss:-0.5447 G loss:-1.968\n",
      "Epoch:  0014 D loss:-0.427 G loss:-1.981\n",
      "Epoch:  0014 D loss:-0.4567 G loss:-1.874\n",
      "Epoch:  0014 D loss:-0.3373 G loss:-2.011\n",
      "Epoch:  0014 D loss:-0.4594 G loss:-2.002\n",
      "Epoch:  0014 D loss:-0.5405 G loss:-1.934\n",
      "Epoch:  0014 D loss:-0.4867 G loss:-1.981\n",
      "Epoch:  0014 D loss:-0.545 G loss:-1.936\n",
      "Epoch:  0014 D loss:-0.5187 G loss:-1.853\n",
      "Epoch:  0014 D loss:-0.5717 G loss:-1.859\n",
      "Epoch:  0014 D loss:-0.4891 G loss:-2.045\n",
      "Epoch:  0014 D loss:-0.6327 G loss:-1.962\n",
      "Epoch:  0014 D loss:-0.4648 G loss:-2.24\n",
      "Epoch:  0014 D loss:-0.4894 G loss:-2.02\n",
      "Epoch:  0014 D loss:-0.6171 G loss:-1.871\n",
      "Epoch:  0014 D loss:-0.3966 G loss:-1.932\n",
      "Epoch:  0014 D loss:-0.4246 G loss:-2.013\n",
      "Epoch:  0014 D loss:-0.4736 G loss:-2.134\n",
      "Epoch:  0014 D loss:-0.4816 G loss:-2.091\n",
      "Epoch:  0014 D loss:-0.4372 G loss:-2.119\n",
      "Epoch:  0014 D loss:-0.3858 G loss:-2.168\n",
      "Epoch:  0014 D loss:-0.3874 G loss:-2.118\n",
      "Epoch:  0014 D loss:-0.4537 G loss:-2.077\n",
      "Epoch:  0014 D loss:-0.428 G loss:-2.045\n",
      "Epoch:  0014 D loss:-0.3597 G loss:-2.196\n",
      "Epoch:  0014 D loss:-0.4989 G loss:-2.077\n",
      "Epoch:  0014 D loss:-0.4334 G loss:-2.148\n",
      "Epoch:  0014 D loss:-0.5075 G loss:-2.107\n",
      "Epoch:  0014 D loss:-0.5098 G loss:-2.066\n",
      "Epoch:  0014 D loss:-0.4632 G loss:-1.963\n",
      "Epoch:  0014 D loss:-0.4222 G loss:-1.952\n",
      "Epoch:  0014 D loss:-0.423 G loss:-2.024\n",
      "Epoch:  0014 D loss:-0.4726 G loss:-1.935\n",
      "Epoch:  0014 D loss:-0.4409 G loss:-2.23\n",
      "Epoch:  0014 D loss:-0.4224 G loss:-2.175\n",
      "Epoch:  0014 D loss:-0.4164 G loss:-2.214\n",
      "Epoch:  0014 D loss:-0.4086 G loss:-2.299\n",
      "Epoch:  0014 D loss:-0.4382 G loss:-2.255\n",
      "Epoch:  0014 D loss:-0.4863 G loss:-2.195\n",
      "Epoch:  0014 D loss:-0.4624 G loss:-2.216\n",
      "Epoch:  0014 D loss:-0.4317 G loss:-2.132\n",
      "Epoch:  0014 D loss:-0.3832 G loss:-2.037\n",
      "Epoch:  0014 D loss:-0.4146 G loss:-2.049\n",
      "Epoch:  0014 D loss:-0.4495 G loss:-2.169\n",
      "Epoch:  0014 D loss:-0.4084 G loss:-2.07\n",
      "Epoch:  0014 D loss:-0.4936 G loss:-2.15\n",
      "Epoch:  0014 D loss:-0.413 G loss:-2.139\n",
      "Epoch:  0014 D loss:-0.4507 G loss:-2.159\n",
      "Epoch:  0014 D loss:-0.4183 G loss:-2.118\n",
      "Epoch:  0014 D loss:-0.4213 G loss:-2.108\n",
      "Epoch:  0014 D loss:-0.42 G loss:-1.994\n",
      "Epoch:  0014 D loss:-0.4119 G loss:-2.068\n",
      "Epoch:  0014 D loss:-0.3542 G loss:-2.416\n",
      "Epoch:  0014 D loss:-0.4339 G loss:-2.279\n",
      "Epoch:  0014 D loss:-0.4965 G loss:-2.238\n",
      "Epoch:  0014 D loss:-0.4064 G loss:-2.234\n",
      "Epoch:  0014 D loss:-0.5302 G loss:-2.182\n",
      "Epoch:  0014 D loss:-0.4538 G loss:-2.027\n",
      "Epoch:  0014 D loss:-0.4712 G loss:-2.108\n",
      "Epoch:  0014 D loss:-0.4511 G loss:-2.12\n",
      "Epoch:  0014 D loss:-0.382 G loss:-2.174\n",
      "Epoch:  0014 D loss:-0.4208 G loss:-2.084\n",
      "Epoch:  0014 D loss:-0.4557 G loss:-2.116\n",
      "Epoch:  0014 D loss:-0.4311 G loss:-2.23\n",
      "Epoch:  0014 D loss:-0.4765 G loss:-2.201\n",
      "Epoch:  0014 D loss:-0.3727 G loss:-2.256\n",
      "Epoch:  0014 D loss:-0.5093 G loss:-2.152\n",
      "Epoch:  0014 D loss:-0.4626 G loss:-2.2\n",
      "Epoch:  0014 D loss:-0.4787 G loss:-2.223\n",
      "Epoch:  0014 D loss:-0.558 G loss:-2.137\n",
      "Epoch:  0014 D loss:-0.4873 G loss:-2.163\n",
      "Epoch:  0014 D loss:-0.3967 G loss:-2.199\n",
      "Epoch:  0014 D loss:-0.5869 G loss:-2.146\n",
      "Epoch:  0014 D loss:-0.4973 G loss:-2.039\n",
      "Epoch:  0014 D loss:-0.4882 G loss:-1.96\n",
      "Epoch:  0014 D loss:-0.4988 G loss:-2.015\n",
      "Epoch:  0014 D loss:-0.4219 G loss:-2.267\n",
      "Epoch:  0014 D loss:-0.4621 G loss:-2.158\n",
      "Epoch:  0014 D loss:-0.4447 G loss:-2.131\n",
      "Epoch:  0014 D loss:-0.4972 G loss:-2.099\n",
      "Epoch:  0014 D loss:-0.4314 G loss:-2.213\n",
      "Epoch:  0014 D loss:-0.4472 G loss:-2.242\n",
      "Epoch:  0014 D loss:-0.4143 G loss:-2.362\n",
      "Epoch:  0014 D loss:-0.5556 G loss:-2.104\n",
      "Epoch:  0014 D loss:-0.4486 G loss:-2.295\n",
      "Epoch:  0014 D loss:-0.4408 G loss:-2.188\n",
      "Epoch:  0014 D loss:-0.4444 G loss:-2.125\n",
      "Epoch:  0014 D loss:-0.4557 G loss:-2.15\n",
      "Epoch:  0014 D loss:-0.5004 G loss:-2.244\n",
      "Epoch:  0014 D loss:-0.3844 G loss:-2.237\n",
      "Epoch:  0014 D loss:-0.4455 G loss:-2.088\n",
      "Epoch:  0014 D loss:-0.3938 G loss:-2.212\n",
      "Epoch:  0014 D loss:-0.4862 G loss:-2.11\n",
      "Epoch:  0014 D loss:-0.5165 G loss:-1.926\n",
      "Epoch:  0014 D loss:-0.4123 G loss:-2.217\n",
      "Epoch:  0014 D loss:-0.5355 G loss:-2.133\n",
      "Epoch:  0014 D loss:-0.4323 G loss:-2.157\n",
      "Epoch:  0014 D loss:-0.4911 G loss:-2.137\n",
      "Epoch:  0014 D loss:-0.4397 G loss:-2.201\n",
      "Epoch:  0014 D loss:-0.4324 G loss:-2.262\n",
      "Epoch:  0014 D loss:-0.5326 G loss:-2.028\n",
      "Epoch:  0014 D loss:-0.5005 G loss:-2.136\n",
      "Epoch:  0014 D loss:-0.4831 G loss:-2.167\n",
      "Epoch:  0014 D loss:-0.4315 G loss:-2.142\n",
      "Epoch:  0014 D loss:-0.6058 G loss:-2.079\n",
      "Epoch:  0014 D loss:-0.4663 G loss:-2.156\n",
      "Epoch:  0014 D loss:-0.4268 G loss:-1.905\n",
      "Epoch:  0014 D loss:-0.5821 G loss:-1.966\n",
      "Epoch:  0014 D loss:-0.529 G loss:-1.936\n",
      "Epoch:  0014 D loss:-0.5317 G loss:-2.024\n",
      "Epoch:  0014 D loss:-0.4705 G loss:-2.147\n",
      "Epoch:  0014 D loss:-0.4981 G loss:-2.109\n",
      "Epoch:  0014 D loss:-0.5421 G loss:-2.029\n",
      "Epoch:  0014 D loss:-0.5074 G loss:-2.12\n",
      "Epoch:  0014 D loss:-0.4898 G loss:-2.249\n",
      "Epoch:  0014 D loss:-0.3753 G loss:-2.39\n",
      "Epoch:  0014 D loss:-0.5305 G loss:-2.159\n",
      "Epoch:  0014 D loss:-0.5056 G loss:-2.133\n",
      "Epoch:  0014 D loss:-0.565 G loss:-2.013\n",
      "Epoch:  0014 D loss:-0.4148 G loss:-2.02\n",
      "Epoch:  0014 D loss:-0.4855 G loss:-1.908\n",
      "Epoch:  0014 D loss:-0.4347 G loss:-2.171\n",
      "Epoch:  0014 D loss:-0.4391 G loss:-2.041\n",
      "Epoch:  0014 D loss:-0.4178 G loss:-2.224\n",
      "Epoch:  0014 D loss:-0.4505 G loss:-2.136\n",
      "Epoch:  0014 D loss:-0.4589 G loss:-2.218\n",
      "Epoch:  0014 D loss:-0.5044 G loss:-2.115\n",
      "Epoch:  0014 D loss:-0.4846 G loss:-2.179\n",
      "Epoch:  0014 D loss:-0.4701 G loss:-2.064\n",
      "Epoch:  0014 D loss:-0.5424 G loss:-2.016\n",
      "Epoch:  0014 D loss:-0.5095 G loss:-1.992\n",
      "Epoch:  0014 D loss:-0.4982 G loss:-2.039\n",
      "Epoch:  0014 D loss:-0.4518 G loss:-2.217\n",
      "Epoch:  0014 D loss:-0.5209 G loss:-2.221\n",
      "Epoch:  0014 D loss:-0.5798 G loss:-1.954\n",
      "Epoch:  0014 D loss:-0.5257 G loss:-1.933\n",
      "Epoch:  0014 D loss:-0.4975 G loss:-1.832\n",
      "Epoch:  0014 D loss:-0.4896 G loss:-2.008\n",
      "Epoch:  0014 D loss:-0.4444 G loss:-2.004\n",
      "Epoch:  0014 D loss:-0.5599 G loss:-1.858\n",
      "Epoch:  0014 D loss:-0.5291 G loss:-2.075\n",
      "Epoch:  0014 D loss:-0.5081 G loss:-2.016\n",
      "Epoch:  0014 D loss:-0.4427 G loss:-1.979\n",
      "Epoch:  0014 D loss:-0.4267 G loss:-2.097\n",
      "Epoch:  0014 D loss:-0.524 G loss:-2.048\n",
      "Epoch:  0014 D loss:-0.4736 G loss:-2.218\n",
      "Epoch:  0014 D loss:-0.4845 G loss:-2.104\n",
      "Epoch:  0014 D loss:-0.5266 G loss:-1.987\n",
      "Epoch:  0014 D loss:-0.452 G loss:-2.202\n",
      "Epoch:  0014 D loss:-0.4434 G loss:-2.121\n",
      "Epoch:  0014 D loss:-0.5327 G loss:-2.15\n",
      "Epoch:  0014 D loss:-0.4889 G loss:-2.097\n",
      "Epoch:  0014 D loss:-0.5044 G loss:-2.116\n",
      "Epoch:  0014 D loss:-0.4747 G loss:-2.215\n",
      "Epoch:  0014 D loss:-0.4546 G loss:-2.244\n",
      "Epoch:  0014 D loss:-0.4531 G loss:-2.166\n",
      "Epoch:  0014 D loss:-0.5434 G loss:-2.255\n",
      "Epoch:  0014 D loss:-0.4421 G loss:-2.088\n",
      "Epoch:  0014 D loss:-0.4731 G loss:-2.031\n",
      "Epoch:  0014 D loss:-0.5212 G loss:-1.959\n",
      "Epoch:  0014 D loss:-0.5311 G loss:-1.959\n",
      "Epoch:  0014 D loss:-0.5732 G loss:-1.715\n",
      "Epoch:  0014 D loss:-0.4667 G loss:-1.947\n",
      "Epoch:  0014 D loss:-0.4886 G loss:-1.909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0014 D loss:-0.5737 G loss:-2.072\n",
      "Epoch:  0014 D loss:-0.4819 G loss:-2.119\n",
      "Epoch:  0014 D loss:-0.6006 G loss:-2.093\n",
      "Epoch:  0014 D loss:-0.415 G loss:-2.128\n",
      "Epoch:  0014 D loss:-0.4203 G loss:-2.042\n",
      "Epoch:  0014 D loss:-0.4647 G loss:-1.99\n",
      "Epoch:  0014 D loss:-0.5126 G loss:-2.061\n",
      "Epoch:  0014 D loss:-0.4665 G loss:-2.129\n",
      "Epoch:  0014 D loss:-0.5917 G loss:-1.943\n",
      "Epoch:  0014 D loss:-0.4211 G loss:-2.152\n",
      "Epoch:  0014 D loss:-0.5749 G loss:-2.041\n",
      "Epoch:  0014 D loss:-0.5912 G loss:-2.007\n",
      "Epoch:  0014 D loss:-0.3643 G loss:-2.096\n",
      "Epoch:  0014 D loss:-0.443 G loss:-1.979\n",
      "Epoch:  0014 D loss:-0.5462 G loss:-1.986\n",
      "Epoch:  0014 D loss:-0.377 G loss:-2.082\n",
      "Epoch:  0014 D loss:-0.5087 G loss:-2.07\n",
      "Epoch:  0014 D loss:-0.4547 G loss:-1.879\n",
      "Epoch:  0014 D loss:-0.4737 G loss:-2.071\n",
      "Epoch:  0014 D loss:-0.4427 G loss:-2.124\n",
      "Epoch:  0014 D loss:-0.4526 G loss:-2.069\n",
      "Epoch:  0014 D loss:-0.4381 G loss:-2.239\n",
      "Epoch:  0014 D loss:-0.3476 G loss:-2.157\n",
      "Epoch:  0014 D loss:-0.4176 G loss:-2.317\n",
      "Epoch:  0014 D loss:-0.4474 G loss:-2.243\n",
      "Epoch:  0015 D loss:-0.5022 G loss:-2.16\n",
      "Epoch:  0015 D loss:-0.5243 G loss:-2.298\n",
      "Epoch:  0015 D loss:-0.3904 G loss:-2.231\n",
      "Epoch:  0015 D loss:-0.4162 G loss:-2.184\n",
      "Epoch:  0015 D loss:-0.382 G loss:-2.207\n",
      "Epoch:  0015 D loss:-0.3957 G loss:-2.122\n",
      "Epoch:  0015 D loss:-0.4536 G loss:-2.159\n",
      "Epoch:  0015 D loss:-0.3817 G loss:-2.265\n",
      "Epoch:  0015 D loss:-0.4501 G loss:-2.286\n",
      "Epoch:  0015 D loss:-0.41 G loss:-2.067\n",
      "Epoch:  0015 D loss:-0.4679 G loss:-2.081\n",
      "Epoch:  0015 D loss:-0.4117 G loss:-2.117\n",
      "Epoch:  0015 D loss:-0.4937 G loss:-2.032\n",
      "Epoch:  0015 D loss:-0.4162 G loss:-2.182\n",
      "Epoch:  0015 D loss:-0.4362 G loss:-2.081\n",
      "Epoch:  0015 D loss:-0.4331 G loss:-2.322\n",
      "Epoch:  0015 D loss:-0.4342 G loss:-2.188\n",
      "Epoch:  0015 D loss:-0.4177 G loss:-2.336\n",
      "Epoch:  0015 D loss:-0.4088 G loss:-2.247\n",
      "Epoch:  0015 D loss:-0.3992 G loss:-2.238\n",
      "Epoch:  0015 D loss:-0.4212 G loss:-2.157\n",
      "Epoch:  0015 D loss:-0.4699 G loss:-2.15\n",
      "Epoch:  0015 D loss:-0.449 G loss:-1.935\n",
      "Epoch:  0015 D loss:-0.4502 G loss:-2.04\n",
      "Epoch:  0015 D loss:-0.3603 G loss:-2.137\n",
      "Epoch:  0015 D loss:-0.3918 G loss:-2.108\n",
      "Epoch:  0015 D loss:-0.3555 G loss:-2.121\n",
      "Epoch:  0015 D loss:-0.4836 G loss:-2.082\n",
      "Epoch:  0015 D loss:-0.4189 G loss:-2.18\n",
      "Epoch:  0015 D loss:-0.4624 G loss:-2.267\n",
      "Epoch:  0015 D loss:-0.463 G loss:-2.363\n",
      "Epoch:  0015 D loss:-0.5331 G loss:-2.262\n",
      "Epoch:  0015 D loss:-0.4092 G loss:-2.327\n",
      "Epoch:  0015 D loss:-0.3852 G loss:-2.139\n",
      "Epoch:  0015 D loss:-0.4462 G loss:-2.265\n",
      "Epoch:  0015 D loss:-0.3338 G loss:-2.21\n",
      "Epoch:  0015 D loss:-0.4365 G loss:-2.167\n",
      "Epoch:  0015 D loss:-0.4131 G loss:-2.088\n",
      "Epoch:  0015 D loss:-0.4542 G loss:-2.13\n",
      "Epoch:  0015 D loss:-0.5103 G loss:-2.042\n",
      "Epoch:  0015 D loss:-0.4027 G loss:-2.301\n",
      "Epoch:  0015 D loss:-0.4068 G loss:-2.253\n",
      "Epoch:  0015 D loss:-0.3805 G loss:-2.237\n",
      "Epoch:  0015 D loss:-0.4538 G loss:-2.211\n",
      "Epoch:  0015 D loss:-0.4103 G loss:-2.211\n",
      "Epoch:  0015 D loss:-0.5003 G loss:-2.207\n",
      "Epoch:  0015 D loss:-0.4673 G loss:-2.316\n",
      "Epoch:  0015 D loss:-0.3906 G loss:-2.433\n",
      "Epoch:  0015 D loss:-0.3881 G loss:-2.324\n",
      "Epoch:  0015 D loss:-0.4549 G loss:-2.189\n",
      "Epoch:  0015 D loss:-0.4834 G loss:-2.139\n",
      "Epoch:  0015 D loss:-0.4753 G loss:-2.127\n",
      "Epoch:  0015 D loss:-0.4808 G loss:-2.205\n",
      "Epoch:  0015 D loss:-0.3717 G loss:-2.207\n",
      "Epoch:  0015 D loss:-0.4033 G loss:-2.216\n",
      "Epoch:  0015 D loss:-0.4157 G loss:-2.087\n",
      "Epoch:  0015 D loss:-0.5041 G loss:-2.01\n",
      "Epoch:  0015 D loss:-0.5034 G loss:-2.113\n",
      "Epoch:  0015 D loss:-0.5086 G loss:-2.056\n",
      "Epoch:  0015 D loss:-0.5193 G loss:-2.126\n",
      "Epoch:  0015 D loss:-0.493 G loss:-2.195\n",
      "Epoch:  0015 D loss:-0.4989 G loss:-2.072\n",
      "Epoch:  0015 D loss:-0.535 G loss:-2.139\n",
      "Epoch:  0015 D loss:-0.3863 G loss:-2.189\n",
      "Epoch:  0015 D loss:-0.4383 G loss:-2.147\n",
      "Epoch:  0015 D loss:-0.5861 G loss:-2.083\n",
      "Epoch:  0015 D loss:-0.4338 G loss:-2.14\n",
      "Epoch:  0015 D loss:-0.4438 G loss:-2.309\n",
      "Epoch:  0015 D loss:-0.4369 G loss:-2.121\n",
      "Epoch:  0015 D loss:-0.5013 G loss:-2.089\n",
      "Epoch:  0015 D loss:-0.4833 G loss:-2.015\n",
      "Epoch:  0015 D loss:-0.362 G loss:-2.062\n",
      "Epoch:  0015 D loss:-0.5256 G loss:-1.986\n",
      "Epoch:  0015 D loss:-0.4779 G loss:-1.973\n",
      "Epoch:  0015 D loss:-0.4286 G loss:-2.1\n",
      "Epoch:  0015 D loss:-0.4053 G loss:-2.193\n",
      "Epoch:  0015 D loss:-0.4723 G loss:-2.084\n",
      "Epoch:  0015 D loss:-0.5333 G loss:-2.274\n",
      "Epoch:  0015 D loss:-0.4048 G loss:-2.389\n",
      "Epoch:  0015 D loss:-0.3786 G loss:-2.361\n",
      "Epoch:  0015 D loss:-0.5252 G loss:-1.993\n",
      "Epoch:  0015 D loss:-0.4578 G loss:-2.266\n",
      "Epoch:  0015 D loss:-0.495 G loss:-2.311\n",
      "Epoch:  0015 D loss:-0.5745 G loss:-1.955\n",
      "Epoch:  0015 D loss:-0.4467 G loss:-2.002\n",
      "Epoch:  0015 D loss:-0.3706 G loss:-2.063\n",
      "Epoch:  0015 D loss:-0.4255 G loss:-2.084\n",
      "Epoch:  0015 D loss:-0.5021 G loss:-1.985\n",
      "Epoch:  0015 D loss:-0.4998 G loss:-2.069\n",
      "Epoch:  0015 D loss:-0.436 G loss:-2.135\n",
      "Epoch:  0015 D loss:-0.5553 G loss:-1.988\n",
      "Epoch:  0015 D loss:-0.4953 G loss:-2.114\n",
      "Epoch:  0015 D loss:-0.5123 G loss:-2.194\n",
      "Epoch:  0015 D loss:-0.5313 G loss:-2.139\n",
      "Epoch:  0015 D loss:-0.5092 G loss:-2.162\n",
      "Epoch:  0015 D loss:-0.5842 G loss:-2.105\n",
      "Epoch:  0015 D loss:-0.4835 G loss:-1.84\n",
      "Epoch:  0015 D loss:-0.4982 G loss:-1.994\n",
      "Epoch:  0015 D loss:-0.5314 G loss:-2.002\n",
      "Epoch:  0015 D loss:-0.4959 G loss:-1.868\n",
      "Epoch:  0015 D loss:-0.4777 G loss:-2.092\n",
      "Epoch:  0015 D loss:-0.575 G loss:-1.816\n",
      "Epoch:  0015 D loss:-0.6161 G loss:-1.87\n",
      "Epoch:  0015 D loss:-0.5239 G loss:-1.885\n",
      "Epoch:  0015 D loss:-0.6344 G loss:-1.957\n",
      "Epoch:  0015 D loss:-0.6408 G loss:-1.948\n",
      "Epoch:  0015 D loss:-0.5942 G loss:-2.017\n",
      "Epoch:  0015 D loss:-0.5257 G loss:-2.027\n",
      "Epoch:  0015 D loss:-0.6359 G loss:-1.959\n",
      "Epoch:  0015 D loss:-0.522 G loss:-1.865\n",
      "Epoch:  0015 D loss:-0.5118 G loss:-1.99\n",
      "Epoch:  0015 D loss:-0.7359 G loss:-1.786\n",
      "Epoch:  0015 D loss:-0.4979 G loss:-1.971\n",
      "Epoch:  0015 D loss:-0.5941 G loss:-1.849\n",
      "Epoch:  0015 D loss:-0.6539 G loss:-1.788\n",
      "Epoch:  0015 D loss:-0.5996 G loss:-1.803\n",
      "Epoch:  0015 D loss:-0.5248 G loss:-1.838\n",
      "Epoch:  0015 D loss:-0.554 G loss:-1.847\n",
      "Epoch:  0015 D loss:-0.6156 G loss:-1.739\n",
      "Epoch:  0015 D loss:-0.5805 G loss:-1.886\n",
      "Epoch:  0015 D loss:-0.6036 G loss:-2.008\n",
      "Epoch:  0015 D loss:-0.5602 G loss:-2.062\n",
      "Epoch:  0015 D loss:-0.5585 G loss:-2.098\n",
      "Epoch:  0015 D loss:-0.689 G loss:-2.104\n",
      "Epoch:  0015 D loss:-0.589 G loss:-2.064\n",
      "Epoch:  0015 D loss:-0.5085 G loss:-2.12\n",
      "Epoch:  0015 D loss:-0.5997 G loss:-2.034\n",
      "Epoch:  0015 D loss:-0.698 G loss:-1.892\n",
      "Epoch:  0015 D loss:-0.5504 G loss:-1.716\n",
      "Epoch:  0015 D loss:-0.6516 G loss:-1.813\n",
      "Epoch:  0015 D loss:-0.4641 G loss:-1.878\n",
      "Epoch:  0015 D loss:-0.5851 G loss:-1.84\n",
      "Epoch:  0015 D loss:-0.6179 G loss:-1.892\n",
      "Epoch:  0015 D loss:-0.523 G loss:-1.966\n",
      "Epoch:  0015 D loss:-0.5208 G loss:-1.868\n",
      "Epoch:  0015 D loss:-0.524 G loss:-1.99\n",
      "Epoch:  0015 D loss:-0.6121 G loss:-2.199\n",
      "Epoch:  0015 D loss:-0.4659 G loss:-2.155\n",
      "Epoch:  0015 D loss:-0.5211 G loss:-2.179\n",
      "Epoch:  0015 D loss:-0.49 G loss:-2.288\n",
      "Epoch:  0015 D loss:-0.5832 G loss:-2.215\n",
      "Epoch:  0015 D loss:-0.4709 G loss:-2.214\n",
      "Epoch:  0015 D loss:-0.4481 G loss:-2.12\n",
      "Epoch:  0015 D loss:-0.4688 G loss:-1.933\n",
      "Epoch:  0015 D loss:-0.5713 G loss:-1.989\n",
      "Epoch:  0015 D loss:-0.4506 G loss:-2.009\n",
      "Epoch:  0015 D loss:-0.519 G loss:-1.904\n",
      "Epoch:  0015 D loss:-0.4197 G loss:-2.055\n",
      "Epoch:  0015 D loss:-0.4793 G loss:-2.095\n",
      "Epoch:  0015 D loss:-0.5155 G loss:-2.206\n",
      "Epoch:  0015 D loss:-0.5141 G loss:-2.045\n",
      "Epoch:  0015 D loss:-0.509 G loss:-2.171\n",
      "Epoch:  0015 D loss:-0.5017 G loss:-2.282\n",
      "Epoch:  0015 D loss:-0.4902 G loss:-2.268\n",
      "Epoch:  0015 D loss:-0.5148 G loss:-2.039\n",
      "Epoch:  0015 D loss:-0.4979 G loss:-2.042\n",
      "Epoch:  0015 D loss:-0.4685 G loss:-2.003\n",
      "Epoch:  0015 D loss:-0.4657 G loss:-2.008\n",
      "Epoch:  0015 D loss:-0.4605 G loss:-2.116\n",
      "Epoch:  0015 D loss:-0.515 G loss:-2.08\n",
      "Epoch:  0015 D loss:-0.4104 G loss:-2.216\n",
      "Epoch:  0015 D loss:-0.3938 G loss:-2.273\n",
      "Epoch:  0015 D loss:-0.4286 G loss:-2.273\n",
      "Epoch:  0015 D loss:-0.3764 G loss:-2.266\n",
      "Epoch:  0015 D loss:-0.4178 G loss:-2.101\n",
      "Epoch:  0015 D loss:-0.5162 G loss:-2.089\n",
      "Epoch:  0015 D loss:-0.5044 G loss:-2.333\n",
      "Epoch:  0015 D loss:-0.5239 G loss:-2.285\n",
      "Epoch:  0015 D loss:-0.4407 G loss:-2.325\n",
      "Epoch:  0015 D loss:-0.4374 G loss:-2.346\n",
      "Epoch:  0015 D loss:-0.4725 G loss:-2.492\n",
      "Epoch:  0015 D loss:-0.443 G loss:-2.183\n",
      "Epoch:  0015 D loss:-0.4903 G loss:-2.44\n",
      "Epoch:  0015 D loss:-0.4595 G loss:-2.304\n",
      "Epoch:  0015 D loss:-0.4258 G loss:-2.168\n",
      "Epoch:  0015 D loss:-0.3766 G loss:-2.253\n",
      "Epoch:  0015 D loss:-0.3822 G loss:-2.267\n",
      "Epoch:  0015 D loss:-0.4457 G loss:-2.11\n",
      "Epoch:  0015 D loss:-0.4457 G loss:-2.147\n",
      "Epoch:  0015 D loss:-0.4185 G loss:-2.45\n",
      "Epoch:  0015 D loss:-0.343 G loss:-2.283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0015 D loss:-0.4556 G loss:-2.388\n",
      "Epoch:  0015 D loss:-0.4739 G loss:-2.188\n",
      "Epoch:  0015 D loss:-0.4348 G loss:-2.166\n",
      "Epoch:  0015 D loss:-0.4508 G loss:-2.123\n",
      "Epoch:  0015 D loss:-0.4725 G loss:-2.169\n",
      "Epoch:  0015 D loss:-0.3629 G loss:-2.26\n",
      "Epoch:  0015 D loss:-0.3481 G loss:-2.431\n",
      "Epoch:  0015 D loss:-0.4981 G loss:-2.243\n",
      "Epoch:  0015 D loss:-0.3188 G loss:-2.32\n",
      "Epoch:  0015 D loss:-0.4172 G loss:-2.336\n",
      "Epoch:  0015 D loss:-0.4329 G loss:-2.248\n",
      "Epoch:  0015 D loss:-0.4053 G loss:-2.307\n",
      "Epoch:  0015 D loss:-0.4364 G loss:-2.237\n",
      "Epoch:  0015 D loss:-0.3801 G loss:-2.304\n",
      "Epoch:  0015 D loss:-0.4419 G loss:-2.464\n",
      "Epoch:  0015 D loss:-0.437 G loss:-2.306\n",
      "Epoch:  0015 D loss:-0.4291 G loss:-2.262\n",
      "Epoch:  0015 D loss:-0.4447 G loss:-2.33\n",
      "Epoch:  0015 D loss:-0.4219 G loss:-2.433\n",
      "Epoch:  0015 D loss:-0.5238 G loss:-2.282\n",
      "Epoch:  0015 D loss:-0.355 G loss:-2.428\n",
      "Epoch:  0015 D loss:-0.4964 G loss:-2.189\n",
      "Epoch:  0015 D loss:-0.3617 G loss:-2.314\n",
      "Epoch:  0015 D loss:-0.3584 G loss:-2.405\n",
      "Epoch:  0015 D loss:-0.378 G loss:-2.433\n",
      "Epoch:  0015 D loss:-0.3275 G loss:-2.476\n",
      "Epoch:  0015 D loss:-0.3768 G loss:-2.315\n",
      "Epoch:  0015 D loss:-0.4241 G loss:-2.285\n",
      "Epoch:  0015 D loss:-0.4114 G loss:-2.386\n",
      "Epoch:  0015 D loss:-0.4588 G loss:-2.27\n",
      "Epoch:  0015 D loss:-0.4093 G loss:-2.388\n",
      "Epoch:  0015 D loss:-0.384 G loss:-2.372\n",
      "Epoch:  0015 D loss:-0.4026 G loss:-2.433\n",
      "Epoch:  0015 D loss:-0.3939 G loss:-2.465\n",
      "Epoch:  0015 D loss:-0.4561 G loss:-2.45\n",
      "Epoch:  0015 D loss:-0.4166 G loss:-2.389\n",
      "Epoch:  0015 D loss:-0.401 G loss:-2.232\n",
      "Epoch:  0015 D loss:-0.4828 G loss:-2.182\n",
      "Epoch:  0015 D loss:-0.45 G loss:-2.125\n",
      "Epoch:  0015 D loss:-0.5154 G loss:-2.077\n",
      "Epoch:  0015 D loss:-0.4905 G loss:-2.14\n",
      "Epoch:  0015 D loss:-0.4582 G loss:-2.064\n",
      "Epoch:  0015 D loss:-0.4217 G loss:-2.148\n",
      "Epoch:  0015 D loss:-0.4736 G loss:-2.166\n",
      "Epoch:  0015 D loss:-0.4865 G loss:-2.157\n",
      "Epoch:  0015 D loss:-0.481 G loss:-2.344\n",
      "Epoch:  0015 D loss:-0.4942 G loss:-2.097\n",
      "Epoch:  0015 D loss:-0.4629 G loss:-2.295\n",
      "Epoch:  0015 D loss:-0.4647 G loss:-2.223\n",
      "Epoch:  0015 D loss:-0.4938 G loss:-2.171\n",
      "Epoch:  0015 D loss:-0.5191 G loss:-2.141\n",
      "Epoch:  0015 D loss:-0.3511 G loss:-2.201\n",
      "Epoch:  0015 D loss:-0.3971 G loss:-2.193\n",
      "Epoch:  0015 D loss:-0.3497 G loss:-2.253\n",
      "Epoch:  0015 D loss:-0.3844 G loss:-2.171\n",
      "Epoch:  0015 D loss:-0.5208 G loss:-2.228\n",
      "Epoch:  0015 D loss:-0.4303 G loss:-2.225\n",
      "Epoch:  0015 D loss:-0.4347 G loss:-2.466\n",
      "Epoch:  0015 D loss:-0.548 G loss:-2.187\n",
      "Epoch:  0015 D loss:-0.3845 G loss:-2.242\n",
      "Epoch:  0015 D loss:-0.5143 G loss:-2.223\n",
      "Epoch:  0015 D loss:-0.497 G loss:-2.18\n",
      "Epoch:  0015 D loss:-0.4134 G loss:-2.151\n",
      "Epoch:  0015 D loss:-0.3941 G loss:-2.257\n",
      "Epoch:  0015 D loss:-0.4172 G loss:-2.184\n",
      "Epoch:  0015 D loss:-0.4256 G loss:-2.285\n",
      "Epoch:  0015 D loss:-0.4215 G loss:-2.171\n",
      "Epoch:  0015 D loss:-0.4485 G loss:-2.156\n",
      "Epoch:  0015 D loss:-0.4837 G loss:-2.076\n",
      "Epoch:  0015 D loss:-0.4409 G loss:-2.191\n",
      "Epoch:  0015 D loss:-0.5664 G loss:-2.172\n",
      "Epoch:  0015 D loss:-0.457 G loss:-2.221\n",
      "Epoch:  0015 D loss:-0.4768 G loss:-2.128\n",
      "Epoch:  0015 D loss:-0.5444 G loss:-2.012\n",
      "Epoch:  0015 D loss:-0.5881 G loss:-2.022\n",
      "Epoch:  0015 D loss:-0.4637 G loss:-2.212\n",
      "Epoch:  0015 D loss:-0.492 G loss:-2.091\n",
      "Epoch:  0015 D loss:-0.4973 G loss:-2.002\n",
      "Epoch:  0015 D loss:-0.6029 G loss:-2.062\n",
      "Epoch:  0015 D loss:-0.5513 G loss:-1.899\n",
      "Epoch:  0015 D loss:-0.4879 G loss:-1.952\n",
      "Epoch:  0015 D loss:-0.4125 G loss:-2.046\n",
      "Epoch:  0015 D loss:-0.545 G loss:-1.901\n",
      "Epoch:  0015 D loss:-0.4305 G loss:-2.196\n",
      "Epoch:  0015 D loss:-0.5769 G loss:-2.121\n",
      "Epoch:  0015 D loss:-0.4741 G loss:-2.116\n",
      "Epoch:  0015 D loss:-0.5022 G loss:-2.055\n",
      "Epoch:  0015 D loss:-0.4779 G loss:-2.102\n",
      "Epoch:  0015 D loss:-0.4493 G loss:-2.193\n",
      "Epoch:  0015 D loss:-0.5694 G loss:-1.929\n",
      "Epoch:  0015 D loss:-0.4123 G loss:-2.031\n",
      "Epoch:  0015 D loss:-0.4882 G loss:-1.989\n",
      "Epoch:  0015 D loss:-0.5481 G loss:-2.038\n",
      "Epoch:  0015 D loss:-0.4434 G loss:-2.056\n",
      "Epoch:  0015 D loss:-0.4884 G loss:-2.277\n",
      "Epoch:  0015 D loss:-0.5433 G loss:-2.223\n",
      "Epoch:  0015 D loss:-0.588 G loss:-2.128\n",
      "Epoch:  0015 D loss:-0.4199 G loss:-2.286\n",
      "Epoch:  0015 D loss:-0.4435 G loss:-2.255\n",
      "Epoch:  0015 D loss:-0.4686 G loss:-2.178\n",
      "Epoch:  0015 D loss:-0.4799 G loss:-2.148\n",
      "Epoch:  0015 D loss:-0.5469 G loss:-1.984\n",
      "Epoch:  0015 D loss:-0.4919 G loss:-2.001\n",
      "Epoch:  0015 D loss:-0.4288 G loss:-2.002\n",
      "Epoch:  0015 D loss:-0.5327 G loss:-2.008\n",
      "Epoch:  0015 D loss:-0.5889 G loss:-1.994\n",
      "Epoch:  0015 D loss:-0.4956 G loss:-1.979\n",
      "Epoch:  0015 D loss:-0.6027 G loss:-1.807\n",
      "Epoch:  0015 D loss:-0.5765 G loss:-1.914\n",
      "Epoch:  0015 D loss:-0.6769 G loss:-1.891\n",
      "Epoch:  0015 D loss:-0.583 G loss:-1.858\n",
      "Epoch:  0015 D loss:-0.6053 G loss:-1.905\n",
      "Epoch:  0015 D loss:-0.5341 G loss:-2.08\n",
      "Epoch:  0015 D loss:-0.4477 G loss:-2.182\n",
      "Epoch:  0015 D loss:-0.5431 G loss:-2.155\n",
      "Epoch:  0015 D loss:-0.7944 G loss:-2.127\n",
      "Epoch:  0015 D loss:-0.6032 G loss:-2.106\n",
      "Epoch:  0015 D loss:-0.4639 G loss:-2.018\n",
      "Epoch:  0015 D loss:-0.5905 G loss:-1.997\n",
      "Epoch:  0015 D loss:-0.5657 G loss:-2.046\n",
      "Epoch:  0015 D loss:-0.517 G loss:-2.025\n",
      "Epoch:  0015 D loss:-0.5408 G loss:-1.941\n",
      "Epoch:  0015 D loss:-0.588 G loss:-1.971\n",
      "Epoch:  0015 D loss:-0.5003 G loss:-1.924\n",
      "Epoch:  0015 D loss:-0.4426 G loss:-2.134\n",
      "Epoch:  0015 D loss:-0.6639 G loss:-1.888\n",
      "Epoch:  0015 D loss:-0.5523 G loss:-2.001\n",
      "Epoch:  0015 D loss:-0.5293 G loss:-2.066\n",
      "Epoch:  0015 D loss:-0.6136 G loss:-1.913\n",
      "Epoch:  0015 D loss:-0.5811 G loss:-2.16\n",
      "Epoch:  0015 D loss:-0.5934 G loss:-2.039\n",
      "Epoch:  0015 D loss:-0.5598 G loss:-2.171\n",
      "Epoch:  0015 D loss:-0.6851 G loss:-2.238\n",
      "Epoch:  0015 D loss:-0.4238 G loss:-2.249\n",
      "Epoch:  0015 D loss:-0.5794 G loss:-2.043\n",
      "Epoch:  0015 D loss:-0.3968 G loss:-2.24\n",
      "Epoch:  0015 D loss:-0.5755 G loss:-2.011\n",
      "Epoch:  0015 D loss:-0.5645 G loss:-2.077\n",
      "Epoch:  0015 D loss:-0.4986 G loss:-2.129\n",
      "Epoch:  0015 D loss:-0.5049 G loss:-2.234\n",
      "Epoch:  0015 D loss:-0.5564 G loss:-2.079\n",
      "Epoch:  0015 D loss:-0.4695 G loss:-2.078\n",
      "Epoch:  0015 D loss:-0.5508 G loss:-2.063\n",
      "Epoch:  0015 D loss:-0.4603 G loss:-2.243\n",
      "Epoch:  0015 D loss:-0.4894 G loss:-2.257\n",
      "Epoch:  0015 D loss:-0.6241 G loss:-2.174\n",
      "Epoch:  0015 D loss:-0.622 G loss:-2.022\n",
      "Epoch:  0015 D loss:-0.4635 G loss:-2.177\n",
      "Epoch:  0015 D loss:-0.5369 G loss:-2.148\n",
      "Epoch:  0015 D loss:-0.5991 G loss:-2.182\n",
      "Epoch:  0015 D loss:-0.5181 G loss:-2.122\n",
      "Epoch:  0015 D loss:-0.5612 G loss:-2.131\n",
      "Epoch:  0015 D loss:-0.5014 G loss:-2.186\n",
      "Epoch:  0015 D loss:-0.4831 G loss:-2.29\n",
      "Epoch:  0015 D loss:-0.5764 G loss:-2.051\n",
      "Epoch:  0015 D loss:-0.4841 G loss:-2.32\n",
      "Epoch:  0015 D loss:-0.45 G loss:-2.299\n",
      "Epoch:  0015 D loss:-0.417 G loss:-2.427\n",
      "Epoch:  0015 D loss:-0.4251 G loss:-2.389\n",
      "Epoch:  0015 D loss:-0.4772 G loss:-2.368\n",
      "Epoch:  0015 D loss:-0.4414 G loss:-2.45\n",
      "Epoch:  0015 D loss:-0.3909 G loss:-2.405\n",
      "Epoch:  0015 D loss:-0.4151 G loss:-2.441\n",
      "Epoch:  0015 D loss:-0.4049 G loss:-2.4\n",
      "Epoch:  0015 D loss:-0.3799 G loss:-2.439\n",
      "Epoch:  0015 D loss:-0.5647 G loss:-2.267\n",
      "Epoch:  0015 D loss:-0.3864 G loss:-2.491\n",
      "Epoch:  0015 D loss:-0.3803 G loss:-2.498\n",
      "Epoch:  0015 D loss:-0.4977 G loss:-2.292\n",
      "Epoch:  0015 D loss:-0.3171 G loss:-2.608\n",
      "Epoch:  0015 D loss:-0.377 G loss:-2.551\n",
      "Epoch:  0015 D loss:-0.3735 G loss:-2.403\n",
      "Epoch:  0015 D loss:-0.3068 G loss:-2.334\n",
      "Epoch:  0015 D loss:-0.3484 G loss:-2.33\n",
      "Epoch:  0015 D loss:-0.388 G loss:-2.41\n",
      "Epoch:  0015 D loss:-0.4279 G loss:-2.458\n",
      "Epoch:  0015 D loss:-0.3891 G loss:-2.577\n",
      "Epoch:  0015 D loss:-0.4567 G loss:-2.345\n",
      "Epoch:  0015 D loss:-0.4333 G loss:-2.318\n",
      "Epoch:  0015 D loss:-0.3899 G loss:-2.31\n",
      "Epoch:  0015 D loss:-0.4474 G loss:-2.406\n",
      "Epoch:  0015 D loss:-0.5619 G loss:-2.125\n",
      "Epoch:  0015 D loss:-0.3905 G loss:-2.338\n",
      "Epoch:  0015 D loss:-0.4102 G loss:-2.318\n",
      "Epoch:  0015 D loss:-0.34 G loss:-2.291\n",
      "Epoch:  0015 D loss:-0.4494 G loss:-2.295\n",
      "Epoch:  0015 D loss:-0.4025 G loss:-2.354\n",
      "Epoch:  0015 D loss:-0.3887 G loss:-2.421\n",
      "Epoch:  0015 D loss:-0.4974 G loss:-2.471\n",
      "Epoch:  0015 D loss:-0.4244 G loss:-2.538\n",
      "Epoch:  0015 D loss:-0.3532 G loss:-2.707\n",
      "Epoch:  0015 D loss:-0.3715 G loss:-2.551\n",
      "Epoch:  0015 D loss:-0.4584 G loss:-2.467\n",
      "Epoch:  0015 D loss:-0.4865 G loss:-2.575\n",
      "Epoch:  0015 D loss:-0.3699 G loss:-2.405\n",
      "Epoch:  0015 D loss:-0.4478 G loss:-2.619\n",
      "Epoch:  0015 D loss:-0.4284 G loss:-2.336\n",
      "Epoch:  0015 D loss:-0.5019 G loss:-2.528\n",
      "Epoch:  0015 D loss:-0.3778 G loss:-2.532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0015 D loss:-0.4469 G loss:-2.265\n",
      "Epoch:  0015 D loss:-0.424 G loss:-2.295\n",
      "Epoch:  0015 D loss:-0.5357 G loss:-2.227\n",
      "Epoch:  0015 D loss:-0.4547 G loss:-2.063\n",
      "Epoch:  0015 D loss:-0.4215 G loss:-2.32\n",
      "Epoch:  0015 D loss:-0.4738 G loss:-2.296\n",
      "Epoch:  0015 D loss:-0.485 G loss:-2.279\n",
      "Epoch:  0015 D loss:-0.4162 G loss:-2.423\n",
      "Epoch:  0015 D loss:-0.3834 G loss:-2.433\n",
      "Epoch:  0015 D loss:-0.4169 G loss:-2.336\n",
      "Epoch:  0015 D loss:-0.4333 G loss:-2.586\n",
      "Epoch:  0015 D loss:-0.6177 G loss:-2.252\n",
      "Epoch:  0015 D loss:-0.5341 G loss:-2.229\n",
      "Epoch:  0015 D loss:-0.4438 G loss:-2.384\n",
      "Epoch:  0015 D loss:-0.4189 G loss:-2.266\n",
      "Epoch:  0015 D loss:-0.4472 G loss:-2.5\n",
      "Epoch:  0015 D loss:-0.4423 G loss:-2.451\n",
      "Epoch:  0015 D loss:-0.4079 G loss:-2.224\n",
      "Epoch:  0015 D loss:-0.4493 G loss:-2.35\n",
      "Epoch:  0015 D loss:-0.4289 G loss:-2.201\n",
      "Epoch:  0015 D loss:-0.3871 G loss:-2.259\n",
      "Epoch:  0015 D loss:-0.4698 G loss:-2.356\n",
      "Epoch:  0015 D loss:-0.4394 G loss:-2.282\n",
      "Epoch:  0015 D loss:-0.3862 G loss:-2.339\n",
      "Epoch:  0015 D loss:-0.5762 G loss:-2.26\n",
      "Epoch:  0015 D loss:-0.4595 G loss:-2.203\n",
      "Epoch:  0015 D loss:-0.391 G loss:-2.346\n",
      "Epoch:  0015 D loss:-0.4997 G loss:-2.315\n",
      "Epoch:  0015 D loss:-0.4618 G loss:-2.25\n",
      "Epoch:  0015 D loss:-0.3938 G loss:-2.405\n",
      "Epoch:  0015 D loss:-0.4587 G loss:-2.478\n",
      "Epoch:  0015 D loss:-0.5758 G loss:-2.249\n",
      "Epoch:  0015 D loss:-0.4501 G loss:-2.426\n",
      "Epoch:  0015 D loss:-0.4396 G loss:-2.303\n",
      "Epoch:  0015 D loss:-0.4729 G loss:-2.35\n",
      "Epoch:  0015 D loss:-0.4485 G loss:-2.344\n",
      "Epoch:  0015 D loss:-0.4161 G loss:-2.376\n",
      "Epoch:  0015 D loss:-0.4343 G loss:-2.112\n",
      "Epoch:  0015 D loss:-0.4487 G loss:-2.337\n",
      "Epoch:  0015 D loss:-0.3717 G loss:-2.292\n",
      "Epoch:  0015 D loss:-0.4545 G loss:-2.087\n",
      "Epoch:  0015 D loss:-0.4163 G loss:-2.307\n",
      "Epoch:  0015 D loss:-0.4806 G loss:-2.226\n",
      "Epoch:  0015 D loss:-0.3881 G loss:-2.425\n",
      "Epoch:  0015 D loss:-0.432 G loss:-2.482\n",
      "Epoch:  0015 D loss:-0.471 G loss:-2.322\n",
      "Epoch:  0015 D loss:-0.4755 G loss:-2.384\n",
      "Epoch:  0015 D loss:-0.3601 G loss:-2.6\n",
      "Epoch:  0015 D loss:-0.364 G loss:-2.401\n",
      "Epoch:  0015 D loss:-0.5596 G loss:-2.301\n",
      "Epoch:  0015 D loss:-0.5025 G loss:-2.313\n",
      "Epoch:  0015 D loss:-0.3369 G loss:-2.341\n",
      "Epoch:  0015 D loss:-0.408 G loss:-2.3\n",
      "Epoch:  0015 D loss:-0.4485 G loss:-2.304\n",
      "Epoch:  0015 D loss:-0.5517 G loss:-2.084\n",
      "Epoch:  0015 D loss:-0.439 G loss:-2.081\n",
      "Epoch:  0015 D loss:-0.4201 G loss:-2.34\n",
      "Epoch:  0015 D loss:-0.4173 G loss:-2.299\n",
      "Epoch:  0015 D loss:-0.4527 G loss:-2.37\n",
      "Epoch:  0015 D loss:-0.3626 G loss:-2.317\n",
      "Epoch:  0015 D loss:-0.5428 G loss:-2.31\n",
      "Epoch:  0015 D loss:-0.4611 G loss:-2.27\n",
      "Epoch:  0015 D loss:-0.434 G loss:-2.346\n",
      "Epoch:  0015 D loss:-0.4577 G loss:-2.487\n",
      "Epoch:  0015 D loss:-0.4438 G loss:-2.201\n",
      "Epoch:  0015 D loss:-0.5465 G loss:-2.271\n",
      "Epoch:  0015 D loss:-0.5575 G loss:-2.247\n",
      "Epoch:  0015 D loss:-0.5045 G loss:-2.315\n",
      "Epoch:  0015 D loss:-0.4956 G loss:-2.134\n",
      "Epoch:  0015 D loss:-0.4638 G loss:-2.283\n",
      "Epoch:  0015 D loss:-0.4539 G loss:-2.206\n",
      "Epoch:  0015 D loss:-0.4783 G loss:-2.128\n",
      "Epoch:  0015 D loss:-0.3916 G loss:-2.299\n",
      "Epoch:  0015 D loss:-0.4608 G loss:-2.373\n",
      "Epoch:  0015 D loss:-0.5097 G loss:-2.324\n",
      "Epoch:  0015 D loss:-0.5516 G loss:-2.09\n",
      "Epoch:  0015 D loss:-0.5026 G loss:-2.428\n",
      "Epoch:  0015 D loss:-0.5134 G loss:-2.224\n",
      "Epoch:  0015 D loss:-0.5998 G loss:-2.274\n",
      "Epoch:  0015 D loss:-0.5371 G loss:-2.238\n",
      "Epoch:  0015 D loss:-0.6524 G loss:-1.933\n",
      "Epoch:  0015 D loss:-0.5353 G loss:-2.065\n",
      "Epoch:  0015 D loss:-0.5624 G loss:-2.125\n",
      "Epoch:  0015 D loss:-0.502 G loss:-2.143\n",
      "Epoch:  0015 D loss:-0.5222 G loss:-2.155\n",
      "Epoch:  0015 D loss:-0.5348 G loss:-1.966\n",
      "Epoch:  0015 D loss:-0.5124 G loss:-2.122\n",
      "Epoch:  0015 D loss:-0.4375 G loss:-2.296\n",
      "Epoch:  0015 D loss:-0.4424 G loss:-2.558\n",
      "Epoch:  0015 D loss:-0.4272 G loss:-2.385\n",
      "Epoch:  0015 D loss:-0.5676 G loss:-2.161\n",
      "Epoch:  0015 D loss:-0.656 G loss:-2.359\n",
      "Epoch:  0015 D loss:-0.4096 G loss:-2.311\n",
      "Epoch:  0015 D loss:-0.6132 G loss:-2.159\n",
      "Epoch:  0015 D loss:-0.5777 G loss:-2.31\n",
      "Epoch:  0015 D loss:-0.5355 G loss:-2.006\n",
      "Epoch:  0015 D loss:-0.4403 G loss:-2.189\n",
      "Epoch:  0015 D loss:-0.5038 G loss:-2.045\n",
      "Epoch:  0015 D loss:-0.5275 G loss:-2.08\n",
      "Epoch:  0015 D loss:-0.4943 G loss:-2.28\n",
      "Epoch:  0015 D loss:-0.552 G loss:-2.233\n",
      "Epoch:  0015 D loss:-0.4992 G loss:-2.089\n",
      "Epoch:  0015 D loss:-0.5305 G loss:-2.344\n",
      "Epoch:  0015 D loss:-0.4466 G loss:-2.173\n",
      "Epoch:  0015 D loss:-0.4492 G loss:-2.473\n",
      "Epoch:  0015 D loss:-0.5403 G loss:-2.403\n",
      "Epoch:  0015 D loss:-0.518 G loss:-2.331\n",
      "Epoch:  0015 D loss:-0.5397 G loss:-2.191\n",
      "Epoch:  0015 D loss:-0.5483 G loss:-2.099\n",
      "Epoch:  0015 D loss:-0.4796 G loss:-2.243\n",
      "Epoch:  0015 D loss:-0.3976 G loss:-2.106\n",
      "Epoch:  0015 D loss:-0.5052 G loss:-2.174\n",
      "Epoch:  0015 D loss:-0.4254 G loss:-2.206\n",
      "Epoch:  0015 D loss:-0.4534 G loss:-2.289\n",
      "Epoch:  0015 D loss:-0.5307 G loss:-2.329\n",
      "Epoch:  0015 D loss:-0.4088 G loss:-2.275\n",
      "Epoch:  0015 D loss:-0.5722 G loss:-2.249\n",
      "Epoch:  0015 D loss:-0.4294 G loss:-2.202\n",
      "Epoch:  0015 D loss:-0.5023 G loss:-2.172\n",
      "Epoch:  0015 D loss:-0.525 G loss:-2.054\n",
      "Epoch:  0015 D loss:-0.4466 G loss:-2.089\n",
      "Epoch:  0015 D loss:-0.4009 G loss:-2.248\n",
      "Epoch:  0015 D loss:-0.494 G loss:-2.28\n",
      "Epoch:  0015 D loss:-0.4783 G loss:-2.309\n",
      "Epoch:  0015 D loss:-0.541 G loss:-2.301\n",
      "Epoch:  0015 D loss:-0.5643 G loss:-2.302\n",
      "Epoch:  0015 D loss:-0.4824 G loss:-2.512\n",
      "Epoch:  0015 D loss:-0.4271 G loss:-2.381\n",
      "Epoch:  0015 D loss:-0.4582 G loss:-2.164\n",
      "Epoch:  0015 D loss:-0.4117 G loss:-2.285\n",
      "Epoch:  0015 D loss:-0.4606 G loss:-2.192\n",
      "Epoch:  0015 D loss:-0.473 G loss:-2.143\n",
      "Epoch:  0015 D loss:-0.5504 G loss:-2.05\n",
      "Epoch:  0015 D loss:-0.4525 G loss:-2.159\n",
      "Epoch:  0015 D loss:-0.5056 G loss:-2.162\n",
      "Epoch:  0015 D loss:-0.4678 G loss:-2.116\n",
      "Epoch:  0015 D loss:-0.4405 G loss:-2.157\n",
      "Epoch:  0015 D loss:-0.4768 G loss:-2.134\n",
      "Epoch:  0015 D loss:-0.3733 G loss:-2.25\n",
      "Epoch:  0015 D loss:-0.5085 G loss:-2.2\n",
      "Epoch:  0015 D loss:-0.544 G loss:-2.143\n",
      "Epoch:  0015 D loss:-0.5341 G loss:-2.291\n",
      "Epoch:  0015 D loss:-0.441 G loss:-2.335\n",
      "Epoch:  0015 D loss:-0.4818 G loss:-2.183\n",
      "Epoch:  0015 D loss:-0.5153 G loss:-2.256\n",
      "Epoch:  0015 D loss:-0.4322 G loss:-2.332\n",
      "Epoch:  0015 D loss:-0.3907 G loss:-2.38\n",
      "Epoch:  0015 D loss:-0.3958 G loss:-2.355\n",
      "Epoch:  0015 D loss:-0.4906 G loss:-2.179\n",
      "Epoch:  0015 D loss:-0.4631 G loss:-2.099\n",
      "Epoch:  0015 D loss:-0.478 G loss:-2.112\n",
      "Epoch:  0015 D loss:-0.3572 G loss:-2.235\n",
      "Epoch:  0015 D loss:-0.3739 G loss:-2.179\n",
      "Epoch:  0015 D loss:-0.3901 G loss:-2.381\n",
      "Epoch:  0015 D loss:-0.4085 G loss:-2.288\n",
      "Epoch:  0015 D loss:-0.3788 G loss:-2.36\n",
      "Epoch:  0015 D loss:-0.3753 G loss:-2.34\n",
      "Epoch:  0015 D loss:-0.3731 G loss:-2.552\n",
      "Epoch:  0015 D loss:-0.3721 G loss:-2.36\n",
      "Epoch:  0015 D loss:-0.4015 G loss:-2.591\n",
      "Epoch:  0015 D loss:-0.4057 G loss:-2.486\n",
      "Epoch:  0015 D loss:-0.4235 G loss:-2.504\n",
      "Epoch:  0015 D loss:-0.4901 G loss:-2.343\n",
      "Epoch:  0015 D loss:-0.356 G loss:-2.385\n",
      "Epoch:  0015 D loss:-0.4 G loss:-2.359\n",
      "Epoch:  0015 D loss:-0.3831 G loss:-2.443\n",
      "Epoch:  0015 D loss:-0.4657 G loss:-2.328\n",
      "Epoch:  0015 D loss:-0.4245 G loss:-2.323\n",
      "Epoch:  0015 D loss:-0.2844 G loss:-2.451\n",
      "Epoch:  0015 D loss:-0.4187 G loss:-2.531\n",
      "Epoch:  0016 D loss:-0.4223 G loss:-2.268\n",
      "Epoch:  0016 D loss:-0.3594 G loss:-2.394\n",
      "Epoch:  0016 D loss:-0.3642 G loss:-2.483\n",
      "Epoch:  0016 D loss:-0.3944 G loss:-2.451\n",
      "Epoch:  0016 D loss:-0.392 G loss:-2.425\n",
      "Epoch:  0016 D loss:-0.3926 G loss:-2.397\n",
      "Epoch:  0016 D loss:-0.3931 G loss:-2.36\n",
      "Epoch:  0016 D loss:-0.3554 G loss:-2.483\n",
      "Epoch:  0016 D loss:-0.3432 G loss:-2.45\n",
      "Epoch:  0016 D loss:-0.3651 G loss:-2.385\n",
      "Epoch:  0016 D loss:-0.3727 G loss:-2.45\n",
      "Epoch:  0016 D loss:-0.3719 G loss:-2.415\n",
      "Epoch:  0016 D loss:-0.3494 G loss:-2.45\n",
      "Epoch:  0016 D loss:-0.4276 G loss:-2.445\n",
      "Epoch:  0016 D loss:-0.4123 G loss:-2.53\n",
      "Epoch:  0016 D loss:-0.3277 G loss:-2.578\n",
      "Epoch:  0016 D loss:-0.4823 G loss:-2.32\n",
      "Epoch:  0016 D loss:-0.3782 G loss:-2.351\n",
      "Epoch:  0016 D loss:-0.4157 G loss:-2.368\n",
      "Epoch:  0016 D loss:-0.3362 G loss:-2.322\n",
      "Epoch:  0016 D loss:-0.4154 G loss:-2.288\n",
      "Epoch:  0016 D loss:-0.362 G loss:-2.381\n",
      "Epoch:  0016 D loss:-0.4562 G loss:-2.406\n",
      "Epoch:  0016 D loss:-0.4041 G loss:-2.513\n",
      "Epoch:  0016 D loss:-0.3973 G loss:-2.581\n",
      "Epoch:  0016 D loss:-0.4918 G loss:-2.46\n",
      "Epoch:  0016 D loss:-0.4279 G loss:-2.458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0016 D loss:-0.3506 G loss:-2.572\n",
      "Epoch:  0016 D loss:-0.3768 G loss:-2.537\n",
      "Epoch:  0016 D loss:-0.4289 G loss:-2.47\n",
      "Epoch:  0016 D loss:-0.4578 G loss:-2.344\n",
      "Epoch:  0016 D loss:-0.4838 G loss:-2.304\n",
      "Epoch:  0016 D loss:-0.489 G loss:-2.367\n",
      "Epoch:  0016 D loss:-0.3244 G loss:-2.479\n",
      "Epoch:  0016 D loss:-0.4229 G loss:-2.336\n",
      "Epoch:  0016 D loss:-0.3727 G loss:-2.431\n",
      "Epoch:  0016 D loss:-0.4417 G loss:-2.427\n",
      "Epoch:  0016 D loss:-0.36 G loss:-2.564\n",
      "Epoch:  0016 D loss:-0.4587 G loss:-2.447\n",
      "Epoch:  0016 D loss:-0.4104 G loss:-2.478\n",
      "Epoch:  0016 D loss:-0.3715 G loss:-2.547\n",
      "Epoch:  0016 D loss:-0.3867 G loss:-2.513\n",
      "Epoch:  0016 D loss:-0.3583 G loss:-2.431\n",
      "Epoch:  0016 D loss:-0.3877 G loss:-2.385\n",
      "Epoch:  0016 D loss:-0.3527 G loss:-2.41\n",
      "Epoch:  0016 D loss:-0.4458 G loss:-2.332\n",
      "Epoch:  0016 D loss:-0.405 G loss:-2.596\n",
      "Epoch:  0016 D loss:-0.408 G loss:-2.565\n",
      "Epoch:  0016 D loss:-0.4019 G loss:-2.31\n",
      "Epoch:  0016 D loss:-0.3973 G loss:-2.409\n",
      "Epoch:  0016 D loss:-0.3742 G loss:-2.433\n",
      "Epoch:  0016 D loss:-0.4851 G loss:-2.256\n",
      "Epoch:  0016 D loss:-0.3488 G loss:-2.451\n",
      "Epoch:  0016 D loss:-0.3739 G loss:-2.447\n",
      "Epoch:  0016 D loss:-0.3827 G loss:-2.493\n",
      "Epoch:  0016 D loss:-0.4272 G loss:-2.518\n",
      "Epoch:  0016 D loss:-0.3783 G loss:-2.415\n",
      "Epoch:  0016 D loss:-0.3864 G loss:-2.659\n",
      "Epoch:  0016 D loss:-0.432 G loss:-2.458\n",
      "Epoch:  0016 D loss:-0.4024 G loss:-2.374\n",
      "Epoch:  0016 D loss:-0.4869 G loss:-2.243\n",
      "Epoch:  0016 D loss:-0.3696 G loss:-2.429\n",
      "Epoch:  0016 D loss:-0.4368 G loss:-2.407\n",
      "Epoch:  0016 D loss:-0.3904 G loss:-2.459\n",
      "Epoch:  0016 D loss:-0.3521 G loss:-2.563\n",
      "Epoch:  0016 D loss:-0.4255 G loss:-2.506\n",
      "Epoch:  0016 D loss:-0.3595 G loss:-2.513\n",
      "Epoch:  0016 D loss:-0.4217 G loss:-2.334\n",
      "Epoch:  0016 D loss:-0.3013 G loss:-2.765\n",
      "Epoch:  0016 D loss:-0.4403 G loss:-2.335\n",
      "Epoch:  0016 D loss:-0.3839 G loss:-2.438\n",
      "Epoch:  0016 D loss:-0.3893 G loss:-2.6\n",
      "Epoch:  0016 D loss:-0.4256 G loss:-2.409\n",
      "Epoch:  0016 D loss:-0.3731 G loss:-2.38\n",
      "Epoch:  0016 D loss:-0.2967 G loss:-2.469\n",
      "Epoch:  0016 D loss:-0.316 G loss:-2.547\n",
      "Epoch:  0016 D loss:-0.4608 G loss:-2.467\n",
      "Epoch:  0016 D loss:-0.446 G loss:-2.598\n",
      "Epoch:  0016 D loss:-0.3605 G loss:-2.428\n",
      "Epoch:  0016 D loss:-0.4104 G loss:-2.44\n",
      "Epoch:  0016 D loss:-0.3254 G loss:-2.508\n",
      "Epoch:  0016 D loss:-0.3941 G loss:-2.547\n",
      "Epoch:  0016 D loss:-0.3615 G loss:-2.526\n",
      "Epoch:  0016 D loss:-0.4352 G loss:-2.409\n",
      "Epoch:  0016 D loss:-0.4937 G loss:-2.416\n",
      "Epoch:  0016 D loss:-0.3314 G loss:-2.566\n",
      "Epoch:  0016 D loss:-0.3687 G loss:-2.414\n",
      "Epoch:  0016 D loss:-0.4391 G loss:-2.506\n",
      "Epoch:  0016 D loss:-0.4146 G loss:-2.317\n",
      "Epoch:  0016 D loss:-0.3777 G loss:-2.499\n",
      "Epoch:  0016 D loss:-0.3541 G loss:-2.419\n",
      "Epoch:  0016 D loss:-0.3978 G loss:-2.485\n",
      "Epoch:  0016 D loss:-0.3619 G loss:-2.777\n",
      "Epoch:  0016 D loss:-0.4203 G loss:-2.516\n",
      "Epoch:  0016 D loss:-0.3646 G loss:-2.692\n",
      "Epoch:  0016 D loss:-0.4047 G loss:-2.374\n",
      "Epoch:  0016 D loss:-0.3692 G loss:-2.554\n",
      "Epoch:  0016 D loss:-0.3868 G loss:-2.569\n",
      "Epoch:  0016 D loss:-0.3862 G loss:-2.472\n",
      "Epoch:  0016 D loss:-0.396 G loss:-2.695\n",
      "Epoch:  0016 D loss:-0.3082 G loss:-2.495\n",
      "Epoch:  0016 D loss:-0.375 G loss:-2.761\n",
      "Epoch:  0016 D loss:-0.3627 G loss:-2.499\n",
      "Epoch:  0016 D loss:-0.3434 G loss:-2.578\n",
      "Epoch:  0016 D loss:-0.3858 G loss:-2.505\n",
      "Epoch:  0016 D loss:-0.4173 G loss:-2.426\n",
      "Epoch:  0016 D loss:-0.381 G loss:-2.52\n",
      "Epoch:  0016 D loss:-0.4172 G loss:-2.442\n",
      "Epoch:  0016 D loss:-0.3547 G loss:-2.266\n",
      "Epoch:  0016 D loss:-0.4508 G loss:-2.36\n",
      "Epoch:  0016 D loss:-0.4064 G loss:-2.445\n",
      "Epoch:  0016 D loss:-0.4994 G loss:-2.274\n",
      "Epoch:  0016 D loss:-0.4719 G loss:-2.327\n",
      "Epoch:  0016 D loss:-0.3996 G loss:-2.389\n",
      "Epoch:  0016 D loss:-0.4922 G loss:-2.135\n",
      "Epoch:  0016 D loss:-0.5094 G loss:-2.223\n",
      "Epoch:  0016 D loss:-0.4317 G loss:-2.186\n",
      "Epoch:  0016 D loss:-0.4548 G loss:-2.27\n",
      "Epoch:  0016 D loss:-0.5387 G loss:-2.352\n",
      "Epoch:  0016 D loss:-0.4872 G loss:-2.295\n",
      "Epoch:  0016 D loss:-0.3743 G loss:-2.381\n",
      "Epoch:  0016 D loss:-0.4227 G loss:-2.37\n",
      "Epoch:  0016 D loss:-0.3936 G loss:-2.179\n",
      "Epoch:  0016 D loss:-0.3997 G loss:-2.409\n",
      "Epoch:  0016 D loss:-0.4232 G loss:-2.466\n",
      "Epoch:  0016 D loss:-0.5211 G loss:-2.575\n",
      "Epoch:  0016 D loss:-0.4693 G loss:-2.633\n",
      "Epoch:  0016 D loss:-0.5628 G loss:-2.463\n",
      "Epoch:  0016 D loss:-0.4247 G loss:-2.291\n",
      "Epoch:  0016 D loss:-0.4486 G loss:-2.418\n",
      "Epoch:  0016 D loss:-0.4327 G loss:-2.516\n",
      "Epoch:  0016 D loss:-0.4145 G loss:-2.512\n",
      "Epoch:  0016 D loss:-0.4394 G loss:-2.307\n",
      "Epoch:  0016 D loss:-0.4379 G loss:-2.31\n",
      "Epoch:  0016 D loss:-0.4795 G loss:-2.257\n",
      "Epoch:  0016 D loss:-0.4511 G loss:-2.335\n",
      "Epoch:  0016 D loss:-0.4301 G loss:-2.127\n",
      "Epoch:  0016 D loss:-0.5319 G loss:-2.064\n",
      "Epoch:  0016 D loss:-0.4132 G loss:-2.249\n",
      "Epoch:  0016 D loss:-0.4562 G loss:-2.204\n",
      "Epoch:  0016 D loss:-0.4083 G loss:-2.428\n",
      "Epoch:  0016 D loss:-0.5879 G loss:-2.39\n",
      "Epoch:  0016 D loss:-0.4465 G loss:-2.437\n",
      "Epoch:  0016 D loss:-0.4988 G loss:-2.4\n",
      "Epoch:  0016 D loss:-0.5001 G loss:-2.295\n",
      "Epoch:  0016 D loss:-0.4315 G loss:-2.241\n",
      "Epoch:  0016 D loss:-0.4408 G loss:-2.267\n",
      "Epoch:  0016 D loss:-0.4487 G loss:-2.09\n",
      "Epoch:  0016 D loss:-0.4471 G loss:-2.243\n",
      "Epoch:  0016 D loss:-0.509 G loss:-2.11\n",
      "Epoch:  0016 D loss:-0.6 G loss:-2.1\n",
      "Epoch:  0016 D loss:-0.5249 G loss:-2.2\n",
      "Epoch:  0016 D loss:-0.5972 G loss:-2.053\n",
      "Epoch:  0016 D loss:-0.4809 G loss:-2.178\n",
      "Epoch:  0016 D loss:-0.3876 G loss:-2.275\n",
      "Epoch:  0016 D loss:-0.4678 G loss:-2.106\n",
      "Epoch:  0016 D loss:-0.4969 G loss:-2.327\n",
      "Epoch:  0016 D loss:-0.5288 G loss:-2.126\n",
      "Epoch:  0016 D loss:-0.3431 G loss:-2.321\n",
      "Epoch:  0016 D loss:-0.4894 G loss:-2.403\n",
      "Epoch:  0016 D loss:-0.4796 G loss:-2.287\n",
      "Epoch:  0016 D loss:-0.4705 G loss:-2.396\n",
      "Epoch:  0016 D loss:-0.4541 G loss:-2.208\n",
      "Epoch:  0016 D loss:-0.4481 G loss:-2.252\n",
      "Epoch:  0016 D loss:-0.4404 G loss:-2.215\n",
      "Epoch:  0016 D loss:-0.3286 G loss:-2.276\n",
      "Epoch:  0016 D loss:-0.3226 G loss:-2.339\n",
      "Epoch:  0016 D loss:-0.4643 G loss:-2.268\n",
      "Epoch:  0016 D loss:-0.3732 G loss:-2.238\n",
      "Epoch:  0016 D loss:-0.4002 G loss:-2.3\n",
      "Epoch:  0016 D loss:-0.4247 G loss:-2.427\n",
      "Epoch:  0016 D loss:-0.3709 G loss:-2.425\n",
      "Epoch:  0016 D loss:-0.3775 G loss:-2.476\n",
      "Epoch:  0016 D loss:-0.344 G loss:-2.525\n",
      "Epoch:  0016 D loss:-0.3093 G loss:-2.558\n",
      "Epoch:  0016 D loss:-0.2507 G loss:-2.604\n",
      "Epoch:  0016 D loss:-0.3728 G loss:-2.439\n",
      "Epoch:  0016 D loss:-0.3727 G loss:-2.569\n",
      "Epoch:  0016 D loss:-0.293 G loss:-2.669\n",
      "Epoch:  0016 D loss:-0.2818 G loss:-2.597\n",
      "Epoch:  0016 D loss:-0.4852 G loss:-2.543\n",
      "Epoch:  0016 D loss:-0.3539 G loss:-2.593\n",
      "Epoch:  0016 D loss:-0.3002 G loss:-2.643\n",
      "Epoch:  0016 D loss:-0.306 G loss:-2.657\n",
      "Epoch:  0016 D loss:-0.3824 G loss:-2.666\n",
      "Epoch:  0016 D loss:-0.2801 G loss:-2.458\n",
      "Epoch:  0016 D loss:-0.3907 G loss:-2.46\n",
      "Epoch:  0016 D loss:-0.3993 G loss:-2.462\n",
      "Epoch:  0016 D loss:-0.3755 G loss:-2.491\n",
      "Epoch:  0016 D loss:-0.3044 G loss:-2.481\n",
      "Epoch:  0016 D loss:-0.355 G loss:-2.32\n",
      "Epoch:  0016 D loss:-0.3152 G loss:-2.557\n",
      "Epoch:  0016 D loss:-0.3762 G loss:-2.292\n",
      "Epoch:  0016 D loss:-0.314 G loss:-2.561\n",
      "Epoch:  0016 D loss:-0.3505 G loss:-2.291\n",
      "Epoch:  0016 D loss:-0.3381 G loss:-2.614\n",
      "Epoch:  0016 D loss:-0.3454 G loss:-2.629\n",
      "Epoch:  0016 D loss:-0.3508 G loss:-2.52\n",
      "Epoch:  0016 D loss:-0.3154 G loss:-2.529\n",
      "Epoch:  0016 D loss:-0.3631 G loss:-2.627\n",
      "Epoch:  0016 D loss:-0.324 G loss:-2.717\n",
      "Epoch:  0016 D loss:-0.3266 G loss:-2.557\n",
      "Epoch:  0016 D loss:-0.3806 G loss:-2.437\n",
      "Epoch:  0016 D loss:-0.3605 G loss:-2.602\n",
      "Epoch:  0016 D loss:-0.4037 G loss:-2.504\n",
      "Epoch:  0016 D loss:-0.3417 G loss:-2.546\n",
      "Epoch:  0016 D loss:-0.3938 G loss:-2.378\n",
      "Epoch:  0016 D loss:-0.4259 G loss:-2.417\n",
      "Epoch:  0016 D loss:-0.3471 G loss:-2.31\n",
      "Epoch:  0016 D loss:-0.3461 G loss:-2.381\n",
      "Epoch:  0016 D loss:-0.3247 G loss:-2.494\n",
      "Epoch:  0016 D loss:-0.418 G loss:-2.431\n",
      "Epoch:  0016 D loss:-0.387 G loss:-2.6\n",
      "Epoch:  0016 D loss:-0.269 G loss:-2.506\n",
      "Epoch:  0016 D loss:-0.4282 G loss:-2.52\n",
      "Epoch:  0016 D loss:-0.3967 G loss:-2.546\n",
      "Epoch:  0016 D loss:-0.4796 G loss:-2.558\n",
      "Epoch:  0016 D loss:-0.3565 G loss:-2.62\n",
      "Epoch:  0016 D loss:-0.3371 G loss:-2.401\n",
      "Epoch:  0016 D loss:-0.3539 G loss:-2.387\n",
      "Epoch:  0016 D loss:-0.2949 G loss:-2.619\n",
      "Epoch:  0016 D loss:-0.3459 G loss:-2.544\n",
      "Epoch:  0016 D loss:-0.3215 G loss:-2.537\n",
      "Epoch:  0016 D loss:-0.3121 G loss:-2.501\n",
      "Epoch:  0016 D loss:-0.3701 G loss:-2.402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0016 D loss:-0.3479 G loss:-2.587\n",
      "Epoch:  0016 D loss:-0.32 G loss:-2.538\n",
      "Epoch:  0016 D loss:-0.3536 G loss:-2.585\n",
      "Epoch:  0016 D loss:-0.3384 G loss:-2.596\n",
      "Epoch:  0016 D loss:-0.3081 G loss:-2.716\n",
      "Epoch:  0016 D loss:-0.285 G loss:-2.627\n",
      "Epoch:  0016 D loss:-0.4084 G loss:-2.57\n",
      "Epoch:  0016 D loss:-0.2973 G loss:-2.68\n",
      "Epoch:  0016 D loss:-0.3382 G loss:-2.769\n",
      "Epoch:  0016 D loss:-0.3733 G loss:-2.783\n",
      "Epoch:  0016 D loss:-0.3405 G loss:-2.532\n",
      "Epoch:  0016 D loss:-0.3946 G loss:-2.545\n",
      "Epoch:  0016 D loss:-0.3092 G loss:-2.478\n",
      "Epoch:  0016 D loss:-0.366 G loss:-2.368\n",
      "Epoch:  0016 D loss:-0.3076 G loss:-2.331\n",
      "Epoch:  0016 D loss:-0.4103 G loss:-2.336\n",
      "Epoch:  0016 D loss:-0.4669 G loss:-2.348\n",
      "Epoch:  0016 D loss:-0.3262 G loss:-2.461\n",
      "Epoch:  0016 D loss:-0.3469 G loss:-2.427\n",
      "Epoch:  0016 D loss:-0.5167 G loss:-2.27\n",
      "Epoch:  0016 D loss:-0.3754 G loss:-2.548\n",
      "Epoch:  0016 D loss:-0.3431 G loss:-2.522\n",
      "Epoch:  0016 D loss:-0.441 G loss:-2.534\n",
      "Epoch:  0016 D loss:-0.2706 G loss:-2.593\n",
      "Epoch:  0016 D loss:-0.3827 G loss:-2.379\n",
      "Epoch:  0016 D loss:-0.4377 G loss:-2.306\n",
      "Epoch:  0016 D loss:-0.3393 G loss:-2.344\n",
      "Epoch:  0016 D loss:-0.3214 G loss:-2.367\n",
      "Epoch:  0016 D loss:-0.3442 G loss:-2.49\n",
      "Epoch:  0016 D loss:-0.3883 G loss:-2.545\n",
      "Epoch:  0016 D loss:-0.4452 G loss:-2.332\n",
      "Epoch:  0016 D loss:-0.4037 G loss:-2.443\n",
      "Epoch:  0016 D loss:-0.4036 G loss:-2.431\n",
      "Epoch:  0016 D loss:-0.3718 G loss:-2.544\n",
      "Epoch:  0016 D loss:-0.3457 G loss:-2.55\n",
      "Epoch:  0016 D loss:-0.3608 G loss:-2.453\n",
      "Epoch:  0016 D loss:-0.3203 G loss:-2.612\n",
      "Epoch:  0016 D loss:-0.5168 G loss:-2.252\n",
      "Epoch:  0016 D loss:-0.3614 G loss:-2.503\n",
      "Epoch:  0016 D loss:-0.4232 G loss:-2.227\n",
      "Epoch:  0016 D loss:-0.3809 G loss:-2.412\n",
      "Epoch:  0016 D loss:-0.405 G loss:-2.235\n",
      "Epoch:  0016 D loss:-0.3738 G loss:-2.207\n",
      "Epoch:  0016 D loss:-0.3918 G loss:-2.109\n",
      "Epoch:  0016 D loss:-0.3995 G loss:-2.264\n",
      "Epoch:  0016 D loss:-0.3677 G loss:-2.179\n",
      "Epoch:  0016 D loss:-0.3489 G loss:-2.485\n",
      "Epoch:  0016 D loss:-0.3937 G loss:-2.3\n",
      "Epoch:  0016 D loss:-0.4223 G loss:-2.369\n",
      "Epoch:  0016 D loss:-0.4098 G loss:-2.462\n",
      "Epoch:  0016 D loss:-0.4436 G loss:-2.504\n",
      "Epoch:  0016 D loss:-0.3771 G loss:-2.353\n",
      "Epoch:  0016 D loss:-0.4121 G loss:-2.439\n",
      "Epoch:  0016 D loss:-0.408 G loss:-2.391\n",
      "Epoch:  0016 D loss:-0.3934 G loss:-2.416\n",
      "Epoch:  0016 D loss:-0.3759 G loss:-2.266\n",
      "Epoch:  0016 D loss:-0.5028 G loss:-2.336\n",
      "Epoch:  0016 D loss:-0.4268 G loss:-2.195\n",
      "Epoch:  0016 D loss:-0.4302 G loss:-2.187\n",
      "Epoch:  0016 D loss:-0.3411 G loss:-2.342\n",
      "Epoch:  0016 D loss:-0.3819 G loss:-2.285\n",
      "Epoch:  0016 D loss:-0.4236 G loss:-2.512\n",
      "Epoch:  0016 D loss:-0.3838 G loss:-2.409\n",
      "Epoch:  0016 D loss:-0.3671 G loss:-2.378\n",
      "Epoch:  0016 D loss:-0.4409 G loss:-2.48\n",
      "Epoch:  0016 D loss:-0.3798 G loss:-2.44\n",
      "Epoch:  0016 D loss:-0.3521 G loss:-2.484\n",
      "Epoch:  0016 D loss:-0.3456 G loss:-2.362\n",
      "Epoch:  0016 D loss:-0.4177 G loss:-2.543\n",
      "Epoch:  0016 D loss:-0.4534 G loss:-2.22\n",
      "Epoch:  0016 D loss:-0.3722 G loss:-2.299\n",
      "Epoch:  0016 D loss:-0.5285 G loss:-2.282\n",
      "Epoch:  0016 D loss:-0.3825 G loss:-2.367\n",
      "Epoch:  0016 D loss:-0.3914 G loss:-2.394\n",
      "Epoch:  0016 D loss:-0.4349 G loss:-2.176\n",
      "Epoch:  0016 D loss:-0.3747 G loss:-2.201\n",
      "Epoch:  0016 D loss:-0.3859 G loss:-2.256\n",
      "Epoch:  0016 D loss:-0.5713 G loss:-2.046\n",
      "Epoch:  0016 D loss:-0.4972 G loss:-2.268\n",
      "Epoch:  0016 D loss:-0.4263 G loss:-2.356\n",
      "Epoch:  0016 D loss:-0.4211 G loss:-2.299\n",
      "Epoch:  0016 D loss:-0.457 G loss:-2.222\n",
      "Epoch:  0016 D loss:-0.368 G loss:-2.399\n",
      "Epoch:  0016 D loss:-0.3844 G loss:-2.471\n",
      "Epoch:  0016 D loss:-0.4549 G loss:-2.147\n",
      "Epoch:  0016 D loss:-0.438 G loss:-2.311\n",
      "Epoch:  0016 D loss:-0.4884 G loss:-2.29\n",
      "Epoch:  0016 D loss:-0.3965 G loss:-2.539\n",
      "Epoch:  0016 D loss:-0.4515 G loss:-2.459\n",
      "Epoch:  0016 D loss:-0.414 G loss:-2.381\n",
      "Epoch:  0016 D loss:-0.3815 G loss:-2.443\n",
      "Epoch:  0016 D loss:-0.4553 G loss:-2.469\n",
      "Epoch:  0016 D loss:-0.4575 G loss:-2.367\n",
      "Epoch:  0016 D loss:-0.3669 G loss:-2.463\n",
      "Epoch:  0016 D loss:-0.4454 G loss:-2.384\n",
      "Epoch:  0016 D loss:-0.4564 G loss:-2.344\n",
      "Epoch:  0016 D loss:-0.4098 G loss:-2.33\n",
      "Epoch:  0016 D loss:-0.5766 G loss:-2.214\n",
      "Epoch:  0016 D loss:-0.3288 G loss:-2.338\n",
      "Epoch:  0016 D loss:-0.3196 G loss:-2.264\n",
      "Epoch:  0016 D loss:-0.4541 G loss:-2.103\n",
      "Epoch:  0016 D loss:-0.3701 G loss:-2.195\n",
      "Epoch:  0016 D loss:-0.4353 G loss:-2.316\n",
      "Epoch:  0016 D loss:-0.425 G loss:-2.418\n",
      "Epoch:  0016 D loss:-0.4273 G loss:-2.301\n",
      "Epoch:  0016 D loss:-0.4714 G loss:-2.277\n",
      "Epoch:  0016 D loss:-0.586 G loss:-2.335\n",
      "Epoch:  0016 D loss:-0.4189 G loss:-2.4\n",
      "Epoch:  0016 D loss:-0.5424 G loss:-2.401\n",
      "Epoch:  0016 D loss:-0.5211 G loss:-2.403\n",
      "Epoch:  0016 D loss:-0.574 G loss:-2.165\n",
      "Epoch:  0016 D loss:-0.418 G loss:-2.344\n",
      "Epoch:  0016 D loss:-0.4063 G loss:-2.414\n",
      "Epoch:  0016 D loss:-0.4969 G loss:-2.25\n",
      "Epoch:  0016 D loss:-0.5715 G loss:-2.285\n",
      "Epoch:  0016 D loss:-0.4433 G loss:-2.189\n",
      "Epoch:  0016 D loss:-0.5495 G loss:-2.056\n",
      "Epoch:  0016 D loss:-0.464 G loss:-1.957\n",
      "Epoch:  0016 D loss:-0.602 G loss:-2.041\n",
      "Epoch:  0016 D loss:-0.4635 G loss:-2.141\n",
      "Epoch:  0016 D loss:-0.4502 G loss:-2.158\n",
      "Epoch:  0016 D loss:-0.5021 G loss:-2.381\n",
      "Epoch:  0016 D loss:-0.4586 G loss:-2.291\n",
      "Epoch:  0016 D loss:-0.4534 G loss:-2.311\n",
      "Epoch:  0016 D loss:-0.4853 G loss:-2.526\n",
      "Epoch:  0016 D loss:-0.4926 G loss:-2.371\n",
      "Epoch:  0016 D loss:-0.4585 G loss:-2.611\n",
      "Epoch:  0016 D loss:-0.4694 G loss:-2.471\n",
      "Epoch:  0016 D loss:-0.4365 G loss:-2.421\n",
      "Epoch:  0016 D loss:-0.4359 G loss:-2.519\n",
      "Epoch:  0016 D loss:-0.4143 G loss:-2.504\n",
      "Epoch:  0016 D loss:-0.3533 G loss:-2.561\n",
      "Epoch:  0016 D loss:-0.4227 G loss:-2.383\n",
      "Epoch:  0016 D loss:-0.4049 G loss:-2.368\n",
      "Epoch:  0016 D loss:-0.3956 G loss:-2.436\n",
      "Epoch:  0016 D loss:-0.4197 G loss:-2.387\n",
      "Epoch:  0016 D loss:-0.3379 G loss:-2.33\n",
      "Epoch:  0016 D loss:-0.5315 G loss:-2.329\n",
      "Epoch:  0016 D loss:-0.4727 G loss:-2.389\n",
      "Epoch:  0016 D loss:-0.4971 G loss:-2.437\n",
      "Epoch:  0016 D loss:-0.399 G loss:-2.422\n",
      "Epoch:  0016 D loss:-0.3668 G loss:-2.41\n",
      "Epoch:  0016 D loss:-0.4586 G loss:-2.523\n",
      "Epoch:  0016 D loss:-0.3706 G loss:-2.598\n",
      "Epoch:  0016 D loss:-0.3628 G loss:-2.504\n",
      "Epoch:  0016 D loss:-0.3565 G loss:-2.461\n",
      "Epoch:  0016 D loss:-0.4155 G loss:-2.503\n",
      "Epoch:  0016 D loss:-0.4558 G loss:-2.526\n",
      "Epoch:  0016 D loss:-0.4516 G loss:-2.369\n",
      "Epoch:  0016 D loss:-0.3831 G loss:-2.507\n",
      "Epoch:  0016 D loss:-0.3979 G loss:-2.381\n",
      "Epoch:  0016 D loss:-0.4248 G loss:-2.326\n",
      "Epoch:  0016 D loss:-0.4518 G loss:-2.262\n",
      "Epoch:  0016 D loss:-0.4229 G loss:-2.294\n",
      "Epoch:  0016 D loss:-0.4195 G loss:-2.144\n",
      "Epoch:  0016 D loss:-0.3896 G loss:-2.422\n",
      "Epoch:  0016 D loss:-0.4844 G loss:-2.431\n",
      "Epoch:  0016 D loss:-0.4712 G loss:-2.411\n",
      "Epoch:  0016 D loss:-0.4119 G loss:-2.405\n",
      "Epoch:  0016 D loss:-0.3992 G loss:-2.471\n",
      "Epoch:  0016 D loss:-0.35 G loss:-2.535\n",
      "Epoch:  0016 D loss:-0.4088 G loss:-2.452\n",
      "Epoch:  0016 D loss:-0.4027 G loss:-2.61\n",
      "Epoch:  0016 D loss:-0.5222 G loss:-2.392\n",
      "Epoch:  0016 D loss:-0.4177 G loss:-2.526\n",
      "Epoch:  0016 D loss:-0.4298 G loss:-2.3\n",
      "Epoch:  0016 D loss:-0.3878 G loss:-2.355\n",
      "Epoch:  0016 D loss:-0.3382 G loss:-2.452\n",
      "Epoch:  0016 D loss:-0.4254 G loss:-2.301\n",
      "Epoch:  0016 D loss:-0.4647 G loss:-2.084\n",
      "Epoch:  0016 D loss:-0.3583 G loss:-2.253\n",
      "Epoch:  0016 D loss:-0.3039 G loss:-2.311\n",
      "Epoch:  0016 D loss:-0.3713 G loss:-2.422\n",
      "Epoch:  0016 D loss:-0.3611 G loss:-2.536\n",
      "Epoch:  0016 D loss:-0.351 G loss:-2.64\n",
      "Epoch:  0016 D loss:-0.3257 G loss:-2.6\n",
      "Epoch:  0016 D loss:-0.3962 G loss:-2.638\n",
      "Epoch:  0016 D loss:-0.3122 G loss:-2.713\n",
      "Epoch:  0016 D loss:-0.4068 G loss:-2.598\n",
      "Epoch:  0016 D loss:-0.4206 G loss:-2.471\n",
      "Epoch:  0016 D loss:-0.3907 G loss:-2.594\n",
      "Epoch:  0016 D loss:-0.3261 G loss:-2.601\n",
      "Epoch:  0016 D loss:-0.3616 G loss:-2.492\n",
      "Epoch:  0016 D loss:-0.3993 G loss:-2.42\n",
      "Epoch:  0016 D loss:-0.3625 G loss:-2.477\n",
      "Epoch:  0016 D loss:-0.3801 G loss:-2.363\n",
      "Epoch:  0016 D loss:-0.4215 G loss:-2.409\n",
      "Epoch:  0016 D loss:-0.3506 G loss:-2.431\n",
      "Epoch:  0016 D loss:-0.3608 G loss:-2.432\n",
      "Epoch:  0016 D loss:-0.3216 G loss:-2.434\n",
      "Epoch:  0016 D loss:-0.3473 G loss:-2.458\n",
      "Epoch:  0016 D loss:-0.3108 G loss:-2.547\n",
      "Epoch:  0016 D loss:-0.3397 G loss:-2.495\n",
      "Epoch:  0016 D loss:-0.4204 G loss:-2.363\n",
      "Epoch:  0016 D loss:-0.3469 G loss:-2.471\n",
      "Epoch:  0016 D loss:-0.4314 G loss:-2.443\n",
      "Epoch:  0016 D loss:-0.4104 G loss:-2.461\n",
      "Epoch:  0016 D loss:-0.4156 G loss:-2.317\n",
      "Epoch:  0016 D loss:-0.5169 G loss:-2.519\n",
      "Epoch:  0016 D loss:-0.3736 G loss:-2.547\n",
      "Epoch:  0016 D loss:-0.3682 G loss:-2.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0016 D loss:-0.5085 G loss:-2.435\n",
      "Epoch:  0016 D loss:-0.3201 G loss:-2.585\n",
      "Epoch:  0016 D loss:-0.3971 G loss:-2.366\n",
      "Epoch:  0016 D loss:-0.4028 G loss:-2.238\n",
      "Epoch:  0016 D loss:-0.3795 G loss:-2.31\n",
      "Epoch:  0016 D loss:-0.3105 G loss:-2.371\n",
      "Epoch:  0016 D loss:-0.3736 G loss:-2.317\n",
      "Epoch:  0016 D loss:-0.4055 G loss:-2.236\n",
      "Epoch:  0016 D loss:-0.4755 G loss:-2.471\n",
      "Epoch:  0016 D loss:-0.4189 G loss:-2.282\n",
      "Epoch:  0016 D loss:-0.4305 G loss:-2.387\n",
      "Epoch:  0016 D loss:-0.3757 G loss:-2.433\n",
      "Epoch:  0016 D loss:-0.4181 G loss:-2.466\n",
      "Epoch:  0016 D loss:-0.4856 G loss:-2.341\n",
      "Epoch:  0016 D loss:-0.3285 G loss:-2.558\n",
      "Epoch:  0016 D loss:-0.3712 G loss:-2.436\n",
      "Epoch:  0016 D loss:-0.4081 G loss:-2.443\n",
      "Epoch:  0016 D loss:-0.3462 G loss:-2.552\n",
      "Epoch:  0016 D loss:-0.3742 G loss:-2.58\n",
      "Epoch:  0016 D loss:-0.4257 G loss:-2.562\n",
      "Epoch:  0016 D loss:-0.391 G loss:-2.258\n",
      "Epoch:  0016 D loss:-0.3795 G loss:-2.387\n",
      "Epoch:  0016 D loss:-0.4301 G loss:-2.527\n",
      "Epoch:  0016 D loss:-0.4224 G loss:-2.29\n",
      "Epoch:  0016 D loss:-0.4178 G loss:-2.232\n",
      "Epoch:  0016 D loss:-0.4791 G loss:-2.166\n",
      "Epoch:  0016 D loss:-0.5404 G loss:-2.194\n",
      "Epoch:  0016 D loss:-0.5391 G loss:-2.172\n",
      "Epoch:  0016 D loss:-0.4807 G loss:-2.157\n",
      "Epoch:  0016 D loss:-0.3986 G loss:-2.37\n",
      "Epoch:  0016 D loss:-0.5713 G loss:-2.143\n",
      "Epoch:  0016 D loss:-0.4936 G loss:-2.383\n",
      "Epoch:  0016 D loss:-0.4518 G loss:-2.226\n",
      "Epoch:  0016 D loss:-0.3591 G loss:-2.302\n",
      "Epoch:  0016 D loss:-0.467 G loss:-2.106\n",
      "Epoch:  0016 D loss:-0.4205 G loss:-2.294\n",
      "Epoch:  0016 D loss:-0.4525 G loss:-2.406\n",
      "Epoch:  0016 D loss:-0.3678 G loss:-2.417\n",
      "Epoch:  0016 D loss:-0.3879 G loss:-2.495\n",
      "Epoch:  0016 D loss:-0.4043 G loss:-2.39\n",
      "Epoch:  0016 D loss:-0.4808 G loss:-2.502\n",
      "Epoch:  0016 D loss:-0.4386 G loss:-2.602\n",
      "Epoch:  0016 D loss:-0.4415 G loss:-2.544\n",
      "Epoch:  0016 D loss:-0.3485 G loss:-2.573\n",
      "Epoch:  0016 D loss:-0.4338 G loss:-2.369\n",
      "Epoch:  0016 D loss:-0.4365 G loss:-2.482\n",
      "Epoch:  0016 D loss:-0.4526 G loss:-2.343\n",
      "Epoch:  0016 D loss:-0.4105 G loss:-2.395\n",
      "Epoch:  0016 D loss:-0.4159 G loss:-2.228\n",
      "Epoch:  0016 D loss:-0.4116 G loss:-2.218\n",
      "Epoch:  0016 D loss:-0.464 G loss:-2.228\n",
      "Epoch:  0016 D loss:-0.4596 G loss:-2.2\n",
      "Epoch:  0016 D loss:-0.3733 G loss:-2.189\n",
      "Epoch:  0016 D loss:-0.5365 G loss:-2.087\n",
      "Epoch:  0016 D loss:-0.4274 G loss:-2.095\n",
      "Epoch:  0016 D loss:-0.4179 G loss:-2.1\n",
      "Epoch:  0016 D loss:-0.3925 G loss:-2.229\n",
      "Epoch:  0016 D loss:-0.3948 G loss:-2.39\n",
      "Epoch:  0016 D loss:-0.4663 G loss:-2.35\n",
      "Epoch:  0016 D loss:-0.3862 G loss:-2.395\n",
      "Epoch:  0016 D loss:-0.4244 G loss:-2.352\n",
      "Epoch:  0016 D loss:-0.4798 G loss:-2.387\n",
      "Epoch:  0016 D loss:-0.4132 G loss:-2.398\n",
      "Epoch:  0016 D loss:-0.4415 G loss:-2.23\n",
      "Epoch:  0016 D loss:-0.4999 G loss:-2.2\n",
      "Epoch:  0016 D loss:-0.3878 G loss:-2.396\n",
      "Epoch:  0016 D loss:-0.4189 G loss:-2.282\n",
      "Epoch:  0016 D loss:-0.3769 G loss:-2.438\n",
      "Epoch:  0016 D loss:-0.3939 G loss:-2.305\n",
      "Epoch:  0016 D loss:-0.4377 G loss:-2.514\n",
      "Epoch:  0016 D loss:-0.3838 G loss:-2.426\n",
      "Epoch:  0016 D loss:-0.4479 G loss:-2.357\n",
      "Epoch:  0016 D loss:-0.4738 G loss:-2.325\n",
      "Epoch:  0016 D loss:-0.3748 G loss:-2.401\n",
      "Epoch:  0016 D loss:-0.4123 G loss:-2.408\n",
      "Epoch:  0016 D loss:-0.3557 G loss:-2.405\n",
      "Epoch:  0016 D loss:-0.4667 G loss:-2.181\n",
      "Epoch:  0016 D loss:-0.3924 G loss:-2.195\n",
      "Epoch:  0016 D loss:-0.4976 G loss:-2.189\n",
      "Epoch:  0016 D loss:-0.349 G loss:-2.541\n",
      "Epoch:  0016 D loss:-0.3917 G loss:-2.254\n",
      "Epoch:  0016 D loss:-0.4768 G loss:-2.138\n",
      "Epoch:  0016 D loss:-0.4127 G loss:-2.336\n",
      "Epoch:  0016 D loss:-0.4049 G loss:-2.434\n",
      "Epoch:  0016 D loss:-0.4873 G loss:-2.394\n",
      "Epoch:  0016 D loss:-0.4045 G loss:-2.429\n",
      "Epoch:  0016 D loss:-0.3804 G loss:-2.362\n",
      "Epoch:  0016 D loss:-0.4142 G loss:-2.394\n",
      "Epoch:  0016 D loss:-0.4505 G loss:-2.455\n",
      "Epoch:  0016 D loss:-0.3957 G loss:-2.34\n",
      "Epoch:  0016 D loss:-0.4426 G loss:-2.376\n",
      "Epoch:  0016 D loss:-0.3767 G loss:-2.314\n",
      "Epoch:  0016 D loss:-0.3952 G loss:-2.387\n",
      "Epoch:  0016 D loss:-0.4568 G loss:-2.182\n",
      "Epoch:  0016 D loss:-0.3423 G loss:-2.373\n",
      "Epoch:  0016 D loss:-0.3816 G loss:-2.293\n",
      "Epoch:  0016 D loss:-0.3937 G loss:-2.394\n",
      "Epoch:  0016 D loss:-0.3269 G loss:-2.385\n",
      "Epoch:  0016 D loss:-0.4743 G loss:-2.163\n",
      "Epoch:  0016 D loss:-0.3624 G loss:-2.258\n",
      "Epoch:  0016 D loss:-0.3443 G loss:-2.508\n",
      "Epoch:  0016 D loss:-0.394 G loss:-2.315\n",
      "Epoch:  0016 D loss:-0.4052 G loss:-2.272\n",
      "Epoch:  0016 D loss:-0.3859 G loss:-2.541\n",
      "Epoch:  0016 D loss:-0.4223 G loss:-2.55\n",
      "Epoch:  0016 D loss:-0.3106 G loss:-2.632\n",
      "Epoch:  0016 D loss:-0.3654 G loss:-2.333\n",
      "Epoch:  0016 D loss:-0.3792 G loss:-2.518\n",
      "Epoch:  0016 D loss:-0.4251 G loss:-2.403\n",
      "Epoch:  0016 D loss:-0.4998 G loss:-2.282\n",
      "Epoch:  0016 D loss:-0.3373 G loss:-2.479\n",
      "Epoch:  0016 D loss:-0.4088 G loss:-2.267\n",
      "Epoch:  0016 D loss:-0.4048 G loss:-2.337\n",
      "Epoch:  0016 D loss:-0.3711 G loss:-2.405\n",
      "Epoch:  0016 D loss:-0.3409 G loss:-2.277\n",
      "Epoch:  0016 D loss:-0.4772 G loss:-2.218\n",
      "Epoch:  0016 D loss:-0.4999 G loss:-2.107\n",
      "Epoch:  0016 D loss:-0.3255 G loss:-2.36\n",
      "Epoch:  0016 D loss:-0.4426 G loss:-2.379\n",
      "Epoch:  0016 D loss:-0.4676 G loss:-2.273\n",
      "Epoch:  0016 D loss:-0.3808 G loss:-2.366\n",
      "Epoch:  0016 D loss:-0.4092 G loss:-2.371\n",
      "Epoch:  0016 D loss:-0.401 G loss:-2.364\n",
      "Epoch:  0016 D loss:-0.3253 G loss:-2.447\n",
      "Epoch:  0017 D loss:-0.3898 G loss:-2.382\n",
      "Epoch:  0017 D loss:-0.4456 G loss:-2.366\n",
      "Epoch:  0017 D loss:-0.4095 G loss:-2.554\n",
      "Epoch:  0017 D loss:-0.3504 G loss:-2.405\n",
      "Epoch:  0017 D loss:-0.3316 G loss:-2.468\n",
      "Epoch:  0017 D loss:-0.4625 G loss:-2.308\n",
      "Epoch:  0017 D loss:-0.3922 G loss:-2.283\n",
      "Epoch:  0017 D loss:-0.3768 G loss:-2.397\n",
      "Epoch:  0017 D loss:-0.402 G loss:-2.391\n",
      "Epoch:  0017 D loss:-0.393 G loss:-2.338\n",
      "Epoch:  0017 D loss:-0.4393 G loss:-2.283\n",
      "Epoch:  0017 D loss:-0.3796 G loss:-2.278\n",
      "Epoch:  0017 D loss:-0.4546 G loss:-2.3\n",
      "Epoch:  0017 D loss:-0.4402 G loss:-2.373\n",
      "Epoch:  0017 D loss:-0.4944 G loss:-2.139\n",
      "Epoch:  0017 D loss:-0.4012 G loss:-2.324\n",
      "Epoch:  0017 D loss:-0.4531 G loss:-2.229\n",
      "Epoch:  0017 D loss:-0.3993 G loss:-2.283\n",
      "Epoch:  0017 D loss:-0.46 G loss:-2.403\n",
      "Epoch:  0017 D loss:-0.458 G loss:-2.248\n",
      "Epoch:  0017 D loss:-0.4442 G loss:-2.22\n",
      "Epoch:  0017 D loss:-0.5253 G loss:-2.172\n",
      "Epoch:  0017 D loss:-0.4624 G loss:-2.011\n",
      "Epoch:  0017 D loss:-0.4034 G loss:-2.188\n",
      "Epoch:  0017 D loss:-0.4293 G loss:-2.141\n",
      "Epoch:  0017 D loss:-0.4361 G loss:-2.268\n",
      "Epoch:  0017 D loss:-0.3817 G loss:-2.173\n",
      "Epoch:  0017 D loss:-0.4645 G loss:-2.185\n",
      "Epoch:  0017 D loss:-0.4628 G loss:-2.184\n",
      "Epoch:  0017 D loss:-0.4432 G loss:-2.171\n",
      "Epoch:  0017 D loss:-0.4192 G loss:-2.298\n",
      "Epoch:  0017 D loss:-0.4568 G loss:-2.252\n",
      "Epoch:  0017 D loss:-0.4343 G loss:-2.361\n",
      "Epoch:  0017 D loss:-0.4874 G loss:-2.173\n",
      "Epoch:  0017 D loss:-0.5183 G loss:-2.102\n",
      "Epoch:  0017 D loss:-0.5889 G loss:-2.101\n",
      "Epoch:  0017 D loss:-0.4092 G loss:-2.213\n",
      "Epoch:  0017 D loss:-0.4333 G loss:-2.129\n",
      "Epoch:  0017 D loss:-0.4402 G loss:-2.103\n",
      "Epoch:  0017 D loss:-0.4667 G loss:-2.09\n",
      "Epoch:  0017 D loss:-0.3951 G loss:-2.246\n",
      "Epoch:  0017 D loss:-0.4384 G loss:-2.152\n",
      "Epoch:  0017 D loss:-0.4361 G loss:-2.128\n",
      "Epoch:  0017 D loss:-0.3887 G loss:-2.166\n",
      "Epoch:  0017 D loss:-0.4085 G loss:-2.132\n",
      "Epoch:  0017 D loss:-0.4382 G loss:-2.431\n",
      "Epoch:  0017 D loss:-0.3976 G loss:-2.274\n",
      "Epoch:  0017 D loss:-0.4613 G loss:-2.254\n",
      "Epoch:  0017 D loss:-0.4182 G loss:-2.304\n",
      "Epoch:  0017 D loss:-0.4169 G loss:-2.27\n",
      "Epoch:  0017 D loss:-0.4328 G loss:-2.39\n",
      "Epoch:  0017 D loss:-0.4794 G loss:-2.158\n",
      "Epoch:  0017 D loss:-0.5102 G loss:-2.115\n",
      "Epoch:  0017 D loss:-0.4062 G loss:-2.11\n",
      "Epoch:  0017 D loss:-0.484 G loss:-2.256\n",
      "Epoch:  0017 D loss:-0.4596 G loss:-2.019\n",
      "Epoch:  0017 D loss:-0.3983 G loss:-2.074\n",
      "Epoch:  0017 D loss:-0.3707 G loss:-2.029\n",
      "Epoch:  0017 D loss:-0.4938 G loss:-2.219\n",
      "Epoch:  0017 D loss:-0.4733 G loss:-2.247\n",
      "Epoch:  0017 D loss:-0.4299 G loss:-2.143\n",
      "Epoch:  0017 D loss:-0.4734 G loss:-2.281\n",
      "Epoch:  0017 D loss:-0.42 G loss:-2.319\n",
      "Epoch:  0017 D loss:-0.4374 G loss:-2.321\n",
      "Epoch:  0017 D loss:-0.2992 G loss:-2.552\n",
      "Epoch:  0017 D loss:-0.4768 G loss:-2.424\n",
      "Epoch:  0017 D loss:-0.5734 G loss:-2.273\n",
      "Epoch:  0017 D loss:-0.4357 G loss:-2.165\n",
      "Epoch:  0017 D loss:-0.3482 G loss:-2.391\n",
      "Epoch:  0017 D loss:-0.4046 G loss:-2.202\n",
      "Epoch:  0017 D loss:-0.3928 G loss:-2.228\n",
      "Epoch:  0017 D loss:-0.4356 G loss:-2.122\n",
      "Epoch:  0017 D loss:-0.3326 G loss:-2.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0017 D loss:-0.429 G loss:-2.285\n",
      "Epoch:  0017 D loss:-0.4725 G loss:-2.384\n",
      "Epoch:  0017 D loss:-0.4197 G loss:-2.266\n",
      "Epoch:  0017 D loss:-0.4531 G loss:-2.197\n",
      "Epoch:  0017 D loss:-0.5452 G loss:-2.138\n",
      "Epoch:  0017 D loss:-0.471 G loss:-2.297\n",
      "Epoch:  0017 D loss:-0.5328 G loss:-2.095\n",
      "Epoch:  0017 D loss:-0.4806 G loss:-2.116\n",
      "Epoch:  0017 D loss:-0.4912 G loss:-1.988\n",
      "Epoch:  0017 D loss:-0.4781 G loss:-2.15\n",
      "Epoch:  0017 D loss:-0.3839 G loss:-2.125\n",
      "Epoch:  0017 D loss:-0.4251 G loss:-1.969\n",
      "Epoch:  0017 D loss:-0.5576 G loss:-2.14\n",
      "Epoch:  0017 D loss:-0.3671 G loss:-2.208\n",
      "Epoch:  0017 D loss:-0.5259 G loss:-2.267\n",
      "Epoch:  0017 D loss:-0.5648 G loss:-2.27\n",
      "Epoch:  0017 D loss:-0.4381 G loss:-2.279\n",
      "Epoch:  0017 D loss:-0.4193 G loss:-2.457\n",
      "Epoch:  0017 D loss:-0.4168 G loss:-2.37\n",
      "Epoch:  0017 D loss:-0.4335 G loss:-2.417\n",
      "Epoch:  0017 D loss:-0.4425 G loss:-2.344\n",
      "Epoch:  0017 D loss:-0.5469 G loss:-2.166\n",
      "Epoch:  0017 D loss:-0.4537 G loss:-2.203\n",
      "Epoch:  0017 D loss:-0.449 G loss:-2.162\n",
      "Epoch:  0017 D loss:-0.4577 G loss:-2.218\n",
      "Epoch:  0017 D loss:-0.4434 G loss:-2.102\n",
      "Epoch:  0017 D loss:-0.4506 G loss:-2.203\n",
      "Epoch:  0017 D loss:-0.4232 G loss:-2.17\n",
      "Epoch:  0017 D loss:-0.388 G loss:-2.118\n",
      "Epoch:  0017 D loss:-0.4395 G loss:-2.146\n",
      "Epoch:  0017 D loss:-0.4492 G loss:-2.215\n",
      "Epoch:  0017 D loss:-0.4151 G loss:-2.389\n",
      "Epoch:  0017 D loss:-0.3614 G loss:-2.352\n",
      "Epoch:  0017 D loss:-0.4334 G loss:-2.324\n",
      "Epoch:  0017 D loss:-0.4419 G loss:-2.335\n",
      "Epoch:  0017 D loss:-0.4433 G loss:-2.299\n",
      "Epoch:  0017 D loss:-0.4081 G loss:-2.23\n",
      "Epoch:  0017 D loss:-0.3638 G loss:-2.226\n",
      "Epoch:  0017 D loss:-0.4207 G loss:-2.258\n",
      "Epoch:  0017 D loss:-0.4779 G loss:-2.258\n",
      "Epoch:  0017 D loss:-0.4417 G loss:-2.265\n",
      "Epoch:  0017 D loss:-0.3453 G loss:-2.44\n",
      "Epoch:  0017 D loss:-0.431 G loss:-2.427\n",
      "Epoch:  0017 D loss:-0.3816 G loss:-2.19\n",
      "Epoch:  0017 D loss:-0.3638 G loss:-2.379\n",
      "Epoch:  0017 D loss:-0.3207 G loss:-2.368\n",
      "Epoch:  0017 D loss:-0.3791 G loss:-2.241\n",
      "Epoch:  0017 D loss:-0.3726 G loss:-2.331\n",
      "Epoch:  0017 D loss:-0.4359 G loss:-2.357\n",
      "Epoch:  0017 D loss:-0.3683 G loss:-2.319\n",
      "Epoch:  0017 D loss:-0.3531 G loss:-2.37\n",
      "Epoch:  0017 D loss:-0.4227 G loss:-2.47\n",
      "Epoch:  0017 D loss:-0.4026 G loss:-2.417\n",
      "Epoch:  0017 D loss:-0.3535 G loss:-2.353\n",
      "Epoch:  0017 D loss:-0.4356 G loss:-2.173\n",
      "Epoch:  0017 D loss:-0.3924 G loss:-2.213\n",
      "Epoch:  0017 D loss:-0.2555 G loss:-2.537\n",
      "Epoch:  0017 D loss:-0.3592 G loss:-2.391\n",
      "Epoch:  0017 D loss:-0.3513 G loss:-2.464\n",
      "Epoch:  0017 D loss:-0.3113 G loss:-2.579\n",
      "Epoch:  0017 D loss:-0.2804 G loss:-2.594\n",
      "Epoch:  0017 D loss:-0.3746 G loss:-2.568\n",
      "Epoch:  0017 D loss:-0.4036 G loss:-2.49\n",
      "Epoch:  0017 D loss:-0.2786 G loss:-2.622\n",
      "Epoch:  0017 D loss:-0.3975 G loss:-2.491\n",
      "Epoch:  0017 D loss:-0.4077 G loss:-2.569\n",
      "Epoch:  0017 D loss:-0.3904 G loss:-2.444\n",
      "Epoch:  0017 D loss:-0.3824 G loss:-2.342\n",
      "Epoch:  0017 D loss:-0.3767 G loss:-2.328\n",
      "Epoch:  0017 D loss:-0.3912 G loss:-2.31\n",
      "Epoch:  0017 D loss:-0.2828 G loss:-2.44\n",
      "Epoch:  0017 D loss:-0.3689 G loss:-2.298\n",
      "Epoch:  0017 D loss:-0.2952 G loss:-2.481\n",
      "Epoch:  0017 D loss:-0.3719 G loss:-2.364\n",
      "Epoch:  0017 D loss:-0.3158 G loss:-2.364\n",
      "Epoch:  0017 D loss:-0.389 G loss:-2.445\n",
      "Epoch:  0017 D loss:-0.3383 G loss:-2.554\n",
      "Epoch:  0017 D loss:-0.4022 G loss:-2.473\n",
      "Epoch:  0017 D loss:-0.3782 G loss:-2.753\n",
      "Epoch:  0017 D loss:-0.465 G loss:-2.461\n",
      "Epoch:  0017 D loss:-0.3336 G loss:-2.542\n",
      "Epoch:  0017 D loss:-0.3273 G loss:-2.576\n",
      "Epoch:  0017 D loss:-0.3371 G loss:-2.545\n",
      "Epoch:  0017 D loss:-0.3497 G loss:-2.208\n",
      "Epoch:  0017 D loss:-0.4771 G loss:-2.29\n",
      "Epoch:  0017 D loss:-0.4331 G loss:-2.353\n",
      "Epoch:  0017 D loss:-0.3646 G loss:-2.246\n",
      "Epoch:  0017 D loss:-0.4147 G loss:-2.281\n",
      "Epoch:  0017 D loss:-0.3723 G loss:-2.24\n",
      "Epoch:  0017 D loss:-0.3449 G loss:-2.32\n",
      "Epoch:  0017 D loss:-0.4099 G loss:-2.247\n",
      "Epoch:  0017 D loss:-0.4468 G loss:-2.366\n",
      "Epoch:  0017 D loss:-0.4272 G loss:-2.444\n",
      "Epoch:  0017 D loss:-0.3897 G loss:-2.302\n",
      "Epoch:  0017 D loss:-0.3976 G loss:-2.343\n",
      "Epoch:  0017 D loss:-0.4151 G loss:-2.319\n",
      "Epoch:  0017 D loss:-0.2991 G loss:-2.396\n",
      "Epoch:  0017 D loss:-0.4564 G loss:-2.244\n",
      "Epoch:  0017 D loss:-0.3944 G loss:-2.4\n",
      "Epoch:  0017 D loss:-0.45 G loss:-2.14\n",
      "Epoch:  0017 D loss:-0.3707 G loss:-2.265\n",
      "Epoch:  0017 D loss:-0.3945 G loss:-2.218\n",
      "Epoch:  0017 D loss:-0.4197 G loss:-2.392\n",
      "Epoch:  0017 D loss:-0.3397 G loss:-2.401\n",
      "Epoch:  0017 D loss:-0.3907 G loss:-2.389\n",
      "Epoch:  0017 D loss:-0.3528 G loss:-2.428\n",
      "Epoch:  0017 D loss:-0.5331 G loss:-2.484\n",
      "Epoch:  0017 D loss:-0.3883 G loss:-2.467\n",
      "Epoch:  0017 D loss:-0.4617 G loss:-2.215\n",
      "Epoch:  0017 D loss:-0.4549 G loss:-2.267\n",
      "Epoch:  0017 D loss:-0.4268 G loss:-2.267\n",
      "Epoch:  0017 D loss:-0.449 G loss:-2.141\n",
      "Epoch:  0017 D loss:-0.3935 G loss:-2.219\n",
      "Epoch:  0017 D loss:-0.4574 G loss:-2.129\n",
      "Epoch:  0017 D loss:-0.3907 G loss:-2.179\n",
      "Epoch:  0017 D loss:-0.4043 G loss:-2.152\n",
      "Epoch:  0017 D loss:-0.4461 G loss:-2.45\n",
      "Epoch:  0017 D loss:-0.4022 G loss:-2.345\n",
      "Epoch:  0017 D loss:-0.4379 G loss:-2.475\n",
      "Epoch:  0017 D loss:-0.4345 G loss:-2.356\n",
      "Epoch:  0017 D loss:-0.4845 G loss:-2.389\n",
      "Epoch:  0017 D loss:-0.4741 G loss:-2.31\n",
      "Epoch:  0017 D loss:-0.4536 G loss:-2.36\n",
      "Epoch:  0017 D loss:-0.5182 G loss:-2.425\n",
      "Epoch:  0017 D loss:-0.4358 G loss:-2.213\n",
      "Epoch:  0017 D loss:-0.4876 G loss:-2.205\n",
      "Epoch:  0017 D loss:-0.3929 G loss:-2.218\n",
      "Epoch:  0017 D loss:-0.393 G loss:-2.293\n",
      "Epoch:  0017 D loss:-0.4412 G loss:-2.326\n",
      "Epoch:  0017 D loss:-0.4761 G loss:-2.289\n",
      "Epoch:  0017 D loss:-0.4603 G loss:-2.164\n",
      "Epoch:  0017 D loss:-0.4671 G loss:-2.138\n",
      "Epoch:  0017 D loss:-0.4053 G loss:-2.253\n",
      "Epoch:  0017 D loss:-0.4876 G loss:-2.001\n",
      "Epoch:  0017 D loss:-0.4643 G loss:-2.047\n",
      "Epoch:  0017 D loss:-0.4965 G loss:-2.151\n",
      "Epoch:  0017 D loss:-0.453 G loss:-2.253\n",
      "Epoch:  0017 D loss:-0.5552 G loss:-2.042\n",
      "Epoch:  0017 D loss:-0.4959 G loss:-2.335\n",
      "Epoch:  0017 D loss:-0.4655 G loss:-2.228\n",
      "Epoch:  0017 D loss:-0.5013 G loss:-2.343\n",
      "Epoch:  0017 D loss:-0.4252 G loss:-2.404\n",
      "Epoch:  0017 D loss:-0.4958 G loss:-2.311\n",
      "Epoch:  0017 D loss:-0.3955 G loss:-2.256\n",
      "Epoch:  0017 D loss:-0.3881 G loss:-2.319\n",
      "Epoch:  0017 D loss:-0.4234 G loss:-2.424\n",
      "Epoch:  0017 D loss:-0.4971 G loss:-2.275\n",
      "Epoch:  0017 D loss:-0.4683 G loss:-2.282\n",
      "Epoch:  0017 D loss:-0.5029 G loss:-2.141\n",
      "Epoch:  0017 D loss:-0.5107 G loss:-2.089\n",
      "Epoch:  0017 D loss:-0.3761 G loss:-2.284\n",
      "Epoch:  0017 D loss:-0.4209 G loss:-2.111\n",
      "Epoch:  0017 D loss:-0.491 G loss:-2.204\n",
      "Epoch:  0017 D loss:-0.4126 G loss:-2.188\n",
      "Epoch:  0017 D loss:-0.4305 G loss:-2.213\n",
      "Epoch:  0017 D loss:-0.3756 G loss:-2.24\n",
      "Epoch:  0017 D loss:-0.4253 G loss:-2.068\n",
      "Epoch:  0017 D loss:-0.4149 G loss:-2.164\n",
      "Epoch:  0017 D loss:-0.3986 G loss:-2.424\n",
      "Epoch:  0017 D loss:-0.5057 G loss:-2.218\n",
      "Epoch:  0017 D loss:-0.5345 G loss:-2.102\n",
      "Epoch:  0017 D loss:-0.4939 G loss:-2.128\n",
      "Epoch:  0017 D loss:-0.4118 G loss:-2.223\n",
      "Epoch:  0017 D loss:-0.5057 G loss:-2.226\n",
      "Epoch:  0017 D loss:-0.4417 G loss:-2.307\n",
      "Epoch:  0017 D loss:-0.5436 G loss:-2.257\n",
      "Epoch:  0017 D loss:-0.4313 G loss:-2.242\n",
      "Epoch:  0017 D loss:-0.4903 G loss:-1.965\n",
      "Epoch:  0017 D loss:-0.3738 G loss:-2.234\n",
      "Epoch:  0017 D loss:-0.3735 G loss:-2.127\n",
      "Epoch:  0017 D loss:-0.4327 G loss:-2.336\n",
      "Epoch:  0017 D loss:-0.4177 G loss:-2.176\n",
      "Epoch:  0017 D loss:-0.4735 G loss:-2.174\n",
      "Epoch:  0017 D loss:-0.3394 G loss:-2.385\n",
      "Epoch:  0017 D loss:-0.4476 G loss:-2.416\n",
      "Epoch:  0017 D loss:-0.5257 G loss:-2.233\n",
      "Epoch:  0017 D loss:-0.5182 G loss:-2.332\n",
      "Epoch:  0017 D loss:-0.4437 G loss:-2.265\n",
      "Epoch:  0017 D loss:-0.4149 G loss:-2.191\n",
      "Epoch:  0017 D loss:-0.4487 G loss:-2.167\n",
      "Epoch:  0017 D loss:-0.4316 G loss:-2.124\n",
      "Epoch:  0017 D loss:-0.512 G loss:-2.005\n",
      "Epoch:  0017 D loss:-0.4257 G loss:-2.062\n",
      "Epoch:  0017 D loss:-0.4325 G loss:-2.107\n",
      "Epoch:  0017 D loss:-0.3761 G loss:-2.231\n",
      "Epoch:  0017 D loss:-0.4276 G loss:-2.211\n",
      "Epoch:  0017 D loss:-0.3106 G loss:-2.505\n",
      "Epoch:  0017 D loss:-0.3876 G loss:-2.354\n",
      "Epoch:  0017 D loss:-0.4488 G loss:-2.336\n",
      "Epoch:  0017 D loss:-0.5053 G loss:-2.233\n",
      "Epoch:  0017 D loss:-0.4495 G loss:-2.231\n",
      "Epoch:  0017 D loss:-0.5279 G loss:-2.221\n",
      "Epoch:  0017 D loss:-0.3743 G loss:-2.358\n",
      "Epoch:  0017 D loss:-0.4224 G loss:-2.227\n",
      "Epoch:  0017 D loss:-0.4364 G loss:-2.292\n",
      "Epoch:  0017 D loss:-0.4149 G loss:-2.314\n",
      "Epoch:  0017 D loss:-0.4967 G loss:-2.198\n",
      "Epoch:  0017 D loss:-0.3685 G loss:-2.195\n",
      "Epoch:  0017 D loss:-0.4947 G loss:-2.037\n",
      "Epoch:  0017 D loss:-0.442 G loss:-2.188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0017 D loss:-0.5018 G loss:-2.17\n",
      "Epoch:  0017 D loss:-0.4628 G loss:-2.177\n",
      "Epoch:  0017 D loss:-0.4308 G loss:-2.306\n",
      "Epoch:  0017 D loss:-0.4005 G loss:-2.217\n",
      "Epoch:  0017 D loss:-0.4417 G loss:-2.314\n",
      "Epoch:  0017 D loss:-0.3774 G loss:-2.213\n",
      "Epoch:  0017 D loss:-0.4562 G loss:-2.309\n",
      "Epoch:  0017 D loss:-0.4192 G loss:-2.228\n",
      "Epoch:  0017 D loss:-0.4566 G loss:-2.272\n",
      "Epoch:  0017 D loss:-0.4316 G loss:-2.205\n",
      "Epoch:  0017 D loss:-0.4941 G loss:-2.403\n",
      "Epoch:  0017 D loss:-0.4458 G loss:-2.348\n",
      "Epoch:  0017 D loss:-0.4154 G loss:-2.446\n",
      "Epoch:  0017 D loss:-0.465 G loss:-2.129\n",
      "Epoch:  0017 D loss:-0.3787 G loss:-2.254\n",
      "Epoch:  0017 D loss:-0.5074 G loss:-2.263\n",
      "Epoch:  0017 D loss:-0.4255 G loss:-2.153\n",
      "Epoch:  0017 D loss:-0.5927 G loss:-2.272\n",
      "Epoch:  0017 D loss:-0.356 G loss:-2.246\n",
      "Epoch:  0017 D loss:-0.4118 G loss:-2.283\n",
      "Epoch:  0017 D loss:-0.3876 G loss:-2.346\n",
      "Epoch:  0017 D loss:-0.3269 G loss:-2.4\n",
      "Epoch:  0017 D loss:-0.3408 G loss:-2.346\n",
      "Epoch:  0017 D loss:-0.3292 G loss:-2.389\n",
      "Epoch:  0017 D loss:-0.4688 G loss:-2.434\n",
      "Epoch:  0017 D loss:-0.3789 G loss:-2.521\n",
      "Epoch:  0017 D loss:-0.4531 G loss:-2.384\n",
      "Epoch:  0017 D loss:-0.4489 G loss:-2.414\n",
      "Epoch:  0017 D loss:-0.4373 G loss:-2.547\n",
      "Epoch:  0017 D loss:-0.4472 G loss:-2.52\n",
      "Epoch:  0017 D loss:-0.3818 G loss:-2.432\n",
      "Epoch:  0017 D loss:-0.3874 G loss:-2.441\n",
      "Epoch:  0017 D loss:-0.45 G loss:-2.354\n",
      "Epoch:  0017 D loss:-0.5179 G loss:-2.266\n",
      "Epoch:  0017 D loss:-0.3721 G loss:-2.422\n",
      "Epoch:  0017 D loss:-0.4194 G loss:-2.191\n",
      "Epoch:  0017 D loss:-0.5474 G loss:-2.125\n",
      "Epoch:  0017 D loss:-0.3998 G loss:-2.198\n",
      "Epoch:  0017 D loss:-0.4407 G loss:-2.098\n",
      "Epoch:  0017 D loss:-0.4051 G loss:-2.118\n",
      "Epoch:  0017 D loss:-0.4751 G loss:-2.128\n",
      "Epoch:  0017 D loss:-0.4018 G loss:-2.078\n",
      "Epoch:  0017 D loss:-0.3869 G loss:-2.313\n",
      "Epoch:  0017 D loss:-0.3607 G loss:-2.268\n",
      "Epoch:  0017 D loss:-0.4503 G loss:-2.348\n",
      "Epoch:  0017 D loss:-0.3622 G loss:-2.513\n",
      "Epoch:  0017 D loss:-0.3669 G loss:-2.429\n",
      "Epoch:  0017 D loss:-0.4019 G loss:-2.714\n",
      "Epoch:  0017 D loss:-0.3414 G loss:-2.471\n",
      "Epoch:  0017 D loss:-0.4068 G loss:-2.565\n",
      "Epoch:  0017 D loss:-0.448 G loss:-2.466\n",
      "Epoch:  0017 D loss:-0.4809 G loss:-2.312\n",
      "Epoch:  0017 D loss:-0.4384 G loss:-2.387\n",
      "Epoch:  0017 D loss:-0.4845 G loss:-2.221\n",
      "Epoch:  0017 D loss:-0.4237 G loss:-2.192\n",
      "Epoch:  0017 D loss:-0.4627 G loss:-2.36\n",
      "Epoch:  0017 D loss:-0.4062 G loss:-2.367\n",
      "Epoch:  0017 D loss:-0.3834 G loss:-2.332\n",
      "Epoch:  0017 D loss:-0.4814 G loss:-2.11\n",
      "Epoch:  0017 D loss:-0.4451 G loss:-2.11\n",
      "Epoch:  0017 D loss:-0.4303 G loss:-2.286\n",
      "Epoch:  0017 D loss:-0.4355 G loss:-2.223\n",
      "Epoch:  0017 D loss:-0.2757 G loss:-2.565\n",
      "Epoch:  0017 D loss:-0.275 G loss:-2.507\n",
      "Epoch:  0017 D loss:-0.4505 G loss:-2.483\n",
      "Epoch:  0017 D loss:-0.3794 G loss:-2.578\n",
      "Epoch:  0017 D loss:-0.3674 G loss:-2.623\n",
      "Epoch:  0017 D loss:-0.4014 G loss:-2.721\n",
      "Epoch:  0017 D loss:-0.367 G loss:-2.529\n",
      "Epoch:  0017 D loss:-0.3314 G loss:-2.575\n",
      "Epoch:  0017 D loss:-0.3922 G loss:-2.427\n",
      "Epoch:  0017 D loss:-0.4295 G loss:-2.44\n",
      "Epoch:  0017 D loss:-0.3587 G loss:-2.603\n",
      "Epoch:  0017 D loss:-0.3891 G loss:-2.427\n",
      "Epoch:  0017 D loss:-0.3956 G loss:-2.325\n",
      "Epoch:  0017 D loss:-0.4739 G loss:-2.426\n",
      "Epoch:  0017 D loss:-0.4215 G loss:-2.481\n",
      "Epoch:  0017 D loss:-0.3708 G loss:-2.353\n",
      "Epoch:  0017 D loss:-0.4158 G loss:-2.244\n",
      "Epoch:  0017 D loss:-0.3498 G loss:-2.416\n",
      "Epoch:  0017 D loss:-0.4563 G loss:-2.331\n",
      "Epoch:  0017 D loss:-0.4018 G loss:-2.173\n",
      "Epoch:  0017 D loss:-0.4918 G loss:-2.198\n",
      "Epoch:  0017 D loss:-0.4099 G loss:-2.374\n",
      "Epoch:  0017 D loss:-0.5165 G loss:-2.506\n",
      "Epoch:  0017 D loss:-0.3946 G loss:-2.628\n",
      "Epoch:  0017 D loss:-0.3918 G loss:-2.317\n",
      "Epoch:  0017 D loss:-0.5129 G loss:-2.489\n",
      "Epoch:  0017 D loss:-0.4045 G loss:-2.281\n",
      "Epoch:  0017 D loss:-0.4572 G loss:-2.08\n",
      "Epoch:  0017 D loss:-0.3954 G loss:-2.42\n",
      "Epoch:  0017 D loss:-0.3515 G loss:-2.411\n",
      "Epoch:  0017 D loss:-0.6121 G loss:-2.306\n",
      "Epoch:  0017 D loss:-0.3651 G loss:-2.3\n",
      "Epoch:  0017 D loss:-0.3993 G loss:-2.327\n",
      "Epoch:  0017 D loss:-0.3188 G loss:-2.391\n",
      "Epoch:  0017 D loss:-0.3405 G loss:-2.624\n",
      "Epoch:  0017 D loss:-0.4506 G loss:-2.521\n",
      "Epoch:  0017 D loss:-0.2943 G loss:-2.618\n",
      "Epoch:  0017 D loss:-0.3146 G loss:-2.693\n",
      "Epoch:  0017 D loss:-0.3224 G loss:-2.789\n",
      "Epoch:  0017 D loss:-0.3196 G loss:-2.82\n",
      "Epoch:  0017 D loss:-0.4533 G loss:-2.436\n",
      "Epoch:  0017 D loss:-0.4174 G loss:-2.527\n",
      "Epoch:  0017 D loss:-0.3358 G loss:-2.644\n",
      "Epoch:  0017 D loss:-0.4045 G loss:-2.484\n",
      "Epoch:  0017 D loss:-0.3848 G loss:-2.21\n",
      "Epoch:  0017 D loss:-0.365 G loss:-2.461\n",
      "Epoch:  0017 D loss:-0.4689 G loss:-2.301\n",
      "Epoch:  0017 D loss:-0.3804 G loss:-2.165\n",
      "Epoch:  0017 D loss:-0.4643 G loss:-2.258\n",
      "Epoch:  0017 D loss:-0.3897 G loss:-2.284\n",
      "Epoch:  0017 D loss:-0.4089 G loss:-2.291\n",
      "Epoch:  0017 D loss:-0.474 G loss:-2.269\n",
      "Epoch:  0017 D loss:-0.34 G loss:-2.555\n",
      "Epoch:  0017 D loss:-0.4016 G loss:-2.377\n",
      "Epoch:  0017 D loss:-0.545 G loss:-2.453\n",
      "Epoch:  0017 D loss:-0.3895 G loss:-2.652\n",
      "Epoch:  0017 D loss:-0.3581 G loss:-2.447\n",
      "Epoch:  0017 D loss:-0.4103 G loss:-2.544\n",
      "Epoch:  0017 D loss:-0.5462 G loss:-2.289\n",
      "Epoch:  0017 D loss:-0.4464 G loss:-2.647\n",
      "Epoch:  0017 D loss:-0.473 G loss:-2.476\n",
      "Epoch:  0017 D loss:-0.4384 G loss:-2.384\n",
      "Epoch:  0017 D loss:-0.3533 G loss:-2.311\n",
      "Epoch:  0017 D loss:-0.4685 G loss:-2.217\n",
      "Epoch:  0017 D loss:-0.5293 G loss:-2.12\n",
      "Epoch:  0017 D loss:-0.465 G loss:-2.23\n",
      "Epoch:  0017 D loss:-0.4126 G loss:-2.207\n",
      "Epoch:  0017 D loss:-0.427 G loss:-2.119\n",
      "Epoch:  0017 D loss:-0.2977 G loss:-2.397\n",
      "Epoch:  0017 D loss:-0.4103 G loss:-2.265\n",
      "Epoch:  0017 D loss:-0.513 G loss:-2.491\n",
      "Epoch:  0017 D loss:-0.5325 G loss:-2.515\n",
      "Epoch:  0017 D loss:-0.3581 G loss:-2.56\n",
      "Epoch:  0017 D loss:-0.6141 G loss:-2.37\n",
      "Epoch:  0017 D loss:-0.4515 G loss:-2.444\n",
      "Epoch:  0017 D loss:-0.4754 G loss:-2.339\n",
      "Epoch:  0017 D loss:-0.4929 G loss:-2.402\n",
      "Epoch:  0017 D loss:-0.4875 G loss:-2.38\n",
      "Epoch:  0017 D loss:-0.548 G loss:-2.459\n",
      "Epoch:  0017 D loss:-0.5263 G loss:-2.27\n",
      "Epoch:  0017 D loss:-0.6004 G loss:-2.156\n",
      "Epoch:  0017 D loss:-0.5007 G loss:-2.439\n",
      "Epoch:  0017 D loss:-0.5605 G loss:-2.002\n",
      "Epoch:  0017 D loss:-0.4352 G loss:-2.089\n",
      "Epoch:  0017 D loss:-0.5145 G loss:-2.231\n",
      "Epoch:  0017 D loss:-0.5044 G loss:-2.319\n",
      "Epoch:  0017 D loss:-0.5768 G loss:-2.198\n",
      "Epoch:  0017 D loss:-0.6816 G loss:-1.971\n",
      "Epoch:  0017 D loss:-0.5273 G loss:-2.258\n",
      "Epoch:  0017 D loss:-0.5593 G loss:-2.198\n",
      "Epoch:  0017 D loss:-0.5135 G loss:-2.301\n",
      "Epoch:  0017 D loss:-0.4627 G loss:-2.392\n",
      "Epoch:  0017 D loss:-0.534 G loss:-2.375\n",
      "Epoch:  0017 D loss:-0.4786 G loss:-2.345\n",
      "Epoch:  0017 D loss:-0.4451 G loss:-2.279\n",
      "Epoch:  0017 D loss:-0.5197 G loss:-2.503\n",
      "Epoch:  0017 D loss:-0.5633 G loss:-2.301\n",
      "Epoch:  0017 D loss:-0.4846 G loss:-2.246\n",
      "Epoch:  0017 D loss:-0.5188 G loss:-2.407\n",
      "Epoch:  0017 D loss:-0.574 G loss:-2.113\n",
      "Epoch:  0017 D loss:-0.4302 G loss:-2.194\n",
      "Epoch:  0017 D loss:-0.5028 G loss:-2.224\n",
      "Epoch:  0017 D loss:-0.6257 G loss:-2.147\n",
      "Epoch:  0017 D loss:-0.4913 G loss:-2.194\n",
      "Epoch:  0017 D loss:-0.4758 G loss:-2.262\n",
      "Epoch:  0017 D loss:-0.5168 G loss:-2.239\n",
      "Epoch:  0017 D loss:-0.5463 G loss:-2.239\n",
      "Epoch:  0017 D loss:-0.48 G loss:-2.334\n",
      "Epoch:  0017 D loss:-0.4784 G loss:-2.246\n",
      "Epoch:  0017 D loss:-0.4402 G loss:-2.37\n",
      "Epoch:  0017 D loss:-0.4518 G loss:-2.355\n",
      "Epoch:  0017 D loss:-0.4837 G loss:-2.635\n",
      "Epoch:  0017 D loss:-0.4757 G loss:-2.57\n",
      "Epoch:  0017 D loss:-0.4042 G loss:-2.57\n",
      "Epoch:  0017 D loss:-0.5655 G loss:-2.717\n",
      "Epoch:  0017 D loss:-0.4309 G loss:-2.443\n",
      "Epoch:  0017 D loss:-0.4577 G loss:-2.206\n",
      "Epoch:  0017 D loss:-0.4373 G loss:-2.598\n",
      "Epoch:  0017 D loss:-0.3749 G loss:-2.338\n",
      "Epoch:  0017 D loss:-0.4618 G loss:-2.263\n",
      "Epoch:  0017 D loss:-0.4716 G loss:-2.221\n",
      "Epoch:  0017 D loss:-0.4185 G loss:-2.22\n",
      "Epoch:  0017 D loss:-0.4772 G loss:-2.204\n",
      "Epoch:  0017 D loss:-0.3761 G loss:-2.544\n",
      "Epoch:  0017 D loss:-0.3781 G loss:-2.499\n",
      "Epoch:  0017 D loss:-0.4648 G loss:-2.399\n",
      "Epoch:  0017 D loss:-0.4082 G loss:-2.472\n",
      "Epoch:  0017 D loss:-0.4034 G loss:-2.609\n",
      "Epoch:  0017 D loss:-0.4282 G loss:-2.488\n",
      "Epoch:  0017 D loss:-0.4283 G loss:-2.552\n",
      "Epoch:  0017 D loss:-0.4549 G loss:-2.458\n",
      "Epoch:  0017 D loss:-0.3531 G loss:-2.482\n",
      "Epoch:  0017 D loss:-0.4041 G loss:-2.486\n",
      "Epoch:  0017 D loss:-0.3878 G loss:-2.656\n",
      "Epoch:  0017 D loss:-0.3413 G loss:-2.607\n",
      "Epoch:  0017 D loss:-0.4856 G loss:-2.611\n",
      "Epoch:  0017 D loss:-0.469 G loss:-2.721\n",
      "Epoch:  0017 D loss:-0.4648 G loss:-2.755\n",
      "Epoch:  0017 D loss:-0.39 G loss:-2.456\n",
      "Epoch:  0017 D loss:-0.5169 G loss:-2.519\n",
      "Epoch:  0017 D loss:-0.4771 G loss:-2.423\n",
      "Epoch:  0017 D loss:-0.4095 G loss:-2.317\n",
      "Epoch:  0017 D loss:-0.3867 G loss:-2.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0017 D loss:-0.3262 G loss:-2.438\n",
      "Epoch:  0017 D loss:-0.3391 G loss:-2.599\n",
      "Epoch:  0017 D loss:-0.4089 G loss:-2.351\n",
      "Epoch:  0017 D loss:-0.3917 G loss:-2.402\n",
      "Epoch:  0017 D loss:-0.4916 G loss:-2.144\n",
      "Epoch:  0017 D loss:-0.3996 G loss:-2.418\n",
      "Epoch:  0017 D loss:-0.3495 G loss:-2.484\n",
      "Epoch:  0017 D loss:-0.3771 G loss:-2.706\n",
      "Epoch:  0017 D loss:-0.3003 G loss:-2.696\n",
      "Epoch:  0017 D loss:-0.3151 G loss:-2.567\n",
      "Epoch:  0017 D loss:-0.3791 G loss:-2.752\n",
      "Epoch:  0017 D loss:-0.304 G loss:-2.769\n",
      "Epoch:  0017 D loss:-0.4038 G loss:-2.631\n",
      "Epoch:  0017 D loss:-0.4358 G loss:-2.884\n",
      "Epoch:  0017 D loss:-0.4138 G loss:-2.617\n",
      "Epoch:  0017 D loss:-0.3776 G loss:-2.724\n",
      "Epoch:  0017 D loss:-0.5036 G loss:-2.75\n",
      "Epoch:  0017 D loss:-0.4484 G loss:-2.414\n",
      "Epoch:  0017 D loss:-0.4223 G loss:-2.507\n",
      "Epoch:  0017 D loss:-0.3724 G loss:-2.415\n",
      "Epoch:  0017 D loss:-0.3691 G loss:-2.185\n",
      "Epoch:  0017 D loss:-0.4219 G loss:-2.358\n",
      "Epoch:  0017 D loss:-0.4034 G loss:-2.323\n",
      "Epoch:  0017 D loss:-0.4881 G loss:-2.274\n",
      "Epoch:  0017 D loss:-0.3788 G loss:-2.383\n",
      "Epoch:  0017 D loss:-0.3299 G loss:-2.455\n",
      "Epoch:  0017 D loss:-0.4165 G loss:-2.308\n",
      "Epoch:  0017 D loss:-0.3888 G loss:-2.579\n",
      "Epoch:  0017 D loss:-0.3448 G loss:-2.532\n",
      "Epoch:  0017 D loss:-0.4799 G loss:-2.435\n",
      "Epoch:  0017 D loss:-0.517 G loss:-2.624\n",
      "Epoch:  0017 D loss:-0.4636 G loss:-2.545\n",
      "Epoch:  0017 D loss:-0.4578 G loss:-2.327\n",
      "Epoch:  0017 D loss:-0.4003 G loss:-2.494\n",
      "Epoch:  0017 D loss:-0.442 G loss:-2.372\n",
      "Epoch:  0017 D loss:-0.4862 G loss:-2.469\n",
      "Epoch:  0017 D loss:-0.4883 G loss:-2.264\n",
      "Epoch:  0017 D loss:-0.4334 G loss:-2.193\n",
      "Epoch:  0017 D loss:-0.5037 G loss:-2.038\n",
      "Epoch:  0017 D loss:-0.5222 G loss:-2.022\n",
      "Epoch:  0017 D loss:-0.4881 G loss:-2.157\n",
      "Epoch:  0017 D loss:-0.4392 G loss:-2.091\n",
      "Epoch:  0017 D loss:-0.4848 G loss:-2.115\n",
      "Epoch:  0017 D loss:-0.4594 G loss:-2.266\n",
      "Epoch:  0017 D loss:-0.5616 G loss:-2.317\n",
      "Epoch:  0017 D loss:-0.5245 G loss:-2.192\n",
      "Epoch:  0017 D loss:-0.4685 G loss:-2.376\n",
      "Epoch:  0017 D loss:-0.4772 G loss:-2.348\n",
      "Epoch:  0017 D loss:-0.4689 G loss:-2.307\n",
      "Epoch:  0017 D loss:-0.4478 G loss:-2.293\n",
      "Epoch:  0017 D loss:-0.4847 G loss:-2.196\n",
      "Epoch:  0017 D loss:-0.4727 G loss:-2.208\n",
      "Epoch:  0017 D loss:-0.4923 G loss:-2.317\n",
      "Epoch:  0017 D loss:-0.4381 G loss:-2.261\n",
      "Epoch:  0017 D loss:-0.4663 G loss:-2.187\n",
      "Epoch:  0017 D loss:-0.4468 G loss:-2.213\n",
      "Epoch:  0017 D loss:-0.5147 G loss:-2.19\n",
      "Epoch:  0017 D loss:-0.5442 G loss:-2.005\n",
      "Epoch:  0017 D loss:-0.5167 G loss:-2.152\n",
      "Epoch:  0017 D loss:-0.5025 G loss:-2.206\n",
      "Epoch:  0017 D loss:-0.462 G loss:-2.068\n",
      "Epoch:  0017 D loss:-0.56 G loss:-2.117\n",
      "Epoch:  0017 D loss:-0.5785 G loss:-2.304\n",
      "Epoch:  0017 D loss:-0.4958 G loss:-2.333\n",
      "Epoch:  0017 D loss:-0.5464 G loss:-2.238\n",
      "Epoch:  0017 D loss:-0.5097 G loss:-2.384\n",
      "Epoch:  0017 D loss:-0.5531 G loss:-2.343\n",
      "Epoch:  0017 D loss:-0.481 G loss:-2.456\n",
      "Epoch:  0017 D loss:-0.4796 G loss:-2.381\n",
      "Epoch:  0017 D loss:-0.4512 G loss:-2.055\n",
      "Epoch:  0017 D loss:-0.493 G loss:-2.258\n",
      "Epoch:  0017 D loss:-0.5214 G loss:-2.126\n",
      "Epoch:  0018 D loss:-0.4791 G loss:-2.075\n",
      "Epoch:  0018 D loss:-0.6172 G loss:-2.187\n",
      "Epoch:  0018 D loss:-0.4927 G loss:-2.169\n",
      "Epoch:  0018 D loss:-0.4902 G loss:-2.135\n",
      "Epoch:  0018 D loss:-0.463 G loss:-2.213\n",
      "Epoch:  0018 D loss:-0.5394 G loss:-2.396\n",
      "Epoch:  0018 D loss:-0.4847 G loss:-2.416\n",
      "Epoch:  0018 D loss:-0.5888 G loss:-2.224\n",
      "Epoch:  0018 D loss:-0.5283 G loss:-2.282\n",
      "Epoch:  0018 D loss:-0.5913 G loss:-2.041\n",
      "Epoch:  0018 D loss:-0.4629 G loss:-2.088\n",
      "Epoch:  0018 D loss:-0.4287 G loss:-2.078\n",
      "Epoch:  0018 D loss:-0.466 G loss:-2.063\n",
      "Epoch:  0018 D loss:-0.5192 G loss:-2.071\n",
      "Epoch:  0018 D loss:-0.4709 G loss:-2.074\n",
      "Epoch:  0018 D loss:-0.4332 G loss:-2.233\n",
      "Epoch:  0018 D loss:-0.4563 G loss:-2.322\n",
      "Epoch:  0018 D loss:-0.4153 G loss:-2.323\n",
      "Epoch:  0018 D loss:-0.4732 G loss:-2.537\n",
      "Epoch:  0018 D loss:-0.4603 G loss:-2.494\n",
      "Epoch:  0018 D loss:-0.4689 G loss:-2.487\n",
      "Epoch:  0018 D loss:-0.422 G loss:-2.727\n",
      "Epoch:  0018 D loss:-0.4436 G loss:-2.446\n",
      "Epoch:  0018 D loss:-0.4103 G loss:-2.4\n",
      "Epoch:  0018 D loss:-0.3849 G loss:-2.38\n",
      "Epoch:  0018 D loss:-0.4621 G loss:-2.598\n",
      "Epoch:  0018 D loss:-0.4571 G loss:-2.39\n",
      "Epoch:  0018 D loss:-0.4177 G loss:-2.168\n",
      "Epoch:  0018 D loss:-0.345 G loss:-2.216\n",
      "Epoch:  0018 D loss:-0.3656 G loss:-2.316\n",
      "Epoch:  0018 D loss:-0.4059 G loss:-2.293\n",
      "Epoch:  0018 D loss:-0.4476 G loss:-2.336\n",
      "Epoch:  0018 D loss:-0.3574 G loss:-2.352\n",
      "Epoch:  0018 D loss:-0.4699 G loss:-2.145\n",
      "Epoch:  0018 D loss:-0.4841 G loss:-2.212\n",
      "Epoch:  0018 D loss:-0.3786 G loss:-2.544\n",
      "Epoch:  0018 D loss:-0.4075 G loss:-2.479\n",
      "Epoch:  0018 D loss:-0.3783 G loss:-2.476\n",
      "Epoch:  0018 D loss:-0.429 G loss:-2.481\n",
      "Epoch:  0018 D loss:-0.3622 G loss:-2.525\n",
      "Epoch:  0018 D loss:-0.4321 G loss:-2.357\n",
      "Epoch:  0018 D loss:-0.3802 G loss:-2.415\n",
      "Epoch:  0018 D loss:-0.3906 G loss:-2.307\n",
      "Epoch:  0018 D loss:-0.4625 G loss:-2.517\n",
      "Epoch:  0018 D loss:-0.5159 G loss:-2.168\n",
      "Epoch:  0018 D loss:-0.4612 G loss:-2.102\n",
      "Epoch:  0018 D loss:-0.4977 G loss:-2.212\n",
      "Epoch:  0018 D loss:-0.3772 G loss:-2.232\n",
      "Epoch:  0018 D loss:-0.3818 G loss:-2.17\n",
      "Epoch:  0018 D loss:-0.4301 G loss:-2.088\n",
      "Epoch:  0018 D loss:-0.4972 G loss:-2.189\n",
      "Epoch:  0018 D loss:-0.4977 G loss:-2.246\n",
      "Epoch:  0018 D loss:-0.4448 G loss:-2.247\n",
      "Epoch:  0018 D loss:-0.4384 G loss:-2.307\n",
      "Epoch:  0018 D loss:-0.4029 G loss:-2.422\n",
      "Epoch:  0018 D loss:-0.5125 G loss:-2.466\n",
      "Epoch:  0018 D loss:-0.6298 G loss:-2.271\n",
      "Epoch:  0018 D loss:-0.4886 G loss:-2.25\n",
      "Epoch:  0018 D loss:-0.5249 G loss:-2.343\n",
      "Epoch:  0018 D loss:-0.4431 G loss:-2.144\n",
      "Epoch:  0018 D loss:-0.5055 G loss:-2.17\n",
      "Epoch:  0018 D loss:-0.4955 G loss:-2.186\n",
      "Epoch:  0018 D loss:-0.5235 G loss:-2.003\n",
      "Epoch:  0018 D loss:-0.5159 G loss:-2.109\n",
      "Epoch:  0018 D loss:-0.4873 G loss:-2.367\n",
      "Epoch:  0018 D loss:-0.5253 G loss:-2.274\n",
      "Epoch:  0018 D loss:-0.4833 G loss:-2.284\n",
      "Epoch:  0018 D loss:-0.3764 G loss:-2.281\n",
      "Epoch:  0018 D loss:-0.4559 G loss:-2.086\n",
      "Epoch:  0018 D loss:-0.6387 G loss:-2.172\n",
      "Epoch:  0018 D loss:-0.5031 G loss:-2.283\n",
      "Epoch:  0018 D loss:-0.4406 G loss:-2.199\n",
      "Epoch:  0018 D loss:-0.3249 G loss:-2.525\n",
      "Epoch:  0018 D loss:-0.4743 G loss:-2.298\n",
      "Epoch:  0018 D loss:-0.5444 G loss:-2.25\n",
      "Epoch:  0018 D loss:-0.547 G loss:-2.216\n",
      "Epoch:  0018 D loss:-0.572 G loss:-2.217\n",
      "Epoch:  0018 D loss:-0.54 G loss:-2.192\n",
      "Epoch:  0018 D loss:-0.5219 G loss:-2.212\n",
      "Epoch:  0018 D loss:-0.4862 G loss:-2.373\n",
      "Epoch:  0018 D loss:-0.5662 G loss:-2.117\n",
      "Epoch:  0018 D loss:-0.5257 G loss:-2.142\n",
      "Epoch:  0018 D loss:-0.4656 G loss:-2.28\n",
      "Epoch:  0018 D loss:-0.4732 G loss:-2.235\n",
      "Epoch:  0018 D loss:-0.494 G loss:-2.376\n",
      "Epoch:  0018 D loss:-0.5068 G loss:-2.209\n",
      "Epoch:  0018 D loss:-0.5718 G loss:-2.308\n",
      "Epoch:  0018 D loss:-0.4897 G loss:-2.265\n",
      "Epoch:  0018 D loss:-0.4045 G loss:-2.207\n",
      "Epoch:  0018 D loss:-0.4893 G loss:-2.397\n",
      "Epoch:  0018 D loss:-0.4733 G loss:-2.301\n",
      "Epoch:  0018 D loss:-0.4716 G loss:-2.424\n",
      "Epoch:  0018 D loss:-0.4471 G loss:-2.267\n",
      "Epoch:  0018 D loss:-0.4071 G loss:-2.535\n",
      "Epoch:  0018 D loss:-0.4333 G loss:-2.427\n",
      "Epoch:  0018 D loss:-0.5203 G loss:-2.435\n",
      "Epoch:  0018 D loss:-0.5153 G loss:-2.277\n",
      "Epoch:  0018 D loss:-0.5432 G loss:-2.287\n",
      "Epoch:  0018 D loss:-0.4148 G loss:-2.318\n",
      "Epoch:  0018 D loss:-0.3858 G loss:-2.593\n",
      "Epoch:  0018 D loss:-0.4071 G loss:-2.337\n",
      "Epoch:  0018 D loss:-0.3962 G loss:-2.395\n",
      "Epoch:  0018 D loss:-0.4446 G loss:-2.381\n",
      "Epoch:  0018 D loss:-0.4809 G loss:-2.509\n",
      "Epoch:  0018 D loss:-0.4883 G loss:-2.162\n",
      "Epoch:  0018 D loss:-0.4436 G loss:-2.31\n",
      "Epoch:  0018 D loss:-0.4127 G loss:-2.404\n",
      "Epoch:  0018 D loss:-0.4241 G loss:-2.235\n",
      "Epoch:  0018 D loss:-0.3858 G loss:-2.434\n",
      "Epoch:  0018 D loss:-0.425 G loss:-2.425\n",
      "Epoch:  0018 D loss:-0.4542 G loss:-2.269\n",
      "Epoch:  0018 D loss:-0.478 G loss:-2.376\n",
      "Epoch:  0018 D loss:-0.4551 G loss:-2.458\n",
      "Epoch:  0018 D loss:-0.4165 G loss:-2.613\n",
      "Epoch:  0018 D loss:-0.39 G loss:-2.665\n",
      "Epoch:  0018 D loss:-0.5051 G loss:-2.436\n",
      "Epoch:  0018 D loss:-0.5314 G loss:-2.314\n",
      "Epoch:  0018 D loss:-0.4672 G loss:-2.3\n",
      "Epoch:  0018 D loss:-0.5388 G loss:-2.394\n",
      "Epoch:  0018 D loss:-0.336 G loss:-2.624\n",
      "Epoch:  0018 D loss:-0.3933 G loss:-2.509\n",
      "Epoch:  0018 D loss:-0.47 G loss:-2.214\n",
      "Epoch:  0018 D loss:-0.4647 G loss:-2.182\n",
      "Epoch:  0018 D loss:-0.4364 G loss:-2.261\n",
      "Epoch:  0018 D loss:-0.3848 G loss:-2.342\n",
      "Epoch:  0018 D loss:-0.4499 G loss:-2.497\n",
      "Epoch:  0018 D loss:-0.4064 G loss:-2.447\n",
      "Epoch:  0018 D loss:-0.4581 G loss:-2.397\n",
      "Epoch:  0018 D loss:-0.4661 G loss:-2.363\n",
      "Epoch:  0018 D loss:-0.4264 G loss:-2.376\n",
      "Epoch:  0018 D loss:-0.49 G loss:-2.206\n",
      "Epoch:  0018 D loss:-0.3625 G loss:-2.328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0018 D loss:-0.4571 G loss:-2.498\n",
      "Epoch:  0018 D loss:-0.4566 G loss:-2.484\n",
      "Epoch:  0018 D loss:-0.5139 G loss:-2.298\n",
      "Epoch:  0018 D loss:-0.4439 G loss:-2.319\n",
      "Epoch:  0018 D loss:-0.4487 G loss:-2.432\n",
      "Epoch:  0018 D loss:-0.4412 G loss:-2.34\n",
      "Epoch:  0018 D loss:-0.4155 G loss:-2.495\n",
      "Epoch:  0018 D loss:-0.4556 G loss:-2.228\n",
      "Epoch:  0018 D loss:-0.4308 G loss:-2.351\n",
      "Epoch:  0018 D loss:-0.4576 G loss:-2.326\n",
      "Epoch:  0018 D loss:-0.505 G loss:-2.28\n",
      "Epoch:  0018 D loss:-0.4325 G loss:-2.281\n",
      "Epoch:  0018 D loss:-0.4911 G loss:-2.327\n",
      "Epoch:  0018 D loss:-0.4056 G loss:-2.474\n",
      "Epoch:  0018 D loss:-0.3565 G loss:-2.372\n",
      "Epoch:  0018 D loss:-0.3506 G loss:-2.598\n",
      "Epoch:  0018 D loss:-0.392 G loss:-2.438\n",
      "Epoch:  0018 D loss:-0.4148 G loss:-2.444\n",
      "Epoch:  0018 D loss:-0.5251 G loss:-2.486\n",
      "Epoch:  0018 D loss:-0.4809 G loss:-2.49\n",
      "Epoch:  0018 D loss:-0.4407 G loss:-2.497\n",
      "Epoch:  0018 D loss:-0.4106 G loss:-2.491\n",
      "Epoch:  0018 D loss:-0.4027 G loss:-2.274\n",
      "Epoch:  0018 D loss:-0.3888 G loss:-2.207\n",
      "Epoch:  0018 D loss:-0.4691 G loss:-2.234\n",
      "Epoch:  0018 D loss:-0.4298 G loss:-2.278\n",
      "Epoch:  0018 D loss:-0.4769 G loss:-2.278\n",
      "Epoch:  0018 D loss:-0.4408 G loss:-2.294\n",
      "Epoch:  0018 D loss:-0.3947 G loss:-2.423\n",
      "Epoch:  0018 D loss:-0.3919 G loss:-2.268\n",
      "Epoch:  0018 D loss:-0.4809 G loss:-2.441\n",
      "Epoch:  0018 D loss:-0.4492 G loss:-2.318\n",
      "Epoch:  0018 D loss:-0.3616 G loss:-2.571\n",
      "Epoch:  0018 D loss:-0.421 G loss:-2.608\n",
      "Epoch:  0018 D loss:-0.472 G loss:-2.543\n",
      "Epoch:  0018 D loss:-0.4864 G loss:-2.335\n",
      "Epoch:  0018 D loss:-0.4169 G loss:-2.299\n",
      "Epoch:  0018 D loss:-0.4724 G loss:-2.237\n",
      "Epoch:  0018 D loss:-0.4443 G loss:-2.269\n",
      "Epoch:  0018 D loss:-0.3531 G loss:-2.423\n",
      "Epoch:  0018 D loss:-0.4816 G loss:-2.307\n",
      "Epoch:  0018 D loss:-0.4243 G loss:-2.138\n",
      "Epoch:  0018 D loss:-0.4199 G loss:-2.315\n",
      "Epoch:  0018 D loss:-0.4076 G loss:-2.357\n",
      "Epoch:  0018 D loss:-0.5017 G loss:-2.234\n",
      "Epoch:  0018 D loss:-0.5002 G loss:-2.343\n",
      "Epoch:  0018 D loss:-0.514 G loss:-2.337\n",
      "Epoch:  0018 D loss:-0.4142 G loss:-2.522\n",
      "Epoch:  0018 D loss:-0.4359 G loss:-2.308\n",
      "Epoch:  0018 D loss:-0.4321 G loss:-2.313\n",
      "Epoch:  0018 D loss:-0.3347 G loss:-2.397\n",
      "Epoch:  0018 D loss:-0.3813 G loss:-2.474\n",
      "Epoch:  0018 D loss:-0.3651 G loss:-2.491\n",
      "Epoch:  0018 D loss:-0.5007 G loss:-2.497\n",
      "Epoch:  0018 D loss:-0.3931 G loss:-2.398\n",
      "Epoch:  0018 D loss:-0.4392 G loss:-2.469\n",
      "Epoch:  0018 D loss:-0.4957 G loss:-2.358\n",
      "Epoch:  0018 D loss:-0.3775 G loss:-2.32\n",
      "Epoch:  0018 D loss:-0.4421 G loss:-2.397\n",
      "Epoch:  0018 D loss:-0.4845 G loss:-2.183\n",
      "Epoch:  0018 D loss:-0.4717 G loss:-2.358\n",
      "Epoch:  0018 D loss:-0.4673 G loss:-2.122\n",
      "Epoch:  0018 D loss:-0.4004 G loss:-2.202\n",
      "Epoch:  0018 D loss:-0.4235 G loss:-2.239\n",
      "Epoch:  0018 D loss:-0.5366 G loss:-2.246\n",
      "Epoch:  0018 D loss:-0.4348 G loss:-2.301\n",
      "Epoch:  0018 D loss:-0.3841 G loss:-2.452\n",
      "Epoch:  0018 D loss:-0.4148 G loss:-2.664\n",
      "Epoch:  0018 D loss:-0.4999 G loss:-2.64\n",
      "Epoch:  0018 D loss:-0.4137 G loss:-2.722\n",
      "Epoch:  0018 D loss:-0.3864 G loss:-2.624\n",
      "Epoch:  0018 D loss:-0.3952 G loss:-2.591\n",
      "Epoch:  0018 D loss:-0.4624 G loss:-2.452\n",
      "Epoch:  0018 D loss:-0.4208 G loss:-2.378\n",
      "Epoch:  0018 D loss:-0.3371 G loss:-2.53\n",
      "Epoch:  0018 D loss:-0.3726 G loss:-2.218\n",
      "Epoch:  0018 D loss:-0.4157 G loss:-2.29\n",
      "Epoch:  0018 D loss:-0.3803 G loss:-2.157\n",
      "Epoch:  0018 D loss:-0.4349 G loss:-2.388\n",
      "Epoch:  0018 D loss:-0.4943 G loss:-2.334\n",
      "Epoch:  0018 D loss:-0.4234 G loss:-2.354\n",
      "Epoch:  0018 D loss:-0.3422 G loss:-2.382\n",
      "Epoch:  0018 D loss:-0.4378 G loss:-2.302\n",
      "Epoch:  0018 D loss:-0.3487 G loss:-2.499\n",
      "Epoch:  0018 D loss:-0.4124 G loss:-2.611\n",
      "Epoch:  0018 D loss:-0.3926 G loss:-2.447\n",
      "Epoch:  0018 D loss:-0.4545 G loss:-2.487\n",
      "Epoch:  0018 D loss:-0.3628 G loss:-2.405\n",
      "Epoch:  0018 D loss:-0.3598 G loss:-2.366\n",
      "Epoch:  0018 D loss:-0.4133 G loss:-2.405\n",
      "Epoch:  0018 D loss:-0.4134 G loss:-2.412\n",
      "Epoch:  0018 D loss:-0.3379 G loss:-2.495\n",
      "Epoch:  0018 D loss:-0.4657 G loss:-2.487\n",
      "Epoch:  0018 D loss:-0.3892 G loss:-2.594\n",
      "Epoch:  0018 D loss:-0.3916 G loss:-2.414\n",
      "Epoch:  0018 D loss:-0.4422 G loss:-2.501\n",
      "Epoch:  0018 D loss:-0.4143 G loss:-2.601\n",
      "Epoch:  0018 D loss:-0.456 G loss:-2.34\n",
      "Epoch:  0018 D loss:-0.3935 G loss:-2.327\n",
      "Epoch:  0018 D loss:-0.4615 G loss:-2.482\n",
      "Epoch:  0018 D loss:-0.4277 G loss:-2.302\n",
      "Epoch:  0018 D loss:-0.3665 G loss:-2.526\n",
      "Epoch:  0018 D loss:-0.3878 G loss:-2.475\n",
      "Epoch:  0018 D loss:-0.3277 G loss:-2.642\n",
      "Epoch:  0018 D loss:-0.3568 G loss:-2.584\n",
      "Epoch:  0018 D loss:-0.5138 G loss:-2.479\n",
      "Epoch:  0018 D loss:-0.3968 G loss:-2.573\n",
      "Epoch:  0018 D loss:-0.3797 G loss:-2.413\n",
      "Epoch:  0018 D loss:-0.478 G loss:-2.524\n",
      "Epoch:  0018 D loss:-0.409 G loss:-2.359\n",
      "Epoch:  0018 D loss:-0.3463 G loss:-2.542\n",
      "Epoch:  0018 D loss:-0.3816 G loss:-2.46\n",
      "Epoch:  0018 D loss:-0.4488 G loss:-2.272\n",
      "Epoch:  0018 D loss:-0.4511 G loss:-2.203\n",
      "Epoch:  0018 D loss:-0.466 G loss:-2.654\n",
      "Epoch:  0018 D loss:-0.4446 G loss:-2.423\n",
      "Epoch:  0018 D loss:-0.4073 G loss:-2.326\n",
      "Epoch:  0018 D loss:-0.3966 G loss:-2.413\n",
      "Epoch:  0018 D loss:-0.4263 G loss:-2.203\n",
      "Epoch:  0018 D loss:-0.3875 G loss:-2.421\n",
      "Epoch:  0018 D loss:-0.3705 G loss:-2.392\n",
      "Epoch:  0018 D loss:-0.4402 G loss:-2.379\n",
      "Epoch:  0018 D loss:-0.328 G loss:-2.586\n",
      "Epoch:  0018 D loss:-0.461 G loss:-2.412\n",
      "Epoch:  0018 D loss:-0.3852 G loss:-2.641\n",
      "Epoch:  0018 D loss:-0.3305 G loss:-2.657\n",
      "Epoch:  0018 D loss:-0.4394 G loss:-2.559\n",
      "Epoch:  0018 D loss:-0.413 G loss:-2.48\n",
      "Epoch:  0018 D loss:-0.4618 G loss:-2.424\n",
      "Epoch:  0018 D loss:-0.4017 G loss:-2.53\n",
      "Epoch:  0018 D loss:-0.3907 G loss:-2.502\n",
      "Epoch:  0018 D loss:-0.4036 G loss:-2.532\n",
      "Epoch:  0018 D loss:-0.5181 G loss:-2.202\n",
      "Epoch:  0018 D loss:-0.4552 G loss:-2.285\n",
      "Epoch:  0018 D loss:-0.4864 G loss:-2.425\n",
      "Epoch:  0018 D loss:-0.3751 G loss:-2.408\n",
      "Epoch:  0018 D loss:-0.4895 G loss:-2.408\n",
      "Epoch:  0018 D loss:-0.5949 G loss:-2.285\n",
      "Epoch:  0018 D loss:-0.5199 G loss:-2.375\n",
      "Epoch:  0018 D loss:-0.4364 G loss:-2.422\n",
      "Epoch:  0018 D loss:-0.4559 G loss:-2.48\n",
      "Epoch:  0018 D loss:-0.4194 G loss:-2.604\n",
      "Epoch:  0018 D loss:-0.3965 G loss:-2.591\n",
      "Epoch:  0018 D loss:-0.4691 G loss:-2.648\n",
      "Epoch:  0018 D loss:-0.4055 G loss:-2.386\n",
      "Epoch:  0018 D loss:-0.473 G loss:-2.232\n",
      "Epoch:  0018 D loss:-0.4009 G loss:-2.461\n",
      "Epoch:  0018 D loss:-0.358 G loss:-2.32\n",
      "Epoch:  0018 D loss:-0.477 G loss:-2.272\n",
      "Epoch:  0018 D loss:-0.3867 G loss:-2.277\n",
      "Epoch:  0018 D loss:-0.4705 G loss:-2.18\n",
      "Epoch:  0018 D loss:-0.4343 G loss:-2.387\n",
      "Epoch:  0018 D loss:-0.4638 G loss:-2.377\n",
      "Epoch:  0018 D loss:-0.4473 G loss:-2.194\n",
      "Epoch:  0018 D loss:-0.4632 G loss:-2.361\n",
      "Epoch:  0018 D loss:-0.3034 G loss:-2.509\n",
      "Epoch:  0018 D loss:-0.3825 G loss:-2.387\n",
      "Epoch:  0018 D loss:-0.4369 G loss:-2.535\n",
      "Epoch:  0018 D loss:-0.3787 G loss:-2.627\n",
      "Epoch:  0018 D loss:-0.3472 G loss:-2.739\n",
      "Epoch:  0018 D loss:-0.4077 G loss:-2.677\n",
      "Epoch:  0018 D loss:-0.382 G loss:-2.659\n",
      "Epoch:  0018 D loss:-0.4033 G loss:-2.749\n",
      "Epoch:  0018 D loss:-0.4013 G loss:-2.931\n",
      "Epoch:  0018 D loss:-0.3892 G loss:-2.51\n",
      "Epoch:  0018 D loss:-0.3219 G loss:-2.661\n",
      "Epoch:  0018 D loss:-0.379 G loss:-2.732\n",
      "Epoch:  0018 D loss:-0.3553 G loss:-2.486\n",
      "Epoch:  0018 D loss:-0.4028 G loss:-2.53\n",
      "Epoch:  0018 D loss:-0.3853 G loss:-2.316\n",
      "Epoch:  0018 D loss:-0.4765 G loss:-2.22\n",
      "Epoch:  0018 D loss:-0.436 G loss:-2.298\n",
      "Epoch:  0018 D loss:-0.4261 G loss:-2.284\n",
      "Epoch:  0018 D loss:-0.3571 G loss:-2.646\n",
      "Epoch:  0018 D loss:-0.4997 G loss:-2.53\n",
      "Epoch:  0018 D loss:-0.373 G loss:-2.494\n",
      "Epoch:  0018 D loss:-0.4182 G loss:-2.586\n",
      "Epoch:  0018 D loss:-0.3635 G loss:-2.582\n",
      "Epoch:  0018 D loss:-0.4595 G loss:-2.404\n",
      "Epoch:  0018 D loss:-0.3856 G loss:-2.663\n",
      "Epoch:  0018 D loss:-0.3199 G loss:-2.568\n",
      "Epoch:  0018 D loss:-0.4574 G loss:-2.687\n",
      "Epoch:  0018 D loss:-0.4106 G loss:-2.552\n",
      "Epoch:  0018 D loss:-0.4231 G loss:-2.561\n",
      "Epoch:  0018 D loss:-0.4202 G loss:-2.6\n",
      "Epoch:  0018 D loss:-0.3808 G loss:-2.687\n",
      "Epoch:  0018 D loss:-0.4369 G loss:-2.461\n",
      "Epoch:  0018 D loss:-0.4396 G loss:-2.361\n",
      "Epoch:  0018 D loss:-0.4978 G loss:-2.423\n",
      "Epoch:  0018 D loss:-0.4535 G loss:-2.423\n",
      "Epoch:  0018 D loss:-0.4547 G loss:-2.256\n",
      "Epoch:  0018 D loss:-0.3936 G loss:-2.52\n",
      "Epoch:  0018 D loss:-0.4174 G loss:-2.397\n",
      "Epoch:  0018 D loss:-0.4174 G loss:-2.448\n",
      "Epoch:  0018 D loss:-0.4656 G loss:-2.548\n",
      "Epoch:  0018 D loss:-0.5168 G loss:-2.362\n",
      "Epoch:  0018 D loss:-0.5131 G loss:-2.334\n",
      "Epoch:  0018 D loss:-0.407 G loss:-2.559\n",
      "Epoch:  0018 D loss:-0.4838 G loss:-2.237\n",
      "Epoch:  0018 D loss:-0.4675 G loss:-2.273\n",
      "Epoch:  0018 D loss:-0.354 G loss:-2.52\n",
      "Epoch:  0018 D loss:-0.4173 G loss:-2.307\n",
      "Epoch:  0018 D loss:-0.4694 G loss:-2.417\n",
      "Epoch:  0018 D loss:-0.3575 G loss:-2.352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0018 D loss:-0.4251 G loss:-2.437\n",
      "Epoch:  0018 D loss:-0.3558 G loss:-2.528\n",
      "Epoch:  0018 D loss:-0.5078 G loss:-2.637\n",
      "Epoch:  0018 D loss:-0.3589 G loss:-2.414\n",
      "Epoch:  0018 D loss:-0.4574 G loss:-2.34\n",
      "Epoch:  0018 D loss:-0.4141 G loss:-2.511\n",
      "Epoch:  0018 D loss:-0.3427 G loss:-2.556\n",
      "Epoch:  0018 D loss:-0.3162 G loss:-2.596\n",
      "Epoch:  0018 D loss:-0.3857 G loss:-2.536\n",
      "Epoch:  0018 D loss:-0.3986 G loss:-2.41\n",
      "Epoch:  0018 D loss:-0.3823 G loss:-2.655\n",
      "Epoch:  0018 D loss:-0.4685 G loss:-2.54\n",
      "Epoch:  0018 D loss:-0.4103 G loss:-2.322\n",
      "Epoch:  0018 D loss:-0.3413 G loss:-2.565\n",
      "Epoch:  0018 D loss:-0.3796 G loss:-2.571\n",
      "Epoch:  0018 D loss:-0.3567 G loss:-2.533\n",
      "Epoch:  0018 D loss:-0.3743 G loss:-2.72\n",
      "Epoch:  0018 D loss:-0.4436 G loss:-2.579\n",
      "Epoch:  0018 D loss:-0.471 G loss:-2.469\n",
      "Epoch:  0018 D loss:-0.3872 G loss:-2.525\n",
      "Epoch:  0018 D loss:-0.3303 G loss:-2.55\n",
      "Epoch:  0018 D loss:-0.5414 G loss:-2.36\n",
      "Epoch:  0018 D loss:-0.3753 G loss:-2.709\n",
      "Epoch:  0018 D loss:-0.4584 G loss:-2.346\n",
      "Epoch:  0018 D loss:-0.4395 G loss:-2.442\n",
      "Epoch:  0018 D loss:-0.3575 G loss:-2.69\n",
      "Epoch:  0018 D loss:-0.4587 G loss:-2.525\n",
      "Epoch:  0018 D loss:-0.4058 G loss:-2.296\n",
      "Epoch:  0018 D loss:-0.3142 G loss:-2.609\n",
      "Epoch:  0018 D loss:-0.3618 G loss:-2.646\n",
      "Epoch:  0018 D loss:-0.305 G loss:-2.586\n",
      "Epoch:  0018 D loss:-0.449 G loss:-2.46\n",
      "Epoch:  0018 D loss:-0.3548 G loss:-2.431\n",
      "Epoch:  0018 D loss:-0.4033 G loss:-2.455\n",
      "Epoch:  0018 D loss:-0.3633 G loss:-2.474\n",
      "Epoch:  0018 D loss:-0.5003 G loss:-2.471\n",
      "Epoch:  0018 D loss:-0.3824 G loss:-2.448\n",
      "Epoch:  0018 D loss:-0.3726 G loss:-2.332\n",
      "Epoch:  0018 D loss:-0.4318 G loss:-2.604\n",
      "Epoch:  0018 D loss:-0.466 G loss:-2.43\n",
      "Epoch:  0018 D loss:-0.4099 G loss:-2.384\n",
      "Epoch:  0018 D loss:-0.3683 G loss:-2.564\n",
      "Epoch:  0018 D loss:-0.3942 G loss:-2.592\n",
      "Epoch:  0018 D loss:-0.4804 G loss:-2.36\n",
      "Epoch:  0018 D loss:-0.4102 G loss:-2.462\n",
      "Epoch:  0018 D loss:-0.4259 G loss:-2.389\n",
      "Epoch:  0018 D loss:-0.3319 G loss:-2.495\n",
      "Epoch:  0018 D loss:-0.4854 G loss:-2.478\n",
      "Epoch:  0018 D loss:-0.3148 G loss:-2.715\n",
      "Epoch:  0018 D loss:-0.5278 G loss:-2.646\n",
      "Epoch:  0018 D loss:-0.4274 G loss:-2.636\n",
      "Epoch:  0018 D loss:-0.3917 G loss:-2.439\n",
      "Epoch:  0018 D loss:-0.4736 G loss:-2.517\n",
      "Epoch:  0018 D loss:-0.3063 G loss:-2.507\n",
      "Epoch:  0018 D loss:-0.3197 G loss:-2.617\n",
      "Epoch:  0018 D loss:-0.4251 G loss:-2.378\n",
      "Epoch:  0018 D loss:-0.3567 G loss:-2.507\n",
      "Epoch:  0018 D loss:-0.4975 G loss:-2.458\n",
      "Epoch:  0018 D loss:-0.3837 G loss:-2.624\n",
      "Epoch:  0018 D loss:-0.3999 G loss:-2.508\n",
      "Epoch:  0018 D loss:-0.4924 G loss:-2.366\n",
      "Epoch:  0018 D loss:-0.3464 G loss:-2.656\n",
      "Epoch:  0018 D loss:-0.4993 G loss:-2.411\n",
      "Epoch:  0018 D loss:-0.373 G loss:-2.638\n",
      "Epoch:  0018 D loss:-0.4327 G loss:-2.529\n",
      "Epoch:  0018 D loss:-0.4495 G loss:-2.414\n",
      "Epoch:  0018 D loss:-0.4176 G loss:-2.486\n",
      "Epoch:  0018 D loss:-0.3825 G loss:-2.57\n",
      "Epoch:  0018 D loss:-0.3566 G loss:-2.331\n",
      "Epoch:  0018 D loss:-0.3613 G loss:-2.399\n",
      "Epoch:  0018 D loss:-0.4152 G loss:-2.61\n",
      "Epoch:  0018 D loss:-0.3588 G loss:-2.573\n",
      "Epoch:  0018 D loss:-0.3525 G loss:-2.541\n",
      "Epoch:  0018 D loss:-0.2998 G loss:-2.699\n",
      "Epoch:  0018 D loss:-0.3966 G loss:-2.575\n",
      "Epoch:  0018 D loss:-0.2557 G loss:-2.842\n",
      "Epoch:  0018 D loss:-0.3675 G loss:-2.582\n",
      "Epoch:  0018 D loss:-0.3542 G loss:-2.691\n",
      "Epoch:  0018 D loss:-0.287 G loss:-2.766\n",
      "Epoch:  0018 D loss:-0.4036 G loss:-2.426\n",
      "Epoch:  0018 D loss:-0.4544 G loss:-2.489\n",
      "Epoch:  0018 D loss:-0.4038 G loss:-2.449\n",
      "Epoch:  0018 D loss:-0.3469 G loss:-2.758\n",
      "Epoch:  0018 D loss:-0.3228 G loss:-2.679\n",
      "Epoch:  0018 D loss:-0.3635 G loss:-2.668\n",
      "Epoch:  0018 D loss:-0.3531 G loss:-2.663\n",
      "Epoch:  0018 D loss:-0.4028 G loss:-2.636\n",
      "Epoch:  0018 D loss:-0.3508 G loss:-2.736\n",
      "Epoch:  0018 D loss:-0.3442 G loss:-2.705\n",
      "Epoch:  0018 D loss:-0.2811 G loss:-2.761\n",
      "Epoch:  0018 D loss:-0.3032 G loss:-2.884\n",
      "Epoch:  0018 D loss:-0.3977 G loss:-2.781\n",
      "Epoch:  0018 D loss:-0.3022 G loss:-2.6\n",
      "Epoch:  0018 D loss:-0.3737 G loss:-2.691\n",
      "Epoch:  0018 D loss:-0.416 G loss:-2.531\n",
      "Epoch:  0018 D loss:-0.4026 G loss:-2.65\n",
      "Epoch:  0018 D loss:-0.3534 G loss:-2.524\n",
      "Epoch:  0018 D loss:-0.3341 G loss:-2.915\n",
      "Epoch:  0018 D loss:-0.3002 G loss:-2.788\n",
      "Epoch:  0018 D loss:-0.2868 G loss:-2.71\n",
      "Epoch:  0018 D loss:-0.2639 G loss:-2.872\n",
      "Epoch:  0018 D loss:-0.2572 G loss:-2.723\n",
      "Epoch:  0018 D loss:-0.3545 G loss:-2.805\n",
      "Epoch:  0018 D loss:-0.356 G loss:-2.587\n",
      "Epoch:  0018 D loss:-0.328 G loss:-2.696\n",
      "Epoch:  0018 D loss:-0.4111 G loss:-2.776\n",
      "Epoch:  0018 D loss:-0.3431 G loss:-2.504\n",
      "Epoch:  0018 D loss:-0.4229 G loss:-2.372\n",
      "Epoch:  0018 D loss:-0.3833 G loss:-2.562\n",
      "Epoch:  0018 D loss:-0.4764 G loss:-2.426\n",
      "Epoch:  0018 D loss:-0.4225 G loss:-2.507\n",
      "Epoch:  0018 D loss:-0.3882 G loss:-2.375\n",
      "Epoch:  0018 D loss:-0.321 G loss:-2.737\n",
      "Epoch:  0018 D loss:-0.3923 G loss:-2.683\n",
      "Epoch:  0018 D loss:-0.3372 G loss:-2.629\n",
      "Epoch:  0018 D loss:-0.3954 G loss:-2.811\n",
      "Epoch:  0018 D loss:-0.3392 G loss:-2.778\n",
      "Epoch:  0018 D loss:-0.3942 G loss:-2.73\n",
      "Epoch:  0018 D loss:-0.354 G loss:-2.668\n",
      "Epoch:  0018 D loss:-0.3435 G loss:-2.516\n",
      "Epoch:  0018 D loss:-0.3513 G loss:-2.749\n",
      "Epoch:  0018 D loss:-0.422 G loss:-2.564\n",
      "Epoch:  0018 D loss:-0.4493 G loss:-2.694\n",
      "Epoch:  0018 D loss:-0.4611 G loss:-2.369\n",
      "Epoch:  0018 D loss:-0.3537 G loss:-2.646\n",
      "Epoch:  0018 D loss:-0.4094 G loss:-2.647\n",
      "Epoch:  0018 D loss:-0.3368 G loss:-2.642\n",
      "Epoch:  0018 D loss:-0.3306 G loss:-2.58\n",
      "Epoch:  0018 D loss:-0.3811 G loss:-2.677\n",
      "Epoch:  0018 D loss:-0.3651 G loss:-2.676\n",
      "Epoch:  0018 D loss:-0.409 G loss:-2.632\n",
      "Epoch:  0018 D loss:-0.5081 G loss:-2.479\n",
      "Epoch:  0018 D loss:-0.3963 G loss:-2.596\n",
      "Epoch:  0018 D loss:-0.422 G loss:-2.413\n",
      "Epoch:  0018 D loss:-0.3847 G loss:-2.203\n",
      "Epoch:  0018 D loss:-0.3236 G loss:-2.536\n",
      "Epoch:  0018 D loss:-0.3146 G loss:-2.726\n",
      "Epoch:  0018 D loss:-0.4327 G loss:-2.377\n",
      "Epoch:  0018 D loss:-0.3749 G loss:-2.472\n",
      "Epoch:  0018 D loss:-0.3556 G loss:-2.649\n",
      "Epoch:  0018 D loss:-0.4325 G loss:-2.724\n",
      "Epoch:  0018 D loss:-0.4119 G loss:-2.623\n",
      "Epoch:  0018 D loss:-0.327 G loss:-2.749\n",
      "Epoch:  0018 D loss:-0.4114 G loss:-2.511\n",
      "Epoch:  0018 D loss:-0.4436 G loss:-2.673\n",
      "Epoch:  0018 D loss:-0.3798 G loss:-2.748\n",
      "Epoch:  0018 D loss:-0.4225 G loss:-2.603\n",
      "Epoch:  0018 D loss:-0.3311 G loss:-2.667\n",
      "Epoch:  0018 D loss:-0.4891 G loss:-2.544\n",
      "Epoch:  0018 D loss:-0.3457 G loss:-2.426\n",
      "Epoch:  0018 D loss:-0.4187 G loss:-2.379\n",
      "Epoch:  0018 D loss:-0.3515 G loss:-2.452\n",
      "Epoch:  0018 D loss:-0.3928 G loss:-2.568\n",
      "Epoch:  0018 D loss:-0.3614 G loss:-2.525\n",
      "Epoch:  0018 D loss:-0.2817 G loss:-2.565\n",
      "Epoch:  0018 D loss:-0.3644 G loss:-2.472\n",
      "Epoch:  0018 D loss:-0.4346 G loss:-2.562\n",
      "Epoch:  0018 D loss:-0.3879 G loss:-2.293\n",
      "Epoch:  0018 D loss:-0.3756 G loss:-2.591\n",
      "Epoch:  0018 D loss:-0.3965 G loss:-2.545\n",
      "Epoch:  0018 D loss:-0.3539 G loss:-2.582\n",
      "Epoch:  0018 D loss:-0.2785 G loss:-2.714\n",
      "Epoch:  0018 D loss:-0.4222 G loss:-2.761\n",
      "Epoch:  0018 D loss:-0.4783 G loss:-2.342\n",
      "Epoch:  0018 D loss:-0.3708 G loss:-2.694\n",
      "Epoch:  0018 D loss:-0.4152 G loss:-2.462\n",
      "Epoch:  0018 D loss:-0.3552 G loss:-2.363\n",
      "Epoch:  0018 D loss:-0.3914 G loss:-2.37\n",
      "Epoch:  0018 D loss:-0.3408 G loss:-2.585\n",
      "Epoch:  0018 D loss:-0.3863 G loss:-2.47\n",
      "Epoch:  0018 D loss:-0.4374 G loss:-2.414\n",
      "Epoch:  0018 D loss:-0.3906 G loss:-2.39\n",
      "Epoch:  0018 D loss:-0.3975 G loss:-2.381\n",
      "Epoch:  0018 D loss:-0.3647 G loss:-2.484\n",
      "Epoch:  0018 D loss:-0.3041 G loss:-2.492\n",
      "Epoch:  0018 D loss:-0.4658 G loss:-2.498\n",
      "Epoch:  0018 D loss:-0.4325 G loss:-2.397\n",
      "Epoch:  0018 D loss:-0.2797 G loss:-2.536\n",
      "Epoch:  0018 D loss:-0.288 G loss:-2.726\n",
      "Epoch:  0018 D loss:-0.3711 G loss:-2.7\n",
      "Epoch:  0018 D loss:-0.3457 G loss:-2.806\n",
      "Epoch:  0018 D loss:-0.3051 G loss:-2.859\n",
      "Epoch:  0018 D loss:-0.3684 G loss:-2.808\n",
      "Epoch:  0018 D loss:-0.4944 G loss:-2.606\n",
      "Epoch:  0018 D loss:-0.4396 G loss:-2.539\n",
      "Epoch:  0018 D loss:-0.379 G loss:-2.529\n",
      "Epoch:  0018 D loss:-0.3795 G loss:-2.473\n",
      "Epoch:  0018 D loss:-0.366 G loss:-2.409\n",
      "Epoch:  0018 D loss:-0.4187 G loss:-2.218\n",
      "Epoch:  0018 D loss:-0.4905 G loss:-2.337\n",
      "Epoch:  0018 D loss:-0.4558 G loss:-2.026\n",
      "Epoch:  0018 D loss:-0.3666 G loss:-2.234\n",
      "Epoch:  0018 D loss:-0.3021 G loss:-2.35\n",
      "Epoch:  0018 D loss:-0.3521 G loss:-2.432\n",
      "Epoch:  0018 D loss:-0.3997 G loss:-2.416\n",
      "Epoch:  0018 D loss:-0.3779 G loss:-2.676\n",
      "Epoch:  0018 D loss:-0.304 G loss:-2.775\n",
      "Epoch:  0018 D loss:-0.4162 G loss:-2.821\n",
      "Epoch:  0018 D loss:-0.4213 G loss:-2.679\n",
      "Epoch:  0018 D loss:-0.3928 G loss:-2.769\n",
      "Epoch:  0018 D loss:-0.3922 G loss:-2.348\n",
      "Epoch:  0018 D loss:-0.338 G loss:-2.637\n",
      "Epoch:  0018 D loss:-0.3691 G loss:-2.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0018 D loss:-0.4352 G loss:-2.398\n",
      "Epoch:  0018 D loss:-0.3129 G loss:-2.672\n",
      "Epoch:  0018 D loss:-0.4139 G loss:-2.593\n",
      "Epoch:  0018 D loss:-0.4797 G loss:-2.194\n",
      "Epoch:  0018 D loss:-0.3889 G loss:-2.374\n",
      "Epoch:  0018 D loss:-0.4174 G loss:-2.304\n",
      "Epoch:  0018 D loss:-0.4811 G loss:-2.256\n",
      "Epoch:  0018 D loss:-0.532 G loss:-2.246\n",
      "Epoch:  0018 D loss:-0.5461 G loss:-2.281\n",
      "Epoch:  0018 D loss:-0.4614 G loss:-2.392\n",
      "Epoch:  0018 D loss:-0.3884 G loss:-2.375\n",
      "Epoch:  0019 D loss:-0.3866 G loss:-2.186\n",
      "Epoch:  0019 D loss:-0.3911 G loss:-2.288\n",
      "Epoch:  0019 D loss:-0.452 G loss:-2.507\n",
      "Epoch:  0019 D loss:-0.4408 G loss:-2.35\n",
      "Epoch:  0019 D loss:-0.4651 G loss:-2.458\n",
      "Epoch:  0019 D loss:-0.5242 G loss:-2.334\n",
      "Epoch:  0019 D loss:-0.4639 G loss:-2.524\n",
      "Epoch:  0019 D loss:-0.4685 G loss:-2.481\n",
      "Epoch:  0019 D loss:-0.3887 G loss:-2.424\n",
      "Epoch:  0019 D loss:-0.317 G loss:-2.527\n",
      "Epoch:  0019 D loss:-0.4034 G loss:-2.472\n",
      "Epoch:  0019 D loss:-0.3213 G loss:-2.521\n",
      "Epoch:  0019 D loss:-0.3967 G loss:-2.511\n",
      "Epoch:  0019 D loss:-0.5085 G loss:-2.258\n",
      "Epoch:  0019 D loss:-0.4347 G loss:-2.452\n",
      "Epoch:  0019 D loss:-0.3683 G loss:-2.486\n",
      "Epoch:  0019 D loss:-0.4985 G loss:-2.296\n",
      "Epoch:  0019 D loss:-0.3648 G loss:-2.343\n",
      "Epoch:  0019 D loss:-0.3627 G loss:-2.357\n",
      "Epoch:  0019 D loss:-0.4308 G loss:-2.224\n",
      "Epoch:  0019 D loss:-0.5388 G loss:-2.135\n",
      "Epoch:  0019 D loss:-0.4114 G loss:-2.475\n",
      "Epoch:  0019 D loss:-0.4487 G loss:-2.41\n",
      "Epoch:  0019 D loss:-0.3816 G loss:-2.46\n",
      "Epoch:  0019 D loss:-0.3997 G loss:-2.52\n",
      "Epoch:  0019 D loss:-0.4505 G loss:-2.407\n",
      "Epoch:  0019 D loss:-0.4416 G loss:-2.679\n",
      "Epoch:  0019 D loss:-0.441 G loss:-2.489\n",
      "Epoch:  0019 D loss:-0.4665 G loss:-2.527\n",
      "Epoch:  0019 D loss:-0.5168 G loss:-2.466\n",
      "Epoch:  0019 D loss:-0.4513 G loss:-2.2\n",
      "Epoch:  0019 D loss:-0.4016 G loss:-2.194\n",
      "Epoch:  0019 D loss:-0.5193 G loss:-2.126\n",
      "Epoch:  0019 D loss:-0.4149 G loss:-2.078\n",
      "Epoch:  0019 D loss:-0.4069 G loss:-2.028\n",
      "Epoch:  0019 D loss:-0.556 G loss:-2.19\n",
      "Epoch:  0019 D loss:-0.4445 G loss:-2.291\n",
      "Epoch:  0019 D loss:-0.4953 G loss:-2.243\n",
      "Epoch:  0019 D loss:-0.3878 G loss:-2.31\n",
      "Epoch:  0019 D loss:-0.4355 G loss:-2.428\n",
      "Epoch:  0019 D loss:-0.4506 G loss:-2.488\n",
      "Epoch:  0019 D loss:-0.3704 G loss:-2.582\n",
      "Epoch:  0019 D loss:-0.372 G loss:-2.578\n",
      "Epoch:  0019 D loss:-0.3522 G loss:-2.7\n",
      "Epoch:  0019 D loss:-0.4391 G loss:-2.573\n",
      "Epoch:  0019 D loss:-0.4263 G loss:-2.51\n",
      "Epoch:  0019 D loss:-0.3801 G loss:-2.658\n",
      "Epoch:  0019 D loss:-0.603 G loss:-2.483\n",
      "Epoch:  0019 D loss:-0.3816 G loss:-2.244\n",
      "Epoch:  0019 D loss:-0.5267 G loss:-2.155\n",
      "Epoch:  0019 D loss:-0.4172 G loss:-2.314\n",
      "Epoch:  0019 D loss:-0.4685 G loss:-2.074\n",
      "Epoch:  0019 D loss:-0.4456 G loss:-2.221\n",
      "Epoch:  0019 D loss:-0.4358 G loss:-2.156\n",
      "Epoch:  0019 D loss:-0.4201 G loss:-2.043\n",
      "Epoch:  0019 D loss:-0.4046 G loss:-2.11\n",
      "Epoch:  0019 D loss:-0.5107 G loss:-2.285\n",
      "Epoch:  0019 D loss:-0.4513 G loss:-2.499\n",
      "Epoch:  0019 D loss:-0.4996 G loss:-2.665\n",
      "Epoch:  0019 D loss:-0.3735 G loss:-2.622\n",
      "Epoch:  0019 D loss:-0.3814 G loss:-2.668\n",
      "Epoch:  0019 D loss:-0.4701 G loss:-2.71\n",
      "Epoch:  0019 D loss:-0.36 G loss:-2.492\n",
      "Epoch:  0019 D loss:-0.3665 G loss:-2.545\n",
      "Epoch:  0019 D loss:-0.4567 G loss:-2.533\n",
      "Epoch:  0019 D loss:-0.367 G loss:-2.298\n",
      "Epoch:  0019 D loss:-0.4188 G loss:-2.311\n",
      "Epoch:  0019 D loss:-0.4049 G loss:-2.265\n",
      "Epoch:  0019 D loss:-0.2697 G loss:-2.487\n",
      "Epoch:  0019 D loss:-0.3749 G loss:-2.425\n",
      "Epoch:  0019 D loss:-0.312 G loss:-2.425\n",
      "Epoch:  0019 D loss:-0.3515 G loss:-2.432\n",
      "Epoch:  0019 D loss:-0.3764 G loss:-2.463\n",
      "Epoch:  0019 D loss:-0.3503 G loss:-2.415\n",
      "Epoch:  0019 D loss:-0.3998 G loss:-2.437\n",
      "Epoch:  0019 D loss:-0.3514 G loss:-2.663\n",
      "Epoch:  0019 D loss:-0.3309 G loss:-2.673\n",
      "Epoch:  0019 D loss:-0.3831 G loss:-2.781\n",
      "Epoch:  0019 D loss:-0.4041 G loss:-2.636\n",
      "Epoch:  0019 D loss:-0.3813 G loss:-2.488\n",
      "Epoch:  0019 D loss:-0.365 G loss:-2.546\n",
      "Epoch:  0019 D loss:-0.2955 G loss:-2.618\n",
      "Epoch:  0019 D loss:-0.3022 G loss:-2.671\n",
      "Epoch:  0019 D loss:-0.3356 G loss:-2.551\n",
      "Epoch:  0019 D loss:-0.3882 G loss:-2.346\n",
      "Epoch:  0019 D loss:-0.4357 G loss:-2.336\n",
      "Epoch:  0019 D loss:-0.3601 G loss:-2.317\n",
      "Epoch:  0019 D loss:-0.325 G loss:-2.523\n",
      "Epoch:  0019 D loss:-0.3483 G loss:-2.578\n",
      "Epoch:  0019 D loss:-0.2835 G loss:-2.73\n",
      "Epoch:  0019 D loss:-0.3418 G loss:-2.739\n",
      "Epoch:  0019 D loss:-0.4108 G loss:-2.58\n",
      "Epoch:  0019 D loss:-0.3475 G loss:-2.72\n",
      "Epoch:  0019 D loss:-0.3277 G loss:-2.616\n",
      "Epoch:  0019 D loss:-0.2821 G loss:-2.743\n",
      "Epoch:  0019 D loss:-0.4062 G loss:-2.567\n",
      "Epoch:  0019 D loss:-0.3922 G loss:-2.503\n",
      "Epoch:  0019 D loss:-0.3477 G loss:-2.531\n",
      "Epoch:  0019 D loss:-0.2663 G loss:-2.514\n",
      "Epoch:  0019 D loss:-0.4039 G loss:-2.384\n",
      "Epoch:  0019 D loss:-0.3317 G loss:-2.425\n",
      "Epoch:  0019 D loss:-0.2539 G loss:-2.481\n",
      "Epoch:  0019 D loss:-0.3201 G loss:-2.547\n",
      "Epoch:  0019 D loss:-0.3269 G loss:-2.686\n",
      "Epoch:  0019 D loss:-0.2958 G loss:-2.553\n",
      "Epoch:  0019 D loss:-0.4162 G loss:-2.496\n",
      "Epoch:  0019 D loss:-0.3815 G loss:-2.457\n",
      "Epoch:  0019 D loss:-0.3765 G loss:-2.795\n",
      "Epoch:  0019 D loss:-0.3151 G loss:-2.615\n",
      "Epoch:  0019 D loss:-0.3443 G loss:-2.644\n",
      "Epoch:  0019 D loss:-0.2536 G loss:-2.598\n",
      "Epoch:  0019 D loss:-0.3121 G loss:-2.758\n",
      "Epoch:  0019 D loss:-0.382 G loss:-2.681\n",
      "Epoch:  0019 D loss:-0.3514 G loss:-2.581\n",
      "Epoch:  0019 D loss:-0.3913 G loss:-2.652\n",
      "Epoch:  0019 D loss:-0.3095 G loss:-2.646\n",
      "Epoch:  0019 D loss:-0.4391 G loss:-2.441\n",
      "Epoch:  0019 D loss:-0.3731 G loss:-2.509\n",
      "Epoch:  0019 D loss:-0.3021 G loss:-2.556\n",
      "Epoch:  0019 D loss:-0.3357 G loss:-2.411\n",
      "Epoch:  0019 D loss:-0.259 G loss:-2.728\n",
      "Epoch:  0019 D loss:-0.3139 G loss:-2.473\n",
      "Epoch:  0019 D loss:-0.3335 G loss:-2.597\n",
      "Epoch:  0019 D loss:-0.3632 G loss:-2.489\n",
      "Epoch:  0019 D loss:-0.3677 G loss:-2.5\n",
      "Epoch:  0019 D loss:-0.3621 G loss:-2.603\n",
      "Epoch:  0019 D loss:-0.3349 G loss:-2.776\n",
      "Epoch:  0019 D loss:-0.3211 G loss:-2.758\n",
      "Epoch:  0019 D loss:-0.4277 G loss:-2.751\n",
      "Epoch:  0019 D loss:-0.3268 G loss:-2.665\n",
      "Epoch:  0019 D loss:-0.3631 G loss:-2.655\n",
      "Epoch:  0019 D loss:-0.3756 G loss:-2.655\n",
      "Epoch:  0019 D loss:-0.3336 G loss:-2.597\n",
      "Epoch:  0019 D loss:-0.399 G loss:-2.519\n",
      "Epoch:  0019 D loss:-0.3879 G loss:-2.418\n",
      "Epoch:  0019 D loss:-0.4795 G loss:-2.367\n",
      "Epoch:  0019 D loss:-0.3811 G loss:-2.303\n",
      "Epoch:  0019 D loss:-0.4037 G loss:-2.227\n",
      "Epoch:  0019 D loss:-0.3999 G loss:-2.462\n",
      "Epoch:  0019 D loss:-0.3327 G loss:-2.494\n",
      "Epoch:  0019 D loss:-0.3818 G loss:-2.455\n",
      "Epoch:  0019 D loss:-0.3411 G loss:-2.49\n",
      "Epoch:  0019 D loss:-0.3623 G loss:-2.462\n",
      "Epoch:  0019 D loss:-0.4274 G loss:-2.485\n",
      "Epoch:  0019 D loss:-0.4506 G loss:-2.469\n",
      "Epoch:  0019 D loss:-0.447 G loss:-2.662\n",
      "Epoch:  0019 D loss:-0.3312 G loss:-2.581\n",
      "Epoch:  0019 D loss:-0.4414 G loss:-2.681\n",
      "Epoch:  0019 D loss:-0.4093 G loss:-2.413\n",
      "Epoch:  0019 D loss:-0.4575 G loss:-2.492\n",
      "Epoch:  0019 D loss:-0.3795 G loss:-2.361\n",
      "Epoch:  0019 D loss:-0.346 G loss:-2.298\n",
      "Epoch:  0019 D loss:-0.4282 G loss:-2.3\n",
      "Epoch:  0019 D loss:-0.3984 G loss:-2.411\n",
      "Epoch:  0019 D loss:-0.3787 G loss:-2.41\n",
      "Epoch:  0019 D loss:-0.3925 G loss:-2.529\n",
      "Epoch:  0019 D loss:-0.4638 G loss:-2.452\n",
      "Epoch:  0019 D loss:-0.3634 G loss:-2.491\n",
      "Epoch:  0019 D loss:-0.404 G loss:-2.568\n",
      "Epoch:  0019 D loss:-0.3537 G loss:-2.538\n",
      "Epoch:  0019 D loss:-0.3312 G loss:-2.523\n",
      "Epoch:  0019 D loss:-0.4319 G loss:-2.472\n",
      "Epoch:  0019 D loss:-0.3844 G loss:-2.549\n",
      "Epoch:  0019 D loss:-0.2698 G loss:-2.502\n",
      "Epoch:  0019 D loss:-0.4186 G loss:-2.586\n",
      "Epoch:  0019 D loss:-0.3292 G loss:-2.537\n",
      "Epoch:  0019 D loss:-0.4514 G loss:-2.269\n",
      "Epoch:  0019 D loss:-0.4496 G loss:-2.37\n",
      "Epoch:  0019 D loss:-0.4522 G loss:-2.423\n",
      "Epoch:  0019 D loss:-0.4319 G loss:-2.259\n",
      "Epoch:  0019 D loss:-0.5205 G loss:-2.131\n",
      "Epoch:  0019 D loss:-0.4409 G loss:-2.213\n",
      "Epoch:  0019 D loss:-0.3967 G loss:-2.321\n",
      "Epoch:  0019 D loss:-0.4265 G loss:-2.367\n",
      "Epoch:  0019 D loss:-0.3816 G loss:-2.561\n",
      "Epoch:  0019 D loss:-0.4096 G loss:-2.519\n",
      "Epoch:  0019 D loss:-0.4081 G loss:-2.59\n",
      "Epoch:  0019 D loss:-0.4393 G loss:-2.644\n",
      "Epoch:  0019 D loss:-0.3534 G loss:-2.515\n",
      "Epoch:  0019 D loss:-0.549 G loss:-2.299\n",
      "Epoch:  0019 D loss:-0.3305 G loss:-2.574\n",
      "Epoch:  0019 D loss:-0.4258 G loss:-2.251\n",
      "Epoch:  0019 D loss:-0.4437 G loss:-2.433\n",
      "Epoch:  0019 D loss:-0.4674 G loss:-2.24\n",
      "Epoch:  0019 D loss:-0.4227 G loss:-2.323\n",
      "Epoch:  0019 D loss:-0.4649 G loss:-2.213\n",
      "Epoch:  0019 D loss:-0.4236 G loss:-2.19\n",
      "Epoch:  0019 D loss:-0.445 G loss:-2.165\n",
      "Epoch:  0019 D loss:-0.471 G loss:-2.378\n",
      "Epoch:  0019 D loss:-0.4759 G loss:-2.372\n",
      "Epoch:  0019 D loss:-0.4437 G loss:-2.381\n",
      "Epoch:  0019 D loss:-0.5076 G loss:-2.385\n",
      "Epoch:  0019 D loss:-0.4423 G loss:-2.606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0019 D loss:-0.5072 G loss:-2.386\n",
      "Epoch:  0019 D loss:-0.3836 G loss:-2.549\n",
      "Epoch:  0019 D loss:-0.4534 G loss:-2.492\n",
      "Epoch:  0019 D loss:-0.4889 G loss:-2.365\n",
      "Epoch:  0019 D loss:-0.3855 G loss:-2.417\n",
      "Epoch:  0019 D loss:-0.5409 G loss:-2.194\n",
      "Epoch:  0019 D loss:-0.5852 G loss:-2.14\n",
      "Epoch:  0019 D loss:-0.3998 G loss:-2.289\n",
      "Epoch:  0019 D loss:-0.6138 G loss:-2.35\n",
      "Epoch:  0019 D loss:-0.4826 G loss:-2.373\n",
      "Epoch:  0019 D loss:-0.4286 G loss:-2.434\n",
      "Epoch:  0019 D loss:-0.3421 G loss:-2.407\n",
      "Epoch:  0019 D loss:-0.5571 G loss:-2.446\n",
      "Epoch:  0019 D loss:-0.4517 G loss:-2.429\n",
      "Epoch:  0019 D loss:-0.4507 G loss:-2.522\n",
      "Epoch:  0019 D loss:-0.429 G loss:-2.438\n",
      "Epoch:  0019 D loss:-0.4642 G loss:-2.483\n",
      "Epoch:  0019 D loss:-0.5261 G loss:-2.326\n",
      "Epoch:  0019 D loss:-0.3536 G loss:-2.363\n",
      "Epoch:  0019 D loss:-0.4092 G loss:-2.413\n",
      "Epoch:  0019 D loss:-0.3929 G loss:-2.37\n",
      "Epoch:  0019 D loss:-0.439 G loss:-2.185\n",
      "Epoch:  0019 D loss:-0.4899 G loss:-2.363\n",
      "Epoch:  0019 D loss:-0.4037 G loss:-2.369\n",
      "Epoch:  0019 D loss:-0.4677 G loss:-2.343\n",
      "Epoch:  0019 D loss:-0.4127 G loss:-2.446\n",
      "Epoch:  0019 D loss:-0.5022 G loss:-2.534\n",
      "Epoch:  0019 D loss:-0.4432 G loss:-2.377\n",
      "Epoch:  0019 D loss:-0.4342 G loss:-2.485\n",
      "Epoch:  0019 D loss:-0.5134 G loss:-2.468\n",
      "Epoch:  0019 D loss:-0.3855 G loss:-2.284\n",
      "Epoch:  0019 D loss:-0.4415 G loss:-2.357\n",
      "Epoch:  0019 D loss:-0.4662 G loss:-2.42\n",
      "Epoch:  0019 D loss:-0.3381 G loss:-2.522\n",
      "Epoch:  0019 D loss:-0.4503 G loss:-2.434\n",
      "Epoch:  0019 D loss:-0.4918 G loss:-2.413\n",
      "Epoch:  0019 D loss:-0.4505 G loss:-2.386\n",
      "Epoch:  0019 D loss:-0.4006 G loss:-2.32\n",
      "Epoch:  0019 D loss:-0.5236 G loss:-2.396\n",
      "Epoch:  0019 D loss:-0.4147 G loss:-2.391\n",
      "Epoch:  0019 D loss:-0.4223 G loss:-2.425\n",
      "Epoch:  0019 D loss:-0.4173 G loss:-2.47\n",
      "Epoch:  0019 D loss:-0.4375 G loss:-2.534\n",
      "Epoch:  0019 D loss:-0.4721 G loss:-2.588\n",
      "Epoch:  0019 D loss:-0.3876 G loss:-2.622\n",
      "Epoch:  0019 D loss:-0.5283 G loss:-2.383\n",
      "Epoch:  0019 D loss:-0.4372 G loss:-2.546\n",
      "Epoch:  0019 D loss:-0.3272 G loss:-2.668\n",
      "Epoch:  0019 D loss:-0.5205 G loss:-2.397\n",
      "Epoch:  0019 D loss:-0.5111 G loss:-2.595\n",
      "Epoch:  0019 D loss:-0.4854 G loss:-2.527\n",
      "Epoch:  0019 D loss:-0.4212 G loss:-2.462\n",
      "Epoch:  0019 D loss:-0.442 G loss:-2.138\n",
      "Epoch:  0019 D loss:-0.5003 G loss:-2.233\n",
      "Epoch:  0019 D loss:-0.4425 G loss:-2.377\n",
      "Epoch:  0019 D loss:-0.4691 G loss:-2.533\n",
      "Epoch:  0019 D loss:-0.3392 G loss:-2.668\n",
      "Epoch:  0019 D loss:-0.4152 G loss:-2.512\n",
      "Epoch:  0019 D loss:-0.4492 G loss:-2.684\n",
      "Epoch:  0019 D loss:-0.5067 G loss:-2.47\n",
      "Epoch:  0019 D loss:-0.441 G loss:-2.473\n",
      "Epoch:  0019 D loss:-0.4285 G loss:-2.564\n",
      "Epoch:  0019 D loss:-0.411 G loss:-2.513\n",
      "Epoch:  0019 D loss:-0.4415 G loss:-2.468\n",
      "Epoch:  0019 D loss:-0.5123 G loss:-2.455\n",
      "Epoch:  0019 D loss:-0.3678 G loss:-2.657\n",
      "Epoch:  0019 D loss:-0.4058 G loss:-2.667\n",
      "Epoch:  0019 D loss:-0.3974 G loss:-2.471\n",
      "Epoch:  0019 D loss:-0.4253 G loss:-2.381\n",
      "Epoch:  0019 D loss:-0.4376 G loss:-2.464\n",
      "Epoch:  0019 D loss:-0.4009 G loss:-2.6\n",
      "Epoch:  0019 D loss:-0.3953 G loss:-2.583\n",
      "Epoch:  0019 D loss:-0.4321 G loss:-2.713\n",
      "Epoch:  0019 D loss:-0.3747 G loss:-2.655\n",
      "Epoch:  0019 D loss:-0.4045 G loss:-2.624\n",
      "Epoch:  0019 D loss:-0.3132 G loss:-2.635\n",
      "Epoch:  0019 D loss:-0.4464 G loss:-2.557\n",
      "Epoch:  0019 D loss:-0.3671 G loss:-2.59\n",
      "Epoch:  0019 D loss:-0.3356 G loss:-2.57\n",
      "Epoch:  0019 D loss:-0.3376 G loss:-2.814\n",
      "Epoch:  0019 D loss:-0.4042 G loss:-2.671\n",
      "Epoch:  0019 D loss:-0.3402 G loss:-2.754\n",
      "Epoch:  0019 D loss:-0.3684 G loss:-2.68\n",
      "Epoch:  0019 D loss:-0.3428 G loss:-2.796\n",
      "Epoch:  0019 D loss:-0.3513 G loss:-2.717\n",
      "Epoch:  0019 D loss:-0.3697 G loss:-2.685\n",
      "Epoch:  0019 D loss:-0.4145 G loss:-2.741\n",
      "Epoch:  0019 D loss:-0.2605 G loss:-2.68\n",
      "Epoch:  0019 D loss:-0.3833 G loss:-2.511\n",
      "Epoch:  0019 D loss:-0.3901 G loss:-2.597\n",
      "Epoch:  0019 D loss:-0.3643 G loss:-2.791\n",
      "Epoch:  0019 D loss:-0.3912 G loss:-2.798\n",
      "Epoch:  0019 D loss:-0.3851 G loss:-2.661\n",
      "Epoch:  0019 D loss:-0.3125 G loss:-2.762\n",
      "Epoch:  0019 D loss:-0.3556 G loss:-2.707\n",
      "Epoch:  0019 D loss:-0.3307 G loss:-2.664\n",
      "Epoch:  0019 D loss:-0.377 G loss:-2.69\n",
      "Epoch:  0019 D loss:-0.3511 G loss:-2.722\n",
      "Epoch:  0019 D loss:-0.3526 G loss:-2.678\n",
      "Epoch:  0019 D loss:-0.2951 G loss:-2.777\n",
      "Epoch:  0019 D loss:-0.385 G loss:-2.611\n",
      "Epoch:  0019 D loss:-0.3884 G loss:-2.445\n",
      "Epoch:  0019 D loss:-0.3421 G loss:-2.646\n",
      "Epoch:  0019 D loss:-0.2886 G loss:-2.677\n",
      "Epoch:  0019 D loss:-0.3621 G loss:-2.539\n",
      "Epoch:  0019 D loss:-0.316 G loss:-2.508\n",
      "Epoch:  0019 D loss:-0.2976 G loss:-2.668\n",
      "Epoch:  0019 D loss:-0.2983 G loss:-2.736\n",
      "Epoch:  0019 D loss:-0.3045 G loss:-2.827\n",
      "Epoch:  0019 D loss:-0.2907 G loss:-2.84\n",
      "Epoch:  0019 D loss:-0.3904 G loss:-2.959\n",
      "Epoch:  0019 D loss:-0.3242 G loss:-2.737\n",
      "Epoch:  0019 D loss:-0.3509 G loss:-2.689\n",
      "Epoch:  0019 D loss:-0.3957 G loss:-2.663\n",
      "Epoch:  0019 D loss:-0.3244 G loss:-2.498\n",
      "Epoch:  0019 D loss:-0.3229 G loss:-2.639\n",
      "Epoch:  0019 D loss:-0.3849 G loss:-2.338\n",
      "Epoch:  0019 D loss:-0.3497 G loss:-2.524\n",
      "Epoch:  0019 D loss:-0.3472 G loss:-2.371\n",
      "Epoch:  0019 D loss:-0.3522 G loss:-2.473\n",
      "Epoch:  0019 D loss:-0.4081 G loss:-2.286\n",
      "Epoch:  0019 D loss:-0.2873 G loss:-2.602\n",
      "Epoch:  0019 D loss:-0.3251 G loss:-2.532\n",
      "Epoch:  0019 D loss:-0.4225 G loss:-2.597\n",
      "Epoch:  0019 D loss:-0.4329 G loss:-2.442\n",
      "Epoch:  0019 D loss:-0.3578 G loss:-2.695\n",
      "Epoch:  0019 D loss:-0.4124 G loss:-2.538\n",
      "Epoch:  0019 D loss:-0.3519 G loss:-2.499\n",
      "Epoch:  0019 D loss:-0.417 G loss:-2.544\n",
      "Epoch:  0019 D loss:-0.4281 G loss:-2.355\n",
      "Epoch:  0019 D loss:-0.3648 G loss:-2.318\n",
      "Epoch:  0019 D loss:-0.4033 G loss:-2.383\n",
      "Epoch:  0019 D loss:-0.3528 G loss:-2.51\n",
      "Epoch:  0019 D loss:-0.3884 G loss:-2.43\n",
      "Epoch:  0019 D loss:-0.3808 G loss:-2.369\n",
      "Epoch:  0019 D loss:-0.382 G loss:-2.557\n",
      "Epoch:  0019 D loss:-0.4286 G loss:-2.487\n",
      "Epoch:  0019 D loss:-0.4508 G loss:-2.502\n",
      "Epoch:  0019 D loss:-0.3517 G loss:-2.451\n",
      "Epoch:  0019 D loss:-0.3388 G loss:-2.54\n",
      "Epoch:  0019 D loss:-0.3982 G loss:-2.551\n",
      "Epoch:  0019 D loss:-0.5216 G loss:-2.298\n",
      "Epoch:  0019 D loss:-0.3592 G loss:-2.367\n",
      "Epoch:  0019 D loss:-0.3844 G loss:-2.298\n",
      "Epoch:  0019 D loss:-0.4254 G loss:-2.278\n",
      "Epoch:  0019 D loss:-0.3905 G loss:-2.347\n",
      "Epoch:  0019 D loss:-0.4424 G loss:-2.469\n",
      "Epoch:  0019 D loss:-0.4413 G loss:-2.27\n",
      "Epoch:  0019 D loss:-0.2664 G loss:-2.609\n",
      "Epoch:  0019 D loss:-0.3701 G loss:-2.594\n",
      "Epoch:  0019 D loss:-0.3793 G loss:-2.563\n",
      "Epoch:  0019 D loss:-0.4659 G loss:-2.64\n",
      "Epoch:  0019 D loss:-0.3795 G loss:-2.744\n",
      "Epoch:  0019 D loss:-0.4112 G loss:-2.528\n",
      "Epoch:  0019 D loss:-0.3847 G loss:-2.616\n",
      "Epoch:  0019 D loss:-0.4274 G loss:-2.263\n",
      "Epoch:  0019 D loss:-0.4771 G loss:-2.291\n",
      "Epoch:  0019 D loss:-0.4438 G loss:-2.164\n",
      "Epoch:  0019 D loss:-0.4873 G loss:-2.249\n",
      "Epoch:  0019 D loss:-0.4309 G loss:-2.284\n",
      "Epoch:  0019 D loss:-0.4549 G loss:-2.351\n",
      "Epoch:  0019 D loss:-0.4872 G loss:-2.202\n",
      "Epoch:  0019 D loss:-0.4969 G loss:-2.165\n",
      "Epoch:  0019 D loss:-0.493 G loss:-2.388\n",
      "Epoch:  0019 D loss:-0.5006 G loss:-2.148\n",
      "Epoch:  0019 D loss:-0.4829 G loss:-2.166\n",
      "Epoch:  0019 D loss:-0.4799 G loss:-2.284\n",
      "Epoch:  0019 D loss:-0.42 G loss:-2.137\n",
      "Epoch:  0019 D loss:-0.4418 G loss:-2.43\n",
      "Epoch:  0019 D loss:-0.601 G loss:-2.16\n",
      "Epoch:  0019 D loss:-0.4757 G loss:-2.233\n",
      "Epoch:  0019 D loss:-0.4987 G loss:-2.243\n",
      "Epoch:  0019 D loss:-0.4409 G loss:-2.258\n",
      "Epoch:  0019 D loss:-0.4294 G loss:-2.245\n",
      "Epoch:  0019 D loss:-0.6102 G loss:-2.228\n",
      "Epoch:  0019 D loss:-0.4513 G loss:-2.13\n",
      "Epoch:  0019 D loss:-0.4734 G loss:-2.243\n",
      "Epoch:  0019 D loss:-0.5365 G loss:-2.201\n",
      "Epoch:  0019 D loss:-0.5451 G loss:-2.178\n",
      "Epoch:  0019 D loss:-0.4344 G loss:-2.243\n",
      "Epoch:  0019 D loss:-0.5043 G loss:-2.276\n",
      "Epoch:  0019 D loss:-0.4496 G loss:-2.315\n",
      "Epoch:  0019 D loss:-0.619 G loss:-2.122\n",
      "Epoch:  0019 D loss:-0.6546 G loss:-2.207\n",
      "Epoch:  0019 D loss:-0.4667 G loss:-2.324\n",
      "Epoch:  0019 D loss:-0.4172 G loss:-2.431\n",
      "Epoch:  0019 D loss:-0.4721 G loss:-2.363\n",
      "Epoch:  0019 D loss:-0.4044 G loss:-2.523\n",
      "Epoch:  0019 D loss:-0.4266 G loss:-2.363\n",
      "Epoch:  0019 D loss:-0.4628 G loss:-2.326\n",
      "Epoch:  0019 D loss:-0.5639 G loss:-2.35\n",
      "Epoch:  0019 D loss:-0.4242 G loss:-2.441\n",
      "Epoch:  0019 D loss:-0.48 G loss:-2.325\n",
      "Epoch:  0019 D loss:-0.5467 G loss:-2.202\n",
      "Epoch:  0019 D loss:-0.4796 G loss:-2.412\n",
      "Epoch:  0019 D loss:-0.3835 G loss:-2.299\n",
      "Epoch:  0019 D loss:-0.3967 G loss:-2.253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0019 D loss:-0.4488 G loss:-2.155\n",
      "Epoch:  0019 D loss:-0.4788 G loss:-2.197\n",
      "Epoch:  0019 D loss:-0.3298 G loss:-2.329\n",
      "Epoch:  0019 D loss:-0.3763 G loss:-2.643\n",
      "Epoch:  0019 D loss:-0.4293 G loss:-2.435\n",
      "Epoch:  0019 D loss:-0.4233 G loss:-2.427\n",
      "Epoch:  0019 D loss:-0.368 G loss:-2.427\n",
      "Epoch:  0019 D loss:-0.4257 G loss:-2.449\n",
      "Epoch:  0019 D loss:-0.4605 G loss:-2.498\n",
      "Epoch:  0019 D loss:-0.436 G loss:-2.443\n",
      "Epoch:  0019 D loss:-0.4858 G loss:-2.266\n",
      "Epoch:  0019 D loss:-0.4148 G loss:-2.391\n",
      "Epoch:  0019 D loss:-0.4016 G loss:-2.504\n",
      "Epoch:  0019 D loss:-0.3872 G loss:-2.255\n",
      "Epoch:  0019 D loss:-0.4072 G loss:-2.328\n",
      "Epoch:  0019 D loss:-0.47 G loss:-2.177\n",
      "Epoch:  0019 D loss:-0.3428 G loss:-2.361\n",
      "Epoch:  0019 D loss:-0.3909 G loss:-2.34\n",
      "Epoch:  0019 D loss:-0.395 G loss:-2.365\n",
      "Epoch:  0019 D loss:-0.3729 G loss:-2.331\n",
      "Epoch:  0019 D loss:-0.4274 G loss:-2.483\n",
      "Epoch:  0019 D loss:-0.3263 G loss:-2.494\n",
      "Epoch:  0019 D loss:-0.4066 G loss:-2.914\n",
      "Epoch:  0019 D loss:-0.3824 G loss:-2.752\n",
      "Epoch:  0019 D loss:-0.4195 G loss:-2.62\n",
      "Epoch:  0019 D loss:-0.4034 G loss:-2.536\n",
      "Epoch:  0019 D loss:-0.4797 G loss:-2.637\n",
      "Epoch:  0019 D loss:-0.3061 G loss:-2.49\n",
      "Epoch:  0019 D loss:-0.3713 G loss:-2.492\n",
      "Epoch:  0019 D loss:-0.3823 G loss:-2.256\n",
      "Epoch:  0019 D loss:-0.377 G loss:-2.325\n",
      "Epoch:  0019 D loss:-0.4342 G loss:-2.34\n",
      "Epoch:  0019 D loss:-0.2903 G loss:-2.372\n",
      "Epoch:  0019 D loss:-0.4409 G loss:-2.398\n",
      "Epoch:  0019 D loss:-0.4281 G loss:-2.266\n",
      "Epoch:  0019 D loss:-0.3954 G loss:-2.253\n",
      "Epoch:  0019 D loss:-0.3843 G loss:-2.443\n",
      "Epoch:  0019 D loss:-0.3503 G loss:-2.467\n",
      "Epoch:  0019 D loss:-0.3406 G loss:-2.568\n",
      "Epoch:  0019 D loss:-0.354 G loss:-2.694\n",
      "Epoch:  0019 D loss:-0.411 G loss:-2.638\n",
      "Epoch:  0019 D loss:-0.41 G loss:-2.733\n",
      "Epoch:  0019 D loss:-0.3496 G loss:-2.76\n",
      "Epoch:  0019 D loss:-0.3743 G loss:-2.59\n",
      "Epoch:  0019 D loss:-0.2951 G loss:-2.82\n",
      "Epoch:  0019 D loss:-0.354 G loss:-2.691\n",
      "Epoch:  0019 D loss:-0.3317 G loss:-2.837\n",
      "Epoch:  0019 D loss:-0.3471 G loss:-2.545\n",
      "Epoch:  0019 D loss:-0.3559 G loss:-2.564\n",
      "Epoch:  0019 D loss:-0.3108 G loss:-2.458\n",
      "Epoch:  0019 D loss:-0.4106 G loss:-2.399\n",
      "Epoch:  0019 D loss:-0.3621 G loss:-2.773\n",
      "Epoch:  0019 D loss:-0.3655 G loss:-2.574\n",
      "Epoch:  0019 D loss:-0.3755 G loss:-2.5\n",
      "Epoch:  0019 D loss:-0.3604 G loss:-2.552\n",
      "Epoch:  0019 D loss:-0.3438 G loss:-2.629\n",
      "Epoch:  0019 D loss:-0.3991 G loss:-2.598\n",
      "Epoch:  0019 D loss:-0.3212 G loss:-2.673\n",
      "Epoch:  0019 D loss:-0.2935 G loss:-2.635\n",
      "Epoch:  0019 D loss:-0.3636 G loss:-2.521\n",
      "Epoch:  0019 D loss:-0.4725 G loss:-2.554\n",
      "Epoch:  0019 D loss:-0.3464 G loss:-2.856\n",
      "Epoch:  0019 D loss:-0.403 G loss:-2.702\n",
      "Epoch:  0019 D loss:-0.4049 G loss:-2.723\n",
      "Epoch:  0019 D loss:-0.3897 G loss:-2.586\n",
      "Epoch:  0019 D loss:-0.3845 G loss:-2.52\n",
      "Epoch:  0019 D loss:-0.3126 G loss:-2.413\n",
      "Epoch:  0019 D loss:-0.3569 G loss:-2.397\n",
      "Epoch:  0019 D loss:-0.3181 G loss:-2.512\n",
      "Epoch:  0019 D loss:-0.3257 G loss:-2.622\n",
      "Epoch:  0019 D loss:-0.3018 G loss:-2.696\n",
      "Epoch:  0019 D loss:-0.3764 G loss:-2.469\n",
      "Epoch:  0019 D loss:-0.3163 G loss:-2.656\n",
      "Epoch:  0019 D loss:-0.3326 G loss:-2.662\n",
      "Epoch:  0019 D loss:-0.4219 G loss:-2.648\n",
      "Epoch:  0019 D loss:-0.2743 G loss:-2.854\n",
      "Epoch:  0019 D loss:-0.3108 G loss:-2.599\n",
      "Epoch:  0019 D loss:-0.3701 G loss:-2.663\n",
      "Epoch:  0019 D loss:-0.4431 G loss:-2.504\n",
      "Epoch:  0019 D loss:-0.3195 G loss:-2.598\n",
      "Epoch:  0019 D loss:-0.3531 G loss:-2.593\n",
      "Epoch:  0019 D loss:-0.2895 G loss:-2.698\n",
      "Epoch:  0019 D loss:-0.3397 G loss:-2.554\n",
      "Epoch:  0019 D loss:-0.4294 G loss:-2.555\n",
      "Epoch:  0019 D loss:-0.4584 G loss:-2.54\n",
      "Epoch:  0019 D loss:-0.3893 G loss:-2.672\n",
      "Epoch:  0019 D loss:-0.4348 G loss:-2.589\n",
      "Epoch:  0019 D loss:-0.3007 G loss:-2.544\n",
      "Epoch:  0019 D loss:-0.4255 G loss:-2.677\n",
      "Epoch:  0019 D loss:-0.378 G loss:-2.609\n",
      "Epoch:  0019 D loss:-0.3638 G loss:-2.333\n",
      "Epoch:  0019 D loss:-0.3921 G loss:-2.503\n",
      "Epoch:  0019 D loss:-0.4465 G loss:-2.42\n",
      "Epoch:  0019 D loss:-0.3249 G loss:-2.679\n",
      "Epoch:  0019 D loss:-0.4199 G loss:-2.684\n",
      "Epoch:  0019 D loss:-0.3504 G loss:-2.683\n",
      "Epoch:  0019 D loss:-0.3467 G loss:-2.503\n",
      "Epoch:  0019 D loss:-0.4382 G loss:-2.434\n",
      "Epoch:  0019 D loss:-0.4202 G loss:-2.524\n",
      "Epoch:  0019 D loss:-0.3506 G loss:-2.377\n",
      "Epoch:  0019 D loss:-0.4043 G loss:-2.538\n",
      "Epoch:  0019 D loss:-0.4656 G loss:-2.305\n",
      "Epoch:  0019 D loss:-0.4263 G loss:-2.232\n",
      "Epoch:  0019 D loss:-0.4522 G loss:-2.237\n",
      "Epoch:  0019 D loss:-0.5043 G loss:-2.191\n",
      "Epoch:  0019 D loss:-0.4141 G loss:-2.37\n",
      "Epoch:  0019 D loss:-0.5255 G loss:-2.292\n",
      "Epoch:  0019 D loss:-0.3848 G loss:-2.347\n",
      "Epoch:  0019 D loss:-0.5498 G loss:-2.239\n",
      "Epoch:  0019 D loss:-0.4314 G loss:-2.365\n",
      "Epoch:  0019 D loss:-0.5132 G loss:-2.392\n",
      "Epoch:  0019 D loss:-0.4635 G loss:-2.598\n",
      "Epoch:  0019 D loss:-0.4333 G loss:-2.64\n",
      "Epoch:  0019 D loss:-0.6012 G loss:-2.456\n",
      "Epoch:  0019 D loss:-0.4001 G loss:-2.555\n",
      "Epoch:  0019 D loss:-0.4938 G loss:-2.343\n",
      "Epoch:  0019 D loss:-0.4475 G loss:-2.259\n",
      "Epoch:  0019 D loss:-0.4021 G loss:-2.148\n",
      "Epoch:  0019 D loss:-0.4661 G loss:-2.367\n",
      "Epoch:  0019 D loss:-0.5519 G loss:-2.237\n",
      "Epoch:  0019 D loss:-0.4683 G loss:-2.33\n",
      "Epoch:  0019 D loss:-0.6371 G loss:-2.195\n",
      "Epoch:  0019 D loss:-0.6133 G loss:-2.099\n",
      "Epoch:  0019 D loss:-0.6586 G loss:-2.004\n",
      "Epoch:  0019 D loss:-0.5774 G loss:-2.032\n",
      "Epoch:  0019 D loss:-0.4516 G loss:-2.358\n",
      "Epoch:  0019 D loss:-0.566 G loss:-2.127\n",
      "Epoch:  0019 D loss:-0.5455 G loss:-2.244\n",
      "Epoch:  0019 D loss:-0.6249 G loss:-2.144\n",
      "Epoch:  0019 D loss:-0.5211 G loss:-2.211\n",
      "Epoch:  0019 D loss:-0.5428 G loss:-2.276\n",
      "Epoch:  0019 D loss:-0.5399 G loss:-2.216\n",
      "Epoch:  0019 D loss:-0.482 G loss:-2.348\n",
      "Epoch:  0019 D loss:-0.4975 G loss:-2.444\n",
      "Epoch:  0019 D loss:-0.5809 G loss:-2.537\n",
      "Epoch:  0019 D loss:-0.5273 G loss:-2.41\n",
      "Epoch:  0019 D loss:-0.5944 G loss:-2.354\n",
      "Epoch:  0019 D loss:-0.6862 G loss:-2.032\n",
      "Epoch:  0019 D loss:-0.5406 G loss:-2.472\n",
      "Epoch:  0019 D loss:-0.4662 G loss:-2.207\n",
      "Epoch:  0019 D loss:-0.7036 G loss:-2.073\n",
      "Epoch:  0019 D loss:-0.6726 G loss:-1.997\n",
      "Epoch:  0019 D loss:-0.5557 G loss:-2.041\n",
      "Epoch:  0019 D loss:-0.5434 G loss:-1.995\n",
      "Epoch:  0019 D loss:-0.4772 G loss:-2.195\n",
      "Epoch:  0019 D loss:-0.5831 G loss:-2.111\n",
      "Epoch:  0019 D loss:-0.5499 G loss:-2.312\n",
      "Epoch:  0019 D loss:-0.591 G loss:-2.212\n",
      "Epoch:  0019 D loss:-0.5934 G loss:-2.314\n",
      "Epoch:  0019 D loss:-0.487 G loss:-2.326\n",
      "Epoch:  0019 D loss:-0.6274 G loss:-2.237\n",
      "Epoch:  0019 D loss:-0.4803 G loss:-2.268\n",
      "Epoch:  0019 D loss:-0.5345 G loss:-2.365\n",
      "Epoch:  0019 D loss:-0.5129 G loss:-2.476\n",
      "Epoch:  0019 D loss:-0.5241 G loss:-2.325\n",
      "Epoch:  0019 D loss:-0.6413 G loss:-2.225\n",
      "Epoch:  0019 D loss:-0.5561 G loss:-2.187\n",
      "Epoch:  0019 D loss:-0.4008 G loss:-2.276\n",
      "Epoch:  0019 D loss:-0.4742 G loss:-2.256\n",
      "Epoch:  0019 D loss:-0.5476 G loss:-2.305\n",
      "Epoch:  0020 D loss:-0.6231 G loss:-2.228\n",
      "Epoch:  0020 D loss:-0.5908 G loss:-2.149\n",
      "Epoch:  0020 D loss:-0.4837 G loss:-2.271\n",
      "Epoch:  0020 D loss:-0.6246 G loss:-2.11\n",
      "Epoch:  0020 D loss:-0.5608 G loss:-2.252\n",
      "Epoch:  0020 D loss:-0.5089 G loss:-2.382\n",
      "Epoch:  0020 D loss:-0.4702 G loss:-2.284\n",
      "Epoch:  0020 D loss:-0.4784 G loss:-2.538\n",
      "Epoch:  0020 D loss:-0.4178 G loss:-2.559\n",
      "Epoch:  0020 D loss:-0.443 G loss:-2.409\n",
      "Epoch:  0020 D loss:-0.5362 G loss:-2.296\n",
      "Epoch:  0020 D loss:-0.4153 G loss:-2.678\n",
      "Epoch:  0020 D loss:-0.5311 G loss:-2.835\n",
      "Epoch:  0020 D loss:-0.5369 G loss:-2.556\n",
      "Epoch:  0020 D loss:-0.5044 G loss:-2.538\n",
      "Epoch:  0020 D loss:-0.4865 G loss:-2.711\n",
      "Epoch:  0020 D loss:-0.4287 G loss:-2.52\n",
      "Epoch:  0020 D loss:-0.3928 G loss:-2.428\n",
      "Epoch:  0020 D loss:-0.4138 G loss:-2.58\n",
      "Epoch:  0020 D loss:-0.3968 G loss:-2.526\n",
      "Epoch:  0020 D loss:-0.5517 G loss:-2.425\n",
      "Epoch:  0020 D loss:-0.4749 G loss:-2.678\n",
      "Epoch:  0020 D loss:-0.5353 G loss:-2.235\n",
      "Epoch:  0020 D loss:-0.2953 G loss:-2.299\n",
      "Epoch:  0020 D loss:-0.4727 G loss:-2.392\n",
      "Epoch:  0020 D loss:-0.403 G loss:-2.559\n",
      "Epoch:  0020 D loss:-0.3106 G loss:-2.586\n",
      "Epoch:  0020 D loss:-0.5159 G loss:-2.353\n",
      "Epoch:  0020 D loss:-0.4844 G loss:-2.639\n",
      "Epoch:  0020 D loss:-0.2967 G loss:-2.727\n",
      "Epoch:  0020 D loss:-0.4203 G loss:-2.706\n",
      "Epoch:  0020 D loss:-0.5252 G loss:-2.953\n",
      "Epoch:  0020 D loss:-0.4255 G loss:-2.675\n",
      "Epoch:  0020 D loss:-0.4739 G loss:-2.875\n",
      "Epoch:  0020 D loss:-0.3781 G loss:-2.647\n",
      "Epoch:  0020 D loss:-0.4527 G loss:-2.649\n",
      "Epoch:  0020 D loss:-0.385 G loss:-2.784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0020 D loss:-0.3521 G loss:-2.599\n",
      "Epoch:  0020 D loss:-0.375 G loss:-2.793\n",
      "Epoch:  0020 D loss:-0.3796 G loss:-2.69\n",
      "Epoch:  0020 D loss:-0.3676 G loss:-2.785\n",
      "Epoch:  0020 D loss:-0.3513 G loss:-2.699\n",
      "Epoch:  0020 D loss:-0.3012 G loss:-2.619\n",
      "Epoch:  0020 D loss:-0.462 G loss:-2.45\n",
      "Epoch:  0020 D loss:-0.3844 G loss:-2.682\n",
      "Epoch:  0020 D loss:-0.3416 G loss:-2.45\n",
      "Epoch:  0020 D loss:-0.4453 G loss:-2.209\n",
      "Epoch:  0020 D loss:-0.3672 G loss:-2.522\n",
      "Epoch:  0020 D loss:-0.4779 G loss:-2.282\n",
      "Epoch:  0020 D loss:-0.3803 G loss:-2.342\n",
      "Epoch:  0020 D loss:-0.3835 G loss:-2.414\n",
      "Epoch:  0020 D loss:-0.4208 G loss:-2.677\n",
      "Epoch:  0020 D loss:-0.3982 G loss:-2.502\n",
      "Epoch:  0020 D loss:-0.4619 G loss:-2.539\n",
      "Epoch:  0020 D loss:-0.3871 G loss:-2.628\n",
      "Epoch:  0020 D loss:-0.3199 G loss:-2.834\n",
      "Epoch:  0020 D loss:-0.4824 G loss:-2.61\n",
      "Epoch:  0020 D loss:-0.3754 G loss:-2.574\n",
      "Epoch:  0020 D loss:-0.4611 G loss:-2.382\n",
      "Epoch:  0020 D loss:-0.3546 G loss:-2.506\n",
      "Epoch:  0020 D loss:-0.3205 G loss:-2.657\n",
      "Epoch:  0020 D loss:-0.285 G loss:-2.6\n",
      "Epoch:  0020 D loss:-0.3262 G loss:-2.736\n",
      "Epoch:  0020 D loss:-0.3077 G loss:-2.798\n",
      "Epoch:  0020 D loss:-0.3684 G loss:-2.928\n",
      "Epoch:  0020 D loss:-0.2976 G loss:-2.891\n",
      "Epoch:  0020 D loss:-0.3861 G loss:-2.533\n",
      "Epoch:  0020 D loss:-0.3238 G loss:-2.894\n",
      "Epoch:  0020 D loss:-0.2741 G loss:-2.94\n",
      "Epoch:  0020 D loss:-0.3147 G loss:-2.526\n",
      "Epoch:  0020 D loss:-0.2663 G loss:-2.753\n",
      "Epoch:  0020 D loss:-0.3973 G loss:-2.616\n",
      "Epoch:  0020 D loss:-0.335 G loss:-2.768\n",
      "Epoch:  0020 D loss:-0.396 G loss:-2.9\n",
      "Epoch:  0020 D loss:-0.3341 G loss:-2.794\n",
      "Epoch:  0020 D loss:-0.3776 G loss:-2.898\n",
      "Epoch:  0020 D loss:-0.3113 G loss:-2.679\n",
      "Epoch:  0020 D loss:-0.3685 G loss:-2.597\n",
      "Epoch:  0020 D loss:-0.3177 G loss:-2.674\n",
      "Epoch:  0020 D loss:-0.2979 G loss:-2.72\n",
      "Epoch:  0020 D loss:-0.3605 G loss:-2.484\n",
      "Epoch:  0020 D loss:-0.2939 G loss:-2.74\n",
      "Epoch:  0020 D loss:-0.3646 G loss:-2.442\n",
      "Epoch:  0020 D loss:-0.3461 G loss:-2.529\n",
      "Epoch:  0020 D loss:-0.283 G loss:-2.967\n",
      "Epoch:  0020 D loss:-0.2822 G loss:-2.852\n",
      "Epoch:  0020 D loss:-0.2722 G loss:-2.881\n",
      "Epoch:  0020 D loss:-0.2882 G loss:-2.962\n",
      "Epoch:  0020 D loss:-0.3421 G loss:-3.06\n",
      "Epoch:  0020 D loss:-0.3162 G loss:-2.846\n",
      "Epoch:  0020 D loss:-0.3588 G loss:-2.87\n",
      "Epoch:  0020 D loss:-0.2911 G loss:-2.704\n",
      "Epoch:  0020 D loss:-0.3517 G loss:-2.72\n",
      "Epoch:  0020 D loss:-0.3447 G loss:-2.682\n",
      "Epoch:  0020 D loss:-0.2895 G loss:-2.666\n",
      "Epoch:  0020 D loss:-0.3196 G loss:-2.729\n",
      "Epoch:  0020 D loss:-0.4044 G loss:-2.478\n",
      "Epoch:  0020 D loss:-0.346 G loss:-2.556\n",
      "Epoch:  0020 D loss:-0.325 G loss:-2.525\n",
      "Epoch:  0020 D loss:-0.3854 G loss:-2.491\n",
      "Epoch:  0020 D loss:-0.3111 G loss:-2.618\n",
      "Epoch:  0020 D loss:-0.3593 G loss:-2.451\n",
      "Epoch:  0020 D loss:-0.3734 G loss:-2.402\n",
      "Epoch:  0020 D loss:-0.3648 G loss:-2.299\n",
      "Epoch:  0020 D loss:-0.4843 G loss:-2.455\n",
      "Epoch:  0020 D loss:-0.38 G loss:-2.53\n",
      "Epoch:  0020 D loss:-0.3736 G loss:-2.636\n",
      "Epoch:  0020 D loss:-0.3243 G loss:-2.612\n",
      "Epoch:  0020 D loss:-0.3667 G loss:-2.603\n",
      "Epoch:  0020 D loss:-0.3599 G loss:-2.665\n",
      "Epoch:  0020 D loss:-0.343 G loss:-2.681\n",
      "Epoch:  0020 D loss:-0.347 G loss:-2.459\n",
      "Epoch:  0020 D loss:-0.4142 G loss:-2.565\n",
      "Epoch:  0020 D loss:-0.3613 G loss:-2.707\n",
      "Epoch:  0020 D loss:-0.4218 G loss:-2.551\n",
      "Epoch:  0020 D loss:-0.4044 G loss:-2.518\n",
      "Epoch:  0020 D loss:-0.3423 G loss:-2.469\n",
      "Epoch:  0020 D loss:-0.4088 G loss:-2.446\n",
      "Epoch:  0020 D loss:-0.4329 G loss:-2.312\n",
      "Epoch:  0020 D loss:-0.3903 G loss:-2.154\n",
      "Epoch:  0020 D loss:-0.3682 G loss:-2.368\n",
      "Epoch:  0020 D loss:-0.4307 G loss:-2.24\n",
      "Epoch:  0020 D loss:-0.4203 G loss:-2.242\n",
      "Epoch:  0020 D loss:-0.4134 G loss:-2.192\n",
      "Epoch:  0020 D loss:-0.4803 G loss:-2.084\n",
      "Epoch:  0020 D loss:-0.4357 G loss:-2.598\n",
      "Epoch:  0020 D loss:-0.3986 G loss:-2.377\n",
      "Epoch:  0020 D loss:-0.4108 G loss:-2.452\n",
      "Epoch:  0020 D loss:-0.4432 G loss:-2.702\n",
      "Epoch:  0020 D loss:-0.4135 G loss:-2.732\n",
      "Epoch:  0020 D loss:-0.4213 G loss:-2.558\n",
      "Epoch:  0020 D loss:-0.3787 G loss:-2.517\n",
      "Epoch:  0020 D loss:-0.3913 G loss:-2.513\n",
      "Epoch:  0020 D loss:-0.3753 G loss:-2.576\n",
      "Epoch:  0020 D loss:-0.3544 G loss:-2.447\n",
      "Epoch:  0020 D loss:-0.3841 G loss:-2.329\n",
      "Epoch:  0020 D loss:-0.481 G loss:-2.074\n",
      "Epoch:  0020 D loss:-0.3751 G loss:-2.46\n",
      "Epoch:  0020 D loss:-0.4828 G loss:-2.164\n",
      "Epoch:  0020 D loss:-0.371 G loss:-2.451\n",
      "Epoch:  0020 D loss:-0.3982 G loss:-2.36\n",
      "Epoch:  0020 D loss:-0.452 G loss:-2.336\n",
      "Epoch:  0020 D loss:-0.4326 G loss:-2.47\n",
      "Epoch:  0020 D loss:-0.4553 G loss:-2.304\n",
      "Epoch:  0020 D loss:-0.3937 G loss:-2.379\n",
      "Epoch:  0020 D loss:-0.5178 G loss:-2.258\n",
      "Epoch:  0020 D loss:-0.3498 G loss:-2.42\n",
      "Epoch:  0020 D loss:-0.5067 G loss:-2.448\n",
      "Epoch:  0020 D loss:-0.5005 G loss:-2.358\n",
      "Epoch:  0020 D loss:-0.5074 G loss:-2.253\n",
      "Epoch:  0020 D loss:-0.4807 G loss:-2.234\n",
      "Epoch:  0020 D loss:-0.5502 G loss:-2.329\n",
      "Epoch:  0020 D loss:-0.516 G loss:-2.132\n",
      "Epoch:  0020 D loss:-0.4563 G loss:-2.075\n",
      "Epoch:  0020 D loss:-0.4448 G loss:-2.073\n",
      "Epoch:  0020 D loss:-0.4323 G loss:-2.259\n",
      "Epoch:  0020 D loss:-0.4877 G loss:-2.359\n",
      "Epoch:  0020 D loss:-0.4348 G loss:-2.192\n",
      "Epoch:  0020 D loss:-0.5657 G loss:-2.294\n",
      "Epoch:  0020 D loss:-0.4588 G loss:-2.294\n",
      "Epoch:  0020 D loss:-0.5771 G loss:-2.161\n",
      "Epoch:  0020 D loss:-0.4933 G loss:-2.282\n",
      "Epoch:  0020 D loss:-0.5485 G loss:-2.398\n",
      "Epoch:  0020 D loss:-0.5097 G loss:-2.098\n",
      "Epoch:  0020 D loss:-0.4892 G loss:-2.253\n",
      "Epoch:  0020 D loss:-0.5163 G loss:-2.301\n",
      "Epoch:  0020 D loss:-0.5829 G loss:-2.172\n",
      "Epoch:  0020 D loss:-0.5082 G loss:-2.072\n",
      "Epoch:  0020 D loss:-0.4169 G loss:-2.137\n",
      "Epoch:  0020 D loss:-0.5167 G loss:-2.158\n",
      "Epoch:  0020 D loss:-0.6263 G loss:-2.056\n",
      "Epoch:  0020 D loss:-0.5656 G loss:-2.226\n",
      "Epoch:  0020 D loss:-0.5267 G loss:-2.235\n",
      "Epoch:  0020 D loss:-0.4596 G loss:-2.223\n",
      "Epoch:  0020 D loss:-0.4765 G loss:-2.209\n",
      "Epoch:  0020 D loss:-0.5214 G loss:-2.359\n",
      "Epoch:  0020 D loss:-0.5139 G loss:-2.303\n",
      "Epoch:  0020 D loss:-0.4458 G loss:-2.298\n",
      "Epoch:  0020 D loss:-0.5455 G loss:-2.347\n",
      "Epoch:  0020 D loss:-0.3885 G loss:-2.502\n",
      "Epoch:  0020 D loss:-0.5818 G loss:-2.133\n",
      "Epoch:  0020 D loss:-0.4421 G loss:-2.245\n",
      "Epoch:  0020 D loss:-0.4048 G loss:-2.305\n",
      "Epoch:  0020 D loss:-0.4094 G loss:-2.391\n",
      "Epoch:  0020 D loss:-0.4821 G loss:-2.187\n",
      "Epoch:  0020 D loss:-0.333 G loss:-2.521\n",
      "Epoch:  0020 D loss:-0.519 G loss:-2.212\n",
      "Epoch:  0020 D loss:-0.4911 G loss:-2.353\n",
      "Epoch:  0020 D loss:-0.4982 G loss:-2.252\n",
      "Epoch:  0020 D loss:-0.3712 G loss:-2.387\n",
      "Epoch:  0020 D loss:-0.4954 G loss:-2.271\n",
      "Epoch:  0020 D loss:-0.5618 G loss:-2.161\n",
      "Epoch:  0020 D loss:-0.4614 G loss:-2.36\n",
      "Epoch:  0020 D loss:-0.3942 G loss:-2.31\n",
      "Epoch:  0020 D loss:-0.4746 G loss:-2.492\n",
      "Epoch:  0020 D loss:-0.5003 G loss:-2.358\n",
      "Epoch:  0020 D loss:-0.4265 G loss:-2.291\n",
      "Epoch:  0020 D loss:-0.4321 G loss:-2.353\n",
      "Epoch:  0020 D loss:-0.3588 G loss:-2.43\n",
      "Epoch:  0020 D loss:-0.4713 G loss:-2.367\n",
      "Epoch:  0020 D loss:-0.4864 G loss:-2.16\n",
      "Epoch:  0020 D loss:-0.4194 G loss:-2.01\n",
      "Epoch:  0020 D loss:-0.4008 G loss:-2.216\n",
      "Epoch:  0020 D loss:-0.3826 G loss:-2.21\n",
      "Epoch:  0020 D loss:-0.3953 G loss:-2.455\n",
      "Epoch:  0020 D loss:-0.3433 G loss:-2.494\n",
      "Epoch:  0020 D loss:-0.4125 G loss:-2.392\n",
      "Epoch:  0020 D loss:-0.3973 G loss:-2.632\n",
      "Epoch:  0020 D loss:-0.332 G loss:-2.543\n",
      "Epoch:  0020 D loss:-0.3823 G loss:-2.513\n",
      "Epoch:  0020 D loss:-0.3781 G loss:-2.826\n",
      "Epoch:  0020 D loss:-0.3724 G loss:-2.506\n",
      "Epoch:  0020 D loss:-0.4893 G loss:-2.569\n",
      "Epoch:  0020 D loss:-0.3963 G loss:-2.307\n",
      "Epoch:  0020 D loss:-0.5135 G loss:-2.304\n",
      "Epoch:  0020 D loss:-0.3504 G loss:-2.404\n",
      "Epoch:  0020 D loss:-0.4341 G loss:-2.28\n",
      "Epoch:  0020 D loss:-0.4093 G loss:-2.334\n",
      "Epoch:  0020 D loss:-0.4195 G loss:-2.414\n",
      "Epoch:  0020 D loss:-0.377 G loss:-2.361\n",
      "Epoch:  0020 D loss:-0.4685 G loss:-2.211\n",
      "Epoch:  0020 D loss:-0.2998 G loss:-2.395\n",
      "Epoch:  0020 D loss:-0.3654 G loss:-2.392\n",
      "Epoch:  0020 D loss:-0.4354 G loss:-2.454\n",
      "Epoch:  0020 D loss:-0.4024 G loss:-2.474\n",
      "Epoch:  0020 D loss:-0.3023 G loss:-2.577\n",
      "Epoch:  0020 D loss:-0.3426 G loss:-2.536\n",
      "Epoch:  0020 D loss:-0.4055 G loss:-2.513\n",
      "Epoch:  0020 D loss:-0.3894 G loss:-2.475\n",
      "Epoch:  0020 D loss:-0.3924 G loss:-2.475\n",
      "Epoch:  0020 D loss:-0.3553 G loss:-2.513\n",
      "Epoch:  0020 D loss:-0.4001 G loss:-2.573\n",
      "Epoch:  0020 D loss:-0.3698 G loss:-2.538\n",
      "Epoch:  0020 D loss:-0.3565 G loss:-2.516\n",
      "Epoch:  0020 D loss:-0.4488 G loss:-2.409\n",
      "Epoch:  0020 D loss:-0.4408 G loss:-2.458\n",
      "Epoch:  0020 D loss:-0.3376 G loss:-2.418\n",
      "Epoch:  0020 D loss:-0.3842 G loss:-2.351\n",
      "Epoch:  0020 D loss:-0.4159 G loss:-2.179\n",
      "Epoch:  0020 D loss:-0.343 G loss:-2.349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0020 D loss:-0.4109 G loss:-2.364\n",
      "Epoch:  0020 D loss:-0.3609 G loss:-2.443\n",
      "Epoch:  0020 D loss:-0.4319 G loss:-2.365\n",
      "Epoch:  0020 D loss:-0.3749 G loss:-2.388\n",
      "Epoch:  0020 D loss:-0.4102 G loss:-2.399\n",
      "Epoch:  0020 D loss:-0.3736 G loss:-2.441\n",
      "Epoch:  0020 D loss:-0.3156 G loss:-2.723\n",
      "Epoch:  0020 D loss:-0.3297 G loss:-2.669\n",
      "Epoch:  0020 D loss:-0.3701 G loss:-2.752\n",
      "Epoch:  0020 D loss:-0.3565 G loss:-2.576\n",
      "Epoch:  0020 D loss:-0.3597 G loss:-2.514\n",
      "Epoch:  0020 D loss:-0.3831 G loss:-2.59\n",
      "Epoch:  0020 D loss:-0.3745 G loss:-2.515\n",
      "Epoch:  0020 D loss:-0.4 G loss:-2.536\n",
      "Epoch:  0020 D loss:-0.4306 G loss:-2.428\n",
      "Epoch:  0020 D loss:-0.3568 G loss:-2.419\n",
      "Epoch:  0020 D loss:-0.4624 G loss:-2.274\n",
      "Epoch:  0020 D loss:-0.3393 G loss:-2.551\n",
      "Epoch:  0020 D loss:-0.4095 G loss:-2.151\n",
      "Epoch:  0020 D loss:-0.3385 G loss:-2.32\n",
      "Epoch:  0020 D loss:-0.4002 G loss:-2.453\n",
      "Epoch:  0020 D loss:-0.3572 G loss:-2.457\n",
      "Epoch:  0020 D loss:-0.3249 G loss:-2.486\n",
      "Epoch:  0020 D loss:-0.4439 G loss:-2.494\n",
      "Epoch:  0020 D loss:-0.4456 G loss:-2.554\n",
      "Epoch:  0020 D loss:-0.3533 G loss:-2.447\n",
      "Epoch:  0020 D loss:-0.3774 G loss:-2.728\n",
      "Epoch:  0020 D loss:-0.3809 G loss:-2.506\n",
      "Epoch:  0020 D loss:-0.4728 G loss:-2.501\n",
      "Epoch:  0020 D loss:-0.373 G loss:-2.501\n",
      "Epoch:  0020 D loss:-0.3988 G loss:-2.369\n",
      "Epoch:  0020 D loss:-0.4273 G loss:-2.264\n",
      "Epoch:  0020 D loss:-0.4522 G loss:-2.351\n",
      "Epoch:  0020 D loss:-0.4459 G loss:-2.444\n",
      "Epoch:  0020 D loss:-0.395 G loss:-2.273\n",
      "Epoch:  0020 D loss:-0.6234 G loss:-2.039\n",
      "Epoch:  0020 D loss:-0.5315 G loss:-2.273\n",
      "Epoch:  0020 D loss:-0.384 G loss:-2.149\n",
      "Epoch:  0020 D loss:-0.4563 G loss:-2.278\n",
      "Epoch:  0020 D loss:-0.3858 G loss:-2.383\n",
      "Epoch:  0020 D loss:-0.3801 G loss:-2.383\n",
      "Epoch:  0020 D loss:-0.4691 G loss:-2.311\n",
      "Epoch:  0020 D loss:-0.5062 G loss:-2.252\n",
      "Epoch:  0020 D loss:-0.4562 G loss:-2.224\n",
      "Epoch:  0020 D loss:-0.348 G loss:-2.327\n",
      "Epoch:  0020 D loss:-0.3912 G loss:-2.352\n",
      "Epoch:  0020 D loss:-0.4504 G loss:-2.332\n",
      "Epoch:  0020 D loss:-0.5279 G loss:-2.357\n",
      "Epoch:  0020 D loss:-0.3477 G loss:-2.264\n",
      "Epoch:  0020 D loss:-0.4356 G loss:-2.256\n",
      "Epoch:  0020 D loss:-0.4266 G loss:-2.006\n",
      "Epoch:  0020 D loss:-0.3531 G loss:-2.357\n",
      "Epoch:  0020 D loss:-0.4052 G loss:-2.368\n",
      "Epoch:  0020 D loss:-0.3761 G loss:-2.563\n",
      "Epoch:  0020 D loss:-0.4574 G loss:-2.384\n",
      "Epoch:  0020 D loss:-0.4318 G loss:-2.526\n",
      "Epoch:  0020 D loss:-0.4514 G loss:-2.613\n",
      "Epoch:  0020 D loss:-0.4094 G loss:-2.635\n",
      "Epoch:  0020 D loss:-0.3742 G loss:-2.682\n",
      "Epoch:  0020 D loss:-0.396 G loss:-2.249\n",
      "Epoch:  0020 D loss:-0.4481 G loss:-2.42\n",
      "Epoch:  0020 D loss:-0.3834 G loss:-2.511\n",
      "Epoch:  0020 D loss:-0.4219 G loss:-2.206\n",
      "Epoch:  0020 D loss:-0.5058 G loss:-2.419\n",
      "Epoch:  0020 D loss:-0.4478 G loss:-2.407\n",
      "Epoch:  0020 D loss:-0.4831 G loss:-2.451\n",
      "Epoch:  0020 D loss:-0.4108 G loss:-2.235\n",
      "Epoch:  0020 D loss:-0.3638 G loss:-2.25\n",
      "Epoch:  0020 D loss:-0.3832 G loss:-2.26\n",
      "Epoch:  0020 D loss:-0.3788 G loss:-2.356\n",
      "Epoch:  0020 D loss:-0.4081 G loss:-2.454\n",
      "Epoch:  0020 D loss:-0.4411 G loss:-2.49\n",
      "Epoch:  0020 D loss:-0.3308 G loss:-2.413\n",
      "Epoch:  0020 D loss:-0.3806 G loss:-2.46\n",
      "Epoch:  0020 D loss:-0.3533 G loss:-2.268\n",
      "Epoch:  0020 D loss:-0.482 G loss:-2.406\n",
      "Epoch:  0020 D loss:-0.4867 G loss:-2.421\n",
      "Epoch:  0020 D loss:-0.3971 G loss:-2.506\n",
      "Epoch:  0020 D loss:-0.4528 G loss:-2.357\n",
      "Epoch:  0020 D loss:-0.3705 G loss:-2.568\n",
      "Epoch:  0020 D loss:-0.3482 G loss:-2.444\n",
      "Epoch:  0020 D loss:-0.3329 G loss:-2.615\n",
      "Epoch:  0020 D loss:-0.4213 G loss:-2.355\n",
      "Epoch:  0020 D loss:-0.3848 G loss:-2.476\n",
      "Epoch:  0020 D loss:-0.4028 G loss:-2.46\n",
      "Epoch:  0020 D loss:-0.3568 G loss:-2.612\n",
      "Epoch:  0020 D loss:-0.4054 G loss:-2.385\n",
      "Epoch:  0020 D loss:-0.2997 G loss:-2.36\n",
      "Epoch:  0020 D loss:-0.3453 G loss:-2.516\n",
      "Epoch:  0020 D loss:-0.3511 G loss:-2.503\n",
      "Epoch:  0020 D loss:-0.3206 G loss:-2.571\n",
      "Epoch:  0020 D loss:-0.453 G loss:-2.575\n",
      "Epoch:  0020 D loss:-0.39 G loss:-2.651\n",
      "Epoch:  0020 D loss:-0.4355 G loss:-2.549\n",
      "Epoch:  0020 D loss:-0.2993 G loss:-2.635\n",
      "Epoch:  0020 D loss:-0.3893 G loss:-2.796\n",
      "Epoch:  0020 D loss:-0.3886 G loss:-2.735\n",
      "Epoch:  0020 D loss:-0.4029 G loss:-2.497\n",
      "Epoch:  0020 D loss:-0.432 G loss:-2.503\n",
      "Epoch:  0020 D loss:-0.3754 G loss:-2.453\n",
      "Epoch:  0020 D loss:-0.4427 G loss:-2.109\n",
      "Epoch:  0020 D loss:-0.5352 G loss:-2.261\n",
      "Epoch:  0020 D loss:-0.3668 G loss:-2.417\n",
      "Epoch:  0020 D loss:-0.4576 G loss:-2.217\n",
      "Epoch:  0020 D loss:-0.4364 G loss:-2.186\n",
      "Epoch:  0020 D loss:-0.4494 G loss:-2.351\n",
      "Epoch:  0020 D loss:-0.4237 G loss:-2.304\n",
      "Epoch:  0020 D loss:-0.4024 G loss:-2.096\n",
      "Epoch:  0020 D loss:-0.3534 G loss:-2.327\n",
      "Epoch:  0020 D loss:-0.4136 G loss:-2.469\n",
      "Epoch:  0020 D loss:-0.4309 G loss:-2.675\n",
      "Epoch:  0020 D loss:-0.4778 G loss:-2.626\n",
      "Epoch:  0020 D loss:-0.4279 G loss:-2.67\n",
      "Epoch:  0020 D loss:-0.478 G loss:-2.449\n",
      "Epoch:  0020 D loss:-0.4134 G loss:-2.458\n",
      "Epoch:  0020 D loss:-0.4851 G loss:-2.358\n",
      "Epoch:  0020 D loss:-0.423 G loss:-2.591\n",
      "Epoch:  0020 D loss:-0.362 G loss:-2.469\n",
      "Epoch:  0020 D loss:-0.476 G loss:-2.311\n",
      "Epoch:  0020 D loss:-0.4342 G loss:-2.197\n",
      "Epoch:  0020 D loss:-0.437 G loss:-2.411\n",
      "Epoch:  0020 D loss:-0.321 G loss:-2.464\n",
      "Epoch:  0020 D loss:-0.4934 G loss:-2.109\n",
      "Epoch:  0020 D loss:-0.3884 G loss:-2.575\n",
      "Epoch:  0020 D loss:-0.4052 G loss:-2.493\n",
      "Epoch:  0020 D loss:-0.4354 G loss:-2.507\n",
      "Epoch:  0020 D loss:-0.37 G loss:-2.639\n",
      "Epoch:  0020 D loss:-0.4656 G loss:-2.34\n",
      "Epoch:  0020 D loss:-0.4511 G loss:-2.474\n",
      "Epoch:  0020 D loss:-0.3819 G loss:-2.488\n",
      "Epoch:  0020 D loss:-0.4532 G loss:-2.369\n",
      "Epoch:  0020 D loss:-0.2965 G loss:-2.601\n",
      "Epoch:  0020 D loss:-0.3915 G loss:-2.341\n",
      "Epoch:  0020 D loss:-0.4593 G loss:-2.279\n",
      "Epoch:  0020 D loss:-0.3744 G loss:-2.566\n",
      "Epoch:  0020 D loss:-0.3721 G loss:-2.642\n",
      "Epoch:  0020 D loss:-0.3996 G loss:-2.584\n",
      "Epoch:  0020 D loss:-0.4135 G loss:-2.673\n",
      "Epoch:  0020 D loss:-0.3708 G loss:-2.549\n",
      "Epoch:  0020 D loss:-0.5177 G loss:-2.451\n",
      "Epoch:  0020 D loss:-0.4106 G loss:-2.436\n",
      "Epoch:  0020 D loss:-0.4545 G loss:-2.264\n",
      "Epoch:  0020 D loss:-0.4235 G loss:-2.458\n",
      "Epoch:  0020 D loss:-0.4343 G loss:-2.324\n",
      "Epoch:  0020 D loss:-0.4372 G loss:-2.295\n",
      "Epoch:  0020 D loss:-0.4898 G loss:-2.035\n",
      "Epoch:  0020 D loss:-0.4274 G loss:-2.15\n",
      "Epoch:  0020 D loss:-0.3929 G loss:-2.379\n",
      "Epoch:  0020 D loss:-0.4987 G loss:-2.161\n",
      "Epoch:  0020 D loss:-0.4051 G loss:-2.367\n",
      "Epoch:  0020 D loss:-0.3735 G loss:-2.355\n",
      "Epoch:  0020 D loss:-0.3575 G loss:-2.587\n",
      "Epoch:  0020 D loss:-0.3462 G loss:-2.546\n",
      "Epoch:  0020 D loss:-0.3501 G loss:-2.458\n",
      "Epoch:  0020 D loss:-0.5186 G loss:-2.733\n",
      "Epoch:  0020 D loss:-0.3242 G loss:-2.421\n",
      "Epoch:  0020 D loss:-0.4249 G loss:-2.501\n",
      "Epoch:  0020 D loss:-0.3997 G loss:-2.621\n",
      "Epoch:  0020 D loss:-0.3531 G loss:-2.364\n",
      "Epoch:  0020 D loss:-0.4192 G loss:-2.372\n",
      "Epoch:  0020 D loss:-0.4201 G loss:-2.304\n",
      "Epoch:  0020 D loss:-0.4037 G loss:-2.336\n",
      "Epoch:  0020 D loss:-0.3729 G loss:-2.277\n",
      "Epoch:  0020 D loss:-0.3768 G loss:-2.299\n",
      "Epoch:  0020 D loss:-0.3843 G loss:-2.33\n",
      "Epoch:  0020 D loss:-0.4288 G loss:-2.428\n",
      "Epoch:  0020 D loss:-0.4281 G loss:-2.204\n",
      "Epoch:  0020 D loss:-0.3681 G loss:-2.382\n",
      "Epoch:  0020 D loss:-0.3808 G loss:-2.493\n",
      "Epoch:  0020 D loss:-0.4177 G loss:-2.481\n",
      "Epoch:  0020 D loss:-0.4333 G loss:-2.526\n",
      "Epoch:  0020 D loss:-0.3824 G loss:-2.466\n",
      "Epoch:  0020 D loss:-0.4494 G loss:-2.601\n",
      "Epoch:  0020 D loss:-0.5012 G loss:-2.414\n",
      "Epoch:  0020 D loss:-0.3581 G loss:-2.538\n",
      "Epoch:  0020 D loss:-0.3363 G loss:-2.509\n",
      "Epoch:  0020 D loss:-0.4622 G loss:-2.42\n",
      "Epoch:  0020 D loss:-0.3991 G loss:-2.455\n",
      "Epoch:  0020 D loss:-0.3795 G loss:-2.546\n",
      "Epoch:  0020 D loss:-0.3935 G loss:-2.468\n",
      "Epoch:  0020 D loss:-0.43 G loss:-2.638\n",
      "Epoch:  0020 D loss:-0.4113 G loss:-2.395\n",
      "Epoch:  0020 D loss:-0.4091 G loss:-2.396\n",
      "Epoch:  0020 D loss:-0.3702 G loss:-2.338\n",
      "Epoch:  0020 D loss:-0.3473 G loss:-2.646\n",
      "Epoch:  0020 D loss:-0.3889 G loss:-2.312\n",
      "Epoch:  0020 D loss:-0.5166 G loss:-2.498\n",
      "Epoch:  0020 D loss:-0.3669 G loss:-2.589\n",
      "Epoch:  0020 D loss:-0.3675 G loss:-2.728\n",
      "Epoch:  0020 D loss:-0.3381 G loss:-2.516\n",
      "Epoch:  0020 D loss:-0.4846 G loss:-2.46\n",
      "Epoch:  0020 D loss:-0.4253 G loss:-2.579\n",
      "Epoch:  0020 D loss:-0.3963 G loss:-2.698\n",
      "Epoch:  0020 D loss:-0.3986 G loss:-2.46\n",
      "Epoch:  0020 D loss:-0.434 G loss:-2.441\n",
      "Epoch:  0020 D loss:-0.382 G loss:-2.466\n",
      "Epoch:  0020 D loss:-0.3648 G loss:-2.422\n",
      "Epoch:  0020 D loss:-0.2976 G loss:-2.542\n",
      "Epoch:  0020 D loss:-0.4105 G loss:-2.433\n",
      "Epoch:  0020 D loss:-0.4076 G loss:-2.38\n",
      "Epoch:  0020 D loss:-0.4017 G loss:-2.473\n",
      "Epoch:  0020 D loss:-0.3906 G loss:-2.512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0020 D loss:-0.4054 G loss:-2.476\n",
      "Epoch:  0020 D loss:-0.4259 G loss:-2.598\n",
      "Epoch:  0020 D loss:-0.5027 G loss:-2.657\n",
      "Epoch:  0020 D loss:-0.3804 G loss:-2.675\n",
      "Epoch:  0020 D loss:-0.4931 G loss:-2.503\n",
      "Epoch:  0020 D loss:-0.4165 G loss:-2.634\n",
      "Epoch:  0020 D loss:-0.4511 G loss:-2.665\n",
      "Epoch:  0020 D loss:-0.3371 G loss:-2.551\n",
      "Epoch:  0020 D loss:-0.4435 G loss:-2.571\n",
      "Epoch:  0020 D loss:-0.4701 G loss:-2.341\n",
      "Epoch:  0020 D loss:-0.5072 G loss:-2.267\n",
      "Epoch:  0020 D loss:-0.5007 G loss:-2.441\n",
      "Epoch:  0020 D loss:-0.397 G loss:-2.338\n",
      "Epoch:  0020 D loss:-0.4918 G loss:-2.439\n",
      "Epoch:  0020 D loss:-0.377 G loss:-2.387\n",
      "Epoch:  0020 D loss:-0.464 G loss:-2.262\n",
      "Epoch:  0020 D loss:-0.4128 G loss:-2.442\n",
      "Epoch:  0020 D loss:-0.4598 G loss:-2.321\n",
      "Epoch:  0020 D loss:-0.3433 G loss:-2.52\n",
      "Epoch:  0020 D loss:-0.442 G loss:-2.423\n",
      "Epoch:  0020 D loss:-0.382 G loss:-2.597\n",
      "Epoch:  0020 D loss:-0.423 G loss:-2.618\n",
      "Epoch:  0020 D loss:-0.4442 G loss:-2.564\n",
      "Epoch:  0020 D loss:-0.3214 G loss:-2.883\n",
      "Epoch:  0020 D loss:-0.4317 G loss:-2.849\n",
      "Epoch:  0020 D loss:-0.4907 G loss:-2.829\n",
      "Epoch:  0020 D loss:-0.5451 G loss:-2.586\n",
      "Epoch:  0020 D loss:-0.3557 G loss:-2.627\n",
      "Epoch:  0020 D loss:-0.3971 G loss:-2.547\n",
      "Epoch:  0020 D loss:-0.3651 G loss:-2.577\n",
      "Epoch:  0020 D loss:-0.3674 G loss:-2.349\n",
      "Epoch:  0020 D loss:-0.4627 G loss:-2.567\n",
      "Epoch:  0020 D loss:-0.4029 G loss:-2.367\n",
      "Epoch:  0020 D loss:-0.3669 G loss:-2.476\n",
      "Epoch:  0020 D loss:-0.4263 G loss:-2.488\n",
      "Epoch:  0020 D loss:-0.3432 G loss:-2.495\n",
      "Epoch:  0020 D loss:-0.4908 G loss:-2.26\n",
      "Epoch:  0020 D loss:-0.3746 G loss:-2.491\n",
      "Epoch:  0020 D loss:-0.4355 G loss:-2.273\n",
      "Epoch:  0020 D loss:-0.3841 G loss:-2.672\n",
      "Epoch:  0020 D loss:-0.3144 G loss:-2.634\n",
      "Epoch:  0020 D loss:-0.3 G loss:-2.587\n",
      "Epoch:  0020 D loss:-0.3456 G loss:-2.75\n",
      "Epoch:  0020 D loss:-0.3393 G loss:-2.644\n",
      "Epoch:  0020 D loss:-0.3509 G loss:-2.813\n",
      "Epoch:  0020 D loss:-0.3512 G loss:-2.756\n",
      "Epoch:  0020 D loss:-0.418 G loss:-2.669\n",
      "Epoch:  0020 D loss:-0.4545 G loss:-2.595\n",
      "Epoch:  0020 D loss:-0.3556 G loss:-2.756\n",
      "Epoch:  0020 D loss:-0.3473 G loss:-2.803\n",
      "Epoch:  0020 D loss:-0.3916 G loss:-2.404\n",
      "Epoch:  0020 D loss:-0.3858 G loss:-2.273\n",
      "Epoch:  0020 D loss:-0.2903 G loss:-2.623\n",
      "Epoch:  0020 D loss:-0.4801 G loss:-2.476\n",
      "Epoch:  0020 D loss:-0.3384 G loss:-2.35\n",
      "Epoch:  0020 D loss:-0.4353 G loss:-2.541\n",
      "Epoch:  0020 D loss:-0.4222 G loss:-2.71\n",
      "Epoch:  0020 D loss:-0.4439 G loss:-2.683\n",
      "Epoch:  0020 D loss:-0.3598 G loss:-2.443\n",
      "Epoch:  0020 D loss:-0.3773 G loss:-2.392\n",
      "Epoch:  0020 D loss:-0.3411 G loss:-2.582\n",
      "Epoch:  0020 D loss:-0.4168 G loss:-2.509\n",
      "Epoch:  0020 D loss:-0.3357 G loss:-2.747\n",
      "Epoch:  0020 D loss:-0.3178 G loss:-2.781\n",
      "Epoch:  0020 D loss:-0.4281 G loss:-2.725\n",
      "Epoch:  0020 D loss:-0.3445 G loss:-2.607\n",
      "Epoch:  0020 D loss:-0.4098 G loss:-2.558\n",
      "Epoch:  0020 D loss:-0.358 G loss:-2.56\n",
      "Epoch:  0020 D loss:-0.3864 G loss:-2.467\n",
      "Epoch:  0020 D loss:-0.3839 G loss:-2.405\n",
      "Epoch:  0020 D loss:-0.4955 G loss:-2.463\n",
      "Epoch:  0020 D loss:-0.44 G loss:-2.444\n",
      "Epoch:  0020 D loss:-0.307 G loss:-2.4\n",
      "Epoch:  0020 D loss:-0.3348 G loss:-2.504\n",
      "Epoch:  0020 D loss:-0.5088 G loss:-2.26\n",
      "Epoch:  0020 D loss:-0.3519 G loss:-2.472\n",
      "Epoch:  0020 D loss:-0.3804 G loss:-2.371\n",
      "Epoch:  0020 D loss:-0.5084 G loss:-2.349\n",
      "Epoch:  0020 D loss:-0.4311 G loss:-2.411\n",
      "Epoch:  0020 D loss:-0.3916 G loss:-2.479\n",
      "Epoch:  0020 D loss:-0.4219 G loss:-2.731\n",
      "Epoch:  0020 D loss:-0.4695 G loss:-2.539\n",
      "Epoch:  0020 D loss:-0.4048 G loss:-2.72\n",
      "Epoch:  0020 D loss:-0.4451 G loss:-2.413\n",
      "Epoch:  0020 D loss:-0.4176 G loss:-2.574\n",
      "Epoch:  0020 D loss:-0.4819 G loss:-2.427\n",
      "Epoch:  0020 D loss:-0.5633 G loss:-2.343\n",
      "Epoch:  0020 D loss:-0.4457 G loss:-2.543\n",
      "Epoch:  0020 D loss:-0.3675 G loss:-2.234\n",
      "Epoch:  0020 D loss:-0.3365 G loss:-2.298\n",
      "Epoch:  0020 D loss:-0.4091 G loss:-2.47\n",
      "Epoch:  0020 D loss:-0.4182 G loss:-2.407\n",
      "Epoch:  0020 D loss:-0.4015 G loss:-2.544\n",
      "Epoch:  0020 D loss:-0.439 G loss:-2.432\n",
      "Epoch:  0020 D loss:-0.4442 G loss:-2.368\n",
      "Epoch:  0020 D loss:-0.3769 G loss:-2.442\n",
      "Epoch:  0020 D loss:-0.403 G loss:-2.356\n",
      "Epoch:  0020 D loss:-0.4403 G loss:-2.477\n",
      "Epoch:  0020 D loss:-0.4278 G loss:-2.549\n",
      "Epoch:  0020 D loss:-0.4144 G loss:-2.474\n",
      "Epoch:  0020 D loss:-0.3499 G loss:-2.586\n",
      "Epoch:  0020 D loss:-0.427 G loss:-2.739\n",
      "Epoch:  0020 D loss:-0.5605 G loss:-2.618\n",
      "Epoch:  0020 D loss:-0.4223 G loss:-2.607\n",
      "Epoch:  0020 D loss:-0.4105 G loss:-2.572\n",
      "Epoch:  0020 D loss:-0.4747 G loss:-2.478\n",
      "Epoch:  0020 D loss:-0.4247 G loss:-2.481\n",
      "Epoch:  0020 D loss:-0.3231 G loss:-2.382\n",
      "Epoch:  0021 D loss:-0.4155 G loss:-2.332\n",
      "Epoch:  0021 D loss:-0.4076 G loss:-2.285\n",
      "Epoch:  0021 D loss:-0.4529 G loss:-2.199\n",
      "Epoch:  0021 D loss:-0.3623 G loss:-2.707\n",
      "Epoch:  0021 D loss:-0.3619 G loss:-2.44\n",
      "Epoch:  0021 D loss:-0.3886 G loss:-2.443\n",
      "Epoch:  0021 D loss:-0.4165 G loss:-2.625\n",
      "Epoch:  0021 D loss:-0.3923 G loss:-2.7\n",
      "Epoch:  0021 D loss:-0.4298 G loss:-2.545\n",
      "Epoch:  0021 D loss:-0.4447 G loss:-2.734\n",
      "Epoch:  0021 D loss:-0.3119 G loss:-2.886\n",
      "Epoch:  0021 D loss:-0.5076 G loss:-2.64\n",
      "Epoch:  0021 D loss:-0.3828 G loss:-2.773\n",
      "Epoch:  0021 D loss:-0.3681 G loss:-2.786\n",
      "Epoch:  0021 D loss:-0.3823 G loss:-2.787\n",
      "Epoch:  0021 D loss:-0.3554 G loss:-2.675\n",
      "Epoch:  0021 D loss:-0.3126 G loss:-2.724\n",
      "Epoch:  0021 D loss:-0.3994 G loss:-2.579\n",
      "Epoch:  0021 D loss:-0.3779 G loss:-2.573\n",
      "Epoch:  0021 D loss:-0.3921 G loss:-2.519\n",
      "Epoch:  0021 D loss:-0.3069 G loss:-2.592\n",
      "Epoch:  0021 D loss:-0.293 G loss:-2.684\n",
      "Epoch:  0021 D loss:-0.4099 G loss:-2.708\n",
      "Epoch:  0021 D loss:-0.4809 G loss:-2.472\n",
      "Epoch:  0021 D loss:-0.3517 G loss:-2.658\n",
      "Epoch:  0021 D loss:-0.3993 G loss:-2.587\n",
      "Epoch:  0021 D loss:-0.3415 G loss:-2.702\n",
      "Epoch:  0021 D loss:-0.365 G loss:-2.489\n",
      "Epoch:  0021 D loss:-0.4112 G loss:-2.589\n",
      "Epoch:  0021 D loss:-0.406 G loss:-2.459\n",
      "Epoch:  0021 D loss:-0.3213 G loss:-2.62\n",
      "Epoch:  0021 D loss:-0.3395 G loss:-2.672\n",
      "Epoch:  0021 D loss:-0.4976 G loss:-2.541\n",
      "Epoch:  0021 D loss:-0.3104 G loss:-2.654\n",
      "Epoch:  0021 D loss:-0.4435 G loss:-2.348\n",
      "Epoch:  0021 D loss:-0.3255 G loss:-2.464\n",
      "Epoch:  0021 D loss:-0.4098 G loss:-2.663\n",
      "Epoch:  0021 D loss:-0.3171 G loss:-2.66\n",
      "Epoch:  0021 D loss:-0.3431 G loss:-2.716\n",
      "Epoch:  0021 D loss:-0.312 G loss:-2.862\n",
      "Epoch:  0021 D loss:-0.4414 G loss:-2.426\n",
      "Epoch:  0021 D loss:-0.4779 G loss:-2.53\n",
      "Epoch:  0021 D loss:-0.3639 G loss:-2.427\n",
      "Epoch:  0021 D loss:-0.3785 G loss:-2.827\n",
      "Epoch:  0021 D loss:-0.3395 G loss:-2.52\n",
      "Epoch:  0021 D loss:-0.3891 G loss:-2.515\n",
      "Epoch:  0021 D loss:-0.3074 G loss:-2.632\n",
      "Epoch:  0021 D loss:-0.4809 G loss:-2.24\n",
      "Epoch:  0021 D loss:-0.4138 G loss:-2.243\n",
      "Epoch:  0021 D loss:-0.3459 G loss:-2.509\n",
      "Epoch:  0021 D loss:-0.3838 G loss:-2.407\n",
      "Epoch:  0021 D loss:-0.4235 G loss:-2.362\n",
      "Epoch:  0021 D loss:-0.3305 G loss:-2.34\n",
      "Epoch:  0021 D loss:-0.366 G loss:-2.613\n",
      "Epoch:  0021 D loss:-0.3715 G loss:-2.569\n",
      "Epoch:  0021 D loss:-0.4127 G loss:-2.671\n",
      "Epoch:  0021 D loss:-0.3993 G loss:-2.83\n",
      "Epoch:  0021 D loss:-0.2842 G loss:-2.517\n",
      "Epoch:  0021 D loss:-0.3139 G loss:-2.624\n",
      "Epoch:  0021 D loss:-0.2876 G loss:-2.524\n",
      "Epoch:  0021 D loss:-0.4494 G loss:-2.482\n",
      "Epoch:  0021 D loss:-0.382 G loss:-2.63\n",
      "Epoch:  0021 D loss:-0.2769 G loss:-2.598\n",
      "Epoch:  0021 D loss:-0.3469 G loss:-2.574\n",
      "Epoch:  0021 D loss:-0.4135 G loss:-2.465\n",
      "Epoch:  0021 D loss:-0.4281 G loss:-2.577\n",
      "Epoch:  0021 D loss:-0.4012 G loss:-2.598\n",
      "Epoch:  0021 D loss:-0.4022 G loss:-2.464\n",
      "Epoch:  0021 D loss:-0.3605 G loss:-2.414\n",
      "Epoch:  0021 D loss:-0.3705 G loss:-2.405\n",
      "Epoch:  0021 D loss:-0.3169 G loss:-2.533\n",
      "Epoch:  0021 D loss:-0.4064 G loss:-2.207\n",
      "Epoch:  0021 D loss:-0.3878 G loss:-2.238\n",
      "Epoch:  0021 D loss:-0.4127 G loss:-2.304\n",
      "Epoch:  0021 D loss:-0.4269 G loss:-2.485\n",
      "Epoch:  0021 D loss:-0.3971 G loss:-2.641\n",
      "Epoch:  0021 D loss:-0.4554 G loss:-2.441\n",
      "Epoch:  0021 D loss:-0.455 G loss:-2.679\n",
      "Epoch:  0021 D loss:-0.3898 G loss:-2.608\n",
      "Epoch:  0021 D loss:-0.3201 G loss:-2.751\n",
      "Epoch:  0021 D loss:-0.4399 G loss:-2.65\n",
      "Epoch:  0021 D loss:-0.4063 G loss:-2.373\n",
      "Epoch:  0021 D loss:-0.4546 G loss:-2.211\n",
      "Epoch:  0021 D loss:-0.4075 G loss:-2.31\n",
      "Epoch:  0021 D loss:-0.4742 G loss:-2.074\n",
      "Epoch:  0021 D loss:-0.4494 G loss:-2.127\n",
      "Epoch:  0021 D loss:-0.4309 G loss:-2.295\n",
      "Epoch:  0021 D loss:-0.3691 G loss:-2.387\n",
      "Epoch:  0021 D loss:-0.4173 G loss:-2.426\n",
      "Epoch:  0021 D loss:-0.5016 G loss:-2.358\n",
      "Epoch:  0021 D loss:-0.3744 G loss:-2.704\n",
      "Epoch:  0021 D loss:-0.3765 G loss:-2.453\n",
      "Epoch:  0021 D loss:-0.3821 G loss:-2.468\n",
      "Epoch:  0021 D loss:-0.5271 G loss:-2.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0021 D loss:-0.3641 G loss:-2.479\n",
      "Epoch:  0021 D loss:-0.465 G loss:-2.39\n",
      "Epoch:  0021 D loss:-0.3913 G loss:-2.431\n",
      "Epoch:  0021 D loss:-0.4894 G loss:-2.254\n",
      "Epoch:  0021 D loss:-0.3198 G loss:-2.48\n",
      "Epoch:  0021 D loss:-0.5854 G loss:-2.176\n",
      "Epoch:  0021 D loss:-0.4118 G loss:-2.444\n",
      "Epoch:  0021 D loss:-0.4139 G loss:-2.252\n",
      "Epoch:  0021 D loss:-0.3857 G loss:-2.131\n",
      "Epoch:  0021 D loss:-0.3671 G loss:-2.419\n",
      "Epoch:  0021 D loss:-0.453 G loss:-2.534\n",
      "Epoch:  0021 D loss:-0.4269 G loss:-2.426\n",
      "Epoch:  0021 D loss:-0.5604 G loss:-2.283\n",
      "Epoch:  0021 D loss:-0.4571 G loss:-2.364\n",
      "Epoch:  0021 D loss:-0.4429 G loss:-2.278\n",
      "Epoch:  0021 D loss:-0.4673 G loss:-2.338\n",
      "Epoch:  0021 D loss:-0.4771 G loss:-2.211\n",
      "Epoch:  0021 D loss:-0.4321 G loss:-2.327\n",
      "Epoch:  0021 D loss:-0.4901 G loss:-2.337\n",
      "Epoch:  0021 D loss:-0.4437 G loss:-2.404\n",
      "Epoch:  0021 D loss:-0.4574 G loss:-2.488\n",
      "Epoch:  0021 D loss:-0.4602 G loss:-2.252\n",
      "Epoch:  0021 D loss:-0.4516 G loss:-2.406\n",
      "Epoch:  0021 D loss:-0.4092 G loss:-2.367\n",
      "Epoch:  0021 D loss:-0.4336 G loss:-2.486\n",
      "Epoch:  0021 D loss:-0.3548 G loss:-2.413\n",
      "Epoch:  0021 D loss:-0.4824 G loss:-2.329\n",
      "Epoch:  0021 D loss:-0.531 G loss:-2.25\n",
      "Epoch:  0021 D loss:-0.4241 G loss:-2.219\n",
      "Epoch:  0021 D loss:-0.5221 G loss:-2.373\n",
      "Epoch:  0021 D loss:-0.4618 G loss:-2.311\n",
      "Epoch:  0021 D loss:-0.4096 G loss:-2.122\n",
      "Epoch:  0021 D loss:-0.3587 G loss:-2.436\n",
      "Epoch:  0021 D loss:-0.4064 G loss:-2.351\n",
      "Epoch:  0021 D loss:-0.4622 G loss:-2.626\n",
      "Epoch:  0021 D loss:-0.4761 G loss:-2.535\n",
      "Epoch:  0021 D loss:-0.446 G loss:-2.547\n",
      "Epoch:  0021 D loss:-0.3954 G loss:-2.545\n",
      "Epoch:  0021 D loss:-0.4537 G loss:-2.593\n",
      "Epoch:  0021 D loss:-0.3912 G loss:-2.456\n",
      "Epoch:  0021 D loss:-0.3613 G loss:-2.603\n",
      "Epoch:  0021 D loss:-0.5613 G loss:-2.474\n",
      "Epoch:  0021 D loss:-0.4246 G loss:-2.316\n",
      "Epoch:  0021 D loss:-0.5342 G loss:-2.341\n",
      "Epoch:  0021 D loss:-0.5083 G loss:-2.372\n",
      "Epoch:  0021 D loss:-0.4863 G loss:-2.52\n",
      "Epoch:  0021 D loss:-0.3134 G loss:-2.56\n",
      "Epoch:  0021 D loss:-0.4654 G loss:-2.481\n",
      "Epoch:  0021 D loss:-0.4128 G loss:-2.484\n",
      "Epoch:  0021 D loss:-0.3987 G loss:-2.513\n",
      "Epoch:  0021 D loss:-0.3571 G loss:-2.496\n",
      "Epoch:  0021 D loss:-0.5927 G loss:-2.328\n",
      "Epoch:  0021 D loss:-0.4371 G loss:-2.6\n",
      "Epoch:  0021 D loss:-0.4317 G loss:-2.446\n",
      "Epoch:  0021 D loss:-0.3726 G loss:-2.526\n",
      "Epoch:  0021 D loss:-0.3915 G loss:-2.559\n",
      "Epoch:  0021 D loss:-0.5166 G loss:-2.255\n",
      "Epoch:  0021 D loss:-0.5084 G loss:-2.328\n",
      "Epoch:  0021 D loss:-0.461 G loss:-2.515\n",
      "Epoch:  0021 D loss:-0.498 G loss:-2.426\n",
      "Epoch:  0021 D loss:-0.4094 G loss:-2.229\n",
      "Epoch:  0021 D loss:-0.4351 G loss:-2.375\n",
      "Epoch:  0021 D loss:-0.3522 G loss:-2.37\n",
      "Epoch:  0021 D loss:-0.4091 G loss:-2.443\n",
      "Epoch:  0021 D loss:-0.3908 G loss:-2.391\n",
      "Epoch:  0021 D loss:-0.3534 G loss:-2.433\n",
      "Epoch:  0021 D loss:-0.3757 G loss:-2.54\n",
      "Epoch:  0021 D loss:-0.4055 G loss:-2.454\n",
      "Epoch:  0021 D loss:-0.4278 G loss:-2.57\n",
      "Epoch:  0021 D loss:-0.4619 G loss:-2.548\n",
      "Epoch:  0021 D loss:-0.4515 G loss:-2.328\n",
      "Epoch:  0021 D loss:-0.4283 G loss:-2.249\n",
      "Epoch:  0021 D loss:-0.5121 G loss:-2.373\n",
      "Epoch:  0021 D loss:-0.4436 G loss:-2.401\n",
      "Epoch:  0021 D loss:-0.4756 G loss:-2.327\n",
      "Epoch:  0021 D loss:-0.3732 G loss:-2.455\n",
      "Epoch:  0021 D loss:-0.443 G loss:-2.295\n",
      "Epoch:  0021 D loss:-0.3823 G loss:-2.589\n",
      "Epoch:  0021 D loss:-0.3194 G loss:-2.482\n",
      "Epoch:  0021 D loss:-0.3932 G loss:-2.535\n",
      "Epoch:  0021 D loss:-0.3799 G loss:-2.524\n",
      "Epoch:  0021 D loss:-0.393 G loss:-2.628\n",
      "Epoch:  0021 D loss:-0.406 G loss:-2.673\n",
      "Epoch:  0021 D loss:-0.3975 G loss:-2.521\n",
      "Epoch:  0021 D loss:-0.3958 G loss:-2.513\n",
      "Epoch:  0021 D loss:-0.3847 G loss:-2.553\n",
      "Epoch:  0021 D loss:-0.3691 G loss:-2.588\n",
      "Epoch:  0021 D loss:-0.3798 G loss:-2.457\n",
      "Epoch:  0021 D loss:-0.4595 G loss:-2.384\n",
      "Epoch:  0021 D loss:-0.3079 G loss:-2.762\n",
      "Epoch:  0021 D loss:-0.4264 G loss:-2.505\n",
      "Epoch:  0021 D loss:-0.4301 G loss:-2.503\n",
      "Epoch:  0021 D loss:-0.4193 G loss:-2.456\n",
      "Epoch:  0021 D loss:-0.3726 G loss:-2.684\n",
      "Epoch:  0021 D loss:-0.4057 G loss:-2.542\n",
      "Epoch:  0021 D loss:-0.5724 G loss:-2.259\n",
      "Epoch:  0021 D loss:-0.4367 G loss:-2.26\n",
      "Epoch:  0021 D loss:-0.4653 G loss:-2.211\n",
      "Epoch:  0021 D loss:-0.4402 G loss:-2.313\n",
      "Epoch:  0021 D loss:-0.3349 G loss:-2.38\n",
      "Epoch:  0021 D loss:-0.3525 G loss:-2.624\n",
      "Epoch:  0021 D loss:-0.4815 G loss:-2.465\n",
      "Epoch:  0021 D loss:-0.4467 G loss:-2.509\n",
      "Epoch:  0021 D loss:-0.3305 G loss:-2.749\n",
      "Epoch:  0021 D loss:-0.4601 G loss:-2.548\n",
      "Epoch:  0021 D loss:-0.5625 G loss:-2.358\n",
      "Epoch:  0021 D loss:-0.4689 G loss:-2.488\n",
      "Epoch:  0021 D loss:-0.5671 G loss:-2.306\n",
      "Epoch:  0021 D loss:-0.5019 G loss:-2.313\n",
      "Epoch:  0021 D loss:-0.4449 G loss:-2.299\n",
      "Epoch:  0021 D loss:-0.5922 G loss:-2.187\n",
      "Epoch:  0021 D loss:-0.3525 G loss:-2.309\n",
      "Epoch:  0021 D loss:-0.5355 G loss:-2.323\n",
      "Epoch:  0021 D loss:-0.5138 G loss:-2.279\n",
      "Epoch:  0021 D loss:-0.4182 G loss:-2.436\n",
      "Epoch:  0021 D loss:-0.4584 G loss:-2.419\n",
      "Epoch:  0021 D loss:-0.5171 G loss:-2.402\n",
      "Epoch:  0021 D loss:-0.4422 G loss:-2.259\n",
      "Epoch:  0021 D loss:-0.5525 G loss:-2.321\n",
      "Epoch:  0021 D loss:-0.5609 G loss:-2.333\n",
      "Epoch:  0021 D loss:-0.4162 G loss:-2.533\n",
      "Epoch:  0021 D loss:-0.5065 G loss:-2.293\n",
      "Epoch:  0021 D loss:-0.468 G loss:-2.252\n",
      "Epoch:  0021 D loss:-0.4451 G loss:-2.379\n",
      "Epoch:  0021 D loss:-0.5537 G loss:-2.443\n",
      "Epoch:  0021 D loss:-0.4246 G loss:-2.508\n",
      "Epoch:  0021 D loss:-0.3603 G loss:-2.441\n",
      "Epoch:  0021 D loss:-0.4574 G loss:-2.468\n",
      "Epoch:  0021 D loss:-0.4727 G loss:-2.386\n",
      "Epoch:  0021 D loss:-0.5263 G loss:-2.191\n",
      "Epoch:  0021 D loss:-0.4258 G loss:-2.337\n",
      "Epoch:  0021 D loss:-0.3577 G loss:-2.601\n",
      "Epoch:  0021 D loss:-0.3744 G loss:-2.622\n",
      "Epoch:  0021 D loss:-0.4154 G loss:-2.374\n",
      "Epoch:  0021 D loss:-0.4005 G loss:-2.623\n",
      "Epoch:  0021 D loss:-0.4338 G loss:-2.679\n",
      "Epoch:  0021 D loss:-0.4132 G loss:-2.77\n",
      "Epoch:  0021 D loss:-0.4025 G loss:-2.667\n",
      "Epoch:  0021 D loss:-0.3628 G loss:-2.598\n",
      "Epoch:  0021 D loss:-0.3329 G loss:-2.559\n",
      "Epoch:  0021 D loss:-0.4615 G loss:-2.555\n",
      "Epoch:  0021 D loss:-0.4171 G loss:-2.538\n",
      "Epoch:  0021 D loss:-0.4299 G loss:-2.341\n",
      "Epoch:  0021 D loss:-0.3838 G loss:-2.396\n",
      "Epoch:  0021 D loss:-0.3795 G loss:-2.467\n",
      "Epoch:  0021 D loss:-0.4077 G loss:-2.461\n",
      "Epoch:  0021 D loss:-0.446 G loss:-2.46\n",
      "Epoch:  0021 D loss:-0.3953 G loss:-2.455\n",
      "Epoch:  0021 D loss:-0.3803 G loss:-2.622\n",
      "Epoch:  0021 D loss:-0.3933 G loss:-2.627\n",
      "Epoch:  0021 D loss:-0.4236 G loss:-2.838\n",
      "Epoch:  0021 D loss:-0.3333 G loss:-2.858\n",
      "Epoch:  0021 D loss:-0.4037 G loss:-2.572\n",
      "Epoch:  0021 D loss:-0.4304 G loss:-2.441\n",
      "Epoch:  0021 D loss:-0.3919 G loss:-2.403\n",
      "Epoch:  0021 D loss:-0.4086 G loss:-2.566\n",
      "Epoch:  0021 D loss:-0.3409 G loss:-2.634\n",
      "Epoch:  0021 D loss:-0.3113 G loss:-2.518\n",
      "Epoch:  0021 D loss:-0.3981 G loss:-2.455\n",
      "Epoch:  0021 D loss:-0.4285 G loss:-2.55\n",
      "Epoch:  0021 D loss:-0.3287 G loss:-2.628\n",
      "Epoch:  0021 D loss:-0.5168 G loss:-2.478\n",
      "Epoch:  0021 D loss:-0.4096 G loss:-2.549\n",
      "Epoch:  0021 D loss:-0.374 G loss:-2.509\n",
      "Epoch:  0021 D loss:-0.4178 G loss:-2.484\n",
      "Epoch:  0021 D loss:-0.4368 G loss:-2.668\n",
      "Epoch:  0021 D loss:-0.4254 G loss:-2.444\n",
      "Epoch:  0021 D loss:-0.4678 G loss:-2.557\n",
      "Epoch:  0021 D loss:-0.5558 G loss:-2.429\n",
      "Epoch:  0021 D loss:-0.4324 G loss:-2.484\n",
      "Epoch:  0021 D loss:-0.4299 G loss:-2.469\n",
      "Epoch:  0021 D loss:-0.3236 G loss:-2.271\n",
      "Epoch:  0021 D loss:-0.3617 G loss:-2.542\n",
      "Epoch:  0021 D loss:-0.4574 G loss:-2.594\n",
      "Epoch:  0021 D loss:-0.4687 G loss:-2.452\n",
      "Epoch:  0021 D loss:-0.3459 G loss:-2.506\n",
      "Epoch:  0021 D loss:-0.4352 G loss:-2.391\n",
      "Epoch:  0021 D loss:-0.3749 G loss:-2.318\n",
      "Epoch:  0021 D loss:-0.4943 G loss:-2.416\n",
      "Epoch:  0021 D loss:-0.495 G loss:-2.589\n",
      "Epoch:  0021 D loss:-0.3687 G loss:-2.606\n",
      "Epoch:  0021 D loss:-0.489 G loss:-2.414\n",
      "Epoch:  0021 D loss:-0.4036 G loss:-2.474\n",
      "Epoch:  0021 D loss:-0.3913 G loss:-2.73\n",
      "Epoch:  0021 D loss:-0.3582 G loss:-2.619\n",
      "Epoch:  0021 D loss:-0.5648 G loss:-2.495\n",
      "Epoch:  0021 D loss:-0.434 G loss:-2.322\n",
      "Epoch:  0021 D loss:-0.3982 G loss:-2.451\n",
      "Epoch:  0021 D loss:-0.5007 G loss:-2.359\n",
      "Epoch:  0021 D loss:-0.4507 G loss:-2.408\n",
      "Epoch:  0021 D loss:-0.5142 G loss:-2.59\n",
      "Epoch:  0021 D loss:-0.4227 G loss:-2.369\n",
      "Epoch:  0021 D loss:-0.42 G loss:-2.378\n",
      "Epoch:  0021 D loss:-0.3695 G loss:-2.285\n",
      "Epoch:  0021 D loss:-0.4585 G loss:-2.392\n",
      "Epoch:  0021 D loss:-0.501 G loss:-2.616\n",
      "Epoch:  0021 D loss:-0.4916 G loss:-2.525\n",
      "Epoch:  0021 D loss:-0.484 G loss:-2.541\n",
      "Epoch:  0021 D loss:-0.4975 G loss:-2.547\n",
      "Epoch:  0021 D loss:-0.465 G loss:-2.29\n",
      "Epoch:  0021 D loss:-0.4575 G loss:-2.486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0021 D loss:-0.5858 G loss:-2.374\n",
      "Epoch:  0021 D loss:-0.4755 G loss:-2.297\n",
      "Epoch:  0021 D loss:-0.4723 G loss:-2.241\n",
      "Epoch:  0021 D loss:-0.4098 G loss:-2.425\n",
      "Epoch:  0021 D loss:-0.5138 G loss:-2.188\n",
      "Epoch:  0021 D loss:-0.4618 G loss:-2.267\n",
      "Epoch:  0021 D loss:-0.4616 G loss:-2.523\n",
      "Epoch:  0021 D loss:-0.5011 G loss:-2.537\n",
      "Epoch:  0021 D loss:-0.5206 G loss:-2.513\n",
      "Epoch:  0021 D loss:-0.4657 G loss:-2.452\n",
      "Epoch:  0021 D loss:-0.4952 G loss:-2.431\n",
      "Epoch:  0021 D loss:-0.5093 G loss:-2.315\n",
      "Epoch:  0021 D loss:-0.4555 G loss:-2.639\n",
      "Epoch:  0021 D loss:-0.4468 G loss:-2.343\n",
      "Epoch:  0021 D loss:-0.6537 G loss:-2.163\n",
      "Epoch:  0021 D loss:-0.339 G loss:-2.409\n",
      "Epoch:  0021 D loss:-0.4424 G loss:-2.347\n",
      "Epoch:  0021 D loss:-0.6216 G loss:-2.442\n",
      "Epoch:  0021 D loss:-0.5372 G loss:-2.465\n",
      "Epoch:  0021 D loss:-0.4689 G loss:-2.703\n",
      "Epoch:  0021 D loss:-0.4444 G loss:-2.638\n",
      "Epoch:  0021 D loss:-0.5871 G loss:-2.478\n",
      "Epoch:  0021 D loss:-0.4435 G loss:-2.507\n",
      "Epoch:  0021 D loss:-0.5036 G loss:-2.347\n",
      "Epoch:  0021 D loss:-0.5193 G loss:-2.361\n",
      "Epoch:  0021 D loss:-0.4433 G loss:-2.285\n",
      "Epoch:  0021 D loss:-0.4296 G loss:-2.17\n",
      "Epoch:  0021 D loss:-0.3558 G loss:-2.469\n",
      "Epoch:  0021 D loss:-0.4721 G loss:-2.562\n",
      "Epoch:  0021 D loss:-0.4199 G loss:-2.493\n",
      "Epoch:  0021 D loss:-0.4701 G loss:-2.541\n",
      "Epoch:  0021 D loss:-0.3103 G loss:-2.618\n",
      "Epoch:  0021 D loss:-0.4355 G loss:-2.569\n",
      "Epoch:  0021 D loss:-0.4482 G loss:-2.613\n",
      "Epoch:  0021 D loss:-0.4238 G loss:-2.722\n",
      "Epoch:  0021 D loss:-0.4689 G loss:-2.441\n",
      "Epoch:  0021 D loss:-0.3912 G loss:-2.61\n",
      "Epoch:  0021 D loss:-0.4491 G loss:-2.377\n",
      "Epoch:  0021 D loss:-0.4608 G loss:-2.355\n",
      "Epoch:  0021 D loss:-0.3714 G loss:-2.469\n",
      "Epoch:  0021 D loss:-0.3779 G loss:-2.619\n",
      "Epoch:  0021 D loss:-0.3342 G loss:-2.745\n",
      "Epoch:  0021 D loss:-0.4612 G loss:-2.666\n",
      "Epoch:  0021 D loss:-0.4543 G loss:-2.511\n",
      "Epoch:  0021 D loss:-0.3522 G loss:-2.851\n",
      "Epoch:  0021 D loss:-0.3149 G loss:-2.652\n",
      "Epoch:  0021 D loss:-0.4619 G loss:-2.525\n",
      "Epoch:  0021 D loss:-0.419 G loss:-2.671\n",
      "Epoch:  0021 D loss:-0.4281 G loss:-2.702\n",
      "Epoch:  0021 D loss:-0.4238 G loss:-2.858\n",
      "Epoch:  0021 D loss:-0.3428 G loss:-2.79\n",
      "Epoch:  0021 D loss:-0.3885 G loss:-2.516\n",
      "Epoch:  0021 D loss:-0.3966 G loss:-2.583\n",
      "Epoch:  0021 D loss:-0.3507 G loss:-2.333\n",
      "Epoch:  0021 D loss:-0.398 G loss:-2.459\n",
      "Epoch:  0021 D loss:-0.4236 G loss:-2.472\n",
      "Epoch:  0021 D loss:-0.4055 G loss:-2.395\n",
      "Epoch:  0021 D loss:-0.3864 G loss:-2.588\n",
      "Epoch:  0021 D loss:-0.3545 G loss:-2.47\n",
      "Epoch:  0021 D loss:-0.3377 G loss:-2.673\n",
      "Epoch:  0021 D loss:-0.4216 G loss:-2.46\n",
      "Epoch:  0021 D loss:-0.3658 G loss:-2.536\n",
      "Epoch:  0021 D loss:-0.3609 G loss:-2.706\n",
      "Epoch:  0021 D loss:-0.347 G loss:-2.905\n",
      "Epoch:  0021 D loss:-0.3189 G loss:-2.906\n",
      "Epoch:  0021 D loss:-0.3146 G loss:-3.039\n",
      "Epoch:  0021 D loss:-0.3825 G loss:-2.856\n",
      "Epoch:  0021 D loss:-0.3852 G loss:-2.782\n",
      "Epoch:  0021 D loss:-0.3711 G loss:-2.749\n",
      "Epoch:  0021 D loss:-0.3452 G loss:-2.644\n",
      "Epoch:  0021 D loss:-0.4006 G loss:-2.485\n",
      "Epoch:  0021 D loss:-0.3439 G loss:-2.587\n",
      "Epoch:  0021 D loss:-0.3548 G loss:-2.607\n",
      "Epoch:  0021 D loss:-0.3939 G loss:-2.35\n",
      "Epoch:  0021 D loss:-0.4038 G loss:-2.49\n",
      "Epoch:  0021 D loss:-0.3706 G loss:-2.485\n",
      "Epoch:  0021 D loss:-0.4079 G loss:-2.391\n",
      "Epoch:  0021 D loss:-0.3159 G loss:-2.575\n",
      "Epoch:  0021 D loss:-0.3495 G loss:-2.649\n",
      "Epoch:  0021 D loss:-0.3712 G loss:-2.537\n",
      "Epoch:  0021 D loss:-0.4787 G loss:-2.615\n",
      "Epoch:  0021 D loss:-0.3629 G loss:-2.764\n",
      "Epoch:  0021 D loss:-0.3901 G loss:-2.577\n",
      "Epoch:  0021 D loss:-0.2967 G loss:-2.898\n",
      "Epoch:  0021 D loss:-0.3924 G loss:-2.595\n",
      "Epoch:  0021 D loss:-0.2101 G loss:-2.901\n",
      "Epoch:  0021 D loss:-0.3382 G loss:-2.784\n",
      "Epoch:  0021 D loss:-0.3832 G loss:-2.933\n",
      "Epoch:  0021 D loss:-0.3439 G loss:-2.742\n",
      "Epoch:  0021 D loss:-0.5033 G loss:-2.65\n",
      "Epoch:  0021 D loss:-0.3832 G loss:-2.287\n",
      "Epoch:  0021 D loss:-0.2534 G loss:-2.637\n",
      "Epoch:  0021 D loss:-0.4702 G loss:-2.415\n",
      "Epoch:  0021 D loss:-0.3574 G loss:-2.715\n",
      "Epoch:  0021 D loss:-0.4697 G loss:-2.572\n",
      "Epoch:  0021 D loss:-0.3542 G loss:-2.522\n",
      "Epoch:  0021 D loss:-0.2743 G loss:-2.598\n",
      "Epoch:  0021 D loss:-0.3602 G loss:-2.773\n",
      "Epoch:  0021 D loss:-0.3263 G loss:-2.804\n",
      "Epoch:  0021 D loss:-0.3495 G loss:-2.859\n",
      "Epoch:  0021 D loss:-0.3756 G loss:-2.716\n",
      "Epoch:  0021 D loss:-0.3862 G loss:-2.757\n",
      "Epoch:  0021 D loss:-0.3417 G loss:-2.638\n",
      "Epoch:  0021 D loss:-0.3936 G loss:-2.436\n",
      "Epoch:  0021 D loss:-0.3238 G loss:-2.579\n",
      "Epoch:  0021 D loss:-0.4326 G loss:-2.49\n",
      "Epoch:  0021 D loss:-0.4156 G loss:-2.552\n",
      "Epoch:  0021 D loss:-0.4272 G loss:-2.441\n",
      "Epoch:  0021 D loss:-0.3471 G loss:-2.321\n",
      "Epoch:  0021 D loss:-0.3969 G loss:-2.47\n",
      "Epoch:  0021 D loss:-0.4354 G loss:-2.397\n",
      "Epoch:  0021 D loss:-0.4337 G loss:-2.535\n",
      "Epoch:  0021 D loss:-0.4049 G loss:-2.555\n",
      "Epoch:  0021 D loss:-0.565 G loss:-2.513\n",
      "Epoch:  0021 D loss:-0.4188 G loss:-2.411\n",
      "Epoch:  0021 D loss:-0.3854 G loss:-2.616\n",
      "Epoch:  0021 D loss:-0.4167 G loss:-2.421\n",
      "Epoch:  0021 D loss:-0.4322 G loss:-2.493\n",
      "Epoch:  0021 D loss:-0.3745 G loss:-2.449\n",
      "Epoch:  0021 D loss:-0.4245 G loss:-2.537\n",
      "Epoch:  0021 D loss:-0.4054 G loss:-2.366\n",
      "Epoch:  0021 D loss:-0.3884 G loss:-2.457\n",
      "Epoch:  0021 D loss:-0.3627 G loss:-2.523\n",
      "Epoch:  0021 D loss:-0.4569 G loss:-2.477\n",
      "Epoch:  0021 D loss:-0.5242 G loss:-2.481\n",
      "Epoch:  0021 D loss:-0.4265 G loss:-2.831\n",
      "Epoch:  0021 D loss:-0.3639 G loss:-2.529\n",
      "Epoch:  0021 D loss:-0.5244 G loss:-2.651\n",
      "Epoch:  0021 D loss:-0.4037 G loss:-2.624\n",
      "Epoch:  0021 D loss:-0.3808 G loss:-2.475\n",
      "Epoch:  0021 D loss:-0.5302 G loss:-2.566\n",
      "Epoch:  0021 D loss:-0.4122 G loss:-2.328\n",
      "Epoch:  0021 D loss:-0.5298 G loss:-2.165\n",
      "Epoch:  0021 D loss:-0.5576 G loss:-2.21\n",
      "Epoch:  0021 D loss:-0.5446 G loss:-2.518\n",
      "Epoch:  0021 D loss:-0.3639 G loss:-2.461\n",
      "Epoch:  0021 D loss:-0.5401 G loss:-2.558\n",
      "Epoch:  0021 D loss:-0.5104 G loss:-2.461\n",
      "Epoch:  0021 D loss:-0.4819 G loss:-2.461\n",
      "Epoch:  0021 D loss:-0.4121 G loss:-2.543\n",
      "Epoch:  0021 D loss:-0.5227 G loss:-2.322\n",
      "Epoch:  0021 D loss:-0.4867 G loss:-2.362\n",
      "Epoch:  0021 D loss:-0.4172 G loss:-2.519\n",
      "Epoch:  0021 D loss:-0.4238 G loss:-2.737\n",
      "Epoch:  0021 D loss:-0.4089 G loss:-2.415\n",
      "Epoch:  0021 D loss:-0.5844 G loss:-2.4\n",
      "Epoch:  0021 D loss:-0.3958 G loss:-2.686\n",
      "Epoch:  0021 D loss:-0.5635 G loss:-2.362\n",
      "Epoch:  0021 D loss:-0.3836 G loss:-2.499\n",
      "Epoch:  0021 D loss:-0.4469 G loss:-2.552\n",
      "Epoch:  0021 D loss:-0.4114 G loss:-2.433\n",
      "Epoch:  0021 D loss:-0.4712 G loss:-2.368\n",
      "Epoch:  0021 D loss:-0.4274 G loss:-2.515\n",
      "Epoch:  0021 D loss:-0.5312 G loss:-2.519\n",
      "Epoch:  0021 D loss:-0.4425 G loss:-2.535\n",
      "Epoch:  0021 D loss:-0.3935 G loss:-2.657\n",
      "Epoch:  0021 D loss:-0.5006 G loss:-2.407\n",
      "Epoch:  0021 D loss:-0.4688 G loss:-2.641\n",
      "Epoch:  0021 D loss:-0.381 G loss:-2.442\n",
      "Epoch:  0021 D loss:-0.4933 G loss:-2.67\n",
      "Epoch:  0021 D loss:-0.4708 G loss:-2.494\n",
      "Epoch:  0021 D loss:-0.4397 G loss:-2.516\n",
      "Epoch:  0021 D loss:-0.4685 G loss:-2.317\n",
      "Epoch:  0021 D loss:-0.4583 G loss:-2.47\n",
      "Epoch:  0021 D loss:-0.4814 G loss:-2.473\n",
      "Epoch:  0021 D loss:-0.3462 G loss:-2.448\n",
      "Epoch:  0021 D loss:-0.4378 G loss:-2.521\n",
      "Epoch:  0021 D loss:-0.3568 G loss:-2.491\n",
      "Epoch:  0021 D loss:-0.3857 G loss:-2.469\n",
      "Epoch:  0021 D loss:-0.4043 G loss:-2.497\n",
      "Epoch:  0021 D loss:-0.4604 G loss:-2.396\n",
      "Epoch:  0021 D loss:-0.3748 G loss:-2.435\n",
      "Epoch:  0021 D loss:-0.3639 G loss:-2.74\n",
      "Epoch:  0021 D loss:-0.402 G loss:-2.662\n",
      "Epoch:  0021 D loss:-0.4892 G loss:-2.44\n",
      "Epoch:  0021 D loss:-0.4894 G loss:-2.434\n",
      "Epoch:  0021 D loss:-0.4312 G loss:-2.583\n",
      "Epoch:  0021 D loss:-0.4484 G loss:-2.572\n",
      "Epoch:  0021 D loss:-0.414 G loss:-2.652\n",
      "Epoch:  0021 D loss:-0.3453 G loss:-2.701\n",
      "Epoch:  0021 D loss:-0.4228 G loss:-2.538\n",
      "Epoch:  0021 D loss:-0.4278 G loss:-2.688\n",
      "Epoch:  0021 D loss:-0.4951 G loss:-2.348\n",
      "Epoch:  0021 D loss:-0.5646 G loss:-2.534\n",
      "Epoch:  0021 D loss:-0.4046 G loss:-2.341\n",
      "Epoch:  0021 D loss:-0.4073 G loss:-2.451\n",
      "Epoch:  0021 D loss:-0.3667 G loss:-2.582\n",
      "Epoch:  0021 D loss:-0.3438 G loss:-2.242\n",
      "Epoch:  0021 D loss:-0.3979 G loss:-2.303\n",
      "Epoch:  0021 D loss:-0.4316 G loss:-2.606\n",
      "Epoch:  0021 D loss:-0.3916 G loss:-2.56\n",
      "Epoch:  0021 D loss:-0.41 G loss:-2.553\n",
      "Epoch:  0021 D loss:-0.5384 G loss:-2.424\n",
      "Epoch:  0021 D loss:-0.4879 G loss:-2.618\n",
      "Epoch:  0021 D loss:-0.4693 G loss:-2.503\n",
      "Epoch:  0021 D loss:-0.4311 G loss:-2.554\n",
      "Epoch:  0021 D loss:-0.4177 G loss:-2.59\n",
      "Epoch:  0021 D loss:-0.4109 G loss:-2.614\n",
      "Epoch:  0021 D loss:-0.3079 G loss:-2.703\n",
      "Epoch:  0021 D loss:-0.4077 G loss:-2.488\n",
      "Epoch:  0021 D loss:-0.5041 G loss:-2.4\n",
      "Epoch:  0021 D loss:-0.3062 G loss:-2.583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0021 D loss:-0.4775 G loss:-2.725\n",
      "Epoch:  0021 D loss:-0.3885 G loss:-2.75\n",
      "Epoch:  0021 D loss:-0.4394 G loss:-2.437\n",
      "Epoch:  0021 D loss:-0.4315 G loss:-2.49\n",
      "Epoch:  0021 D loss:-0.3748 G loss:-2.597\n",
      "Epoch:  0021 D loss:-0.397 G loss:-2.539\n",
      "Epoch:  0021 D loss:-0.4462 G loss:-2.506\n",
      "Epoch:  0021 D loss:-0.3879 G loss:-2.477\n",
      "Epoch:  0021 D loss:-0.3372 G loss:-2.569\n",
      "Epoch:  0021 D loss:-0.4909 G loss:-2.515\n",
      "Epoch:  0021 D loss:-0.4075 G loss:-2.713\n",
      "Epoch:  0021 D loss:-0.4026 G loss:-2.653\n",
      "Epoch:  0021 D loss:-0.3382 G loss:-2.587\n",
      "Epoch:  0021 D loss:-0.3863 G loss:-2.786\n",
      "Epoch:  0021 D loss:-0.2892 G loss:-2.811\n",
      "Epoch:  0021 D loss:-0.4107 G loss:-2.71\n",
      "Epoch:  0021 D loss:-0.3929 G loss:-2.764\n",
      "Epoch:  0021 D loss:-0.3725 G loss:-2.663\n",
      "Epoch:  0021 D loss:-0.4397 G loss:-2.662\n",
      "Epoch:  0021 D loss:-0.4118 G loss:-2.539\n",
      "Epoch:  0021 D loss:-0.4229 G loss:-2.28\n",
      "Epoch:  0021 D loss:-0.3777 G loss:-2.399\n",
      "Epoch:  0021 D loss:-0.396 G loss:-2.482\n",
      "Epoch:  0021 D loss:-0.3547 G loss:-2.306\n",
      "Epoch:  0021 D loss:-0.3665 G loss:-2.404\n",
      "Epoch:  0021 D loss:-0.3398 G loss:-2.564\n",
      "Epoch:  0021 D loss:-0.4178 G loss:-2.396\n",
      "Epoch:  0021 D loss:-0.3832 G loss:-2.484\n",
      "Epoch:  0021 D loss:-0.4659 G loss:-2.641\n",
      "Epoch:  0021 D loss:-0.3326 G loss:-2.619\n",
      "Epoch:  0021 D loss:-0.3886 G loss:-2.667\n",
      "Epoch:  0021 D loss:-0.3758 G loss:-2.753\n",
      "Epoch:  0021 D loss:-0.3572 G loss:-2.861\n",
      "Epoch:  0021 D loss:-0.3133 G loss:-3.027\n",
      "Epoch:  0021 D loss:-0.3421 G loss:-2.965\n",
      "Epoch:  0021 D loss:-0.3244 G loss:-2.724\n",
      "Epoch:  0021 D loss:-0.4048 G loss:-2.668\n",
      "Epoch:  0021 D loss:-0.3679 G loss:-2.527\n",
      "Epoch:  0021 D loss:-0.3078 G loss:-2.677\n",
      "Epoch:  0021 D loss:-0.3555 G loss:-2.521\n",
      "Epoch:  0021 D loss:-0.3426 G loss:-2.416\n",
      "Epoch:  0021 D loss:-0.335 G loss:-2.577\n",
      "Epoch:  0021 D loss:-0.3083 G loss:-2.637\n",
      "Epoch:  0021 D loss:-0.4055 G loss:-2.794\n",
      "Epoch:  0021 D loss:-0.3959 G loss:-2.831\n",
      "Epoch:  0021 D loss:-0.309 G loss:-2.647\n",
      "Epoch:  0021 D loss:-0.4681 G loss:-2.623\n",
      "Epoch:  0021 D loss:-0.4286 G loss:-2.615\n",
      "Epoch:  0021 D loss:-0.3295 G loss:-2.547\n",
      "Epoch:  0021 D loss:-0.4044 G loss:-2.452\n",
      "Epoch:  0021 D loss:-0.3901 G loss:-2.56\n",
      "Epoch:  0021 D loss:-0.4747 G loss:-2.57\n",
      "Epoch:  0021 D loss:-0.412 G loss:-2.615\n",
      "Epoch:  0022 D loss:-0.3597 G loss:-2.792\n",
      "Epoch:  0022 D loss:-0.3519 G loss:-2.777\n",
      "Epoch:  0022 D loss:-0.353 G loss:-2.79\n",
      "Epoch:  0022 D loss:-0.3732 G loss:-2.594\n",
      "Epoch:  0022 D loss:-0.3625 G loss:-2.522\n",
      "Epoch:  0022 D loss:-0.3136 G loss:-2.582\n",
      "Epoch:  0022 D loss:-0.3579 G loss:-2.587\n",
      "Epoch:  0022 D loss:-0.4126 G loss:-2.849\n",
      "Epoch:  0022 D loss:-0.3101 G loss:-2.966\n",
      "Epoch:  0022 D loss:-0.4087 G loss:-2.557\n",
      "Epoch:  0022 D loss:-0.4582 G loss:-2.588\n",
      "Epoch:  0022 D loss:-0.5043 G loss:-2.536\n",
      "Epoch:  0022 D loss:-0.5821 G loss:-2.672\n",
      "Epoch:  0022 D loss:-0.4686 G loss:-2.42\n",
      "Epoch:  0022 D loss:-0.4294 G loss:-2.723\n",
      "Epoch:  0022 D loss:-0.356 G loss:-2.422\n",
      "Epoch:  0022 D loss:-0.3756 G loss:-2.221\n",
      "Epoch:  0022 D loss:-0.4769 G loss:-2.282\n",
      "Epoch:  0022 D loss:-0.4464 G loss:-2.266\n",
      "Epoch:  0022 D loss:-0.5164 G loss:-2.267\n",
      "Epoch:  0022 D loss:-0.5077 G loss:-2.464\n",
      "Epoch:  0022 D loss:-0.4711 G loss:-2.514\n",
      "Epoch:  0022 D loss:-0.3797 G loss:-2.606\n",
      "Epoch:  0022 D loss:-0.5298 G loss:-2.555\n",
      "Epoch:  0022 D loss:-0.3666 G loss:-2.566\n",
      "Epoch:  0022 D loss:-0.4941 G loss:-2.496\n",
      "Epoch:  0022 D loss:-0.5551 G loss:-2.456\n",
      "Epoch:  0022 D loss:-0.3747 G loss:-2.643\n",
      "Epoch:  0022 D loss:-0.3514 G loss:-2.637\n",
      "Epoch:  0022 D loss:-0.4716 G loss:-2.594\n",
      "Epoch:  0022 D loss:-0.407 G loss:-2.617\n",
      "Epoch:  0022 D loss:-0.4435 G loss:-2.329\n",
      "Epoch:  0022 D loss:-0.4275 G loss:-2.498\n",
      "Epoch:  0022 D loss:-0.3726 G loss:-2.428\n",
      "Epoch:  0022 D loss:-0.4039 G loss:-2.494\n",
      "Epoch:  0022 D loss:-0.4254 G loss:-2.448\n",
      "Epoch:  0022 D loss:-0.2822 G loss:-2.588\n",
      "Epoch:  0022 D loss:-0.3622 G loss:-2.878\n",
      "Epoch:  0022 D loss:-0.37 G loss:-2.675\n",
      "Epoch:  0022 D loss:-0.3571 G loss:-2.686\n",
      "Epoch:  0022 D loss:-0.3836 G loss:-2.5\n",
      "Epoch:  0022 D loss:-0.4133 G loss:-2.621\n",
      "Epoch:  0022 D loss:-0.3272 G loss:-2.708\n",
      "Epoch:  0022 D loss:-0.5115 G loss:-2.495\n",
      "Epoch:  0022 D loss:-0.3431 G loss:-2.703\n",
      "Epoch:  0022 D loss:-0.2936 G loss:-2.847\n",
      "Epoch:  0022 D loss:-0.4236 G loss:-2.786\n",
      "Epoch:  0022 D loss:-0.3813 G loss:-2.766\n",
      "Epoch:  0022 D loss:-0.4092 G loss:-2.716\n",
      "Epoch:  0022 D loss:-0.3706 G loss:-2.605\n",
      "Epoch:  0022 D loss:-0.4659 G loss:-2.544\n",
      "Epoch:  0022 D loss:-0.4764 G loss:-2.597\n",
      "Epoch:  0022 D loss:-0.339 G loss:-2.708\n",
      "Epoch:  0022 D loss:-0.407 G loss:-2.466\n",
      "Epoch:  0022 D loss:-0.3745 G loss:-2.867\n",
      "Epoch:  0022 D loss:-0.3792 G loss:-2.618\n",
      "Epoch:  0022 D loss:-0.3629 G loss:-2.775\n",
      "Epoch:  0022 D loss:-0.4008 G loss:-2.749\n",
      "Epoch:  0022 D loss:-0.2982 G loss:-2.821\n",
      "Epoch:  0022 D loss:-0.3591 G loss:-2.832\n",
      "Epoch:  0022 D loss:-0.4619 G loss:-2.76\n",
      "Epoch:  0022 D loss:-0.3331 G loss:-2.733\n",
      "Epoch:  0022 D loss:-0.3879 G loss:-2.513\n",
      "Epoch:  0022 D loss:-0.3529 G loss:-2.486\n",
      "Epoch:  0022 D loss:-0.3709 G loss:-2.721\n",
      "Epoch:  0022 D loss:-0.4397 G loss:-2.82\n",
      "Epoch:  0022 D loss:-0.3009 G loss:-2.937\n",
      "Epoch:  0022 D loss:-0.3874 G loss:-3.092\n",
      "Epoch:  0022 D loss:-0.3437 G loss:-2.818\n",
      "Epoch:  0022 D loss:-0.3366 G loss:-2.847\n",
      "Epoch:  0022 D loss:-0.3784 G loss:-2.65\n",
      "Epoch:  0022 D loss:-0.3672 G loss:-2.836\n",
      "Epoch:  0022 D loss:-0.4034 G loss:-2.777\n",
      "Epoch:  0022 D loss:-0.302 G loss:-2.794\n",
      "Epoch:  0022 D loss:-0.3711 G loss:-2.67\n",
      "Epoch:  0022 D loss:-0.4774 G loss:-2.599\n",
      "Epoch:  0022 D loss:-0.3109 G loss:-2.831\n",
      "Epoch:  0022 D loss:-0.4175 G loss:-2.741\n",
      "Epoch:  0022 D loss:-0.5166 G loss:-2.458\n",
      "Epoch:  0022 D loss:-0.3838 G loss:-2.812\n",
      "Epoch:  0022 D loss:-0.411 G loss:-2.736\n",
      "Epoch:  0022 D loss:-0.4279 G loss:-2.648\n",
      "Epoch:  0022 D loss:-0.3972 G loss:-2.531\n",
      "Epoch:  0022 D loss:-0.3357 G loss:-2.543\n",
      "Epoch:  0022 D loss:-0.4603 G loss:-2.421\n",
      "Epoch:  0022 D loss:-0.4137 G loss:-2.543\n",
      "Epoch:  0022 D loss:-0.5301 G loss:-2.37\n",
      "Epoch:  0022 D loss:-0.5152 G loss:-2.487\n",
      "Epoch:  0022 D loss:-0.4839 G loss:-2.361\n",
      "Epoch:  0022 D loss:-0.3874 G loss:-2.805\n",
      "Epoch:  0022 D loss:-0.416 G loss:-2.815\n",
      "Epoch:  0022 D loss:-0.4133 G loss:-2.691\n",
      "Epoch:  0022 D loss:-0.3564 G loss:-2.704\n",
      "Epoch:  0022 D loss:-0.4083 G loss:-2.606\n",
      "Epoch:  0022 D loss:-0.4371 G loss:-2.555\n",
      "Epoch:  0022 D loss:-0.3141 G loss:-2.736\n",
      "Epoch:  0022 D loss:-0.4172 G loss:-2.685\n",
      "Epoch:  0022 D loss:-0.373 G loss:-2.696\n",
      "Epoch:  0022 D loss:-0.4494 G loss:-2.634\n",
      "Epoch:  0022 D loss:-0.4228 G loss:-2.775\n",
      "Epoch:  0022 D loss:-0.444 G loss:-2.542\n",
      "Epoch:  0022 D loss:-0.4106 G loss:-2.224\n",
      "Epoch:  0022 D loss:-0.483 G loss:-2.499\n",
      "Epoch:  0022 D loss:-0.3855 G loss:-2.689\n",
      "Epoch:  0022 D loss:-0.4424 G loss:-2.592\n",
      "Epoch:  0022 D loss:-0.375 G loss:-2.769\n",
      "Epoch:  0022 D loss:-0.2789 G loss:-2.844\n",
      "Epoch:  0022 D loss:-0.413 G loss:-2.629\n",
      "Epoch:  0022 D loss:-0.369 G loss:-2.694\n",
      "Epoch:  0022 D loss:-0.4909 G loss:-2.723\n",
      "Epoch:  0022 D loss:-0.3948 G loss:-2.815\n",
      "Epoch:  0022 D loss:-0.3461 G loss:-2.911\n",
      "Epoch:  0022 D loss:-0.3476 G loss:-2.815\n",
      "Epoch:  0022 D loss:-0.345 G loss:-2.874\n",
      "Epoch:  0022 D loss:-0.3372 G loss:-2.888\n",
      "Epoch:  0022 D loss:-0.3401 G loss:-2.958\n",
      "Epoch:  0022 D loss:-0.4699 G loss:-2.696\n",
      "Epoch:  0022 D loss:-0.381 G loss:-2.321\n",
      "Epoch:  0022 D loss:-0.3902 G loss:-2.443\n",
      "Epoch:  0022 D loss:-0.3994 G loss:-2.474\n",
      "Epoch:  0022 D loss:-0.3741 G loss:-2.53\n",
      "Epoch:  0022 D loss:-0.4186 G loss:-2.344\n",
      "Epoch:  0022 D loss:-0.4243 G loss:-2.38\n",
      "Epoch:  0022 D loss:-0.5377 G loss:-2.495\n",
      "Epoch:  0022 D loss:-0.3272 G loss:-2.743\n",
      "Epoch:  0022 D loss:-0.3241 G loss:-2.876\n",
      "Epoch:  0022 D loss:-0.4155 G loss:-2.951\n",
      "Epoch:  0022 D loss:-0.3127 G loss:-2.974\n",
      "Epoch:  0022 D loss:-0.3914 G loss:-2.648\n",
      "Epoch:  0022 D loss:-0.3688 G loss:-2.812\n",
      "Epoch:  0022 D loss:-0.3781 G loss:-2.82\n",
      "Epoch:  0022 D loss:-0.4078 G loss:-2.808\n",
      "Epoch:  0022 D loss:-0.3796 G loss:-2.681\n",
      "Epoch:  0022 D loss:-0.4393 G loss:-2.482\n",
      "Epoch:  0022 D loss:-0.3258 G loss:-2.604\n",
      "Epoch:  0022 D loss:-0.3651 G loss:-2.48\n",
      "Epoch:  0022 D loss:-0.2908 G loss:-2.559\n",
      "Epoch:  0022 D loss:-0.3552 G loss:-2.57\n",
      "Epoch:  0022 D loss:-0.3898 G loss:-2.598\n",
      "Epoch:  0022 D loss:-0.377 G loss:-2.773\n",
      "Epoch:  0022 D loss:-0.437 G loss:-2.767\n",
      "Epoch:  0022 D loss:-0.365 G loss:-2.699\n",
      "Epoch:  0022 D loss:-0.3094 G loss:-2.774\n",
      "Epoch:  0022 D loss:-0.4193 G loss:-2.757\n",
      "Epoch:  0022 D loss:-0.3696 G loss:-2.832\n",
      "Epoch:  0022 D loss:-0.4079 G loss:-2.805\n",
      "Epoch:  0022 D loss:-0.4264 G loss:-2.737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0022 D loss:-0.3545 G loss:-2.775\n",
      "Epoch:  0022 D loss:-0.4038 G loss:-2.749\n",
      "Epoch:  0022 D loss:-0.3465 G loss:-2.779\n",
      "Epoch:  0022 D loss:-0.3752 G loss:-2.932\n",
      "Epoch:  0022 D loss:-0.3362 G loss:-2.566\n",
      "Epoch:  0022 D loss:-0.4608 G loss:-2.445\n",
      "Epoch:  0022 D loss:-0.3616 G loss:-2.487\n",
      "Epoch:  0022 D loss:-0.3472 G loss:-2.711\n",
      "Epoch:  0022 D loss:-0.3856 G loss:-2.399\n",
      "Epoch:  0022 D loss:-0.4086 G loss:-2.631\n",
      "Epoch:  0022 D loss:-0.4111 G loss:-2.802\n",
      "Epoch:  0022 D loss:-0.4404 G loss:-2.833\n",
      "Epoch:  0022 D loss:-0.4397 G loss:-2.731\n",
      "Epoch:  0022 D loss:-0.3798 G loss:-2.686\n",
      "Epoch:  0022 D loss:-0.4073 G loss:-2.983\n",
      "Epoch:  0022 D loss:-0.3772 G loss:-2.811\n",
      "Epoch:  0022 D loss:-0.4099 G loss:-2.806\n",
      "Epoch:  0022 D loss:-0.357 G loss:-2.802\n",
      "Epoch:  0022 D loss:-0.3525 G loss:-2.608\n",
      "Epoch:  0022 D loss:-0.4057 G loss:-2.699\n",
      "Epoch:  0022 D loss:-0.4691 G loss:-2.671\n",
      "Epoch:  0022 D loss:-0.5132 G loss:-2.386\n",
      "Epoch:  0022 D loss:-0.3498 G loss:-2.595\n",
      "Epoch:  0022 D loss:-0.5819 G loss:-2.309\n",
      "Epoch:  0022 D loss:-0.5398 G loss:-2.543\n",
      "Epoch:  0022 D loss:-0.4484 G loss:-2.659\n",
      "Epoch:  0022 D loss:-0.4721 G loss:-2.648\n",
      "Epoch:  0022 D loss:-0.4155 G loss:-2.561\n",
      "Epoch:  0022 D loss:-0.5203 G loss:-2.628\n",
      "Epoch:  0022 D loss:-0.3849 G loss:-2.79\n",
      "Epoch:  0022 D loss:-0.4919 G loss:-2.661\n",
      "Epoch:  0022 D loss:-0.4072 G loss:-2.588\n",
      "Epoch:  0022 D loss:-0.4837 G loss:-2.755\n",
      "Epoch:  0022 D loss:-0.5499 G loss:-2.503\n",
      "Epoch:  0022 D loss:-0.4921 G loss:-2.442\n",
      "Epoch:  0022 D loss:-0.4621 G loss:-2.546\n",
      "Epoch:  0022 D loss:-0.4598 G loss:-2.369\n",
      "Epoch:  0022 D loss:-0.5077 G loss:-2.37\n",
      "Epoch:  0022 D loss:-0.4495 G loss:-2.41\n",
      "Epoch:  0022 D loss:-0.4191 G loss:-2.403\n",
      "Epoch:  0022 D loss:-0.3757 G loss:-2.435\n",
      "Epoch:  0022 D loss:-0.408 G loss:-2.722\n",
      "Epoch:  0022 D loss:-0.4195 G loss:-2.718\n",
      "Epoch:  0022 D loss:-0.2903 G loss:-3.068\n",
      "Epoch:  0022 D loss:-0.4036 G loss:-2.957\n",
      "Epoch:  0022 D loss:-0.3693 G loss:-2.804\n",
      "Epoch:  0022 D loss:-0.4895 G loss:-2.927\n",
      "Epoch:  0022 D loss:-0.3122 G loss:-2.942\n",
      "Epoch:  0022 D loss:-0.3421 G loss:-2.957\n",
      "Epoch:  0022 D loss:-0.322 G loss:-2.99\n",
      "Epoch:  0022 D loss:-0.427 G loss:-2.826\n",
      "Epoch:  0022 D loss:-0.3857 G loss:-2.832\n",
      "Epoch:  0022 D loss:-0.2676 G loss:-2.878\n",
      "Epoch:  0022 D loss:-0.3547 G loss:-2.627\n",
      "Epoch:  0022 D loss:-0.3374 G loss:-2.701\n",
      "Epoch:  0022 D loss:-0.2681 G loss:-2.872\n",
      "Epoch:  0022 D loss:-0.345 G loss:-2.751\n",
      "Epoch:  0022 D loss:-0.2678 G loss:-2.715\n",
      "Epoch:  0022 D loss:-0.29 G loss:-2.966\n",
      "Epoch:  0022 D loss:-0.3082 G loss:-2.998\n",
      "Epoch:  0022 D loss:-0.2511 G loss:-3.012\n",
      "Epoch:  0022 D loss:-0.3494 G loss:-3.015\n",
      "Epoch:  0022 D loss:-0.2538 G loss:-2.874\n",
      "Epoch:  0022 D loss:-0.2299 G loss:-3.197\n",
      "Epoch:  0022 D loss:-0.4417 G loss:-2.838\n",
      "Epoch:  0022 D loss:-0.2781 G loss:-2.767\n",
      "Epoch:  0022 D loss:-0.2493 G loss:-2.948\n",
      "Epoch:  0022 D loss:-0.2825 G loss:-3.166\n",
      "Epoch:  0022 D loss:-0.2671 G loss:-3.12\n",
      "Epoch:  0022 D loss:-0.287 G loss:-2.939\n",
      "Epoch:  0022 D loss:-0.3037 G loss:-2.833\n",
      "Epoch:  0022 D loss:-0.343 G loss:-2.774\n",
      "Epoch:  0022 D loss:-0.2918 G loss:-2.732\n",
      "Epoch:  0022 D loss:-0.313 G loss:-2.777\n",
      "Epoch:  0022 D loss:-0.371 G loss:-2.814\n",
      "Epoch:  0022 D loss:-0.2257 G loss:-3.068\n",
      "Epoch:  0022 D loss:-0.2789 G loss:-2.87\n",
      "Epoch:  0022 D loss:-0.3154 G loss:-2.739\n",
      "Epoch:  0022 D loss:-0.3004 G loss:-2.942\n",
      "Epoch:  0022 D loss:-0.2735 G loss:-3.049\n",
      "Epoch:  0022 D loss:-0.2669 G loss:-3.03\n",
      "Epoch:  0022 D loss:-0.3244 G loss:-2.862\n",
      "Epoch:  0022 D loss:-0.2966 G loss:-2.822\n",
      "Epoch:  0022 D loss:-0.2454 G loss:-2.988\n",
      "Epoch:  0022 D loss:-0.2877 G loss:-2.884\n",
      "Epoch:  0022 D loss:-0.2813 G loss:-2.793\n",
      "Epoch:  0022 D loss:-0.2694 G loss:-2.995\n",
      "Epoch:  0022 D loss:-0.3006 G loss:-3.001\n",
      "Epoch:  0022 D loss:-0.3939 G loss:-3.17\n",
      "Epoch:  0022 D loss:-0.2937 G loss:-2.887\n",
      "Epoch:  0022 D loss:-0.2421 G loss:-3.214\n",
      "Epoch:  0022 D loss:-0.3304 G loss:-3.216\n",
      "Epoch:  0022 D loss:-0.2753 G loss:-3.164\n",
      "Epoch:  0022 D loss:-0.2787 G loss:-2.992\n",
      "Epoch:  0022 D loss:-0.2998 G loss:-2.888\n",
      "Epoch:  0022 D loss:-0.3757 G loss:-2.912\n",
      "Epoch:  0022 D loss:-0.2367 G loss:-2.983\n",
      "Epoch:  0022 D loss:-0.2481 G loss:-2.798\n",
      "Epoch:  0022 D loss:-0.4148 G loss:-2.589\n",
      "Epoch:  0022 D loss:-0.3648 G loss:-2.77\n",
      "Epoch:  0022 D loss:-0.3633 G loss:-2.887\n",
      "Epoch:  0022 D loss:-0.3856 G loss:-2.688\n",
      "Epoch:  0022 D loss:-0.4006 G loss:-2.764\n",
      "Epoch:  0022 D loss:-0.35 G loss:-2.717\n",
      "Epoch:  0022 D loss:-0.2537 G loss:-2.943\n",
      "Epoch:  0022 D loss:-0.4016 G loss:-2.969\n",
      "Epoch:  0022 D loss:-0.2797 G loss:-2.843\n",
      "Epoch:  0022 D loss:-0.4064 G loss:-2.747\n",
      "Epoch:  0022 D loss:-0.357 G loss:-2.868\n",
      "Epoch:  0022 D loss:-0.3795 G loss:-2.82\n",
      "Epoch:  0022 D loss:-0.2807 G loss:-2.595\n",
      "Epoch:  0022 D loss:-0.4204 G loss:-2.769\n",
      "Epoch:  0022 D loss:-0.3289 G loss:-2.775\n",
      "Epoch:  0022 D loss:-0.3279 G loss:-2.78\n",
      "Epoch:  0022 D loss:-0.3487 G loss:-2.949\n",
      "Epoch:  0022 D loss:-0.4129 G loss:-2.587\n",
      "Epoch:  0022 D loss:-0.5039 G loss:-2.6\n",
      "Epoch:  0022 D loss:-0.3555 G loss:-2.857\n",
      "Epoch:  0022 D loss:-0.5302 G loss:-2.43\n",
      "Epoch:  0022 D loss:-0.3692 G loss:-2.494\n",
      "Epoch:  0022 D loss:-0.3564 G loss:-2.476\n",
      "Epoch:  0022 D loss:-0.3458 G loss:-2.51\n",
      "Epoch:  0022 D loss:-0.4187 G loss:-2.662\n",
      "Epoch:  0022 D loss:-0.4008 G loss:-2.571\n",
      "Epoch:  0022 D loss:-0.3791 G loss:-2.578\n",
      "Epoch:  0022 D loss:-0.3056 G loss:-2.787\n",
      "Epoch:  0022 D loss:-0.3596 G loss:-2.795\n",
      "Epoch:  0022 D loss:-0.3949 G loss:-2.863\n",
      "Epoch:  0022 D loss:-0.4605 G loss:-2.774\n",
      "Epoch:  0022 D loss:-0.4185 G loss:-2.692\n",
      "Epoch:  0022 D loss:-0.3905 G loss:-2.776\n",
      "Epoch:  0022 D loss:-0.3117 G loss:-2.853\n",
      "Epoch:  0022 D loss:-0.5128 G loss:-2.731\n",
      "Epoch:  0022 D loss:-0.2806 G loss:-2.784\n",
      "Epoch:  0022 D loss:-0.3651 G loss:-2.772\n",
      "Epoch:  0022 D loss:-0.2848 G loss:-2.958\n",
      "Epoch:  0022 D loss:-0.4491 G loss:-2.609\n",
      "Epoch:  0022 D loss:-0.3721 G loss:-2.687\n",
      "Epoch:  0022 D loss:-0.3834 G loss:-2.62\n",
      "Epoch:  0022 D loss:-0.2426 G loss:-2.863\n",
      "Epoch:  0022 D loss:-0.2214 G loss:-2.979\n",
      "Epoch:  0022 D loss:-0.3123 G loss:-3.037\n",
      "Epoch:  0022 D loss:-0.4404 G loss:-2.773\n",
      "Epoch:  0022 D loss:-0.3007 G loss:-2.848\n",
      "Epoch:  0022 D loss:-0.3792 G loss:-2.943\n",
      "Epoch:  0022 D loss:-0.2399 G loss:-2.881\n",
      "Epoch:  0022 D loss:-0.4217 G loss:-2.943\n",
      "Epoch:  0022 D loss:-0.358 G loss:-2.934\n",
      "Epoch:  0022 D loss:-0.3169 G loss:-2.962\n",
      "Epoch:  0022 D loss:-0.2161 G loss:-3.182\n",
      "Epoch:  0022 D loss:-0.321 G loss:-2.59\n",
      "Epoch:  0022 D loss:-0.2986 G loss:-3.053\n",
      "Epoch:  0022 D loss:-0.2508 G loss:-2.943\n",
      "Epoch:  0022 D loss:-0.2458 G loss:-2.873\n",
      "Epoch:  0022 D loss:-0.3668 G loss:-2.866\n",
      "Epoch:  0022 D loss:-0.3188 G loss:-2.879\n",
      "Epoch:  0022 D loss:-0.2861 G loss:-2.913\n",
      "Epoch:  0022 D loss:-0.2712 G loss:-3.006\n",
      "Epoch:  0022 D loss:-0.4215 G loss:-3.071\n",
      "Epoch:  0022 D loss:-0.3351 G loss:-2.8\n",
      "Epoch:  0022 D loss:-0.285 G loss:-2.848\n",
      "Epoch:  0022 D loss:-0.2481 G loss:-2.891\n",
      "Epoch:  0022 D loss:-0.3913 G loss:-2.734\n",
      "Epoch:  0022 D loss:-0.3618 G loss:-2.863\n",
      "Epoch:  0022 D loss:-0.3353 G loss:-2.663\n",
      "Epoch:  0022 D loss:-0.3382 G loss:-2.932\n",
      "Epoch:  0022 D loss:-0.3766 G loss:-2.555\n",
      "Epoch:  0022 D loss:-0.4252 G loss:-2.772\n",
      "Epoch:  0022 D loss:-0.2792 G loss:-2.85\n",
      "Epoch:  0022 D loss:-0.2669 G loss:-2.888\n",
      "Epoch:  0022 D loss:-0.41 G loss:-2.719\n",
      "Epoch:  0022 D loss:-0.3474 G loss:-2.735\n",
      "Epoch:  0022 D loss:-0.3812 G loss:-2.854\n",
      "Epoch:  0022 D loss:-0.3539 G loss:-2.829\n",
      "Epoch:  0022 D loss:-0.4327 G loss:-2.953\n",
      "Epoch:  0022 D loss:-0.3827 G loss:-2.868\n",
      "Epoch:  0022 D loss:-0.3408 G loss:-2.714\n",
      "Epoch:  0022 D loss:-0.3162 G loss:-2.53\n",
      "Epoch:  0022 D loss:-0.3448 G loss:-2.612\n",
      "Epoch:  0022 D loss:-0.483 G loss:-2.517\n",
      "Epoch:  0022 D loss:-0.3396 G loss:-2.559\n",
      "Epoch:  0022 D loss:-0.4122 G loss:-2.484\n",
      "Epoch:  0022 D loss:-0.3657 G loss:-2.68\n",
      "Epoch:  0022 D loss:-0.4225 G loss:-2.38\n",
      "Epoch:  0022 D loss:-0.3408 G loss:-2.643\n",
      "Epoch:  0022 D loss:-0.4249 G loss:-2.447\n",
      "Epoch:  0022 D loss:-0.332 G loss:-2.621\n",
      "Epoch:  0022 D loss:-0.4427 G loss:-2.796\n",
      "Epoch:  0022 D loss:-0.5532 G loss:-2.513\n",
      "Epoch:  0022 D loss:-0.394 G loss:-2.727\n",
      "Epoch:  0022 D loss:-0.4073 G loss:-2.69\n",
      "Epoch:  0022 D loss:-0.3953 G loss:-2.653\n",
      "Epoch:  0022 D loss:-0.4639 G loss:-2.41\n",
      "Epoch:  0022 D loss:-0.3399 G loss:-2.719\n",
      "Epoch:  0022 D loss:-0.3898 G loss:-2.489\n",
      "Epoch:  0022 D loss:-0.3342 G loss:-2.808\n",
      "Epoch:  0022 D loss:-0.4924 G loss:-2.641\n",
      "Epoch:  0022 D loss:-0.4436 G loss:-2.616\n",
      "Epoch:  0022 D loss:-0.407 G loss:-2.472\n",
      "Epoch:  0022 D loss:-0.3982 G loss:-2.506\n",
      "Epoch:  0022 D loss:-0.4159 G loss:-2.452\n",
      "Epoch:  0022 D loss:-0.5929 G loss:-2.384\n",
      "Epoch:  0022 D loss:-0.4729 G loss:-2.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0022 D loss:-0.4293 G loss:-2.197\n",
      "Epoch:  0022 D loss:-0.5106 G loss:-2.411\n",
      "Epoch:  0022 D loss:-0.3819 G loss:-2.423\n",
      "Epoch:  0022 D loss:-0.4188 G loss:-2.517\n",
      "Epoch:  0022 D loss:-0.4337 G loss:-2.631\n",
      "Epoch:  0022 D loss:-0.3958 G loss:-2.55\n",
      "Epoch:  0022 D loss:-0.4501 G loss:-2.711\n",
      "Epoch:  0022 D loss:-0.3695 G loss:-2.838\n",
      "Epoch:  0022 D loss:-0.4757 G loss:-2.854\n",
      "Epoch:  0022 D loss:-0.4067 G loss:-2.786\n",
      "Epoch:  0022 D loss:-0.4731 G loss:-2.53\n",
      "Epoch:  0022 D loss:-0.4172 G loss:-2.703\n",
      "Epoch:  0022 D loss:-0.4814 G loss:-2.68\n",
      "Epoch:  0022 D loss:-0.4172 G loss:-2.568\n",
      "Epoch:  0022 D loss:-0.4201 G loss:-2.416\n",
      "Epoch:  0022 D loss:-0.4291 G loss:-2.526\n",
      "Epoch:  0022 D loss:-0.361 G loss:-2.354\n",
      "Epoch:  0022 D loss:-0.4266 G loss:-2.43\n",
      "Epoch:  0022 D loss:-0.3377 G loss:-2.532\n",
      "Epoch:  0022 D loss:-0.4533 G loss:-2.439\n",
      "Epoch:  0022 D loss:-0.4913 G loss:-2.49\n",
      "Epoch:  0022 D loss:-0.4921 G loss:-2.654\n",
      "Epoch:  0022 D loss:-0.3961 G loss:-2.722\n",
      "Epoch:  0022 D loss:-0.392 G loss:-2.59\n",
      "Epoch:  0022 D loss:-0.5236 G loss:-2.55\n",
      "Epoch:  0022 D loss:-0.4012 G loss:-2.404\n",
      "Epoch:  0022 D loss:-0.5076 G loss:-2.529\n",
      "Epoch:  0022 D loss:-0.4356 G loss:-2.556\n",
      "Epoch:  0022 D loss:-0.3161 G loss:-2.655\n",
      "Epoch:  0022 D loss:-0.5183 G loss:-2.329\n",
      "Epoch:  0022 D loss:-0.4272 G loss:-2.504\n",
      "Epoch:  0022 D loss:-0.3529 G loss:-2.518\n",
      "Epoch:  0022 D loss:-0.5242 G loss:-2.528\n",
      "Epoch:  0022 D loss:-0.5031 G loss:-2.5\n",
      "Epoch:  0022 D loss:-0.3854 G loss:-2.453\n",
      "Epoch:  0022 D loss:-0.5058 G loss:-2.3\n",
      "Epoch:  0022 D loss:-0.3461 G loss:-2.532\n",
      "Epoch:  0022 D loss:-0.3686 G loss:-2.645\n",
      "Epoch:  0022 D loss:-0.5038 G loss:-2.473\n",
      "Epoch:  0022 D loss:-0.4998 G loss:-2.47\n",
      "Epoch:  0022 D loss:-0.4927 G loss:-2.656\n",
      "Epoch:  0022 D loss:-0.3143 G loss:-2.701\n",
      "Epoch:  0022 D loss:-0.3052 G loss:-3.111\n",
      "Epoch:  0022 D loss:-0.5369 G loss:-2.725\n",
      "Epoch:  0022 D loss:-0.3481 G loss:-3.02\n",
      "Epoch:  0022 D loss:-0.4612 G loss:-2.776\n",
      "Epoch:  0022 D loss:-0.4584 G loss:-2.536\n",
      "Epoch:  0022 D loss:-0.3767 G loss:-2.824\n",
      "Epoch:  0022 D loss:-0.3864 G loss:-2.635\n",
      "Epoch:  0022 D loss:-0.4355 G loss:-2.366\n",
      "Epoch:  0022 D loss:-0.4075 G loss:-2.651\n",
      "Epoch:  0022 D loss:-0.3319 G loss:-2.497\n",
      "Epoch:  0022 D loss:-0.3828 G loss:-2.419\n",
      "Epoch:  0022 D loss:-0.3366 G loss:-2.63\n",
      "Epoch:  0022 D loss:-0.411 G loss:-2.566\n",
      "Epoch:  0022 D loss:-0.321 G loss:-2.602\n",
      "Epoch:  0022 D loss:-0.392 G loss:-2.742\n",
      "Epoch:  0022 D loss:-0.3484 G loss:-3.033\n",
      "Epoch:  0022 D loss:-0.289 G loss:-3.057\n",
      "Epoch:  0022 D loss:-0.2922 G loss:-3.279\n",
      "Epoch:  0022 D loss:-0.3476 G loss:-3.272\n",
      "Epoch:  0022 D loss:-0.3517 G loss:-3.252\n",
      "Epoch:  0022 D loss:-0.3379 G loss:-2.975\n",
      "Epoch:  0022 D loss:-0.3815 G loss:-2.98\n",
      "Epoch:  0022 D loss:-0.2803 G loss:-2.819\n",
      "Epoch:  0022 D loss:-0.344 G loss:-2.842\n",
      "Epoch:  0022 D loss:-0.332 G loss:-2.622\n",
      "Epoch:  0022 D loss:-0.3045 G loss:-2.672\n",
      "Epoch:  0022 D loss:-0.3928 G loss:-2.689\n",
      "Epoch:  0022 D loss:-0.2859 G loss:-2.796\n",
      "Epoch:  0022 D loss:-0.302 G loss:-2.76\n",
      "Epoch:  0022 D loss:-0.3548 G loss:-2.781\n",
      "Epoch:  0022 D loss:-0.3038 G loss:-3.006\n",
      "Epoch:  0022 D loss:-0.342 G loss:-3.04\n",
      "Epoch:  0022 D loss:-0.4029 G loss:-2.778\n",
      "Epoch:  0022 D loss:-0.356 G loss:-3.012\n",
      "Epoch:  0022 D loss:-0.4195 G loss:-2.618\n",
      "Epoch:  0022 D loss:-0.3322 G loss:-2.809\n",
      "Epoch:  0022 D loss:-0.336 G loss:-2.541\n",
      "Epoch:  0022 D loss:-0.3114 G loss:-2.543\n",
      "Epoch:  0022 D loss:-0.2827 G loss:-2.857\n",
      "Epoch:  0022 D loss:-0.2925 G loss:-2.968\n",
      "Epoch:  0022 D loss:-0.3225 G loss:-2.805\n",
      "Epoch:  0022 D loss:-0.3232 G loss:-2.866\n",
      "Epoch:  0022 D loss:-0.3248 G loss:-2.875\n",
      "Epoch:  0022 D loss:-0.2794 G loss:-2.921\n",
      "Epoch:  0022 D loss:-0.3789 G loss:-3.007\n",
      "Epoch:  0022 D loss:-0.276 G loss:-3.001\n",
      "Epoch:  0022 D loss:-0.3053 G loss:-2.933\n",
      "Epoch:  0022 D loss:-0.2979 G loss:-2.892\n",
      "Epoch:  0022 D loss:-0.2857 G loss:-2.791\n",
      "Epoch:  0022 D loss:-0.3589 G loss:-2.805\n",
      "Epoch:  0022 D loss:-0.2928 G loss:-2.872\n",
      "Epoch:  0022 D loss:-0.3795 G loss:-3.058\n",
      "Epoch:  0022 D loss:-0.3477 G loss:-2.835\n",
      "Epoch:  0022 D loss:-0.2927 G loss:-3.045\n",
      "Epoch:  0022 D loss:-0.3489 G loss:-2.818\n",
      "Epoch:  0022 D loss:-0.2493 G loss:-3.177\n",
      "Epoch:  0022 D loss:-0.3159 G loss:-3.015\n",
      "Epoch:  0022 D loss:-0.2522 G loss:-3.005\n",
      "Epoch:  0022 D loss:-0.2458 G loss:-2.875\n",
      "Epoch:  0022 D loss:-0.2746 G loss:-3.062\n",
      "Epoch:  0022 D loss:-0.2668 G loss:-2.932\n",
      "Epoch:  0022 D loss:-0.2749 G loss:-3.072\n",
      "Epoch:  0022 D loss:-0.2595 G loss:-3.233\n",
      "Epoch:  0022 D loss:-0.3304 G loss:-2.971\n",
      "Epoch:  0022 D loss:-0.2867 G loss:-2.887\n",
      "Epoch:  0022 D loss:-0.3265 G loss:-2.977\n",
      "Epoch:  0022 D loss:-0.2959 G loss:-2.913\n",
      "Epoch:  0022 D loss:-0.4317 G loss:-2.587\n",
      "Epoch:  0022 D loss:-0.4319 G loss:-2.723\n",
      "Epoch:  0022 D loss:-0.375 G loss:-2.789\n",
      "Epoch:  0022 D loss:-0.3824 G loss:-2.871\n",
      "Epoch:  0022 D loss:-0.3021 G loss:-2.653\n",
      "Epoch:  0022 D loss:-0.3029 G loss:-2.923\n",
      "Epoch:  0022 D loss:-0.4001 G loss:-2.573\n",
      "Epoch:  0022 D loss:-0.3206 G loss:-2.778\n",
      "Epoch:  0022 D loss:-0.3772 G loss:-2.744\n",
      "Epoch:  0022 D loss:-0.365 G loss:-2.846\n",
      "Epoch:  0022 D loss:-0.298 G loss:-2.92\n",
      "Epoch:  0022 D loss:-0.4038 G loss:-2.772\n",
      "Epoch:  0022 D loss:-0.2724 G loss:-2.716\n",
      "Epoch:  0022 D loss:-0.3389 G loss:-2.763\n",
      "Epoch:  0022 D loss:-0.4222 G loss:-2.607\n",
      "Epoch:  0022 D loss:-0.3807 G loss:-2.73\n",
      "Epoch:  0022 D loss:-0.3649 G loss:-2.772\n",
      "Epoch:  0022 D loss:-0.3592 G loss:-2.749\n",
      "Epoch:  0022 D loss:-0.3537 G loss:-3.01\n",
      "Epoch:  0022 D loss:-0.2742 G loss:-3.248\n",
      "Epoch:  0022 D loss:-0.3119 G loss:-3.162\n",
      "Epoch:  0022 D loss:-0.3174 G loss:-2.923\n",
      "Epoch:  0022 D loss:-0.2746 G loss:-3.043\n",
      "Epoch:  0022 D loss:-0.3545 G loss:-3.127\n",
      "Epoch:  0022 D loss:-0.3632 G loss:-2.921\n",
      "Epoch:  0022 D loss:-0.2897 G loss:-3.113\n",
      "Epoch:  0022 D loss:-0.3266 G loss:-2.899\n",
      "Epoch:  0022 D loss:-0.2938 G loss:-2.761\n",
      "Epoch:  0022 D loss:-0.3123 G loss:-2.758\n",
      "Epoch:  0022 D loss:-0.414 G loss:-2.793\n",
      "Epoch:  0022 D loss:-0.3796 G loss:-2.773\n",
      "Epoch:  0022 D loss:-0.3457 G loss:-2.536\n",
      "Epoch:  0022 D loss:-0.3138 G loss:-2.883\n",
      "Epoch:  0022 D loss:-0.3627 G loss:-2.822\n",
      "Epoch:  0022 D loss:-0.3208 G loss:-2.847\n",
      "Epoch:  0022 D loss:-0.3429 G loss:-2.821\n",
      "Epoch:  0022 D loss:-0.4388 G loss:-2.678\n",
      "Epoch:  0022 D loss:-0.422 G loss:-2.801\n",
      "Epoch:  0022 D loss:-0.353 G loss:-2.67\n",
      "Epoch:  0022 D loss:-0.3848 G loss:-2.782\n",
      "Epoch:  0022 D loss:-0.3235 G loss:-2.831\n",
      "Epoch:  0022 D loss:-0.4056 G loss:-2.644\n",
      "Epoch:  0022 D loss:-0.3314 G loss:-2.65\n",
      "Epoch:  0022 D loss:-0.3301 G loss:-2.805\n",
      "Epoch:  0022 D loss:-0.411 G loss:-2.553\n",
      "Epoch:  0022 D loss:-0.4284 G loss:-3.08\n",
      "Epoch:  0022 D loss:-0.2548 G loss:-2.939\n",
      "Epoch:  0022 D loss:-0.332 G loss:-2.96\n",
      "Epoch:  0022 D loss:-0.3567 G loss:-2.73\n",
      "Epoch:  0022 D loss:-0.3589 G loss:-2.676\n",
      "Epoch:  0022 D loss:-0.3814 G loss:-2.75\n",
      "Epoch:  0022 D loss:-0.4064 G loss:-2.715\n",
      "Epoch:  0022 D loss:-0.2871 G loss:-2.775\n",
      "Epoch:  0022 D loss:-0.3155 G loss:-2.986\n",
      "Epoch:  0022 D loss:-0.3213 G loss:-2.735\n",
      "Epoch:  0022 D loss:-0.3208 G loss:-2.849\n",
      "Epoch:  0022 D loss:-0.3664 G loss:-3.025\n",
      "Epoch:  0022 D loss:-0.3499 G loss:-2.854\n",
      "Epoch:  0022 D loss:-0.252 G loss:-2.985\n",
      "Epoch:  0022 D loss:-0.3466 G loss:-3.004\n",
      "Epoch:  0022 D loss:-0.2022 G loss:-3.093\n",
      "Epoch:  0022 D loss:-0.277 G loss:-3.053\n",
      "Epoch:  0022 D loss:-0.3985 G loss:-2.924\n",
      "Epoch:  0022 D loss:-0.313 G loss:-2.788\n",
      "Epoch:  0022 D loss:-0.3629 G loss:-2.785\n",
      "Epoch:  0022 D loss:-0.2721 G loss:-2.986\n",
      "Epoch:  0022 D loss:-0.3893 G loss:-2.805\n",
      "Epoch:  0022 D loss:-0.3708 G loss:-2.708\n",
      "Epoch:  0022 D loss:-0.2714 G loss:-2.909\n",
      "Epoch:  0022 D loss:-0.3658 G loss:-2.589\n",
      "Epoch:  0022 D loss:-0.2855 G loss:-2.933\n",
      "Epoch:  0022 D loss:-0.3676 G loss:-2.949\n",
      "Epoch:  0022 D loss:-0.2232 G loss:-3.191\n",
      "Epoch:  0022 D loss:-0.397 G loss:-2.652\n",
      "Epoch:  0022 D loss:-0.3467 G loss:-3.036\n",
      "Epoch:  0022 D loss:-0.3401 G loss:-2.798\n",
      "Epoch:  0022 D loss:-0.3537 G loss:-2.836\n",
      "Epoch:  0022 D loss:-0.2808 G loss:-2.921\n",
      "Epoch:  0022 D loss:-0.3599 G loss:-2.737\n",
      "Epoch:  0022 D loss:-0.4189 G loss:-2.855\n",
      "Epoch:  0022 D loss:-0.3444 G loss:-2.956\n",
      "Epoch:  0022 D loss:-0.2881 G loss:-2.985\n",
      "Epoch:  0022 D loss:-0.3484 G loss:-2.912\n",
      "Epoch:  0022 D loss:-0.2832 G loss:-3.047\n",
      "Epoch:  0022 D loss:-0.3955 G loss:-2.903\n",
      "Epoch:  0022 D loss:-0.4247 G loss:-2.808\n",
      "Epoch:  0022 D loss:-0.3153 G loss:-2.748\n",
      "Epoch:  0022 D loss:-0.3412 G loss:-2.948\n",
      "Epoch:  0022 D loss:-0.3052 G loss:-3.044\n",
      "Epoch:  0022 D loss:-0.2936 G loss:-3.194\n",
      "Epoch:  0022 D loss:-0.2936 G loss:-2.924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0023 D loss:-0.3949 G loss:-3.095\n",
      "Epoch:  0023 D loss:-0.3537 G loss:-2.961\n",
      "Epoch:  0023 D loss:-0.2452 G loss:-3.061\n",
      "Epoch:  0023 D loss:-0.4589 G loss:-2.788\n",
      "Epoch:  0023 D loss:-0.341 G loss:-2.938\n",
      "Epoch:  0023 D loss:-0.3763 G loss:-3.304\n",
      "Epoch:  0023 D loss:-0.3816 G loss:-2.806\n",
      "Epoch:  0023 D loss:-0.333 G loss:-2.964\n",
      "Epoch:  0023 D loss:-0.3241 G loss:-2.902\n",
      "Epoch:  0023 D loss:-0.3688 G loss:-2.61\n",
      "Epoch:  0023 D loss:-0.2728 G loss:-2.83\n",
      "Epoch:  0023 D loss:-0.3251 G loss:-2.887\n",
      "Epoch:  0023 D loss:-0.4173 G loss:-2.817\n",
      "Epoch:  0023 D loss:-0.3507 G loss:-2.834\n",
      "Epoch:  0023 D loss:-0.3405 G loss:-2.873\n",
      "Epoch:  0023 D loss:-0.3423 G loss:-2.919\n",
      "Epoch:  0023 D loss:-0.3479 G loss:-2.891\n",
      "Epoch:  0023 D loss:-0.3118 G loss:-2.859\n",
      "Epoch:  0023 D loss:-0.3176 G loss:-3.016\n",
      "Epoch:  0023 D loss:-0.3721 G loss:-2.828\n",
      "Epoch:  0023 D loss:-0.3496 G loss:-2.808\n",
      "Epoch:  0023 D loss:-0.3223 G loss:-2.968\n",
      "Epoch:  0023 D loss:-0.3313 G loss:-2.891\n",
      "Epoch:  0023 D loss:-0.4381 G loss:-2.741\n",
      "Epoch:  0023 D loss:-0.352 G loss:-2.809\n",
      "Epoch:  0023 D loss:-0.356 G loss:-2.894\n",
      "Epoch:  0023 D loss:-0.3701 G loss:-2.861\n",
      "Epoch:  0023 D loss:-0.2584 G loss:-3.046\n",
      "Epoch:  0023 D loss:-0.2918 G loss:-2.735\n",
      "Epoch:  0023 D loss:-0.3006 G loss:-2.798\n",
      "Epoch:  0023 D loss:-0.3872 G loss:-2.623\n",
      "Epoch:  0023 D loss:-0.3435 G loss:-2.911\n",
      "Epoch:  0023 D loss:-0.4437 G loss:-2.591\n",
      "Epoch:  0023 D loss:-0.2595 G loss:-2.838\n",
      "Epoch:  0023 D loss:-0.378 G loss:-2.7\n",
      "Epoch:  0023 D loss:-0.3192 G loss:-3.182\n",
      "Epoch:  0023 D loss:-0.3117 G loss:-3.103\n",
      "Epoch:  0023 D loss:-0.3938 G loss:-2.987\n",
      "Epoch:  0023 D loss:-0.4494 G loss:-2.719\n",
      "Epoch:  0023 D loss:-0.3752 G loss:-2.781\n",
      "Epoch:  0023 D loss:-0.3637 G loss:-2.716\n",
      "Epoch:  0023 D loss:-0.4454 G loss:-2.777\n",
      "Epoch:  0023 D loss:-0.4699 G loss:-2.759\n",
      "Epoch:  0023 D loss:-0.3472 G loss:-2.73\n",
      "Epoch:  0023 D loss:-0.3663 G loss:-2.472\n",
      "Epoch:  0023 D loss:-0.3703 G loss:-2.781\n",
      "Epoch:  0023 D loss:-0.3845 G loss:-2.618\n",
      "Epoch:  0023 D loss:-0.3909 G loss:-2.762\n",
      "Epoch:  0023 D loss:-0.2861 G loss:-2.769\n",
      "Epoch:  0023 D loss:-0.4182 G loss:-2.875\n",
      "Epoch:  0023 D loss:-0.3709 G loss:-2.815\n",
      "Epoch:  0023 D loss:-0.3858 G loss:-3.018\n",
      "Epoch:  0023 D loss:-0.3676 G loss:-2.918\n",
      "Epoch:  0023 D loss:-0.3649 G loss:-2.845\n",
      "Epoch:  0023 D loss:-0.3557 G loss:-2.996\n",
      "Epoch:  0023 D loss:-0.3428 G loss:-2.887\n",
      "Epoch:  0023 D loss:-0.4806 G loss:-2.768\n",
      "Epoch:  0023 D loss:-0.3389 G loss:-2.856\n",
      "Epoch:  0023 D loss:-0.3049 G loss:-2.882\n",
      "Epoch:  0023 D loss:-0.3738 G loss:-2.824\n",
      "Epoch:  0023 D loss:-0.2915 G loss:-2.888\n",
      "Epoch:  0023 D loss:-0.3687 G loss:-2.738\n",
      "Epoch:  0023 D loss:-0.3807 G loss:-2.877\n",
      "Epoch:  0023 D loss:-0.3531 G loss:-2.85\n",
      "Epoch:  0023 D loss:-0.3186 G loss:-2.953\n",
      "Epoch:  0023 D loss:-0.403 G loss:-2.845\n",
      "Epoch:  0023 D loss:-0.3663 G loss:-2.892\n",
      "Epoch:  0023 D loss:-0.431 G loss:-2.625\n",
      "Epoch:  0023 D loss:-0.2971 G loss:-2.55\n",
      "Epoch:  0023 D loss:-0.3057 G loss:-2.89\n",
      "Epoch:  0023 D loss:-0.4243 G loss:-2.662\n",
      "Epoch:  0023 D loss:-0.3936 G loss:-2.612\n",
      "Epoch:  0023 D loss:-0.2719 G loss:-2.759\n",
      "Epoch:  0023 D loss:-0.3339 G loss:-2.758\n",
      "Epoch:  0023 D loss:-0.274 G loss:-2.819\n",
      "Epoch:  0023 D loss:-0.4306 G loss:-2.998\n",
      "Epoch:  0023 D loss:-0.4456 G loss:-2.896\n",
      "Epoch:  0023 D loss:-0.3661 G loss:-2.891\n",
      "Epoch:  0023 D loss:-0.2656 G loss:-3.044\n",
      "Epoch:  0023 D loss:-0.3189 G loss:-3.043\n",
      "Epoch:  0023 D loss:-0.3754 G loss:-2.913\n",
      "Epoch:  0023 D loss:-0.4012 G loss:-2.788\n",
      "Epoch:  0023 D loss:-0.3398 G loss:-2.74\n",
      "Epoch:  0023 D loss:-0.374 G loss:-2.857\n",
      "Epoch:  0023 D loss:-0.3091 G loss:-2.756\n",
      "Epoch:  0023 D loss:-0.3881 G loss:-2.611\n",
      "Epoch:  0023 D loss:-0.2817 G loss:-2.754\n",
      "Epoch:  0023 D loss:-0.3875 G loss:-2.598\n",
      "Epoch:  0023 D loss:-0.3353 G loss:-2.839\n",
      "Epoch:  0023 D loss:-0.4116 G loss:-2.645\n",
      "Epoch:  0023 D loss:-0.3848 G loss:-2.886\n",
      "Epoch:  0023 D loss:-0.3436 G loss:-2.945\n",
      "Epoch:  0023 D loss:-0.3223 G loss:-3.008\n",
      "Epoch:  0023 D loss:-0.3944 G loss:-3.415\n",
      "Epoch:  0023 D loss:-0.3247 G loss:-3.1\n",
      "Epoch:  0023 D loss:-0.4082 G loss:-3.008\n",
      "Epoch:  0023 D loss:-0.2965 G loss:-3.023\n",
      "Epoch:  0023 D loss:-0.3454 G loss:-3.03\n",
      "Epoch:  0023 D loss:-0.267 G loss:-3.027\n",
      "Epoch:  0023 D loss:-0.4081 G loss:-2.881\n",
      "Epoch:  0023 D loss:-0.3279 G loss:-2.741\n",
      "Epoch:  0023 D loss:-0.3565 G loss:-2.658\n",
      "Epoch:  0023 D loss:-0.3388 G loss:-2.733\n",
      "Epoch:  0023 D loss:-0.4603 G loss:-2.526\n",
      "Epoch:  0023 D loss:-0.3191 G loss:-2.736\n",
      "Epoch:  0023 D loss:-0.3745 G loss:-2.851\n",
      "Epoch:  0023 D loss:-0.367 G loss:-2.927\n",
      "Epoch:  0023 D loss:-0.5322 G loss:-2.593\n",
      "Epoch:  0023 D loss:-0.3897 G loss:-2.796\n",
      "Epoch:  0023 D loss:-0.3881 G loss:-2.756\n",
      "Epoch:  0023 D loss:-0.383 G loss:-2.691\n",
      "Epoch:  0023 D loss:-0.3493 G loss:-2.905\n",
      "Epoch:  0023 D loss:-0.4238 G loss:-2.448\n",
      "Epoch:  0023 D loss:-0.4009 G loss:-2.758\n",
      "Epoch:  0023 D loss:-0.4613 G loss:-2.487\n",
      "Epoch:  0023 D loss:-0.3935 G loss:-2.341\n",
      "Epoch:  0023 D loss:-0.3243 G loss:-2.694\n",
      "Epoch:  0023 D loss:-0.4258 G loss:-2.754\n",
      "Epoch:  0023 D loss:-0.4409 G loss:-2.911\n",
      "Epoch:  0023 D loss:-0.3353 G loss:-2.969\n",
      "Epoch:  0023 D loss:-0.3665 G loss:-2.981\n",
      "Epoch:  0023 D loss:-0.4314 G loss:-2.702\n",
      "Epoch:  0023 D loss:-0.4463 G loss:-2.76\n",
      "Epoch:  0023 D loss:-0.4586 G loss:-2.576\n",
      "Epoch:  0023 D loss:-0.4212 G loss:-2.501\n",
      "Epoch:  0023 D loss:-0.4448 G loss:-2.7\n",
      "Epoch:  0023 D loss:-0.3187 G loss:-2.916\n",
      "Epoch:  0023 D loss:-0.3347 G loss:-2.993\n",
      "Epoch:  0023 D loss:-0.3582 G loss:-3.071\n",
      "Epoch:  0023 D loss:-0.3244 G loss:-3.175\n",
      "Epoch:  0023 D loss:-0.3951 G loss:-2.941\n",
      "Epoch:  0023 D loss:-0.3703 G loss:-2.913\n",
      "Epoch:  0023 D loss:-0.3565 G loss:-2.971\n",
      "Epoch:  0023 D loss:-0.4093 G loss:-2.658\n",
      "Epoch:  0023 D loss:-0.3193 G loss:-2.963\n",
      "Epoch:  0023 D loss:-0.3592 G loss:-2.924\n",
      "Epoch:  0023 D loss:-0.2804 G loss:-2.921\n",
      "Epoch:  0023 D loss:-0.272 G loss:-3.204\n",
      "Epoch:  0023 D loss:-0.2525 G loss:-3.221\n",
      "Epoch:  0023 D loss:-0.3251 G loss:-2.87\n",
      "Epoch:  0023 D loss:-0.3873 G loss:-2.722\n",
      "Epoch:  0023 D loss:-0.4223 G loss:-2.633\n",
      "Epoch:  0023 D loss:-0.3304 G loss:-2.817\n",
      "Epoch:  0023 D loss:-0.3659 G loss:-2.823\n",
      "Epoch:  0023 D loss:-0.3746 G loss:-2.786\n",
      "Epoch:  0023 D loss:-0.2968 G loss:-3.026\n",
      "Epoch:  0023 D loss:-0.3443 G loss:-2.992\n",
      "Epoch:  0023 D loss:-0.3658 G loss:-2.952\n",
      "Epoch:  0023 D loss:-0.3874 G loss:-2.752\n",
      "Epoch:  0023 D loss:-0.3084 G loss:-2.882\n",
      "Epoch:  0023 D loss:-0.4162 G loss:-2.788\n",
      "Epoch:  0023 D loss:-0.33 G loss:-2.717\n",
      "Epoch:  0023 D loss:-0.3413 G loss:-2.643\n",
      "Epoch:  0023 D loss:-0.3525 G loss:-2.769\n",
      "Epoch:  0023 D loss:-0.3044 G loss:-2.729\n",
      "Epoch:  0023 D loss:-0.3143 G loss:-2.705\n",
      "Epoch:  0023 D loss:-0.2812 G loss:-2.721\n",
      "Epoch:  0023 D loss:-0.3768 G loss:-2.867\n",
      "Epoch:  0023 D loss:-0.2912 G loss:-2.771\n",
      "Epoch:  0023 D loss:-0.3555 G loss:-2.934\n",
      "Epoch:  0023 D loss:-0.3802 G loss:-2.853\n",
      "Epoch:  0023 D loss:-0.2351 G loss:-2.991\n",
      "Epoch:  0023 D loss:-0.3594 G loss:-2.933\n",
      "Epoch:  0023 D loss:-0.3249 G loss:-2.822\n",
      "Epoch:  0023 D loss:-0.4655 G loss:-2.767\n",
      "Epoch:  0023 D loss:-0.3465 G loss:-2.913\n",
      "Epoch:  0023 D loss:-0.3782 G loss:-2.744\n",
      "Epoch:  0023 D loss:-0.3411 G loss:-2.743\n",
      "Epoch:  0023 D loss:-0.307 G loss:-2.734\n",
      "Epoch:  0023 D loss:-0.4078 G loss:-2.691\n",
      "Epoch:  0023 D loss:-0.4139 G loss:-2.401\n",
      "Epoch:  0023 D loss:-0.3324 G loss:-2.74\n",
      "Epoch:  0023 D loss:-0.3916 G loss:-2.591\n",
      "Epoch:  0023 D loss:-0.3552 G loss:-2.665\n",
      "Epoch:  0023 D loss:-0.3496 G loss:-2.62\n",
      "Epoch:  0023 D loss:-0.2341 G loss:-2.714\n",
      "Epoch:  0023 D loss:-0.3715 G loss:-2.825\n",
      "Epoch:  0023 D loss:-0.3185 G loss:-2.77\n",
      "Epoch:  0023 D loss:-0.3208 G loss:-2.693\n",
      "Epoch:  0023 D loss:-0.3005 G loss:-2.772\n",
      "Epoch:  0023 D loss:-0.3337 G loss:-3.002\n",
      "Epoch:  0023 D loss:-0.2766 G loss:-2.856\n",
      "Epoch:  0023 D loss:-0.2772 G loss:-2.99\n",
      "Epoch:  0023 D loss:-0.3112 G loss:-3.032\n",
      "Epoch:  0023 D loss:-0.3622 G loss:-3.023\n",
      "Epoch:  0023 D loss:-0.3247 G loss:-2.751\n",
      "Epoch:  0023 D loss:-0.381 G loss:-2.901\n",
      "Epoch:  0023 D loss:-0.3644 G loss:-2.841\n",
      "Epoch:  0023 D loss:-0.2977 G loss:-2.852\n",
      "Epoch:  0023 D loss:-0.3539 G loss:-2.702\n",
      "Epoch:  0023 D loss:-0.2572 G loss:-2.856\n",
      "Epoch:  0023 D loss:-0.3286 G loss:-2.855\n",
      "Epoch:  0023 D loss:-0.4047 G loss:-2.799\n",
      "Epoch:  0023 D loss:-0.2659 G loss:-2.956\n",
      "Epoch:  0023 D loss:-0.3199 G loss:-2.895\n",
      "Epoch:  0023 D loss:-0.256 G loss:-2.833\n",
      "Epoch:  0023 D loss:-0.3234 G loss:-2.811\n",
      "Epoch:  0023 D loss:-0.3033 G loss:-2.705\n",
      "Epoch:  0023 D loss:-0.3755 G loss:-2.76\n",
      "Epoch:  0023 D loss:-0.2881 G loss:-2.842\n",
      "Epoch:  0023 D loss:-0.3062 G loss:-2.928\n",
      "Epoch:  0023 D loss:-0.3981 G loss:-2.74\n",
      "Epoch:  0023 D loss:-0.3472 G loss:-2.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0023 D loss:-0.3061 G loss:-2.912\n",
      "Epoch:  0023 D loss:-0.3203 G loss:-2.764\n",
      "Epoch:  0023 D loss:-0.3415 G loss:-2.624\n",
      "Epoch:  0023 D loss:-0.2777 G loss:-2.983\n",
      "Epoch:  0023 D loss:-0.4249 G loss:-2.947\n",
      "Epoch:  0023 D loss:-0.3371 G loss:-2.775\n",
      "Epoch:  0023 D loss:-0.3001 G loss:-2.845\n",
      "Epoch:  0023 D loss:-0.3501 G loss:-2.745\n",
      "Epoch:  0023 D loss:-0.4044 G loss:-2.672\n",
      "Epoch:  0023 D loss:-0.3714 G loss:-2.686\n",
      "Epoch:  0023 D loss:-0.2964 G loss:-2.755\n",
      "Epoch:  0023 D loss:-0.4151 G loss:-2.494\n",
      "Epoch:  0023 D loss:-0.2716 G loss:-2.814\n",
      "Epoch:  0023 D loss:-0.3548 G loss:-2.771\n",
      "Epoch:  0023 D loss:-0.3357 G loss:-2.76\n",
      "Epoch:  0023 D loss:-0.3169 G loss:-2.826\n",
      "Epoch:  0023 D loss:-0.3081 G loss:-2.553\n",
      "Epoch:  0023 D loss:-0.4037 G loss:-2.877\n",
      "Epoch:  0023 D loss:-0.4247 G loss:-2.78\n",
      "Epoch:  0023 D loss:-0.3041 G loss:-2.926\n",
      "Epoch:  0023 D loss:-0.3646 G loss:-2.655\n",
      "Epoch:  0023 D loss:-0.4035 G loss:-2.819\n",
      "Epoch:  0023 D loss:-0.3318 G loss:-3.011\n",
      "Epoch:  0023 D loss:-0.3749 G loss:-2.799\n",
      "Epoch:  0023 D loss:-0.3647 G loss:-2.627\n",
      "Epoch:  0023 D loss:-0.4045 G loss:-2.725\n",
      "Epoch:  0023 D loss:-0.345 G loss:-2.64\n",
      "Epoch:  0023 D loss:-0.3348 G loss:-2.798\n",
      "Epoch:  0023 D loss:-0.3292 G loss:-2.609\n",
      "Epoch:  0023 D loss:-0.2888 G loss:-2.627\n",
      "Epoch:  0023 D loss:-0.3222 G loss:-2.783\n",
      "Epoch:  0023 D loss:-0.2433 G loss:-2.894\n",
      "Epoch:  0023 D loss:-0.3708 G loss:-2.744\n",
      "Epoch:  0023 D loss:-0.3729 G loss:-2.906\n",
      "Epoch:  0023 D loss:-0.4282 G loss:-2.761\n",
      "Epoch:  0023 D loss:-0.4298 G loss:-2.645\n",
      "Epoch:  0023 D loss:-0.4077 G loss:-2.712\n",
      "Epoch:  0023 D loss:-0.292 G loss:-2.885\n",
      "Epoch:  0023 D loss:-0.395 G loss:-2.761\n",
      "Epoch:  0023 D loss:-0.4964 G loss:-2.716\n",
      "Epoch:  0023 D loss:-0.3506 G loss:-2.61\n",
      "Epoch:  0023 D loss:-0.3871 G loss:-2.697\n",
      "Epoch:  0023 D loss:-0.3698 G loss:-2.752\n",
      "Epoch:  0023 D loss:-0.3653 G loss:-2.766\n",
      "Epoch:  0023 D loss:-0.3436 G loss:-2.656\n",
      "Epoch:  0023 D loss:-0.3544 G loss:-2.702\n",
      "Epoch:  0023 D loss:-0.35 G loss:-2.619\n",
      "Epoch:  0023 D loss:-0.3722 G loss:-2.717\n",
      "Epoch:  0023 D loss:-0.3433 G loss:-2.848\n",
      "Epoch:  0023 D loss:-0.3875 G loss:-2.749\n",
      "Epoch:  0023 D loss:-0.2925 G loss:-3.018\n",
      "Epoch:  0023 D loss:-0.3871 G loss:-2.779\n",
      "Epoch:  0023 D loss:-0.3068 G loss:-2.934\n",
      "Epoch:  0023 D loss:-0.344 G loss:-2.803\n",
      "Epoch:  0023 D loss:-0.3606 G loss:-2.936\n",
      "Epoch:  0023 D loss:-0.4153 G loss:-2.732\n",
      "Epoch:  0023 D loss:-0.3343 G loss:-2.661\n",
      "Epoch:  0023 D loss:-0.2627 G loss:-2.706\n",
      "Epoch:  0023 D loss:-0.3549 G loss:-2.717\n",
      "Epoch:  0023 D loss:-0.2347 G loss:-2.999\n",
      "Epoch:  0023 D loss:-0.3155 G loss:-2.893\n",
      "Epoch:  0023 D loss:-0.4098 G loss:-3.061\n",
      "Epoch:  0023 D loss:-0.3416 G loss:-2.775\n",
      "Epoch:  0023 D loss:-0.2356 G loss:-3.102\n",
      "Epoch:  0023 D loss:-0.2991 G loss:-2.846\n",
      "Epoch:  0023 D loss:-0.335 G loss:-2.829\n",
      "Epoch:  0023 D loss:-0.3809 G loss:-2.957\n",
      "Epoch:  0023 D loss:-0.3097 G loss:-3.063\n",
      "Epoch:  0023 D loss:-0.3395 G loss:-2.832\n",
      "Epoch:  0023 D loss:-0.3921 G loss:-2.865\n",
      "Epoch:  0023 D loss:-0.3144 G loss:-2.629\n",
      "Epoch:  0023 D loss:-0.2917 G loss:-2.972\n",
      "Epoch:  0023 D loss:-0.381 G loss:-2.707\n",
      "Epoch:  0023 D loss:-0.2573 G loss:-2.895\n",
      "Epoch:  0023 D loss:-0.3777 G loss:-2.933\n",
      "Epoch:  0023 D loss:-0.4007 G loss:-2.748\n",
      "Epoch:  0023 D loss:-0.2693 G loss:-2.885\n",
      "Epoch:  0023 D loss:-0.3728 G loss:-3.033\n",
      "Epoch:  0023 D loss:-0.2899 G loss:-2.781\n",
      "Epoch:  0023 D loss:-0.3571 G loss:-2.642\n",
      "Epoch:  0023 D loss:-0.2945 G loss:-2.74\n",
      "Epoch:  0023 D loss:-0.4078 G loss:-2.911\n",
      "Epoch:  0023 D loss:-0.3792 G loss:-2.615\n",
      "Epoch:  0023 D loss:-0.3176 G loss:-2.934\n",
      "Epoch:  0023 D loss:-0.3608 G loss:-2.85\n",
      "Epoch:  0023 D loss:-0.3562 G loss:-2.566\n",
      "Epoch:  0023 D loss:-0.3695 G loss:-2.883\n",
      "Epoch:  0023 D loss:-0.3502 G loss:-2.868\n",
      "Epoch:  0023 D loss:-0.3303 G loss:-3.06\n",
      "Epoch:  0023 D loss:-0.3188 G loss:-2.911\n",
      "Epoch:  0023 D loss:-0.2973 G loss:-3.3\n",
      "Epoch:  0023 D loss:-0.3384 G loss:-2.751\n",
      "Epoch:  0023 D loss:-0.3409 G loss:-3.054\n",
      "Epoch:  0023 D loss:-0.3237 G loss:-3.086\n",
      "Epoch:  0023 D loss:-0.3172 G loss:-2.947\n",
      "Epoch:  0023 D loss:-0.4063 G loss:-2.984\n",
      "Epoch:  0023 D loss:-0.304 G loss:-2.952\n",
      "Epoch:  0023 D loss:-0.2386 G loss:-2.974\n",
      "Epoch:  0023 D loss:-0.2794 G loss:-3.05\n",
      "Epoch:  0023 D loss:-0.3285 G loss:-2.918\n",
      "Epoch:  0023 D loss:-0.3506 G loss:-2.92\n",
      "Epoch:  0023 D loss:-0.294 G loss:-3.37\n",
      "Epoch:  0023 D loss:-0.2722 G loss:-2.991\n",
      "Epoch:  0023 D loss:-0.3599 G loss:-2.61\n",
      "Epoch:  0023 D loss:-0.2891 G loss:-2.911\n",
      "Epoch:  0023 D loss:-0.3807 G loss:-2.762\n",
      "Epoch:  0023 D loss:-0.3151 G loss:-2.8\n",
      "Epoch:  0023 D loss:-0.2919 G loss:-2.919\n",
      "Epoch:  0023 D loss:-0.3577 G loss:-2.864\n",
      "Epoch:  0023 D loss:-0.4282 G loss:-2.677\n",
      "Epoch:  0023 D loss:-0.2907 G loss:-3.001\n",
      "Epoch:  0023 D loss:-0.251 G loss:-3.199\n",
      "Epoch:  0023 D loss:-0.2886 G loss:-3.146\n",
      "Epoch:  0023 D loss:-0.3514 G loss:-2.9\n",
      "Epoch:  0023 D loss:-0.4039 G loss:-3.054\n",
      "Epoch:  0023 D loss:-0.3539 G loss:-2.915\n",
      "Epoch:  0023 D loss:-0.3518 G loss:-3.036\n",
      "Epoch:  0023 D loss:-0.3455 G loss:-2.95\n",
      "Epoch:  0023 D loss:-0.5677 G loss:-2.829\n",
      "Epoch:  0023 D loss:-0.4847 G loss:-2.794\n",
      "Epoch:  0023 D loss:-0.2877 G loss:-2.868\n",
      "Epoch:  0023 D loss:-0.3789 G loss:-2.646\n",
      "Epoch:  0023 D loss:-0.324 G loss:-2.957\n",
      "Epoch:  0023 D loss:-0.2446 G loss:-2.903\n",
      "Epoch:  0023 D loss:-0.299 G loss:-2.958\n",
      "Epoch:  0023 D loss:-0.3338 G loss:-3.21\n",
      "Epoch:  0023 D loss:-0.3763 G loss:-3.181\n",
      "Epoch:  0023 D loss:-0.3572 G loss:-2.992\n",
      "Epoch:  0023 D loss:-0.295 G loss:-2.764\n",
      "Epoch:  0023 D loss:-0.298 G loss:-2.946\n",
      "Epoch:  0023 D loss:-0.3809 G loss:-2.814\n",
      "Epoch:  0023 D loss:-0.2664 G loss:-2.775\n",
      "Epoch:  0023 D loss:-0.2724 G loss:-3.111\n",
      "Epoch:  0023 D loss:-0.3019 G loss:-3.017\n",
      "Epoch:  0023 D loss:-0.288 G loss:-3.143\n",
      "Epoch:  0023 D loss:-0.3307 G loss:-2.924\n",
      "Epoch:  0023 D loss:-0.3571 G loss:-2.757\n",
      "Epoch:  0023 D loss:-0.3342 G loss:-3.213\n",
      "Epoch:  0023 D loss:-0.2891 G loss:-3.127\n",
      "Epoch:  0023 D loss:-0.4274 G loss:-2.803\n",
      "Epoch:  0023 D loss:-0.391 G loss:-2.865\n",
      "Epoch:  0023 D loss:-0.4175 G loss:-2.519\n",
      "Epoch:  0023 D loss:-0.3501 G loss:-2.882\n",
      "Epoch:  0023 D loss:-0.4414 G loss:-2.636\n",
      "Epoch:  0023 D loss:-0.3843 G loss:-2.548\n",
      "Epoch:  0023 D loss:-0.3902 G loss:-2.693\n",
      "Epoch:  0023 D loss:-0.3898 G loss:-2.766\n",
      "Epoch:  0023 D loss:-0.4175 G loss:-2.685\n",
      "Epoch:  0023 D loss:-0.3253 G loss:-2.77\n",
      "Epoch:  0023 D loss:-0.3128 G loss:-3.075\n",
      "Epoch:  0023 D loss:-0.4345 G loss:-2.964\n",
      "Epoch:  0023 D loss:-0.4 G loss:-2.667\n",
      "Epoch:  0023 D loss:-0.3699 G loss:-3.042\n",
      "Epoch:  0023 D loss:-0.4541 G loss:-2.818\n",
      "Epoch:  0023 D loss:-0.446 G loss:-2.594\n",
      "Epoch:  0023 D loss:-0.3328 G loss:-2.65\n",
      "Epoch:  0023 D loss:-0.4261 G loss:-2.622\n",
      "Epoch:  0023 D loss:-0.4714 G loss:-2.756\n",
      "Epoch:  0023 D loss:-0.4263 G loss:-2.755\n",
      "Epoch:  0023 D loss:-0.4034 G loss:-2.742\n",
      "Epoch:  0023 D loss:-0.3131 G loss:-2.857\n",
      "Epoch:  0023 D loss:-0.4444 G loss:-2.619\n",
      "Epoch:  0023 D loss:-0.3557 G loss:-2.76\n",
      "Epoch:  0023 D loss:-0.3402 G loss:-2.761\n",
      "Epoch:  0023 D loss:-0.4876 G loss:-2.792\n",
      "Epoch:  0023 D loss:-0.418 G loss:-2.915\n",
      "Epoch:  0023 D loss:-0.4568 G loss:-2.708\n",
      "Epoch:  0023 D loss:-0.3967 G loss:-2.947\n",
      "Epoch:  0023 D loss:-0.3865 G loss:-2.767\n",
      "Epoch:  0023 D loss:-0.363 G loss:-2.401\n",
      "Epoch:  0023 D loss:-0.5319 G loss:-2.447\n",
      "Epoch:  0023 D loss:-0.3726 G loss:-2.697\n",
      "Epoch:  0023 D loss:-0.4056 G loss:-2.76\n",
      "Epoch:  0023 D loss:-0.5457 G loss:-2.6\n",
      "Epoch:  0023 D loss:-0.3793 G loss:-2.962\n",
      "Epoch:  0023 D loss:-0.3643 G loss:-2.85\n",
      "Epoch:  0023 D loss:-0.3297 G loss:-2.911\n",
      "Epoch:  0023 D loss:-0.4608 G loss:-2.836\n",
      "Epoch:  0023 D loss:-0.5002 G loss:-2.629\n",
      "Epoch:  0023 D loss:-0.4031 G loss:-2.698\n",
      "Epoch:  0023 D loss:-0.4466 G loss:-2.57\n",
      "Epoch:  0023 D loss:-0.4354 G loss:-2.504\n",
      "Epoch:  0023 D loss:-0.4103 G loss:-2.606\n",
      "Epoch:  0023 D loss:-0.418 G loss:-2.538\n",
      "Epoch:  0023 D loss:-0.3944 G loss:-2.588\n",
      "Epoch:  0023 D loss:-0.3739 G loss:-2.88\n",
      "Epoch:  0023 D loss:-0.3752 G loss:-2.738\n",
      "Epoch:  0023 D loss:-0.4183 G loss:-2.508\n",
      "Epoch:  0023 D loss:-0.3707 G loss:-2.798\n",
      "Epoch:  0023 D loss:-0.4485 G loss:-2.82\n",
      "Epoch:  0023 D loss:-0.5934 G loss:-2.737\n",
      "Epoch:  0023 D loss:-0.5015 G loss:-2.634\n",
      "Epoch:  0023 D loss:-0.5259 G loss:-2.508\n",
      "Epoch:  0023 D loss:-0.4827 G loss:-2.541\n",
      "Epoch:  0023 D loss:-0.4586 G loss:-2.847\n",
      "Epoch:  0023 D loss:-0.3695 G loss:-2.831\n",
      "Epoch:  0023 D loss:-0.3718 G loss:-2.632\n",
      "Epoch:  0023 D loss:-0.5123 G loss:-2.361\n",
      "Epoch:  0023 D loss:-0.412 G loss:-2.683\n",
      "Epoch:  0023 D loss:-0.3611 G loss:-2.954\n",
      "Epoch:  0023 D loss:-0.4532 G loss:-2.689\n",
      "Epoch:  0023 D loss:-0.548 G loss:-2.862\n",
      "Epoch:  0023 D loss:-0.4536 G loss:-2.885\n",
      "Epoch:  0023 D loss:-0.4393 G loss:-2.541\n",
      "Epoch:  0023 D loss:-0.4372 G loss:-2.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0023 D loss:-0.3255 G loss:-2.685\n",
      "Epoch:  0023 D loss:-0.4212 G loss:-2.585\n",
      "Epoch:  0023 D loss:-0.4525 G loss:-2.663\n",
      "Epoch:  0023 D loss:-0.441 G loss:-2.626\n",
      "Epoch:  0023 D loss:-0.3901 G loss:-2.664\n",
      "Epoch:  0023 D loss:-0.4156 G loss:-2.633\n",
      "Epoch:  0023 D loss:-0.3305 G loss:-2.778\n",
      "Epoch:  0023 D loss:-0.3642 G loss:-2.773\n",
      "Epoch:  0023 D loss:-0.4494 G loss:-2.758\n",
      "Epoch:  0023 D loss:-0.3677 G loss:-3.032\n",
      "Epoch:  0023 D loss:-0.3867 G loss:-2.58\n",
      "Epoch:  0023 D loss:-0.3785 G loss:-2.871\n",
      "Epoch:  0023 D loss:-0.4998 G loss:-2.997\n",
      "Epoch:  0023 D loss:-0.4544 G loss:-2.891\n",
      "Epoch:  0023 D loss:-0.5165 G loss:-2.529\n",
      "Epoch:  0023 D loss:-0.3579 G loss:-2.65\n",
      "Epoch:  0023 D loss:-0.3932 G loss:-2.654\n",
      "Epoch:  0023 D loss:-0.3402 G loss:-2.775\n",
      "Epoch:  0023 D loss:-0.3941 G loss:-2.629\n",
      "Epoch:  0023 D loss:-0.3187 G loss:-2.742\n",
      "Epoch:  0023 D loss:-0.4331 G loss:-2.77\n",
      "Epoch:  0023 D loss:-0.4163 G loss:-2.763\n",
      "Epoch:  0023 D loss:-0.3344 G loss:-2.84\n",
      "Epoch:  0023 D loss:-0.4181 G loss:-2.635\n",
      "Epoch:  0023 D loss:-0.284 G loss:-2.64\n",
      "Epoch:  0023 D loss:-0.3845 G loss:-2.569\n",
      "Epoch:  0023 D loss:-0.4327 G loss:-2.51\n",
      "Epoch:  0023 D loss:-0.3578 G loss:-2.979\n",
      "Epoch:  0023 D loss:-0.3736 G loss:-3.204\n",
      "Epoch:  0023 D loss:-0.399 G loss:-3.005\n",
      "Epoch:  0023 D loss:-0.4012 G loss:-3.014\n",
      "Epoch:  0023 D loss:-0.3666 G loss:-2.901\n",
      "Epoch:  0023 D loss:-0.4027 G loss:-2.697\n",
      "Epoch:  0023 D loss:-0.5086 G loss:-2.706\n",
      "Epoch:  0023 D loss:-0.4692 G loss:-2.685\n",
      "Epoch:  0023 D loss:-0.4465 G loss:-2.49\n",
      "Epoch:  0023 D loss:-0.3306 G loss:-2.675\n",
      "Epoch:  0023 D loss:-0.3194 G loss:-2.6\n",
      "Epoch:  0023 D loss:-0.3409 G loss:-2.668\n",
      "Epoch:  0023 D loss:-0.2971 G loss:-2.78\n",
      "Epoch:  0023 D loss:-0.4882 G loss:-2.821\n",
      "Epoch:  0023 D loss:-0.3674 G loss:-2.69\n",
      "Epoch:  0023 D loss:-0.3272 G loss:-2.896\n",
      "Epoch:  0023 D loss:-0.3216 G loss:-2.762\n",
      "Epoch:  0023 D loss:-0.3842 G loss:-2.649\n",
      "Epoch:  0023 D loss:-0.3622 G loss:-2.927\n",
      "Epoch:  0023 D loss:-0.3595 G loss:-3.083\n",
      "Epoch:  0023 D loss:-0.4125 G loss:-2.966\n",
      "Epoch:  0023 D loss:-0.3073 G loss:-2.776\n",
      "Epoch:  0023 D loss:-0.3411 G loss:-2.797\n",
      "Epoch:  0023 D loss:-0.3715 G loss:-3.037\n",
      "Epoch:  0023 D loss:-0.4111 G loss:-2.737\n",
      "Epoch:  0023 D loss:-0.3348 G loss:-2.84\n",
      "Epoch:  0023 D loss:-0.2787 G loss:-2.939\n",
      "Epoch:  0023 D loss:-0.3222 G loss:-2.942\n",
      "Epoch:  0023 D loss:-0.3274 G loss:-2.788\n",
      "Epoch:  0023 D loss:-0.3784 G loss:-2.827\n",
      "Epoch:  0023 D loss:-0.3521 G loss:-2.848\n",
      "Epoch:  0023 D loss:-0.2518 G loss:-2.918\n",
      "Epoch:  0023 D loss:-0.3307 G loss:-2.599\n",
      "Epoch:  0023 D loss:-0.3006 G loss:-3.18\n",
      "Epoch:  0023 D loss:-0.3443 G loss:-2.945\n",
      "Epoch:  0023 D loss:-0.3199 G loss:-2.992\n",
      "Epoch:  0023 D loss:-0.2913 G loss:-2.854\n",
      "Epoch:  0023 D loss:-0.3108 G loss:-2.82\n",
      "Epoch:  0023 D loss:-0.3461 G loss:-3.012\n",
      "Epoch:  0023 D loss:-0.278 G loss:-2.758\n",
      "Epoch:  0023 D loss:-0.2448 G loss:-2.956\n",
      "Epoch:  0023 D loss:-0.4252 G loss:-2.856\n",
      "Epoch:  0023 D loss:-0.3156 G loss:-2.918\n",
      "Epoch:  0023 D loss:-0.2919 G loss:-2.773\n",
      "Epoch:  0023 D loss:-0.2646 G loss:-3.01\n",
      "Epoch:  0023 D loss:-0.2998 G loss:-2.882\n",
      "Epoch:  0023 D loss:-0.2843 G loss:-3.195\n",
      "Epoch:  0023 D loss:-0.2686 G loss:-3.193\n",
      "Epoch:  0023 D loss:-0.3066 G loss:-3.11\n",
      "Epoch:  0023 D loss:-0.2668 G loss:-2.842\n",
      "Epoch:  0023 D loss:-0.3133 G loss:-2.879\n",
      "Epoch:  0023 D loss:-0.3524 G loss:-2.939\n",
      "Epoch:  0023 D loss:-0.3605 G loss:-2.881\n",
      "Epoch:  0023 D loss:-0.3322 G loss:-2.778\n",
      "Epoch:  0023 D loss:-0.3431 G loss:-2.824\n",
      "Epoch:  0023 D loss:-0.2283 G loss:-3.069\n",
      "Epoch:  0023 D loss:-0.2987 G loss:-2.621\n",
      "Epoch:  0023 D loss:-0.2543 G loss:-2.936\n",
      "Epoch:  0023 D loss:-0.2902 G loss:-2.988\n",
      "Epoch:  0023 D loss:-0.2824 G loss:-3.013\n",
      "Epoch:  0023 D loss:-0.3305 G loss:-3.171\n",
      "Epoch:  0023 D loss:-0.3164 G loss:-3.178\n",
      "Epoch:  0023 D loss:-0.3665 G loss:-3.075\n",
      "Epoch:  0023 D loss:-0.2611 G loss:-2.956\n",
      "Epoch:  0023 D loss:-0.2553 G loss:-3.046\n",
      "Epoch:  0023 D loss:-0.2948 G loss:-3.115\n",
      "Epoch:  0023 D loss:-0.2575 G loss:-2.997\n",
      "Epoch:  0023 D loss:-0.2535 G loss:-3.054\n",
      "Epoch:  0023 D loss:-0.2964 G loss:-3.0\n",
      "Epoch:  0023 D loss:-0.3715 G loss:-2.769\n",
      "Epoch:  0023 D loss:-0.2196 G loss:-3.175\n",
      "Epoch:  0023 D loss:-0.241 G loss:-2.955\n",
      "Epoch:  0023 D loss:-0.36 G loss:-3.014\n",
      "Epoch:  0023 D loss:-0.2636 G loss:-2.975\n",
      "Epoch:  0023 D loss:-0.384 G loss:-2.629\n",
      "Epoch:  0023 D loss:-0.2702 G loss:-3.035\n",
      "Epoch:  0023 D loss:-0.3858 G loss:-2.644\n",
      "Epoch:  0023 D loss:-0.4244 G loss:-2.538\n",
      "Epoch:  0023 D loss:-0.2906 G loss:-2.86\n",
      "Epoch:  0023 D loss:-0.4244 G loss:-2.878\n",
      "Epoch:  0023 D loss:-0.2982 G loss:-2.936\n",
      "Epoch:  0023 D loss:-0.3741 G loss:-2.782\n",
      "Epoch:  0023 D loss:-0.3365 G loss:-2.833\n",
      "Epoch:  0023 D loss:-0.3584 G loss:-2.596\n",
      "Epoch:  0023 D loss:-0.2584 G loss:-2.971\n",
      "Epoch:  0023 D loss:-0.3022 G loss:-2.903\n",
      "Epoch:  0023 D loss:-0.3536 G loss:-2.787\n",
      "Epoch:  0023 D loss:-0.3688 G loss:-2.71\n",
      "Epoch:  0023 D loss:-0.3266 G loss:-2.853\n",
      "Epoch:  0023 D loss:-0.3595 G loss:-2.837\n",
      "Epoch:  0023 D loss:-0.3994 G loss:-2.596\n",
      "Epoch:  0023 D loss:-0.3322 G loss:-2.764\n",
      "Epoch:  0023 D loss:-0.411 G loss:-2.425\n",
      "Epoch:  0023 D loss:-0.3142 G loss:-2.658\n",
      "Epoch:  0023 D loss:-0.3471 G loss:-2.472\n",
      "Epoch:  0023 D loss:-0.3315 G loss:-2.767\n",
      "Epoch:  0023 D loss:-0.322 G loss:-2.596\n",
      "Epoch:  0023 D loss:-0.3586 G loss:-2.801\n",
      "Epoch:  0023 D loss:-0.3079 G loss:-3.047\n",
      "Epoch:  0023 D loss:-0.3556 G loss:-2.847\n",
      "Epoch:  0023 D loss:-0.3197 G loss:-2.851\n",
      "Epoch:  0023 D loss:-0.3621 G loss:-2.72\n",
      "Epoch:  0023 D loss:-0.3378 G loss:-2.87\n",
      "Epoch:  0023 D loss:-0.4795 G loss:-2.713\n",
      "Epoch:  0023 D loss:-0.2971 G loss:-3.206\n",
      "Epoch:  0023 D loss:-0.4128 G loss:-2.736\n",
      "Epoch:  0023 D loss:-0.3731 G loss:-2.886\n",
      "Epoch:  0023 D loss:-0.4603 G loss:-2.623\n",
      "Epoch:  0023 D loss:-0.4708 G loss:-2.604\n",
      "Epoch:  0023 D loss:-0.3591 G loss:-2.737\n",
      "Epoch:  0023 D loss:-0.3564 G loss:-2.492\n",
      "Epoch:  0023 D loss:-0.337 G loss:-2.544\n",
      "Epoch:  0023 D loss:-0.3795 G loss:-2.513\n",
      "Epoch:  0023 D loss:-0.3469 G loss:-2.365\n",
      "Epoch:  0023 D loss:-0.3215 G loss:-2.717\n",
      "Epoch:  0024 D loss:-0.41 G loss:-2.59\n",
      "Epoch:  0024 D loss:-0.5286 G loss:-2.717\n",
      "Epoch:  0024 D loss:-0.3535 G loss:-2.708\n",
      "Epoch:  0024 D loss:-0.331 G loss:-2.904\n",
      "Epoch:  0024 D loss:-0.4109 G loss:-2.628\n",
      "Epoch:  0024 D loss:-0.3844 G loss:-2.882\n",
      "Epoch:  0024 D loss:-0.4323 G loss:-2.958\n",
      "Epoch:  0024 D loss:-0.3306 G loss:-3.004\n",
      "Epoch:  0024 D loss:-0.3137 G loss:-3.223\n",
      "Epoch:  0024 D loss:-0.482 G loss:-2.841\n",
      "Epoch:  0024 D loss:-0.4444 G loss:-2.787\n",
      "Epoch:  0024 D loss:-0.4314 G loss:-2.49\n",
      "Epoch:  0024 D loss:-0.4599 G loss:-2.41\n",
      "Epoch:  0024 D loss:-0.4237 G loss:-2.333\n",
      "Epoch:  0024 D loss:-0.4648 G loss:-2.327\n",
      "Epoch:  0024 D loss:-0.464 G loss:-2.274\n",
      "Epoch:  0024 D loss:-0.3565 G loss:-2.349\n",
      "Epoch:  0024 D loss:-0.4005 G loss:-2.49\n",
      "Epoch:  0024 D loss:-0.3224 G loss:-2.856\n",
      "Epoch:  0024 D loss:-0.3509 G loss:-2.726\n",
      "Epoch:  0024 D loss:-0.3303 G loss:-2.834\n",
      "Epoch:  0024 D loss:-0.3628 G loss:-2.854\n",
      "Epoch:  0024 D loss:-0.3357 G loss:-3.045\n",
      "Epoch:  0024 D loss:-0.3415 G loss:-3.511\n",
      "Epoch:  0024 D loss:-0.3046 G loss:-3.147\n",
      "Epoch:  0024 D loss:-0.2966 G loss:-2.881\n",
      "Epoch:  0024 D loss:-0.3608 G loss:-2.751\n",
      "Epoch:  0024 D loss:-0.3431 G loss:-3.006\n",
      "Epoch:  0024 D loss:-0.3067 G loss:-2.907\n",
      "Epoch:  0024 D loss:-0.3024 G loss:-2.994\n",
      "Epoch:  0024 D loss:-0.3364 G loss:-2.857\n",
      "Epoch:  0024 D loss:-0.4767 G loss:-2.551\n",
      "Epoch:  0024 D loss:-0.3906 G loss:-2.457\n",
      "Epoch:  0024 D loss:-0.374 G loss:-2.61\n",
      "Epoch:  0024 D loss:-0.4589 G loss:-2.682\n",
      "Epoch:  0024 D loss:-0.4048 G loss:-2.771\n",
      "Epoch:  0024 D loss:-0.405 G loss:-2.629\n",
      "Epoch:  0024 D loss:-0.4315 G loss:-2.503\n",
      "Epoch:  0024 D loss:-0.4591 G loss:-2.746\n",
      "Epoch:  0024 D loss:-0.4086 G loss:-2.365\n",
      "Epoch:  0024 D loss:-0.5144 G loss:-2.267\n",
      "Epoch:  0024 D loss:-0.3831 G loss:-2.59\n",
      "Epoch:  0024 D loss:-0.685 G loss:-2.303\n",
      "Epoch:  0024 D loss:-0.3871 G loss:-2.725\n",
      "Epoch:  0024 D loss:-0.4746 G loss:-2.452\n",
      "Epoch:  0024 D loss:-0.4992 G loss:-2.917\n",
      "Epoch:  0024 D loss:-0.3379 G loss:-2.762\n",
      "Epoch:  0024 D loss:-0.4341 G loss:-2.509\n",
      "Epoch:  0024 D loss:-0.4858 G loss:-2.378\n",
      "Epoch:  0024 D loss:-0.487 G loss:-2.405\n",
      "Epoch:  0024 D loss:-0.417 G loss:-2.491\n",
      "Epoch:  0024 D loss:-0.5003 G loss:-2.466\n",
      "Epoch:  0024 D loss:-0.4743 G loss:-2.578\n",
      "Epoch:  0024 D loss:-0.4406 G loss:-2.618\n",
      "Epoch:  0024 D loss:-0.4921 G loss:-2.644\n",
      "Epoch:  0024 D loss:-0.4118 G loss:-2.682\n",
      "Epoch:  0024 D loss:-0.41 G loss:-2.643\n",
      "Epoch:  0024 D loss:-0.4004 G loss:-2.64\n",
      "Epoch:  0024 D loss:-0.3674 G loss:-2.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0024 D loss:-0.4878 G loss:-2.616\n",
      "Epoch:  0024 D loss:-0.4195 G loss:-2.668\n",
      "Epoch:  0024 D loss:-0.5188 G loss:-2.545\n",
      "Epoch:  0024 D loss:-0.538 G loss:-2.343\n",
      "Epoch:  0024 D loss:-0.4487 G loss:-2.726\n",
      "Epoch:  0024 D loss:-0.556 G loss:-2.349\n",
      "Epoch:  0024 D loss:-0.6108 G loss:-2.605\n",
      "Epoch:  0024 D loss:-0.4029 G loss:-2.357\n",
      "Epoch:  0024 D loss:-0.4421 G loss:-2.419\n",
      "Epoch:  0024 D loss:-0.4432 G loss:-2.48\n",
      "Epoch:  0024 D loss:-0.5081 G loss:-2.34\n",
      "Epoch:  0024 D loss:-0.2822 G loss:-2.878\n",
      "Epoch:  0024 D loss:-0.4293 G loss:-2.599\n",
      "Epoch:  0024 D loss:-0.3746 G loss:-2.658\n",
      "Epoch:  0024 D loss:-0.4753 G loss:-2.528\n",
      "Epoch:  0024 D loss:-0.497 G loss:-2.726\n",
      "Epoch:  0024 D loss:-0.4897 G loss:-2.709\n",
      "Epoch:  0024 D loss:-0.4717 G loss:-2.686\n",
      "Epoch:  0024 D loss:-0.4293 G loss:-2.7\n",
      "Epoch:  0024 D loss:-0.374 G loss:-2.806\n",
      "Epoch:  0024 D loss:-0.508 G loss:-2.807\n",
      "Epoch:  0024 D loss:-0.3336 G loss:-3.021\n",
      "Epoch:  0024 D loss:-0.3903 G loss:-2.751\n",
      "Epoch:  0024 D loss:-0.5166 G loss:-2.592\n",
      "Epoch:  0024 D loss:-0.4043 G loss:-2.641\n",
      "Epoch:  0024 D loss:-0.3618 G loss:-2.552\n",
      "Epoch:  0024 D loss:-0.3501 G loss:-2.419\n",
      "Epoch:  0024 D loss:-0.3893 G loss:-2.434\n",
      "Epoch:  0024 D loss:-0.4748 G loss:-2.419\n",
      "Epoch:  0024 D loss:-0.3726 G loss:-2.551\n",
      "Epoch:  0024 D loss:-0.3415 G loss:-2.548\n",
      "Epoch:  0024 D loss:-0.4169 G loss:-2.755\n",
      "Epoch:  0024 D loss:-0.3912 G loss:-2.724\n",
      "Epoch:  0024 D loss:-0.3893 G loss:-2.858\n",
      "Epoch:  0024 D loss:-0.4335 G loss:-2.756\n",
      "Epoch:  0024 D loss:-0.4779 G loss:-3.017\n",
      "Epoch:  0024 D loss:-0.3649 G loss:-2.891\n",
      "Epoch:  0024 D loss:-0.4337 G loss:-2.662\n",
      "Epoch:  0024 D loss:-0.4802 G loss:-2.767\n",
      "Epoch:  0024 D loss:-0.424 G loss:-2.624\n",
      "Epoch:  0024 D loss:-0.4658 G loss:-2.767\n",
      "Epoch:  0024 D loss:-0.2378 G loss:-2.78\n",
      "Epoch:  0024 D loss:-0.3814 G loss:-2.67\n",
      "Epoch:  0024 D loss:-0.3914 G loss:-2.616\n",
      "Epoch:  0024 D loss:-0.31 G loss:-2.729\n",
      "Epoch:  0024 D loss:-0.3814 G loss:-2.249\n",
      "Epoch:  0024 D loss:-0.3885 G loss:-2.549\n",
      "Epoch:  0024 D loss:-0.3605 G loss:-2.82\n",
      "Epoch:  0024 D loss:-0.3214 G loss:-2.72\n",
      "Epoch:  0024 D loss:-0.3785 G loss:-2.77\n",
      "Epoch:  0024 D loss:-0.4133 G loss:-2.687\n",
      "Epoch:  0024 D loss:-0.468 G loss:-2.675\n",
      "Epoch:  0024 D loss:-0.2984 G loss:-2.861\n",
      "Epoch:  0024 D loss:-0.3117 G loss:-3.027\n",
      "Epoch:  0024 D loss:-0.3712 G loss:-2.879\n",
      "Epoch:  0024 D loss:-0.3239 G loss:-2.827\n",
      "Epoch:  0024 D loss:-0.4647 G loss:-2.621\n",
      "Epoch:  0024 D loss:-0.3166 G loss:-2.769\n",
      "Epoch:  0024 D loss:-0.304 G loss:-2.977\n",
      "Epoch:  0024 D loss:-0.4239 G loss:-2.656\n",
      "Epoch:  0024 D loss:-0.3177 G loss:-2.896\n",
      "Epoch:  0024 D loss:-0.446 G loss:-3.02\n",
      "Epoch:  0024 D loss:-0.3922 G loss:-2.781\n",
      "Epoch:  0024 D loss:-0.3413 G loss:-2.737\n",
      "Epoch:  0024 D loss:-0.3516 G loss:-2.728\n",
      "Epoch:  0024 D loss:-0.306 G loss:-2.874\n",
      "Epoch:  0024 D loss:-0.3491 G loss:-2.837\n",
      "Epoch:  0024 D loss:-0.4253 G loss:-2.85\n",
      "Epoch:  0024 D loss:-0.2991 G loss:-2.847\n",
      "Epoch:  0024 D loss:-0.3968 G loss:-2.746\n",
      "Epoch:  0024 D loss:-0.2955 G loss:-3.145\n",
      "Epoch:  0024 D loss:-0.4124 G loss:-2.898\n",
      "Epoch:  0024 D loss:-0.382 G loss:-2.947\n",
      "Epoch:  0024 D loss:-0.3327 G loss:-2.93\n",
      "Epoch:  0024 D loss:-0.3926 G loss:-3.029\n",
      "Epoch:  0024 D loss:-0.332 G loss:-2.967\n",
      "Epoch:  0024 D loss:-0.3885 G loss:-2.977\n",
      "Epoch:  0024 D loss:-0.2797 G loss:-3.219\n",
      "Epoch:  0024 D loss:-0.2915 G loss:-2.948\n",
      "Epoch:  0024 D loss:-0.3324 G loss:-2.663\n",
      "Epoch:  0024 D loss:-0.3802 G loss:-2.993\n",
      "Epoch:  0024 D loss:-0.3854 G loss:-2.835\n",
      "Epoch:  0024 D loss:-0.272 G loss:-2.812\n",
      "Epoch:  0024 D loss:-0.2831 G loss:-2.928\n",
      "Epoch:  0024 D loss:-0.3708 G loss:-2.82\n",
      "Epoch:  0024 D loss:-0.2666 G loss:-3.046\n",
      "Epoch:  0024 D loss:-0.3188 G loss:-2.939\n",
      "Epoch:  0024 D loss:-0.2802 G loss:-2.971\n",
      "Epoch:  0024 D loss:-0.3231 G loss:-2.972\n",
      "Epoch:  0024 D loss:-0.3024 G loss:-3.24\n",
      "Epoch:  0024 D loss:-0.3692 G loss:-2.758\n",
      "Epoch:  0024 D loss:-0.3852 G loss:-3.065\n",
      "Epoch:  0024 D loss:-0.3849 G loss:-2.987\n",
      "Epoch:  0024 D loss:-0.3866 G loss:-2.801\n",
      "Epoch:  0024 D loss:-0.2915 G loss:-2.942\n",
      "Epoch:  0024 D loss:-0.3452 G loss:-2.869\n",
      "Epoch:  0024 D loss:-0.2849 G loss:-2.95\n",
      "Epoch:  0024 D loss:-0.3232 G loss:-3.106\n",
      "Epoch:  0024 D loss:-0.2383 G loss:-2.882\n",
      "Epoch:  0024 D loss:-0.3228 G loss:-2.92\n",
      "Epoch:  0024 D loss:-0.3591 G loss:-2.882\n",
      "Epoch:  0024 D loss:-0.3942 G loss:-2.887\n",
      "Epoch:  0024 D loss:-0.2958 G loss:-2.976\n",
      "Epoch:  0024 D loss:-0.2662 G loss:-2.964\n",
      "Epoch:  0024 D loss:-0.5458 G loss:-2.914\n",
      "Epoch:  0024 D loss:-0.376 G loss:-2.946\n",
      "Epoch:  0024 D loss:-0.3188 G loss:-2.6\n",
      "Epoch:  0024 D loss:-0.2856 G loss:-2.999\n",
      "Epoch:  0024 D loss:-0.2876 G loss:-2.842\n",
      "Epoch:  0024 D loss:-0.3254 G loss:-2.934\n",
      "Epoch:  0024 D loss:-0.2942 G loss:-3.091\n",
      "Epoch:  0024 D loss:-0.2963 G loss:-2.785\n",
      "Epoch:  0024 D loss:-0.3213 G loss:-3.124\n",
      "Epoch:  0024 D loss:-0.2962 G loss:-3.075\n",
      "Epoch:  0024 D loss:-0.3285 G loss:-3.076\n",
      "Epoch:  0024 D loss:-0.3393 G loss:-2.897\n",
      "Epoch:  0024 D loss:-0.2289 G loss:-3.223\n",
      "Epoch:  0024 D loss:-0.3908 G loss:-2.866\n",
      "Epoch:  0024 D loss:-0.2974 G loss:-2.971\n",
      "Epoch:  0024 D loss:-0.3352 G loss:-3.285\n",
      "Epoch:  0024 D loss:-0.453 G loss:-3.259\n",
      "Epoch:  0024 D loss:-0.4458 G loss:-3.093\n",
      "Epoch:  0024 D loss:-0.4109 G loss:-2.787\n",
      "Epoch:  0024 D loss:-0.3416 G loss:-2.704\n",
      "Epoch:  0024 D loss:-0.4034 G loss:-2.61\n",
      "Epoch:  0024 D loss:-0.4355 G loss:-2.351\n",
      "Epoch:  0024 D loss:-0.4768 G loss:-2.38\n",
      "Epoch:  0024 D loss:-0.3469 G loss:-2.727\n",
      "Epoch:  0024 D loss:-0.2995 G loss:-2.756\n",
      "Epoch:  0024 D loss:-0.3901 G loss:-2.745\n",
      "Epoch:  0024 D loss:-0.2922 G loss:-3.334\n",
      "Epoch:  0024 D loss:-0.4052 G loss:-2.644\n",
      "Epoch:  0024 D loss:-0.3347 G loss:-2.91\n",
      "Epoch:  0024 D loss:-0.3741 G loss:-3.208\n",
      "Epoch:  0024 D loss:-0.3747 G loss:-3.072\n",
      "Epoch:  0024 D loss:-0.4101 G loss:-2.877\n",
      "Epoch:  0024 D loss:-0.3583 G loss:-3.122\n",
      "Epoch:  0024 D loss:-0.2775 G loss:-3.198\n",
      "Epoch:  0024 D loss:-0.3935 G loss:-2.956\n",
      "Epoch:  0024 D loss:-0.3402 G loss:-3.295\n",
      "Epoch:  0024 D loss:-0.4267 G loss:-2.734\n",
      "Epoch:  0024 D loss:-0.2712 G loss:-3.011\n",
      "Epoch:  0024 D loss:-0.3188 G loss:-2.73\n",
      "Epoch:  0024 D loss:-0.3712 G loss:-2.824\n",
      "Epoch:  0024 D loss:-0.4265 G loss:-3.064\n",
      "Epoch:  0024 D loss:-0.2941 G loss:-2.647\n",
      "Epoch:  0024 D loss:-0.3752 G loss:-2.813\n",
      "Epoch:  0024 D loss:-0.2991 G loss:-2.886\n",
      "Epoch:  0024 D loss:-0.4296 G loss:-2.643\n",
      "Epoch:  0024 D loss:-0.3424 G loss:-2.723\n",
      "Epoch:  0024 D loss:-0.5037 G loss:-2.731\n",
      "Epoch:  0024 D loss:-0.5782 G loss:-2.607\n",
      "Epoch:  0024 D loss:-0.4157 G loss:-2.694\n",
      "Epoch:  0024 D loss:-0.4276 G loss:-2.717\n",
      "Epoch:  0024 D loss:-0.4282 G loss:-2.66\n",
      "Epoch:  0024 D loss:-0.413 G loss:-2.346\n",
      "Epoch:  0024 D loss:-0.4485 G loss:-2.581\n",
      "Epoch:  0024 D loss:-0.4759 G loss:-2.67\n",
      "Epoch:  0024 D loss:-0.4807 G loss:-2.513\n",
      "Epoch:  0024 D loss:-0.5133 G loss:-2.503\n",
      "Epoch:  0024 D loss:-0.4434 G loss:-2.641\n",
      "Epoch:  0024 D loss:-0.4454 G loss:-2.371\n",
      "Epoch:  0024 D loss:-0.5513 G loss:-2.533\n",
      "Epoch:  0024 D loss:-0.5731 G loss:-2.526\n",
      "Epoch:  0024 D loss:-0.528 G loss:-2.598\n",
      "Epoch:  0024 D loss:-0.3809 G loss:-2.674\n",
      "Epoch:  0024 D loss:-0.3851 G loss:-3.055\n",
      "Epoch:  0024 D loss:-0.4399 G loss:-2.65\n",
      "Epoch:  0024 D loss:-0.3355 G loss:-3.037\n",
      "Epoch:  0024 D loss:-0.6425 G loss:-2.643\n",
      "Epoch:  0024 D loss:-0.3952 G loss:-2.756\n",
      "Epoch:  0024 D loss:-0.4891 G loss:-2.516\n",
      "Epoch:  0024 D loss:-0.4695 G loss:-2.636\n",
      "Epoch:  0024 D loss:-0.6049 G loss:-2.628\n",
      "Epoch:  0024 D loss:-0.5005 G loss:-2.596\n",
      "Epoch:  0024 D loss:-0.4776 G loss:-2.184\n",
      "Epoch:  0024 D loss:-0.4792 G loss:-2.356\n",
      "Epoch:  0024 D loss:-0.4567 G loss:-2.328\n",
      "Epoch:  0024 D loss:-0.5646 G loss:-2.369\n",
      "Epoch:  0024 D loss:-0.5261 G loss:-2.314\n",
      "Epoch:  0024 D loss:-0.5816 G loss:-2.395\n",
      "Epoch:  0024 D loss:-0.5621 G loss:-2.474\n",
      "Epoch:  0024 D loss:-0.4928 G loss:-2.55\n",
      "Epoch:  0024 D loss:-0.566 G loss:-2.323\n",
      "Epoch:  0024 D loss:-0.3602 G loss:-2.652\n",
      "Epoch:  0024 D loss:-0.4594 G loss:-2.502\n",
      "Epoch:  0024 D loss:-0.4805 G loss:-2.831\n",
      "Epoch:  0024 D loss:-0.3776 G loss:-2.906\n",
      "Epoch:  0024 D loss:-0.4149 G loss:-2.568\n",
      "Epoch:  0024 D loss:-0.5555 G loss:-2.684\n",
      "Epoch:  0024 D loss:-0.4435 G loss:-2.768\n",
      "Epoch:  0024 D loss:-0.542 G loss:-2.429\n",
      "Epoch:  0024 D loss:-0.5058 G loss:-2.355\n",
      "Epoch:  0024 D loss:-0.5203 G loss:-2.294\n",
      "Epoch:  0024 D loss:-0.4495 G loss:-2.461\n",
      "Epoch:  0024 D loss:-0.4849 G loss:-2.393\n",
      "Epoch:  0024 D loss:-0.5147 G loss:-2.375\n",
      "Epoch:  0024 D loss:-0.4567 G loss:-2.371\n",
      "Epoch:  0024 D loss:-0.4549 G loss:-2.488\n",
      "Epoch:  0024 D loss:-0.5537 G loss:-2.402\n",
      "Epoch:  0024 D loss:-0.4543 G loss:-2.449\n",
      "Epoch:  0024 D loss:-0.3891 G loss:-2.852\n",
      "Epoch:  0024 D loss:-0.3681 G loss:-2.564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0024 D loss:-0.3542 G loss:-2.919\n",
      "Epoch:  0024 D loss:-0.4349 G loss:-2.88\n",
      "Epoch:  0024 D loss:-0.3396 G loss:-2.919\n",
      "Epoch:  0024 D loss:-0.4087 G loss:-2.852\n",
      "Epoch:  0024 D loss:-0.4983 G loss:-2.689\n",
      "Epoch:  0024 D loss:-0.3754 G loss:-2.833\n",
      "Epoch:  0024 D loss:-0.3522 G loss:-2.862\n",
      "Epoch:  0024 D loss:-0.4334 G loss:-2.83\n",
      "Epoch:  0024 D loss:-0.5198 G loss:-2.868\n",
      "Epoch:  0024 D loss:-0.4336 G loss:-2.778\n",
      "Epoch:  0024 D loss:-0.4162 G loss:-2.765\n",
      "Epoch:  0024 D loss:-0.498 G loss:-2.631\n",
      "Epoch:  0024 D loss:-0.4479 G loss:-2.644\n",
      "Epoch:  0024 D loss:-0.4443 G loss:-2.5\n",
      "Epoch:  0024 D loss:-0.4781 G loss:-2.404\n",
      "Epoch:  0024 D loss:-0.4019 G loss:-2.564\n",
      "Epoch:  0024 D loss:-0.3825 G loss:-2.412\n",
      "Epoch:  0024 D loss:-0.4003 G loss:-2.429\n",
      "Epoch:  0024 D loss:-0.4094 G loss:-2.506\n",
      "Epoch:  0024 D loss:-0.351 G loss:-2.759\n",
      "Epoch:  0024 D loss:-0.3897 G loss:-2.52\n",
      "Epoch:  0024 D loss:-0.4893 G loss:-2.759\n",
      "Epoch:  0024 D loss:-0.3877 G loss:-2.861\n",
      "Epoch:  0024 D loss:-0.4534 G loss:-2.717\n",
      "Epoch:  0024 D loss:-0.4732 G loss:-2.722\n",
      "Epoch:  0024 D loss:-0.4547 G loss:-2.962\n",
      "Epoch:  0024 D loss:-0.3053 G loss:-2.769\n",
      "Epoch:  0024 D loss:-0.4436 G loss:-2.659\n",
      "Epoch:  0024 D loss:-0.4427 G loss:-2.636\n",
      "Epoch:  0024 D loss:-0.3257 G loss:-2.78\n",
      "Epoch:  0024 D loss:-0.3939 G loss:-2.797\n",
      "Epoch:  0024 D loss:-0.3544 G loss:-2.999\n",
      "Epoch:  0024 D loss:-0.3997 G loss:-2.514\n",
      "Epoch:  0024 D loss:-0.5186 G loss:-2.695\n",
      "Epoch:  0024 D loss:-0.3289 G loss:-2.98\n",
      "Epoch:  0024 D loss:-0.3971 G loss:-2.748\n",
      "Epoch:  0024 D loss:-0.3801 G loss:-2.881\n",
      "Epoch:  0024 D loss:-0.3924 G loss:-2.778\n",
      "Epoch:  0024 D loss:-0.3348 G loss:-2.723\n",
      "Epoch:  0024 D loss:-0.2998 G loss:-2.629\n",
      "Epoch:  0024 D loss:-0.3601 G loss:-2.622\n",
      "Epoch:  0024 D loss:-0.3277 G loss:-2.601\n",
      "Epoch:  0024 D loss:-0.2587 G loss:-3.012\n",
      "Epoch:  0024 D loss:-0.345 G loss:-2.883\n",
      "Epoch:  0024 D loss:-0.267 G loss:-3.077\n",
      "Epoch:  0024 D loss:-0.4279 G loss:-2.943\n",
      "Epoch:  0024 D loss:-0.305 G loss:-3.074\n",
      "Epoch:  0024 D loss:-0.3161 G loss:-3.077\n",
      "Epoch:  0024 D loss:-0.3237 G loss:-2.78\n",
      "Epoch:  0024 D loss:-0.3416 G loss:-2.93\n",
      "Epoch:  0024 D loss:-0.3483 G loss:-3.02\n",
      "Epoch:  0024 D loss:-0.4142 G loss:-3.112\n",
      "Epoch:  0024 D loss:-0.2649 G loss:-2.967\n",
      "Epoch:  0024 D loss:-0.2426 G loss:-2.818\n",
      "Epoch:  0024 D loss:-0.3482 G loss:-2.961\n",
      "Epoch:  0024 D loss:-0.319 G loss:-2.849\n",
      "Epoch:  0024 D loss:-0.2821 G loss:-2.978\n",
      "Epoch:  0024 D loss:-0.3789 G loss:-2.597\n",
      "Epoch:  0024 D loss:-0.3672 G loss:-2.697\n",
      "Epoch:  0024 D loss:-0.4127 G loss:-2.64\n",
      "Epoch:  0024 D loss:-0.311 G loss:-2.906\n",
      "Epoch:  0024 D loss:-0.3646 G loss:-2.65\n",
      "Epoch:  0024 D loss:-0.4102 G loss:-2.908\n",
      "Epoch:  0024 D loss:-0.3305 G loss:-2.869\n",
      "Epoch:  0024 D loss:-0.3347 G loss:-2.841\n",
      "Epoch:  0024 D loss:-0.3645 G loss:-3.204\n",
      "Epoch:  0024 D loss:-0.3765 G loss:-2.882\n",
      "Epoch:  0024 D loss:-0.3576 G loss:-3.107\n",
      "Epoch:  0024 D loss:-0.377 G loss:-2.851\n",
      "Epoch:  0024 D loss:-0.346 G loss:-2.898\n",
      "Epoch:  0024 D loss:-0.3322 G loss:-2.906\n",
      "Epoch:  0024 D loss:-0.3169 G loss:-2.832\n",
      "Epoch:  0024 D loss:-0.4663 G loss:-2.808\n",
      "Epoch:  0024 D loss:-0.3223 G loss:-2.734\n",
      "Epoch:  0024 D loss:-0.4009 G loss:-2.711\n",
      "Epoch:  0024 D loss:-0.4424 G loss:-2.573\n",
      "Epoch:  0024 D loss:-0.4379 G loss:-2.398\n",
      "Epoch:  0024 D loss:-0.3951 G loss:-2.463\n",
      "Epoch:  0024 D loss:-0.5159 G loss:-2.573\n",
      "Epoch:  0024 D loss:-0.3739 G loss:-2.548\n",
      "Epoch:  0024 D loss:-0.3334 G loss:-2.742\n",
      "Epoch:  0024 D loss:-0.3942 G loss:-3.001\n",
      "Epoch:  0024 D loss:-0.3866 G loss:-2.691\n",
      "Epoch:  0024 D loss:-0.3988 G loss:-2.689\n",
      "Epoch:  0024 D loss:-0.4641 G loss:-3.065\n",
      "Epoch:  0024 D loss:-0.3804 G loss:-2.955\n",
      "Epoch:  0024 D loss:-0.3541 G loss:-2.903\n",
      "Epoch:  0024 D loss:-0.3564 G loss:-2.827\n",
      "Epoch:  0024 D loss:-0.3557 G loss:-3.052\n",
      "Epoch:  0024 D loss:-0.3804 G loss:-2.751\n",
      "Epoch:  0024 D loss:-0.3454 G loss:-2.76\n",
      "Epoch:  0024 D loss:-0.3756 G loss:-2.839\n",
      "Epoch:  0024 D loss:-0.4248 G loss:-2.696\n",
      "Epoch:  0024 D loss:-0.4532 G loss:-2.616\n",
      "Epoch:  0024 D loss:-0.3539 G loss:-2.437\n",
      "Epoch:  0024 D loss:-0.3062 G loss:-2.753\n",
      "Epoch:  0024 D loss:-0.2895 G loss:-2.626\n",
      "Epoch:  0024 D loss:-0.3263 G loss:-2.783\n",
      "Epoch:  0024 D loss:-0.3906 G loss:-2.716\n",
      "Epoch:  0024 D loss:-0.453 G loss:-2.872\n",
      "Epoch:  0024 D loss:-0.2488 G loss:-3.246\n",
      "Epoch:  0024 D loss:-0.3817 G loss:-2.84\n",
      "Epoch:  0024 D loss:-0.2964 G loss:-2.95\n",
      "Epoch:  0024 D loss:-0.4205 G loss:-2.812\n",
      "Epoch:  0024 D loss:-0.4081 G loss:-2.671\n",
      "Epoch:  0024 D loss:-0.4268 G loss:-2.846\n",
      "Epoch:  0024 D loss:-0.4249 G loss:-2.747\n",
      "Epoch:  0024 D loss:-0.4197 G loss:-2.828\n",
      "Epoch:  0024 D loss:-0.4707 G loss:-2.381\n",
      "Epoch:  0024 D loss:-0.3753 G loss:-2.356\n",
      "Epoch:  0024 D loss:-0.4166 G loss:-2.415\n",
      "Epoch:  0024 D loss:-0.3233 G loss:-2.698\n",
      "Epoch:  0024 D loss:-0.4804 G loss:-2.432\n",
      "Epoch:  0024 D loss:-0.4219 G loss:-2.577\n",
      "Epoch:  0024 D loss:-0.5852 G loss:-2.728\n",
      "Epoch:  0024 D loss:-0.4893 G loss:-2.682\n",
      "Epoch:  0024 D loss:-0.3695 G loss:-2.696\n",
      "Epoch:  0024 D loss:-0.3825 G loss:-2.672\n",
      "Epoch:  0024 D loss:-0.3543 G loss:-2.718\n",
      "Epoch:  0024 D loss:-0.46 G loss:-2.614\n",
      "Epoch:  0024 D loss:-0.4908 G loss:-2.671\n",
      "Epoch:  0024 D loss:-0.4498 G loss:-2.705\n",
      "Epoch:  0024 D loss:-0.3871 G loss:-2.893\n",
      "Epoch:  0024 D loss:-0.4356 G loss:-2.555\n",
      "Epoch:  0024 D loss:-0.4243 G loss:-2.554\n",
      "Epoch:  0024 D loss:-0.5155 G loss:-2.829\n",
      "Epoch:  0024 D loss:-0.576 G loss:-2.796\n",
      "Epoch:  0024 D loss:-0.397 G loss:-2.665\n",
      "Epoch:  0024 D loss:-0.3894 G loss:-2.799\n",
      "Epoch:  0024 D loss:-0.3471 G loss:-2.812\n",
      "Epoch:  0024 D loss:-0.46 G loss:-2.608\n",
      "Epoch:  0024 D loss:-0.5863 G loss:-2.408\n",
      "Epoch:  0024 D loss:-0.3853 G loss:-2.441\n",
      "Epoch:  0024 D loss:-0.4293 G loss:-2.698\n",
      "Epoch:  0024 D loss:-0.4451 G loss:-2.433\n",
      "Epoch:  0024 D loss:-0.3614 G loss:-2.67\n",
      "Epoch:  0024 D loss:-0.3945 G loss:-2.608\n",
      "Epoch:  0024 D loss:-0.5095 G loss:-2.992\n",
      "Epoch:  0024 D loss:-0.5082 G loss:-2.854\n",
      "Epoch:  0024 D loss:-0.5553 G loss:-2.675\n",
      "Epoch:  0024 D loss:-0.3909 G loss:-2.507\n",
      "Epoch:  0024 D loss:-0.5006 G loss:-2.41\n",
      "Epoch:  0024 D loss:-0.5373 G loss:-2.543\n",
      "Epoch:  0024 D loss:-0.6476 G loss:-2.429\n",
      "Epoch:  0024 D loss:-0.4039 G loss:-2.637\n",
      "Epoch:  0024 D loss:-0.4453 G loss:-2.576\n",
      "Epoch:  0024 D loss:-0.4459 G loss:-2.459\n",
      "Epoch:  0024 D loss:-0.4613 G loss:-2.523\n",
      "Epoch:  0024 D loss:-0.6554 G loss:-2.288\n",
      "Epoch:  0024 D loss:-0.3761 G loss:-2.703\n",
      "Epoch:  0024 D loss:-0.569 G loss:-2.833\n",
      "Epoch:  0024 D loss:-0.4671 G loss:-3.094\n",
      "Epoch:  0024 D loss:-0.5221 G loss:-3.122\n",
      "Epoch:  0024 D loss:-0.4019 G loss:-3.15\n",
      "Epoch:  0024 D loss:-0.4496 G loss:-2.815\n",
      "Epoch:  0024 D loss:-0.4321 G loss:-2.934\n",
      "Epoch:  0024 D loss:-0.5113 G loss:-2.529\n",
      "Epoch:  0024 D loss:-0.5361 G loss:-2.602\n",
      "Epoch:  0024 D loss:-0.4263 G loss:-2.482\n",
      "Epoch:  0024 D loss:-0.4695 G loss:-2.375\n",
      "Epoch:  0024 D loss:-0.5059 G loss:-2.31\n",
      "Epoch:  0024 D loss:-0.3097 G loss:-2.598\n",
      "Epoch:  0024 D loss:-0.3893 G loss:-2.368\n",
      "Epoch:  0024 D loss:-0.3835 G loss:-2.77\n",
      "Epoch:  0024 D loss:-0.4784 G loss:-2.706\n",
      "Epoch:  0024 D loss:-0.4822 G loss:-2.906\n",
      "Epoch:  0024 D loss:-0.3842 G loss:-2.97\n",
      "Epoch:  0024 D loss:-0.549 G loss:-2.882\n",
      "Epoch:  0024 D loss:-0.4952 G loss:-2.799\n",
      "Epoch:  0024 D loss:-0.4049 G loss:-2.782\n",
      "Epoch:  0024 D loss:-0.3885 G loss:-2.733\n",
      "Epoch:  0024 D loss:-0.4282 G loss:-2.561\n",
      "Epoch:  0024 D loss:-0.5161 G loss:-2.487\n",
      "Epoch:  0024 D loss:-0.3766 G loss:-2.527\n",
      "Epoch:  0024 D loss:-0.3892 G loss:-2.509\n",
      "Epoch:  0024 D loss:-0.4492 G loss:-2.826\n",
      "Epoch:  0024 D loss:-0.3884 G loss:-2.6\n",
      "Epoch:  0024 D loss:-0.4112 G loss:-2.65\n",
      "Epoch:  0024 D loss:-0.4217 G loss:-2.553\n",
      "Epoch:  0024 D loss:-0.4432 G loss:-2.698\n",
      "Epoch:  0024 D loss:-0.367 G loss:-2.832\n",
      "Epoch:  0024 D loss:-0.3468 G loss:-3.03\n",
      "Epoch:  0024 D loss:-0.4313 G loss:-2.823\n",
      "Epoch:  0024 D loss:-0.421 G loss:-3.025\n",
      "Epoch:  0024 D loss:-0.4366 G loss:-3.165\n",
      "Epoch:  0024 D loss:-0.4302 G loss:-2.926\n",
      "Epoch:  0024 D loss:-0.394 G loss:-2.927\n",
      "Epoch:  0024 D loss:-0.5093 G loss:-2.836\n",
      "Epoch:  0024 D loss:-0.4029 G loss:-2.792\n",
      "Epoch:  0024 D loss:-0.4394 G loss:-2.808\n",
      "Epoch:  0024 D loss:-0.4799 G loss:-2.585\n",
      "Epoch:  0024 D loss:-0.3819 G loss:-2.691\n",
      "Epoch:  0024 D loss:-0.3283 G loss:-2.481\n",
      "Epoch:  0024 D loss:-0.4358 G loss:-2.569\n",
      "Epoch:  0024 D loss:-0.4416 G loss:-2.918\n",
      "Epoch:  0024 D loss:-0.3306 G loss:-2.761\n",
      "Epoch:  0024 D loss:-0.408 G loss:-2.883\n",
      "Epoch:  0024 D loss:-0.3933 G loss:-2.895\n",
      "Epoch:  0024 D loss:-0.5148 G loss:-2.976\n",
      "Epoch:  0024 D loss:-0.3862 G loss:-3.109\n",
      "Epoch:  0024 D loss:-0.4771 G loss:-2.821\n",
      "Epoch:  0024 D loss:-0.3146 G loss:-3.177\n",
      "Epoch:  0024 D loss:-0.3616 G loss:-2.939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0024 D loss:-0.3182 G loss:-2.937\n",
      "Epoch:  0024 D loss:-0.3482 G loss:-2.794\n",
      "Epoch:  0024 D loss:-0.402 G loss:-2.994\n",
      "Epoch:  0024 D loss:-0.4052 G loss:-2.755\n",
      "Epoch:  0024 D loss:-0.418 G loss:-2.666\n",
      "Epoch:  0024 D loss:-0.412 G loss:-2.677\n",
      "Epoch:  0024 D loss:-0.3815 G loss:-2.516\n",
      "Epoch:  0024 D loss:-0.4948 G loss:-2.547\n",
      "Epoch:  0024 D loss:-0.3957 G loss:-2.543\n",
      "Epoch:  0024 D loss:-0.353 G loss:-2.687\n",
      "Epoch:  0024 D loss:-0.3097 G loss:-2.782\n",
      "Epoch:  0024 D loss:-0.4623 G loss:-2.817\n",
      "Epoch:  0024 D loss:-0.408 G loss:-2.821\n",
      "Epoch:  0024 D loss:-0.2951 G loss:-3.15\n",
      "Epoch:  0024 D loss:-0.305 G loss:-2.996\n",
      "Epoch:  0024 D loss:-0.3585 G loss:-3.096\n",
      "Epoch:  0024 D loss:-0.3291 G loss:-2.91\n",
      "Epoch:  0024 D loss:-0.3529 G loss:-2.944\n",
      "Epoch:  0024 D loss:-0.37 G loss:-2.846\n",
      "Epoch:  0024 D loss:-0.3869 G loss:-2.953\n",
      "Epoch:  0024 D loss:-0.2697 G loss:-3.128\n",
      "Epoch:  0024 D loss:-0.4376 G loss:-2.955\n",
      "Epoch:  0024 D loss:-0.4287 G loss:-3.055\n",
      "Epoch:  0024 D loss:-0.3924 G loss:-2.667\n",
      "Epoch:  0024 D loss:-0.3956 G loss:-2.701\n",
      "Epoch:  0024 D loss:-0.3692 G loss:-2.65\n",
      "Epoch:  0024 D loss:-0.4746 G loss:-2.508\n",
      "Epoch:  0024 D loss:-0.3544 G loss:-2.674\n",
      "Epoch:  0024 D loss:-0.3906 G loss:-2.882\n",
      "Epoch:  0024 D loss:-0.354 G loss:-2.898\n",
      "Epoch:  0024 D loss:-0.3616 G loss:-2.812\n",
      "Epoch:  0024 D loss:-0.2956 G loss:-2.774\n",
      "Epoch:  0024 D loss:-0.3159 G loss:-3.0\n",
      "Epoch:  0024 D loss:-0.4178 G loss:-3.008\n",
      "Epoch:  0024 D loss:-0.2264 G loss:-3.25\n",
      "Epoch:  0024 D loss:-0.3405 G loss:-3.339\n",
      "Epoch:  0024 D loss:-0.3661 G loss:-3.032\n",
      "Epoch:  0024 D loss:-0.356 G loss:-3.191\n",
      "Epoch:  0024 D loss:-0.3981 G loss:-2.923\n",
      "Epoch:  0024 D loss:-0.3263 G loss:-2.976\n",
      "Epoch:  0024 D loss:-0.3169 G loss:-2.61\n",
      "Epoch:  0024 D loss:-0.4641 G loss:-2.744\n",
      "Epoch:  0024 D loss:-0.3894 G loss:-2.332\n",
      "Epoch:  0024 D loss:-0.2909 G loss:-2.517\n",
      "Epoch:  0024 D loss:-0.4333 G loss:-2.692\n",
      "Epoch:  0024 D loss:-0.3537 G loss:-2.683\n",
      "Epoch:  0024 D loss:-0.3945 G loss:-2.782\n",
      "Epoch:  0024 D loss:-0.4173 G loss:-3.007\n",
      "Epoch:  0024 D loss:-0.5163 G loss:-2.966\n",
      "Epoch:  0024 D loss:-0.4347 G loss:-2.685\n",
      "Epoch:  0024 D loss:-0.3296 G loss:-2.897\n",
      "Epoch:  0024 D loss:-0.3301 G loss:-3.211\n",
      "Epoch:  0024 D loss:-0.2953 G loss:-3.402\n",
      "Epoch:  0024 D loss:-0.2805 G loss:-3.129\n",
      "Epoch:  0024 D loss:-0.3547 G loss:-3.085\n",
      "Epoch:  0024 D loss:-0.3133 G loss:-2.974\n",
      "Epoch:  0024 D loss:-0.3484 G loss:-2.919\n",
      "Epoch:  0024 D loss:-0.2366 G loss:-3.103\n",
      "Epoch:  0024 D loss:-0.3323 G loss:-3.196\n",
      "Epoch:  0024 D loss:-0.4546 G loss:-2.834\n",
      "Epoch:  0024 D loss:-0.3211 G loss:-3.232\n",
      "Epoch:  0024 D loss:-0.2938 G loss:-3.04\n",
      "Epoch:  0024 D loss:-0.3293 G loss:-2.869\n",
      "Epoch:  0024 D loss:-0.3917 G loss:-3.083\n",
      "Epoch:  0024 D loss:-0.253 G loss:-3.044\n",
      "Epoch:  0024 D loss:-0.3336 G loss:-2.947\n",
      "Epoch:  0024 D loss:-0.4071 G loss:-2.626\n",
      "Epoch:  0024 D loss:-0.3636 G loss:-2.738\n",
      "Epoch:  0024 D loss:-0.3649 G loss:-2.666\n",
      "Epoch:  0024 D loss:-0.4227 G loss:-2.736\n",
      "Epoch:  0024 D loss:-0.3886 G loss:-2.588\n",
      "Epoch:  0024 D loss:-0.3448 G loss:-2.625\n",
      "Epoch:  0024 D loss:-0.354 G loss:-2.833\n",
      "Epoch:  0024 D loss:-0.3171 G loss:-2.883\n",
      "Epoch:  0024 D loss:-0.3561 G loss:-2.865\n",
      "Epoch:  0024 D loss:-0.4079 G loss:-2.733\n",
      "Epoch:  0024 D loss:-0.5437 G loss:-2.92\n",
      "Epoch:  0024 D loss:-0.3291 G loss:-2.929\n",
      "Epoch:  0024 D loss:-0.4199 G loss:-2.809\n",
      "Epoch:  0024 D loss:-0.3869 G loss:-2.861\n",
      "Epoch:  0024 D loss:-0.4877 G loss:-2.947\n",
      "Epoch:  0024 D loss:-0.494 G loss:-2.866\n",
      "Epoch:  0024 D loss:-0.4297 G loss:-2.876\n",
      "Epoch:  0024 D loss:-0.3331 G loss:-2.719\n",
      "Epoch:  0024 D loss:-0.4227 G loss:-2.435\n",
      "Epoch:  0025 D loss:-0.3731 G loss:-2.796\n",
      "Epoch:  0025 D loss:-0.3277 G loss:-2.578\n",
      "Epoch:  0025 D loss:-0.4073 G loss:-2.614\n",
      "Epoch:  0025 D loss:-0.3858 G loss:-2.647\n",
      "Epoch:  0025 D loss:-0.3431 G loss:-2.705\n",
      "Epoch:  0025 D loss:-0.4629 G loss:-2.684\n",
      "Epoch:  0025 D loss:-0.4594 G loss:-2.723\n",
      "Epoch:  0025 D loss:-0.3601 G loss:-3.059\n",
      "Epoch:  0025 D loss:-0.322 G loss:-2.765\n",
      "Epoch:  0025 D loss:-0.4575 G loss:-2.875\n",
      "Epoch:  0025 D loss:-0.531 G loss:-2.777\n",
      "Epoch:  0025 D loss:-0.5864 G loss:-2.581\n",
      "Epoch:  0025 D loss:-0.5445 G loss:-2.545\n",
      "Epoch:  0025 D loss:-0.4598 G loss:-2.691\n",
      "Epoch:  0025 D loss:-0.4336 G loss:-2.606\n",
      "Epoch:  0025 D loss:-0.5112 G loss:-2.376\n",
      "Epoch:  0025 D loss:-0.4702 G loss:-2.738\n",
      "Epoch:  0025 D loss:-0.4037 G loss:-2.525\n",
      "Epoch:  0025 D loss:-0.3995 G loss:-2.411\n",
      "Epoch:  0025 D loss:-0.3626 G loss:-2.689\n",
      "Epoch:  0025 D loss:-0.4623 G loss:-2.429\n",
      "Epoch:  0025 D loss:-0.4101 G loss:-2.786\n",
      "Epoch:  0025 D loss:-0.4008 G loss:-2.716\n",
      "Epoch:  0025 D loss:-0.4878 G loss:-2.731\n",
      "Epoch:  0025 D loss:-0.6027 G loss:-2.799\n",
      "Epoch:  0025 D loss:-0.442 G loss:-2.81\n",
      "Epoch:  0025 D loss:-0.4352 G loss:-2.598\n",
      "Epoch:  0025 D loss:-0.5109 G loss:-2.702\n",
      "Epoch:  0025 D loss:-0.3266 G loss:-2.846\n",
      "Epoch:  0025 D loss:-0.4554 G loss:-2.76\n",
      "Epoch:  0025 D loss:-0.3969 G loss:-2.664\n",
      "Epoch:  0025 D loss:-0.3663 G loss:-2.55\n",
      "Epoch:  0025 D loss:-0.6096 G loss:-2.578\n",
      "Epoch:  0025 D loss:-0.3479 G loss:-2.542\n",
      "Epoch:  0025 D loss:-0.4955 G loss:-2.6\n",
      "Epoch:  0025 D loss:-0.4155 G loss:-2.594\n",
      "Epoch:  0025 D loss:-0.5094 G loss:-2.54\n",
      "Epoch:  0025 D loss:-0.5211 G loss:-2.794\n",
      "Epoch:  0025 D loss:-0.5019 G loss:-2.703\n",
      "Epoch:  0025 D loss:-0.3389 G loss:-2.885\n",
      "Epoch:  0025 D loss:-0.4723 G loss:-2.817\n",
      "Epoch:  0025 D loss:-0.4917 G loss:-2.918\n",
      "Epoch:  0025 D loss:-0.4433 G loss:-2.67\n",
      "Epoch:  0025 D loss:-0.5213 G loss:-2.581\n",
      "Epoch:  0025 D loss:-0.5114 G loss:-2.533\n",
      "Epoch:  0025 D loss:-0.5394 G loss:-2.48\n",
      "Epoch:  0025 D loss:-0.4964 G loss:-2.618\n",
      "Epoch:  0025 D loss:-0.4384 G loss:-2.599\n",
      "Epoch:  0025 D loss:-0.3676 G loss:-2.525\n",
      "Epoch:  0025 D loss:-0.5305 G loss:-2.266\n",
      "Epoch:  0025 D loss:-0.4157 G loss:-2.669\n",
      "Epoch:  0025 D loss:-0.4868 G loss:-2.675\n",
      "Epoch:  0025 D loss:-0.3389 G loss:-2.858\n",
      "Epoch:  0025 D loss:-0.4739 G loss:-2.494\n",
      "Epoch:  0025 D loss:-0.4539 G loss:-2.596\n",
      "Epoch:  0025 D loss:-0.4205 G loss:-2.587\n",
      "Epoch:  0025 D loss:-0.509 G loss:-2.492\n",
      "Epoch:  0025 D loss:-0.4367 G loss:-2.757\n",
      "Epoch:  0025 D loss:-0.5814 G loss:-2.72\n",
      "Epoch:  0025 D loss:-0.4793 G loss:-2.923\n",
      "Epoch:  0025 D loss:-0.4481 G loss:-2.6\n",
      "Epoch:  0025 D loss:-0.5368 G loss:-2.529\n",
      "Epoch:  0025 D loss:-0.6075 G loss:-2.279\n",
      "Epoch:  0025 D loss:-0.4804 G loss:-2.567\n",
      "Epoch:  0025 D loss:-0.4439 G loss:-2.544\n",
      "Epoch:  0025 D loss:-0.4325 G loss:-2.439\n",
      "Epoch:  0025 D loss:-0.5208 G loss:-2.318\n",
      "Epoch:  0025 D loss:-0.5188 G loss:-2.357\n",
      "Epoch:  0025 D loss:-0.5113 G loss:-2.337\n",
      "Epoch:  0025 D loss:-0.4697 G loss:-2.483\n",
      "Epoch:  0025 D loss:-0.5115 G loss:-2.901\n",
      "Epoch:  0025 D loss:-0.4877 G loss:-2.651\n",
      "Epoch:  0025 D loss:-0.5287 G loss:-2.377\n",
      "Epoch:  0025 D loss:-0.3967 G loss:-2.887\n",
      "Epoch:  0025 D loss:-0.4773 G loss:-2.783\n",
      "Epoch:  0025 D loss:-0.5044 G loss:-2.726\n",
      "Epoch:  0025 D loss:-0.5118 G loss:-2.602\n",
      "Epoch:  0025 D loss:-0.4005 G loss:-2.661\n",
      "Epoch:  0025 D loss:-0.4981 G loss:-2.353\n",
      "Epoch:  0025 D loss:-0.4561 G loss:-2.487\n",
      "Epoch:  0025 D loss:-0.5949 G loss:-2.278\n",
      "Epoch:  0025 D loss:-0.5146 G loss:-2.502\n",
      "Epoch:  0025 D loss:-0.5133 G loss:-2.453\n",
      "Epoch:  0025 D loss:-0.4171 G loss:-2.448\n",
      "Epoch:  0025 D loss:-0.4744 G loss:-2.596\n",
      "Epoch:  0025 D loss:-0.4529 G loss:-2.541\n",
      "Epoch:  0025 D loss:-0.4704 G loss:-2.435\n",
      "Epoch:  0025 D loss:-0.5913 G loss:-2.473\n",
      "Epoch:  0025 D loss:-0.3804 G loss:-2.718\n",
      "Epoch:  0025 D loss:-0.5719 G loss:-2.522\n",
      "Epoch:  0025 D loss:-0.4772 G loss:-2.599\n",
      "Epoch:  0025 D loss:-0.4728 G loss:-2.76\n",
      "Epoch:  0025 D loss:-0.5401 G loss:-2.634\n",
      "Epoch:  0025 D loss:-0.396 G loss:-2.611\n",
      "Epoch:  0025 D loss:-0.4584 G loss:-2.384\n",
      "Epoch:  0025 D loss:-0.5628 G loss:-2.432\n",
      "Epoch:  0025 D loss:-0.4605 G loss:-2.358\n",
      "Epoch:  0025 D loss:-0.5642 G loss:-2.351\n",
      "Epoch:  0025 D loss:-0.4084 G loss:-2.279\n",
      "Epoch:  0025 D loss:-0.5428 G loss:-2.236\n",
      "Epoch:  0025 D loss:-0.4592 G loss:-2.398\n",
      "Epoch:  0025 D loss:-0.4592 G loss:-2.368\n",
      "Epoch:  0025 D loss:-0.5423 G loss:-2.438\n",
      "Epoch:  0025 D loss:-0.527 G loss:-2.417\n",
      "Epoch:  0025 D loss:-0.4179 G loss:-2.776\n",
      "Epoch:  0025 D loss:-0.5837 G loss:-2.733\n",
      "Epoch:  0025 D loss:-0.4808 G loss:-3.016\n",
      "Epoch:  0025 D loss:-0.4797 G loss:-2.618\n",
      "Epoch:  0025 D loss:-0.3783 G loss:-2.91\n",
      "Epoch:  0025 D loss:-0.4875 G loss:-2.889\n",
      "Epoch:  0025 D loss:-0.433 G loss:-2.66\n",
      "Epoch:  0025 D loss:-0.4596 G loss:-2.537\n",
      "Epoch:  0025 D loss:-0.4704 G loss:-2.351\n",
      "Epoch:  0025 D loss:-0.6328 G loss:-2.217\n",
      "Epoch:  0025 D loss:-0.5764 G loss:-2.057\n",
      "Epoch:  0025 D loss:-0.5261 G loss:-2.329\n",
      "Epoch:  0025 D loss:-0.502 G loss:-2.712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0025 D loss:-0.5333 G loss:-2.313\n",
      "Epoch:  0025 D loss:-0.5042 G loss:-2.592\n",
      "Epoch:  0025 D loss:-0.4201 G loss:-2.492\n",
      "Epoch:  0025 D loss:-0.6334 G loss:-2.28\n",
      "Epoch:  0025 D loss:-0.4821 G loss:-2.443\n",
      "Epoch:  0025 D loss:-0.5807 G loss:-2.555\n",
      "Epoch:  0025 D loss:-0.4476 G loss:-2.695\n",
      "Epoch:  0025 D loss:-0.4605 G loss:-2.78\n",
      "Epoch:  0025 D loss:-0.5399 G loss:-2.724\n",
      "Epoch:  0025 D loss:-0.4824 G loss:-2.702\n",
      "Epoch:  0025 D loss:-0.4584 G loss:-2.358\n",
      "Epoch:  0025 D loss:-0.4509 G loss:-2.549\n",
      "Epoch:  0025 D loss:-0.4619 G loss:-2.616\n",
      "Epoch:  0025 D loss:-0.5747 G loss:-2.69\n",
      "Epoch:  0025 D loss:-0.5848 G loss:-2.561\n",
      "Epoch:  0025 D loss:-0.5773 G loss:-2.642\n",
      "Epoch:  0025 D loss:-0.4981 G loss:-2.421\n",
      "Epoch:  0025 D loss:-0.4931 G loss:-2.552\n",
      "Epoch:  0025 D loss:-0.4686 G loss:-2.583\n",
      "Epoch:  0025 D loss:-0.4388 G loss:-2.731\n",
      "Epoch:  0025 D loss:-0.4151 G loss:-2.603\n",
      "Epoch:  0025 D loss:-0.3877 G loss:-2.71\n",
      "Epoch:  0025 D loss:-0.3658 G loss:-2.831\n",
      "Epoch:  0025 D loss:-0.3701 G loss:-2.919\n",
      "Epoch:  0025 D loss:-0.3088 G loss:-2.801\n",
      "Epoch:  0025 D loss:-0.3984 G loss:-2.882\n",
      "Epoch:  0025 D loss:-0.4645 G loss:-2.853\n",
      "Epoch:  0025 D loss:-0.3012 G loss:-2.894\n",
      "Epoch:  0025 D loss:-0.333 G loss:-2.804\n",
      "Epoch:  0025 D loss:-0.4992 G loss:-2.689\n",
      "Epoch:  0025 D loss:-0.4948 G loss:-2.701\n",
      "Epoch:  0025 D loss:-0.3898 G loss:-2.799\n",
      "Epoch:  0025 D loss:-0.4523 G loss:-2.676\n",
      "Epoch:  0025 D loss:-0.3715 G loss:-2.734\n",
      "Epoch:  0025 D loss:-0.2741 G loss:-2.781\n",
      "Epoch:  0025 D loss:-0.3558 G loss:-2.744\n",
      "Epoch:  0025 D loss:-0.4001 G loss:-2.936\n",
      "Epoch:  0025 D loss:-0.3029 G loss:-2.961\n",
      "Epoch:  0025 D loss:-0.4061 G loss:-3.19\n",
      "Epoch:  0025 D loss:-0.2637 G loss:-3.046\n",
      "Epoch:  0025 D loss:-0.3272 G loss:-2.937\n",
      "Epoch:  0025 D loss:-0.4158 G loss:-2.779\n",
      "Epoch:  0025 D loss:-0.2725 G loss:-2.784\n",
      "Epoch:  0025 D loss:-0.3359 G loss:-2.914\n",
      "Epoch:  0025 D loss:-0.3046 G loss:-3.191\n",
      "Epoch:  0025 D loss:-0.3295 G loss:-3.128\n",
      "Epoch:  0025 D loss:-0.311 G loss:-3.139\n",
      "Epoch:  0025 D loss:-0.4064 G loss:-2.779\n",
      "Epoch:  0025 D loss:-0.3669 G loss:-2.985\n",
      "Epoch:  0025 D loss:-0.3754 G loss:-2.918\n",
      "Epoch:  0025 D loss:-0.387 G loss:-2.795\n",
      "Epoch:  0025 D loss:-0.3783 G loss:-2.695\n",
      "Epoch:  0025 D loss:-0.3687 G loss:-2.867\n",
      "Epoch:  0025 D loss:-0.3675 G loss:-2.774\n",
      "Epoch:  0025 D loss:-0.4256 G loss:-3.006\n",
      "Epoch:  0025 D loss:-0.3504 G loss:-2.755\n",
      "Epoch:  0025 D loss:-0.3581 G loss:-2.8\n",
      "Epoch:  0025 D loss:-0.3761 G loss:-2.973\n",
      "Epoch:  0025 D loss:-0.3148 G loss:-3.271\n",
      "Epoch:  0025 D loss:-0.2713 G loss:-3.038\n",
      "Epoch:  0025 D loss:-0.2989 G loss:-2.976\n",
      "Epoch:  0025 D loss:-0.6026 G loss:-2.713\n",
      "Epoch:  0025 D loss:-0.3745 G loss:-3.139\n",
      "Epoch:  0025 D loss:-0.4164 G loss:-2.914\n",
      "Epoch:  0025 D loss:-0.4193 G loss:-3.085\n",
      "Epoch:  0025 D loss:-0.3774 G loss:-2.838\n",
      "Epoch:  0025 D loss:-0.3378 G loss:-2.746\n",
      "Epoch:  0025 D loss:-0.3196 G loss:-2.8\n",
      "Epoch:  0025 D loss:-0.3615 G loss:-3.083\n",
      "Epoch:  0025 D loss:-0.4456 G loss:-2.761\n",
      "Epoch:  0025 D loss:-0.4321 G loss:-2.681\n",
      "Epoch:  0025 D loss:-0.3853 G loss:-2.982\n",
      "Epoch:  0025 D loss:-0.4322 G loss:-2.67\n",
      "Epoch:  0025 D loss:-0.387 G loss:-2.805\n",
      "Epoch:  0025 D loss:-0.3948 G loss:-2.808\n",
      "Epoch:  0025 D loss:-0.424 G loss:-2.741\n",
      "Epoch:  0025 D loss:-0.4223 G loss:-2.743\n",
      "Epoch:  0025 D loss:-0.34 G loss:-2.855\n",
      "Epoch:  0025 D loss:-0.356 G loss:-2.709\n",
      "Epoch:  0025 D loss:-0.4416 G loss:-2.804\n",
      "Epoch:  0025 D loss:-0.296 G loss:-2.969\n",
      "Epoch:  0025 D loss:-0.325 G loss:-2.99\n",
      "Epoch:  0025 D loss:-0.2788 G loss:-2.896\n",
      "Epoch:  0025 D loss:-0.3237 G loss:-3.04\n",
      "Epoch:  0025 D loss:-0.3182 G loss:-2.872\n",
      "Epoch:  0025 D loss:-0.3286 G loss:-2.966\n",
      "Epoch:  0025 D loss:-0.4099 G loss:-2.851\n",
      "Epoch:  0025 D loss:-0.3832 G loss:-3.004\n",
      "Epoch:  0025 D loss:-0.3793 G loss:-2.873\n",
      "Epoch:  0025 D loss:-0.4219 G loss:-2.913\n",
      "Epoch:  0025 D loss:-0.4053 G loss:-2.523\n",
      "Epoch:  0025 D loss:-0.35 G loss:-2.424\n",
      "Epoch:  0025 D loss:-0.453 G loss:-2.63\n",
      "Epoch:  0025 D loss:-0.3585 G loss:-2.621\n",
      "Epoch:  0025 D loss:-0.4805 G loss:-2.543\n",
      "Epoch:  0025 D loss:-0.4659 G loss:-2.544\n",
      "Epoch:  0025 D loss:-0.4258 G loss:-2.657\n",
      "Epoch:  0025 D loss:-0.5192 G loss:-2.489\n",
      "Epoch:  0025 D loss:-0.3265 G loss:-2.723\n",
      "Epoch:  0025 D loss:-0.3381 G loss:-2.865\n",
      "Epoch:  0025 D loss:-0.3811 G loss:-2.845\n",
      "Epoch:  0025 D loss:-0.3103 G loss:-3.15\n",
      "Epoch:  0025 D loss:-0.3607 G loss:-3.104\n",
      "Epoch:  0025 D loss:-0.3564 G loss:-3.359\n",
      "Epoch:  0025 D loss:-0.2645 G loss:-3.198\n",
      "Epoch:  0025 D loss:-0.5074 G loss:-3.18\n",
      "Epoch:  0025 D loss:-0.346 G loss:-3.01\n",
      "Epoch:  0025 D loss:-0.4279 G loss:-2.729\n",
      "Epoch:  0025 D loss:-0.3494 G loss:-2.795\n",
      "Epoch:  0025 D loss:-0.4398 G loss:-3.045\n",
      "Epoch:  0025 D loss:-0.4353 G loss:-2.58\n",
      "Epoch:  0025 D loss:-0.4389 G loss:-2.617\n",
      "Epoch:  0025 D loss:-0.546 G loss:-2.462\n",
      "Epoch:  0025 D loss:-0.3753 G loss:-2.587\n",
      "Epoch:  0025 D loss:-0.4053 G loss:-2.476\n",
      "Epoch:  0025 D loss:-0.4215 G loss:-2.601\n",
      "Epoch:  0025 D loss:-0.3718 G loss:-2.519\n",
      "Epoch:  0025 D loss:-0.511 G loss:-2.725\n",
      "Epoch:  0025 D loss:-0.3935 G loss:-2.778\n",
      "Epoch:  0025 D loss:-0.3646 G loss:-2.937\n",
      "Epoch:  0025 D loss:-0.3593 G loss:-3.015\n",
      "Epoch:  0025 D loss:-0.3864 G loss:-2.939\n",
      "Epoch:  0025 D loss:-0.4137 G loss:-2.885\n",
      "Epoch:  0025 D loss:-0.3251 G loss:-3.123\n",
      "Epoch:  0025 D loss:-0.3832 G loss:-2.77\n",
      "Epoch:  0025 D loss:-0.3774 G loss:-2.944\n",
      "Epoch:  0025 D loss:-0.3753 G loss:-2.692\n",
      "Epoch:  0025 D loss:-0.325 G loss:-2.825\n",
      "Epoch:  0025 D loss:-0.3506 G loss:-2.807\n",
      "Epoch:  0025 D loss:-0.3586 G loss:-2.614\n",
      "Epoch:  0025 D loss:-0.3864 G loss:-2.625\n",
      "Epoch:  0025 D loss:-0.3606 G loss:-2.625\n",
      "Epoch:  0025 D loss:-0.448 G loss:-2.644\n",
      "Epoch:  0025 D loss:-0.4776 G loss:-2.758\n",
      "Epoch:  0025 D loss:-0.4918 G loss:-2.725\n",
      "Epoch:  0025 D loss:-0.2718 G loss:-2.961\n",
      "Epoch:  0025 D loss:-0.3468 G loss:-2.875\n",
      "Epoch:  0025 D loss:-0.328 G loss:-2.762\n",
      "Epoch:  0025 D loss:-0.4077 G loss:-2.846\n",
      "Epoch:  0025 D loss:-0.3543 G loss:-3.034\n",
      "Epoch:  0025 D loss:-0.3323 G loss:-2.931\n",
      "Epoch:  0025 D loss:-0.4104 G loss:-2.947\n",
      "Epoch:  0025 D loss:-0.3687 G loss:-2.703\n",
      "Epoch:  0025 D loss:-0.3744 G loss:-2.626\n",
      "Epoch:  0025 D loss:-0.3206 G loss:-2.657\n",
      "Epoch:  0025 D loss:-0.4863 G loss:-2.499\n",
      "Epoch:  0025 D loss:-0.3809 G loss:-2.646\n",
      "Epoch:  0025 D loss:-0.412 G loss:-2.608\n",
      "Epoch:  0025 D loss:-0.3288 G loss:-2.76\n",
      "Epoch:  0025 D loss:-0.4535 G loss:-2.897\n",
      "Epoch:  0025 D loss:-0.3352 G loss:-2.974\n",
      "Epoch:  0025 D loss:-0.2849 G loss:-2.919\n",
      "Epoch:  0025 D loss:-0.4246 G loss:-3.108\n",
      "Epoch:  0025 D loss:-0.4225 G loss:-2.965\n",
      "Epoch:  0025 D loss:-0.3655 G loss:-2.764\n",
      "Epoch:  0025 D loss:-0.3486 G loss:-2.741\n",
      "Epoch:  0025 D loss:-0.4293 G loss:-2.917\n",
      "Epoch:  0025 D loss:-0.3838 G loss:-2.75\n",
      "Epoch:  0025 D loss:-0.3645 G loss:-2.765\n",
      "Epoch:  0025 D loss:-0.484 G loss:-2.59\n",
      "Epoch:  0025 D loss:-0.4989 G loss:-2.658\n",
      "Epoch:  0025 D loss:-0.4043 G loss:-2.592\n",
      "Epoch:  0025 D loss:-0.3243 G loss:-2.559\n",
      "Epoch:  0025 D loss:-0.4224 G loss:-2.442\n",
      "Epoch:  0025 D loss:-0.3708 G loss:-2.646\n",
      "Epoch:  0025 D loss:-0.3528 G loss:-2.862\n",
      "Epoch:  0025 D loss:-0.335 G loss:-2.862\n",
      "Epoch:  0025 D loss:-0.394 G loss:-2.783\n",
      "Epoch:  0025 D loss:-0.3909 G loss:-3.01\n",
      "Epoch:  0025 D loss:-0.4399 G loss:-3.327\n",
      "Epoch:  0025 D loss:-0.3295 G loss:-3.064\n",
      "Epoch:  0025 D loss:-0.4114 G loss:-3.0\n",
      "Epoch:  0025 D loss:-0.3669 G loss:-2.746\n",
      "Epoch:  0025 D loss:-0.3573 G loss:-2.658\n",
      "Epoch:  0025 D loss:-0.3532 G loss:-2.474\n",
      "Epoch:  0025 D loss:-0.4307 G loss:-2.402\n",
      "Epoch:  0025 D loss:-0.2734 G loss:-2.698\n",
      "Epoch:  0025 D loss:-0.4051 G loss:-2.633\n",
      "Epoch:  0025 D loss:-0.4361 G loss:-2.5\n",
      "Epoch:  0025 D loss:-0.4241 G loss:-2.726\n",
      "Epoch:  0025 D loss:-0.2993 G loss:-2.787\n",
      "Epoch:  0025 D loss:-0.4657 G loss:-2.911\n",
      "Epoch:  0025 D loss:-0.4016 G loss:-2.58\n",
      "Epoch:  0025 D loss:-0.4913 G loss:-2.818\n",
      "Epoch:  0025 D loss:-0.4431 G loss:-2.699\n",
      "Epoch:  0025 D loss:-0.4729 G loss:-2.827\n",
      "Epoch:  0025 D loss:-0.4081 G loss:-2.737\n",
      "Epoch:  0025 D loss:-0.5204 G loss:-2.742\n",
      "Epoch:  0025 D loss:-0.4232 G loss:-2.8\n",
      "Epoch:  0025 D loss:-0.4907 G loss:-2.515\n",
      "Epoch:  0025 D loss:-0.453 G loss:-2.698\n",
      "Epoch:  0025 D loss:-0.3959 G loss:-2.535\n",
      "Epoch:  0025 D loss:-0.4104 G loss:-2.744\n",
      "Epoch:  0025 D loss:-0.4684 G loss:-2.471\n",
      "Epoch:  0025 D loss:-0.4137 G loss:-2.735\n",
      "Epoch:  0025 D loss:-0.3964 G loss:-2.678\n",
      "Epoch:  0025 D loss:-0.3693 G loss:-2.737\n",
      "Epoch:  0025 D loss:-0.412 G loss:-2.965\n",
      "Epoch:  0025 D loss:-0.3935 G loss:-3.216\n",
      "Epoch:  0025 D loss:-0.3303 G loss:-3.298\n",
      "Epoch:  0025 D loss:-0.3772 G loss:-2.874\n",
      "Epoch:  0025 D loss:-0.3317 G loss:-2.994\n",
      "Epoch:  0025 D loss:-0.3243 G loss:-3.089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0025 D loss:-0.4028 G loss:-3.021\n",
      "Epoch:  0025 D loss:-0.4933 G loss:-2.601\n",
      "Epoch:  0025 D loss:-0.5076 G loss:-2.503\n",
      "Epoch:  0025 D loss:-0.4348 G loss:-2.487\n",
      "Epoch:  0025 D loss:-0.447 G loss:-2.352\n",
      "Epoch:  0025 D loss:-0.3763 G loss:-2.708\n",
      "Epoch:  0025 D loss:-0.4477 G loss:-2.464\n",
      "Epoch:  0025 D loss:-0.7076 G loss:-2.259\n",
      "Epoch:  0025 D loss:-0.3134 G loss:-2.74\n",
      "Epoch:  0025 D loss:-0.4069 G loss:-2.788\n",
      "Epoch:  0025 D loss:-0.4109 G loss:-3.001\n",
      "Epoch:  0025 D loss:-0.367 G loss:-2.763\n",
      "Epoch:  0025 D loss:-0.431 G loss:-2.861\n",
      "Epoch:  0025 D loss:-0.3252 G loss:-2.929\n",
      "Epoch:  0025 D loss:-0.2883 G loss:-3.09\n",
      "Epoch:  0025 D loss:-0.5097 G loss:-2.719\n",
      "Epoch:  0025 D loss:-0.4401 G loss:-2.971\n",
      "Epoch:  0025 D loss:-0.4338 G loss:-2.747\n",
      "Epoch:  0025 D loss:-0.3933 G loss:-3.13\n",
      "Epoch:  0025 D loss:-0.4615 G loss:-2.975\n",
      "Epoch:  0025 D loss:-0.3141 G loss:-2.571\n",
      "Epoch:  0025 D loss:-0.5566 G loss:-2.587\n",
      "Epoch:  0025 D loss:-0.341 G loss:-2.894\n",
      "Epoch:  0025 D loss:-0.4644 G loss:-2.47\n",
      "Epoch:  0025 D loss:-0.3801 G loss:-2.887\n",
      "Epoch:  0025 D loss:-0.3352 G loss:-2.542\n",
      "Epoch:  0025 D loss:-0.4972 G loss:-2.575\n",
      "Epoch:  0025 D loss:-0.5046 G loss:-2.998\n",
      "Epoch:  0025 D loss:-0.3971 G loss:-2.96\n",
      "Epoch:  0025 D loss:-0.3331 G loss:-3.047\n",
      "Epoch:  0025 D loss:-0.4398 G loss:-2.837\n",
      "Epoch:  0025 D loss:-0.322 G loss:-3.074\n",
      "Epoch:  0025 D loss:-0.3928 G loss:-2.859\n",
      "Epoch:  0025 D loss:-0.3829 G loss:-2.633\n",
      "Epoch:  0025 D loss:-0.2987 G loss:-2.921\n",
      "Epoch:  0025 D loss:-0.3511 G loss:-3.05\n",
      "Epoch:  0025 D loss:-0.3852 G loss:-2.964\n",
      "Epoch:  0025 D loss:-0.4366 G loss:-2.923\n",
      "Epoch:  0025 D loss:-0.3099 G loss:-3.019\n",
      "Epoch:  0025 D loss:-0.3382 G loss:-2.859\n",
      "Epoch:  0025 D loss:-0.3322 G loss:-2.844\n",
      "Epoch:  0025 D loss:-0.3752 G loss:-2.723\n",
      "Epoch:  0025 D loss:-0.3665 G loss:-2.823\n",
      "Epoch:  0025 D loss:-0.3979 G loss:-2.845\n",
      "Epoch:  0025 D loss:-0.3298 G loss:-2.805\n",
      "Epoch:  0025 D loss:-0.3232 G loss:-2.783\n",
      "Epoch:  0025 D loss:-0.3356 G loss:-2.859\n",
      "Epoch:  0025 D loss:-0.3625 G loss:-2.729\n",
      "Epoch:  0025 D loss:-0.3054 G loss:-3.007\n",
      "Epoch:  0025 D loss:-0.4743 G loss:-2.76\n",
      "Epoch:  0025 D loss:-0.3485 G loss:-3.204\n",
      "Epoch:  0025 D loss:-0.3659 G loss:-3.139\n",
      "Epoch:  0025 D loss:-0.4053 G loss:-2.987\n",
      "Epoch:  0025 D loss:-0.2691 G loss:-2.978\n",
      "Epoch:  0025 D loss:-0.2805 G loss:-3.007\n",
      "Epoch:  0025 D loss:-0.3573 G loss:-2.872\n",
      "Epoch:  0025 D loss:-0.3657 G loss:-3.044\n",
      "Epoch:  0025 D loss:-0.3022 G loss:-2.979\n",
      "Epoch:  0025 D loss:-0.3374 G loss:-3.006\n",
      "Epoch:  0025 D loss:-0.3982 G loss:-2.985\n",
      "Epoch:  0025 D loss:-0.3116 G loss:-2.951\n",
      "Epoch:  0025 D loss:-0.3394 G loss:-2.941\n",
      "Epoch:  0025 D loss:-0.3202 G loss:-3.038\n",
      "Epoch:  0025 D loss:-0.3307 G loss:-2.809\n",
      "Epoch:  0025 D loss:-0.3039 G loss:-2.996\n",
      "Epoch:  0025 D loss:-0.289 G loss:-2.953\n",
      "Epoch:  0025 D loss:-0.3758 G loss:-2.837\n",
      "Epoch:  0025 D loss:-0.2967 G loss:-2.727\n",
      "Epoch:  0025 D loss:-0.2619 G loss:-2.794\n",
      "Epoch:  0025 D loss:-0.3266 G loss:-2.902\n",
      "Epoch:  0025 D loss:-0.31 G loss:-3.036\n",
      "Epoch:  0025 D loss:-0.2695 G loss:-3.109\n",
      "Epoch:  0025 D loss:-0.3658 G loss:-3.23\n",
      "Epoch:  0025 D loss:-0.2683 G loss:-3.368\n",
      "Epoch:  0025 D loss:-0.3127 G loss:-3.183\n",
      "Epoch:  0025 D loss:-0.4718 G loss:-2.801\n",
      "Epoch:  0025 D loss:-0.3503 G loss:-2.889\n",
      "Epoch:  0025 D loss:-0.3998 G loss:-2.548\n",
      "Epoch:  0025 D loss:-0.3812 G loss:-2.856\n",
      "Epoch:  0025 D loss:-0.375 G loss:-2.821\n",
      "Epoch:  0025 D loss:-0.3515 G loss:-2.99\n",
      "Epoch:  0025 D loss:-0.3876 G loss:-2.899\n",
      "Epoch:  0025 D loss:-0.3802 G loss:-2.757\n",
      "Epoch:  0025 D loss:-0.3568 G loss:-3.009\n",
      "Epoch:  0025 D loss:-0.2985 G loss:-2.924\n",
      "Epoch:  0025 D loss:-0.3757 G loss:-2.965\n",
      "Epoch:  0025 D loss:-0.3305 G loss:-3.055\n",
      "Epoch:  0025 D loss:-0.3374 G loss:-3.127\n",
      "Epoch:  0025 D loss:-0.4552 G loss:-2.745\n",
      "Epoch:  0025 D loss:-0.2896 G loss:-3.231\n",
      "Epoch:  0025 D loss:-0.3527 G loss:-3.044\n",
      "Epoch:  0025 D loss:-0.2931 G loss:-3.004\n",
      "Epoch:  0025 D loss:-0.2734 G loss:-2.849\n",
      "Epoch:  0025 D loss:-0.302 G loss:-3.072\n",
      "Epoch:  0025 D loss:-0.3962 G loss:-2.959\n",
      "Epoch:  0025 D loss:-0.3675 G loss:-2.825\n",
      "Epoch:  0025 D loss:-0.3586 G loss:-3.147\n",
      "Epoch:  0025 D loss:-0.3547 G loss:-2.966\n",
      "Epoch:  0025 D loss:-0.4199 G loss:-2.799\n",
      "Epoch:  0025 D loss:-0.389 G loss:-3.022\n",
      "Epoch:  0025 D loss:-0.4155 G loss:-2.656\n",
      "Epoch:  0025 D loss:-0.3042 G loss:-2.669\n",
      "Epoch:  0025 D loss:-0.3881 G loss:-2.61\n",
      "Epoch:  0025 D loss:-0.407 G loss:-2.716\n",
      "Epoch:  0025 D loss:-0.4116 G loss:-2.735\n",
      "Epoch:  0025 D loss:-0.312 G loss:-2.804\n",
      "Epoch:  0025 D loss:-0.3234 G loss:-2.992\n",
      "Epoch:  0025 D loss:-0.412 G loss:-3.067\n",
      "Epoch:  0025 D loss:-0.3403 G loss:-3.107\n",
      "Epoch:  0025 D loss:-0.3109 G loss:-3.065\n",
      "Epoch:  0025 D loss:-0.2883 G loss:-3.083\n",
      "Epoch:  0025 D loss:-0.3619 G loss:-2.864\n",
      "Epoch:  0025 D loss:-0.3671 G loss:-3.187\n",
      "Epoch:  0025 D loss:-0.3036 G loss:-3.1\n",
      "Epoch:  0025 D loss:-0.4796 G loss:-3.043\n",
      "Epoch:  0025 D loss:-0.4247 G loss:-2.998\n",
      "Epoch:  0025 D loss:-0.3616 G loss:-2.956\n",
      "Epoch:  0025 D loss:-0.2956 G loss:-2.867\n",
      "Epoch:  0025 D loss:-0.3712 G loss:-2.772\n",
      "Epoch:  0025 D loss:-0.378 G loss:-2.63\n",
      "Epoch:  0025 D loss:-0.3744 G loss:-2.643\n",
      "Epoch:  0025 D loss:-0.386 G loss:-2.592\n",
      "Epoch:  0025 D loss:-0.3775 G loss:-2.588\n",
      "Epoch:  0025 D loss:-0.3277 G loss:-2.9\n",
      "Epoch:  0025 D loss:-0.3709 G loss:-2.958\n",
      "Epoch:  0025 D loss:-0.4523 G loss:-2.983\n",
      "Epoch:  0025 D loss:-0.4259 G loss:-3.06\n",
      "Epoch:  0025 D loss:-0.3176 G loss:-3.134\n",
      "Epoch:  0025 D loss:-0.3677 G loss:-2.795\n",
      "Epoch:  0025 D loss:-0.3923 G loss:-2.861\n",
      "Epoch:  0025 D loss:-0.4672 G loss:-2.835\n",
      "Epoch:  0025 D loss:-0.2795 G loss:-3.036\n",
      "Epoch:  0025 D loss:-0.3406 G loss:-2.877\n",
      "Epoch:  0025 D loss:-0.3541 G loss:-2.838\n",
      "Epoch:  0025 D loss:-0.3207 G loss:-2.838\n",
      "Epoch:  0025 D loss:-0.4174 G loss:-2.926\n",
      "Epoch:  0025 D loss:-0.3566 G loss:-2.805\n",
      "Epoch:  0025 D loss:-0.3676 G loss:-2.788\n",
      "Epoch:  0025 D loss:-0.4638 G loss:-2.979\n",
      "Epoch:  0025 D loss:-0.3537 G loss:-2.8\n",
      "Epoch:  0025 D loss:-0.3765 G loss:-2.823\n",
      "Epoch:  0025 D loss:-0.4586 G loss:-2.739\n",
      "Epoch:  0025 D loss:-0.4263 G loss:-2.575\n",
      "Epoch:  0025 D loss:-0.3308 G loss:-2.672\n",
      "Epoch:  0025 D loss:-0.3856 G loss:-2.476\n",
      "Epoch:  0025 D loss:-0.3956 G loss:-2.746\n",
      "Epoch:  0025 D loss:-0.4177 G loss:-2.737\n",
      "Epoch:  0025 D loss:-0.4213 G loss:-2.941\n",
      "Epoch:  0025 D loss:-0.3942 G loss:-2.925\n",
      "Epoch:  0025 D loss:-0.3542 G loss:-2.853\n",
      "Epoch:  0025 D loss:-0.2925 G loss:-2.986\n",
      "Epoch:  0025 D loss:-0.3483 G loss:-3.227\n",
      "Epoch:  0025 D loss:-0.3721 G loss:-3.075\n",
      "Epoch:  0025 D loss:-0.375 G loss:-2.865\n",
      "Epoch:  0025 D loss:-0.3379 G loss:-2.936\n",
      "Epoch:  0025 D loss:-0.3179 G loss:-3.091\n",
      "Epoch:  0025 D loss:-0.407 G loss:-2.873\n",
      "Epoch:  0025 D loss:-0.3604 G loss:-3.181\n",
      "Epoch:  0025 D loss:-0.297 G loss:-3.054\n",
      "Epoch:  0025 D loss:-0.366 G loss:-2.828\n",
      "Epoch:  0025 D loss:-0.2885 G loss:-2.889\n",
      "Epoch:  0025 D loss:-0.4451 G loss:-2.831\n",
      "Epoch:  0025 D loss:-0.3647 G loss:-2.519\n",
      "Epoch:  0025 D loss:-0.3381 G loss:-2.614\n",
      "Epoch:  0025 D loss:-0.3347 G loss:-2.674\n",
      "Epoch:  0025 D loss:-0.3216 G loss:-2.707\n",
      "Epoch:  0025 D loss:-0.4635 G loss:-2.603\n",
      "Epoch:  0025 D loss:-0.4074 G loss:-2.29\n",
      "Epoch:  0025 D loss:-0.3289 G loss:-2.685\n",
      "Epoch:  0025 D loss:-0.3733 G loss:-2.751\n",
      "Epoch:  0025 D loss:-0.5234 G loss:-2.59\n",
      "Epoch:  0025 D loss:-0.4062 G loss:-2.863\n",
      "Epoch:  0025 D loss:-0.4177 G loss:-2.879\n",
      "Epoch:  0025 D loss:-0.3712 G loss:-2.832\n",
      "Epoch:  0025 D loss:-0.3629 G loss:-2.997\n",
      "Epoch:  0025 D loss:-0.3814 G loss:-3.016\n",
      "Epoch:  0025 D loss:-0.3074 G loss:-3.036\n",
      "Epoch:  0025 D loss:-0.3198 G loss:-3.024\n",
      "Epoch:  0025 D loss:-0.4264 G loss:-2.801\n",
      "Epoch:  0025 D loss:-0.3824 G loss:-2.819\n",
      "Epoch:  0025 D loss:-0.3505 G loss:-2.731\n",
      "Epoch:  0025 D loss:-0.3423 G loss:-2.794\n",
      "Epoch:  0025 D loss:-0.419 G loss:-2.639\n",
      "Epoch:  0025 D loss:-0.2951 G loss:-2.675\n",
      "Epoch:  0025 D loss:-0.4225 G loss:-2.907\n",
      "Epoch:  0025 D loss:-0.3758 G loss:-2.813\n",
      "Epoch:  0025 D loss:-0.4209 G loss:-2.853\n",
      "Epoch:  0025 D loss:-0.4697 G loss:-2.692\n",
      "Epoch:  0025 D loss:-0.4111 G loss:-2.697\n",
      "Epoch:  0025 D loss:-0.454 G loss:-2.542\n",
      "Epoch:  0025 D loss:-0.4345 G loss:-2.604\n",
      "Epoch:  0025 D loss:-0.4412 G loss:-2.672\n",
      "Epoch:  0025 D loss:-0.4334 G loss:-2.971\n",
      "Epoch:  0025 D loss:-0.4108 G loss:-2.82\n",
      "Epoch:  0025 D loss:-0.3665 G loss:-2.758\n",
      "Epoch:  0025 D loss:-0.3424 G loss:-2.878\n",
      "Epoch:  0025 D loss:-0.4555 G loss:-2.812\n",
      "Epoch:  0025 D loss:-0.3053 G loss:-2.697\n",
      "Epoch:  0025 D loss:-0.6088 G loss:-2.684\n",
      "Epoch:  0025 D loss:-0.2522 G loss:-2.983\n",
      "Epoch:  0025 D loss:-0.5038 G loss:-2.542\n",
      "Epoch:  0025 D loss:-0.3831 G loss:-2.632\n",
      "Epoch:  0025 D loss:-0.4573 G loss:-2.655\n",
      "Epoch:  0025 D loss:-0.4046 G loss:-2.764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0025 D loss:-0.5213 G loss:-2.615\n",
      "Epoch:  0025 D loss:-0.421 G loss:-2.663\n",
      "Epoch:  0025 D loss:-0.3971 G loss:-2.474\n",
      "Epoch:  0025 D loss:-0.3631 G loss:-2.679\n",
      "Epoch:  0025 D loss:-0.3792 G loss:-2.977\n",
      "Epoch:  0025 D loss:-0.4302 G loss:-2.755\n",
      "Epoch:  0025 D loss:-0.5473 G loss:-2.845\n",
      "Epoch:  0025 D loss:-0.4434 G loss:-2.545\n",
      "Epoch:  0025 D loss:-0.4487 G loss:-2.651\n",
      "Epoch:  0025 D loss:-0.4445 G loss:-2.642\n",
      "Epoch:  0025 D loss:-0.3786 G loss:-2.711\n",
      "Epoch:  0025 D loss:-0.5273 G loss:-2.725\n",
      "Epoch:  0025 D loss:-0.3798 G loss:-2.987\n",
      "Epoch:  0025 D loss:-0.3746 G loss:-2.823\n",
      "Epoch:  0025 D loss:-0.4163 G loss:-2.718\n",
      "Epoch:  0025 D loss:-0.5223 G loss:-2.752\n",
      "Epoch:  0025 D loss:-0.3405 G loss:-2.785\n",
      "Epoch:  0025 D loss:-0.5459 G loss:-2.554\n",
      "Epoch:  0025 D loss:-0.4116 G loss:-2.501\n",
      "Epoch:  0025 D loss:-0.474 G loss:-2.667\n",
      "Epoch:  0025 D loss:-0.3914 G loss:-2.697\n",
      "Epoch:  0025 D loss:-0.3606 G loss:-3.095\n",
      "Epoch:  0025 D loss:-0.4766 G loss:-2.645\n",
      "Epoch:  0025 D loss:-0.4127 G loss:-2.769\n",
      "Epoch:  0025 D loss:-0.5296 G loss:-2.911\n",
      "Epoch:  0025 D loss:-0.3206 G loss:-2.886\n",
      "Epoch:  0026 D loss:-0.3418 G loss:-2.626\n",
      "Epoch:  0026 D loss:-0.3335 G loss:-2.755\n",
      "Epoch:  0026 D loss:-0.3563 G loss:-3.061\n",
      "Epoch:  0026 D loss:-0.4621 G loss:-2.88\n",
      "Epoch:  0026 D loss:-0.4196 G loss:-2.81\n",
      "Epoch:  0026 D loss:-0.401 G loss:-2.78\n",
      "Epoch:  0026 D loss:-0.4197 G loss:-2.808\n",
      "Epoch:  0026 D loss:-0.4267 G loss:-2.834\n",
      "Epoch:  0026 D loss:-0.3684 G loss:-2.902\n",
      "Epoch:  0026 D loss:-0.3058 G loss:-2.971\n",
      "Epoch:  0026 D loss:-0.4336 G loss:-3.102\n",
      "Epoch:  0026 D loss:-0.3168 G loss:-3.137\n",
      "Epoch:  0026 D loss:-0.37 G loss:-3.065\n",
      "Epoch:  0026 D loss:-0.3812 G loss:-3.045\n",
      "Epoch:  0026 D loss:-0.3625 G loss:-3.254\n",
      "Epoch:  0026 D loss:-0.2829 G loss:-3.116\n",
      "Epoch:  0026 D loss:-0.3726 G loss:-3.035\n",
      "Epoch:  0026 D loss:-0.2826 G loss:-3.104\n",
      "Epoch:  0026 D loss:-0.311 G loss:-2.997\n",
      "Epoch:  0026 D loss:-0.3211 G loss:-3.033\n",
      "Epoch:  0026 D loss:-0.2912 G loss:-3.012\n",
      "Epoch:  0026 D loss:-0.3491 G loss:-2.875\n",
      "Epoch:  0026 D loss:-0.3554 G loss:-2.767\n",
      "Epoch:  0026 D loss:-0.2793 G loss:-2.867\n",
      "Epoch:  0026 D loss:-0.3506 G loss:-2.874\n",
      "Epoch:  0026 D loss:-0.3754 G loss:-2.834\n",
      "Epoch:  0026 D loss:-0.3822 G loss:-2.842\n",
      "Epoch:  0026 D loss:-0.3034 G loss:-2.788\n",
      "Epoch:  0026 D loss:-0.3058 G loss:-3.067\n",
      "Epoch:  0026 D loss:-0.4271 G loss:-2.803\n",
      "Epoch:  0026 D loss:-0.3223 G loss:-2.843\n",
      "Epoch:  0026 D loss:-0.4413 G loss:-2.907\n",
      "Epoch:  0026 D loss:-0.2917 G loss:-2.98\n",
      "Epoch:  0026 D loss:-0.3542 G loss:-2.843\n",
      "Epoch:  0026 D loss:-0.394 G loss:-2.854\n",
      "Epoch:  0026 D loss:-0.3439 G loss:-2.84\n",
      "Epoch:  0026 D loss:-0.3658 G loss:-3.014\n",
      "Epoch:  0026 D loss:-0.4091 G loss:-2.981\n",
      "Epoch:  0026 D loss:-0.4916 G loss:-2.737\n",
      "Epoch:  0026 D loss:-0.5525 G loss:-2.672\n",
      "Epoch:  0026 D loss:-0.3953 G loss:-2.657\n",
      "Epoch:  0026 D loss:-0.4174 G loss:-2.802\n",
      "Epoch:  0026 D loss:-0.3217 G loss:-2.726\n",
      "Epoch:  0026 D loss:-0.4329 G loss:-2.517\n",
      "Epoch:  0026 D loss:-0.5591 G loss:-2.606\n",
      "Epoch:  0026 D loss:-0.377 G loss:-2.624\n",
      "Epoch:  0026 D loss:-0.4167 G loss:-2.591\n",
      "Epoch:  0026 D loss:-0.4261 G loss:-2.663\n",
      "Epoch:  0026 D loss:-0.4515 G loss:-2.768\n",
      "Epoch:  0026 D loss:-0.4079 G loss:-2.721\n",
      "Epoch:  0026 D loss:-0.3862 G loss:-2.961\n",
      "Epoch:  0026 D loss:-0.4217 G loss:-3.123\n",
      "Epoch:  0026 D loss:-0.3994 G loss:-2.795\n",
      "Epoch:  0026 D loss:-0.4401 G loss:-2.824\n",
      "Epoch:  0026 D loss:-0.4847 G loss:-2.752\n",
      "Epoch:  0026 D loss:-0.4106 G loss:-2.79\n",
      "Epoch:  0026 D loss:-0.3427 G loss:-2.736\n",
      "Epoch:  0026 D loss:-0.4273 G loss:-2.59\n",
      "Epoch:  0026 D loss:-0.4865 G loss:-2.48\n",
      "Epoch:  0026 D loss:-0.3626 G loss:-2.731\n",
      "Epoch:  0026 D loss:-0.5284 G loss:-2.501\n",
      "Epoch:  0026 D loss:-0.3688 G loss:-2.506\n",
      "Epoch:  0026 D loss:-0.3941 G loss:-2.576\n",
      "Epoch:  0026 D loss:-0.3644 G loss:-2.816\n",
      "Epoch:  0026 D loss:-0.4287 G loss:-2.466\n",
      "Epoch:  0026 D loss:-0.3464 G loss:-2.842\n",
      "Epoch:  0026 D loss:-0.333 G loss:-2.797\n",
      "Epoch:  0026 D loss:-0.3319 G loss:-2.874\n",
      "Epoch:  0026 D loss:-0.4052 G loss:-2.664\n",
      "Epoch:  0026 D loss:-0.3646 G loss:-2.771\n",
      "Epoch:  0026 D loss:-0.4124 G loss:-2.766\n",
      "Epoch:  0026 D loss:-0.3619 G loss:-2.993\n",
      "Epoch:  0026 D loss:-0.4555 G loss:-2.859\n",
      "Epoch:  0026 D loss:-0.3682 G loss:-2.987\n",
      "Epoch:  0026 D loss:-0.3732 G loss:-2.966\n",
      "Epoch:  0026 D loss:-0.3662 G loss:-2.823\n",
      "Epoch:  0026 D loss:-0.4177 G loss:-2.624\n",
      "Epoch:  0026 D loss:-0.4554 G loss:-2.802\n",
      "Epoch:  0026 D loss:-0.3856 G loss:-2.638\n",
      "Epoch:  0026 D loss:-0.3782 G loss:-2.772\n",
      "Epoch:  0026 D loss:-0.3305 G loss:-2.833\n",
      "Epoch:  0026 D loss:-0.3306 G loss:-2.771\n",
      "Epoch:  0026 D loss:-0.3868 G loss:-2.7\n",
      "Epoch:  0026 D loss:-0.4132 G loss:-2.824\n",
      "Epoch:  0026 D loss:-0.4379 G loss:-2.447\n",
      "Epoch:  0026 D loss:-0.4159 G loss:-2.62\n",
      "Epoch:  0026 D loss:-0.4217 G loss:-2.761\n",
      "Epoch:  0026 D loss:-0.4395 G loss:-2.84\n",
      "Epoch:  0026 D loss:-0.4092 G loss:-2.588\n",
      "Epoch:  0026 D loss:-0.3417 G loss:-2.649\n",
      "Epoch:  0026 D loss:-0.329 G loss:-2.986\n",
      "Epoch:  0026 D loss:-0.5405 G loss:-2.906\n",
      "Epoch:  0026 D loss:-0.3242 G loss:-3.019\n",
      "Epoch:  0026 D loss:-0.4376 G loss:-2.841\n",
      "Epoch:  0026 D loss:-0.3175 G loss:-2.859\n",
      "Epoch:  0026 D loss:-0.3688 G loss:-2.732\n",
      "Epoch:  0026 D loss:-0.4199 G loss:-2.927\n",
      "Epoch:  0026 D loss:-0.3956 G loss:-2.73\n",
      "Epoch:  0026 D loss:-0.3057 G loss:-2.947\n",
      "Epoch:  0026 D loss:-0.4861 G loss:-2.796\n",
      "Epoch:  0026 D loss:-0.3414 G loss:-2.933\n",
      "Epoch:  0026 D loss:-0.2914 G loss:-2.67\n",
      "Epoch:  0026 D loss:-0.3364 G loss:-2.661\n",
      "Epoch:  0026 D loss:-0.3897 G loss:-2.671\n",
      "Epoch:  0026 D loss:-0.3341 G loss:-2.841\n",
      "Epoch:  0026 D loss:-0.4536 G loss:-2.685\n",
      "Epoch:  0026 D loss:-0.4731 G loss:-2.612\n",
      "Epoch:  0026 D loss:-0.4018 G loss:-2.491\n",
      "Epoch:  0026 D loss:-0.4179 G loss:-2.515\n",
      "Epoch:  0026 D loss:-0.376 G loss:-2.812\n",
      "Epoch:  0026 D loss:-0.4847 G loss:-2.827\n",
      "Epoch:  0026 D loss:-0.4492 G loss:-2.803\n",
      "Epoch:  0026 D loss:-0.3797 G loss:-2.492\n",
      "Epoch:  0026 D loss:-0.3981 G loss:-2.655\n",
      "Epoch:  0026 D loss:-0.46 G loss:-2.809\n",
      "Epoch:  0026 D loss:-0.4204 G loss:-2.628\n",
      "Epoch:  0026 D loss:-0.3729 G loss:-2.877\n",
      "Epoch:  0026 D loss:-0.4087 G loss:-2.638\n",
      "Epoch:  0026 D loss:-0.4483 G loss:-2.598\n",
      "Epoch:  0026 D loss:-0.3587 G loss:-2.849\n",
      "Epoch:  0026 D loss:-0.4143 G loss:-2.825\n",
      "Epoch:  0026 D loss:-0.3963 G loss:-3.045\n",
      "Epoch:  0026 D loss:-0.4506 G loss:-2.938\n",
      "Epoch:  0026 D loss:-0.3235 G loss:-2.855\n",
      "Epoch:  0026 D loss:-0.4567 G loss:-2.52\n",
      "Epoch:  0026 D loss:-0.3537 G loss:-2.734\n",
      "Epoch:  0026 D loss:-0.3774 G loss:-2.614\n",
      "Epoch:  0026 D loss:-0.4146 G loss:-2.645\n",
      "Epoch:  0026 D loss:-0.4367 G loss:-2.78\n",
      "Epoch:  0026 D loss:-0.3581 G loss:-2.82\n",
      "Epoch:  0026 D loss:-0.4425 G loss:-3.074\n",
      "Epoch:  0026 D loss:-0.3863 G loss:-3.062\n",
      "Epoch:  0026 D loss:-0.2675 G loss:-3.01\n",
      "Epoch:  0026 D loss:-0.4363 G loss:-2.938\n",
      "Epoch:  0026 D loss:-0.3703 G loss:-2.809\n",
      "Epoch:  0026 D loss:-0.4743 G loss:-2.796\n",
      "Epoch:  0026 D loss:-0.4635 G loss:-3.101\n",
      "Epoch:  0026 D loss:-0.4035 G loss:-2.71\n",
      "Epoch:  0026 D loss:-0.4754 G loss:-2.762\n",
      "Epoch:  0026 D loss:-0.3127 G loss:-2.985\n",
      "Epoch:  0026 D loss:-0.3612 G loss:-2.729\n",
      "Epoch:  0026 D loss:-0.4091 G loss:-2.879\n",
      "Epoch:  0026 D loss:-0.4253 G loss:-2.421\n",
      "Epoch:  0026 D loss:-0.4267 G loss:-2.561\n",
      "Epoch:  0026 D loss:-0.344 G loss:-2.782\n",
      "Epoch:  0026 D loss:-0.3446 G loss:-2.918\n",
      "Epoch:  0026 D loss:-0.2938 G loss:-3.14\n",
      "Epoch:  0026 D loss:-0.3423 G loss:-2.952\n",
      "Epoch:  0026 D loss:-0.3326 G loss:-3.003\n",
      "Epoch:  0026 D loss:-0.3538 G loss:-3.275\n",
      "Epoch:  0026 D loss:-0.2723 G loss:-3.229\n",
      "Epoch:  0026 D loss:-0.3673 G loss:-3.099\n",
      "Epoch:  0026 D loss:-0.3607 G loss:-3.101\n",
      "Epoch:  0026 D loss:-0.2951 G loss:-3.276\n",
      "Epoch:  0026 D loss:-0.3032 G loss:-2.77\n",
      "Epoch:  0026 D loss:-0.3898 G loss:-2.774\n",
      "Epoch:  0026 D loss:-0.3348 G loss:-2.929\n",
      "Epoch:  0026 D loss:-0.3802 G loss:-2.752\n",
      "Epoch:  0026 D loss:-0.4584 G loss:-2.613\n",
      "Epoch:  0026 D loss:-0.4314 G loss:-2.721\n",
      "Epoch:  0026 D loss:-0.3719 G loss:-2.86\n",
      "Epoch:  0026 D loss:-0.3883 G loss:-2.992\n",
      "Epoch:  0026 D loss:-0.4695 G loss:-2.795\n",
      "Epoch:  0026 D loss:-0.3996 G loss:-2.845\n",
      "Epoch:  0026 D loss:-0.2651 G loss:-2.847\n",
      "Epoch:  0026 D loss:-0.3209 G loss:-2.816\n",
      "Epoch:  0026 D loss:-0.3117 G loss:-3.088\n",
      "Epoch:  0026 D loss:-0.3706 G loss:-2.801\n",
      "Epoch:  0026 D loss:-0.3293 G loss:-2.903\n",
      "Epoch:  0026 D loss:-0.376 G loss:-3.179\n",
      "Epoch:  0026 D loss:-0.3495 G loss:-2.754\n",
      "Epoch:  0026 D loss:-0.4875 G loss:-2.781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0026 D loss:-0.3361 G loss:-2.879\n",
      "Epoch:  0026 D loss:-0.3724 G loss:-2.716\n",
      "Epoch:  0026 D loss:-0.4016 G loss:-2.698\n",
      "Epoch:  0026 D loss:-0.3502 G loss:-2.753\n",
      "Epoch:  0026 D loss:-0.3359 G loss:-2.626\n",
      "Epoch:  0026 D loss:-0.3038 G loss:-2.87\n",
      "Epoch:  0026 D loss:-0.3278 G loss:-3.177\n",
      "Epoch:  0026 D loss:-0.2906 G loss:-3.11\n",
      "Epoch:  0026 D loss:-0.2552 G loss:-3.227\n",
      "Epoch:  0026 D loss:-0.3664 G loss:-3.068\n",
      "Epoch:  0026 D loss:-0.3678 G loss:-3.022\n",
      "Epoch:  0026 D loss:-0.3421 G loss:-3.003\n",
      "Epoch:  0026 D loss:-0.3299 G loss:-2.979\n",
      "Epoch:  0026 D loss:-0.359 G loss:-2.93\n",
      "Epoch:  0026 D loss:-0.2865 G loss:-2.979\n",
      "Epoch:  0026 D loss:-0.3089 G loss:-2.966\n",
      "Epoch:  0026 D loss:-0.273 G loss:-2.902\n",
      "Epoch:  0026 D loss:-0.2759 G loss:-2.82\n",
      "Epoch:  0026 D loss:-0.3258 G loss:-2.896\n",
      "Epoch:  0026 D loss:-0.3411 G loss:-2.782\n",
      "Epoch:  0026 D loss:-0.3144 G loss:-2.869\n",
      "Epoch:  0026 D loss:-0.308 G loss:-2.752\n",
      "Epoch:  0026 D loss:-0.2633 G loss:-2.924\n",
      "Epoch:  0026 D loss:-0.2793 G loss:-3.162\n",
      "Epoch:  0026 D loss:-0.3153 G loss:-3.137\n",
      "Epoch:  0026 D loss:-0.2538 G loss:-3.234\n",
      "Epoch:  0026 D loss:-0.3203 G loss:-3.142\n",
      "Epoch:  0026 D loss:-0.2602 G loss:-3.058\n",
      "Epoch:  0026 D loss:-0.2398 G loss:-3.217\n",
      "Epoch:  0026 D loss:-0.2737 G loss:-3.105\n",
      "Epoch:  0026 D loss:-0.3474 G loss:-3.109\n",
      "Epoch:  0026 D loss:-0.2762 G loss:-3.361\n",
      "Epoch:  0026 D loss:-0.285 G loss:-3.145\n",
      "Epoch:  0026 D loss:-0.2805 G loss:-3.033\n",
      "Epoch:  0026 D loss:-0.3212 G loss:-3.096\n",
      "Epoch:  0026 D loss:-0.3929 G loss:-3.033\n",
      "Epoch:  0026 D loss:-0.238 G loss:-3.285\n",
      "Epoch:  0026 D loss:-0.2911 G loss:-3.008\n",
      "Epoch:  0026 D loss:-0.3179 G loss:-3.071\n",
      "Epoch:  0026 D loss:-0.3328 G loss:-2.862\n",
      "Epoch:  0026 D loss:-0.2876 G loss:-3.046\n",
      "Epoch:  0026 D loss:-0.3361 G loss:-2.683\n",
      "Epoch:  0026 D loss:-0.3286 G loss:-2.853\n",
      "Epoch:  0026 D loss:-0.3676 G loss:-2.757\n",
      "Epoch:  0026 D loss:-0.2709 G loss:-2.936\n",
      "Epoch:  0026 D loss:-0.3219 G loss:-3.031\n",
      "Epoch:  0026 D loss:-0.3245 G loss:-2.769\n",
      "Epoch:  0026 D loss:-0.3848 G loss:-2.915\n",
      "Epoch:  0026 D loss:-0.3913 G loss:-2.875\n",
      "Epoch:  0026 D loss:-0.3005 G loss:-3.07\n",
      "Epoch:  0026 D loss:-0.4031 G loss:-3.079\n",
      "Epoch:  0026 D loss:-0.2775 G loss:-3.188\n",
      "Epoch:  0026 D loss:-0.2593 G loss:-3.203\n",
      "Epoch:  0026 D loss:-0.2731 G loss:-3.1\n",
      "Epoch:  0026 D loss:-0.3165 G loss:-2.773\n",
      "Epoch:  0026 D loss:-0.3853 G loss:-2.757\n",
      "Epoch:  0026 D loss:-0.2336 G loss:-2.879\n",
      "Epoch:  0026 D loss:-0.3695 G loss:-2.992\n",
      "Epoch:  0026 D loss:-0.2688 G loss:-3.116\n",
      "Epoch:  0026 D loss:-0.3535 G loss:-2.866\n",
      "Epoch:  0026 D loss:-0.306 G loss:-2.708\n",
      "Epoch:  0026 D loss:-0.3415 G loss:-3.101\n",
      "Epoch:  0026 D loss:-0.3077 G loss:-2.947\n",
      "Epoch:  0026 D loss:-0.3621 G loss:-3.071\n",
      "Epoch:  0026 D loss:-0.3106 G loss:-3.128\n",
      "Epoch:  0026 D loss:-0.2671 G loss:-3.065\n",
      "Epoch:  0026 D loss:-0.3504 G loss:-3.05\n",
      "Epoch:  0026 D loss:-0.3172 G loss:-3.298\n",
      "Epoch:  0026 D loss:-0.3224 G loss:-3.147\n",
      "Epoch:  0026 D loss:-0.3261 G loss:-3.08\n",
      "Epoch:  0026 D loss:-0.2341 G loss:-3.303\n",
      "Epoch:  0026 D loss:-0.3026 G loss:-3.239\n",
      "Epoch:  0026 D loss:-0.3102 G loss:-3.036\n",
      "Epoch:  0026 D loss:-0.3314 G loss:-3.043\n",
      "Epoch:  0026 D loss:-0.3209 G loss:-2.955\n",
      "Epoch:  0026 D loss:-0.3459 G loss:-2.705\n",
      "Epoch:  0026 D loss:-0.2617 G loss:-2.781\n",
      "Epoch:  0026 D loss:-0.2561 G loss:-3.095\n",
      "Epoch:  0026 D loss:-0.2378 G loss:-3.39\n",
      "Epoch:  0026 D loss:-0.2687 G loss:-3.13\n",
      "Epoch:  0026 D loss:-0.307 G loss:-3.271\n",
      "Epoch:  0026 D loss:-0.2771 G loss:-3.402\n",
      "Epoch:  0026 D loss:-0.1996 G loss:-3.221\n",
      "Epoch:  0026 D loss:-0.2315 G loss:-3.306\n",
      "Epoch:  0026 D loss:-0.2983 G loss:-3.167\n",
      "Epoch:  0026 D loss:-0.2255 G loss:-3.291\n",
      "Epoch:  0026 D loss:-0.2309 G loss:-3.279\n",
      "Epoch:  0026 D loss:-0.4096 G loss:-2.788\n",
      "Epoch:  0026 D loss:-0.2065 G loss:-3.29\n",
      "Epoch:  0026 D loss:-0.2723 G loss:-2.982\n",
      "Epoch:  0026 D loss:-0.2765 G loss:-2.98\n",
      "Epoch:  0026 D loss:-0.3306 G loss:-3.086\n",
      "Epoch:  0026 D loss:-0.3492 G loss:-3.103\n",
      "Epoch:  0026 D loss:-0.2924 G loss:-3.279\n",
      "Epoch:  0026 D loss:-0.2968 G loss:-3.008\n",
      "Epoch:  0026 D loss:-0.2891 G loss:-3.374\n",
      "Epoch:  0026 D loss:-0.2747 G loss:-3.254\n",
      "Epoch:  0026 D loss:-0.2781 G loss:-3.087\n",
      "Epoch:  0026 D loss:-0.2486 G loss:-3.293\n",
      "Epoch:  0026 D loss:-0.329 G loss:-3.282\n",
      "Epoch:  0026 D loss:-0.2487 G loss:-3.208\n",
      "Epoch:  0026 D loss:-0.2926 G loss:-3.078\n",
      "Epoch:  0026 D loss:-0.2796 G loss:-3.041\n",
      "Epoch:  0026 D loss:-0.3319 G loss:-3.169\n",
      "Epoch:  0026 D loss:-0.2515 G loss:-2.924\n",
      "Epoch:  0026 D loss:-0.2951 G loss:-2.999\n",
      "Epoch:  0026 D loss:-0.2179 G loss:-3.082\n",
      "Epoch:  0026 D loss:-0.2835 G loss:-2.855\n",
      "Epoch:  0026 D loss:-0.2974 G loss:-3.202\n",
      "Epoch:  0026 D loss:-0.2694 G loss:-2.945\n",
      "Epoch:  0026 D loss:-0.2462 G loss:-3.182\n",
      "Epoch:  0026 D loss:-0.2701 G loss:-3.128\n",
      "Epoch:  0026 D loss:-0.2993 G loss:-3.124\n",
      "Epoch:  0026 D loss:-0.3731 G loss:-2.851\n",
      "Epoch:  0026 D loss:-0.3169 G loss:-3.053\n",
      "Epoch:  0026 D loss:-0.2919 G loss:-3.407\n",
      "Epoch:  0026 D loss:-0.3251 G loss:-3.02\n",
      "Epoch:  0026 D loss:-0.3046 G loss:-3.279\n",
      "Epoch:  0026 D loss:-0.3381 G loss:-3.159\n",
      "Epoch:  0026 D loss:-0.3694 G loss:-2.991\n",
      "Epoch:  0026 D loss:-0.3456 G loss:-2.989\n",
      "Epoch:  0026 D loss:-0.2883 G loss:-2.851\n",
      "Epoch:  0026 D loss:-0.2994 G loss:-2.894\n",
      "Epoch:  0026 D loss:-0.3039 G loss:-3.001\n",
      "Epoch:  0026 D loss:-0.2773 G loss:-3.063\n",
      "Epoch:  0026 D loss:-0.2945 G loss:-2.977\n",
      "Epoch:  0026 D loss:-0.2568 G loss:-3.0\n",
      "Epoch:  0026 D loss:-0.2241 G loss:-3.164\n",
      "Epoch:  0026 D loss:-0.2948 G loss:-3.131\n",
      "Epoch:  0026 D loss:-0.3419 G loss:-3.026\n",
      "Epoch:  0026 D loss:-0.3512 G loss:-3.047\n",
      "Epoch:  0026 D loss:-0.383 G loss:-2.883\n",
      "Epoch:  0026 D loss:-0.2376 G loss:-2.952\n",
      "Epoch:  0026 D loss:-0.2793 G loss:-3.007\n",
      "Epoch:  0026 D loss:-0.4163 G loss:-2.828\n",
      "Epoch:  0026 D loss:-0.3441 G loss:-2.576\n",
      "Epoch:  0026 D loss:-0.3361 G loss:-2.819\n",
      "Epoch:  0026 D loss:-0.3274 G loss:-2.802\n",
      "Epoch:  0026 D loss:-0.3356 G loss:-2.655\n",
      "Epoch:  0026 D loss:-0.412 G loss:-2.946\n",
      "Epoch:  0026 D loss:-0.224 G loss:-2.987\n",
      "Epoch:  0026 D loss:-0.3119 G loss:-3.23\n",
      "Epoch:  0026 D loss:-0.3993 G loss:-2.823\n",
      "Epoch:  0026 D loss:-0.3134 G loss:-2.843\n",
      "Epoch:  0026 D loss:-0.2406 G loss:-3.076\n",
      "Epoch:  0026 D loss:-0.2584 G loss:-3.02\n",
      "Epoch:  0026 D loss:-0.3692 G loss:-3.072\n",
      "Epoch:  0026 D loss:-0.3353 G loss:-2.94\n",
      "Epoch:  0026 D loss:-0.3534 G loss:-2.956\n",
      "Epoch:  0026 D loss:-0.3649 G loss:-2.872\n",
      "Epoch:  0026 D loss:-0.2702 G loss:-3.195\n",
      "Epoch:  0026 D loss:-0.3707 G loss:-2.964\n",
      "Epoch:  0026 D loss:-0.3933 G loss:-3.016\n",
      "Epoch:  0026 D loss:-0.3279 G loss:-2.912\n",
      "Epoch:  0026 D loss:-0.3888 G loss:-2.678\n",
      "Epoch:  0026 D loss:-0.3326 G loss:-3.004\n",
      "Epoch:  0026 D loss:-0.3332 G loss:-2.989\n",
      "Epoch:  0026 D loss:-0.2736 G loss:-2.926\n",
      "Epoch:  0026 D loss:-0.3114 G loss:-2.962\n",
      "Epoch:  0026 D loss:-0.309 G loss:-2.788\n",
      "Epoch:  0026 D loss:-0.3333 G loss:-3.229\n",
      "Epoch:  0026 D loss:-0.3965 G loss:-2.897\n",
      "Epoch:  0026 D loss:-0.2884 G loss:-3.103\n",
      "Epoch:  0026 D loss:-0.4812 G loss:-2.869\n",
      "Epoch:  0026 D loss:-0.3586 G loss:-2.845\n",
      "Epoch:  0026 D loss:-0.3695 G loss:-2.973\n",
      "Epoch:  0026 D loss:-0.3099 G loss:-2.89\n",
      "Epoch:  0026 D loss:-0.3156 G loss:-2.722\n",
      "Epoch:  0026 D loss:-0.3468 G loss:-2.563\n",
      "Epoch:  0026 D loss:-0.3291 G loss:-2.577\n",
      "Epoch:  0026 D loss:-0.3943 G loss:-2.676\n",
      "Epoch:  0026 D loss:-0.313 G loss:-2.702\n",
      "Epoch:  0026 D loss:-0.3648 G loss:-2.759\n",
      "Epoch:  0026 D loss:-0.3086 G loss:-2.964\n",
      "Epoch:  0026 D loss:-0.399 G loss:-2.72\n",
      "Epoch:  0026 D loss:-0.2756 G loss:-2.902\n",
      "Epoch:  0026 D loss:-0.3519 G loss:-2.997\n",
      "Epoch:  0026 D loss:-0.3488 G loss:-2.962\n",
      "Epoch:  0026 D loss:-0.3051 G loss:-3.068\n",
      "Epoch:  0026 D loss:-0.432 G loss:-3.347\n",
      "Epoch:  0026 D loss:-0.3081 G loss:-3.03\n",
      "Epoch:  0026 D loss:-0.3576 G loss:-2.946\n",
      "Epoch:  0026 D loss:-0.3375 G loss:-2.905\n",
      "Epoch:  0026 D loss:-0.3914 G loss:-3.018\n",
      "Epoch:  0026 D loss:-0.3013 G loss:-2.768\n",
      "Epoch:  0026 D loss:-0.3267 G loss:-2.65\n",
      "Epoch:  0026 D loss:-0.3924 G loss:-2.623\n",
      "Epoch:  0026 D loss:-0.3289 G loss:-2.773\n",
      "Epoch:  0026 D loss:-0.3763 G loss:-2.651\n",
      "Epoch:  0026 D loss:-0.425 G loss:-2.82\n",
      "Epoch:  0026 D loss:-0.3457 G loss:-2.55\n",
      "Epoch:  0026 D loss:-0.4084 G loss:-2.707\n",
      "Epoch:  0026 D loss:-0.2892 G loss:-2.819\n",
      "Epoch:  0026 D loss:-0.2896 G loss:-2.882\n",
      "Epoch:  0026 D loss:-0.387 G loss:-3.023\n",
      "Epoch:  0026 D loss:-0.3202 G loss:-2.991\n",
      "Epoch:  0026 D loss:-0.3059 G loss:-2.948\n",
      "Epoch:  0026 D loss:-0.3414 G loss:-2.94\n",
      "Epoch:  0026 D loss:-0.3144 G loss:-3.101\n",
      "Epoch:  0026 D loss:-0.359 G loss:-2.836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0026 D loss:-0.485 G loss:-2.827\n",
      "Epoch:  0026 D loss:-0.4315 G loss:-2.803\n",
      "Epoch:  0026 D loss:-0.3675 G loss:-2.753\n",
      "Epoch:  0026 D loss:-0.3457 G loss:-2.801\n",
      "Epoch:  0026 D loss:-0.4761 G loss:-2.527\n",
      "Epoch:  0026 D loss:-0.3404 G loss:-2.737\n",
      "Epoch:  0026 D loss:-0.2899 G loss:-2.665\n",
      "Epoch:  0026 D loss:-0.3675 G loss:-2.786\n",
      "Epoch:  0026 D loss:-0.3371 G loss:-2.927\n",
      "Epoch:  0026 D loss:-0.3589 G loss:-3.015\n",
      "Epoch:  0026 D loss:-0.2966 G loss:-3.114\n",
      "Epoch:  0026 D loss:-0.3493 G loss:-2.871\n",
      "Epoch:  0026 D loss:-0.3226 G loss:-3.052\n",
      "Epoch:  0026 D loss:-0.2534 G loss:-3.112\n",
      "Epoch:  0026 D loss:-0.3385 G loss:-3.324\n",
      "Epoch:  0026 D loss:-0.2939 G loss:-2.918\n",
      "Epoch:  0026 D loss:-0.3278 G loss:-2.721\n",
      "Epoch:  0026 D loss:-0.3405 G loss:-2.967\n",
      "Epoch:  0026 D loss:-0.3392 G loss:-2.75\n",
      "Epoch:  0026 D loss:-0.2622 G loss:-2.902\n",
      "Epoch:  0026 D loss:-0.2616 G loss:-3.05\n",
      "Epoch:  0026 D loss:-0.4265 G loss:-2.864\n",
      "Epoch:  0026 D loss:-0.4031 G loss:-2.751\n",
      "Epoch:  0026 D loss:-0.2861 G loss:-2.975\n",
      "Epoch:  0026 D loss:-0.3397 G loss:-2.863\n",
      "Epoch:  0026 D loss:-0.2957 G loss:-2.906\n",
      "Epoch:  0026 D loss:-0.3218 G loss:-2.929\n",
      "Epoch:  0026 D loss:-0.3522 G loss:-2.838\n",
      "Epoch:  0026 D loss:-0.2643 G loss:-2.963\n",
      "Epoch:  0026 D loss:-0.2856 G loss:-2.835\n",
      "Epoch:  0026 D loss:-0.3055 G loss:-2.871\n",
      "Epoch:  0026 D loss:-0.2674 G loss:-2.778\n",
      "Epoch:  0026 D loss:-0.3453 G loss:-2.781\n",
      "Epoch:  0026 D loss:-0.3359 G loss:-2.836\n",
      "Epoch:  0026 D loss:-0.3858 G loss:-2.8\n",
      "Epoch:  0026 D loss:-0.367 G loss:-2.824\n",
      "Epoch:  0026 D loss:-0.2667 G loss:-2.918\n",
      "Epoch:  0026 D loss:-0.2683 G loss:-2.913\n",
      "Epoch:  0026 D loss:-0.3575 G loss:-2.796\n",
      "Epoch:  0026 D loss:-0.3964 G loss:-2.844\n",
      "Epoch:  0026 D loss:-0.3017 G loss:-2.857\n",
      "Epoch:  0026 D loss:-0.4125 G loss:-2.53\n",
      "Epoch:  0026 D loss:-0.3223 G loss:-2.871\n",
      "Epoch:  0026 D loss:-0.4355 G loss:-2.981\n",
      "Epoch:  0026 D loss:-0.3023 G loss:-2.825\n",
      "Epoch:  0026 D loss:-0.4585 G loss:-2.576\n",
      "Epoch:  0026 D loss:-0.4486 G loss:-2.612\n",
      "Epoch:  0026 D loss:-0.3247 G loss:-2.887\n",
      "Epoch:  0026 D loss:-0.3274 G loss:-2.707\n",
      "Epoch:  0026 D loss:-0.3319 G loss:-2.864\n",
      "Epoch:  0026 D loss:-0.3764 G loss:-2.746\n",
      "Epoch:  0026 D loss:-0.3804 G loss:-2.924\n",
      "Epoch:  0026 D loss:-0.4983 G loss:-2.704\n",
      "Epoch:  0026 D loss:-0.3224 G loss:-2.975\n",
      "Epoch:  0026 D loss:-0.4079 G loss:-2.583\n",
      "Epoch:  0026 D loss:-0.3737 G loss:-2.657\n",
      "Epoch:  0026 D loss:-0.321 G loss:-2.86\n",
      "Epoch:  0026 D loss:-0.3184 G loss:-2.852\n",
      "Epoch:  0026 D loss:-0.3649 G loss:-2.731\n",
      "Epoch:  0026 D loss:-0.411 G loss:-2.756\n",
      "Epoch:  0026 D loss:-0.4219 G loss:-2.802\n",
      "Epoch:  0026 D loss:-0.315 G loss:-2.711\n",
      "Epoch:  0026 D loss:-0.3977 G loss:-2.746\n",
      "Epoch:  0026 D loss:-0.4015 G loss:-2.655\n",
      "Epoch:  0026 D loss:-0.415 G loss:-2.709\n",
      "Epoch:  0026 D loss:-0.3013 G loss:-2.741\n",
      "Epoch:  0026 D loss:-0.3926 G loss:-2.736\n",
      "Epoch:  0026 D loss:-0.4746 G loss:-2.886\n",
      "Epoch:  0026 D loss:-0.3297 G loss:-2.694\n",
      "Epoch:  0026 D loss:-0.409 G loss:-2.726\n",
      "Epoch:  0026 D loss:-0.4616 G loss:-2.695\n",
      "Epoch:  0026 D loss:-0.4454 G loss:-2.969\n",
      "Epoch:  0026 D loss:-0.4061 G loss:-2.641\n",
      "Epoch:  0026 D loss:-0.5084 G loss:-2.81\n",
      "Epoch:  0026 D loss:-0.3151 G loss:-2.704\n",
      "Epoch:  0026 D loss:-0.4948 G loss:-2.361\n",
      "Epoch:  0026 D loss:-0.4506 G loss:-2.487\n",
      "Epoch:  0026 D loss:-0.4494 G loss:-2.626\n",
      "Epoch:  0026 D loss:-0.3668 G loss:-2.677\n",
      "Epoch:  0026 D loss:-0.5316 G loss:-2.495\n",
      "Epoch:  0026 D loss:-0.4107 G loss:-2.776\n",
      "Epoch:  0026 D loss:-0.4413 G loss:-2.885\n",
      "Epoch:  0026 D loss:-0.4956 G loss:-2.793\n",
      "Epoch:  0026 D loss:-0.4226 G loss:-2.935\n",
      "Epoch:  0026 D loss:-0.4621 G loss:-2.816\n",
      "Epoch:  0026 D loss:-0.4392 G loss:-2.712\n",
      "Epoch:  0026 D loss:-0.5244 G loss:-2.621\n",
      "Epoch:  0026 D loss:-0.4441 G loss:-2.401\n",
      "Epoch:  0026 D loss:-0.4238 G loss:-2.482\n",
      "Epoch:  0026 D loss:-0.3416 G loss:-2.529\n",
      "Epoch:  0026 D loss:-0.5249 G loss:-2.306\n",
      "Epoch:  0026 D loss:-0.4859 G loss:-2.509\n",
      "Epoch:  0026 D loss:-0.4012 G loss:-2.459\n",
      "Epoch:  0026 D loss:-0.4927 G loss:-2.457\n",
      "Epoch:  0026 D loss:-0.4612 G loss:-2.466\n",
      "Epoch:  0026 D loss:-0.5162 G loss:-2.575\n",
      "Epoch:  0026 D loss:-0.515 G loss:-2.756\n",
      "Epoch:  0026 D loss:-0.4496 G loss:-2.499\n",
      "Epoch:  0026 D loss:-0.49 G loss:-2.511\n",
      "Epoch:  0026 D loss:-0.4155 G loss:-2.473\n",
      "Epoch:  0026 D loss:-0.4862 G loss:-2.483\n",
      "Epoch:  0026 D loss:-0.5581 G loss:-2.362\n",
      "Epoch:  0026 D loss:-0.4211 G loss:-2.697\n",
      "Epoch:  0026 D loss:-0.4269 G loss:-2.512\n",
      "Epoch:  0026 D loss:-0.4197 G loss:-2.707\n",
      "Epoch:  0026 D loss:-0.5 G loss:-2.695\n",
      "Epoch:  0026 D loss:-0.3694 G loss:-2.882\n",
      "Epoch:  0026 D loss:-0.5105 G loss:-2.878\n",
      "Epoch:  0026 D loss:-0.4395 G loss:-2.856\n",
      "Epoch:  0026 D loss:-0.4219 G loss:-2.509\n",
      "Epoch:  0026 D loss:-0.3835 G loss:-2.69\n",
      "Epoch:  0026 D loss:-0.3915 G loss:-2.849\n",
      "Epoch:  0026 D loss:-0.404 G loss:-2.705\n",
      "Epoch:  0026 D loss:-0.4184 G loss:-2.452\n",
      "Epoch:  0026 D loss:-0.3436 G loss:-2.807\n",
      "Epoch:  0026 D loss:-0.5753 G loss:-2.533\n",
      "Epoch:  0026 D loss:-0.4459 G loss:-2.708\n",
      "Epoch:  0026 D loss:-0.4247 G loss:-2.764\n",
      "Epoch:  0026 D loss:-0.3599 G loss:-2.628\n",
      "Epoch:  0026 D loss:-0.5148 G loss:-2.559\n",
      "Epoch:  0026 D loss:-0.3698 G loss:-2.721\n",
      "Epoch:  0026 D loss:-0.5193 G loss:-2.513\n",
      "Epoch:  0026 D loss:-0.4461 G loss:-2.388\n",
      "Epoch:  0026 D loss:-0.4569 G loss:-2.521\n",
      "Epoch:  0026 D loss:-0.4794 G loss:-2.627\n",
      "Epoch:  0026 D loss:-0.4024 G loss:-2.723\n",
      "Epoch:  0026 D loss:-0.3572 G loss:-2.859\n",
      "Epoch:  0026 D loss:-0.5103 G loss:-2.829\n",
      "Epoch:  0026 D loss:-0.4126 G loss:-2.644\n",
      "Epoch:  0026 D loss:-0.5049 G loss:-2.886\n",
      "Epoch:  0026 D loss:-0.3877 G loss:-2.894\n",
      "Epoch:  0026 D loss:-0.3862 G loss:-2.994\n",
      "Epoch:  0026 D loss:-0.4672 G loss:-2.699\n",
      "Epoch:  0026 D loss:-0.4071 G loss:-2.676\n",
      "Epoch:  0026 D loss:-0.5279 G loss:-2.619\n",
      "Epoch:  0026 D loss:-0.3996 G loss:-2.627\n",
      "Epoch:  0026 D loss:-0.4431 G loss:-2.678\n",
      "Epoch:  0026 D loss:-0.4211 G loss:-2.702\n",
      "Epoch:  0026 D loss:-0.4608 G loss:-2.591\n",
      "Epoch:  0026 D loss:-0.4218 G loss:-2.753\n",
      "Epoch:  0026 D loss:-0.371 G loss:-2.977\n",
      "Epoch:  0026 D loss:-0.4093 G loss:-2.532\n",
      "Epoch:  0026 D loss:-0.3571 G loss:-2.905\n",
      "Epoch:  0026 D loss:-0.6095 G loss:-2.562\n",
      "Epoch:  0026 D loss:-0.4621 G loss:-2.644\n",
      "Epoch:  0026 D loss:-0.4022 G loss:-2.666\n",
      "Epoch:  0026 D loss:-0.5174 G loss:-2.447\n",
      "Epoch:  0026 D loss:-0.3461 G loss:-2.753\n",
      "Epoch:  0026 D loss:-0.4633 G loss:-2.758\n",
      "Epoch:  0026 D loss:-0.4433 G loss:-2.56\n",
      "Epoch:  0026 D loss:-0.539 G loss:-2.647\n",
      "Epoch:  0026 D loss:-0.5586 G loss:-2.643\n",
      "Epoch:  0026 D loss:-0.5489 G loss:-2.837\n",
      "Epoch:  0026 D loss:-0.5136 G loss:-2.457\n",
      "Epoch:  0026 D loss:-0.4005 G loss:-2.695\n",
      "Epoch:  0026 D loss:-0.3904 G loss:-2.754\n",
      "Epoch:  0026 D loss:-0.4354 G loss:-2.632\n",
      "Epoch:  0026 D loss:-0.4016 G loss:-2.657\n",
      "Epoch:  0026 D loss:-0.3927 G loss:-2.841\n",
      "Epoch:  0026 D loss:-0.4677 G loss:-2.716\n",
      "Epoch:  0026 D loss:-0.4787 G loss:-2.911\n",
      "Epoch:  0026 D loss:-0.4525 G loss:-2.417\n",
      "Epoch:  0026 D loss:-0.3618 G loss:-2.569\n",
      "Epoch:  0026 D loss:-0.4601 G loss:-2.634\n",
      "Epoch:  0026 D loss:-0.4201 G loss:-2.631\n",
      "Epoch:  0026 D loss:-0.4412 G loss:-2.681\n",
      "Epoch:  0026 D loss:-0.4374 G loss:-2.897\n",
      "Epoch:  0026 D loss:-0.3621 G loss:-2.846\n",
      "Epoch:  0026 D loss:-0.3001 G loss:-3.024\n",
      "Epoch:  0026 D loss:-0.4503 G loss:-2.942\n",
      "Epoch:  0026 D loss:-0.3881 G loss:-2.88\n",
      "Epoch:  0026 D loss:-0.3818 G loss:-2.783\n",
      "Epoch:  0026 D loss:-0.4152 G loss:-2.829\n",
      "Epoch:  0026 D loss:-0.3486 G loss:-2.911\n",
      "Epoch:  0026 D loss:-0.3558 G loss:-2.946\n",
      "Epoch:  0026 D loss:-0.5221 G loss:-2.819\n",
      "Epoch:  0026 D loss:-0.393 G loss:-2.728\n",
      "Epoch:  0026 D loss:-0.2989 G loss:-2.815\n",
      "Epoch:  0027 D loss:-0.3239 G loss:-3.053\n",
      "Epoch:  0027 D loss:-0.3278 G loss:-3.039\n",
      "Epoch:  0027 D loss:-0.3867 G loss:-2.827\n",
      "Epoch:  0027 D loss:-0.3635 G loss:-2.802\n",
      "Epoch:  0027 D loss:-0.5107 G loss:-2.602\n",
      "Epoch:  0027 D loss:-0.4185 G loss:-2.66\n",
      "Epoch:  0027 D loss:-0.496 G loss:-2.734\n",
      "Epoch:  0027 D loss:-0.3348 G loss:-2.911\n",
      "Epoch:  0027 D loss:-0.325 G loss:-3.01\n",
      "Epoch:  0027 D loss:-0.4432 G loss:-2.98\n",
      "Epoch:  0027 D loss:-0.3595 G loss:-3.209\n",
      "Epoch:  0027 D loss:-0.2777 G loss:-3.193\n",
      "Epoch:  0027 D loss:-0.3389 G loss:-2.715\n",
      "Epoch:  0027 D loss:-0.333 G loss:-3.019\n",
      "Epoch:  0027 D loss:-0.357 G loss:-2.763\n",
      "Epoch:  0027 D loss:-0.4286 G loss:-2.662\n",
      "Epoch:  0027 D loss:-0.2795 G loss:-3.038\n",
      "Epoch:  0027 D loss:-0.3297 G loss:-2.685\n",
      "Epoch:  0027 D loss:-0.334 G loss:-2.692\n",
      "Epoch:  0027 D loss:-0.2264 G loss:-2.934\n",
      "Epoch:  0027 D loss:-0.2813 G loss:-2.821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0027 D loss:-0.3169 G loss:-2.837\n",
      "Epoch:  0027 D loss:-0.2902 G loss:-3.114\n",
      "Epoch:  0027 D loss:-0.3267 G loss:-3.094\n",
      "Epoch:  0027 D loss:-0.3596 G loss:-3.383\n",
      "Epoch:  0027 D loss:-0.3158 G loss:-3.168\n",
      "Epoch:  0027 D loss:-0.225 G loss:-3.366\n",
      "Epoch:  0027 D loss:-0.4061 G loss:-2.991\n",
      "Epoch:  0027 D loss:-0.2921 G loss:-3.121\n",
      "Epoch:  0027 D loss:-0.3351 G loss:-2.881\n",
      "Epoch:  0027 D loss:-0.3307 G loss:-3.176\n",
      "Epoch:  0027 D loss:-0.4053 G loss:-2.952\n",
      "Epoch:  0027 D loss:-0.3338 G loss:-2.778\n",
      "Epoch:  0027 D loss:-0.2896 G loss:-2.962\n",
      "Epoch:  0027 D loss:-0.4145 G loss:-2.553\n",
      "Epoch:  0027 D loss:-0.2587 G loss:-2.953\n",
      "Epoch:  0027 D loss:-0.3642 G loss:-2.586\n",
      "Epoch:  0027 D loss:-0.2924 G loss:-2.842\n",
      "Epoch:  0027 D loss:-0.3169 G loss:-2.765\n",
      "Epoch:  0027 D loss:-0.4076 G loss:-2.806\n",
      "Epoch:  0027 D loss:-0.353 G loss:-3.004\n",
      "Epoch:  0027 D loss:-0.3647 G loss:-3.026\n",
      "Epoch:  0027 D loss:-0.4502 G loss:-3.113\n",
      "Epoch:  0027 D loss:-0.3088 G loss:-3.012\n",
      "Epoch:  0027 D loss:-0.3248 G loss:-3.061\n",
      "Epoch:  0027 D loss:-0.3707 G loss:-2.9\n",
      "Epoch:  0027 D loss:-0.3131 G loss:-3.042\n",
      "Epoch:  0027 D loss:-0.2828 G loss:-2.795\n",
      "Epoch:  0027 D loss:-0.3464 G loss:-3.059\n",
      "Epoch:  0027 D loss:-0.4038 G loss:-2.997\n",
      "Epoch:  0027 D loss:-0.3975 G loss:-3.003\n",
      "Epoch:  0027 D loss:-0.4214 G loss:-2.991\n",
      "Epoch:  0027 D loss:-0.2267 G loss:-3.061\n",
      "Epoch:  0027 D loss:-0.3642 G loss:-2.702\n",
      "Epoch:  0027 D loss:-0.3209 G loss:-3.113\n",
      "Epoch:  0027 D loss:-0.2997 G loss:-3.001\n",
      "Epoch:  0027 D loss:-0.3991 G loss:-2.67\n",
      "Epoch:  0027 D loss:-0.3526 G loss:-2.764\n",
      "Epoch:  0027 D loss:-0.3193 G loss:-2.624\n",
      "Epoch:  0027 D loss:-0.2979 G loss:-2.977\n",
      "Epoch:  0027 D loss:-0.2955 G loss:-2.944\n",
      "Epoch:  0027 D loss:-0.3439 G loss:-2.937\n",
      "Epoch:  0027 D loss:-0.3304 G loss:-3.045\n",
      "Epoch:  0027 D loss:-0.311 G loss:-2.842\n",
      "Epoch:  0027 D loss:-0.3331 G loss:-3.076\n",
      "Epoch:  0027 D loss:-0.3155 G loss:-3.291\n",
      "Epoch:  0027 D loss:-0.3815 G loss:-3.171\n",
      "Epoch:  0027 D loss:-0.3931 G loss:-3.004\n",
      "Epoch:  0027 D loss:-0.3523 G loss:-2.866\n",
      "Epoch:  0027 D loss:-0.4071 G loss:-2.84\n",
      "Epoch:  0027 D loss:-0.3504 G loss:-2.767\n",
      "Epoch:  0027 D loss:-0.3555 G loss:-2.779\n",
      "Epoch:  0027 D loss:-0.3069 G loss:-2.858\n",
      "Epoch:  0027 D loss:-0.3333 G loss:-2.816\n",
      "Epoch:  0027 D loss:-0.2842 G loss:-2.966\n",
      "Epoch:  0027 D loss:-0.3145 G loss:-2.893\n",
      "Epoch:  0027 D loss:-0.2807 G loss:-2.941\n",
      "Epoch:  0027 D loss:-0.2961 G loss:-3.123\n",
      "Epoch:  0027 D loss:-0.3856 G loss:-3.097\n",
      "Epoch:  0027 D loss:-0.2884 G loss:-3.041\n",
      "Epoch:  0027 D loss:-0.3867 G loss:-3.031\n",
      "Epoch:  0027 D loss:-0.3655 G loss:-2.884\n",
      "Epoch:  0027 D loss:-0.3919 G loss:-2.961\n",
      "Epoch:  0027 D loss:-0.2919 G loss:-3.196\n",
      "Epoch:  0027 D loss:-0.2961 G loss:-3.214\n",
      "Epoch:  0027 D loss:-0.3344 G loss:-3.328\n",
      "Epoch:  0027 D loss:-0.3973 G loss:-2.88\n",
      "Epoch:  0027 D loss:-0.2933 G loss:-2.586\n",
      "Epoch:  0027 D loss:-0.3065 G loss:-2.956\n",
      "Epoch:  0027 D loss:-0.2995 G loss:-2.883\n",
      "Epoch:  0027 D loss:-0.3575 G loss:-2.831\n",
      "Epoch:  0027 D loss:-0.2935 G loss:-2.905\n",
      "Epoch:  0027 D loss:-0.3098 G loss:-3.251\n",
      "Epoch:  0027 D loss:-0.3151 G loss:-3.086\n",
      "Epoch:  0027 D loss:-0.2973 G loss:-3.041\n",
      "Epoch:  0027 D loss:-0.2791 G loss:-2.921\n",
      "Epoch:  0027 D loss:-0.2748 G loss:-2.847\n",
      "Epoch:  0027 D loss:-0.2508 G loss:-3.158\n",
      "Epoch:  0027 D loss:-0.4143 G loss:-2.992\n",
      "Epoch:  0027 D loss:-0.3105 G loss:-2.92\n",
      "Epoch:  0027 D loss:-0.4482 G loss:-2.46\n",
      "Epoch:  0027 D loss:-0.3372 G loss:-2.788\n",
      "Epoch:  0027 D loss:-0.3026 G loss:-2.741\n",
      "Epoch:  0027 D loss:-0.3211 G loss:-2.629\n",
      "Epoch:  0027 D loss:-0.3029 G loss:-2.726\n",
      "Epoch:  0027 D loss:-0.2997 G loss:-2.825\n",
      "Epoch:  0027 D loss:-0.4107 G loss:-2.868\n",
      "Epoch:  0027 D loss:-0.2982 G loss:-2.961\n",
      "Epoch:  0027 D loss:-0.3246 G loss:-3.082\n",
      "Epoch:  0027 D loss:-0.2788 G loss:-3.248\n",
      "Epoch:  0027 D loss:-0.3311 G loss:-2.903\n",
      "Epoch:  0027 D loss:-0.3512 G loss:-2.705\n",
      "Epoch:  0027 D loss:-0.3089 G loss:-2.841\n",
      "Epoch:  0027 D loss:-0.3092 G loss:-2.745\n",
      "Epoch:  0027 D loss:-0.2649 G loss:-2.919\n",
      "Epoch:  0027 D loss:-0.3348 G loss:-2.892\n",
      "Epoch:  0027 D loss:-0.2862 G loss:-2.958\n",
      "Epoch:  0027 D loss:-0.2937 G loss:-2.975\n",
      "Epoch:  0027 D loss:-0.2884 G loss:-3.018\n",
      "Epoch:  0027 D loss:-0.3455 G loss:-3.041\n",
      "Epoch:  0027 D loss:-0.3149 G loss:-2.979\n",
      "Epoch:  0027 D loss:-0.3329 G loss:-2.775\n",
      "Epoch:  0027 D loss:-0.3568 G loss:-3.007\n",
      "Epoch:  0027 D loss:-0.3103 G loss:-2.79\n",
      "Epoch:  0027 D loss:-0.256 G loss:-3.08\n",
      "Epoch:  0027 D loss:-0.3038 G loss:-2.991\n",
      "Epoch:  0027 D loss:-0.3312 G loss:-3.006\n",
      "Epoch:  0027 D loss:-0.2823 G loss:-2.941\n",
      "Epoch:  0027 D loss:-0.2978 G loss:-2.874\n",
      "Epoch:  0027 D loss:-0.2621 G loss:-3.036\n",
      "Epoch:  0027 D loss:-0.3176 G loss:-2.981\n",
      "Epoch:  0027 D loss:-0.2919 G loss:-3.11\n",
      "Epoch:  0027 D loss:-0.2788 G loss:-2.997\n",
      "Epoch:  0027 D loss:-0.2477 G loss:-3.04\n",
      "Epoch:  0027 D loss:-0.277 G loss:-2.766\n",
      "Epoch:  0027 D loss:-0.2658 G loss:-2.906\n",
      "Epoch:  0027 D loss:-0.2548 G loss:-2.818\n",
      "Epoch:  0027 D loss:-0.3529 G loss:-2.804\n",
      "Epoch:  0027 D loss:-0.3254 G loss:-2.777\n",
      "Epoch:  0027 D loss:-0.2749 G loss:-3.291\n",
      "Epoch:  0027 D loss:-0.3223 G loss:-3.018\n",
      "Epoch:  0027 D loss:-0.4202 G loss:-2.837\n",
      "Epoch:  0027 D loss:-0.3718 G loss:-2.858\n",
      "Epoch:  0027 D loss:-0.3303 G loss:-3.103\n",
      "Epoch:  0027 D loss:-0.2776 G loss:-2.765\n",
      "Epoch:  0027 D loss:-0.3142 G loss:-2.802\n",
      "Epoch:  0027 D loss:-0.2675 G loss:-2.739\n",
      "Epoch:  0027 D loss:-0.2747 G loss:-2.83\n",
      "Epoch:  0027 D loss:-0.4243 G loss:-2.803\n",
      "Epoch:  0027 D loss:-0.326 G loss:-2.649\n",
      "Epoch:  0027 D loss:-0.3473 G loss:-2.891\n",
      "Epoch:  0027 D loss:-0.3576 G loss:-2.853\n",
      "Epoch:  0027 D loss:-0.2935 G loss:-2.824\n",
      "Epoch:  0027 D loss:-0.2604 G loss:-2.914\n",
      "Epoch:  0027 D loss:-0.3618 G loss:-2.853\n",
      "Epoch:  0027 D loss:-0.3959 G loss:-2.759\n",
      "Epoch:  0027 D loss:-0.4195 G loss:-2.637\n",
      "Epoch:  0027 D loss:-0.4084 G loss:-2.698\n",
      "Epoch:  0027 D loss:-0.395 G loss:-2.811\n",
      "Epoch:  0027 D loss:-0.3535 G loss:-2.958\n",
      "Epoch:  0027 D loss:-0.3069 G loss:-2.941\n",
      "Epoch:  0027 D loss:-0.3506 G loss:-2.863\n",
      "Epoch:  0027 D loss:-0.3713 G loss:-2.769\n",
      "Epoch:  0027 D loss:-0.4639 G loss:-2.754\n",
      "Epoch:  0027 D loss:-0.3631 G loss:-2.801\n",
      "Epoch:  0027 D loss:-0.3614 G loss:-2.64\n",
      "Epoch:  0027 D loss:-0.4223 G loss:-2.556\n",
      "Epoch:  0027 D loss:-0.3512 G loss:-2.76\n",
      "Epoch:  0027 D loss:-0.3015 G loss:-2.582\n",
      "Epoch:  0027 D loss:-0.3786 G loss:-2.674\n",
      "Epoch:  0027 D loss:-0.3214 G loss:-2.937\n",
      "Epoch:  0027 D loss:-0.4234 G loss:-2.623\n",
      "Epoch:  0027 D loss:-0.2695 G loss:-3.026\n",
      "Epoch:  0027 D loss:-0.3732 G loss:-2.761\n",
      "Epoch:  0027 D loss:-0.4245 G loss:-2.854\n",
      "Epoch:  0027 D loss:-0.3268 G loss:-2.865\n",
      "Epoch:  0027 D loss:-0.3987 G loss:-2.64\n",
      "Epoch:  0027 D loss:-0.3929 G loss:-2.68\n",
      "Epoch:  0027 D loss:-0.404 G loss:-2.696\n",
      "Epoch:  0027 D loss:-0.3568 G loss:-2.791\n",
      "Epoch:  0027 D loss:-0.4074 G loss:-2.681\n",
      "Epoch:  0027 D loss:-0.399 G loss:-2.484\n",
      "Epoch:  0027 D loss:-0.4879 G loss:-2.619\n",
      "Epoch:  0027 D loss:-0.352 G loss:-2.792\n",
      "Epoch:  0027 D loss:-0.3504 G loss:-2.554\n",
      "Epoch:  0027 D loss:-0.3607 G loss:-2.85\n",
      "Epoch:  0027 D loss:-0.4334 G loss:-2.569\n",
      "Epoch:  0027 D loss:-0.3558 G loss:-2.978\n",
      "Epoch:  0027 D loss:-0.3505 G loss:-2.781\n",
      "Epoch:  0027 D loss:-0.4824 G loss:-2.948\n",
      "Epoch:  0027 D loss:-0.2479 G loss:-3.179\n",
      "Epoch:  0027 D loss:-0.3306 G loss:-2.998\n",
      "Epoch:  0027 D loss:-0.4009 G loss:-3.112\n",
      "Epoch:  0027 D loss:-0.476 G loss:-2.705\n",
      "Epoch:  0027 D loss:-0.3209 G loss:-2.963\n",
      "Epoch:  0027 D loss:-0.3848 G loss:-2.899\n",
      "Epoch:  0027 D loss:-0.3668 G loss:-2.773\n",
      "Epoch:  0027 D loss:-0.4044 G loss:-2.695\n",
      "Epoch:  0027 D loss:-0.358 G loss:-2.76\n",
      "Epoch:  0027 D loss:-0.4152 G loss:-2.683\n",
      "Epoch:  0027 D loss:-0.3541 G loss:-2.802\n",
      "Epoch:  0027 D loss:-0.3132 G loss:-2.778\n",
      "Epoch:  0027 D loss:-0.4268 G loss:-2.536\n",
      "Epoch:  0027 D loss:-0.3738 G loss:-2.744\n",
      "Epoch:  0027 D loss:-0.3829 G loss:-2.86\n",
      "Epoch:  0027 D loss:-0.3334 G loss:-2.913\n",
      "Epoch:  0027 D loss:-0.3537 G loss:-2.929\n",
      "Epoch:  0027 D loss:-0.3959 G loss:-2.659\n",
      "Epoch:  0027 D loss:-0.4317 G loss:-2.992\n",
      "Epoch:  0027 D loss:-0.3268 G loss:-3.095\n",
      "Epoch:  0027 D loss:-0.3255 G loss:-2.938\n",
      "Epoch:  0027 D loss:-0.3939 G loss:-2.755\n",
      "Epoch:  0027 D loss:-0.3057 G loss:-2.835\n",
      "Epoch:  0027 D loss:-0.311 G loss:-2.83\n",
      "Epoch:  0027 D loss:-0.4363 G loss:-2.543\n",
      "Epoch:  0027 D loss:-0.3246 G loss:-2.763\n",
      "Epoch:  0027 D loss:-0.3817 G loss:-2.912\n",
      "Epoch:  0027 D loss:-0.4931 G loss:-2.748\n",
      "Epoch:  0027 D loss:-0.3843 G loss:-2.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0027 D loss:-0.3757 G loss:-2.813\n",
      "Epoch:  0027 D loss:-0.2771 G loss:-3.154\n",
      "Epoch:  0027 D loss:-0.3557 G loss:-2.934\n",
      "Epoch:  0027 D loss:-0.3301 G loss:-2.941\n",
      "Epoch:  0027 D loss:-0.4635 G loss:-2.832\n",
      "Epoch:  0027 D loss:-0.3893 G loss:-2.864\n",
      "Epoch:  0027 D loss:-0.349 G loss:-2.978\n",
      "Epoch:  0027 D loss:-0.3305 G loss:-2.924\n",
      "Epoch:  0027 D loss:-0.3962 G loss:-2.617\n",
      "Epoch:  0027 D loss:-0.4732 G loss:-2.854\n",
      "Epoch:  0027 D loss:-0.3374 G loss:-2.885\n",
      "Epoch:  0027 D loss:-0.3749 G loss:-2.958\n",
      "Epoch:  0027 D loss:-0.3941 G loss:-2.796\n",
      "Epoch:  0027 D loss:-0.416 G loss:-2.91\n",
      "Epoch:  0027 D loss:-0.3739 G loss:-2.888\n",
      "Epoch:  0027 D loss:-0.4193 G loss:-2.684\n",
      "Epoch:  0027 D loss:-0.4168 G loss:-2.691\n",
      "Epoch:  0027 D loss:-0.3083 G loss:-2.912\n",
      "Epoch:  0027 D loss:-0.3796 G loss:-2.858\n",
      "Epoch:  0027 D loss:-0.3263 G loss:-2.627\n",
      "Epoch:  0027 D loss:-0.3742 G loss:-2.709\n",
      "Epoch:  0027 D loss:-0.3079 G loss:-2.854\n",
      "Epoch:  0027 D loss:-0.3073 G loss:-2.733\n",
      "Epoch:  0027 D loss:-0.4007 G loss:-2.832\n",
      "Epoch:  0027 D loss:-0.3232 G loss:-2.942\n",
      "Epoch:  0027 D loss:-0.3503 G loss:-2.979\n",
      "Epoch:  0027 D loss:-0.3526 G loss:-2.865\n",
      "Epoch:  0027 D loss:-0.3869 G loss:-2.722\n",
      "Epoch:  0027 D loss:-0.3861 G loss:-2.767\n",
      "Epoch:  0027 D loss:-0.3396 G loss:-2.962\n",
      "Epoch:  0027 D loss:-0.4025 G loss:-2.927\n",
      "Epoch:  0027 D loss:-0.371 G loss:-2.818\n",
      "Epoch:  0027 D loss:-0.4068 G loss:-2.974\n",
      "Epoch:  0027 D loss:-0.2509 G loss:-2.913\n",
      "Epoch:  0027 D loss:-0.3304 G loss:-3.044\n",
      "Epoch:  0027 D loss:-0.3875 G loss:-2.97\n",
      "Epoch:  0027 D loss:-0.3866 G loss:-2.852\n",
      "Epoch:  0027 D loss:-0.3944 G loss:-2.729\n",
      "Epoch:  0027 D loss:-0.4134 G loss:-2.704\n",
      "Epoch:  0027 D loss:-0.3804 G loss:-2.637\n",
      "Epoch:  0027 D loss:-0.4263 G loss:-2.715\n",
      "Epoch:  0027 D loss:-0.3688 G loss:-2.714\n",
      "Epoch:  0027 D loss:-0.3482 G loss:-2.742\n",
      "Epoch:  0027 D loss:-0.3784 G loss:-2.62\n",
      "Epoch:  0027 D loss:-0.3678 G loss:-2.479\n",
      "Epoch:  0027 D loss:-0.4841 G loss:-2.715\n",
      "Epoch:  0027 D loss:-0.4491 G loss:-2.598\n",
      "Epoch:  0027 D loss:-0.3941 G loss:-2.642\n",
      "Epoch:  0027 D loss:-0.4639 G loss:-2.679\n",
      "Epoch:  0027 D loss:-0.2999 G loss:-2.687\n",
      "Epoch:  0027 D loss:-0.3425 G loss:-3.11\n",
      "Epoch:  0027 D loss:-0.4077 G loss:-2.972\n",
      "Epoch:  0027 D loss:-0.3514 G loss:-2.852\n",
      "Epoch:  0027 D loss:-0.2972 G loss:-3.066\n",
      "Epoch:  0027 D loss:-0.3501 G loss:-2.905\n",
      "Epoch:  0027 D loss:-0.3597 G loss:-2.817\n",
      "Epoch:  0027 D loss:-0.3448 G loss:-2.487\n",
      "Epoch:  0027 D loss:-0.3556 G loss:-2.74\n",
      "Epoch:  0027 D loss:-0.3688 G loss:-2.462\n",
      "Epoch:  0027 D loss:-0.4393 G loss:-2.705\n",
      "Epoch:  0027 D loss:-0.4044 G loss:-2.56\n",
      "Epoch:  0027 D loss:-0.3832 G loss:-2.641\n",
      "Epoch:  0027 D loss:-0.3426 G loss:-2.677\n",
      "Epoch:  0027 D loss:-0.3734 G loss:-2.73\n",
      "Epoch:  0027 D loss:-0.3465 G loss:-2.749\n",
      "Epoch:  0027 D loss:-0.3828 G loss:-2.855\n",
      "Epoch:  0027 D loss:-0.3717 G loss:-2.95\n",
      "Epoch:  0027 D loss:-0.4041 G loss:-2.988\n",
      "Epoch:  0027 D loss:-0.3257 G loss:-3.03\n",
      "Epoch:  0027 D loss:-0.5353 G loss:-2.814\n",
      "Epoch:  0027 D loss:-0.3182 G loss:-2.948\n",
      "Epoch:  0027 D loss:-0.346 G loss:-2.733\n",
      "Epoch:  0027 D loss:-0.3849 G loss:-2.745\n",
      "Epoch:  0027 D loss:-0.3211 G loss:-2.661\n",
      "Epoch:  0027 D loss:-0.3015 G loss:-2.818\n",
      "Epoch:  0027 D loss:-0.4648 G loss:-2.796\n",
      "Epoch:  0027 D loss:-0.3601 G loss:-3.089\n",
      "Epoch:  0027 D loss:-0.4991 G loss:-2.891\n",
      "Epoch:  0027 D loss:-0.3774 G loss:-2.85\n",
      "Epoch:  0027 D loss:-0.3866 G loss:-2.698\n",
      "Epoch:  0027 D loss:-0.3793 G loss:-3.019\n",
      "Epoch:  0027 D loss:-0.3213 G loss:-3.003\n",
      "Epoch:  0027 D loss:-0.3069 G loss:-3.206\n",
      "Epoch:  0027 D loss:-0.3482 G loss:-3.025\n",
      "Epoch:  0027 D loss:-0.2713 G loss:-2.929\n",
      "Epoch:  0027 D loss:-0.4351 G loss:-2.88\n",
      "Epoch:  0027 D loss:-0.305 G loss:-2.864\n",
      "Epoch:  0027 D loss:-0.3674 G loss:-2.878\n",
      "Epoch:  0027 D loss:-0.464 G loss:-2.664\n",
      "Epoch:  0027 D loss:-0.3696 G loss:-2.827\n",
      "Epoch:  0027 D loss:-0.3314 G loss:-2.709\n",
      "Epoch:  0027 D loss:-0.3094 G loss:-2.706\n",
      "Epoch:  0027 D loss:-0.3687 G loss:-2.782\n",
      "Epoch:  0027 D loss:-0.3233 G loss:-2.793\n",
      "Epoch:  0027 D loss:-0.3914 G loss:-2.872\n",
      "Epoch:  0027 D loss:-0.309 G loss:-2.993\n",
      "Epoch:  0027 D loss:-0.3644 G loss:-3.113\n",
      "Epoch:  0027 D loss:-0.433 G loss:-3.311\n",
      "Epoch:  0027 D loss:-0.3645 G loss:-2.745\n",
      "Epoch:  0027 D loss:-0.3354 G loss:-3.226\n",
      "Epoch:  0027 D loss:-0.3754 G loss:-3.134\n",
      "Epoch:  0027 D loss:-0.3236 G loss:-2.889\n",
      "Epoch:  0027 D loss:-0.3594 G loss:-2.841\n",
      "Epoch:  0027 D loss:-0.3098 G loss:-2.804\n",
      "Epoch:  0027 D loss:-0.3444 G loss:-2.8\n",
      "Epoch:  0027 D loss:-0.4439 G loss:-2.89\n",
      "Epoch:  0027 D loss:-0.4483 G loss:-2.894\n",
      "Epoch:  0027 D loss:-0.3571 G loss:-2.854\n",
      "Epoch:  0027 D loss:-0.4131 G loss:-3.024\n",
      "Epoch:  0027 D loss:-0.3631 G loss:-2.823\n",
      "Epoch:  0027 D loss:-0.3636 G loss:-2.943\n",
      "Epoch:  0027 D loss:-0.3096 G loss:-2.926\n",
      "Epoch:  0027 D loss:-0.3863 G loss:-2.978\n",
      "Epoch:  0027 D loss:-0.4015 G loss:-2.823\n",
      "Epoch:  0027 D loss:-0.4111 G loss:-2.764\n",
      "Epoch:  0027 D loss:-0.3695 G loss:-2.833\n",
      "Epoch:  0027 D loss:-0.3222 G loss:-3.062\n",
      "Epoch:  0027 D loss:-0.356 G loss:-3.036\n",
      "Epoch:  0027 D loss:-0.3477 G loss:-2.878\n",
      "Epoch:  0027 D loss:-0.245 G loss:-3.128\n",
      "Epoch:  0027 D loss:-0.4149 G loss:-3.054\n",
      "Epoch:  0027 D loss:-0.3949 G loss:-3.07\n",
      "Epoch:  0027 D loss:-0.2863 G loss:-2.946\n",
      "Epoch:  0027 D loss:-0.2821 G loss:-3.069\n",
      "Epoch:  0027 D loss:-0.4152 G loss:-3.088\n",
      "Epoch:  0027 D loss:-0.317 G loss:-2.85\n",
      "Epoch:  0027 D loss:-0.3831 G loss:-2.854\n",
      "Epoch:  0027 D loss:-0.5132 G loss:-2.676\n",
      "Epoch:  0027 D loss:-0.352 G loss:-2.955\n",
      "Epoch:  0027 D loss:-0.3156 G loss:-2.982\n",
      "Epoch:  0027 D loss:-0.3056 G loss:-3.228\n",
      "Epoch:  0027 D loss:-0.4419 G loss:-3.023\n",
      "Epoch:  0027 D loss:-0.3868 G loss:-3.05\n",
      "Epoch:  0027 D loss:-0.4493 G loss:-2.719\n",
      "Epoch:  0027 D loss:-0.3397 G loss:-2.718\n",
      "Epoch:  0027 D loss:-0.3673 G loss:-2.735\n",
      "Epoch:  0027 D loss:-0.357 G loss:-2.656\n",
      "Epoch:  0027 D loss:-0.3843 G loss:-2.638\n",
      "Epoch:  0027 D loss:-0.4769 G loss:-2.447\n",
      "Epoch:  0027 D loss:-0.3094 G loss:-2.848\n",
      "Epoch:  0027 D loss:-0.4619 G loss:-2.774\n",
      "Epoch:  0027 D loss:-0.4013 G loss:-3.064\n",
      "Epoch:  0027 D loss:-0.2934 G loss:-3.127\n",
      "Epoch:  0027 D loss:-0.4637 G loss:-3.04\n",
      "Epoch:  0027 D loss:-0.5139 G loss:-2.855\n",
      "Epoch:  0027 D loss:-0.4054 G loss:-2.983\n",
      "Epoch:  0027 D loss:-0.4717 G loss:-2.821\n",
      "Epoch:  0027 D loss:-0.2902 G loss:-3.066\n",
      "Epoch:  0027 D loss:-0.3456 G loss:-2.567\n",
      "Epoch:  0027 D loss:-0.3668 G loss:-2.456\n",
      "Epoch:  0027 D loss:-0.3628 G loss:-2.757\n",
      "Epoch:  0027 D loss:-0.4769 G loss:-2.626\n",
      "Epoch:  0027 D loss:-0.4518 G loss:-2.585\n",
      "Epoch:  0027 D loss:-0.3226 G loss:-2.685\n",
      "Epoch:  0027 D loss:-0.3956 G loss:-2.539\n",
      "Epoch:  0027 D loss:-0.4105 G loss:-2.774\n",
      "Epoch:  0027 D loss:-0.3853 G loss:-3.033\n",
      "Epoch:  0027 D loss:-0.4758 G loss:-2.839\n",
      "Epoch:  0027 D loss:-0.3306 G loss:-3.044\n",
      "Epoch:  0027 D loss:-0.3352 G loss:-2.853\n",
      "Epoch:  0027 D loss:-0.4438 G loss:-3.059\n",
      "Epoch:  0027 D loss:-0.5221 G loss:-2.834\n",
      "Epoch:  0027 D loss:-0.3544 G loss:-3.082\n",
      "Epoch:  0027 D loss:-0.4808 G loss:-2.704\n",
      "Epoch:  0027 D loss:-0.4327 G loss:-2.821\n",
      "Epoch:  0027 D loss:-0.3748 G loss:-2.761\n",
      "Epoch:  0027 D loss:-0.4248 G loss:-2.509\n",
      "Epoch:  0027 D loss:-0.3104 G loss:-2.719\n",
      "Epoch:  0027 D loss:-0.3746 G loss:-2.56\n",
      "Epoch:  0027 D loss:-0.551 G loss:-2.657\n",
      "Epoch:  0027 D loss:-0.4235 G loss:-2.769\n",
      "Epoch:  0027 D loss:-0.4052 G loss:-2.788\n",
      "Epoch:  0027 D loss:-0.3511 G loss:-3.083\n",
      "Epoch:  0027 D loss:-0.4344 G loss:-2.718\n",
      "Epoch:  0027 D loss:-0.4329 G loss:-3.211\n",
      "Epoch:  0027 D loss:-0.3523 G loss:-2.744\n",
      "Epoch:  0027 D loss:-0.3915 G loss:-2.57\n",
      "Epoch:  0027 D loss:-0.3936 G loss:-2.81\n",
      "Epoch:  0027 D loss:-0.4154 G loss:-3.085\n",
      "Epoch:  0027 D loss:-0.3195 G loss:-3.061\n",
      "Epoch:  0027 D loss:-0.358 G loss:-3.213\n",
      "Epoch:  0027 D loss:-0.5089 G loss:-2.746\n",
      "Epoch:  0027 D loss:-0.4942 G loss:-2.861\n",
      "Epoch:  0027 D loss:-0.4394 G loss:-2.648\n",
      "Epoch:  0027 D loss:-0.4244 G loss:-2.776\n",
      "Epoch:  0027 D loss:-0.3792 G loss:-2.68\n",
      "Epoch:  0027 D loss:-0.4239 G loss:-2.641\n",
      "Epoch:  0027 D loss:-0.5737 G loss:-2.549\n",
      "Epoch:  0027 D loss:-0.4267 G loss:-2.659\n",
      "Epoch:  0027 D loss:-0.4581 G loss:-2.639\n",
      "Epoch:  0027 D loss:-0.5613 G loss:-2.641\n",
      "Epoch:  0027 D loss:-0.44 G loss:-2.857\n",
      "Epoch:  0027 D loss:-0.4916 G loss:-2.724\n",
      "Epoch:  0027 D loss:-0.3759 G loss:-2.985\n",
      "Epoch:  0027 D loss:-0.3384 G loss:-2.645\n",
      "Epoch:  0027 D loss:-0.4323 G loss:-2.489\n",
      "Epoch:  0027 D loss:-0.5137 G loss:-2.717\n",
      "Epoch:  0027 D loss:-0.482 G loss:-2.62\n",
      "Epoch:  0027 D loss:-0.489 G loss:-2.82\n",
      "Epoch:  0027 D loss:-0.4199 G loss:-2.616\n",
      "Epoch:  0027 D loss:-0.5066 G loss:-2.729\n",
      "Epoch:  0027 D loss:-0.3738 G loss:-2.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0027 D loss:-0.3945 G loss:-2.99\n",
      "Epoch:  0027 D loss:-0.4377 G loss:-2.848\n",
      "Epoch:  0027 D loss:-0.4393 G loss:-3.065\n",
      "Epoch:  0027 D loss:-0.4815 G loss:-2.784\n",
      "Epoch:  0027 D loss:-0.5133 G loss:-2.698\n",
      "Epoch:  0027 D loss:-0.4859 G loss:-2.632\n",
      "Epoch:  0027 D loss:-0.4032 G loss:-2.735\n",
      "Epoch:  0027 D loss:-0.5672 G loss:-2.579\n",
      "Epoch:  0027 D loss:-0.3998 G loss:-2.519\n",
      "Epoch:  0027 D loss:-0.4121 G loss:-2.44\n",
      "Epoch:  0027 D loss:-0.5353 G loss:-2.695\n",
      "Epoch:  0027 D loss:-0.5467 G loss:-2.678\n",
      "Epoch:  0027 D loss:-0.4394 G loss:-2.505\n",
      "Epoch:  0027 D loss:-0.5762 G loss:-2.596\n",
      "Epoch:  0027 D loss:-0.5828 G loss:-2.661\n",
      "Epoch:  0027 D loss:-0.4867 G loss:-2.741\n",
      "Epoch:  0027 D loss:-0.3962 G loss:-2.91\n",
      "Epoch:  0027 D loss:-0.4339 G loss:-2.51\n",
      "Epoch:  0027 D loss:-0.4892 G loss:-2.494\n",
      "Epoch:  0027 D loss:-0.5319 G loss:-3.07\n",
      "Epoch:  0027 D loss:-0.4408 G loss:-2.708\n",
      "Epoch:  0027 D loss:-0.5052 G loss:-3.006\n",
      "Epoch:  0027 D loss:-0.6935 G loss:-2.659\n",
      "Epoch:  0027 D loss:-0.5004 G loss:-2.694\n",
      "Epoch:  0027 D loss:-0.4673 G loss:-2.655\n",
      "Epoch:  0027 D loss:-0.3942 G loss:-2.551\n",
      "Epoch:  0027 D loss:-0.4571 G loss:-2.676\n",
      "Epoch:  0027 D loss:-0.5004 G loss:-2.128\n",
      "Epoch:  0027 D loss:-0.4612 G loss:-2.445\n",
      "Epoch:  0027 D loss:-0.6147 G loss:-2.46\n",
      "Epoch:  0027 D loss:-0.4957 G loss:-2.774\n",
      "Epoch:  0027 D loss:-0.555 G loss:-2.725\n",
      "Epoch:  0027 D loss:-0.4347 G loss:-2.918\n",
      "Epoch:  0027 D loss:-0.3965 G loss:-2.895\n",
      "Epoch:  0027 D loss:-0.5118 G loss:-2.738\n",
      "Epoch:  0027 D loss:-0.4861 G loss:-2.563\n",
      "Epoch:  0027 D loss:-0.4394 G loss:-2.7\n",
      "Epoch:  0027 D loss:-0.5196 G loss:-2.514\n",
      "Epoch:  0027 D loss:-0.5389 G loss:-2.466\n",
      "Epoch:  0027 D loss:-0.4255 G loss:-2.42\n",
      "Epoch:  0027 D loss:-0.4861 G loss:-2.704\n",
      "Epoch:  0027 D loss:-0.3943 G loss:-2.535\n",
      "Epoch:  0027 D loss:-0.4933 G loss:-2.531\n",
      "Epoch:  0027 D loss:-0.3602 G loss:-2.642\n",
      "Epoch:  0027 D loss:-0.4164 G loss:-2.968\n",
      "Epoch:  0027 D loss:-0.4149 G loss:-2.936\n",
      "Epoch:  0027 D loss:-0.4284 G loss:-2.703\n",
      "Epoch:  0027 D loss:-0.4008 G loss:-3.07\n",
      "Epoch:  0027 D loss:-0.402 G loss:-2.806\n",
      "Epoch:  0027 D loss:-0.5474 G loss:-2.604\n",
      "Epoch:  0027 D loss:-0.5879 G loss:-2.77\n",
      "Epoch:  0027 D loss:-0.4147 G loss:-2.778\n",
      "Epoch:  0027 D loss:-0.4962 G loss:-2.533\n",
      "Epoch:  0027 D loss:-0.4874 G loss:-2.535\n",
      "Epoch:  0027 D loss:-0.4486 G loss:-2.493\n",
      "Epoch:  0027 D loss:-0.4739 G loss:-2.377\n",
      "Epoch:  0027 D loss:-0.4941 G loss:-2.347\n",
      "Epoch:  0027 D loss:-0.3841 G loss:-2.665\n",
      "Epoch:  0027 D loss:-0.4472 G loss:-2.789\n",
      "Epoch:  0027 D loss:-0.3198 G loss:-2.659\n",
      "Epoch:  0027 D loss:-0.4208 G loss:-2.956\n",
      "Epoch:  0027 D loss:-0.3526 G loss:-2.877\n",
      "Epoch:  0027 D loss:-0.333 G loss:-2.824\n",
      "Epoch:  0027 D loss:-0.372 G loss:-3.002\n",
      "Epoch:  0027 D loss:-0.4951 G loss:-2.818\n",
      "Epoch:  0027 D loss:-0.3851 G loss:-2.916\n",
      "Epoch:  0027 D loss:-0.405 G loss:-2.699\n",
      "Epoch:  0027 D loss:-0.308 G loss:-2.977\n",
      "Epoch:  0027 D loss:-0.4182 G loss:-2.867\n",
      "Epoch:  0027 D loss:-0.3166 G loss:-2.89\n",
      "Epoch:  0027 D loss:-0.4901 G loss:-2.859\n",
      "Epoch:  0027 D loss:-0.3879 G loss:-2.631\n",
      "Epoch:  0027 D loss:-0.321 G loss:-2.667\n",
      "Epoch:  0027 D loss:-0.3218 G loss:-2.782\n",
      "Epoch:  0027 D loss:-0.3222 G loss:-2.673\n",
      "Epoch:  0027 D loss:-0.4056 G loss:-2.605\n",
      "Epoch:  0027 D loss:-0.3865 G loss:-2.761\n",
      "Epoch:  0027 D loss:-0.4258 G loss:-2.705\n",
      "Epoch:  0027 D loss:-0.3151 G loss:-2.988\n",
      "Epoch:  0027 D loss:-0.3403 G loss:-3.088\n",
      "Epoch:  0027 D loss:-0.293 G loss:-2.727\n",
      "Epoch:  0027 D loss:-0.3397 G loss:-2.803\n",
      "Epoch:  0027 D loss:-0.3394 G loss:-2.812\n",
      "Epoch:  0027 D loss:-0.3694 G loss:-2.825\n",
      "Epoch:  0027 D loss:-0.4139 G loss:-2.699\n",
      "Epoch:  0027 D loss:-0.3523 G loss:-2.739\n",
      "Epoch:  0027 D loss:-0.4002 G loss:-2.863\n",
      "Epoch:  0027 D loss:-0.396 G loss:-2.612\n",
      "Epoch:  0027 D loss:-0.3625 G loss:-2.825\n",
      "Epoch:  0027 D loss:-0.4216 G loss:-2.967\n",
      "Epoch:  0027 D loss:-0.4308 G loss:-2.966\n",
      "Epoch:  0027 D loss:-0.4128 G loss:-2.625\n",
      "Epoch:  0027 D loss:-0.4283 G loss:-2.809\n",
      "Epoch:  0027 D loss:-0.3836 G loss:-2.613\n",
      "Epoch:  0027 D loss:-0.3088 G loss:-2.591\n",
      "Epoch:  0027 D loss:-0.3499 G loss:-2.753\n",
      "Epoch:  0027 D loss:-0.3299 G loss:-2.79\n",
      "Epoch:  0027 D loss:-0.2948 G loss:-3.134\n",
      "Epoch:  0027 D loss:-0.3294 G loss:-2.698\n",
      "Epoch:  0027 D loss:-0.2834 G loss:-2.911\n",
      "Epoch:  0027 D loss:-0.3766 G loss:-2.86\n",
      "Epoch:  0027 D loss:-0.4636 G loss:-2.827\n",
      "Epoch:  0027 D loss:-0.3943 G loss:-2.765\n",
      "Epoch:  0027 D loss:-0.3786 G loss:-2.728\n",
      "Epoch:  0027 D loss:-0.4465 G loss:-2.572\n",
      "Epoch:  0027 D loss:-0.3941 G loss:-2.668\n",
      "Epoch:  0027 D loss:-0.337 G loss:-2.59\n",
      "Epoch:  0027 D loss:-0.3658 G loss:-2.468\n",
      "Epoch:  0027 D loss:-0.513 G loss:-2.434\n",
      "Epoch:  0027 D loss:-0.2891 G loss:-2.882\n",
      "Epoch:  0027 D loss:-0.3591 G loss:-2.964\n",
      "Epoch:  0027 D loss:-0.4385 G loss:-2.836\n",
      "Epoch:  0027 D loss:-0.3487 G loss:-2.896\n",
      "Epoch:  0027 D loss:-0.4465 G loss:-2.812\n",
      "Epoch:  0027 D loss:-0.3208 G loss:-2.951\n",
      "Epoch:  0027 D loss:-0.3595 G loss:-2.809\n",
      "Epoch:  0027 D loss:-0.4848 G loss:-2.727\n",
      "Epoch:  0027 D loss:-0.4202 G loss:-2.754\n",
      "Epoch:  0027 D loss:-0.3654 G loss:-2.709\n",
      "Epoch:  0027 D loss:-0.3254 G loss:-2.625\n",
      "Epoch:  0027 D loss:-0.4397 G loss:-2.53\n",
      "Epoch:  0027 D loss:-0.3353 G loss:-2.978\n",
      "Epoch:  0027 D loss:-0.3503 G loss:-2.916\n",
      "Epoch:  0027 D loss:-0.3776 G loss:-2.903\n",
      "Epoch:  0027 D loss:-0.3445 G loss:-2.647\n",
      "Epoch:  0027 D loss:-0.3436 G loss:-2.727\n",
      "Epoch:  0027 D loss:-0.365 G loss:-2.763\n",
      "Epoch:  0027 D loss:-0.4461 G loss:-2.776\n",
      "Epoch:  0027 D loss:-0.3786 G loss:-2.798\n",
      "Epoch:  0028 D loss:-0.3792 G loss:-2.55\n",
      "Epoch:  0028 D loss:-0.3763 G loss:-2.838\n",
      "Epoch:  0028 D loss:-0.3242 G loss:-2.711\n",
      "Epoch:  0028 D loss:-0.4895 G loss:-2.503\n",
      "Epoch:  0028 D loss:-0.4611 G loss:-2.379\n",
      "Epoch:  0028 D loss:-0.4582 G loss:-2.54\n",
      "Epoch:  0028 D loss:-0.5917 G loss:-2.358\n",
      "Epoch:  0028 D loss:-0.3815 G loss:-2.8\n",
      "Epoch:  0028 D loss:-0.3484 G loss:-2.645\n",
      "Epoch:  0028 D loss:-0.4101 G loss:-2.756\n",
      "Epoch:  0028 D loss:-0.3834 G loss:-2.979\n",
      "Epoch:  0028 D loss:-0.4708 G loss:-2.986\n",
      "Epoch:  0028 D loss:-0.4131 G loss:-2.756\n",
      "Epoch:  0028 D loss:-0.5328 G loss:-2.521\n",
      "Epoch:  0028 D loss:-0.3991 G loss:-2.579\n",
      "Epoch:  0028 D loss:-0.4537 G loss:-2.68\n",
      "Epoch:  0028 D loss:-0.5281 G loss:-2.497\n",
      "Epoch:  0028 D loss:-0.5054 G loss:-2.397\n",
      "Epoch:  0028 D loss:-0.3803 G loss:-2.626\n",
      "Epoch:  0028 D loss:-0.4373 G loss:-2.478\n",
      "Epoch:  0028 D loss:-0.4043 G loss:-2.452\n",
      "Epoch:  0028 D loss:-0.4445 G loss:-2.31\n",
      "Epoch:  0028 D loss:-0.4222 G loss:-2.49\n",
      "Epoch:  0028 D loss:-0.4007 G loss:-2.664\n",
      "Epoch:  0028 D loss:-0.5221 G loss:-2.604\n",
      "Epoch:  0028 D loss:-0.4428 G loss:-2.576\n",
      "Epoch:  0028 D loss:-0.2668 G loss:-3.133\n",
      "Epoch:  0028 D loss:-0.3677 G loss:-2.855\n",
      "Epoch:  0028 D loss:-0.3486 G loss:-3.289\n",
      "Epoch:  0028 D loss:-0.3598 G loss:-2.866\n",
      "Epoch:  0028 D loss:-0.5686 G loss:-2.723\n",
      "Epoch:  0028 D loss:-0.4302 G loss:-2.977\n",
      "Epoch:  0028 D loss:-0.4279 G loss:-2.62\n",
      "Epoch:  0028 D loss:-0.3875 G loss:-2.824\n",
      "Epoch:  0028 D loss:-0.3273 G loss:-2.839\n",
      "Epoch:  0028 D loss:-0.4601 G loss:-2.674\n",
      "Epoch:  0028 D loss:-0.4656 G loss:-2.574\n",
      "Epoch:  0028 D loss:-0.5104 G loss:-2.428\n",
      "Epoch:  0028 D loss:-0.5278 G loss:-2.137\n",
      "Epoch:  0028 D loss:-0.475 G loss:-2.315\n",
      "Epoch:  0028 D loss:-0.4237 G loss:-2.204\n",
      "Epoch:  0028 D loss:-0.3869 G loss:-2.627\n",
      "Epoch:  0028 D loss:-0.4735 G loss:-2.605\n",
      "Epoch:  0028 D loss:-0.5496 G loss:-2.569\n",
      "Epoch:  0028 D loss:-0.4748 G loss:-2.519\n",
      "Epoch:  0028 D loss:-0.5428 G loss:-2.542\n",
      "Epoch:  0028 D loss:-0.5306 G loss:-2.649\n",
      "Epoch:  0028 D loss:-0.4662 G loss:-2.756\n",
      "Epoch:  0028 D loss:-0.4652 G loss:-2.745\n",
      "Epoch:  0028 D loss:-0.3905 G loss:-2.863\n",
      "Epoch:  0028 D loss:-0.4231 G loss:-2.726\n",
      "Epoch:  0028 D loss:-0.363 G loss:-2.796\n",
      "Epoch:  0028 D loss:-0.3634 G loss:-2.756\n",
      "Epoch:  0028 D loss:-0.5225 G loss:-2.528\n",
      "Epoch:  0028 D loss:-0.4132 G loss:-2.697\n",
      "Epoch:  0028 D loss:-0.4262 G loss:-2.532\n",
      "Epoch:  0028 D loss:-0.4152 G loss:-2.569\n",
      "Epoch:  0028 D loss:-0.4907 G loss:-2.587\n",
      "Epoch:  0028 D loss:-0.4111 G loss:-2.321\n",
      "Epoch:  0028 D loss:-0.5232 G loss:-2.376\n",
      "Epoch:  0028 D loss:-0.3754 G loss:-2.593\n",
      "Epoch:  0028 D loss:-0.4215 G loss:-2.554\n",
      "Epoch:  0028 D loss:-0.3618 G loss:-2.797\n",
      "Epoch:  0028 D loss:-0.4488 G loss:-2.807\n",
      "Epoch:  0028 D loss:-0.4118 G loss:-2.749\n",
      "Epoch:  0028 D loss:-0.3892 G loss:-2.853\n",
      "Epoch:  0028 D loss:-0.423 G loss:-2.763\n",
      "Epoch:  0028 D loss:-0.4533 G loss:-3.031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0028 D loss:-0.2902 G loss:-3.116\n",
      "Epoch:  0028 D loss:-0.4039 G loss:-2.945\n",
      "Epoch:  0028 D loss:-0.3349 G loss:-2.879\n",
      "Epoch:  0028 D loss:-0.4562 G loss:-2.9\n",
      "Epoch:  0028 D loss:-0.409 G loss:-2.88\n",
      "Epoch:  0028 D loss:-0.3317 G loss:-2.936\n",
      "Epoch:  0028 D loss:-0.2909 G loss:-2.991\n",
      "Epoch:  0028 D loss:-0.4117 G loss:-2.829\n",
      "Epoch:  0028 D loss:-0.3664 G loss:-2.868\n",
      "Epoch:  0028 D loss:-0.4055 G loss:-2.604\n",
      "Epoch:  0028 D loss:-0.4938 G loss:-2.658\n",
      "Epoch:  0028 D loss:-0.4688 G loss:-2.582\n",
      "Epoch:  0028 D loss:-0.4711 G loss:-2.953\n",
      "Epoch:  0028 D loss:-0.4018 G loss:-3.069\n",
      "Epoch:  0028 D loss:-0.4757 G loss:-2.694\n",
      "Epoch:  0028 D loss:-0.3912 G loss:-2.774\n",
      "Epoch:  0028 D loss:-0.3228 G loss:-3.054\n",
      "Epoch:  0028 D loss:-0.3345 G loss:-2.996\n",
      "Epoch:  0028 D loss:-0.3304 G loss:-3.093\n",
      "Epoch:  0028 D loss:-0.333 G loss:-3.052\n",
      "Epoch:  0028 D loss:-0.3057 G loss:-3.151\n",
      "Epoch:  0028 D loss:-0.3495 G loss:-2.942\n",
      "Epoch:  0028 D loss:-0.2864 G loss:-3.008\n",
      "Epoch:  0028 D loss:-0.3968 G loss:-2.87\n",
      "Epoch:  0028 D loss:-0.4045 G loss:-2.933\n",
      "Epoch:  0028 D loss:-0.4256 G loss:-2.572\n",
      "Epoch:  0028 D loss:-0.3263 G loss:-2.837\n",
      "Epoch:  0028 D loss:-0.2886 G loss:-3.025\n",
      "Epoch:  0028 D loss:-0.381 G loss:-2.747\n",
      "Epoch:  0028 D loss:-0.3429 G loss:-2.981\n",
      "Epoch:  0028 D loss:-0.3783 G loss:-2.976\n",
      "Epoch:  0028 D loss:-0.348 G loss:-3.062\n",
      "Epoch:  0028 D loss:-0.3057 G loss:-3.239\n",
      "Epoch:  0028 D loss:-0.3357 G loss:-3.201\n",
      "Epoch:  0028 D loss:-0.3449 G loss:-3.088\n",
      "Epoch:  0028 D loss:-0.3915 G loss:-2.914\n",
      "Epoch:  0028 D loss:-0.3767 G loss:-3.095\n",
      "Epoch:  0028 D loss:-0.3666 G loss:-2.841\n",
      "Epoch:  0028 D loss:-0.3792 G loss:-2.646\n",
      "Epoch:  0028 D loss:-0.2816 G loss:-2.874\n",
      "Epoch:  0028 D loss:-0.3763 G loss:-2.568\n",
      "Epoch:  0028 D loss:-0.467 G loss:-2.618\n",
      "Epoch:  0028 D loss:-0.4006 G loss:-2.741\n",
      "Epoch:  0028 D loss:-0.3413 G loss:-2.746\n",
      "Epoch:  0028 D loss:-0.3229 G loss:-3.073\n",
      "Epoch:  0028 D loss:-0.3714 G loss:-3.271\n",
      "Epoch:  0028 D loss:-0.3706 G loss:-3.133\n",
      "Epoch:  0028 D loss:-0.5261 G loss:-2.977\n",
      "Epoch:  0028 D loss:-0.4001 G loss:-3.222\n",
      "Epoch:  0028 D loss:-0.4225 G loss:-2.981\n",
      "Epoch:  0028 D loss:-0.3502 G loss:-2.955\n",
      "Epoch:  0028 D loss:-0.416 G loss:-2.925\n",
      "Epoch:  0028 D loss:-0.4473 G loss:-2.905\n",
      "Epoch:  0028 D loss:-0.2925 G loss:-3.001\n",
      "Epoch:  0028 D loss:-0.3034 G loss:-2.993\n",
      "Epoch:  0028 D loss:-0.3552 G loss:-2.845\n",
      "Epoch:  0028 D loss:-0.3275 G loss:-2.812\n",
      "Epoch:  0028 D loss:-0.379 G loss:-2.699\n",
      "Epoch:  0028 D loss:-0.389 G loss:-2.941\n",
      "Epoch:  0028 D loss:-0.3862 G loss:-2.975\n",
      "Epoch:  0028 D loss:-0.4212 G loss:-2.91\n",
      "Epoch:  0028 D loss:-0.3412 G loss:-3.05\n",
      "Epoch:  0028 D loss:-0.3903 G loss:-2.94\n",
      "Epoch:  0028 D loss:-0.4054 G loss:-3.028\n",
      "Epoch:  0028 D loss:-0.3862 G loss:-3.006\n",
      "Epoch:  0028 D loss:-0.3817 G loss:-2.913\n",
      "Epoch:  0028 D loss:-0.3695 G loss:-2.87\n",
      "Epoch:  0028 D loss:-0.4272 G loss:-2.838\n",
      "Epoch:  0028 D loss:-0.3848 G loss:-2.808\n",
      "Epoch:  0028 D loss:-0.3502 G loss:-2.929\n",
      "Epoch:  0028 D loss:-0.4111 G loss:-3.087\n",
      "Epoch:  0028 D loss:-0.4269 G loss:-2.84\n",
      "Epoch:  0028 D loss:-0.3553 G loss:-3.048\n",
      "Epoch:  0028 D loss:-0.4557 G loss:-3.096\n",
      "Epoch:  0028 D loss:-0.423 G loss:-2.84\n",
      "Epoch:  0028 D loss:-0.4539 G loss:-2.792\n",
      "Epoch:  0028 D loss:-0.4298 G loss:-2.923\n",
      "Epoch:  0028 D loss:-0.4896 G loss:-2.967\n",
      "Epoch:  0028 D loss:-0.415 G loss:-2.643\n",
      "Epoch:  0028 D loss:-0.3239 G loss:-2.828\n",
      "Epoch:  0028 D loss:-0.415 G loss:-2.864\n",
      "Epoch:  0028 D loss:-0.4122 G loss:-2.887\n",
      "Epoch:  0028 D loss:-0.5005 G loss:-2.635\n",
      "Epoch:  0028 D loss:-0.3899 G loss:-2.654\n",
      "Epoch:  0028 D loss:-0.4753 G loss:-2.602\n",
      "Epoch:  0028 D loss:-0.3956 G loss:-3.068\n",
      "Epoch:  0028 D loss:-0.3841 G loss:-3.126\n",
      "Epoch:  0028 D loss:-0.3767 G loss:-3.023\n",
      "Epoch:  0028 D loss:-0.3614 G loss:-3.076\n",
      "Epoch:  0028 D loss:-0.3074 G loss:-3.253\n",
      "Epoch:  0028 D loss:-0.4909 G loss:-2.903\n",
      "Epoch:  0028 D loss:-0.412 G loss:-3.013\n",
      "Epoch:  0028 D loss:-0.4751 G loss:-2.915\n",
      "Epoch:  0028 D loss:-0.4096 G loss:-2.77\n",
      "Epoch:  0028 D loss:-0.3263 G loss:-2.665\n",
      "Epoch:  0028 D loss:-0.3765 G loss:-2.954\n",
      "Epoch:  0028 D loss:-0.4289 G loss:-2.648\n",
      "Epoch:  0028 D loss:-0.4434 G loss:-2.646\n",
      "Epoch:  0028 D loss:-0.4684 G loss:-3.085\n",
      "Epoch:  0028 D loss:-0.4532 G loss:-2.819\n",
      "Epoch:  0028 D loss:-0.4595 G loss:-3.056\n",
      "Epoch:  0028 D loss:-0.4811 G loss:-2.999\n",
      "Epoch:  0028 D loss:-0.4002 G loss:-2.961\n",
      "Epoch:  0028 D loss:-0.4894 G loss:-3.025\n",
      "Epoch:  0028 D loss:-0.3765 G loss:-2.882\n",
      "Epoch:  0028 D loss:-0.3934 G loss:-2.695\n",
      "Epoch:  0028 D loss:-0.3465 G loss:-3.08\n",
      "Epoch:  0028 D loss:-0.4892 G loss:-2.665\n",
      "Epoch:  0028 D loss:-0.4863 G loss:-2.744\n",
      "Epoch:  0028 D loss:-0.5259 G loss:-2.857\n",
      "Epoch:  0028 D loss:-0.422 G loss:-2.808\n",
      "Epoch:  0028 D loss:-0.3962 G loss:-2.73\n",
      "Epoch:  0028 D loss:-0.378 G loss:-2.664\n",
      "Epoch:  0028 D loss:-0.4941 G loss:-2.781\n",
      "Epoch:  0028 D loss:-0.4074 G loss:-2.913\n",
      "Epoch:  0028 D loss:-0.3822 G loss:-3.04\n",
      "Epoch:  0028 D loss:-0.4847 G loss:-2.809\n",
      "Epoch:  0028 D loss:-0.5323 G loss:-2.95\n",
      "Epoch:  0028 D loss:-0.3349 G loss:-3.141\n",
      "Epoch:  0028 D loss:-0.3748 G loss:-2.805\n",
      "Epoch:  0028 D loss:-0.4393 G loss:-2.949\n",
      "Epoch:  0028 D loss:-0.3603 G loss:-2.792\n",
      "Epoch:  0028 D loss:-0.3037 G loss:-3.119\n",
      "Epoch:  0028 D loss:-0.5152 G loss:-2.688\n",
      "Epoch:  0028 D loss:-0.3463 G loss:-2.687\n",
      "Epoch:  0028 D loss:-0.3523 G loss:-2.732\n",
      "Epoch:  0028 D loss:-0.4666 G loss:-2.754\n",
      "Epoch:  0028 D loss:-0.3954 G loss:-2.649\n",
      "Epoch:  0028 D loss:-0.4386 G loss:-2.705\n",
      "Epoch:  0028 D loss:-0.5149 G loss:-2.849\n",
      "Epoch:  0028 D loss:-0.3129 G loss:-2.643\n",
      "Epoch:  0028 D loss:-0.3261 G loss:-2.964\n",
      "Epoch:  0028 D loss:-0.4554 G loss:-2.919\n",
      "Epoch:  0028 D loss:-0.3784 G loss:-2.822\n",
      "Epoch:  0028 D loss:-0.4552 G loss:-2.904\n",
      "Epoch:  0028 D loss:-0.4168 G loss:-2.905\n",
      "Epoch:  0028 D loss:-0.3922 G loss:-2.966\n",
      "Epoch:  0028 D loss:-0.454 G loss:-2.92\n",
      "Epoch:  0028 D loss:-0.4536 G loss:-2.829\n",
      "Epoch:  0028 D loss:-0.4454 G loss:-2.735\n",
      "Epoch:  0028 D loss:-0.4178 G loss:-2.745\n",
      "Epoch:  0028 D loss:-0.5533 G loss:-2.614\n",
      "Epoch:  0028 D loss:-0.4956 G loss:-2.671\n",
      "Epoch:  0028 D loss:-0.4725 G loss:-2.509\n",
      "Epoch:  0028 D loss:-0.4741 G loss:-2.609\n",
      "Epoch:  0028 D loss:-0.5373 G loss:-2.706\n",
      "Epoch:  0028 D loss:-0.5552 G loss:-2.448\n",
      "Epoch:  0028 D loss:-0.4968 G loss:-2.705\n",
      "Epoch:  0028 D loss:-0.5408 G loss:-2.374\n",
      "Epoch:  0028 D loss:-0.4991 G loss:-2.649\n",
      "Epoch:  0028 D loss:-0.4851 G loss:-2.702\n",
      "Epoch:  0028 D loss:-0.507 G loss:-2.423\n",
      "Epoch:  0028 D loss:-0.4135 G loss:-2.587\n",
      "Epoch:  0028 D loss:-0.483 G loss:-2.526\n",
      "Epoch:  0028 D loss:-0.5701 G loss:-2.686\n",
      "Epoch:  0028 D loss:-0.4276 G loss:-2.786\n",
      "Epoch:  0028 D loss:-0.5808 G loss:-2.618\n",
      "Epoch:  0028 D loss:-0.5335 G loss:-2.519\n",
      "Epoch:  0028 D loss:-0.4831 G loss:-2.935\n",
      "Epoch:  0028 D loss:-0.5151 G loss:-2.736\n",
      "Epoch:  0028 D loss:-0.5704 G loss:-2.496\n",
      "Epoch:  0028 D loss:-0.4208 G loss:-2.812\n",
      "Epoch:  0028 D loss:-0.3908 G loss:-2.956\n",
      "Epoch:  0028 D loss:-0.402 G loss:-2.87\n",
      "Epoch:  0028 D loss:-0.4451 G loss:-2.785\n",
      "Epoch:  0028 D loss:-0.53 G loss:-3.124\n",
      "Epoch:  0028 D loss:-0.5123 G loss:-2.949\n",
      "Epoch:  0028 D loss:-0.5938 G loss:-2.645\n",
      "Epoch:  0028 D loss:-0.3596 G loss:-2.62\n",
      "Epoch:  0028 D loss:-0.5357 G loss:-2.476\n",
      "Epoch:  0028 D loss:-0.4708 G loss:-2.641\n",
      "Epoch:  0028 D loss:-0.406 G loss:-2.615\n",
      "Epoch:  0028 D loss:-0.5998 G loss:-2.361\n",
      "Epoch:  0028 D loss:-0.4625 G loss:-2.333\n",
      "Epoch:  0028 D loss:-0.493 G loss:-2.504\n",
      "Epoch:  0028 D loss:-0.519 G loss:-2.605\n",
      "Epoch:  0028 D loss:-0.376 G loss:-2.486\n",
      "Epoch:  0028 D loss:-0.4521 G loss:-2.658\n",
      "Epoch:  0028 D loss:-0.4034 G loss:-2.817\n",
      "Epoch:  0028 D loss:-0.4682 G loss:-3.124\n",
      "Epoch:  0028 D loss:-0.5551 G loss:-3.134\n",
      "Epoch:  0028 D loss:-0.4444 G loss:-3.088\n",
      "Epoch:  0028 D loss:-0.4256 G loss:-3.209\n",
      "Epoch:  0028 D loss:-0.4572 G loss:-2.945\n",
      "Epoch:  0028 D loss:-0.4296 G loss:-3.105\n",
      "Epoch:  0028 D loss:-0.4546 G loss:-2.92\n",
      "Epoch:  0028 D loss:-0.5914 G loss:-2.658\n",
      "Epoch:  0028 D loss:-0.466 G loss:-2.774\n",
      "Epoch:  0028 D loss:-0.3841 G loss:-2.729\n",
      "Epoch:  0028 D loss:-0.3975 G loss:-2.366\n",
      "Epoch:  0028 D loss:-0.4244 G loss:-2.278\n",
      "Epoch:  0028 D loss:-0.4314 G loss:-2.483\n",
      "Epoch:  0028 D loss:-0.4871 G loss:-2.509\n",
      "Epoch:  0028 D loss:-0.4515 G loss:-2.71\n",
      "Epoch:  0028 D loss:-0.44 G loss:-2.716\n",
      "Epoch:  0028 D loss:-0.3683 G loss:-2.898\n",
      "Epoch:  0028 D loss:-0.3516 G loss:-2.596\n",
      "Epoch:  0028 D loss:-0.3792 G loss:-2.851\n",
      "Epoch:  0028 D loss:-0.4337 G loss:-2.958\n",
      "Epoch:  0028 D loss:-0.3226 G loss:-3.075\n",
      "Epoch:  0028 D loss:-0.3756 G loss:-3.283\n",
      "Epoch:  0028 D loss:-0.3723 G loss:-3.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0028 D loss:-0.3647 G loss:-3.078\n",
      "Epoch:  0028 D loss:-0.3572 G loss:-3.201\n",
      "Epoch:  0028 D loss:-0.4007 G loss:-3.027\n",
      "Epoch:  0028 D loss:-0.2775 G loss:-3.015\n",
      "Epoch:  0028 D loss:-0.387 G loss:-2.688\n",
      "Epoch:  0028 D loss:-0.4389 G loss:-2.623\n",
      "Epoch:  0028 D loss:-0.3737 G loss:-2.587\n",
      "Epoch:  0028 D loss:-0.3981 G loss:-2.645\n",
      "Epoch:  0028 D loss:-0.4083 G loss:-2.801\n",
      "Epoch:  0028 D loss:-0.2818 G loss:-2.719\n",
      "Epoch:  0028 D loss:-0.3766 G loss:-2.712\n",
      "Epoch:  0028 D loss:-0.4257 G loss:-2.862\n",
      "Epoch:  0028 D loss:-0.322 G loss:-2.982\n",
      "Epoch:  0028 D loss:-0.3137 G loss:-3.017\n",
      "Epoch:  0028 D loss:-0.3061 G loss:-2.932\n",
      "Epoch:  0028 D loss:-0.4215 G loss:-2.942\n",
      "Epoch:  0028 D loss:-0.4319 G loss:-2.878\n",
      "Epoch:  0028 D loss:-0.3552 G loss:-2.927\n",
      "Epoch:  0028 D loss:-0.3897 G loss:-2.69\n",
      "Epoch:  0028 D loss:-0.5134 G loss:-2.692\n",
      "Epoch:  0028 D loss:-0.3212 G loss:-2.766\n",
      "Epoch:  0028 D loss:-0.3512 G loss:-2.63\n",
      "Epoch:  0028 D loss:-0.4058 G loss:-2.698\n",
      "Epoch:  0028 D loss:-0.4836 G loss:-2.678\n",
      "Epoch:  0028 D loss:-0.4195 G loss:-2.637\n",
      "Epoch:  0028 D loss:-0.4894 G loss:-2.645\n",
      "Epoch:  0028 D loss:-0.4013 G loss:-2.72\n",
      "Epoch:  0028 D loss:-0.4029 G loss:-2.953\n",
      "Epoch:  0028 D loss:-0.4047 G loss:-3.024\n",
      "Epoch:  0028 D loss:-0.3748 G loss:-2.785\n",
      "Epoch:  0028 D loss:-0.3337 G loss:-2.784\n",
      "Epoch:  0028 D loss:-0.3204 G loss:-2.867\n",
      "Epoch:  0028 D loss:-0.4002 G loss:-3.032\n",
      "Epoch:  0028 D loss:-0.3928 G loss:-2.906\n",
      "Epoch:  0028 D loss:-0.3679 G loss:-2.896\n",
      "Epoch:  0028 D loss:-0.4103 G loss:-2.874\n",
      "Epoch:  0028 D loss:-0.4025 G loss:-2.699\n",
      "Epoch:  0028 D loss:-0.3829 G loss:-2.556\n",
      "Epoch:  0028 D loss:-0.4462 G loss:-2.479\n",
      "Epoch:  0028 D loss:-0.3507 G loss:-2.529\n",
      "Epoch:  0028 D loss:-0.2375 G loss:-2.865\n",
      "Epoch:  0028 D loss:-0.3799 G loss:-2.663\n",
      "Epoch:  0028 D loss:-0.4307 G loss:-2.765\n",
      "Epoch:  0028 D loss:-0.4065 G loss:-2.965\n",
      "Epoch:  0028 D loss:-0.4686 G loss:-2.864\n",
      "Epoch:  0028 D loss:-0.3925 G loss:-2.714\n",
      "Epoch:  0028 D loss:-0.2609 G loss:-3.178\n",
      "Epoch:  0028 D loss:-0.321 G loss:-3.072\n",
      "Epoch:  0028 D loss:-0.3563 G loss:-2.886\n",
      "Epoch:  0028 D loss:-0.4093 G loss:-2.819\n",
      "Epoch:  0028 D loss:-0.2918 G loss:-2.783\n",
      "Epoch:  0028 D loss:-0.2998 G loss:-2.915\n",
      "Epoch:  0028 D loss:-0.3585 G loss:-3.048\n",
      "Epoch:  0028 D loss:-0.4869 G loss:-2.645\n",
      "Epoch:  0028 D loss:-0.3726 G loss:-2.89\n",
      "Epoch:  0028 D loss:-0.3157 G loss:-2.565\n",
      "Epoch:  0028 D loss:-0.3465 G loss:-2.589\n",
      "Epoch:  0028 D loss:-0.3473 G loss:-2.65\n",
      "Epoch:  0028 D loss:-0.2917 G loss:-2.841\n",
      "Epoch:  0028 D loss:-0.318 G loss:-3.029\n",
      "Epoch:  0028 D loss:-0.3241 G loss:-3.069\n",
      "Epoch:  0028 D loss:-0.2641 G loss:-3.032\n",
      "Epoch:  0028 D loss:-0.455 G loss:-2.989\n",
      "Epoch:  0028 D loss:-0.3434 G loss:-2.999\n",
      "Epoch:  0028 D loss:-0.4094 G loss:-2.954\n",
      "Epoch:  0028 D loss:-0.3886 G loss:-2.646\n",
      "Epoch:  0028 D loss:-0.2943 G loss:-3.04\n",
      "Epoch:  0028 D loss:-0.4227 G loss:-2.646\n",
      "Epoch:  0028 D loss:-0.4796 G loss:-2.739\n",
      "Epoch:  0028 D loss:-0.376 G loss:-2.538\n",
      "Epoch:  0028 D loss:-0.3962 G loss:-2.499\n",
      "Epoch:  0028 D loss:-0.474 G loss:-2.636\n",
      "Epoch:  0028 D loss:-0.4059 G loss:-2.727\n",
      "Epoch:  0028 D loss:-0.4277 G loss:-2.762\n",
      "Epoch:  0028 D loss:-0.46 G loss:-2.717\n",
      "Epoch:  0028 D loss:-0.4139 G loss:-2.551\n",
      "Epoch:  0028 D loss:-0.4614 G loss:-2.643\n",
      "Epoch:  0028 D loss:-0.4457 G loss:-2.548\n",
      "Epoch:  0028 D loss:-0.4268 G loss:-2.709\n",
      "Epoch:  0028 D loss:-0.5366 G loss:-2.755\n",
      "Epoch:  0028 D loss:-0.3781 G loss:-2.63\n",
      "Epoch:  0028 D loss:-0.4896 G loss:-2.691\n",
      "Epoch:  0028 D loss:-0.4288 G loss:-2.599\n",
      "Epoch:  0028 D loss:-0.4857 G loss:-2.724\n",
      "Epoch:  0028 D loss:-0.4596 G loss:-2.852\n",
      "Epoch:  0028 D loss:-0.3741 G loss:-2.399\n",
      "Epoch:  0028 D loss:-0.4162 G loss:-2.716\n",
      "Epoch:  0028 D loss:-0.4105 G loss:-2.529\n",
      "Epoch:  0028 D loss:-0.4876 G loss:-2.496\n",
      "Epoch:  0028 D loss:-0.3793 G loss:-2.78\n",
      "Epoch:  0028 D loss:-0.4273 G loss:-2.492\n",
      "Epoch:  0028 D loss:-0.4347 G loss:-2.762\n",
      "Epoch:  0028 D loss:-0.4905 G loss:-2.238\n",
      "Epoch:  0028 D loss:-0.3481 G loss:-2.82\n",
      "Epoch:  0028 D loss:-0.4083 G loss:-2.75\n",
      "Epoch:  0028 D loss:-0.4001 G loss:-2.75\n",
      "Epoch:  0028 D loss:-0.4311 G loss:-2.661\n",
      "Epoch:  0028 D loss:-0.412 G loss:-2.782\n",
      "Epoch:  0028 D loss:-0.4177 G loss:-2.905\n",
      "Epoch:  0028 D loss:-0.4196 G loss:-2.911\n",
      "Epoch:  0028 D loss:-0.445 G loss:-2.709\n",
      "Epoch:  0028 D loss:-0.4356 G loss:-2.684\n",
      "Epoch:  0028 D loss:-0.5505 G loss:-2.549\n",
      "Epoch:  0028 D loss:-0.4648 G loss:-2.329\n",
      "Epoch:  0028 D loss:-0.3818 G loss:-2.477\n",
      "Epoch:  0028 D loss:-0.5482 G loss:-2.241\n",
      "Epoch:  0028 D loss:-0.6031 G loss:-2.303\n",
      "Epoch:  0028 D loss:-0.549 G loss:-2.173\n",
      "Epoch:  0028 D loss:-0.5435 G loss:-2.397\n",
      "Epoch:  0028 D loss:-0.4167 G loss:-2.736\n",
      "Epoch:  0028 D loss:-0.5231 G loss:-2.536\n",
      "Epoch:  0028 D loss:-0.3874 G loss:-2.814\n",
      "Epoch:  0028 D loss:-0.4274 G loss:-2.675\n",
      "Epoch:  0028 D loss:-0.4222 G loss:-2.903\n",
      "Epoch:  0028 D loss:-0.5284 G loss:-2.974\n",
      "Epoch:  0028 D loss:-0.5643 G loss:-2.851\n",
      "Epoch:  0028 D loss:-0.4946 G loss:-2.799\n",
      "Epoch:  0028 D loss:-0.5985 G loss:-2.602\n",
      "Epoch:  0028 D loss:-0.5153 G loss:-2.624\n",
      "Epoch:  0028 D loss:-0.548 G loss:-2.346\n",
      "Epoch:  0028 D loss:-0.4208 G loss:-2.322\n",
      "Epoch:  0028 D loss:-0.4486 G loss:-2.365\n",
      "Epoch:  0028 D loss:-0.4834 G loss:-2.415\n",
      "Epoch:  0028 D loss:-0.5363 G loss:-2.168\n",
      "Epoch:  0028 D loss:-0.4093 G loss:-2.274\n",
      "Epoch:  0028 D loss:-0.4484 G loss:-2.477\n",
      "Epoch:  0028 D loss:-0.3794 G loss:-2.645\n",
      "Epoch:  0028 D loss:-0.4036 G loss:-2.708\n",
      "Epoch:  0028 D loss:-0.5017 G loss:-2.522\n",
      "Epoch:  0028 D loss:-0.4296 G loss:-3.162\n",
      "Epoch:  0028 D loss:-0.3961 G loss:-3.045\n",
      "Epoch:  0028 D loss:-0.5093 G loss:-3.092\n",
      "Epoch:  0028 D loss:-0.4827 G loss:-2.764\n",
      "Epoch:  0028 D loss:-0.392 G loss:-2.943\n",
      "Epoch:  0028 D loss:-0.4824 G loss:-2.757\n",
      "Epoch:  0028 D loss:-0.4442 G loss:-2.719\n",
      "Epoch:  0028 D loss:-0.4867 G loss:-2.458\n",
      "Epoch:  0028 D loss:-0.543 G loss:-2.496\n",
      "Epoch:  0028 D loss:-0.5087 G loss:-2.363\n",
      "Epoch:  0028 D loss:-0.4911 G loss:-2.535\n",
      "Epoch:  0028 D loss:-0.4902 G loss:-2.452\n",
      "Epoch:  0028 D loss:-0.4448 G loss:-2.463\n",
      "Epoch:  0028 D loss:-0.5066 G loss:-2.684\n",
      "Epoch:  0028 D loss:-0.4612 G loss:-2.514\n",
      "Epoch:  0028 D loss:-0.4059 G loss:-2.576\n",
      "Epoch:  0028 D loss:-0.3996 G loss:-2.737\n",
      "Epoch:  0028 D loss:-0.4114 G loss:-2.658\n",
      "Epoch:  0028 D loss:-0.4864 G loss:-2.634\n",
      "Epoch:  0028 D loss:-0.4373 G loss:-2.933\n",
      "Epoch:  0028 D loss:-0.5183 G loss:-2.825\n",
      "Epoch:  0028 D loss:-0.4637 G loss:-2.719\n",
      "Epoch:  0028 D loss:-0.539 G loss:-2.837\n",
      "Epoch:  0028 D loss:-0.5676 G loss:-2.591\n",
      "Epoch:  0028 D loss:-0.5202 G loss:-2.818\n",
      "Epoch:  0028 D loss:-0.5181 G loss:-2.421\n",
      "Epoch:  0028 D loss:-0.4406 G loss:-2.586\n",
      "Epoch:  0028 D loss:-0.5121 G loss:-2.42\n",
      "Epoch:  0028 D loss:-0.4058 G loss:-2.614\n",
      "Epoch:  0028 D loss:-0.4406 G loss:-2.46\n",
      "Epoch:  0028 D loss:-0.3393 G loss:-2.849\n",
      "Epoch:  0028 D loss:-0.4196 G loss:-2.785\n",
      "Epoch:  0028 D loss:-0.5645 G loss:-2.614\n",
      "Epoch:  0028 D loss:-0.4709 G loss:-2.443\n",
      "Epoch:  0028 D loss:-0.5212 G loss:-2.721\n",
      "Epoch:  0028 D loss:-0.475 G loss:-2.604\n",
      "Epoch:  0028 D loss:-0.5354 G loss:-2.77\n",
      "Epoch:  0028 D loss:-0.4958 G loss:-2.556\n",
      "Epoch:  0028 D loss:-0.4695 G loss:-2.88\n",
      "Epoch:  0028 D loss:-0.4819 G loss:-2.89\n",
      "Epoch:  0028 D loss:-0.4325 G loss:-2.783\n",
      "Epoch:  0028 D loss:-0.5131 G loss:-2.805\n",
      "Epoch:  0028 D loss:-0.3455 G loss:-2.602\n",
      "Epoch:  0028 D loss:-0.4558 G loss:-2.675\n",
      "Epoch:  0028 D loss:-0.3656 G loss:-2.676\n",
      "Epoch:  0028 D loss:-0.4494 G loss:-2.483\n",
      "Epoch:  0028 D loss:-0.5557 G loss:-2.553\n",
      "Epoch:  0028 D loss:-0.5267 G loss:-2.668\n",
      "Epoch:  0028 D loss:-0.5021 G loss:-2.386\n",
      "Epoch:  0028 D loss:-0.3367 G loss:-2.725\n",
      "Epoch:  0028 D loss:-0.4486 G loss:-2.559\n",
      "Epoch:  0028 D loss:-0.5185 G loss:-2.369\n",
      "Epoch:  0028 D loss:-0.3601 G loss:-2.682\n",
      "Epoch:  0028 D loss:-0.503 G loss:-2.618\n",
      "Epoch:  0028 D loss:-0.3379 G loss:-2.948\n",
      "Epoch:  0028 D loss:-0.4789 G loss:-2.876\n",
      "Epoch:  0028 D loss:-0.4991 G loss:-2.853\n",
      "Epoch:  0028 D loss:-0.4281 G loss:-2.895\n",
      "Epoch:  0028 D loss:-0.4672 G loss:-2.893\n",
      "Epoch:  0028 D loss:-0.4398 G loss:-2.569\n",
      "Epoch:  0028 D loss:-0.3239 G loss:-2.94\n",
      "Epoch:  0028 D loss:-0.3699 G loss:-2.787\n",
      "Epoch:  0028 D loss:-0.4583 G loss:-2.629\n",
      "Epoch:  0028 D loss:-0.3985 G loss:-2.936\n",
      "Epoch:  0028 D loss:-0.3664 G loss:-2.773\n",
      "Epoch:  0028 D loss:-0.3836 G loss:-2.669\n",
      "Epoch:  0028 D loss:-0.3739 G loss:-2.841\n",
      "Epoch:  0028 D loss:-0.3451 G loss:-3.128\n",
      "Epoch:  0028 D loss:-0.2784 G loss:-3.037\n",
      "Epoch:  0028 D loss:-0.3745 G loss:-2.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0028 D loss:-0.3859 G loss:-2.995\n",
      "Epoch:  0028 D loss:-0.4545 G loss:-2.882\n",
      "Epoch:  0028 D loss:-0.3036 G loss:-2.917\n",
      "Epoch:  0028 D loss:-0.3817 G loss:-2.913\n",
      "Epoch:  0028 D loss:-0.239 G loss:-2.962\n",
      "Epoch:  0028 D loss:-0.3516 G loss:-2.871\n",
      "Epoch:  0028 D loss:-0.3773 G loss:-2.814\n",
      "Epoch:  0028 D loss:-0.281 G loss:-2.806\n",
      "Epoch:  0028 D loss:-0.3394 G loss:-2.789\n",
      "Epoch:  0028 D loss:-0.3381 G loss:-2.912\n",
      "Epoch:  0028 D loss:-0.2965 G loss:-3.233\n",
      "Epoch:  0028 D loss:-0.3025 G loss:-3.09\n",
      "Epoch:  0028 D loss:-0.421 G loss:-3.071\n",
      "Epoch:  0028 D loss:-0.3263 G loss:-3.049\n",
      "Epoch:  0028 D loss:-0.3081 G loss:-2.758\n",
      "Epoch:  0028 D loss:-0.2474 G loss:-3.23\n",
      "Epoch:  0028 D loss:-0.2398 G loss:-3.268\n",
      "Epoch:  0028 D loss:-0.4014 G loss:-3.026\n",
      "Epoch:  0028 D loss:-0.278 G loss:-3.062\n",
      "Epoch:  0028 D loss:-0.3387 G loss:-2.812\n",
      "Epoch:  0028 D loss:-0.3869 G loss:-2.772\n",
      "Epoch:  0028 D loss:-0.3011 G loss:-2.641\n",
      "Epoch:  0028 D loss:-0.287 G loss:-2.946\n",
      "Epoch:  0028 D loss:-0.3535 G loss:-2.904\n",
      "Epoch:  0028 D loss:-0.3227 G loss:-2.622\n",
      "Epoch:  0028 D loss:-0.3138 G loss:-2.874\n",
      "Epoch:  0028 D loss:-0.4829 G loss:-2.695\n",
      "Epoch:  0028 D loss:-0.3677 G loss:-3.034\n",
      "Epoch:  0028 D loss:-0.3531 G loss:-2.835\n",
      "Epoch:  0028 D loss:-0.3925 G loss:-2.995\n",
      "Epoch:  0028 D loss:-0.3459 G loss:-2.995\n",
      "Epoch:  0028 D loss:-0.3475 G loss:-2.66\n",
      "Epoch:  0028 D loss:-0.3391 G loss:-2.668\n",
      "Epoch:  0028 D loss:-0.4015 G loss:-2.642\n",
      "Epoch:  0028 D loss:-0.3887 G loss:-2.984\n",
      "Epoch:  0028 D loss:-0.3895 G loss:-2.79\n",
      "Epoch:  0028 D loss:-0.4178 G loss:-2.556\n",
      "Epoch:  0028 D loss:-0.3981 G loss:-2.626\n",
      "Epoch:  0028 D loss:-0.3462 G loss:-2.659\n",
      "Epoch:  0028 D loss:-0.3902 G loss:-2.683\n",
      "Epoch:  0028 D loss:-0.4306 G loss:-2.826\n",
      "Epoch:  0028 D loss:-0.3533 G loss:-2.849\n",
      "Epoch:  0028 D loss:-0.445 G loss:-2.705\n",
      "Epoch:  0028 D loss:-0.3803 G loss:-2.94\n",
      "Epoch:  0028 D loss:-0.438 G loss:-2.968\n",
      "Epoch:  0028 D loss:-0.445 G loss:-2.738\n",
      "Epoch:  0028 D loss:-0.4017 G loss:-2.816\n",
      "Epoch:  0028 D loss:-0.3326 G loss:-2.89\n",
      "Epoch:  0028 D loss:-0.4749 G loss:-2.54\n",
      "Epoch:  0028 D loss:-0.3601 G loss:-2.672\n",
      "Epoch:  0028 D loss:-0.4446 G loss:-2.642\n",
      "Epoch:  0028 D loss:-0.3477 G loss:-2.752\n",
      "Epoch:  0028 D loss:-0.4425 G loss:-2.829\n",
      "Epoch:  0028 D loss:-0.3971 G loss:-2.715\n",
      "Epoch:  0028 D loss:-0.3334 G loss:-2.843\n",
      "Epoch:  0028 D loss:-0.2739 G loss:-2.919\n",
      "Epoch:  0028 D loss:-0.5035 G loss:-2.88\n",
      "Epoch:  0028 D loss:-0.407 G loss:-2.762\n",
      "Epoch:  0028 D loss:-0.4333 G loss:-2.753\n",
      "Epoch:  0028 D loss:-0.3512 G loss:-2.998\n",
      "Epoch:  0028 D loss:-0.4722 G loss:-2.826\n",
      "Epoch:  0028 D loss:-0.4535 G loss:-2.893\n",
      "Epoch:  0028 D loss:-0.3723 G loss:-2.797\n",
      "Epoch:  0028 D loss:-0.4067 G loss:-2.987\n",
      "Epoch:  0028 D loss:-0.3872 G loss:-2.619\n",
      "Epoch:  0028 D loss:-0.5508 G loss:-2.356\n",
      "Epoch:  0028 D loss:-0.4106 G loss:-2.592\n",
      "Epoch:  0028 D loss:-0.4709 G loss:-2.365\n",
      "Epoch:  0028 D loss:-0.3955 G loss:-2.313\n",
      "Epoch:  0028 D loss:-0.4073 G loss:-2.768\n",
      "Epoch:  0028 D loss:-0.526 G loss:-2.482\n",
      "Epoch:  0028 D loss:-0.3923 G loss:-2.626\n",
      "Epoch:  0028 D loss:-0.334 G loss:-2.959\n",
      "Epoch:  0028 D loss:-0.3501 G loss:-2.778\n",
      "Epoch:  0028 D loss:-0.3495 G loss:-3.019\n",
      "Epoch:  0028 D loss:-0.3323 G loss:-3.109\n",
      "Epoch:  0028 D loss:-0.4533 G loss:-2.907\n",
      "Epoch:  0028 D loss:-0.3774 G loss:-2.984\n",
      "Epoch:  0028 D loss:-0.4761 G loss:-3.027\n",
      "Epoch:  0028 D loss:-0.3845 G loss:-2.777\n",
      "Epoch:  0028 D loss:-0.3021 G loss:-2.791\n",
      "Epoch:  0029 D loss:-0.3904 G loss:-2.748\n",
      "Epoch:  0029 D loss:-0.4337 G loss:-2.731\n",
      "Epoch:  0029 D loss:-0.4162 G loss:-2.593\n",
      "Epoch:  0029 D loss:-0.4437 G loss:-2.596\n",
      "Epoch:  0029 D loss:-0.3931 G loss:-2.824\n",
      "Epoch:  0029 D loss:-0.4153 G loss:-2.656\n",
      "Epoch:  0029 D loss:-0.2948 G loss:-2.581\n",
      "Epoch:  0029 D loss:-0.414 G loss:-2.768\n",
      "Epoch:  0029 D loss:-0.4401 G loss:-2.461\n",
      "Epoch:  0029 D loss:-0.4391 G loss:-2.545\n",
      "Epoch:  0029 D loss:-0.3613 G loss:-2.542\n",
      "Epoch:  0029 D loss:-0.373 G loss:-2.492\n",
      "Epoch:  0029 D loss:-0.4819 G loss:-2.493\n",
      "Epoch:  0029 D loss:-0.4556 G loss:-2.73\n",
      "Epoch:  0029 D loss:-0.364 G loss:-2.679\n",
      "Epoch:  0029 D loss:-0.3459 G loss:-2.897\n",
      "Epoch:  0029 D loss:-0.3303 G loss:-2.902\n",
      "Epoch:  0029 D loss:-0.4668 G loss:-2.871\n",
      "Epoch:  0029 D loss:-0.5274 G loss:-3.128\n",
      "Epoch:  0029 D loss:-0.4256 G loss:-2.979\n",
      "Epoch:  0029 D loss:-0.3902 G loss:-2.695\n",
      "Epoch:  0029 D loss:-0.4167 G loss:-2.49\n",
      "Epoch:  0029 D loss:-0.476 G loss:-2.561\n",
      "Epoch:  0029 D loss:-0.4107 G loss:-2.809\n",
      "Epoch:  0029 D loss:-0.4484 G loss:-2.602\n",
      "Epoch:  0029 D loss:-0.32 G loss:-2.507\n",
      "Epoch:  0029 D loss:-0.4271 G loss:-2.51\n",
      "Epoch:  0029 D loss:-0.4291 G loss:-2.358\n",
      "Epoch:  0029 D loss:-0.4625 G loss:-2.587\n",
      "Epoch:  0029 D loss:-0.4076 G loss:-2.616\n",
      "Epoch:  0029 D loss:-0.3316 G loss:-2.499\n",
      "Epoch:  0029 D loss:-0.4345 G loss:-2.456\n",
      "Epoch:  0029 D loss:-0.367 G loss:-2.516\n",
      "Epoch:  0029 D loss:-0.4256 G loss:-2.718\n",
      "Epoch:  0029 D loss:-0.4496 G loss:-2.604\n",
      "Epoch:  0029 D loss:-0.3856 G loss:-3.013\n",
      "Epoch:  0029 D loss:-0.4489 G loss:-2.898\n",
      "Epoch:  0029 D loss:-0.4538 G loss:-2.922\n",
      "Epoch:  0029 D loss:-0.4189 G loss:-3.108\n",
      "Epoch:  0029 D loss:-0.3426 G loss:-3.02\n",
      "Epoch:  0029 D loss:-0.497 G loss:-2.961\n",
      "Epoch:  0029 D loss:-0.471 G loss:-2.844\n",
      "Epoch:  0029 D loss:-0.4025 G loss:-2.624\n",
      "Epoch:  0029 D loss:-0.3783 G loss:-2.797\n",
      "Epoch:  0029 D loss:-0.348 G loss:-2.625\n",
      "Epoch:  0029 D loss:-0.4552 G loss:-2.445\n",
      "Epoch:  0029 D loss:-0.4652 G loss:-2.37\n",
      "Epoch:  0029 D loss:-0.4156 G loss:-2.416\n",
      "Epoch:  0029 D loss:-0.5892 G loss:-2.444\n",
      "Epoch:  0029 D loss:-0.3706 G loss:-2.424\n",
      "Epoch:  0029 D loss:-0.3383 G loss:-2.566\n",
      "Epoch:  0029 D loss:-0.4795 G loss:-2.615\n",
      "Epoch:  0029 D loss:-0.4268 G loss:-2.587\n",
      "Epoch:  0029 D loss:-0.3571 G loss:-2.951\n",
      "Epoch:  0029 D loss:-0.3367 G loss:-2.565\n",
      "Epoch:  0029 D loss:-0.5133 G loss:-2.93\n",
      "Epoch:  0029 D loss:-0.2916 G loss:-2.908\n",
      "Epoch:  0029 D loss:-0.4828 G loss:-2.621\n",
      "Epoch:  0029 D loss:-0.4329 G loss:-2.665\n",
      "Epoch:  0029 D loss:-0.3965 G loss:-2.982\n",
      "Epoch:  0029 D loss:-0.6208 G loss:-2.723\n",
      "Epoch:  0029 D loss:-0.5976 G loss:-2.762\n",
      "Epoch:  0029 D loss:-0.3518 G loss:-2.769\n",
      "Epoch:  0029 D loss:-0.4197 G loss:-2.89\n",
      "Epoch:  0029 D loss:-0.4261 G loss:-2.718\n",
      "Epoch:  0029 D loss:-0.4845 G loss:-2.661\n",
      "Epoch:  0029 D loss:-0.3993 G loss:-2.63\n",
      "Epoch:  0029 D loss:-0.4472 G loss:-2.579\n",
      "Epoch:  0029 D loss:-0.3851 G loss:-2.479\n",
      "Epoch:  0029 D loss:-0.3871 G loss:-2.424\n",
      "Epoch:  0029 D loss:-0.4414 G loss:-2.49\n",
      "Epoch:  0029 D loss:-0.431 G loss:-2.527\n",
      "Epoch:  0029 D loss:-0.3819 G loss:-2.502\n",
      "Epoch:  0029 D loss:-0.4743 G loss:-2.383\n",
      "Epoch:  0029 D loss:-0.402 G loss:-2.557\n",
      "Epoch:  0029 D loss:-0.4769 G loss:-2.345\n",
      "Epoch:  0029 D loss:-0.4992 G loss:-2.913\n",
      "Epoch:  0029 D loss:-0.4247 G loss:-2.683\n",
      "Epoch:  0029 D loss:-0.4208 G loss:-2.584\n",
      "Epoch:  0029 D loss:-0.5476 G loss:-2.626\n",
      "Epoch:  0029 D loss:-0.4457 G loss:-2.723\n",
      "Epoch:  0029 D loss:-0.4447 G loss:-2.566\n",
      "Epoch:  0029 D loss:-0.4069 G loss:-2.692\n",
      "Epoch:  0029 D loss:-0.4295 G loss:-2.514\n",
      "Epoch:  0029 D loss:-0.3984 G loss:-2.684\n",
      "Epoch:  0029 D loss:-0.3705 G loss:-2.513\n",
      "Epoch:  0029 D loss:-0.5599 G loss:-2.553\n",
      "Epoch:  0029 D loss:-0.3585 G loss:-2.754\n",
      "Epoch:  0029 D loss:-0.3743 G loss:-2.705\n",
      "Epoch:  0029 D loss:-0.4542 G loss:-2.549\n",
      "Epoch:  0029 D loss:-0.4614 G loss:-2.385\n",
      "Epoch:  0029 D loss:-0.3999 G loss:-2.481\n",
      "Epoch:  0029 D loss:-0.3752 G loss:-2.665\n",
      "Epoch:  0029 D loss:-0.4242 G loss:-2.661\n",
      "Epoch:  0029 D loss:-0.4063 G loss:-2.515\n",
      "Epoch:  0029 D loss:-0.3805 G loss:-2.537\n",
      "Epoch:  0029 D loss:-0.4422 G loss:-2.655\n",
      "Epoch:  0029 D loss:-0.5192 G loss:-2.513\n",
      "Epoch:  0029 D loss:-0.4664 G loss:-2.626\n",
      "Epoch:  0029 D loss:-0.3867 G loss:-2.91\n",
      "Epoch:  0029 D loss:-0.3512 G loss:-2.585\n",
      "Epoch:  0029 D loss:-0.3854 G loss:-2.604\n",
      "Epoch:  0029 D loss:-0.4719 G loss:-2.508\n",
      "Epoch:  0029 D loss:-0.3955 G loss:-2.729\n",
      "Epoch:  0029 D loss:-0.4378 G loss:-2.55\n",
      "Epoch:  0029 D loss:-0.3929 G loss:-2.558\n",
      "Epoch:  0029 D loss:-0.2693 G loss:-2.671\n",
      "Epoch:  0029 D loss:-0.3834 G loss:-2.81\n",
      "Epoch:  0029 D loss:-0.332 G loss:-2.819\n",
      "Epoch:  0029 D loss:-0.4245 G loss:-2.899\n",
      "Epoch:  0029 D loss:-0.4404 G loss:-2.926\n",
      "Epoch:  0029 D loss:-0.3505 G loss:-2.644\n",
      "Epoch:  0029 D loss:-0.4078 G loss:-2.776\n",
      "Epoch:  0029 D loss:-0.4165 G loss:-3.002\n",
      "Epoch:  0029 D loss:-0.3275 G loss:-2.98\n",
      "Epoch:  0029 D loss:-0.3172 G loss:-2.8\n",
      "Epoch:  0029 D loss:-0.3586 G loss:-2.755\n",
      "Epoch:  0029 D loss:-0.4279 G loss:-2.673\n",
      "Epoch:  0029 D loss:-0.4729 G loss:-2.61\n",
      "Epoch:  0029 D loss:-0.3754 G loss:-2.496\n",
      "Epoch:  0029 D loss:-0.4528 G loss:-2.632\n",
      "Epoch:  0029 D loss:-0.3508 G loss:-2.814\n",
      "Epoch:  0029 D loss:-0.3003 G loss:-2.658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0029 D loss:-0.336 G loss:-2.766\n",
      "Epoch:  0029 D loss:-0.3293 G loss:-2.669\n",
      "Epoch:  0029 D loss:-0.397 G loss:-2.726\n",
      "Epoch:  0029 D loss:-0.3078 G loss:-2.801\n",
      "Epoch:  0029 D loss:-0.3973 G loss:-2.82\n",
      "Epoch:  0029 D loss:-0.3746 G loss:-2.914\n",
      "Epoch:  0029 D loss:-0.2757 G loss:-2.887\n",
      "Epoch:  0029 D loss:-0.3013 G loss:-2.86\n",
      "Epoch:  0029 D loss:-0.3504 G loss:-2.901\n",
      "Epoch:  0029 D loss:-0.3203 G loss:-2.943\n",
      "Epoch:  0029 D loss:-0.3818 G loss:-2.827\n",
      "Epoch:  0029 D loss:-0.3268 G loss:-2.753\n",
      "Epoch:  0029 D loss:-0.3838 G loss:-3.13\n",
      "Epoch:  0029 D loss:-0.4046 G loss:-2.636\n",
      "Epoch:  0029 D loss:-0.4058 G loss:-2.817\n",
      "Epoch:  0029 D loss:-0.3093 G loss:-2.763\n",
      "Epoch:  0029 D loss:-0.4321 G loss:-2.773\n",
      "Epoch:  0029 D loss:-0.3384 G loss:-2.771\n",
      "Epoch:  0029 D loss:-0.3102 G loss:-3.028\n",
      "Epoch:  0029 D loss:-0.4562 G loss:-2.329\n",
      "Epoch:  0029 D loss:-0.4022 G loss:-2.649\n",
      "Epoch:  0029 D loss:-0.5162 G loss:-2.575\n",
      "Epoch:  0029 D loss:-0.3805 G loss:-2.477\n",
      "Epoch:  0029 D loss:-0.3437 G loss:-2.483\n",
      "Epoch:  0029 D loss:-0.448 G loss:-2.72\n",
      "Epoch:  0029 D loss:-0.3557 G loss:-2.583\n",
      "Epoch:  0029 D loss:-0.3991 G loss:-2.58\n",
      "Epoch:  0029 D loss:-0.3938 G loss:-2.705\n",
      "Epoch:  0029 D loss:-0.5024 G loss:-2.763\n",
      "Epoch:  0029 D loss:-0.4552 G loss:-2.822\n",
      "Epoch:  0029 D loss:-0.3483 G loss:-2.723\n",
      "Epoch:  0029 D loss:-0.3569 G loss:-2.668\n",
      "Epoch:  0029 D loss:-0.3662 G loss:-2.668\n",
      "Epoch:  0029 D loss:-0.48 G loss:-2.719\n",
      "Epoch:  0029 D loss:-0.3209 G loss:-2.675\n",
      "Epoch:  0029 D loss:-0.3197 G loss:-2.519\n",
      "Epoch:  0029 D loss:-0.4131 G loss:-2.601\n",
      "Epoch:  0029 D loss:-0.4028 G loss:-2.549\n",
      "Epoch:  0029 D loss:-0.415 G loss:-2.819\n",
      "Epoch:  0029 D loss:-0.3898 G loss:-2.765\n",
      "Epoch:  0029 D loss:-0.3986 G loss:-2.968\n",
      "Epoch:  0029 D loss:-0.3708 G loss:-2.874\n",
      "Epoch:  0029 D loss:-0.3652 G loss:-3.102\n",
      "Epoch:  0029 D loss:-0.3724 G loss:-2.9\n",
      "Epoch:  0029 D loss:-0.3788 G loss:-2.886\n",
      "Epoch:  0029 D loss:-0.3989 G loss:-2.567\n",
      "Epoch:  0029 D loss:-0.3232 G loss:-2.636\n",
      "Epoch:  0029 D loss:-0.4956 G loss:-2.564\n",
      "Epoch:  0029 D loss:-0.3874 G loss:-2.507\n",
      "Epoch:  0029 D loss:-0.3328 G loss:-2.697\n",
      "Epoch:  0029 D loss:-0.5009 G loss:-2.65\n",
      "Epoch:  0029 D loss:-0.3817 G loss:-2.723\n",
      "Epoch:  0029 D loss:-0.4253 G loss:-2.82\n",
      "Epoch:  0029 D loss:-0.4104 G loss:-2.523\n",
      "Epoch:  0029 D loss:-0.3675 G loss:-2.728\n",
      "Epoch:  0029 D loss:-0.4332 G loss:-2.664\n",
      "Epoch:  0029 D loss:-0.3335 G loss:-2.64\n",
      "Epoch:  0029 D loss:-0.3147 G loss:-3.161\n",
      "Epoch:  0029 D loss:-0.4427 G loss:-2.844\n",
      "Epoch:  0029 D loss:-0.3223 G loss:-3.046\n",
      "Epoch:  0029 D loss:-0.4156 G loss:-2.724\n",
      "Epoch:  0029 D loss:-0.337 G loss:-3.192\n",
      "Epoch:  0029 D loss:-0.4152 G loss:-2.926\n",
      "Epoch:  0029 D loss:-0.3067 G loss:-2.82\n",
      "Epoch:  0029 D loss:-0.3644 G loss:-2.999\n",
      "Epoch:  0029 D loss:-0.3791 G loss:-2.719\n",
      "Epoch:  0029 D loss:-0.4001 G loss:-3.243\n",
      "Epoch:  0029 D loss:-0.4308 G loss:-2.78\n",
      "Epoch:  0029 D loss:-0.4244 G loss:-2.68\n",
      "Epoch:  0029 D loss:-0.3676 G loss:-2.684\n",
      "Epoch:  0029 D loss:-0.2829 G loss:-2.64\n",
      "Epoch:  0029 D loss:-0.3643 G loss:-2.779\n",
      "Epoch:  0029 D loss:-0.3237 G loss:-2.609\n",
      "Epoch:  0029 D loss:-0.3526 G loss:-2.874\n",
      "Epoch:  0029 D loss:-0.3383 G loss:-2.645\n",
      "Epoch:  0029 D loss:-0.3093 G loss:-2.67\n",
      "Epoch:  0029 D loss:-0.3061 G loss:-2.871\n",
      "Epoch:  0029 D loss:-0.5065 G loss:-2.643\n",
      "Epoch:  0029 D loss:-0.3262 G loss:-2.758\n",
      "Epoch:  0029 D loss:-0.3562 G loss:-2.748\n",
      "Epoch:  0029 D loss:-0.3781 G loss:-2.614\n",
      "Epoch:  0029 D loss:-0.456 G loss:-2.726\n",
      "Epoch:  0029 D loss:-0.3515 G loss:-2.861\n",
      "Epoch:  0029 D loss:-0.359 G loss:-2.867\n",
      "Epoch:  0029 D loss:-0.4331 G loss:-2.959\n",
      "Epoch:  0029 D loss:-0.3937 G loss:-2.671\n",
      "Epoch:  0029 D loss:-0.4433 G loss:-3.009\n",
      "Epoch:  0029 D loss:-0.3523 G loss:-2.548\n",
      "Epoch:  0029 D loss:-0.4337 G loss:-2.714\n",
      "Epoch:  0029 D loss:-0.3583 G loss:-2.883\n",
      "Epoch:  0029 D loss:-0.3224 G loss:-2.894\n",
      "Epoch:  0029 D loss:-0.3667 G loss:-2.795\n",
      "Epoch:  0029 D loss:-0.3867 G loss:-2.627\n",
      "Epoch:  0029 D loss:-0.3601 G loss:-2.563\n",
      "Epoch:  0029 D loss:-0.3987 G loss:-2.757\n",
      "Epoch:  0029 D loss:-0.4433 G loss:-2.445\n",
      "Epoch:  0029 D loss:-0.4621 G loss:-2.841\n",
      "Epoch:  0029 D loss:-0.3201 G loss:-2.955\n",
      "Epoch:  0029 D loss:-0.4401 G loss:-2.675\n",
      "Epoch:  0029 D loss:-0.4847 G loss:-2.926\n",
      "Epoch:  0029 D loss:-0.5265 G loss:-2.565\n",
      "Epoch:  0029 D loss:-0.3978 G loss:-2.829\n",
      "Epoch:  0029 D loss:-0.3589 G loss:-2.642\n",
      "Epoch:  0029 D loss:-0.379 G loss:-2.915\n",
      "Epoch:  0029 D loss:-0.4238 G loss:-2.618\n",
      "Epoch:  0029 D loss:-0.4677 G loss:-2.939\n",
      "Epoch:  0029 D loss:-0.436 G loss:-2.611\n",
      "Epoch:  0029 D loss:-0.3296 G loss:-2.5\n",
      "Epoch:  0029 D loss:-0.3524 G loss:-2.724\n",
      "Epoch:  0029 D loss:-0.4223 G loss:-2.646\n",
      "Epoch:  0029 D loss:-0.4064 G loss:-2.523\n",
      "Epoch:  0029 D loss:-0.3752 G loss:-2.722\n",
      "Epoch:  0029 D loss:-0.479 G loss:-2.646\n",
      "Epoch:  0029 D loss:-0.3659 G loss:-2.921\n",
      "Epoch:  0029 D loss:-0.392 G loss:-2.848\n",
      "Epoch:  0029 D loss:-0.3554 G loss:-2.818\n",
      "Epoch:  0029 D loss:-0.5058 G loss:-2.536\n",
      "Epoch:  0029 D loss:-0.4659 G loss:-2.715\n",
      "Epoch:  0029 D loss:-0.4188 G loss:-2.766\n",
      "Epoch:  0029 D loss:-0.4505 G loss:-2.398\n",
      "Epoch:  0029 D loss:-0.3712 G loss:-2.759\n",
      "Epoch:  0029 D loss:-0.3641 G loss:-2.749\n",
      "Epoch:  0029 D loss:-0.3894 G loss:-2.522\n",
      "Epoch:  0029 D loss:-0.4018 G loss:-2.622\n",
      "Epoch:  0029 D loss:-0.4362 G loss:-2.821\n",
      "Epoch:  0029 D loss:-0.4172 G loss:-2.567\n",
      "Epoch:  0029 D loss:-0.3461 G loss:-2.638\n",
      "Epoch:  0029 D loss:-0.4022 G loss:-2.595\n",
      "Epoch:  0029 D loss:-0.3523 G loss:-2.87\n",
      "Epoch:  0029 D loss:-0.3767 G loss:-2.616\n",
      "Epoch:  0029 D loss:-0.4199 G loss:-2.773\n",
      "Epoch:  0029 D loss:-0.371 G loss:-2.865\n",
      "Epoch:  0029 D loss:-0.4793 G loss:-2.847\n",
      "Epoch:  0029 D loss:-0.4405 G loss:-2.865\n",
      "Epoch:  0029 D loss:-0.4463 G loss:-2.805\n",
      "Epoch:  0029 D loss:-0.4737 G loss:-2.825\n",
      "Epoch:  0029 D loss:-0.3478 G loss:-2.911\n",
      "Epoch:  0029 D loss:-0.2604 G loss:-3.085\n",
      "Epoch:  0029 D loss:-0.3914 G loss:-2.613\n",
      "Epoch:  0029 D loss:-0.4073 G loss:-2.668\n",
      "Epoch:  0029 D loss:-0.3644 G loss:-2.848\n",
      "Epoch:  0029 D loss:-0.2623 G loss:-3.017\n",
      "Epoch:  0029 D loss:-0.4227 G loss:-2.928\n",
      "Epoch:  0029 D loss:-0.442 G loss:-2.718\n",
      "Epoch:  0029 D loss:-0.337 G loss:-2.78\n",
      "Epoch:  0029 D loss:-0.3535 G loss:-2.786\n",
      "Epoch:  0029 D loss:-0.3628 G loss:-2.561\n",
      "Epoch:  0029 D loss:-0.432 G loss:-2.559\n",
      "Epoch:  0029 D loss:-0.3923 G loss:-2.759\n",
      "Epoch:  0029 D loss:-0.4544 G loss:-2.752\n",
      "Epoch:  0029 D loss:-0.3711 G loss:-2.705\n",
      "Epoch:  0029 D loss:-0.3803 G loss:-2.473\n",
      "Epoch:  0029 D loss:-0.3104 G loss:-2.721\n",
      "Epoch:  0029 D loss:-0.3345 G loss:-2.559\n",
      "Epoch:  0029 D loss:-0.4541 G loss:-2.764\n",
      "Epoch:  0029 D loss:-0.3661 G loss:-3.066\n",
      "Epoch:  0029 D loss:-0.3207 G loss:-2.969\n",
      "Epoch:  0029 D loss:-0.3116 G loss:-3.019\n",
      "Epoch:  0029 D loss:-0.3661 G loss:-3.134\n",
      "Epoch:  0029 D loss:-0.3992 G loss:-2.867\n",
      "Epoch:  0029 D loss:-0.3226 G loss:-3.146\n",
      "Epoch:  0029 D loss:-0.4248 G loss:-3.064\n",
      "Epoch:  0029 D loss:-0.387 G loss:-2.82\n",
      "Epoch:  0029 D loss:-0.3982 G loss:-2.414\n",
      "Epoch:  0029 D loss:-0.4271 G loss:-2.539\n",
      "Epoch:  0029 D loss:-0.3915 G loss:-2.423\n",
      "Epoch:  0029 D loss:-0.4487 G loss:-2.505\n",
      "Epoch:  0029 D loss:-0.4776 G loss:-2.553\n",
      "Epoch:  0029 D loss:-0.4239 G loss:-2.534\n",
      "Epoch:  0029 D loss:-0.3175 G loss:-2.608\n",
      "Epoch:  0029 D loss:-0.5572 G loss:-2.748\n",
      "Epoch:  0029 D loss:-0.3705 G loss:-2.794\n",
      "Epoch:  0029 D loss:-0.3311 G loss:-2.776\n",
      "Epoch:  0029 D loss:-0.3858 G loss:-2.877\n",
      "Epoch:  0029 D loss:-0.426 G loss:-2.812\n",
      "Epoch:  0029 D loss:-0.4311 G loss:-2.858\n",
      "Epoch:  0029 D loss:-0.3919 G loss:-3.011\n",
      "Epoch:  0029 D loss:-0.3771 G loss:-2.914\n",
      "Epoch:  0029 D loss:-0.4684 G loss:-2.804\n",
      "Epoch:  0029 D loss:-0.3559 G loss:-2.574\n",
      "Epoch:  0029 D loss:-0.3345 G loss:-2.633\n",
      "Epoch:  0029 D loss:-0.3922 G loss:-2.262\n",
      "Epoch:  0029 D loss:-0.4581 G loss:-2.45\n",
      "Epoch:  0029 D loss:-0.3971 G loss:-2.649\n",
      "Epoch:  0029 D loss:-0.2857 G loss:-2.669\n",
      "Epoch:  0029 D loss:-0.3594 G loss:-2.491\n",
      "Epoch:  0029 D loss:-0.3234 G loss:-2.842\n",
      "Epoch:  0029 D loss:-0.4643 G loss:-2.854\n",
      "Epoch:  0029 D loss:-0.3755 G loss:-2.935\n",
      "Epoch:  0029 D loss:-0.3663 G loss:-3.014\n",
      "Epoch:  0029 D loss:-0.3808 G loss:-2.905\n",
      "Epoch:  0029 D loss:-0.3985 G loss:-3.116\n",
      "Epoch:  0029 D loss:-0.3931 G loss:-2.991\n",
      "Epoch:  0029 D loss:-0.3698 G loss:-2.823\n",
      "Epoch:  0029 D loss:-0.2692 G loss:-3.06\n",
      "Epoch:  0029 D loss:-0.3845 G loss:-2.856\n",
      "Epoch:  0029 D loss:-0.3342 G loss:-2.735\n",
      "Epoch:  0029 D loss:-0.3339 G loss:-2.569\n",
      "Epoch:  0029 D loss:-0.4245 G loss:-2.759\n",
      "Epoch:  0029 D loss:-0.4698 G loss:-2.417\n",
      "Epoch:  0029 D loss:-0.4189 G loss:-2.534\n",
      "Epoch:  0029 D loss:-0.3626 G loss:-2.456\n",
      "Epoch:  0029 D loss:-0.3283 G loss:-2.492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0029 D loss:-0.4557 G loss:-2.64\n",
      "Epoch:  0029 D loss:-0.434 G loss:-2.785\n",
      "Epoch:  0029 D loss:-0.4344 G loss:-2.869\n",
      "Epoch:  0029 D loss:-0.4102 G loss:-3.146\n",
      "Epoch:  0029 D loss:-0.346 G loss:-2.901\n",
      "Epoch:  0029 D loss:-0.4406 G loss:-2.653\n",
      "Epoch:  0029 D loss:-0.4368 G loss:-2.549\n",
      "Epoch:  0029 D loss:-0.2935 G loss:-2.816\n",
      "Epoch:  0029 D loss:-0.4277 G loss:-2.749\n",
      "Epoch:  0029 D loss:-0.325 G loss:-2.836\n",
      "Epoch:  0029 D loss:-0.3811 G loss:-2.694\n",
      "Epoch:  0029 D loss:-0.3419 G loss:-2.941\n",
      "Epoch:  0029 D loss:-0.4407 G loss:-2.869\n",
      "Epoch:  0029 D loss:-0.4059 G loss:-2.703\n",
      "Epoch:  0029 D loss:-0.3513 G loss:-2.877\n",
      "Epoch:  0029 D loss:-0.3289 G loss:-2.929\n",
      "Epoch:  0029 D loss:-0.4218 G loss:-2.808\n",
      "Epoch:  0029 D loss:-0.3373 G loss:-2.935\n",
      "Epoch:  0029 D loss:-0.3861 G loss:-2.642\n",
      "Epoch:  0029 D loss:-0.3566 G loss:-2.596\n",
      "Epoch:  0029 D loss:-0.3606 G loss:-2.753\n",
      "Epoch:  0029 D loss:-0.4407 G loss:-2.375\n",
      "Epoch:  0029 D loss:-0.4606 G loss:-2.562\n",
      "Epoch:  0029 D loss:-0.328 G loss:-2.745\n",
      "Epoch:  0029 D loss:-0.3596 G loss:-2.771\n",
      "Epoch:  0029 D loss:-0.5262 G loss:-2.69\n",
      "Epoch:  0029 D loss:-0.4191 G loss:-2.801\n",
      "Epoch:  0029 D loss:-0.372 G loss:-2.85\n",
      "Epoch:  0029 D loss:-0.4064 G loss:-2.692\n",
      "Epoch:  0029 D loss:-0.4701 G loss:-2.928\n",
      "Epoch:  0029 D loss:-0.4064 G loss:-2.643\n",
      "Epoch:  0029 D loss:-0.4293 G loss:-2.482\n",
      "Epoch:  0029 D loss:-0.4101 G loss:-2.589\n",
      "Epoch:  0029 D loss:-0.4641 G loss:-2.53\n",
      "Epoch:  0029 D loss:-0.4489 G loss:-2.575\n",
      "Epoch:  0029 D loss:-0.4353 G loss:-2.349\n",
      "Epoch:  0029 D loss:-0.5173 G loss:-2.309\n",
      "Epoch:  0029 D loss:-0.3745 G loss:-2.393\n",
      "Epoch:  0029 D loss:-0.383 G loss:-2.551\n",
      "Epoch:  0029 D loss:-0.4264 G loss:-2.676\n",
      "Epoch:  0029 D loss:-0.397 G loss:-2.768\n",
      "Epoch:  0029 D loss:-0.3602 G loss:-2.673\n",
      "Epoch:  0029 D loss:-0.3978 G loss:-2.761\n",
      "Epoch:  0029 D loss:-0.4434 G loss:-2.746\n",
      "Epoch:  0029 D loss:-0.3416 G loss:-2.696\n",
      "Epoch:  0029 D loss:-0.2291 G loss:-3.169\n",
      "Epoch:  0029 D loss:-0.3665 G loss:-2.906\n",
      "Epoch:  0029 D loss:-0.3545 G loss:-2.873\n",
      "Epoch:  0029 D loss:-0.5551 G loss:-2.688\n",
      "Epoch:  0029 D loss:-0.3991 G loss:-2.628\n",
      "Epoch:  0029 D loss:-0.3532 G loss:-2.619\n",
      "Epoch:  0029 D loss:-0.4097 G loss:-2.644\n",
      "Epoch:  0029 D loss:-0.4637 G loss:-2.671\n",
      "Epoch:  0029 D loss:-0.4837 G loss:-2.611\n",
      "Epoch:  0029 D loss:-0.3835 G loss:-2.554\n",
      "Epoch:  0029 D loss:-0.3719 G loss:-2.475\n",
      "Epoch:  0029 D loss:-0.5582 G loss:-2.469\n",
      "Epoch:  0029 D loss:-0.3638 G loss:-2.648\n",
      "Epoch:  0029 D loss:-0.5149 G loss:-2.227\n",
      "Epoch:  0029 D loss:-0.3928 G loss:-2.701\n",
      "Epoch:  0029 D loss:-0.4314 G loss:-2.595\n",
      "Epoch:  0029 D loss:-0.3804 G loss:-2.751\n",
      "Epoch:  0029 D loss:-0.3366 G loss:-2.862\n",
      "Epoch:  0029 D loss:-0.4565 G loss:-2.855\n",
      "Epoch:  0029 D loss:-0.4202 G loss:-2.727\n",
      "Epoch:  0029 D loss:-0.5603 G loss:-2.559\n",
      "Epoch:  0029 D loss:-0.4577 G loss:-2.702\n",
      "Epoch:  0029 D loss:-0.4233 G loss:-2.591\n",
      "Epoch:  0029 D loss:-0.4643 G loss:-2.684\n",
      "Epoch:  0029 D loss:-0.4749 G loss:-2.514\n",
      "Epoch:  0029 D loss:-0.57 G loss:-2.26\n",
      "Epoch:  0029 D loss:-0.4056 G loss:-2.375\n",
      "Epoch:  0029 D loss:-0.4678 G loss:-2.377\n",
      "Epoch:  0029 D loss:-0.4044 G loss:-2.594\n",
      "Epoch:  0029 D loss:-0.4275 G loss:-2.469\n",
      "Epoch:  0029 D loss:-0.3812 G loss:-2.441\n",
      "Epoch:  0029 D loss:-0.3665 G loss:-2.584\n",
      "Epoch:  0029 D loss:-0.4435 G loss:-2.576\n",
      "Epoch:  0029 D loss:-0.4251 G loss:-2.913\n",
      "Epoch:  0029 D loss:-0.4367 G loss:-2.6\n",
      "Epoch:  0029 D loss:-0.3576 G loss:-2.773\n",
      "Epoch:  0029 D loss:-0.4337 G loss:-2.786\n",
      "Epoch:  0029 D loss:-0.4882 G loss:-2.784\n",
      "Epoch:  0029 D loss:-0.3599 G loss:-2.701\n",
      "Epoch:  0029 D loss:-0.3422 G loss:-2.56\n",
      "Epoch:  0029 D loss:-0.5127 G loss:-2.688\n",
      "Epoch:  0029 D loss:-0.4634 G loss:-2.655\n",
      "Epoch:  0029 D loss:-0.4705 G loss:-2.639\n",
      "Epoch:  0029 D loss:-0.5186 G loss:-2.53\n",
      "Epoch:  0029 D loss:-0.377 G loss:-2.445\n",
      "Epoch:  0029 D loss:-0.4032 G loss:-2.65\n",
      "Epoch:  0029 D loss:-0.4591 G loss:-2.453\n",
      "Epoch:  0029 D loss:-0.371 G loss:-2.469\n",
      "Epoch:  0029 D loss:-0.3963 G loss:-2.588\n",
      "Epoch:  0029 D loss:-0.458 G loss:-2.502\n",
      "Epoch:  0029 D loss:-0.4517 G loss:-2.376\n",
      "Epoch:  0029 D loss:-0.4008 G loss:-2.507\n",
      "Epoch:  0029 D loss:-0.5833 G loss:-2.633\n",
      "Epoch:  0029 D loss:-0.3631 G loss:-2.827\n",
      "Epoch:  0029 D loss:-0.5329 G loss:-2.686\n",
      "Epoch:  0029 D loss:-0.4986 G loss:-2.505\n",
      "Epoch:  0029 D loss:-0.433 G loss:-2.418\n",
      "Epoch:  0029 D loss:-0.4124 G loss:-2.422\n",
      "Epoch:  0029 D loss:-0.4581 G loss:-2.656\n",
      "Epoch:  0029 D loss:-0.5096 G loss:-2.427\n",
      "Epoch:  0029 D loss:-0.4736 G loss:-2.7\n",
      "Epoch:  0029 D loss:-0.3534 G loss:-2.536\n",
      "Epoch:  0029 D loss:-0.3094 G loss:-2.498\n",
      "Epoch:  0029 D loss:-0.3052 G loss:-2.79\n",
      "Epoch:  0029 D loss:-0.323 G loss:-2.47\n",
      "Epoch:  0029 D loss:-0.4425 G loss:-2.508\n",
      "Epoch:  0029 D loss:-0.3812 G loss:-2.692\n",
      "Epoch:  0029 D loss:-0.3033 G loss:-2.948\n",
      "Epoch:  0029 D loss:-0.3393 G loss:-2.959\n",
      "Epoch:  0029 D loss:-0.4372 G loss:-2.593\n",
      "Epoch:  0029 D loss:-0.5191 G loss:-2.744\n",
      "Epoch:  0029 D loss:-0.3315 G loss:-2.881\n",
      "Epoch:  0029 D loss:-0.4374 G loss:-2.622\n",
      "Epoch:  0029 D loss:-0.4897 G loss:-2.64\n",
      "Epoch:  0029 D loss:-0.436 G loss:-2.397\n",
      "Epoch:  0029 D loss:-0.3879 G loss:-2.703\n",
      "Epoch:  0029 D loss:-0.3543 G loss:-2.553\n",
      "Epoch:  0029 D loss:-0.5285 G loss:-2.357\n",
      "Epoch:  0029 D loss:-0.3894 G loss:-2.514\n",
      "Epoch:  0029 D loss:-0.4179 G loss:-2.517\n",
      "Epoch:  0029 D loss:-0.4676 G loss:-2.184\n",
      "Epoch:  0029 D loss:-0.5096 G loss:-2.393\n",
      "Epoch:  0029 D loss:-0.429 G loss:-2.707\n",
      "Epoch:  0029 D loss:-0.4234 G loss:-2.507\n",
      "Epoch:  0029 D loss:-0.4345 G loss:-2.881\n",
      "Epoch:  0029 D loss:-0.4466 G loss:-2.811\n",
      "Epoch:  0029 D loss:-0.3905 G loss:-2.663\n",
      "Epoch:  0029 D loss:-0.4139 G loss:-2.553\n",
      "Epoch:  0029 D loss:-0.4321 G loss:-2.614\n",
      "Epoch:  0029 D loss:-0.3902 G loss:-2.531\n",
      "Epoch:  0029 D loss:-0.3504 G loss:-2.843\n",
      "Epoch:  0029 D loss:-0.4467 G loss:-2.623\n",
      "Epoch:  0029 D loss:-0.3487 G loss:-2.754\n",
      "Epoch:  0029 D loss:-0.3319 G loss:-2.69\n",
      "Epoch:  0029 D loss:-0.4489 G loss:-2.465\n",
      "Epoch:  0029 D loss:-0.3985 G loss:-2.547\n",
      "Epoch:  0029 D loss:-0.5302 G loss:-2.931\n",
      "Epoch:  0029 D loss:-0.4787 G loss:-2.514\n",
      "Epoch:  0029 D loss:-0.4691 G loss:-2.491\n",
      "Epoch:  0029 D loss:-0.3259 G loss:-2.458\n",
      "Epoch:  0029 D loss:-0.4729 G loss:-2.504\n",
      "Epoch:  0029 D loss:-0.3761 G loss:-2.634\n",
      "Epoch:  0029 D loss:-0.3573 G loss:-2.799\n",
      "Epoch:  0029 D loss:-0.3866 G loss:-2.746\n",
      "Epoch:  0029 D loss:-0.4329 G loss:-2.549\n",
      "Epoch:  0029 D loss:-0.4852 G loss:-2.708\n",
      "Epoch:  0029 D loss:-0.3997 G loss:-2.498\n",
      "Epoch:  0029 D loss:-0.4335 G loss:-2.755\n",
      "Epoch:  0029 D loss:-0.3869 G loss:-2.844\n",
      "Epoch:  0029 D loss:-0.4213 G loss:-2.742\n",
      "Epoch:  0029 D loss:-0.4155 G loss:-2.64\n",
      "Epoch:  0029 D loss:-0.3836 G loss:-2.67\n",
      "Epoch:  0029 D loss:-0.4244 G loss:-2.457\n",
      "Epoch:  0029 D loss:-0.4267 G loss:-2.672\n",
      "Epoch:  0029 D loss:-0.4208 G loss:-2.444\n",
      "Epoch:  0029 D loss:-0.3811 G loss:-2.662\n",
      "Epoch:  0029 D loss:-0.4861 G loss:-2.593\n",
      "Epoch:  0029 D loss:-0.4735 G loss:-2.742\n",
      "Epoch:  0029 D loss:-0.5728 G loss:-2.602\n",
      "Epoch:  0029 D loss:-0.3973 G loss:-2.583\n",
      "Epoch:  0029 D loss:-0.4698 G loss:-2.444\n",
      "Epoch:  0029 D loss:-0.4467 G loss:-2.405\n",
      "Epoch:  0029 D loss:-0.3933 G loss:-2.513\n",
      "Epoch:  0029 D loss:-0.3708 G loss:-2.626\n",
      "Epoch:  0029 D loss:-0.4167 G loss:-2.49\n",
      "Epoch:  0029 D loss:-0.4022 G loss:-2.506\n",
      "Epoch:  0029 D loss:-0.3962 G loss:-2.591\n",
      "Epoch:  0029 D loss:-0.3985 G loss:-2.655\n",
      "Epoch:  0029 D loss:-0.4221 G loss:-2.513\n",
      "Epoch:  0029 D loss:-0.3956 G loss:-2.78\n",
      "Epoch:  0029 D loss:-0.3903 G loss:-2.897\n",
      "Epoch:  0029 D loss:-0.3076 G loss:-2.906\n",
      "Epoch:  0029 D loss:-0.4368 G loss:-2.962\n",
      "Epoch:  0029 D loss:-0.3988 G loss:-2.956\n",
      "Epoch:  0029 D loss:-0.349 G loss:-2.576\n",
      "Epoch:  0029 D loss:-0.4279 G loss:-2.589\n",
      "Epoch:  0029 D loss:-0.3061 G loss:-2.66\n",
      "Epoch:  0029 D loss:-0.423 G loss:-2.591\n",
      "Epoch:  0029 D loss:-0.3348 G loss:-2.812\n",
      "Epoch:  0029 D loss:-0.5045 G loss:-2.369\n",
      "Epoch:  0029 D loss:-0.4278 G loss:-2.703\n",
      "Epoch:  0029 D loss:-0.3764 G loss:-2.765\n",
      "Epoch:  0029 D loss:-0.3245 G loss:-2.67\n",
      "Epoch:  0029 D loss:-0.4558 G loss:-2.578\n",
      "Epoch:  0029 D loss:-0.3668 G loss:-2.579\n",
      "Epoch:  0029 D loss:-0.3978 G loss:-2.507\n",
      "Epoch:  0029 D loss:-0.3043 G loss:-2.715\n",
      "Epoch:  0029 D loss:-0.377 G loss:-2.518\n",
      "Epoch:  0029 D loss:-0.4494 G loss:-2.689\n",
      "Epoch:  0029 D loss:-0.4478 G loss:-2.744\n",
      "Epoch:  0029 D loss:-0.3238 G loss:-2.761\n",
      "Epoch:  0029 D loss:-0.438 G loss:-2.737\n",
      "Epoch:  0029 D loss:-0.277 G loss:-2.918\n",
      "Epoch:  0029 D loss:-0.4328 G loss:-2.643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0029 D loss:-0.5474 G loss:-2.567\n",
      "Epoch:  0029 D loss:-0.4454 G loss:-2.801\n",
      "Epoch:  0029 D loss:-0.3213 G loss:-2.577\n",
      "Epoch:  0029 D loss:-0.4266 G loss:-2.396\n",
      "Epoch:  0029 D loss:-0.3548 G loss:-2.634\n",
      "Epoch:  0029 D loss:-0.3918 G loss:-2.554\n",
      "Epoch:  0029 D loss:-0.4172 G loss:-2.63\n",
      "Epoch:  0029 D loss:-0.4462 G loss:-2.541\n",
      "Epoch:  0029 D loss:-0.4138 G loss:-2.704\n",
      "Epoch:  0029 D loss:-0.2977 G loss:-2.808\n",
      "Epoch:  0029 D loss:-0.3722 G loss:-2.707\n",
      "Epoch:  0029 D loss:-0.3714 G loss:-2.528\n",
      "Epoch:  0029 D loss:-0.3444 G loss:-2.813\n",
      "Epoch:  0029 D loss:-0.4746 G loss:-2.573\n",
      "Epoch:  0029 D loss:-0.4238 G loss:-2.64\n",
      "Epoch:  0029 D loss:-0.5578 G loss:-2.465\n",
      "Epoch:  0029 D loss:-0.3896 G loss:-2.659\n",
      "Epoch:  0029 D loss:-0.628 G loss:-2.423\n",
      "Epoch:  0029 D loss:-0.463 G loss:-2.525\n",
      "Epoch:  0029 D loss:-0.3676 G loss:-2.513\n",
      "Epoch:  0029 D loss:-0.4122 G loss:-2.514\n",
      "Epoch:  0029 D loss:-0.4126 G loss:-2.212\n",
      "Epoch:  0029 D loss:-0.4916 G loss:-2.371\n",
      "Epoch:  0029 D loss:-0.397 G loss:-2.548\n",
      "Epoch:  0029 D loss:-0.5579 G loss:-2.449\n",
      "Epoch:  0030 D loss:-0.4228 G loss:-2.771\n",
      "Epoch:  0030 D loss:-0.5723 G loss:-2.533\n",
      "Epoch:  0030 D loss:-0.5785 G loss:-2.43\n",
      "Epoch:  0030 D loss:-0.446 G loss:-2.675\n",
      "Epoch:  0030 D loss:-0.3959 G loss:-2.627\n",
      "Epoch:  0030 D loss:-0.4605 G loss:-2.698\n",
      "Epoch:  0030 D loss:-0.3319 G loss:-2.83\n",
      "Epoch:  0030 D loss:-0.3446 G loss:-2.533\n",
      "Epoch:  0030 D loss:-0.3852 G loss:-2.688\n",
      "Epoch:  0030 D loss:-0.3602 G loss:-2.792\n",
      "Epoch:  0030 D loss:-0.4967 G loss:-2.65\n",
      "Epoch:  0030 D loss:-0.3904 G loss:-2.799\n",
      "Epoch:  0030 D loss:-0.4584 G loss:-2.752\n",
      "Epoch:  0030 D loss:-0.3735 G loss:-2.659\n",
      "Epoch:  0030 D loss:-0.3311 G loss:-2.64\n",
      "Epoch:  0030 D loss:-0.3514 G loss:-2.62\n",
      "Epoch:  0030 D loss:-0.5012 G loss:-2.595\n",
      "Epoch:  0030 D loss:-0.4451 G loss:-2.573\n",
      "Epoch:  0030 D loss:-0.5481 G loss:-2.471\n",
      "Epoch:  0030 D loss:-0.5103 G loss:-2.436\n",
      "Epoch:  0030 D loss:-0.4639 G loss:-2.569\n",
      "Epoch:  0030 D loss:-0.443 G loss:-2.415\n",
      "Epoch:  0030 D loss:-0.4744 G loss:-2.513\n",
      "Epoch:  0030 D loss:-0.4891 G loss:-2.557\n",
      "Epoch:  0030 D loss:-0.5259 G loss:-2.731\n",
      "Epoch:  0030 D loss:-0.3765 G loss:-2.809\n",
      "Epoch:  0030 D loss:-0.418 G loss:-2.632\n",
      "Epoch:  0030 D loss:-0.4002 G loss:-2.833\n",
      "Epoch:  0030 D loss:-0.4205 G loss:-2.76\n",
      "Epoch:  0030 D loss:-0.4413 G loss:-2.768\n",
      "Epoch:  0030 D loss:-0.4616 G loss:-2.845\n",
      "Epoch:  0030 D loss:-0.4979 G loss:-2.619\n",
      "Epoch:  0030 D loss:-0.4424 G loss:-2.874\n",
      "Epoch:  0030 D loss:-0.3014 G loss:-2.624\n",
      "Epoch:  0030 D loss:-0.4733 G loss:-2.556\n",
      "Epoch:  0030 D loss:-0.5104 G loss:-2.623\n",
      "Epoch:  0030 D loss:-0.3942 G loss:-2.426\n",
      "Epoch:  0030 D loss:-0.4542 G loss:-2.436\n",
      "Epoch:  0030 D loss:-0.2903 G loss:-2.671\n",
      "Epoch:  0030 D loss:-0.4422 G loss:-2.551\n",
      "Epoch:  0030 D loss:-0.4379 G loss:-2.411\n",
      "Epoch:  0030 D loss:-0.4155 G loss:-2.507\n",
      "Epoch:  0030 D loss:-0.4139 G loss:-2.605\n",
      "Epoch:  0030 D loss:-0.381 G loss:-2.363\n",
      "Epoch:  0030 D loss:-0.4688 G loss:-2.572\n",
      "Epoch:  0030 D loss:-0.4684 G loss:-2.615\n",
      "Epoch:  0030 D loss:-0.4506 G loss:-2.646\n",
      "Epoch:  0030 D loss:-0.4684 G loss:-2.627\n",
      "Epoch:  0030 D loss:-0.4477 G loss:-2.707\n",
      "Epoch:  0030 D loss:-0.5024 G loss:-2.607\n",
      "Epoch:  0030 D loss:-0.4135 G loss:-2.75\n",
      "Epoch:  0030 D loss:-0.3628 G loss:-2.948\n",
      "Epoch:  0030 D loss:-0.4024 G loss:-2.716\n",
      "Epoch:  0030 D loss:-0.4453 G loss:-2.595\n",
      "Epoch:  0030 D loss:-0.5003 G loss:-2.62\n",
      "Epoch:  0030 D loss:-0.4146 G loss:-2.756\n",
      "Epoch:  0030 D loss:-0.3901 G loss:-2.641\n",
      "Epoch:  0030 D loss:-0.4402 G loss:-2.606\n",
      "Epoch:  0030 D loss:-0.4348 G loss:-2.678\n",
      "Epoch:  0030 D loss:-0.3646 G loss:-2.792\n",
      "Epoch:  0030 D loss:-0.5354 G loss:-2.301\n",
      "Epoch:  0030 D loss:-0.4802 G loss:-2.513\n",
      "Epoch:  0030 D loss:-0.4315 G loss:-2.666\n",
      "Epoch:  0030 D loss:-0.3576 G loss:-2.669\n",
      "Epoch:  0030 D loss:-0.4606 G loss:-2.584\n",
      "Epoch:  0030 D loss:-0.4964 G loss:-2.406\n",
      "Epoch:  0030 D loss:-0.4519 G loss:-2.513\n",
      "Epoch:  0030 D loss:-0.523 G loss:-2.525\n",
      "Epoch:  0030 D loss:-0.4831 G loss:-2.418\n",
      "Epoch:  0030 D loss:-0.3972 G loss:-2.532\n",
      "Epoch:  0030 D loss:-0.4164 G loss:-2.596\n",
      "Epoch:  0030 D loss:-0.5912 G loss:-2.376\n",
      "Epoch:  0030 D loss:-0.3949 G loss:-2.576\n",
      "Epoch:  0030 D loss:-0.4833 G loss:-2.268\n",
      "Epoch:  0030 D loss:-0.4516 G loss:-2.122\n",
      "Epoch:  0030 D loss:-0.5219 G loss:-2.575\n",
      "Epoch:  0030 D loss:-0.586 G loss:-2.508\n",
      "Epoch:  0030 D loss:-0.4728 G loss:-2.529\n",
      "Epoch:  0030 D loss:-0.4025 G loss:-2.547\n",
      "Epoch:  0030 D loss:-0.4358 G loss:-2.612\n",
      "Epoch:  0030 D loss:-0.4793 G loss:-2.532\n",
      "Epoch:  0030 D loss:-0.4386 G loss:-2.513\n",
      "Epoch:  0030 D loss:-0.3258 G loss:-2.96\n",
      "Epoch:  0030 D loss:-0.5305 G loss:-2.723\n",
      "Epoch:  0030 D loss:-0.3963 G loss:-2.713\n",
      "Epoch:  0030 D loss:-0.4527 G loss:-2.671\n",
      "Epoch:  0030 D loss:-0.5077 G loss:-2.567\n",
      "Epoch:  0030 D loss:-0.3385 G loss:-2.689\n",
      "Epoch:  0030 D loss:-0.3541 G loss:-2.512\n",
      "Epoch:  0030 D loss:-0.5294 G loss:-2.727\n",
      "Epoch:  0030 D loss:-0.3502 G loss:-2.653\n",
      "Epoch:  0030 D loss:-0.4145 G loss:-2.617\n",
      "Epoch:  0030 D loss:-0.4067 G loss:-2.619\n",
      "Epoch:  0030 D loss:-0.4857 G loss:-2.472\n",
      "Epoch:  0030 D loss:-0.45 G loss:-2.419\n",
      "Epoch:  0030 D loss:-0.5482 G loss:-2.438\n",
      "Epoch:  0030 D loss:-0.4853 G loss:-2.362\n",
      "Epoch:  0030 D loss:-0.5189 G loss:-2.508\n",
      "Epoch:  0030 D loss:-0.4528 G loss:-2.623\n",
      "Epoch:  0030 D loss:-0.489 G loss:-2.588\n",
      "Epoch:  0030 D loss:-0.5824 G loss:-2.296\n",
      "Epoch:  0030 D loss:-0.5844 G loss:-2.408\n",
      "Epoch:  0030 D loss:-0.4867 G loss:-2.338\n",
      "Epoch:  0030 D loss:-0.4345 G loss:-2.609\n",
      "Epoch:  0030 D loss:-0.4699 G loss:-2.76\n",
      "Epoch:  0030 D loss:-0.5239 G loss:-2.553\n",
      "Epoch:  0030 D loss:-0.5027 G loss:-2.541\n",
      "Epoch:  0030 D loss:-0.3886 G loss:-2.408\n",
      "Epoch:  0030 D loss:-0.3857 G loss:-2.528\n",
      "Epoch:  0030 D loss:-0.46 G loss:-2.824\n",
      "Epoch:  0030 D loss:-0.3396 G loss:-2.786\n",
      "Epoch:  0030 D loss:-0.4373 G loss:-2.696\n",
      "Epoch:  0030 D loss:-0.4459 G loss:-2.766\n",
      "Epoch:  0030 D loss:-0.3617 G loss:-2.418\n",
      "Epoch:  0030 D loss:-0.3578 G loss:-2.779\n",
      "Epoch:  0030 D loss:-0.3497 G loss:-2.92\n",
      "Epoch:  0030 D loss:-0.3965 G loss:-2.734\n",
      "Epoch:  0030 D loss:-0.3528 G loss:-2.613\n",
      "Epoch:  0030 D loss:-0.3624 G loss:-2.599\n",
      "Epoch:  0030 D loss:-0.4193 G loss:-2.6\n",
      "Epoch:  0030 D loss:-0.4412 G loss:-2.733\n",
      "Epoch:  0030 D loss:-0.4486 G loss:-2.619\n",
      "Epoch:  0030 D loss:-0.4344 G loss:-2.631\n",
      "Epoch:  0030 D loss:-0.3486 G loss:-2.719\n",
      "Epoch:  0030 D loss:-0.4272 G loss:-2.607\n",
      "Epoch:  0030 D loss:-0.3169 G loss:-2.632\n",
      "Epoch:  0030 D loss:-0.386 G loss:-2.745\n",
      "Epoch:  0030 D loss:-0.5221 G loss:-2.673\n",
      "Epoch:  0030 D loss:-0.3851 G loss:-2.826\n",
      "Epoch:  0030 D loss:-0.3403 G loss:-2.944\n",
      "Epoch:  0030 D loss:-0.3788 G loss:-3.052\n",
      "Epoch:  0030 D loss:-0.5407 G loss:-2.483\n",
      "Epoch:  0030 D loss:-0.4265 G loss:-2.881\n",
      "Epoch:  0030 D loss:-0.3588 G loss:-2.767\n",
      "Epoch:  0030 D loss:-0.4309 G loss:-2.819\n",
      "Epoch:  0030 D loss:-0.444 G loss:-2.659\n",
      "Epoch:  0030 D loss:-0.354 G loss:-2.751\n",
      "Epoch:  0030 D loss:-0.4337 G loss:-2.728\n",
      "Epoch:  0030 D loss:-0.4541 G loss:-2.706\n",
      "Epoch:  0030 D loss:-0.4252 G loss:-2.722\n",
      "Epoch:  0030 D loss:-0.3765 G loss:-2.697\n",
      "Epoch:  0030 D loss:-0.4476 G loss:-2.823\n",
      "Epoch:  0030 D loss:-0.3463 G loss:-2.622\n",
      "Epoch:  0030 D loss:-0.4294 G loss:-2.725\n",
      "Epoch:  0030 D loss:-0.3927 G loss:-2.848\n",
      "Epoch:  0030 D loss:-0.468 G loss:-2.7\n",
      "Epoch:  0030 D loss:-0.3241 G loss:-2.852\n",
      "Epoch:  0030 D loss:-0.5442 G loss:-2.851\n",
      "Epoch:  0030 D loss:-0.4031 G loss:-2.853\n",
      "Epoch:  0030 D loss:-0.4706 G loss:-2.889\n",
      "Epoch:  0030 D loss:-0.383 G loss:-2.737\n",
      "Epoch:  0030 D loss:-0.4382 G loss:-2.686\n",
      "Epoch:  0030 D loss:-0.3592 G loss:-2.684\n",
      "Epoch:  0030 D loss:-0.3914 G loss:-2.62\n",
      "Epoch:  0030 D loss:-0.4501 G loss:-2.556\n",
      "Epoch:  0030 D loss:-0.3387 G loss:-2.667\n",
      "Epoch:  0030 D loss:-0.5571 G loss:-2.416\n",
      "Epoch:  0030 D loss:-0.4109 G loss:-2.591\n",
      "Epoch:  0030 D loss:-0.3679 G loss:-2.859\n",
      "Epoch:  0030 D loss:-0.3249 G loss:-2.75\n",
      "Epoch:  0030 D loss:-0.4461 G loss:-2.681\n",
      "Epoch:  0030 D loss:-0.5543 G loss:-2.714\n",
      "Epoch:  0030 D loss:-0.4554 G loss:-2.769\n",
      "Epoch:  0030 D loss:-0.4956 G loss:-2.67\n",
      "Epoch:  0030 D loss:-0.5413 G loss:-2.618\n",
      "Epoch:  0030 D loss:-0.4475 G loss:-2.787\n",
      "Epoch:  0030 D loss:-0.4645 G loss:-2.313\n",
      "Epoch:  0030 D loss:-0.3687 G loss:-2.458\n",
      "Epoch:  0030 D loss:-0.397 G loss:-2.473\n",
      "Epoch:  0030 D loss:-0.304 G loss:-2.522\n",
      "Epoch:  0030 D loss:-0.3445 G loss:-2.846\n",
      "Epoch:  0030 D loss:-0.4507 G loss:-2.558\n",
      "Epoch:  0030 D loss:-0.4689 G loss:-2.56\n",
      "Epoch:  0030 D loss:-0.4865 G loss:-2.926\n",
      "Epoch:  0030 D loss:-0.3569 G loss:-3.014\n",
      "Epoch:  0030 D loss:-0.4078 G loss:-2.662\n",
      "Epoch:  0030 D loss:-0.4108 G loss:-2.975\n",
      "Epoch:  0030 D loss:-0.5855 G loss:-2.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0030 D loss:-0.4816 G loss:-3.0\n",
      "Epoch:  0030 D loss:-0.3838 G loss:-2.632\n",
      "Epoch:  0030 D loss:-0.4869 G loss:-2.792\n",
      "Epoch:  0030 D loss:-0.3992 G loss:-2.88\n",
      "Epoch:  0030 D loss:-0.3371 G loss:-2.678\n",
      "Epoch:  0030 D loss:-0.4876 G loss:-2.493\n",
      "Epoch:  0030 D loss:-0.449 G loss:-2.549\n",
      "Epoch:  0030 D loss:-0.3849 G loss:-2.631\n",
      "Epoch:  0030 D loss:-0.4647 G loss:-2.276\n",
      "Epoch:  0030 D loss:-0.4259 G loss:-2.421\n",
      "Epoch:  0030 D loss:-0.4168 G loss:-2.481\n",
      "Epoch:  0030 D loss:-0.6078 G loss:-2.333\n",
      "Epoch:  0030 D loss:-0.3716 G loss:-2.713\n",
      "Epoch:  0030 D loss:-0.5096 G loss:-2.398\n",
      "Epoch:  0030 D loss:-0.4888 G loss:-2.848\n",
      "Epoch:  0030 D loss:-0.5421 G loss:-2.472\n",
      "Epoch:  0030 D loss:-0.5002 G loss:-2.405\n",
      "Epoch:  0030 D loss:-0.4802 G loss:-2.784\n",
      "Epoch:  0030 D loss:-0.4925 G loss:-2.82\n",
      "Epoch:  0030 D loss:-0.56 G loss:-2.531\n",
      "Epoch:  0030 D loss:-0.4122 G loss:-2.772\n",
      "Epoch:  0030 D loss:-0.3885 G loss:-2.643\n",
      "Epoch:  0030 D loss:-0.4685 G loss:-2.537\n",
      "Epoch:  0030 D loss:-0.4458 G loss:-2.377\n",
      "Epoch:  0030 D loss:-0.4021 G loss:-2.786\n",
      "Epoch:  0030 D loss:-0.4168 G loss:-2.604\n",
      "Epoch:  0030 D loss:-0.4875 G loss:-2.523\n",
      "Epoch:  0030 D loss:-0.4921 G loss:-2.637\n",
      "Epoch:  0030 D loss:-0.4804 G loss:-2.616\n",
      "Epoch:  0030 D loss:-0.5074 G loss:-2.792\n",
      "Epoch:  0030 D loss:-0.5435 G loss:-2.359\n",
      "Epoch:  0030 D loss:-0.4232 G loss:-2.765\n",
      "Epoch:  0030 D loss:-0.4798 G loss:-2.514\n",
      "Epoch:  0030 D loss:-0.4427 G loss:-2.629\n",
      "Epoch:  0030 D loss:-0.4901 G loss:-2.85\n",
      "Epoch:  0030 D loss:-0.4852 G loss:-2.688\n",
      "Epoch:  0030 D loss:-0.4852 G loss:-2.864\n",
      "Epoch:  0030 D loss:-0.6706 G loss:-2.641\n",
      "Epoch:  0030 D loss:-0.4378 G loss:-2.642\n",
      "Epoch:  0030 D loss:-0.3927 G loss:-2.65\n",
      "Epoch:  0030 D loss:-0.4704 G loss:-2.677\n",
      "Epoch:  0030 D loss:-0.5519 G loss:-2.308\n",
      "Epoch:  0030 D loss:-0.4723 G loss:-2.392\n",
      "Epoch:  0030 D loss:-0.4597 G loss:-2.529\n",
      "Epoch:  0030 D loss:-0.5575 G loss:-2.582\n",
      "Epoch:  0030 D loss:-0.4704 G loss:-2.569\n",
      "Epoch:  0030 D loss:-0.5043 G loss:-2.728\n",
      "Epoch:  0030 D loss:-0.4932 G loss:-2.499\n",
      "Epoch:  0030 D loss:-0.48 G loss:-2.601\n",
      "Epoch:  0030 D loss:-0.4075 G loss:-2.795\n",
      "Epoch:  0030 D loss:-0.4252 G loss:-2.558\n",
      "Epoch:  0030 D loss:-0.3865 G loss:-2.889\n",
      "Epoch:  0030 D loss:-0.4966 G loss:-2.399\n",
      "Epoch:  0030 D loss:-0.3796 G loss:-2.728\n",
      "Epoch:  0030 D loss:-0.51 G loss:-2.802\n",
      "Epoch:  0030 D loss:-0.4866 G loss:-2.859\n",
      "Epoch:  0030 D loss:-0.4101 G loss:-2.811\n",
      "Epoch:  0030 D loss:-0.5091 G loss:-2.767\n",
      "Epoch:  0030 D loss:-0.5812 G loss:-2.951\n",
      "Epoch:  0030 D loss:-0.4593 G loss:-2.567\n",
      "Epoch:  0030 D loss:-0.5355 G loss:-2.451\n",
      "Epoch:  0030 D loss:-0.5125 G loss:-2.347\n",
      "Epoch:  0030 D loss:-0.4127 G loss:-2.443\n",
      "Epoch:  0030 D loss:-0.4982 G loss:-2.478\n",
      "Epoch:  0030 D loss:-0.5593 G loss:-2.377\n",
      "Epoch:  0030 D loss:-0.5222 G loss:-2.462\n",
      "Epoch:  0030 D loss:-0.4115 G loss:-2.581\n",
      "Epoch:  0030 D loss:-0.4741 G loss:-2.581\n",
      "Epoch:  0030 D loss:-0.4404 G loss:-2.693\n",
      "Epoch:  0030 D loss:-0.4344 G loss:-2.73\n",
      "Epoch:  0030 D loss:-0.5291 G loss:-2.664\n",
      "Epoch:  0030 D loss:-0.4148 G loss:-2.967\n",
      "Epoch:  0030 D loss:-0.4819 G loss:-2.945\n",
      "Epoch:  0030 D loss:-0.3982 G loss:-3.142\n",
      "Epoch:  0030 D loss:-0.4556 G loss:-2.663\n",
      "Epoch:  0030 D loss:-0.515 G loss:-2.63\n",
      "Epoch:  0030 D loss:-0.387 G loss:-2.723\n",
      "Epoch:  0030 D loss:-0.4306 G loss:-2.584\n",
      "Epoch:  0030 D loss:-0.4756 G loss:-2.445\n",
      "Epoch:  0030 D loss:-0.4245 G loss:-2.503\n",
      "Epoch:  0030 D loss:-0.4257 G loss:-2.477\n",
      "Epoch:  0030 D loss:-0.4945 G loss:-2.49\n",
      "Epoch:  0030 D loss:-0.4831 G loss:-2.495\n",
      "Epoch:  0030 D loss:-0.4124 G loss:-2.453\n",
      "Epoch:  0030 D loss:-0.5667 G loss:-2.457\n",
      "Epoch:  0030 D loss:-0.4898 G loss:-2.494\n",
      "Epoch:  0030 D loss:-0.4432 G loss:-2.629\n",
      "Epoch:  0030 D loss:-0.4563 G loss:-2.627\n",
      "Epoch:  0030 D loss:-0.5841 G loss:-2.469\n",
      "Epoch:  0030 D loss:-0.4361 G loss:-2.546\n",
      "Epoch:  0030 D loss:-0.392 G loss:-2.725\n",
      "Epoch:  0030 D loss:-0.4641 G loss:-2.662\n",
      "Epoch:  0030 D loss:-0.4397 G loss:-2.653\n",
      "Epoch:  0030 D loss:-0.5513 G loss:-2.691\n",
      "Epoch:  0030 D loss:-0.467 G loss:-2.588\n",
      "Epoch:  0030 D loss:-0.4901 G loss:-2.75\n",
      "Epoch:  0030 D loss:-0.3808 G loss:-2.491\n",
      "Epoch:  0030 D loss:-0.4638 G loss:-2.526\n",
      "Epoch:  0030 D loss:-0.5055 G loss:-2.597\n",
      "Epoch:  0030 D loss:-0.5907 G loss:-2.356\n",
      "Epoch:  0030 D loss:-0.4508 G loss:-2.733\n",
      "Epoch:  0030 D loss:-0.453 G loss:-2.606\n",
      "Epoch:  0030 D loss:-0.4666 G loss:-2.871\n",
      "Epoch:  0030 D loss:-0.5276 G loss:-2.462\n",
      "Epoch:  0030 D loss:-0.5618 G loss:-2.632\n",
      "Epoch:  0030 D loss:-0.3843 G loss:-2.636\n",
      "Epoch:  0030 D loss:-0.4915 G loss:-2.269\n",
      "Epoch:  0030 D loss:-0.3462 G loss:-2.512\n",
      "Epoch:  0030 D loss:-0.5371 G loss:-2.393\n",
      "Epoch:  0030 D loss:-0.4134 G loss:-2.488\n",
      "Epoch:  0030 D loss:-0.3717 G loss:-2.72\n",
      "Epoch:  0030 D loss:-0.4245 G loss:-2.802\n",
      "Epoch:  0030 D loss:-0.4371 G loss:-2.818\n",
      "Epoch:  0030 D loss:-0.4546 G loss:-2.751\n",
      "Epoch:  0030 D loss:-0.4282 G loss:-2.865\n",
      "Epoch:  0030 D loss:-0.3874 G loss:-2.744\n",
      "Epoch:  0030 D loss:-0.485 G loss:-2.748\n",
      "Epoch:  0030 D loss:-0.3415 G loss:-2.817\n",
      "Epoch:  0030 D loss:-0.4446 G loss:-2.57\n",
      "Epoch:  0030 D loss:-0.4639 G loss:-2.423\n",
      "Epoch:  0030 D loss:-0.4089 G loss:-2.764\n",
      "Epoch:  0030 D loss:-0.525 G loss:-2.481\n",
      "Epoch:  0030 D loss:-0.5097 G loss:-2.396\n",
      "Epoch:  0030 D loss:-0.4163 G loss:-2.595\n",
      "Epoch:  0030 D loss:-0.4367 G loss:-2.395\n",
      "Epoch:  0030 D loss:-0.5921 G loss:-2.249\n",
      "Epoch:  0030 D loss:-0.3314 G loss:-2.558\n",
      "Epoch:  0030 D loss:-0.4086 G loss:-2.717\n",
      "Epoch:  0030 D loss:-0.4177 G loss:-2.531\n",
      "Epoch:  0030 D loss:-0.3803 G loss:-2.506\n",
      "Epoch:  0030 D loss:-0.5499 G loss:-2.838\n",
      "Epoch:  0030 D loss:-0.4383 G loss:-2.783\n",
      "Epoch:  0030 D loss:-0.4556 G loss:-3.057\n",
      "Epoch:  0030 D loss:-0.471 G loss:-2.854\n",
      "Epoch:  0030 D loss:-0.4901 G loss:-2.606\n",
      "Epoch:  0030 D loss:-0.5295 G loss:-2.451\n",
      "Epoch:  0030 D loss:-0.4253 G loss:-2.472\n",
      "Epoch:  0030 D loss:-0.4654 G loss:-2.754\n",
      "Epoch:  0030 D loss:-0.4875 G loss:-2.765\n",
      "Epoch:  0030 D loss:-0.5295 G loss:-2.537\n",
      "Epoch:  0030 D loss:-0.5226 G loss:-2.387\n",
      "Epoch:  0030 D loss:-0.4904 G loss:-2.527\n",
      "Epoch:  0030 D loss:-0.443 G loss:-2.245\n",
      "Epoch:  0030 D loss:-0.566 G loss:-2.322\n",
      "Epoch:  0030 D loss:-0.5949 G loss:-2.313\n",
      "Epoch:  0030 D loss:-0.3802 G loss:-2.42\n",
      "Epoch:  0030 D loss:-0.458 G loss:-2.265\n",
      "Epoch:  0030 D loss:-0.5345 G loss:-2.477\n",
      "Epoch:  0030 D loss:-0.3559 G loss:-2.585\n",
      "Epoch:  0030 D loss:-0.4773 G loss:-2.482\n",
      "Epoch:  0030 D loss:-0.4079 G loss:-2.629\n",
      "Epoch:  0030 D loss:-0.3298 G loss:-2.546\n",
      "Epoch:  0030 D loss:-0.5837 G loss:-2.401\n",
      "Epoch:  0030 D loss:-0.5407 G loss:-2.438\n",
      "Epoch:  0030 D loss:-0.5502 G loss:-2.404\n",
      "Epoch:  0030 D loss:-0.5218 G loss:-2.332\n",
      "Epoch:  0030 D loss:-0.4191 G loss:-2.384\n",
      "Epoch:  0030 D loss:-0.3893 G loss:-2.658\n",
      "Epoch:  0030 D loss:-0.5672 G loss:-2.526\n",
      "Epoch:  0030 D loss:-0.3689 G loss:-2.504\n",
      "Epoch:  0030 D loss:-0.6298 G loss:-2.394\n",
      "Epoch:  0030 D loss:-0.5657 G loss:-2.539\n",
      "Epoch:  0030 D loss:-0.4027 G loss:-2.445\n",
      "Epoch:  0030 D loss:-0.4271 G loss:-2.511\n",
      "Epoch:  0030 D loss:-0.4715 G loss:-2.439\n",
      "Epoch:  0030 D loss:-0.5399 G loss:-2.35\n",
      "Epoch:  0030 D loss:-0.4255 G loss:-2.296\n",
      "Epoch:  0030 D loss:-0.4448 G loss:-2.465\n",
      "Epoch:  0030 D loss:-0.4348 G loss:-2.424\n",
      "Epoch:  0030 D loss:-0.4829 G loss:-2.457\n",
      "Epoch:  0030 D loss:-0.4862 G loss:-2.43\n",
      "Epoch:  0030 D loss:-0.4106 G loss:-2.549\n",
      "Epoch:  0030 D loss:-0.491 G loss:-2.555\n",
      "Epoch:  0030 D loss:-0.5331 G loss:-2.304\n",
      "Epoch:  0030 D loss:-0.4572 G loss:-2.626\n",
      "Epoch:  0030 D loss:-0.3849 G loss:-2.525\n",
      "Epoch:  0030 D loss:-0.3862 G loss:-2.727\n",
      "Epoch:  0030 D loss:-0.5428 G loss:-2.667\n",
      "Epoch:  0030 D loss:-0.4239 G loss:-2.729\n",
      "Epoch:  0030 D loss:-0.4719 G loss:-2.5\n",
      "Epoch:  0030 D loss:-0.4418 G loss:-2.633\n",
      "Epoch:  0030 D loss:-0.442 G loss:-2.663\n",
      "Epoch:  0030 D loss:-0.4942 G loss:-2.416\n",
      "Epoch:  0030 D loss:-0.4564 G loss:-2.33\n",
      "Epoch:  0030 D loss:-0.5167 G loss:-2.54\n",
      "Epoch:  0030 D loss:-0.3369 G loss:-2.481\n",
      "Epoch:  0030 D loss:-0.4492 G loss:-2.523\n",
      "Epoch:  0030 D loss:-0.4221 G loss:-2.463\n",
      "Epoch:  0030 D loss:-0.5047 G loss:-2.399\n",
      "Epoch:  0030 D loss:-0.3789 G loss:-2.44\n",
      "Epoch:  0030 D loss:-0.5093 G loss:-2.486\n",
      "Epoch:  0030 D loss:-0.4765 G loss:-2.34\n",
      "Epoch:  0030 D loss:-0.3991 G loss:-2.32\n",
      "Epoch:  0030 D loss:-0.5248 G loss:-2.399\n",
      "Epoch:  0030 D loss:-0.5506 G loss:-2.415\n",
      "Epoch:  0030 D loss:-0.5009 G loss:-2.806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0030 D loss:-0.4348 G loss:-2.564\n",
      "Epoch:  0030 D loss:-0.5635 G loss:-2.706\n",
      "Epoch:  0030 D loss:-0.6336 G loss:-2.42\n",
      "Epoch:  0030 D loss:-0.4163 G loss:-2.455\n",
      "Epoch:  0030 D loss:-0.4771 G loss:-2.402\n",
      "Epoch:  0030 D loss:-0.3788 G loss:-2.591\n",
      "Epoch:  0030 D loss:-0.5574 G loss:-2.36\n",
      "Epoch:  0030 D loss:-0.4439 G loss:-2.404\n",
      "Epoch:  0030 D loss:-0.4598 G loss:-2.544\n",
      "Epoch:  0030 D loss:-0.5617 G loss:-2.562\n",
      "Epoch:  0030 D loss:-0.4027 G loss:-2.65\n",
      "Epoch:  0030 D loss:-0.4675 G loss:-2.624\n",
      "Epoch:  0030 D loss:-0.5048 G loss:-2.666\n",
      "Epoch:  0030 D loss:-0.5849 G loss:-2.416\n",
      "Epoch:  0030 D loss:-0.5465 G loss:-2.197\n",
      "Epoch:  0030 D loss:-0.4285 G loss:-2.338\n",
      "Epoch:  0030 D loss:-0.4012 G loss:-2.527\n",
      "Epoch:  0030 D loss:-0.4593 G loss:-2.588\n",
      "Epoch:  0030 D loss:-0.4923 G loss:-2.449\n",
      "Epoch:  0030 D loss:-0.4476 G loss:-2.311\n",
      "Epoch:  0030 D loss:-0.548 G loss:-2.362\n",
      "Epoch:  0030 D loss:-0.4839 G loss:-2.458\n",
      "Epoch:  0030 D loss:-0.555 G loss:-2.217\n",
      "Epoch:  0030 D loss:-0.5084 G loss:-2.48\n",
      "Epoch:  0030 D loss:-0.5878 G loss:-2.534\n",
      "Epoch:  0030 D loss:-0.4574 G loss:-2.572\n",
      "Epoch:  0030 D loss:-0.432 G loss:-2.499\n",
      "Epoch:  0030 D loss:-0.5158 G loss:-2.603\n",
      "Epoch:  0030 D loss:-0.2734 G loss:-2.589\n",
      "Epoch:  0030 D loss:-0.4055 G loss:-2.64\n",
      "Epoch:  0030 D loss:-0.4818 G loss:-2.954\n",
      "Epoch:  0030 D loss:-0.3568 G loss:-2.616\n",
      "Epoch:  0030 D loss:-0.4003 G loss:-2.959\n",
      "Epoch:  0030 D loss:-0.4392 G loss:-2.692\n",
      "Epoch:  0030 D loss:-0.437 G loss:-2.585\n",
      "Epoch:  0030 D loss:-0.3903 G loss:-2.513\n",
      "Epoch:  0030 D loss:-0.4766 G loss:-2.469\n",
      "Epoch:  0030 D loss:-0.5164 G loss:-2.414\n",
      "Epoch:  0030 D loss:-0.4624 G loss:-2.362\n",
      "Epoch:  0030 D loss:-0.5237 G loss:-2.298\n",
      "Epoch:  0030 D loss:-0.3425 G loss:-2.446\n",
      "Epoch:  0030 D loss:-0.4702 G loss:-2.52\n",
      "Epoch:  0030 D loss:-0.4085 G loss:-2.464\n",
      "Epoch:  0030 D loss:-0.4111 G loss:-2.551\n",
      "Epoch:  0030 D loss:-0.5152 G loss:-2.534\n",
      "Epoch:  0030 D loss:-0.321 G loss:-2.624\n",
      "Epoch:  0030 D loss:-0.5032 G loss:-2.615\n",
      "Epoch:  0030 D loss:-0.3826 G loss:-2.708\n",
      "Epoch:  0030 D loss:-0.3464 G loss:-2.843\n",
      "Epoch:  0030 D loss:-0.4514 G loss:-2.69\n",
      "Epoch:  0030 D loss:-0.3705 G loss:-2.902\n",
      "Epoch:  0030 D loss:-0.4933 G loss:-2.735\n",
      "Epoch:  0030 D loss:-0.5576 G loss:-2.665\n",
      "Epoch:  0030 D loss:-0.6142 G loss:-2.682\n",
      "Epoch:  0030 D loss:-0.4555 G loss:-2.399\n",
      "Epoch:  0030 D loss:-0.4177 G loss:-2.634\n",
      "Epoch:  0030 D loss:-0.5044 G loss:-2.562\n",
      "Epoch:  0030 D loss:-0.3421 G loss:-2.635\n",
      "Epoch:  0030 D loss:-0.4269 G loss:-2.472\n",
      "Epoch:  0030 D loss:-0.4883 G loss:-2.668\n",
      "Epoch:  0030 D loss:-0.3935 G loss:-2.36\n",
      "Epoch:  0030 D loss:-0.3847 G loss:-2.537\n",
      "Epoch:  0030 D loss:-0.5159 G loss:-2.21\n",
      "Epoch:  0030 D loss:-0.4314 G loss:-2.397\n",
      "Epoch:  0030 D loss:-0.361 G loss:-2.741\n",
      "Epoch:  0030 D loss:-0.4425 G loss:-2.646\n",
      "Epoch:  0030 D loss:-0.4102 G loss:-2.727\n",
      "Epoch:  0030 D loss:-0.5898 G loss:-2.826\n",
      "Epoch:  0030 D loss:-0.4836 G loss:-2.605\n",
      "Epoch:  0030 D loss:-0.4799 G loss:-2.603\n",
      "Epoch:  0030 D loss:-0.4689 G loss:-2.698\n",
      "Epoch:  0030 D loss:-0.4856 G loss:-2.651\n",
      "Epoch:  0030 D loss:-0.4966 G loss:-2.575\n",
      "Epoch:  0030 D loss:-0.4494 G loss:-2.584\n",
      "Epoch:  0030 D loss:-0.4284 G loss:-2.756\n",
      "Epoch:  0030 D loss:-0.4249 G loss:-2.753\n",
      "Epoch:  0030 D loss:-0.496 G loss:-2.536\n",
      "Epoch:  0030 D loss:-0.3953 G loss:-2.743\n",
      "Epoch:  0030 D loss:-0.5217 G loss:-2.412\n",
      "Epoch:  0030 D loss:-0.5219 G loss:-2.657\n",
      "Epoch:  0030 D loss:-0.4648 G loss:-2.57\n",
      "Epoch:  0030 D loss:-0.4534 G loss:-2.387\n",
      "Epoch:  0030 D loss:-0.4348 G loss:-2.598\n",
      "Epoch:  0030 D loss:-0.3932 G loss:-2.717\n",
      "Epoch:  0030 D loss:-0.404 G loss:-2.809\n",
      "Epoch:  0030 D loss:-0.3816 G loss:-2.816\n",
      "Epoch:  0030 D loss:-0.4973 G loss:-2.62\n",
      "Epoch:  0030 D loss:-0.48 G loss:-2.728\n",
      "Epoch:  0030 D loss:-0.4913 G loss:-2.903\n",
      "Epoch:  0030 D loss:-0.456 G loss:-2.686\n",
      "Epoch:  0030 D loss:-0.3721 G loss:-2.609\n",
      "Epoch:  0030 D loss:-0.3921 G loss:-2.617\n",
      "Epoch:  0030 D loss:-0.2886 G loss:-2.825\n",
      "Epoch:  0030 D loss:-0.4567 G loss:-2.949\n",
      "Epoch:  0030 D loss:-0.2913 G loss:-2.83\n",
      "Epoch:  0030 D loss:-0.4532 G loss:-2.832\n",
      "Epoch:  0030 D loss:-0.434 G loss:-2.957\n",
      "Epoch:  0030 D loss:-0.5625 G loss:-2.873\n",
      "Epoch:  0030 D loss:-0.3317 G loss:-2.891\n",
      "Epoch:  0030 D loss:-0.352 G loss:-2.733\n",
      "Epoch:  0030 D loss:-0.524 G loss:-2.618\n",
      "Epoch:  0030 D loss:-0.5345 G loss:-2.585\n",
      "Epoch:  0030 D loss:-0.4939 G loss:-2.535\n",
      "Epoch:  0030 D loss:-0.4073 G loss:-2.477\n",
      "Epoch:  0030 D loss:-0.3797 G loss:-2.574\n",
      "Epoch:  0030 D loss:-0.4485 G loss:-2.609\n",
      "Epoch:  0030 D loss:-0.4672 G loss:-2.702\n",
      "Epoch:  0030 D loss:-0.478 G loss:-2.542\n",
      "Epoch:  0030 D loss:-0.4242 G loss:-2.781\n",
      "Epoch:  0030 D loss:-0.3986 G loss:-2.612\n",
      "Epoch:  0030 D loss:-0.4574 G loss:-2.847\n",
      "Epoch:  0030 D loss:-0.3989 G loss:-2.609\n",
      "Epoch:  0030 D loss:-0.483 G loss:-2.819\n",
      "Epoch:  0030 D loss:-0.531 G loss:-2.648\n",
      "Epoch:  0030 D loss:-0.3522 G loss:-2.819\n",
      "Epoch:  0030 D loss:-0.4348 G loss:-2.409\n",
      "Epoch:  0030 D loss:-0.4769 G loss:-2.654\n",
      "Epoch:  0030 D loss:-0.3998 G loss:-2.635\n",
      "Epoch:  0030 D loss:-0.4384 G loss:-2.361\n",
      "Epoch:  0030 D loss:-0.4276 G loss:-2.612\n",
      "Epoch:  0030 D loss:-0.5336 G loss:-2.453\n",
      "Epoch:  0030 D loss:-0.4831 G loss:-2.557\n",
      "Epoch:  0030 D loss:-0.411 G loss:-2.642\n",
      "Epoch:  0030 D loss:-0.4711 G loss:-2.526\n",
      "Epoch:  0030 D loss:-0.3692 G loss:-2.702\n",
      "Epoch:  0030 D loss:-0.4553 G loss:-2.852\n",
      "Epoch:  0030 D loss:-0.4495 G loss:-2.728\n",
      "Epoch:  0030 D loss:-0.4976 G loss:-2.429\n",
      "Epoch:  0030 D loss:-0.4429 G loss:-2.741\n",
      "Epoch:  0030 D loss:-0.3794 G loss:-2.512\n",
      "Epoch:  0030 D loss:-0.4023 G loss:-2.335\n",
      "Epoch:  0030 D loss:-0.5662 G loss:-2.586\n",
      "Epoch:  0030 D loss:-0.4739 G loss:-2.384\n",
      "Epoch:  0030 D loss:-0.5547 G loss:-2.498\n",
      "Epoch:  0030 D loss:-0.4738 G loss:-2.219\n",
      "Epoch:  0030 D loss:-0.518 G loss:-2.35\n",
      "Epoch:  0030 D loss:-0.491 G loss:-2.394\n",
      "Epoch:  0030 D loss:-0.4978 G loss:-2.592\n",
      "Epoch:  0030 D loss:-0.4724 G loss:-2.72\n",
      "Epoch:  0030 D loss:-0.4456 G loss:-2.547\n",
      "Epoch:  0030 D loss:-0.6074 G loss:-2.483\n",
      "Epoch:  0030 D loss:-0.4041 G loss:-2.529\n",
      "Epoch:  0030 D loss:-0.5202 G loss:-2.683\n",
      "Epoch:  0030 D loss:-0.4708 G loss:-2.253\n",
      "Epoch:  0030 D loss:-0.5937 G loss:-2.645\n",
      "Epoch:  0030 D loss:-0.5512 G loss:-2.225\n",
      "Epoch:  0030 D loss:-0.534 G loss:-2.334\n",
      "Epoch:  0030 D loss:-0.5423 G loss:-2.426\n",
      "Epoch:  0030 D loss:-0.5102 G loss:-2.307\n",
      "Epoch:  0030 D loss:-0.5087 G loss:-2.819\n",
      "Epoch:  0030 D loss:-0.5519 G loss:-2.553\n",
      "Epoch:  0030 D loss:-0.4626 G loss:-2.313\n",
      "Epoch:  0030 D loss:-0.5879 G loss:-2.288\n",
      "Epoch:  0030 D loss:-0.6449 G loss:-2.146\n",
      "Epoch:  0030 D loss:-0.4605 G loss:-2.422\n",
      "Epoch:  0030 D loss:-0.5305 G loss:-2.315\n",
      "Epoch:  0030 D loss:-0.6498 G loss:-2.314\n",
      "Epoch:  0030 D loss:-0.5486 G loss:-2.487\n",
      "Epoch:  0030 D loss:-0.5945 G loss:-2.452\n",
      "Epoch:  0030 D loss:-0.4577 G loss:-2.365\n",
      "Epoch:  0030 D loss:-0.5178 G loss:-2.397\n",
      "Epoch:  0030 D loss:-0.6526 G loss:-2.409\n",
      "Epoch:  0030 D loss:-0.4387 G loss:-2.259\n",
      "Epoch:  0030 D loss:-0.497 G loss:-2.495\n",
      "Epoch:  0030 D loss:-0.5244 G loss:-2.475\n",
      "Epoch:  0030 D loss:-0.4844 G loss:-2.399\n",
      "Epoch:  0030 D loss:-0.621 G loss:-2.388\n",
      "Epoch:  0030 D loss:-0.5109 G loss:-2.499\n",
      "Epoch:  0030 D loss:-0.4662 G loss:-2.553\n",
      "Epoch:  0030 D loss:-0.5534 G loss:-2.694\n",
      "Epoch:  0030 D loss:-0.5275 G loss:-2.447\n",
      "Epoch:  0030 D loss:-0.5361 G loss:-2.665\n",
      "Epoch:  0030 D loss:-0.5231 G loss:-2.643\n",
      "Epoch:  0030 D loss:-0.479 G loss:-2.805\n",
      "Epoch:  0030 D loss:-0.4679 G loss:-2.366\n",
      "Epoch:  0030 D loss:-0.4231 G loss:-2.472\n",
      "Epoch:  0031 D loss:-0.5787 G loss:-2.328\n",
      "Epoch:  0031 D loss:-0.4816 G loss:-2.352\n",
      "Epoch:  0031 D loss:-0.4633 G loss:-2.495\n",
      "Epoch:  0031 D loss:-0.5204 G loss:-2.453\n",
      "Epoch:  0031 D loss:-0.5915 G loss:-2.413\n",
      "Epoch:  0031 D loss:-0.4574 G loss:-2.42\n",
      "Epoch:  0031 D loss:-0.6289 G loss:-2.489\n",
      "Epoch:  0031 D loss:-0.5425 G loss:-2.506\n",
      "Epoch:  0031 D loss:-0.6027 G loss:-2.488\n",
      "Epoch:  0031 D loss:-0.4856 G loss:-2.371\n",
      "Epoch:  0031 D loss:-0.4636 G loss:-2.472\n",
      "Epoch:  0031 D loss:-0.4493 G loss:-2.523\n",
      "Epoch:  0031 D loss:-0.5859 G loss:-2.652\n",
      "Epoch:  0031 D loss:-0.4888 G loss:-2.683\n",
      "Epoch:  0031 D loss:-0.4938 G loss:-2.546\n",
      "Epoch:  0031 D loss:-0.4359 G loss:-2.85\n",
      "Epoch:  0031 D loss:-0.4309 G loss:-2.46\n",
      "Epoch:  0031 D loss:-0.4618 G loss:-2.774\n",
      "Epoch:  0031 D loss:-0.5291 G loss:-2.418\n",
      "Epoch:  0031 D loss:-0.5973 G loss:-2.447\n",
      "Epoch:  0031 D loss:-0.374 G loss:-2.379\n",
      "Epoch:  0031 D loss:-0.5123 G loss:-2.437\n",
      "Epoch:  0031 D loss:-0.4877 G loss:-2.382\n",
      "Epoch:  0031 D loss:-0.499 G loss:-2.228\n",
      "Epoch:  0031 D loss:-0.4588 G loss:-2.571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0031 D loss:-0.4188 G loss:-2.463\n",
      "Epoch:  0031 D loss:-0.592 G loss:-2.719\n",
      "Epoch:  0031 D loss:-0.3948 G loss:-2.971\n",
      "Epoch:  0031 D loss:-0.4528 G loss:-2.851\n",
      "Epoch:  0031 D loss:-0.5739 G loss:-2.778\n",
      "Epoch:  0031 D loss:-0.524 G loss:-2.813\n",
      "Epoch:  0031 D loss:-0.4722 G loss:-2.466\n",
      "Epoch:  0031 D loss:-0.456 G loss:-2.616\n",
      "Epoch:  0031 D loss:-0.4501 G loss:-2.469\n",
      "Epoch:  0031 D loss:-0.4394 G loss:-2.613\n",
      "Epoch:  0031 D loss:-0.4566 G loss:-2.324\n",
      "Epoch:  0031 D loss:-0.4148 G loss:-2.34\n",
      "Epoch:  0031 D loss:-0.4889 G loss:-2.541\n",
      "Epoch:  0031 D loss:-0.4681 G loss:-2.29\n",
      "Epoch:  0031 D loss:-0.6154 G loss:-2.4\n",
      "Epoch:  0031 D loss:-0.4296 G loss:-2.709\n",
      "Epoch:  0031 D loss:-0.4588 G loss:-2.531\n",
      "Epoch:  0031 D loss:-0.6378 G loss:-2.522\n",
      "Epoch:  0031 D loss:-0.3333 G loss:-2.67\n",
      "Epoch:  0031 D loss:-0.3869 G loss:-2.542\n",
      "Epoch:  0031 D loss:-0.359 G loss:-2.972\n",
      "Epoch:  0031 D loss:-0.4089 G loss:-2.745\n",
      "Epoch:  0031 D loss:-0.5236 G loss:-2.716\n",
      "Epoch:  0031 D loss:-0.3736 G loss:-2.871\n",
      "Epoch:  0031 D loss:-0.4315 G loss:-2.661\n",
      "Epoch:  0031 D loss:-0.6134 G loss:-2.674\n",
      "Epoch:  0031 D loss:-0.4346 G loss:-2.709\n",
      "Epoch:  0031 D loss:-0.5427 G loss:-2.598\n",
      "Epoch:  0031 D loss:-0.3252 G loss:-2.722\n",
      "Epoch:  0031 D loss:-0.4579 G loss:-2.735\n",
      "Epoch:  0031 D loss:-0.4527 G loss:-2.486\n",
      "Epoch:  0031 D loss:-0.3566 G loss:-2.307\n",
      "Epoch:  0031 D loss:-0.3652 G loss:-2.48\n",
      "Epoch:  0031 D loss:-0.4711 G loss:-2.502\n",
      "Epoch:  0031 D loss:-0.3642 G loss:-2.667\n",
      "Epoch:  0031 D loss:-0.4548 G loss:-2.744\n",
      "Epoch:  0031 D loss:-0.4152 G loss:-2.607\n",
      "Epoch:  0031 D loss:-0.3722 G loss:-2.89\n",
      "Epoch:  0031 D loss:-0.3556 G loss:-3.437\n",
      "Epoch:  0031 D loss:-0.3943 G loss:-2.783\n",
      "Epoch:  0031 D loss:-0.4291 G loss:-2.914\n",
      "Epoch:  0031 D loss:-0.4153 G loss:-2.814\n",
      "Epoch:  0031 D loss:-0.4211 G loss:-2.722\n",
      "Epoch:  0031 D loss:-0.4143 G loss:-2.623\n",
      "Epoch:  0031 D loss:-0.2742 G loss:-2.789\n",
      "Epoch:  0031 D loss:-0.3594 G loss:-2.676\n",
      "Epoch:  0031 D loss:-0.3159 G loss:-2.743\n",
      "Epoch:  0031 D loss:-0.3521 G loss:-2.849\n",
      "Epoch:  0031 D loss:-0.2973 G loss:-2.749\n",
      "Epoch:  0031 D loss:-0.3215 G loss:-2.693\n",
      "Epoch:  0031 D loss:-0.3375 G loss:-2.617\n",
      "Epoch:  0031 D loss:-0.3527 G loss:-2.517\n",
      "Epoch:  0031 D loss:-0.3571 G loss:-2.721\n",
      "Epoch:  0031 D loss:-0.2851 G loss:-2.809\n",
      "Epoch:  0031 D loss:-0.2631 G loss:-2.791\n",
      "Epoch:  0031 D loss:-0.2338 G loss:-2.894\n",
      "Epoch:  0031 D loss:-0.424 G loss:-2.902\n",
      "Epoch:  0031 D loss:-0.335 G loss:-2.959\n",
      "Epoch:  0031 D loss:-0.3452 G loss:-2.964\n",
      "Epoch:  0031 D loss:-0.4387 G loss:-2.898\n",
      "Epoch:  0031 D loss:-0.5644 G loss:-2.53\n",
      "Epoch:  0031 D loss:-0.4711 G loss:-2.739\n",
      "Epoch:  0031 D loss:-0.3556 G loss:-2.627\n",
      "Epoch:  0031 D loss:-0.3418 G loss:-2.517\n",
      "Epoch:  0031 D loss:-0.4121 G loss:-2.34\n",
      "Epoch:  0031 D loss:-0.4125 G loss:-2.559\n",
      "Epoch:  0031 D loss:-0.4276 G loss:-2.506\n",
      "Epoch:  0031 D loss:-0.3579 G loss:-2.643\n",
      "Epoch:  0031 D loss:-0.4248 G loss:-2.422\n",
      "Epoch:  0031 D loss:-0.3325 G loss:-2.399\n",
      "Epoch:  0031 D loss:-0.4012 G loss:-2.494\n",
      "Epoch:  0031 D loss:-0.4099 G loss:-2.541\n",
      "Epoch:  0031 D loss:-0.3944 G loss:-2.957\n",
      "Epoch:  0031 D loss:-0.4 G loss:-2.462\n",
      "Epoch:  0031 D loss:-0.3952 G loss:-2.799\n",
      "Epoch:  0031 D loss:-0.4284 G loss:-2.739\n",
      "Epoch:  0031 D loss:-0.5528 G loss:-2.841\n",
      "Epoch:  0031 D loss:-0.4067 G loss:-2.678\n",
      "Epoch:  0031 D loss:-0.4339 G loss:-2.783\n",
      "Epoch:  0031 D loss:-0.4293 G loss:-2.949\n",
      "Epoch:  0031 D loss:-0.3424 G loss:-2.701\n",
      "Epoch:  0031 D loss:-0.5255 G loss:-2.703\n",
      "Epoch:  0031 D loss:-0.4606 G loss:-2.629\n",
      "Epoch:  0031 D loss:-0.4501 G loss:-2.418\n",
      "Epoch:  0031 D loss:-0.4953 G loss:-2.717\n",
      "Epoch:  0031 D loss:-0.4407 G loss:-2.452\n",
      "Epoch:  0031 D loss:-0.4972 G loss:-2.443\n",
      "Epoch:  0031 D loss:-0.3899 G loss:-2.575\n",
      "Epoch:  0031 D loss:-0.4096 G loss:-2.491\n",
      "Epoch:  0031 D loss:-0.4613 G loss:-2.373\n",
      "Epoch:  0031 D loss:-0.3547 G loss:-2.53\n",
      "Epoch:  0031 D loss:-0.4916 G loss:-2.406\n",
      "Epoch:  0031 D loss:-0.3928 G loss:-2.399\n",
      "Epoch:  0031 D loss:-0.3991 G loss:-2.425\n",
      "Epoch:  0031 D loss:-0.358 G loss:-2.566\n",
      "Epoch:  0031 D loss:-0.3863 G loss:-2.526\n",
      "Epoch:  0031 D loss:-0.4034 G loss:-2.59\n",
      "Epoch:  0031 D loss:-0.5037 G loss:-2.718\n",
      "Epoch:  0031 D loss:-0.4622 G loss:-2.529\n",
      "Epoch:  0031 D loss:-0.4369 G loss:-2.589\n",
      "Epoch:  0031 D loss:-0.3989 G loss:-2.469\n",
      "Epoch:  0031 D loss:-0.3729 G loss:-2.934\n",
      "Epoch:  0031 D loss:-0.417 G loss:-2.721\n",
      "Epoch:  0031 D loss:-0.3535 G loss:-2.723\n",
      "Epoch:  0031 D loss:-0.4731 G loss:-2.632\n",
      "Epoch:  0031 D loss:-0.4874 G loss:-2.592\n",
      "Epoch:  0031 D loss:-0.6692 G loss:-2.315\n",
      "Epoch:  0031 D loss:-0.5544 G loss:-2.195\n",
      "Epoch:  0031 D loss:-0.4465 G loss:-2.528\n",
      "Epoch:  0031 D loss:-0.5159 G loss:-2.48\n",
      "Epoch:  0031 D loss:-0.4781 G loss:-2.473\n",
      "Epoch:  0031 D loss:-0.3884 G loss:-2.473\n",
      "Epoch:  0031 D loss:-0.5197 G loss:-2.19\n",
      "Epoch:  0031 D loss:-0.444 G loss:-2.522\n",
      "Epoch:  0031 D loss:-0.4777 G loss:-2.282\n",
      "Epoch:  0031 D loss:-0.4121 G loss:-2.41\n",
      "Epoch:  0031 D loss:-0.5086 G loss:-2.551\n",
      "Epoch:  0031 D loss:-0.5032 G loss:-2.765\n",
      "Epoch:  0031 D loss:-0.5773 G loss:-2.506\n",
      "Epoch:  0031 D loss:-0.5221 G loss:-2.37\n",
      "Epoch:  0031 D loss:-0.5023 G loss:-2.421\n",
      "Epoch:  0031 D loss:-0.4977 G loss:-2.372\n",
      "Epoch:  0031 D loss:-0.511 G loss:-2.49\n",
      "Epoch:  0031 D loss:-0.4563 G loss:-2.599\n",
      "Epoch:  0031 D loss:-0.5256 G loss:-2.357\n",
      "Epoch:  0031 D loss:-0.6123 G loss:-2.252\n",
      "Epoch:  0031 D loss:-0.5161 G loss:-2.22\n",
      "Epoch:  0031 D loss:-0.6021 G loss:-2.341\n",
      "Epoch:  0031 D loss:-0.4019 G loss:-2.511\n",
      "Epoch:  0031 D loss:-0.5245 G loss:-2.584\n",
      "Epoch:  0031 D loss:-0.4791 G loss:-2.379\n",
      "Epoch:  0031 D loss:-0.6037 G loss:-2.21\n",
      "Epoch:  0031 D loss:-0.5133 G loss:-2.338\n",
      "Epoch:  0031 D loss:-0.5213 G loss:-2.429\n",
      "Epoch:  0031 D loss:-0.4903 G loss:-2.433\n",
      "Epoch:  0031 D loss:-0.6428 G loss:-2.379\n",
      "Epoch:  0031 D loss:-0.4967 G loss:-2.43\n",
      "Epoch:  0031 D loss:-0.4845 G loss:-2.545\n",
      "Epoch:  0031 D loss:-0.5935 G loss:-2.439\n",
      "Epoch:  0031 D loss:-0.3957 G loss:-2.604\n",
      "Epoch:  0031 D loss:-0.6045 G loss:-2.335\n",
      "Epoch:  0031 D loss:-0.4106 G loss:-2.482\n",
      "Epoch:  0031 D loss:-0.5172 G loss:-2.296\n",
      "Epoch:  0031 D loss:-0.5257 G loss:-2.466\n",
      "Epoch:  0031 D loss:-0.5714 G loss:-2.375\n",
      "Epoch:  0031 D loss:-0.6408 G loss:-2.258\n",
      "Epoch:  0031 D loss:-0.4825 G loss:-2.329\n",
      "Epoch:  0031 D loss:-0.5418 G loss:-2.466\n",
      "Epoch:  0031 D loss:-0.6852 G loss:-2.028\n",
      "Epoch:  0031 D loss:-0.5333 G loss:-2.299\n",
      "Epoch:  0031 D loss:-0.5289 G loss:-2.594\n",
      "Epoch:  0031 D loss:-0.5576 G loss:-2.455\n",
      "Epoch:  0031 D loss:-0.5311 G loss:-2.407\n",
      "Epoch:  0031 D loss:-0.3638 G loss:-2.398\n",
      "Epoch:  0031 D loss:-0.4185 G loss:-2.534\n",
      "Epoch:  0031 D loss:-0.6224 G loss:-2.505\n",
      "Epoch:  0031 D loss:-0.5261 G loss:-2.501\n",
      "Epoch:  0031 D loss:-0.6509 G loss:-2.401\n",
      "Epoch:  0031 D loss:-0.3679 G loss:-2.66\n",
      "Epoch:  0031 D loss:-0.473 G loss:-2.515\n",
      "Epoch:  0031 D loss:-0.4607 G loss:-2.426\n",
      "Epoch:  0031 D loss:-0.4373 G loss:-2.483\n",
      "Epoch:  0031 D loss:-0.5018 G loss:-2.492\n",
      "Epoch:  0031 D loss:-0.3742 G loss:-2.659\n",
      "Epoch:  0031 D loss:-0.4724 G loss:-2.313\n",
      "Epoch:  0031 D loss:-0.4896 G loss:-2.318\n",
      "Epoch:  0031 D loss:-0.5884 G loss:-2.431\n",
      "Epoch:  0031 D loss:-0.47 G loss:-2.34\n",
      "Epoch:  0031 D loss:-0.52 G loss:-2.316\n",
      "Epoch:  0031 D loss:-0.5342 G loss:-2.378\n",
      "Epoch:  0031 D loss:-0.5296 G loss:-2.724\n",
      "Epoch:  0031 D loss:-0.5649 G loss:-2.345\n",
      "Epoch:  0031 D loss:-0.5518 G loss:-2.275\n",
      "Epoch:  0031 D loss:-0.5301 G loss:-2.488\n",
      "Epoch:  0031 D loss:-0.4761 G loss:-2.56\n",
      "Epoch:  0031 D loss:-0.4082 G loss:-2.669\n",
      "Epoch:  0031 D loss:-0.4534 G loss:-2.624\n",
      "Epoch:  0031 D loss:-0.3741 G loss:-2.505\n",
      "Epoch:  0031 D loss:-0.437 G loss:-2.731\n",
      "Epoch:  0031 D loss:-0.5124 G loss:-2.474\n",
      "Epoch:  0031 D loss:-0.5679 G loss:-2.618\n",
      "Epoch:  0031 D loss:-0.4044 G loss:-2.547\n",
      "Epoch:  0031 D loss:-0.4371 G loss:-2.582\n",
      "Epoch:  0031 D loss:-0.4928 G loss:-2.291\n",
      "Epoch:  0031 D loss:-0.4591 G loss:-2.288\n",
      "Epoch:  0031 D loss:-0.444 G loss:-2.354\n",
      "Epoch:  0031 D loss:-0.4612 G loss:-2.373\n",
      "Epoch:  0031 D loss:-0.5249 G loss:-2.421\n",
      "Epoch:  0031 D loss:-0.4731 G loss:-2.591\n",
      "Epoch:  0031 D loss:-0.6087 G loss:-2.627\n",
      "Epoch:  0031 D loss:-0.5966 G loss:-2.606\n",
      "Epoch:  0031 D loss:-0.5234 G loss:-2.517\n",
      "Epoch:  0031 D loss:-0.5762 G loss:-2.255\n",
      "Epoch:  0031 D loss:-0.4218 G loss:-2.502\n",
      "Epoch:  0031 D loss:-0.571 G loss:-2.417\n",
      "Epoch:  0031 D loss:-0.4937 G loss:-2.241\n",
      "Epoch:  0031 D loss:-0.4638 G loss:-2.133\n",
      "Epoch:  0031 D loss:-0.4318 G loss:-2.274\n",
      "Epoch:  0031 D loss:-0.4799 G loss:-2.156\n",
      "Epoch:  0031 D loss:-0.5668 G loss:-2.037\n",
      "Epoch:  0031 D loss:-0.2943 G loss:-2.792\n",
      "Epoch:  0031 D loss:-0.5161 G loss:-2.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0031 D loss:-0.4967 G loss:-2.567\n",
      "Epoch:  0031 D loss:-0.5458 G loss:-2.653\n",
      "Epoch:  0031 D loss:-0.3435 G loss:-2.677\n",
      "Epoch:  0031 D loss:-0.5023 G loss:-2.727\n",
      "Epoch:  0031 D loss:-0.4484 G loss:-2.633\n",
      "Epoch:  0031 D loss:-0.4731 G loss:-2.518\n",
      "Epoch:  0031 D loss:-0.4377 G loss:-2.458\n",
      "Epoch:  0031 D loss:-0.4761 G loss:-2.457\n",
      "Epoch:  0031 D loss:-0.4353 G loss:-2.384\n",
      "Epoch:  0031 D loss:-0.3618 G loss:-2.54\n",
      "Epoch:  0031 D loss:-0.4521 G loss:-2.293\n",
      "Epoch:  0031 D loss:-0.3901 G loss:-2.422\n",
      "Epoch:  0031 D loss:-0.5377 G loss:-2.315\n",
      "Epoch:  0031 D loss:-0.4419 G loss:-2.49\n",
      "Epoch:  0031 D loss:-0.4141 G loss:-2.426\n",
      "Epoch:  0031 D loss:-0.3753 G loss:-2.492\n",
      "Epoch:  0031 D loss:-0.3918 G loss:-2.405\n",
      "Epoch:  0031 D loss:-0.4166 G loss:-2.691\n",
      "Epoch:  0031 D loss:-0.4749 G loss:-2.753\n",
      "Epoch:  0031 D loss:-0.448 G loss:-2.586\n",
      "Epoch:  0031 D loss:-0.4314 G loss:-2.575\n",
      "Epoch:  0031 D loss:-0.3838 G loss:-2.785\n",
      "Epoch:  0031 D loss:-0.5154 G loss:-2.7\n",
      "Epoch:  0031 D loss:-0.4095 G loss:-2.649\n",
      "Epoch:  0031 D loss:-0.4999 G loss:-2.578\n",
      "Epoch:  0031 D loss:-0.4215 G loss:-2.557\n",
      "Epoch:  0031 D loss:-0.503 G loss:-2.358\n",
      "Epoch:  0031 D loss:-0.4186 G loss:-2.605\n",
      "Epoch:  0031 D loss:-0.4288 G loss:-2.524\n",
      "Epoch:  0031 D loss:-0.3598 G loss:-2.45\n",
      "Epoch:  0031 D loss:-0.441 G loss:-2.442\n",
      "Epoch:  0031 D loss:-0.505 G loss:-2.455\n",
      "Epoch:  0031 D loss:-0.4099 G loss:-2.543\n",
      "Epoch:  0031 D loss:-0.4117 G loss:-2.539\n",
      "Epoch:  0031 D loss:-0.5437 G loss:-2.603\n",
      "Epoch:  0031 D loss:-0.3866 G loss:-2.892\n",
      "Epoch:  0031 D loss:-0.5448 G loss:-2.676\n",
      "Epoch:  0031 D loss:-0.5275 G loss:-2.586\n",
      "Epoch:  0031 D loss:-0.542 G loss:-2.596\n",
      "Epoch:  0031 D loss:-0.4944 G loss:-2.527\n",
      "Epoch:  0031 D loss:-0.2589 G loss:-2.748\n",
      "Epoch:  0031 D loss:-0.4212 G loss:-2.514\n",
      "Epoch:  0031 D loss:-0.4325 G loss:-2.416\n",
      "Epoch:  0031 D loss:-0.306 G loss:-2.637\n",
      "Epoch:  0031 D loss:-0.4288 G loss:-2.623\n",
      "Epoch:  0031 D loss:-0.3511 G loss:-2.599\n",
      "Epoch:  0031 D loss:-0.3925 G loss:-2.54\n",
      "Epoch:  0031 D loss:-0.3734 G loss:-2.717\n",
      "Epoch:  0031 D loss:-0.4216 G loss:-2.82\n",
      "Epoch:  0031 D loss:-0.3883 G loss:-2.85\n",
      "Epoch:  0031 D loss:-0.3903 G loss:-3.023\n",
      "Epoch:  0031 D loss:-0.4478 G loss:-2.864\n",
      "Epoch:  0031 D loss:-0.3818 G loss:-2.865\n",
      "Epoch:  0031 D loss:-0.4777 G loss:-2.854\n",
      "Epoch:  0031 D loss:-0.3243 G loss:-2.805\n",
      "Epoch:  0031 D loss:-0.3695 G loss:-2.762\n",
      "Epoch:  0031 D loss:-0.4351 G loss:-2.526\n",
      "Epoch:  0031 D loss:-0.3936 G loss:-2.709\n",
      "Epoch:  0031 D loss:-0.3926 G loss:-2.476\n",
      "Epoch:  0031 D loss:-0.3714 G loss:-2.526\n",
      "Epoch:  0031 D loss:-0.3738 G loss:-2.447\n",
      "Epoch:  0031 D loss:-0.3933 G loss:-2.543\n",
      "Epoch:  0031 D loss:-0.4158 G loss:-2.584\n",
      "Epoch:  0031 D loss:-0.3424 G loss:-2.794\n",
      "Epoch:  0031 D loss:-0.3842 G loss:-2.571\n",
      "Epoch:  0031 D loss:-0.3201 G loss:-2.952\n",
      "Epoch:  0031 D loss:-0.3856 G loss:-2.934\n",
      "Epoch:  0031 D loss:-0.2528 G loss:-3.135\n",
      "Epoch:  0031 D loss:-0.4274 G loss:-2.623\n",
      "Epoch:  0031 D loss:-0.3569 G loss:-3.114\n",
      "Epoch:  0031 D loss:-0.3426 G loss:-2.723\n",
      "Epoch:  0031 D loss:-0.2924 G loss:-3.054\n",
      "Epoch:  0031 D loss:-0.2821 G loss:-2.872\n",
      "Epoch:  0031 D loss:-0.4517 G loss:-2.675\n",
      "Epoch:  0031 D loss:-0.4819 G loss:-2.791\n",
      "Epoch:  0031 D loss:-0.4943 G loss:-2.739\n",
      "Epoch:  0031 D loss:-0.3176 G loss:-2.776\n",
      "Epoch:  0031 D loss:-0.4057 G loss:-2.648\n",
      "Epoch:  0031 D loss:-0.5656 G loss:-2.361\n",
      "Epoch:  0031 D loss:-0.4129 G loss:-2.501\n",
      "Epoch:  0031 D loss:-0.4015 G loss:-2.399\n",
      "Epoch:  0031 D loss:-0.3688 G loss:-2.498\n",
      "Epoch:  0031 D loss:-0.3898 G loss:-2.628\n",
      "Epoch:  0031 D loss:-0.2817 G loss:-2.57\n",
      "Epoch:  0031 D loss:-0.3422 G loss:-2.762\n",
      "Epoch:  0031 D loss:-0.4234 G loss:-2.897\n",
      "Epoch:  0031 D loss:-0.3973 G loss:-2.876\n",
      "Epoch:  0031 D loss:-0.4287 G loss:-2.933\n",
      "Epoch:  0031 D loss:-0.4319 G loss:-2.921\n",
      "Epoch:  0031 D loss:-0.2797 G loss:-2.912\n",
      "Epoch:  0031 D loss:-0.3264 G loss:-3.162\n",
      "Epoch:  0031 D loss:-0.2889 G loss:-2.975\n",
      "Epoch:  0031 D loss:-0.4364 G loss:-2.644\n",
      "Epoch:  0031 D loss:-0.3736 G loss:-2.839\n",
      "Epoch:  0031 D loss:-0.3292 G loss:-2.898\n",
      "Epoch:  0031 D loss:-0.4472 G loss:-2.46\n",
      "Epoch:  0031 D loss:-0.3258 G loss:-2.686\n",
      "Epoch:  0031 D loss:-0.4242 G loss:-2.299\n",
      "Epoch:  0031 D loss:-0.4328 G loss:-2.5\n",
      "Epoch:  0031 D loss:-0.4806 G loss:-2.495\n",
      "Epoch:  0031 D loss:-0.4113 G loss:-2.528\n",
      "Epoch:  0031 D loss:-0.3697 G loss:-2.564\n",
      "Epoch:  0031 D loss:-0.5964 G loss:-2.688\n",
      "Epoch:  0031 D loss:-0.4466 G loss:-2.542\n",
      "Epoch:  0031 D loss:-0.3777 G loss:-2.913\n",
      "Epoch:  0031 D loss:-0.4728 G loss:-2.826\n",
      "Epoch:  0031 D loss:-0.4173 G loss:-2.473\n",
      "Epoch:  0031 D loss:-0.4789 G loss:-2.528\n",
      "Epoch:  0031 D loss:-0.3789 G loss:-2.557\n",
      "Epoch:  0031 D loss:-0.4577 G loss:-2.509\n",
      "Epoch:  0031 D loss:-0.4928 G loss:-2.615\n",
      "Epoch:  0031 D loss:-0.5427 G loss:-2.428\n",
      "Epoch:  0031 D loss:-0.3966 G loss:-2.507\n",
      "Epoch:  0031 D loss:-0.4479 G loss:-2.379\n",
      "Epoch:  0031 D loss:-0.4956 G loss:-2.465\n",
      "Epoch:  0031 D loss:-0.4688 G loss:-2.614\n",
      "Epoch:  0031 D loss:-0.3503 G loss:-2.633\n",
      "Epoch:  0031 D loss:-0.4613 G loss:-2.502\n",
      "Epoch:  0031 D loss:-0.5195 G loss:-2.673\n",
      "Epoch:  0031 D loss:-0.4949 G loss:-2.325\n",
      "Epoch:  0031 D loss:-0.5553 G loss:-2.59\n",
      "Epoch:  0031 D loss:-0.5314 G loss:-2.42\n",
      "Epoch:  0031 D loss:-0.4733 G loss:-2.436\n",
      "Epoch:  0031 D loss:-0.5199 G loss:-2.538\n",
      "Epoch:  0031 D loss:-0.4317 G loss:-2.372\n",
      "Epoch:  0031 D loss:-0.5035 G loss:-2.388\n",
      "Epoch:  0031 D loss:-0.5509 G loss:-2.394\n",
      "Epoch:  0031 D loss:-0.4566 G loss:-2.722\n",
      "Epoch:  0031 D loss:-0.4401 G loss:-2.41\n",
      "Epoch:  0031 D loss:-0.473 G loss:-2.533\n",
      "Epoch:  0031 D loss:-0.3654 G loss:-2.744\n",
      "Epoch:  0031 D loss:-0.5378 G loss:-2.769\n",
      "Epoch:  0031 D loss:-0.5089 G loss:-2.495\n",
      "Epoch:  0031 D loss:-0.544 G loss:-2.93\n",
      "Epoch:  0031 D loss:-0.3747 G loss:-2.644\n",
      "Epoch:  0031 D loss:-0.4651 G loss:-2.585\n",
      "Epoch:  0031 D loss:-0.3639 G loss:-2.768\n",
      "Epoch:  0031 D loss:-0.5043 G loss:-2.555\n",
      "Epoch:  0031 D loss:-0.3211 G loss:-2.906\n",
      "Epoch:  0031 D loss:-0.6361 G loss:-2.427\n",
      "Epoch:  0031 D loss:-0.5352 G loss:-2.508\n",
      "Epoch:  0031 D loss:-0.6231 G loss:-2.321\n",
      "Epoch:  0031 D loss:-0.5522 G loss:-2.302\n",
      "Epoch:  0031 D loss:-0.4337 G loss:-2.529\n",
      "Epoch:  0031 D loss:-0.5537 G loss:-2.366\n",
      "Epoch:  0031 D loss:-0.4498 G loss:-2.524\n",
      "Epoch:  0031 D loss:-0.5316 G loss:-2.389\n",
      "Epoch:  0031 D loss:-0.4447 G loss:-2.49\n",
      "Epoch:  0031 D loss:-0.5083 G loss:-2.615\n",
      "Epoch:  0031 D loss:-0.5243 G loss:-2.74\n",
      "Epoch:  0031 D loss:-0.4587 G loss:-2.606\n",
      "Epoch:  0031 D loss:-0.522 G loss:-2.693\n",
      "Epoch:  0031 D loss:-0.4696 G loss:-2.556\n",
      "Epoch:  0031 D loss:-0.3939 G loss:-2.582\n",
      "Epoch:  0031 D loss:-0.4926 G loss:-2.654\n",
      "Epoch:  0031 D loss:-0.424 G loss:-2.652\n",
      "Epoch:  0031 D loss:-0.4531 G loss:-2.54\n",
      "Epoch:  0031 D loss:-0.5325 G loss:-2.277\n",
      "Epoch:  0031 D loss:-0.4006 G loss:-2.547\n",
      "Epoch:  0031 D loss:-0.5306 G loss:-2.233\n",
      "Epoch:  0031 D loss:-0.4272 G loss:-2.397\n",
      "Epoch:  0031 D loss:-0.4855 G loss:-2.391\n",
      "Epoch:  0031 D loss:-0.5079 G loss:-2.228\n",
      "Epoch:  0031 D loss:-0.3856 G loss:-2.588\n",
      "Epoch:  0031 D loss:-0.4518 G loss:-2.539\n",
      "Epoch:  0031 D loss:-0.5865 G loss:-2.711\n",
      "Epoch:  0031 D loss:-0.6455 G loss:-2.268\n",
      "Epoch:  0031 D loss:-0.3768 G loss:-2.948\n",
      "Epoch:  0031 D loss:-0.3447 G loss:-2.736\n",
      "Epoch:  0031 D loss:-0.4605 G loss:-2.821\n",
      "Epoch:  0031 D loss:-0.4255 G loss:-2.852\n",
      "Epoch:  0031 D loss:-0.5952 G loss:-2.832\n",
      "Epoch:  0031 D loss:-0.6004 G loss:-2.634\n",
      "Epoch:  0031 D loss:-0.4393 G loss:-2.549\n",
      "Epoch:  0031 D loss:-0.4205 G loss:-2.695\n",
      "Epoch:  0031 D loss:-0.4647 G loss:-2.392\n",
      "Epoch:  0031 D loss:-0.6512 G loss:-2.339\n",
      "Epoch:  0031 D loss:-0.5172 G loss:-2.358\n",
      "Epoch:  0031 D loss:-0.4809 G loss:-2.643\n",
      "Epoch:  0031 D loss:-0.3872 G loss:-2.589\n",
      "Epoch:  0031 D loss:-0.5841 G loss:-2.602\n",
      "Epoch:  0031 D loss:-0.4184 G loss:-2.34\n",
      "Epoch:  0031 D loss:-0.4104 G loss:-2.527\n",
      "Epoch:  0031 D loss:-0.4734 G loss:-2.705\n",
      "Epoch:  0031 D loss:-0.6264 G loss:-2.406\n",
      "Epoch:  0031 D loss:-0.5225 G loss:-2.472\n",
      "Epoch:  0031 D loss:-0.3947 G loss:-2.882\n",
      "Epoch:  0031 D loss:-0.5292 G loss:-2.53\n",
      "Epoch:  0031 D loss:-0.4139 G loss:-2.876\n",
      "Epoch:  0031 D loss:-0.4515 G loss:-2.538\n",
      "Epoch:  0031 D loss:-0.6009 G loss:-2.606\n",
      "Epoch:  0031 D loss:-0.5989 G loss:-2.637\n",
      "Epoch:  0031 D loss:-0.4645 G loss:-2.447\n",
      "Epoch:  0031 D loss:-0.43 G loss:-2.803\n",
      "Epoch:  0031 D loss:-0.452 G loss:-2.589\n",
      "Epoch:  0031 D loss:-0.4768 G loss:-2.58\n",
      "Epoch:  0031 D loss:-0.5527 G loss:-2.899\n",
      "Epoch:  0031 D loss:-0.5517 G loss:-2.635\n",
      "Epoch:  0031 D loss:-0.3722 G loss:-2.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0031 D loss:-0.4304 G loss:-2.491\n",
      "Epoch:  0031 D loss:-0.4511 G loss:-2.62\n",
      "Epoch:  0031 D loss:-0.3891 G loss:-2.884\n",
      "Epoch:  0031 D loss:-0.5502 G loss:-2.604\n",
      "Epoch:  0031 D loss:-0.5513 G loss:-2.385\n",
      "Epoch:  0031 D loss:-0.5235 G loss:-2.648\n",
      "Epoch:  0031 D loss:-0.4641 G loss:-2.553\n",
      "Epoch:  0031 D loss:-0.4632 G loss:-2.592\n",
      "Epoch:  0031 D loss:-0.4479 G loss:-2.538\n",
      "Epoch:  0031 D loss:-0.3911 G loss:-2.504\n",
      "Epoch:  0031 D loss:-0.4481 G loss:-2.454\n",
      "Epoch:  0031 D loss:-0.4327 G loss:-2.422\n",
      "Epoch:  0031 D loss:-0.4774 G loss:-2.717\n",
      "Epoch:  0031 D loss:-0.5488 G loss:-2.675\n",
      "Epoch:  0031 D loss:-0.3879 G loss:-2.767\n",
      "Epoch:  0031 D loss:-0.3595 G loss:-2.677\n",
      "Epoch:  0031 D loss:-0.4912 G loss:-2.485\n",
      "Epoch:  0031 D loss:-0.3192 G loss:-2.697\n",
      "Epoch:  0031 D loss:-0.4614 G loss:-2.513\n",
      "Epoch:  0031 D loss:-0.448 G loss:-2.8\n",
      "Epoch:  0031 D loss:-0.3632 G loss:-2.824\n",
      "Epoch:  0031 D loss:-0.4605 G loss:-2.576\n",
      "Epoch:  0031 D loss:-0.3687 G loss:-2.527\n",
      "Epoch:  0031 D loss:-0.3872 G loss:-2.809\n",
      "Epoch:  0031 D loss:-0.3401 G loss:-2.787\n",
      "Epoch:  0031 D loss:-0.3232 G loss:-2.871\n",
      "Epoch:  0031 D loss:-0.4523 G loss:-2.687\n",
      "Epoch:  0031 D loss:-0.4688 G loss:-2.893\n",
      "Epoch:  0031 D loss:-0.3136 G loss:-2.657\n",
      "Epoch:  0031 D loss:-0.4843 G loss:-2.773\n",
      "Epoch:  0031 D loss:-0.4984 G loss:-2.558\n",
      "Epoch:  0031 D loss:-0.448 G loss:-2.69\n",
      "Epoch:  0031 D loss:-0.5262 G loss:-2.614\n",
      "Epoch:  0031 D loss:-0.4102 G loss:-2.51\n",
      "Epoch:  0031 D loss:-0.4854 G loss:-2.472\n",
      "Epoch:  0031 D loss:-0.4132 G loss:-2.616\n",
      "Epoch:  0031 D loss:-0.3551 G loss:-2.476\n",
      "Epoch:  0031 D loss:-0.3469 G loss:-2.676\n",
      "Epoch:  0031 D loss:-0.4567 G loss:-2.493\n",
      "Epoch:  0031 D loss:-0.4295 G loss:-2.509\n",
      "Epoch:  0031 D loss:-0.4775 G loss:-2.284\n",
      "Epoch:  0031 D loss:-0.3722 G loss:-2.482\n",
      "Epoch:  0031 D loss:-0.2402 G loss:-2.779\n",
      "Epoch:  0031 D loss:-0.4623 G loss:-2.835\n",
      "Epoch:  0031 D loss:-0.4299 G loss:-2.63\n",
      "Epoch:  0031 D loss:-0.5413 G loss:-2.748\n",
      "Epoch:  0031 D loss:-0.4207 G loss:-2.662\n",
      "Epoch:  0031 D loss:-0.5107 G loss:-2.767\n",
      "Epoch:  0031 D loss:-0.4431 G loss:-2.539\n",
      "Epoch:  0031 D loss:-0.4157 G loss:-2.603\n",
      "Epoch:  0031 D loss:-0.5287 G loss:-2.646\n",
      "Epoch:  0031 D loss:-0.3866 G loss:-2.654\n",
      "Epoch:  0031 D loss:-0.4427 G loss:-2.439\n",
      "Epoch:  0031 D loss:-0.377 G loss:-2.593\n",
      "Epoch:  0031 D loss:-0.3892 G loss:-2.743\n",
      "Epoch:  0031 D loss:-0.369 G loss:-2.706\n",
      "Epoch:  0031 D loss:-0.5072 G loss:-2.456\n",
      "Epoch:  0031 D loss:-0.3487 G loss:-2.51\n",
      "Epoch:  0031 D loss:-0.4333 G loss:-2.576\n",
      "Epoch:  0031 D loss:-0.3691 G loss:-2.597\n",
      "Epoch:  0031 D loss:-0.3996 G loss:-2.631\n",
      "Epoch:  0031 D loss:-0.4984 G loss:-2.777\n",
      "Epoch:  0031 D loss:-0.3769 G loss:-2.966\n",
      "Epoch:  0031 D loss:-0.4484 G loss:-2.497\n",
      "Epoch:  0031 D loss:-0.3773 G loss:-2.71\n",
      "Epoch:  0031 D loss:-0.4901 G loss:-2.618\n",
      "Epoch:  0031 D loss:-0.4642 G loss:-2.582\n",
      "Epoch:  0031 D loss:-0.5548 G loss:-2.53\n",
      "Epoch:  0031 D loss:-0.3408 G loss:-2.676\n",
      "Epoch:  0031 D loss:-0.5272 G loss:-2.447\n",
      "Epoch:  0031 D loss:-0.4753 G loss:-2.76\n",
      "Epoch:  0031 D loss:-0.4583 G loss:-2.649\n",
      "Epoch:  0031 D loss:-0.3546 G loss:-2.458\n",
      "Epoch:  0031 D loss:-0.481 G loss:-2.423\n",
      "Epoch:  0031 D loss:-0.4998 G loss:-2.389\n",
      "Epoch:  0031 D loss:-0.4219 G loss:-2.481\n",
      "Epoch:  0031 D loss:-0.4851 G loss:-2.383\n",
      "Epoch:  0031 D loss:-0.3833 G loss:-2.834\n",
      "Epoch:  0031 D loss:-0.368 G loss:-2.763\n",
      "Epoch:  0031 D loss:-0.4722 G loss:-2.839\n",
      "Epoch:  0031 D loss:-0.3057 G loss:-2.806\n",
      "Epoch:  0031 D loss:-0.3831 G loss:-2.801\n",
      "Epoch:  0031 D loss:-0.3631 G loss:-2.855\n",
      "Epoch:  0031 D loss:-0.3891 G loss:-2.72\n",
      "Epoch:  0031 D loss:-0.442 G loss:-2.538\n",
      "Epoch:  0031 D loss:-0.3914 G loss:-2.78\n",
      "Epoch:  0031 D loss:-0.3422 G loss:-2.853\n",
      "Epoch:  0031 D loss:-0.3195 G loss:-2.759\n",
      "Epoch:  0031 D loss:-0.3191 G loss:-2.775\n",
      "Epoch:  0031 D loss:-0.4878 G loss:-2.751\n",
      "Epoch:  0031 D loss:-0.4726 G loss:-2.563\n",
      "Epoch:  0031 D loss:-0.2727 G loss:-2.763\n",
      "Epoch:  0031 D loss:-0.3339 G loss:-2.695\n",
      "Epoch:  0031 D loss:-0.5016 G loss:-2.325\n",
      "Epoch:  0031 D loss:-0.4253 G loss:-2.508\n",
      "Epoch:  0031 D loss:-0.3888 G loss:-2.496\n",
      "Epoch:  0031 D loss:-0.5161 G loss:-2.46\n",
      "Epoch:  0031 D loss:-0.3177 G loss:-2.756\n",
      "Epoch:  0031 D loss:-0.3238 G loss:-2.75\n",
      "Epoch:  0031 D loss:-0.3741 G loss:-2.629\n",
      "Epoch:  0031 D loss:-0.5758 G loss:-2.426\n",
      "Epoch:  0031 D loss:-0.4003 G loss:-2.732\n",
      "Epoch:  0031 D loss:-0.5095 G loss:-2.781\n",
      "Epoch:  0031 D loss:-0.3852 G loss:-2.564\n",
      "Epoch:  0031 D loss:-0.464 G loss:-2.626\n",
      "Epoch:  0031 D loss:-0.4197 G loss:-2.636\n",
      "Epoch:  0031 D loss:-0.5285 G loss:-2.563\n",
      "Epoch:  0031 D loss:-0.381 G loss:-2.797\n",
      "Epoch:  0031 D loss:-0.4726 G loss:-2.393\n",
      "Epoch:  0031 D loss:-0.385 G loss:-2.584\n",
      "Epoch:  0031 D loss:-0.3898 G loss:-2.584\n",
      "Epoch:  0031 D loss:-0.4213 G loss:-2.612\n",
      "Epoch:  0031 D loss:-0.4433 G loss:-2.643\n",
      "Epoch:  0031 D loss:-0.3719 G loss:-2.694\n",
      "Epoch:  0031 D loss:-0.394 G loss:-2.696\n",
      "Epoch:  0031 D loss:-0.4013 G loss:-2.678\n",
      "Epoch:  0031 D loss:-0.4931 G loss:-2.677\n",
      "Epoch:  0031 D loss:-0.5661 G loss:-2.661\n",
      "Epoch:  0031 D loss:-0.3966 G loss:-2.892\n",
      "Epoch:  0031 D loss:-0.4728 G loss:-2.639\n",
      "Epoch:  0031 D loss:-0.4478 G loss:-2.623\n",
      "Epoch:  0031 D loss:-0.4019 G loss:-2.629\n",
      "Epoch:  0031 D loss:-0.3877 G loss:-2.467\n",
      "Epoch:  0031 D loss:-0.3942 G loss:-2.505\n",
      "Epoch:  0032 D loss:-0.3354 G loss:-2.677\n",
      "Epoch:  0032 D loss:-0.2888 G loss:-2.542\n",
      "Epoch:  0032 D loss:-0.3832 G loss:-2.765\n",
      "Epoch:  0032 D loss:-0.328 G loss:-2.741\n",
      "Epoch:  0032 D loss:-0.4076 G loss:-2.458\n",
      "Epoch:  0032 D loss:-0.4266 G loss:-2.529\n",
      "Epoch:  0032 D loss:-0.378 G loss:-2.696\n",
      "Epoch:  0032 D loss:-0.3811 G loss:-2.672\n",
      "Epoch:  0032 D loss:-0.3686 G loss:-2.647\n",
      "Epoch:  0032 D loss:-0.4519 G loss:-2.585\n",
      "Epoch:  0032 D loss:-0.4071 G loss:-2.647\n",
      "Epoch:  0032 D loss:-0.3742 G loss:-2.608\n",
      "Epoch:  0032 D loss:-0.4324 G loss:-2.784\n",
      "Epoch:  0032 D loss:-0.4088 G loss:-2.56\n",
      "Epoch:  0032 D loss:-0.4814 G loss:-2.701\n",
      "Epoch:  0032 D loss:-0.4856 G loss:-2.655\n",
      "Epoch:  0032 D loss:-0.4407 G loss:-2.67\n",
      "Epoch:  0032 D loss:-0.3596 G loss:-2.545\n",
      "Epoch:  0032 D loss:-0.5182 G loss:-2.544\n",
      "Epoch:  0032 D loss:-0.4516 G loss:-2.433\n",
      "Epoch:  0032 D loss:-0.4826 G loss:-2.381\n",
      "Epoch:  0032 D loss:-0.4029 G loss:-2.541\n",
      "Epoch:  0032 D loss:-0.3841 G loss:-2.449\n",
      "Epoch:  0032 D loss:-0.3205 G loss:-2.541\n",
      "Epoch:  0032 D loss:-0.5123 G loss:-2.331\n",
      "Epoch:  0032 D loss:-0.4835 G loss:-2.429\n",
      "Epoch:  0032 D loss:-0.349 G loss:-2.568\n",
      "Epoch:  0032 D loss:-0.5135 G loss:-2.524\n",
      "Epoch:  0032 D loss:-0.3491 G loss:-2.551\n",
      "Epoch:  0032 D loss:-0.4678 G loss:-2.746\n",
      "Epoch:  0032 D loss:-0.4609 G loss:-2.826\n",
      "Epoch:  0032 D loss:-0.5216 G loss:-2.69\n",
      "Epoch:  0032 D loss:-0.4437 G loss:-2.835\n",
      "Epoch:  0032 D loss:-0.3736 G loss:-2.789\n",
      "Epoch:  0032 D loss:-0.5173 G loss:-2.511\n",
      "Epoch:  0032 D loss:-0.5417 G loss:-2.468\n",
      "Epoch:  0032 D loss:-0.3716 G loss:-2.887\n",
      "Epoch:  0032 D loss:-0.5044 G loss:-2.454\n",
      "Epoch:  0032 D loss:-0.3077 G loss:-2.798\n",
      "Epoch:  0032 D loss:-0.4225 G loss:-2.61\n",
      "Epoch:  0032 D loss:-0.4584 G loss:-2.517\n",
      "Epoch:  0032 D loss:-0.5604 G loss:-2.469\n",
      "Epoch:  0032 D loss:-0.5174 G loss:-2.441\n",
      "Epoch:  0032 D loss:-0.4784 G loss:-2.397\n",
      "Epoch:  0032 D loss:-0.4725 G loss:-2.486\n",
      "Epoch:  0032 D loss:-0.3819 G loss:-2.628\n",
      "Epoch:  0032 D loss:-0.3931 G loss:-2.444\n",
      "Epoch:  0032 D loss:-0.4338 G loss:-2.606\n",
      "Epoch:  0032 D loss:-0.421 G loss:-2.801\n",
      "Epoch:  0032 D loss:-0.3926 G loss:-2.816\n",
      "Epoch:  0032 D loss:-0.4111 G loss:-2.907\n",
      "Epoch:  0032 D loss:-0.3903 G loss:-2.982\n",
      "Epoch:  0032 D loss:-0.4215 G loss:-2.945\n",
      "Epoch:  0032 D loss:-0.4493 G loss:-2.841\n",
      "Epoch:  0032 D loss:-0.3763 G loss:-2.607\n",
      "Epoch:  0032 D loss:-0.5072 G loss:-2.554\n",
      "Epoch:  0032 D loss:-0.3674 G loss:-2.567\n",
      "Epoch:  0032 D loss:-0.4713 G loss:-2.646\n",
      "Epoch:  0032 D loss:-0.4567 G loss:-2.353\n",
      "Epoch:  0032 D loss:-0.4647 G loss:-2.362\n",
      "Epoch:  0032 D loss:-0.43 G loss:-2.283\n",
      "Epoch:  0032 D loss:-0.4536 G loss:-2.423\n",
      "Epoch:  0032 D loss:-0.4734 G loss:-2.671\n",
      "Epoch:  0032 D loss:-0.4375 G loss:-2.615\n",
      "Epoch:  0032 D loss:-0.3945 G loss:-2.785\n",
      "Epoch:  0032 D loss:-0.5456 G loss:-2.621\n",
      "Epoch:  0032 D loss:-0.4815 G loss:-2.625\n",
      "Epoch:  0032 D loss:-0.4838 G loss:-2.626\n",
      "Epoch:  0032 D loss:-0.4916 G loss:-2.743\n",
      "Epoch:  0032 D loss:-0.4968 G loss:-2.497\n",
      "Epoch:  0032 D loss:-0.4391 G loss:-2.534\n",
      "Epoch:  0032 D loss:-0.6358 G loss:-2.663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0032 D loss:-0.6359 G loss:-2.534\n",
      "Epoch:  0032 D loss:-0.3516 G loss:-2.473\n",
      "Epoch:  0032 D loss:-0.4871 G loss:-2.521\n",
      "Epoch:  0032 D loss:-0.4463 G loss:-2.562\n",
      "Epoch:  0032 D loss:-0.5486 G loss:-2.129\n",
      "Epoch:  0032 D loss:-0.4611 G loss:-2.33\n",
      "Epoch:  0032 D loss:-0.5209 G loss:-2.501\n",
      "Epoch:  0032 D loss:-0.4906 G loss:-2.38\n",
      "Epoch:  0032 D loss:-0.5769 G loss:-2.335\n",
      "Epoch:  0032 D loss:-0.4682 G loss:-2.614\n",
      "Epoch:  0032 D loss:-0.4662 G loss:-2.583\n",
      "Epoch:  0032 D loss:-0.4796 G loss:-2.585\n",
      "Epoch:  0032 D loss:-0.5823 G loss:-2.535\n",
      "Epoch:  0032 D loss:-0.5692 G loss:-2.306\n",
      "Epoch:  0032 D loss:-0.6451 G loss:-2.712\n",
      "Epoch:  0032 D loss:-0.5194 G loss:-2.411\n",
      "Epoch:  0032 D loss:-0.5145 G loss:-2.629\n",
      "Epoch:  0032 D loss:-0.4504 G loss:-2.399\n",
      "Epoch:  0032 D loss:-0.3877 G loss:-2.582\n",
      "Epoch:  0032 D loss:-0.4506 G loss:-2.38\n",
      "Epoch:  0032 D loss:-0.3823 G loss:-2.756\n",
      "Epoch:  0032 D loss:-0.5162 G loss:-2.507\n",
      "Epoch:  0032 D loss:-0.4863 G loss:-2.484\n",
      "Epoch:  0032 D loss:-0.4134 G loss:-2.546\n",
      "Epoch:  0032 D loss:-0.4726 G loss:-2.521\n",
      "Epoch:  0032 D loss:-0.3449 G loss:-2.743\n",
      "Epoch:  0032 D loss:-0.4402 G loss:-2.414\n",
      "Epoch:  0032 D loss:-0.3911 G loss:-2.826\n",
      "Epoch:  0032 D loss:-0.5245 G loss:-2.619\n",
      "Epoch:  0032 D loss:-0.4752 G loss:-2.834\n",
      "Epoch:  0032 D loss:-0.4351 G loss:-2.732\n",
      "Epoch:  0032 D loss:-0.3663 G loss:-2.723\n",
      "Epoch:  0032 D loss:-0.4906 G loss:-2.627\n",
      "Epoch:  0032 D loss:-0.4107 G loss:-2.571\n",
      "Epoch:  0032 D loss:-0.496 G loss:-2.589\n",
      "Epoch:  0032 D loss:-0.4574 G loss:-2.634\n",
      "Epoch:  0032 D loss:-0.3431 G loss:-2.468\n",
      "Epoch:  0032 D loss:-0.3696 G loss:-2.595\n",
      "Epoch:  0032 D loss:-0.4654 G loss:-2.6\n",
      "Epoch:  0032 D loss:-0.5388 G loss:-2.491\n",
      "Epoch:  0032 D loss:-0.344 G loss:-2.515\n",
      "Epoch:  0032 D loss:-0.3994 G loss:-2.945\n",
      "Epoch:  0032 D loss:-0.4985 G loss:-2.61\n",
      "Epoch:  0032 D loss:-0.3404 G loss:-2.513\n",
      "Epoch:  0032 D loss:-0.4608 G loss:-2.691\n",
      "Epoch:  0032 D loss:-0.402 G loss:-2.529\n",
      "Epoch:  0032 D loss:-0.3948 G loss:-2.788\n",
      "Epoch:  0032 D loss:-0.4281 G loss:-2.769\n",
      "Epoch:  0032 D loss:-0.4873 G loss:-2.611\n",
      "Epoch:  0032 D loss:-0.5511 G loss:-2.786\n",
      "Epoch:  0032 D loss:-0.4546 G loss:-2.692\n",
      "Epoch:  0032 D loss:-0.3194 G loss:-2.853\n",
      "Epoch:  0032 D loss:-0.4332 G loss:-2.551\n",
      "Epoch:  0032 D loss:-0.4151 G loss:-2.677\n",
      "Epoch:  0032 D loss:-0.3681 G loss:-2.691\n",
      "Epoch:  0032 D loss:-0.4564 G loss:-2.647\n",
      "Epoch:  0032 D loss:-0.52 G loss:-2.43\n",
      "Epoch:  0032 D loss:-0.3952 G loss:-2.679\n",
      "Epoch:  0032 D loss:-0.372 G loss:-2.46\n",
      "Epoch:  0032 D loss:-0.3911 G loss:-2.59\n",
      "Epoch:  0032 D loss:-0.4875 G loss:-2.616\n",
      "Epoch:  0032 D loss:-0.3844 G loss:-2.456\n",
      "Epoch:  0032 D loss:-0.4253 G loss:-2.415\n",
      "Epoch:  0032 D loss:-0.4083 G loss:-2.554\n",
      "Epoch:  0032 D loss:-0.4686 G loss:-2.689\n",
      "Epoch:  0032 D loss:-0.3908 G loss:-2.853\n",
      "Epoch:  0032 D loss:-0.4443 G loss:-2.669\n",
      "Epoch:  0032 D loss:-0.4546 G loss:-2.579\n",
      "Epoch:  0032 D loss:-0.4216 G loss:-2.736\n",
      "Epoch:  0032 D loss:-0.3055 G loss:-2.877\n",
      "Epoch:  0032 D loss:-0.4138 G loss:-2.685\n",
      "Epoch:  0032 D loss:-0.4257 G loss:-2.71\n",
      "Epoch:  0032 D loss:-0.3913 G loss:-2.69\n",
      "Epoch:  0032 D loss:-0.404 G loss:-2.806\n",
      "Epoch:  0032 D loss:-0.4329 G loss:-2.431\n",
      "Epoch:  0032 D loss:-0.3161 G loss:-2.966\n",
      "Epoch:  0032 D loss:-0.3542 G loss:-2.817\n",
      "Epoch:  0032 D loss:-0.4593 G loss:-2.693\n",
      "Epoch:  0032 D loss:-0.433 G loss:-2.55\n",
      "Epoch:  0032 D loss:-0.3619 G loss:-2.787\n",
      "Epoch:  0032 D loss:-0.474 G loss:-2.835\n",
      "Epoch:  0032 D loss:-0.3749 G loss:-2.565\n",
      "Epoch:  0032 D loss:-0.3796 G loss:-2.733\n",
      "Epoch:  0032 D loss:-0.4047 G loss:-2.748\n",
      "Epoch:  0032 D loss:-0.3065 G loss:-2.637\n",
      "Epoch:  0032 D loss:-0.4084 G loss:-2.92\n",
      "Epoch:  0032 D loss:-0.4734 G loss:-2.671\n",
      "Epoch:  0032 D loss:-0.3733 G loss:-2.796\n",
      "Epoch:  0032 D loss:-0.4657 G loss:-2.466\n",
      "Epoch:  0032 D loss:-0.498 G loss:-2.615\n",
      "Epoch:  0032 D loss:-0.3745 G loss:-2.824\n",
      "Epoch:  0032 D loss:-0.5029 G loss:-2.851\n",
      "Epoch:  0032 D loss:-0.35 G loss:-2.612\n",
      "Epoch:  0032 D loss:-0.3854 G loss:-2.693\n",
      "Epoch:  0032 D loss:-0.3385 G loss:-2.836\n",
      "Epoch:  0032 D loss:-0.4956 G loss:-2.785\n",
      "Epoch:  0032 D loss:-0.4101 G loss:-2.593\n",
      "Epoch:  0032 D loss:-0.355 G loss:-2.553\n",
      "Epoch:  0032 D loss:-0.475 G loss:-2.622\n",
      "Epoch:  0032 D loss:-0.4696 G loss:-2.575\n",
      "Epoch:  0032 D loss:-0.4604 G loss:-2.693\n",
      "Epoch:  0032 D loss:-0.4701 G loss:-2.536\n",
      "Epoch:  0032 D loss:-0.4505 G loss:-2.544\n",
      "Epoch:  0032 D loss:-0.3957 G loss:-2.633\n",
      "Epoch:  0032 D loss:-0.4068 G loss:-2.592\n",
      "Epoch:  0032 D loss:-0.5358 G loss:-2.33\n",
      "Epoch:  0032 D loss:-0.5609 G loss:-2.451\n",
      "Epoch:  0032 D loss:-0.4555 G loss:-2.745\n",
      "Epoch:  0032 D loss:-0.489 G loss:-2.63\n",
      "Epoch:  0032 D loss:-0.4373 G loss:-2.765\n",
      "Epoch:  0032 D loss:-0.3716 G loss:-2.592\n",
      "Epoch:  0032 D loss:-0.4776 G loss:-2.636\n",
      "Epoch:  0032 D loss:-0.4628 G loss:-2.54\n",
      "Epoch:  0032 D loss:-0.3698 G loss:-2.754\n",
      "Epoch:  0032 D loss:-0.4535 G loss:-2.759\n",
      "Epoch:  0032 D loss:-0.3161 G loss:-2.713\n",
      "Epoch:  0032 D loss:-0.3876 G loss:-2.802\n",
      "Epoch:  0032 D loss:-0.3899 G loss:-2.601\n",
      "Epoch:  0032 D loss:-0.4578 G loss:-2.558\n",
      "Epoch:  0032 D loss:-0.3953 G loss:-2.412\n",
      "Epoch:  0032 D loss:-0.4182 G loss:-2.489\n",
      "Epoch:  0032 D loss:-0.4835 G loss:-2.427\n",
      "Epoch:  0032 D loss:-0.4848 G loss:-2.72\n",
      "Epoch:  0032 D loss:-0.4393 G loss:-2.744\n",
      "Epoch:  0032 D loss:-0.4383 G loss:-2.809\n",
      "Epoch:  0032 D loss:-0.4601 G loss:-2.711\n",
      "Epoch:  0032 D loss:-0.4172 G loss:-2.691\n",
      "Epoch:  0032 D loss:-0.466 G loss:-2.663\n",
      "Epoch:  0032 D loss:-0.5397 G loss:-2.746\n",
      "Epoch:  0032 D loss:-0.4662 G loss:-2.595\n",
      "Epoch:  0032 D loss:-0.4862 G loss:-2.895\n",
      "Epoch:  0032 D loss:-0.3953 G loss:-2.791\n",
      "Epoch:  0032 D loss:-0.4498 G loss:-2.795\n",
      "Epoch:  0032 D loss:-0.4812 G loss:-2.715\n",
      "Epoch:  0032 D loss:-0.4336 G loss:-2.627\n",
      "Epoch:  0032 D loss:-0.3027 G loss:-2.575\n",
      "Epoch:  0032 D loss:-0.3437 G loss:-2.549\n",
      "Epoch:  0032 D loss:-0.4221 G loss:-2.732\n",
      "Epoch:  0032 D loss:-0.3518 G loss:-2.501\n",
      "Epoch:  0032 D loss:-0.5223 G loss:-2.297\n",
      "Epoch:  0032 D loss:-0.3973 G loss:-2.672\n",
      "Epoch:  0032 D loss:-0.4609 G loss:-2.625\n",
      "Epoch:  0032 D loss:-0.3802 G loss:-2.549\n",
      "Epoch:  0032 D loss:-0.4344 G loss:-2.695\n",
      "Epoch:  0032 D loss:-0.4279 G loss:-2.653\n",
      "Epoch:  0032 D loss:-0.5161 G loss:-2.886\n",
      "Epoch:  0032 D loss:-0.452 G loss:-2.784\n",
      "Epoch:  0032 D loss:-0.3476 G loss:-2.88\n",
      "Epoch:  0032 D loss:-0.4727 G loss:-2.82\n",
      "Epoch:  0032 D loss:-0.4298 G loss:-2.753\n",
      "Epoch:  0032 D loss:-0.4365 G loss:-2.979\n",
      "Epoch:  0032 D loss:-0.569 G loss:-2.643\n",
      "Epoch:  0032 D loss:-0.428 G loss:-2.835\n",
      "Epoch:  0032 D loss:-0.4554 G loss:-2.484\n",
      "Epoch:  0032 D loss:-0.386 G loss:-2.584\n",
      "Epoch:  0032 D loss:-0.55 G loss:-2.563\n",
      "Epoch:  0032 D loss:-0.4621 G loss:-2.609\n",
      "Epoch:  0032 D loss:-0.4502 G loss:-2.395\n",
      "Epoch:  0032 D loss:-0.5624 G loss:-2.279\n",
      "Epoch:  0032 D loss:-0.3914 G loss:-2.556\n",
      "Epoch:  0032 D loss:-0.4989 G loss:-2.798\n",
      "Epoch:  0032 D loss:-0.5121 G loss:-2.821\n",
      "Epoch:  0032 D loss:-0.4837 G loss:-2.842\n",
      "Epoch:  0032 D loss:-0.3984 G loss:-2.673\n",
      "Epoch:  0032 D loss:-0.5001 G loss:-2.686\n",
      "Epoch:  0032 D loss:-0.4251 G loss:-2.897\n",
      "Epoch:  0032 D loss:-0.4988 G loss:-2.631\n",
      "Epoch:  0032 D loss:-0.3707 G loss:-2.939\n",
      "Epoch:  0032 D loss:-0.5094 G loss:-2.743\n",
      "Epoch:  0032 D loss:-0.5943 G loss:-2.192\n",
      "Epoch:  0032 D loss:-0.3754 G loss:-2.584\n",
      "Epoch:  0032 D loss:-0.4502 G loss:-2.557\n",
      "Epoch:  0032 D loss:-0.4979 G loss:-2.389\n",
      "Epoch:  0032 D loss:-0.549 G loss:-2.554\n",
      "Epoch:  0032 D loss:-0.4491 G loss:-2.622\n",
      "Epoch:  0032 D loss:-0.5305 G loss:-2.516\n",
      "Epoch:  0032 D loss:-0.4602 G loss:-2.427\n",
      "Epoch:  0032 D loss:-0.426 G loss:-2.377\n",
      "Epoch:  0032 D loss:-0.4409 G loss:-2.745\n",
      "Epoch:  0032 D loss:-0.4202 G loss:-2.716\n",
      "Epoch:  0032 D loss:-0.3389 G loss:-2.69\n",
      "Epoch:  0032 D loss:-0.451 G loss:-2.605\n",
      "Epoch:  0032 D loss:-0.5753 G loss:-2.725\n",
      "Epoch:  0032 D loss:-0.467 G loss:-2.837\n",
      "Epoch:  0032 D loss:-0.4122 G loss:-2.767\n",
      "Epoch:  0032 D loss:-0.4454 G loss:-2.725\n",
      "Epoch:  0032 D loss:-0.3538 G loss:-2.862\n",
      "Epoch:  0032 D loss:-0.405 G loss:-2.863\n",
      "Epoch:  0032 D loss:-0.4909 G loss:-2.606\n",
      "Epoch:  0032 D loss:-0.5685 G loss:-2.603\n",
      "Epoch:  0032 D loss:-0.5367 G loss:-2.513\n",
      "Epoch:  0032 D loss:-0.484 G loss:-2.716\n",
      "Epoch:  0032 D loss:-0.5689 G loss:-2.455\n",
      "Epoch:  0032 D loss:-0.5994 G loss:-2.442\n",
      "Epoch:  0032 D loss:-0.3797 G loss:-2.644\n",
      "Epoch:  0032 D loss:-0.4108 G loss:-2.59\n",
      "Epoch:  0032 D loss:-0.4976 G loss:-2.513\n",
      "Epoch:  0032 D loss:-0.4936 G loss:-2.445\n",
      "Epoch:  0032 D loss:-0.4078 G loss:-2.473\n",
      "Epoch:  0032 D loss:-0.4299 G loss:-2.527\n",
      "Epoch:  0032 D loss:-0.5367 G loss:-2.411\n",
      "Epoch:  0032 D loss:-0.4941 G loss:-2.558\n",
      "Epoch:  0032 D loss:-0.453 G loss:-2.682\n",
      "Epoch:  0032 D loss:-0.6292 G loss:-2.485\n",
      "Epoch:  0032 D loss:-0.479 G loss:-2.734\n",
      "Epoch:  0032 D loss:-0.4489 G loss:-2.707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0032 D loss:-0.4931 G loss:-2.88\n",
      "Epoch:  0032 D loss:-0.4454 G loss:-2.556\n",
      "Epoch:  0032 D loss:-0.5125 G loss:-2.516\n",
      "Epoch:  0032 D loss:-0.4257 G loss:-2.467\n",
      "Epoch:  0032 D loss:-0.4676 G loss:-2.43\n",
      "Epoch:  0032 D loss:-0.396 G loss:-2.605\n",
      "Epoch:  0032 D loss:-0.4357 G loss:-2.749\n",
      "Epoch:  0032 D loss:-0.4693 G loss:-2.492\n",
      "Epoch:  0032 D loss:-0.4096 G loss:-2.506\n",
      "Epoch:  0032 D loss:-0.4674 G loss:-2.443\n",
      "Epoch:  0032 D loss:-0.3998 G loss:-2.538\n",
      "Epoch:  0032 D loss:-0.3777 G loss:-2.608\n",
      "Epoch:  0032 D loss:-0.396 G loss:-2.747\n",
      "Epoch:  0032 D loss:-0.4431 G loss:-2.559\n",
      "Epoch:  0032 D loss:-0.4192 G loss:-2.71\n",
      "Epoch:  0032 D loss:-0.3946 G loss:-2.788\n",
      "Epoch:  0032 D loss:-0.4942 G loss:-2.558\n",
      "Epoch:  0032 D loss:-0.4225 G loss:-2.554\n",
      "Epoch:  0032 D loss:-0.591 G loss:-2.559\n",
      "Epoch:  0032 D loss:-0.4734 G loss:-2.449\n",
      "Epoch:  0032 D loss:-0.3813 G loss:-2.549\n",
      "Epoch:  0032 D loss:-0.531 G loss:-2.3\n",
      "Epoch:  0032 D loss:-0.3641 G loss:-2.577\n",
      "Epoch:  0032 D loss:-0.475 G loss:-2.362\n",
      "Epoch:  0032 D loss:-0.4898 G loss:-2.64\n",
      "Epoch:  0032 D loss:-0.4046 G loss:-2.439\n",
      "Epoch:  0032 D loss:-0.5437 G loss:-2.546\n",
      "Epoch:  0032 D loss:-0.4926 G loss:-2.439\n",
      "Epoch:  0032 D loss:-0.3669 G loss:-2.421\n",
      "Epoch:  0032 D loss:-0.3431 G loss:-2.644\n",
      "Epoch:  0032 D loss:-0.3904 G loss:-2.517\n",
      "Epoch:  0032 D loss:-0.4257 G loss:-2.841\n",
      "Epoch:  0032 D loss:-0.4151 G loss:-2.327\n",
      "Epoch:  0032 D loss:-0.3975 G loss:-2.778\n",
      "Epoch:  0032 D loss:-0.5922 G loss:-2.516\n",
      "Epoch:  0032 D loss:-0.5192 G loss:-2.498\n",
      "Epoch:  0032 D loss:-0.4715 G loss:-2.489\n",
      "Epoch:  0032 D loss:-0.4205 G loss:-2.403\n",
      "Epoch:  0032 D loss:-0.3299 G loss:-2.511\n",
      "Epoch:  0032 D loss:-0.4407 G loss:-2.455\n",
      "Epoch:  0032 D loss:-0.439 G loss:-2.251\n",
      "Epoch:  0032 D loss:-0.5276 G loss:-2.247\n",
      "Epoch:  0032 D loss:-0.5459 G loss:-2.422\n",
      "Epoch:  0032 D loss:-0.4756 G loss:-2.686\n",
      "Epoch:  0032 D loss:-0.3909 G loss:-2.7\n",
      "Epoch:  0032 D loss:-0.4788 G loss:-2.556\n",
      "Epoch:  0032 D loss:-0.383 G loss:-2.613\n",
      "Epoch:  0032 D loss:-0.3865 G loss:-2.815\n",
      "Epoch:  0032 D loss:-0.5281 G loss:-2.587\n",
      "Epoch:  0032 D loss:-0.4585 G loss:-2.42\n",
      "Epoch:  0032 D loss:-0.4622 G loss:-2.374\n",
      "Epoch:  0032 D loss:-0.3832 G loss:-2.665\n",
      "Epoch:  0032 D loss:-0.3712 G loss:-2.59\n",
      "Epoch:  0032 D loss:-0.4315 G loss:-2.503\n",
      "Epoch:  0032 D loss:-0.4218 G loss:-2.372\n",
      "Epoch:  0032 D loss:-0.4223 G loss:-2.733\n",
      "Epoch:  0032 D loss:-0.3426 G loss:-2.487\n",
      "Epoch:  0032 D loss:-0.4654 G loss:-2.491\n",
      "Epoch:  0032 D loss:-0.4421 G loss:-2.621\n",
      "Epoch:  0032 D loss:-0.4225 G loss:-2.59\n",
      "Epoch:  0032 D loss:-0.656 G loss:-2.409\n",
      "Epoch:  0032 D loss:-0.3758 G loss:-2.457\n",
      "Epoch:  0032 D loss:-0.5679 G loss:-2.353\n",
      "Epoch:  0032 D loss:-0.5252 G loss:-2.739\n",
      "Epoch:  0032 D loss:-0.5244 G loss:-2.538\n",
      "Epoch:  0032 D loss:-0.4112 G loss:-2.729\n",
      "Epoch:  0032 D loss:-0.4437 G loss:-2.649\n",
      "Epoch:  0032 D loss:-0.3592 G loss:-2.584\n",
      "Epoch:  0032 D loss:-0.3866 G loss:-2.628\n",
      "Epoch:  0032 D loss:-0.3993 G loss:-2.62\n",
      "Epoch:  0032 D loss:-0.4278 G loss:-2.444\n",
      "Epoch:  0032 D loss:-0.4416 G loss:-2.484\n",
      "Epoch:  0032 D loss:-0.3223 G loss:-2.651\n",
      "Epoch:  0032 D loss:-0.4442 G loss:-2.403\n",
      "Epoch:  0032 D loss:-0.4455 G loss:-2.577\n",
      "Epoch:  0032 D loss:-0.3946 G loss:-2.718\n",
      "Epoch:  0032 D loss:-0.4901 G loss:-2.663\n",
      "Epoch:  0032 D loss:-0.3776 G loss:-2.89\n",
      "Epoch:  0032 D loss:-0.6822 G loss:-2.687\n",
      "Epoch:  0032 D loss:-0.4222 G loss:-2.716\n",
      "Epoch:  0032 D loss:-0.5392 G loss:-2.588\n",
      "Epoch:  0032 D loss:-0.4497 G loss:-2.43\n",
      "Epoch:  0032 D loss:-0.4318 G loss:-2.555\n",
      "Epoch:  0032 D loss:-0.3902 G loss:-2.56\n",
      "Epoch:  0032 D loss:-0.3935 G loss:-2.581\n",
      "Epoch:  0032 D loss:-0.5359 G loss:-2.296\n",
      "Epoch:  0032 D loss:-0.474 G loss:-2.37\n",
      "Epoch:  0032 D loss:-0.4303 G loss:-2.836\n",
      "Epoch:  0032 D loss:-0.4373 G loss:-2.765\n",
      "Epoch:  0032 D loss:-0.4575 G loss:-2.705\n",
      "Epoch:  0032 D loss:-0.49 G loss:-2.722\n",
      "Epoch:  0032 D loss:-0.4381 G loss:-2.548\n",
      "Epoch:  0032 D loss:-0.4217 G loss:-2.869\n",
      "Epoch:  0032 D loss:-0.5022 G loss:-2.741\n",
      "Epoch:  0032 D loss:-0.5434 G loss:-2.668\n",
      "Epoch:  0032 D loss:-0.514 G loss:-2.627\n",
      "Epoch:  0032 D loss:-0.3676 G loss:-2.868\n",
      "Epoch:  0032 D loss:-0.3534 G loss:-2.855\n",
      "Epoch:  0032 D loss:-0.4722 G loss:-2.458\n",
      "Epoch:  0032 D loss:-0.4622 G loss:-2.456\n",
      "Epoch:  0032 D loss:-0.4262 G loss:-2.652\n",
      "Epoch:  0032 D loss:-0.4634 G loss:-2.569\n",
      "Epoch:  0032 D loss:-0.321 G loss:-2.662\n",
      "Epoch:  0032 D loss:-0.4413 G loss:-2.474\n",
      "Epoch:  0032 D loss:-0.4033 G loss:-2.502\n",
      "Epoch:  0032 D loss:-0.5018 G loss:-2.44\n",
      "Epoch:  0032 D loss:-0.3922 G loss:-2.637\n",
      "Epoch:  0032 D loss:-0.4692 G loss:-2.443\n",
      "Epoch:  0032 D loss:-0.5042 G loss:-2.671\n",
      "Epoch:  0032 D loss:-0.4137 G loss:-2.81\n",
      "Epoch:  0032 D loss:-0.4612 G loss:-2.812\n",
      "Epoch:  0032 D loss:-0.3667 G loss:-2.797\n",
      "Epoch:  0032 D loss:-0.4151 G loss:-2.839\n",
      "Epoch:  0032 D loss:-0.5208 G loss:-2.594\n",
      "Epoch:  0032 D loss:-0.4574 G loss:-2.663\n",
      "Epoch:  0032 D loss:-0.5266 G loss:-2.736\n",
      "Epoch:  0032 D loss:-0.2955 G loss:-2.673\n",
      "Epoch:  0032 D loss:-0.4408 G loss:-2.745\n",
      "Epoch:  0032 D loss:-0.4555 G loss:-2.453\n",
      "Epoch:  0032 D loss:-0.3845 G loss:-2.768\n",
      "Epoch:  0032 D loss:-0.3882 G loss:-2.883\n",
      "Epoch:  0032 D loss:-0.3471 G loss:-2.865\n",
      "Epoch:  0032 D loss:-0.4549 G loss:-2.564\n",
      "Epoch:  0032 D loss:-0.4117 G loss:-2.531\n",
      "Epoch:  0032 D loss:-0.3176 G loss:-2.65\n",
      "Epoch:  0032 D loss:-0.406 G loss:-2.75\n",
      "Epoch:  0032 D loss:-0.4456 G loss:-2.44\n",
      "Epoch:  0032 D loss:-0.5719 G loss:-2.432\n",
      "Epoch:  0032 D loss:-0.4678 G loss:-2.865\n",
      "Epoch:  0032 D loss:-0.4224 G loss:-2.667\n",
      "Epoch:  0032 D loss:-0.4402 G loss:-2.469\n",
      "Epoch:  0032 D loss:-0.483 G loss:-2.722\n",
      "Epoch:  0032 D loss:-0.4841 G loss:-2.498\n",
      "Epoch:  0032 D loss:-0.4306 G loss:-2.614\n",
      "Epoch:  0032 D loss:-0.4897 G loss:-2.522\n",
      "Epoch:  0032 D loss:-0.5144 G loss:-2.57\n",
      "Epoch:  0032 D loss:-0.4469 G loss:-2.708\n",
      "Epoch:  0032 D loss:-0.5285 G loss:-2.33\n",
      "Epoch:  0032 D loss:-0.5936 G loss:-2.679\n",
      "Epoch:  0032 D loss:-0.5541 G loss:-2.787\n",
      "Epoch:  0032 D loss:-0.4031 G loss:-2.694\n",
      "Epoch:  0032 D loss:-0.5651 G loss:-2.414\n",
      "Epoch:  0032 D loss:-0.5582 G loss:-2.394\n",
      "Epoch:  0032 D loss:-0.3568 G loss:-2.505\n",
      "Epoch:  0032 D loss:-0.4433 G loss:-2.362\n",
      "Epoch:  0032 D loss:-0.5379 G loss:-2.593\n",
      "Epoch:  0032 D loss:-0.4888 G loss:-2.502\n",
      "Epoch:  0032 D loss:-0.4736 G loss:-2.304\n",
      "Epoch:  0032 D loss:-0.5052 G loss:-2.589\n",
      "Epoch:  0032 D loss:-0.5141 G loss:-2.621\n",
      "Epoch:  0032 D loss:-0.5835 G loss:-2.617\n",
      "Epoch:  0032 D loss:-0.4379 G loss:-2.555\n",
      "Epoch:  0032 D loss:-0.4752 G loss:-2.251\n",
      "Epoch:  0032 D loss:-0.4679 G loss:-2.603\n",
      "Epoch:  0032 D loss:-0.4629 G loss:-2.596\n",
      "Epoch:  0032 D loss:-0.4141 G loss:-2.708\n",
      "Epoch:  0032 D loss:-0.5183 G loss:-2.463\n",
      "Epoch:  0032 D loss:-0.3956 G loss:-2.57\n",
      "Epoch:  0032 D loss:-0.428 G loss:-2.936\n",
      "Epoch:  0032 D loss:-0.5247 G loss:-2.42\n",
      "Epoch:  0032 D loss:-0.4589 G loss:-2.543\n",
      "Epoch:  0032 D loss:-0.522 G loss:-2.764\n",
      "Epoch:  0032 D loss:-0.4173 G loss:-2.363\n",
      "Epoch:  0032 D loss:-0.6967 G loss:-2.347\n",
      "Epoch:  0032 D loss:-0.5783 G loss:-2.339\n",
      "Epoch:  0032 D loss:-0.5262 G loss:-2.295\n",
      "Epoch:  0032 D loss:-0.7065 G loss:-2.147\n",
      "Epoch:  0032 D loss:-0.559 G loss:-2.234\n",
      "Epoch:  0032 D loss:-0.6495 G loss:-2.209\n",
      "Epoch:  0032 D loss:-0.6346 G loss:-2.203\n",
      "Epoch:  0032 D loss:-0.5811 G loss:-2.23\n",
      "Epoch:  0032 D loss:-0.5082 G loss:-2.273\n",
      "Epoch:  0032 D loss:-0.4462 G loss:-2.337\n",
      "Epoch:  0032 D loss:-0.5213 G loss:-2.77\n",
      "Epoch:  0032 D loss:-0.5062 G loss:-2.327\n",
      "Epoch:  0032 D loss:-0.5338 G loss:-2.674\n",
      "Epoch:  0032 D loss:-0.5302 G loss:-2.731\n",
      "Epoch:  0032 D loss:-0.4364 G loss:-2.628\n",
      "Epoch:  0032 D loss:-0.5789 G loss:-2.582\n",
      "Epoch:  0032 D loss:-0.6325 G loss:-2.606\n",
      "Epoch:  0032 D loss:-0.3743 G loss:-2.573\n",
      "Epoch:  0032 D loss:-0.4553 G loss:-2.619\n",
      "Epoch:  0032 D loss:-0.5584 G loss:-2.626\n",
      "Epoch:  0032 D loss:-0.5798 G loss:-2.317\n",
      "Epoch:  0032 D loss:-0.3041 G loss:-2.36\n",
      "Epoch:  0032 D loss:-0.4888 G loss:-2.382\n",
      "Epoch:  0032 D loss:-0.4112 G loss:-2.484\n",
      "Epoch:  0032 D loss:-0.4186 G loss:-2.557\n",
      "Epoch:  0032 D loss:-0.5214 G loss:-2.437\n",
      "Epoch:  0032 D loss:-0.5786 G loss:-2.553\n",
      "Epoch:  0032 D loss:-0.4631 G loss:-2.597\n",
      "Epoch:  0032 D loss:-0.3715 G loss:-2.753\n",
      "Epoch:  0032 D loss:-0.586 G loss:-2.619\n",
      "Epoch:  0032 D loss:-0.5842 G loss:-2.666\n",
      "Epoch:  0032 D loss:-0.5352 G loss:-2.67\n",
      "Epoch:  0032 D loss:-0.4588 G loss:-2.629\n",
      "Epoch:  0032 D loss:-0.5233 G loss:-2.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0032 D loss:-0.3911 G loss:-2.56\n",
      "Epoch:  0032 D loss:-0.3859 G loss:-2.634\n",
      "Epoch:  0032 D loss:-0.4232 G loss:-2.653\n",
      "Epoch:  0032 D loss:-0.5647 G loss:-2.473\n",
      "Epoch:  0032 D loss:-0.5524 G loss:-2.49\n",
      "Epoch:  0032 D loss:-0.3541 G loss:-2.782\n",
      "Epoch:  0032 D loss:-0.4561 G loss:-2.716\n",
      "Epoch:  0032 D loss:-0.5336 G loss:-2.755\n",
      "Epoch:  0032 D loss:-0.5187 G loss:-2.67\n",
      "Epoch:  0032 D loss:-0.3859 G loss:-2.509\n",
      "Epoch:  0032 D loss:-0.5031 G loss:-2.654\n",
      "Epoch:  0032 D loss:-0.464 G loss:-2.39\n",
      "Epoch:  0032 D loss:-0.6007 G loss:-2.449\n",
      "Epoch:  0032 D loss:-0.5159 G loss:-2.658\n",
      "Epoch:  0032 D loss:-0.4837 G loss:-2.451\n",
      "Epoch:  0032 D loss:-0.4422 G loss:-2.409\n",
      "Epoch:  0032 D loss:-0.4798 G loss:-2.511\n",
      "Epoch:  0032 D loss:-0.5472 G loss:-2.287\n",
      "Epoch:  0032 D loss:-0.564 G loss:-2.452\n",
      "Epoch:  0032 D loss:-0.5167 G loss:-2.424\n",
      "Epoch:  0032 D loss:-0.6 G loss:-2.476\n",
      "Epoch:  0032 D loss:-0.5732 G loss:-2.341\n",
      "Epoch:  0032 D loss:-0.4897 G loss:-2.478\n",
      "Epoch:  0032 D loss:-0.4923 G loss:-2.412\n",
      "Epoch:  0032 D loss:-0.5204 G loss:-2.537\n",
      "Epoch:  0032 D loss:-0.5124 G loss:-2.374\n",
      "Epoch:  0032 D loss:-0.3653 G loss:-2.607\n",
      "Epoch:  0032 D loss:-0.4768 G loss:-2.597\n",
      "Epoch:  0032 D loss:-0.3938 G loss:-2.736\n",
      "Epoch:  0032 D loss:-0.4062 G loss:-2.54\n",
      "Epoch:  0032 D loss:-0.4966 G loss:-2.597\n",
      "Epoch:  0032 D loss:-0.4255 G loss:-2.72\n",
      "Epoch:  0032 D loss:-0.5201 G loss:-2.513\n",
      "Epoch:  0032 D loss:-0.4754 G loss:-2.53\n",
      "Epoch:  0032 D loss:-0.4715 G loss:-2.616\n",
      "Epoch:  0032 D loss:-0.5217 G loss:-2.648\n",
      "Epoch:  0032 D loss:-0.3598 G loss:-2.79\n",
      "Epoch:  0032 D loss:-0.4248 G loss:-2.658\n",
      "Epoch:  0032 D loss:-0.544 G loss:-2.792\n",
      "Epoch:  0032 D loss:-0.4427 G loss:-2.48\n",
      "Epoch:  0032 D loss:-0.4875 G loss:-2.646\n",
      "Epoch:  0032 D loss:-0.4526 G loss:-2.458\n",
      "Epoch:  0032 D loss:-0.5584 G loss:-2.278\n",
      "Epoch:  0032 D loss:-0.3994 G loss:-2.418\n",
      "Epoch:  0032 D loss:-0.3656 G loss:-2.448\n",
      "Epoch:  0032 D loss:-0.6095 G loss:-2.348\n",
      "Epoch:  0032 D loss:-0.3349 G loss:-2.495\n",
      "Epoch:  0032 D loss:-0.5623 G loss:-2.418\n",
      "Epoch:  0032 D loss:-0.4395 G loss:-2.482\n",
      "Epoch:  0032 D loss:-0.3729 G loss:-2.486\n",
      "Epoch:  0032 D loss:-0.5094 G loss:-2.342\n",
      "Epoch:  0032 D loss:-0.4994 G loss:-2.633\n",
      "Epoch:  0032 D loss:-0.5024 G loss:-2.59\n",
      "Epoch:  0032 D loss:-0.5243 G loss:-2.533\n",
      "Epoch:  0032 D loss:-0.4499 G loss:-2.589\n",
      "Epoch:  0032 D loss:-0.3849 G loss:-2.513\n",
      "Epoch:  0032 D loss:-0.4445 G loss:-2.558\n",
      "Epoch:  0032 D loss:-0.4651 G loss:-2.615\n",
      "Epoch:  0032 D loss:-0.3733 G loss:-2.502\n",
      "Epoch:  0032 D loss:-0.4867 G loss:-2.473\n",
      "Epoch:  0032 D loss:-0.3858 G loss:-2.564\n",
      "Epoch:  0032 D loss:-0.522 G loss:-2.537\n",
      "Epoch:  0032 D loss:-0.3743 G loss:-2.61\n",
      "Epoch:  0032 D loss:-0.3595 G loss:-2.709\n",
      "Epoch:  0032 D loss:-0.5875 G loss:-2.453\n",
      "Epoch:  0032 D loss:-0.3151 G loss:-2.674\n",
      "Epoch:  0032 D loss:-0.3804 G loss:-2.65\n",
      "Epoch:  0032 D loss:-0.4077 G loss:-2.781\n",
      "Epoch:  0032 D loss:-0.3933 G loss:-2.705\n",
      "Epoch:  0032 D loss:-0.42 G loss:-2.693\n",
      "Epoch:  0032 D loss:-0.4505 G loss:-2.622\n",
      "Epoch:  0032 D loss:-0.4442 G loss:-2.371\n",
      "Epoch:  0032 D loss:-0.3764 G loss:-2.707\n",
      "Epoch:  0032 D loss:-0.3904 G loss:-2.639\n",
      "Epoch:  0032 D loss:-0.6647 G loss:-2.573\n",
      "Epoch:  0033 D loss:-0.4402 G loss:-2.816\n",
      "Epoch:  0033 D loss:-0.5186 G loss:-2.551\n",
      "Epoch:  0033 D loss:-0.4303 G loss:-2.59\n",
      "Epoch:  0033 D loss:-0.4295 G loss:-2.527\n",
      "Epoch:  0033 D loss:-0.438 G loss:-2.438\n",
      "Epoch:  0033 D loss:-0.5244 G loss:-2.116\n",
      "Epoch:  0033 D loss:-0.4841 G loss:-2.253\n",
      "Epoch:  0033 D loss:-0.4194 G loss:-2.503\n",
      "Epoch:  0033 D loss:-0.4629 G loss:-2.294\n",
      "Epoch:  0033 D loss:-0.3455 G loss:-2.632\n",
      "Epoch:  0033 D loss:-0.5691 G loss:-2.523\n",
      "Epoch:  0033 D loss:-0.514 G loss:-2.665\n",
      "Epoch:  0033 D loss:-0.4706 G loss:-2.806\n",
      "Epoch:  0033 D loss:-0.4248 G loss:-2.938\n",
      "Epoch:  0033 D loss:-0.5449 G loss:-2.694\n",
      "Epoch:  0033 D loss:-0.4366 G loss:-2.594\n",
      "Epoch:  0033 D loss:-0.4084 G loss:-2.651\n",
      "Epoch:  0033 D loss:-0.3798 G loss:-2.339\n",
      "Epoch:  0033 D loss:-0.5343 G loss:-2.592\n",
      "Epoch:  0033 D loss:-0.4519 G loss:-2.531\n",
      "Epoch:  0033 D loss:-0.4642 G loss:-2.636\n",
      "Epoch:  0033 D loss:-0.3364 G loss:-2.484\n",
      "Epoch:  0033 D loss:-0.4245 G loss:-2.582\n",
      "Epoch:  0033 D loss:-0.4156 G loss:-2.596\n",
      "Epoch:  0033 D loss:-0.3505 G loss:-2.723\n",
      "Epoch:  0033 D loss:-0.4264 G loss:-2.621\n",
      "Epoch:  0033 D loss:-0.525 G loss:-2.812\n",
      "Epoch:  0033 D loss:-0.4754 G loss:-2.599\n",
      "Epoch:  0033 D loss:-0.3699 G loss:-2.904\n",
      "Epoch:  0033 D loss:-0.4518 G loss:-2.861\n",
      "Epoch:  0033 D loss:-0.4266 G loss:-2.908\n",
      "Epoch:  0033 D loss:-0.4077 G loss:-2.835\n",
      "Epoch:  0033 D loss:-0.3953 G loss:-2.71\n",
      "Epoch:  0033 D loss:-0.6223 G loss:-2.671\n",
      "Epoch:  0033 D loss:-0.481 G loss:-2.214\n",
      "Epoch:  0033 D loss:-0.4704 G loss:-2.471\n",
      "Epoch:  0033 D loss:-0.4667 G loss:-2.332\n",
      "Epoch:  0033 D loss:-0.5389 G loss:-2.358\n",
      "Epoch:  0033 D loss:-0.3916 G loss:-2.606\n",
      "Epoch:  0033 D loss:-0.4589 G loss:-2.483\n",
      "Epoch:  0033 D loss:-0.5538 G loss:-2.574\n",
      "Epoch:  0033 D loss:-0.4887 G loss:-2.675\n",
      "Epoch:  0033 D loss:-0.4005 G loss:-2.451\n",
      "Epoch:  0033 D loss:-0.5133 G loss:-2.493\n",
      "Epoch:  0033 D loss:-0.4406 G loss:-2.494\n",
      "Epoch:  0033 D loss:-0.5064 G loss:-2.714\n",
      "Epoch:  0033 D loss:-0.4373 G loss:-2.583\n",
      "Epoch:  0033 D loss:-0.4167 G loss:-2.754\n",
      "Epoch:  0033 D loss:-0.4425 G loss:-2.654\n",
      "Epoch:  0033 D loss:-0.5347 G loss:-2.567\n",
      "Epoch:  0033 D loss:-0.3917 G loss:-2.879\n",
      "Epoch:  0033 D loss:-0.3751 G loss:-2.738\n",
      "Epoch:  0033 D loss:-0.428 G loss:-2.849\n",
      "Epoch:  0033 D loss:-0.5682 G loss:-2.624\n",
      "Epoch:  0033 D loss:-0.4398 G loss:-2.44\n",
      "Epoch:  0033 D loss:-0.5479 G loss:-2.487\n",
      "Epoch:  0033 D loss:-0.4564 G loss:-2.557\n",
      "Epoch:  0033 D loss:-0.483 G loss:-2.51\n",
      "Epoch:  0033 D loss:-0.4238 G loss:-2.666\n",
      "Epoch:  0033 D loss:-0.4487 G loss:-2.735\n",
      "Epoch:  0033 D loss:-0.3032 G loss:-2.761\n",
      "Epoch:  0033 D loss:-0.4666 G loss:-2.766\n",
      "Epoch:  0033 D loss:-0.4427 G loss:-2.618\n",
      "Epoch:  0033 D loss:-0.3794 G loss:-2.584\n",
      "Epoch:  0033 D loss:-0.4047 G loss:-2.661\n",
      "Epoch:  0033 D loss:-0.488 G loss:-2.646\n",
      "Epoch:  0033 D loss:-0.5088 G loss:-2.706\n",
      "Epoch:  0033 D loss:-0.3975 G loss:-2.644\n",
      "Epoch:  0033 D loss:-0.5661 G loss:-2.425\n",
      "Epoch:  0033 D loss:-0.4168 G loss:-2.674\n",
      "Epoch:  0033 D loss:-0.5394 G loss:-2.624\n",
      "Epoch:  0033 D loss:-0.525 G loss:-2.322\n",
      "Epoch:  0033 D loss:-0.5229 G loss:-2.632\n",
      "Epoch:  0033 D loss:-0.4626 G loss:-2.491\n",
      "Epoch:  0033 D loss:-0.4221 G loss:-2.553\n",
      "Epoch:  0033 D loss:-0.4568 G loss:-2.493\n",
      "Epoch:  0033 D loss:-0.4169 G loss:-2.574\n",
      "Epoch:  0033 D loss:-0.6074 G loss:-2.568\n",
      "Epoch:  0033 D loss:-0.4713 G loss:-2.526\n",
      "Epoch:  0033 D loss:-0.5655 G loss:-2.359\n",
      "Epoch:  0033 D loss:-0.5014 G loss:-2.522\n",
      "Epoch:  0033 D loss:-0.4057 G loss:-2.58\n",
      "Epoch:  0033 D loss:-0.5534 G loss:-2.745\n",
      "Epoch:  0033 D loss:-0.4881 G loss:-2.546\n",
      "Epoch:  0033 D loss:-0.4521 G loss:-2.618\n",
      "Epoch:  0033 D loss:-0.4869 G loss:-2.649\n",
      "Epoch:  0033 D loss:-0.3722 G loss:-2.752\n",
      "Epoch:  0033 D loss:-0.406 G loss:-2.64\n",
      "Epoch:  0033 D loss:-0.4182 G loss:-2.701\n",
      "Epoch:  0033 D loss:-0.5398 G loss:-2.575\n",
      "Epoch:  0033 D loss:-0.4254 G loss:-2.532\n",
      "Epoch:  0033 D loss:-0.4387 G loss:-2.7\n",
      "Epoch:  0033 D loss:-0.5317 G loss:-2.412\n",
      "Epoch:  0033 D loss:-0.5417 G loss:-2.626\n",
      "Epoch:  0033 D loss:-0.4715 G loss:-2.436\n",
      "Epoch:  0033 D loss:-0.4654 G loss:-2.648\n",
      "Epoch:  0033 D loss:-0.3146 G loss:-2.606\n",
      "Epoch:  0033 D loss:-0.4336 G loss:-2.614\n",
      "Epoch:  0033 D loss:-0.3025 G loss:-2.687\n",
      "Epoch:  0033 D loss:-0.4351 G loss:-2.825\n",
      "Epoch:  0033 D loss:-0.4055 G loss:-2.968\n",
      "Epoch:  0033 D loss:-0.4244 G loss:-2.516\n",
      "Epoch:  0033 D loss:-0.4245 G loss:-2.796\n",
      "Epoch:  0033 D loss:-0.4015 G loss:-2.622\n",
      "Epoch:  0033 D loss:-0.3899 G loss:-2.664\n",
      "Epoch:  0033 D loss:-0.4405 G loss:-2.763\n",
      "Epoch:  0033 D loss:-0.3753 G loss:-2.557\n",
      "Epoch:  0033 D loss:-0.528 G loss:-2.557\n",
      "Epoch:  0033 D loss:-0.4822 G loss:-2.457\n",
      "Epoch:  0033 D loss:-0.5424 G loss:-2.466\n",
      "Epoch:  0033 D loss:-0.3888 G loss:-2.594\n",
      "Epoch:  0033 D loss:-0.4788 G loss:-2.555\n",
      "Epoch:  0033 D loss:-0.4191 G loss:-2.7\n",
      "Epoch:  0033 D loss:-0.3501 G loss:-2.553\n",
      "Epoch:  0033 D loss:-0.4465 G loss:-2.633\n",
      "Epoch:  0033 D loss:-0.4161 G loss:-2.476\n",
      "Epoch:  0033 D loss:-0.4653 G loss:-2.65\n",
      "Epoch:  0033 D loss:-0.3774 G loss:-2.646\n",
      "Epoch:  0033 D loss:-0.3899 G loss:-2.814\n",
      "Epoch:  0033 D loss:-0.3903 G loss:-2.911\n",
      "Epoch:  0033 D loss:-0.364 G loss:-2.71\n",
      "Epoch:  0033 D loss:-0.433 G loss:-2.788\n",
      "Epoch:  0033 D loss:-0.4963 G loss:-2.808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0033 D loss:-0.428 G loss:-2.657\n",
      "Epoch:  0033 D loss:-0.4038 G loss:-2.617\n",
      "Epoch:  0033 D loss:-0.3662 G loss:-2.528\n",
      "Epoch:  0033 D loss:-0.4607 G loss:-2.427\n",
      "Epoch:  0033 D loss:-0.4577 G loss:-2.417\n",
      "Epoch:  0033 D loss:-0.4695 G loss:-2.398\n",
      "Epoch:  0033 D loss:-0.4222 G loss:-2.647\n",
      "Epoch:  0033 D loss:-0.4697 G loss:-2.766\n",
      "Epoch:  0033 D loss:-0.4674 G loss:-2.763\n",
      "Epoch:  0033 D loss:-0.3355 G loss:-2.613\n",
      "Epoch:  0033 D loss:-0.3856 G loss:-2.703\n",
      "Epoch:  0033 D loss:-0.4888 G loss:-2.338\n",
      "Epoch:  0033 D loss:-0.4664 G loss:-2.526\n",
      "Epoch:  0033 D loss:-0.4163 G loss:-2.779\n",
      "Epoch:  0033 D loss:-0.3318 G loss:-2.713\n",
      "Epoch:  0033 D loss:-0.4523 G loss:-2.797\n",
      "Epoch:  0033 D loss:-0.5038 G loss:-2.707\n",
      "Epoch:  0033 D loss:-0.3783 G loss:-2.815\n",
      "Epoch:  0033 D loss:-0.3294 G loss:-2.711\n",
      "Epoch:  0033 D loss:-0.4522 G loss:-2.487\n",
      "Epoch:  0033 D loss:-0.362 G loss:-2.919\n",
      "Epoch:  0033 D loss:-0.4127 G loss:-2.574\n",
      "Epoch:  0033 D loss:-0.5973 G loss:-2.713\n",
      "Epoch:  0033 D loss:-0.4625 G loss:-2.585\n",
      "Epoch:  0033 D loss:-0.4829 G loss:-2.762\n",
      "Epoch:  0033 D loss:-0.437 G loss:-2.753\n",
      "Epoch:  0033 D loss:-0.3003 G loss:-2.444\n",
      "Epoch:  0033 D loss:-0.3826 G loss:-2.566\n",
      "Epoch:  0033 D loss:-0.4152 G loss:-2.78\n",
      "Epoch:  0033 D loss:-0.5141 G loss:-2.483\n",
      "Epoch:  0033 D loss:-0.4256 G loss:-2.581\n",
      "Epoch:  0033 D loss:-0.5009 G loss:-2.624\n",
      "Epoch:  0033 D loss:-0.4459 G loss:-2.384\n",
      "Epoch:  0033 D loss:-0.4363 G loss:-2.448\n",
      "Epoch:  0033 D loss:-0.5086 G loss:-2.583\n",
      "Epoch:  0033 D loss:-0.3724 G loss:-2.519\n",
      "Epoch:  0033 D loss:-0.3213 G loss:-2.656\n",
      "Epoch:  0033 D loss:-0.4821 G loss:-2.842\n",
      "Epoch:  0033 D loss:-0.3401 G loss:-3.076\n",
      "Epoch:  0033 D loss:-0.3979 G loss:-3.053\n",
      "Epoch:  0033 D loss:-0.4499 G loss:-3.313\n",
      "Epoch:  0033 D loss:-0.5069 G loss:-2.853\n",
      "Epoch:  0033 D loss:-0.353 G loss:-2.862\n",
      "Epoch:  0033 D loss:-0.3424 G loss:-2.748\n",
      "Epoch:  0033 D loss:-0.4502 G loss:-2.601\n",
      "Epoch:  0033 D loss:-0.4235 G loss:-2.67\n",
      "Epoch:  0033 D loss:-0.5249 G loss:-2.45\n",
      "Epoch:  0033 D loss:-0.5254 G loss:-2.336\n",
      "Epoch:  0033 D loss:-0.4568 G loss:-2.435\n",
      "Epoch:  0033 D loss:-0.4093 G loss:-2.609\n",
      "Epoch:  0033 D loss:-0.5632 G loss:-2.4\n",
      "Epoch:  0033 D loss:-0.5683 G loss:-2.238\n",
      "Epoch:  0033 D loss:-0.4922 G loss:-2.265\n",
      "Epoch:  0033 D loss:-0.6113 G loss:-2.323\n",
      "Epoch:  0033 D loss:-0.4161 G loss:-2.39\n",
      "Epoch:  0033 D loss:-0.4499 G loss:-2.579\n",
      "Epoch:  0033 D loss:-0.4513 G loss:-2.687\n",
      "Epoch:  0033 D loss:-0.4695 G loss:-2.807\n",
      "Epoch:  0033 D loss:-0.3739 G loss:-2.691\n",
      "Epoch:  0033 D loss:-0.4979 G loss:-2.981\n",
      "Epoch:  0033 D loss:-0.4248 G loss:-3.088\n",
      "Epoch:  0033 D loss:-0.5052 G loss:-2.647\n",
      "Epoch:  0033 D loss:-0.4155 G loss:-2.702\n",
      "Epoch:  0033 D loss:-0.3878 G loss:-2.674\n",
      "Epoch:  0033 D loss:-0.3722 G loss:-2.47\n",
      "Epoch:  0033 D loss:-0.4133 G loss:-2.529\n",
      "Epoch:  0033 D loss:-0.4101 G loss:-2.551\n",
      "Epoch:  0033 D loss:-0.5248 G loss:-2.62\n",
      "Epoch:  0033 D loss:-0.4885 G loss:-2.322\n",
      "Epoch:  0033 D loss:-0.4123 G loss:-2.557\n",
      "Epoch:  0033 D loss:-0.4026 G loss:-2.507\n",
      "Epoch:  0033 D loss:-0.5409 G loss:-2.527\n",
      "Epoch:  0033 D loss:-0.5217 G loss:-2.576\n",
      "Epoch:  0033 D loss:-0.4927 G loss:-2.403\n",
      "Epoch:  0033 D loss:-0.3916 G loss:-2.74\n",
      "Epoch:  0033 D loss:-0.4635 G loss:-2.517\n",
      "Epoch:  0033 D loss:-0.4047 G loss:-2.586\n",
      "Epoch:  0033 D loss:-0.4279 G loss:-2.452\n",
      "Epoch:  0033 D loss:-0.4345 G loss:-2.538\n",
      "Epoch:  0033 D loss:-0.583 G loss:-2.568\n",
      "Epoch:  0033 D loss:-0.5165 G loss:-2.439\n",
      "Epoch:  0033 D loss:-0.4632 G loss:-2.753\n",
      "Epoch:  0033 D loss:-0.3899 G loss:-2.998\n",
      "Epoch:  0033 D loss:-0.3813 G loss:-2.786\n",
      "Epoch:  0033 D loss:-0.5354 G loss:-2.619\n",
      "Epoch:  0033 D loss:-0.4134 G loss:-2.659\n",
      "Epoch:  0033 D loss:-0.4851 G loss:-2.789\n",
      "Epoch:  0033 D loss:-0.4146 G loss:-2.514\n",
      "Epoch:  0033 D loss:-0.4255 G loss:-2.657\n",
      "Epoch:  0033 D loss:-0.3474 G loss:-2.636\n",
      "Epoch:  0033 D loss:-0.4064 G loss:-2.574\n",
      "Epoch:  0033 D loss:-0.3894 G loss:-2.603\n",
      "Epoch:  0033 D loss:-0.473 G loss:-2.543\n",
      "Epoch:  0033 D loss:-0.471 G loss:-2.479\n",
      "Epoch:  0033 D loss:-0.4127 G loss:-2.576\n",
      "Epoch:  0033 D loss:-0.3861 G loss:-2.638\n",
      "Epoch:  0033 D loss:-0.4835 G loss:-2.932\n",
      "Epoch:  0033 D loss:-0.4893 G loss:-2.774\n",
      "Epoch:  0033 D loss:-0.5401 G loss:-2.521\n",
      "Epoch:  0033 D loss:-0.58 G loss:-2.502\n",
      "Epoch:  0033 D loss:-0.3822 G loss:-2.563\n",
      "Epoch:  0033 D loss:-0.4146 G loss:-2.624\n",
      "Epoch:  0033 D loss:-0.4558 G loss:-2.588\n",
      "Epoch:  0033 D loss:-0.4044 G loss:-2.667\n",
      "Epoch:  0033 D loss:-0.4739 G loss:-2.471\n",
      "Epoch:  0033 D loss:-0.3909 G loss:-2.625\n",
      "Epoch:  0033 D loss:-0.4362 G loss:-2.549\n",
      "Epoch:  0033 D loss:-0.3886 G loss:-2.631\n",
      "Epoch:  0033 D loss:-0.357 G loss:-2.93\n",
      "Epoch:  0033 D loss:-0.4162 G loss:-2.672\n",
      "Epoch:  0033 D loss:-0.4345 G loss:-2.777\n",
      "Epoch:  0033 D loss:-0.445 G loss:-2.763\n",
      "Epoch:  0033 D loss:-0.5106 G loss:-2.801\n",
      "Epoch:  0033 D loss:-0.3783 G loss:-2.826\n",
      "Epoch:  0033 D loss:-0.4014 G loss:-3.079\n",
      "Epoch:  0033 D loss:-0.3994 G loss:-2.959\n",
      "Epoch:  0033 D loss:-0.3934 G loss:-2.729\n",
      "Epoch:  0033 D loss:-0.3836 G loss:-2.762\n",
      "Epoch:  0033 D loss:-0.4242 G loss:-2.504\n",
      "Epoch:  0033 D loss:-0.4324 G loss:-2.426\n",
      "Epoch:  0033 D loss:-0.4401 G loss:-2.506\n",
      "Epoch:  0033 D loss:-0.4495 G loss:-2.595\n",
      "Epoch:  0033 D loss:-0.364 G loss:-2.424\n",
      "Epoch:  0033 D loss:-0.293 G loss:-2.713\n",
      "Epoch:  0033 D loss:-0.303 G loss:-2.867\n",
      "Epoch:  0033 D loss:-0.4025 G loss:-2.815\n",
      "Epoch:  0033 D loss:-0.3995 G loss:-2.635\n",
      "Epoch:  0033 D loss:-0.3486 G loss:-2.702\n",
      "Epoch:  0033 D loss:-0.332 G loss:-2.984\n",
      "Epoch:  0033 D loss:-0.417 G loss:-2.995\n",
      "Epoch:  0033 D loss:-0.3843 G loss:-2.923\n",
      "Epoch:  0033 D loss:-0.3306 G loss:-2.906\n",
      "Epoch:  0033 D loss:-0.4708 G loss:-2.999\n",
      "Epoch:  0033 D loss:-0.4035 G loss:-2.872\n",
      "Epoch:  0033 D loss:-0.4713 G loss:-2.691\n",
      "Epoch:  0033 D loss:-0.422 G loss:-2.826\n",
      "Epoch:  0033 D loss:-0.4386 G loss:-2.792\n",
      "Epoch:  0033 D loss:-0.2207 G loss:-2.898\n",
      "Epoch:  0033 D loss:-0.3785 G loss:-2.717\n",
      "Epoch:  0033 D loss:-0.4196 G loss:-2.645\n",
      "Epoch:  0033 D loss:-0.6135 G loss:-2.638\n",
      "Epoch:  0033 D loss:-0.4089 G loss:-2.711\n",
      "Epoch:  0033 D loss:-0.4601 G loss:-2.608\n",
      "Epoch:  0033 D loss:-0.4358 G loss:-2.437\n",
      "Epoch:  0033 D loss:-0.5427 G loss:-2.552\n",
      "Epoch:  0033 D loss:-0.4314 G loss:-2.665\n",
      "Epoch:  0033 D loss:-0.3816 G loss:-2.743\n",
      "Epoch:  0033 D loss:-0.3868 G loss:-2.803\n",
      "Epoch:  0033 D loss:-0.3453 G loss:-2.735\n",
      "Epoch:  0033 D loss:-0.3692 G loss:-2.871\n",
      "Epoch:  0033 D loss:-0.3967 G loss:-2.84\n",
      "Epoch:  0033 D loss:-0.4811 G loss:-2.917\n",
      "Epoch:  0033 D loss:-0.5697 G loss:-2.695\n",
      "Epoch:  0033 D loss:-0.4677 G loss:-2.645\n",
      "Epoch:  0033 D loss:-0.3714 G loss:-2.43\n",
      "Epoch:  0033 D loss:-0.3437 G loss:-2.526\n",
      "Epoch:  0033 D loss:-0.4696 G loss:-2.428\n",
      "Epoch:  0033 D loss:-0.3576 G loss:-2.74\n",
      "Epoch:  0033 D loss:-0.3088 G loss:-2.603\n",
      "Epoch:  0033 D loss:-0.4355 G loss:-2.591\n",
      "Epoch:  0033 D loss:-0.4323 G loss:-2.596\n",
      "Epoch:  0033 D loss:-0.4091 G loss:-2.459\n",
      "Epoch:  0033 D loss:-0.5106 G loss:-2.733\n",
      "Epoch:  0033 D loss:-0.4679 G loss:-2.784\n",
      "Epoch:  0033 D loss:-0.5635 G loss:-2.573\n",
      "Epoch:  0033 D loss:-0.5579 G loss:-2.621\n",
      "Epoch:  0033 D loss:-0.3358 G loss:-2.713\n",
      "Epoch:  0033 D loss:-0.454 G loss:-2.487\n",
      "Epoch:  0033 D loss:-0.505 G loss:-2.529\n",
      "Epoch:  0033 D loss:-0.4065 G loss:-2.731\n",
      "Epoch:  0033 D loss:-0.3914 G loss:-2.74\n",
      "Epoch:  0033 D loss:-0.4762 G loss:-2.713\n",
      "Epoch:  0033 D loss:-0.4035 G loss:-2.562\n",
      "Epoch:  0033 D loss:-0.4514 G loss:-2.688\n",
      "Epoch:  0033 D loss:-0.5292 G loss:-2.65\n",
      "Epoch:  0033 D loss:-0.4593 G loss:-2.416\n",
      "Epoch:  0033 D loss:-0.4053 G loss:-2.319\n",
      "Epoch:  0033 D loss:-0.5639 G loss:-2.384\n",
      "Epoch:  0033 D loss:-0.4533 G loss:-2.361\n",
      "Epoch:  0033 D loss:-0.4811 G loss:-2.592\n",
      "Epoch:  0033 D loss:-0.5073 G loss:-2.554\n",
      "Epoch:  0033 D loss:-0.4028 G loss:-2.764\n",
      "Epoch:  0033 D loss:-0.4245 G loss:-2.592\n",
      "Epoch:  0033 D loss:-0.3298 G loss:-2.841\n",
      "Epoch:  0033 D loss:-0.5306 G loss:-2.868\n",
      "Epoch:  0033 D loss:-0.3842 G loss:-3.0\n",
      "Epoch:  0033 D loss:-0.3825 G loss:-2.858\n",
      "Epoch:  0033 D loss:-0.5061 G loss:-2.443\n",
      "Epoch:  0033 D loss:-0.504 G loss:-2.59\n",
      "Epoch:  0033 D loss:-0.433 G loss:-2.779\n",
      "Epoch:  0033 D loss:-0.3759 G loss:-2.473\n",
      "Epoch:  0033 D loss:-0.4543 G loss:-2.718\n",
      "Epoch:  0033 D loss:-0.4176 G loss:-2.421\n",
      "Epoch:  0033 D loss:-0.4253 G loss:-2.6\n",
      "Epoch:  0033 D loss:-0.4128 G loss:-2.439\n",
      "Epoch:  0033 D loss:-0.4109 G loss:-2.624\n",
      "Epoch:  0033 D loss:-0.4108 G loss:-2.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0033 D loss:-0.3445 G loss:-2.759\n",
      "Epoch:  0033 D loss:-0.4089 G loss:-2.94\n",
      "Epoch:  0033 D loss:-0.4868 G loss:-2.439\n",
      "Epoch:  0033 D loss:-0.3308 G loss:-2.676\n",
      "Epoch:  0033 D loss:-0.4402 G loss:-2.616\n",
      "Epoch:  0033 D loss:-0.3987 G loss:-2.821\n",
      "Epoch:  0033 D loss:-0.4955 G loss:-2.633\n",
      "Epoch:  0033 D loss:-0.3493 G loss:-2.753\n",
      "Epoch:  0033 D loss:-0.3532 G loss:-2.834\n",
      "Epoch:  0033 D loss:-0.4414 G loss:-2.931\n",
      "Epoch:  0033 D loss:-0.3516 G loss:-2.766\n",
      "Epoch:  0033 D loss:-0.4165 G loss:-2.822\n",
      "Epoch:  0033 D loss:-0.4466 G loss:-2.522\n",
      "Epoch:  0033 D loss:-0.3432 G loss:-2.948\n",
      "Epoch:  0033 D loss:-0.4569 G loss:-2.97\n",
      "Epoch:  0033 D loss:-0.275 G loss:-2.917\n",
      "Epoch:  0033 D loss:-0.4581 G loss:-2.821\n",
      "Epoch:  0033 D loss:-0.4031 G loss:-3.081\n",
      "Epoch:  0033 D loss:-0.3583 G loss:-2.896\n",
      "Epoch:  0033 D loss:-0.3447 G loss:-2.976\n",
      "Epoch:  0033 D loss:-0.3656 G loss:-2.798\n",
      "Epoch:  0033 D loss:-0.2796 G loss:-2.927\n",
      "Epoch:  0033 D loss:-0.4226 G loss:-2.757\n",
      "Epoch:  0033 D loss:-0.5546 G loss:-2.46\n",
      "Epoch:  0033 D loss:-0.4589 G loss:-2.549\n",
      "Epoch:  0033 D loss:-0.3619 G loss:-2.606\n",
      "Epoch:  0033 D loss:-0.3413 G loss:-2.783\n",
      "Epoch:  0033 D loss:-0.4554 G loss:-2.367\n",
      "Epoch:  0033 D loss:-0.3458 G loss:-2.569\n",
      "Epoch:  0033 D loss:-0.4396 G loss:-2.713\n",
      "Epoch:  0033 D loss:-0.3751 G loss:-2.813\n",
      "Epoch:  0033 D loss:-0.4241 G loss:-2.794\n",
      "Epoch:  0033 D loss:-0.4451 G loss:-2.833\n",
      "Epoch:  0033 D loss:-0.3936 G loss:-2.654\n",
      "Epoch:  0033 D loss:-0.4556 G loss:-2.742\n",
      "Epoch:  0033 D loss:-0.5432 G loss:-2.65\n",
      "Epoch:  0033 D loss:-0.5477 G loss:-2.958\n",
      "Epoch:  0033 D loss:-0.4399 G loss:-2.884\n",
      "Epoch:  0033 D loss:-0.4496 G loss:-2.65\n",
      "Epoch:  0033 D loss:-0.4202 G loss:-2.605\n",
      "Epoch:  0033 D loss:-0.421 G loss:-2.416\n",
      "Epoch:  0033 D loss:-0.4653 G loss:-2.569\n",
      "Epoch:  0033 D loss:-0.312 G loss:-2.584\n",
      "Epoch:  0033 D loss:-0.356 G loss:-2.62\n",
      "Epoch:  0033 D loss:-0.3867 G loss:-2.434\n",
      "Epoch:  0033 D loss:-0.4482 G loss:-2.416\n",
      "Epoch:  0033 D loss:-0.4259 G loss:-2.719\n",
      "Epoch:  0033 D loss:-0.3284 G loss:-2.75\n",
      "Epoch:  0033 D loss:-0.4063 G loss:-2.734\n",
      "Epoch:  0033 D loss:-0.5337 G loss:-2.854\n",
      "Epoch:  0033 D loss:-0.5806 G loss:-3.047\n",
      "Epoch:  0033 D loss:-0.4346 G loss:-2.645\n",
      "Epoch:  0033 D loss:-0.3308 G loss:-2.905\n",
      "Epoch:  0033 D loss:-0.4271 G loss:-2.697\n",
      "Epoch:  0033 D loss:-0.3666 G loss:-2.845\n",
      "Epoch:  0033 D loss:-0.4092 G loss:-2.914\n",
      "Epoch:  0033 D loss:-0.393 G loss:-2.537\n",
      "Epoch:  0033 D loss:-0.3755 G loss:-2.753\n",
      "Epoch:  0033 D loss:-0.4498 G loss:-2.659\n",
      "Epoch:  0033 D loss:-0.4585 G loss:-2.516\n",
      "Epoch:  0033 D loss:-0.4864 G loss:-2.515\n",
      "Epoch:  0033 D loss:-0.3111 G loss:-2.925\n",
      "Epoch:  0033 D loss:-0.3809 G loss:-2.896\n",
      "Epoch:  0033 D loss:-0.5087 G loss:-2.815\n",
      "Epoch:  0033 D loss:-0.3419 G loss:-3.033\n",
      "Epoch:  0033 D loss:-0.4005 G loss:-2.971\n",
      "Epoch:  0033 D loss:-0.4643 G loss:-2.945\n",
      "Epoch:  0033 D loss:-0.392 G loss:-2.994\n",
      "Epoch:  0033 D loss:-0.3262 G loss:-2.891\n",
      "Epoch:  0033 D loss:-0.4322 G loss:-2.571\n",
      "Epoch:  0033 D loss:-0.3842 G loss:-2.773\n",
      "Epoch:  0033 D loss:-0.3563 G loss:-2.599\n",
      "Epoch:  0033 D loss:-0.5066 G loss:-2.586\n",
      "Epoch:  0033 D loss:-0.4686 G loss:-2.668\n",
      "Epoch:  0033 D loss:-0.4366 G loss:-2.774\n",
      "Epoch:  0033 D loss:-0.3926 G loss:-2.536\n",
      "Epoch:  0033 D loss:-0.3489 G loss:-2.397\n",
      "Epoch:  0033 D loss:-0.3072 G loss:-2.681\n",
      "Epoch:  0033 D loss:-0.3662 G loss:-2.799\n",
      "Epoch:  0033 D loss:-0.4267 G loss:-2.645\n",
      "Epoch:  0033 D loss:-0.4125 G loss:-2.838\n",
      "Epoch:  0033 D loss:-0.521 G loss:-2.989\n",
      "Epoch:  0033 D loss:-0.372 G loss:-3.103\n",
      "Epoch:  0033 D loss:-0.4937 G loss:-2.691\n",
      "Epoch:  0033 D loss:-0.4269 G loss:-2.858\n",
      "Epoch:  0033 D loss:-0.3681 G loss:-2.991\n",
      "Epoch:  0033 D loss:-0.3795 G loss:-3.056\n",
      "Epoch:  0033 D loss:-0.3681 G loss:-2.91\n",
      "Epoch:  0033 D loss:-0.2745 G loss:-2.707\n",
      "Epoch:  0033 D loss:-0.2839 G loss:-2.714\n",
      "Epoch:  0033 D loss:-0.4881 G loss:-2.94\n",
      "Epoch:  0033 D loss:-0.4462 G loss:-2.751\n",
      "Epoch:  0033 D loss:-0.3582 G loss:-2.691\n",
      "Epoch:  0033 D loss:-0.335 G loss:-2.857\n",
      "Epoch:  0033 D loss:-0.3855 G loss:-2.901\n",
      "Epoch:  0033 D loss:-0.3865 G loss:-2.621\n",
      "Epoch:  0033 D loss:-0.4433 G loss:-2.43\n",
      "Epoch:  0033 D loss:-0.4524 G loss:-2.754\n",
      "Epoch:  0033 D loss:-0.4334 G loss:-2.69\n",
      "Epoch:  0033 D loss:-0.4878 G loss:-2.508\n",
      "Epoch:  0033 D loss:-0.4764 G loss:-2.597\n",
      "Epoch:  0033 D loss:-0.3542 G loss:-2.804\n",
      "Epoch:  0033 D loss:-0.3921 G loss:-2.842\n",
      "Epoch:  0033 D loss:-0.3578 G loss:-2.571\n",
      "Epoch:  0033 D loss:-0.4592 G loss:-2.816\n",
      "Epoch:  0033 D loss:-0.3999 G loss:-2.727\n",
      "Epoch:  0033 D loss:-0.3871 G loss:-2.616\n",
      "Epoch:  0033 D loss:-0.3949 G loss:-2.679\n",
      "Epoch:  0033 D loss:-0.4153 G loss:-2.64\n",
      "Epoch:  0033 D loss:-0.4155 G loss:-2.812\n",
      "Epoch:  0033 D loss:-0.3914 G loss:-2.729\n",
      "Epoch:  0033 D loss:-0.5419 G loss:-2.583\n",
      "Epoch:  0033 D loss:-0.4161 G loss:-2.708\n",
      "Epoch:  0033 D loss:-0.3519 G loss:-2.924\n",
      "Epoch:  0033 D loss:-0.4018 G loss:-2.819\n",
      "Epoch:  0033 D loss:-0.4429 G loss:-2.642\n",
      "Epoch:  0033 D loss:-0.5056 G loss:-2.724\n",
      "Epoch:  0033 D loss:-0.4926 G loss:-2.6\n",
      "Epoch:  0033 D loss:-0.3767 G loss:-2.737\n",
      "Epoch:  0033 D loss:-0.4414 G loss:-2.743\n",
      "Epoch:  0033 D loss:-0.3773 G loss:-2.621\n",
      "Epoch:  0033 D loss:-0.4294 G loss:-2.701\n",
      "Epoch:  0033 D loss:-0.3997 G loss:-2.86\n",
      "Epoch:  0033 D loss:-0.6414 G loss:-2.593\n",
      "Epoch:  0033 D loss:-0.4936 G loss:-2.727\n",
      "Epoch:  0033 D loss:-0.3799 G loss:-2.629\n",
      "Epoch:  0033 D loss:-0.4164 G loss:-2.5\n",
      "Epoch:  0033 D loss:-0.6795 G loss:-2.305\n",
      "Epoch:  0033 D loss:-0.3673 G loss:-2.619\n",
      "Epoch:  0033 D loss:-0.3335 G loss:-2.653\n",
      "Epoch:  0033 D loss:-0.3873 G loss:-2.751\n",
      "Epoch:  0033 D loss:-0.4298 G loss:-2.729\n",
      "Epoch:  0033 D loss:-0.4063 G loss:-2.669\n",
      "Epoch:  0033 D loss:-0.3303 G loss:-2.871\n",
      "Epoch:  0033 D loss:-0.4755 G loss:-2.98\n",
      "Epoch:  0033 D loss:-0.3737 G loss:-2.692\n",
      "Epoch:  0033 D loss:-0.4766 G loss:-3.046\n",
      "Epoch:  0033 D loss:-0.3755 G loss:-2.908\n",
      "Epoch:  0033 D loss:-0.4983 G loss:-2.931\n",
      "Epoch:  0033 D loss:-0.4078 G loss:-2.796\n",
      "Epoch:  0033 D loss:-0.5595 G loss:-2.513\n",
      "Epoch:  0033 D loss:-0.526 G loss:-2.484\n",
      "Epoch:  0033 D loss:-0.4656 G loss:-2.475\n",
      "Epoch:  0033 D loss:-0.5527 G loss:-2.395\n",
      "Epoch:  0033 D loss:-0.4006 G loss:-2.658\n",
      "Epoch:  0033 D loss:-0.4731 G loss:-2.404\n",
      "Epoch:  0033 D loss:-0.3501 G loss:-2.702\n",
      "Epoch:  0033 D loss:-0.4069 G loss:-2.762\n",
      "Epoch:  0033 D loss:-0.614 G loss:-2.681\n",
      "Epoch:  0033 D loss:-0.386 G loss:-2.782\n",
      "Epoch:  0033 D loss:-0.4462 G loss:-2.722\n",
      "Epoch:  0033 D loss:-0.5096 G loss:-2.594\n",
      "Epoch:  0033 D loss:-0.4702 G loss:-2.667\n",
      "Epoch:  0033 D loss:-0.4902 G loss:-2.613\n",
      "Epoch:  0033 D loss:-0.4165 G loss:-2.588\n",
      "Epoch:  0033 D loss:-0.4506 G loss:-2.893\n",
      "Epoch:  0033 D loss:-0.3939 G loss:-2.577\n",
      "Epoch:  0033 D loss:-0.373 G loss:-2.82\n",
      "Epoch:  0033 D loss:-0.5353 G loss:-2.443\n",
      "Epoch:  0033 D loss:-0.3805 G loss:-2.623\n",
      "Epoch:  0033 D loss:-0.539 G loss:-2.628\n",
      "Epoch:  0033 D loss:-0.545 G loss:-2.463\n",
      "Epoch:  0033 D loss:-0.3635 G loss:-2.664\n",
      "Epoch:  0033 D loss:-0.4228 G loss:-2.753\n",
      "Epoch:  0033 D loss:-0.3108 G loss:-3.142\n",
      "Epoch:  0033 D loss:-0.3812 G loss:-2.926\n",
      "Epoch:  0033 D loss:-0.4776 G loss:-2.87\n",
      "Epoch:  0033 D loss:-0.3778 G loss:-3.088\n",
      "Epoch:  0033 D loss:-0.3347 G loss:-2.936\n",
      "Epoch:  0033 D loss:-0.3613 G loss:-2.678\n",
      "Epoch:  0033 D loss:-0.3815 G loss:-2.891\n",
      "Epoch:  0033 D loss:-0.4252 G loss:-2.793\n",
      "Epoch:  0033 D loss:-0.4706 G loss:-2.725\n",
      "Epoch:  0033 D loss:-0.4105 G loss:-2.614\n",
      "Epoch:  0033 D loss:-0.4388 G loss:-2.737\n",
      "Epoch:  0033 D loss:-0.44 G loss:-2.589\n",
      "Epoch:  0033 D loss:-0.3857 G loss:-2.563\n",
      "Epoch:  0033 D loss:-0.468 G loss:-2.735\n",
      "Epoch:  0033 D loss:-0.5145 G loss:-2.844\n",
      "Epoch:  0033 D loss:-0.2927 G loss:-3.096\n",
      "Epoch:  0033 D loss:-0.4394 G loss:-2.757\n",
      "Epoch:  0033 D loss:-0.5564 G loss:-2.464\n",
      "Epoch:  0033 D loss:-0.4232 G loss:-2.584\n",
      "Epoch:  0033 D loss:-0.3414 G loss:-2.752\n",
      "Epoch:  0033 D loss:-0.4107 G loss:-2.643\n",
      "Epoch:  0033 D loss:-0.3954 G loss:-2.689\n",
      "Epoch:  0033 D loss:-0.3746 G loss:-2.625\n",
      "Epoch:  0033 D loss:-0.4432 G loss:-2.641\n",
      "Epoch:  0033 D loss:-0.3436 G loss:-2.776\n",
      "Epoch:  0033 D loss:-0.3949 G loss:-2.765\n",
      "Epoch:  0033 D loss:-0.4085 G loss:-2.731\n",
      "Epoch:  0033 D loss:-0.3288 G loss:-2.641\n",
      "Epoch:  0033 D loss:-0.3957 G loss:-2.77\n",
      "Epoch:  0033 D loss:-0.3991 G loss:-2.837\n",
      "Epoch:  0033 D loss:-0.4965 G loss:-2.875\n",
      "Epoch:  0033 D loss:-0.4173 G loss:-2.876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0033 D loss:-0.4017 G loss:-2.727\n",
      "Epoch:  0033 D loss:-0.4371 G loss:-2.79\n",
      "Epoch:  0033 D loss:-0.4259 G loss:-2.817\n",
      "Epoch:  0033 D loss:-0.3435 G loss:-2.93\n",
      "Epoch:  0033 D loss:-0.3547 G loss:-2.686\n",
      "Epoch:  0033 D loss:-0.404 G loss:-2.518\n",
      "Epoch:  0033 D loss:-0.5282 G loss:-2.615\n",
      "Epoch:  0033 D loss:-0.4492 G loss:-2.827\n",
      "Epoch:  0033 D loss:-0.3544 G loss:-2.88\n",
      "Epoch:  0033 D loss:-0.4164 G loss:-2.892\n",
      "Epoch:  0033 D loss:-0.3832 G loss:-2.761\n",
      "Epoch:  0033 D loss:-0.4214 G loss:-2.982\n",
      "Epoch:  0033 D loss:-0.4777 G loss:-2.779\n",
      "Epoch:  0033 D loss:-0.3866 G loss:-2.6\n",
      "Epoch:  0033 D loss:-0.4314 G loss:-2.873\n",
      "Epoch:  0033 D loss:-0.2776 G loss:-3.065\n",
      "Epoch:  0033 D loss:-0.3967 G loss:-2.789\n",
      "Epoch:  0033 D loss:-0.38 G loss:-2.945\n",
      "Epoch:  0033 D loss:-0.4769 G loss:-2.954\n",
      "Epoch:  0033 D loss:-0.4544 G loss:-2.855\n",
      "Epoch:  0033 D loss:-0.3476 G loss:-2.77\n",
      "Epoch:  0033 D loss:-0.5335 G loss:-2.916\n",
      "Epoch:  0033 D loss:-0.5238 G loss:-2.559\n",
      "Epoch:  0033 D loss:-0.3322 G loss:-2.602\n",
      "Epoch:  0033 D loss:-0.4017 G loss:-2.823\n",
      "Epoch:  0033 D loss:-0.4022 G loss:-2.697\n",
      "Epoch:  0033 D loss:-0.3867 G loss:-2.81\n",
      "Epoch:  0033 D loss:-0.4223 G loss:-2.614\n",
      "Epoch:  0033 D loss:-0.4347 G loss:-2.785\n",
      "Epoch:  0033 D loss:-0.513 G loss:-2.608\n",
      "Epoch:  0033 D loss:-0.4187 G loss:-2.94\n",
      "Epoch:  0033 D loss:-0.3178 G loss:-2.829\n",
      "Epoch:  0033 D loss:-0.3404 G loss:-2.853\n",
      "Epoch:  0033 D loss:-0.499 G loss:-2.873\n",
      "Epoch:  0034 D loss:-0.3235 G loss:-2.934\n",
      "Epoch:  0034 D loss:-0.3925 G loss:-2.829\n",
      "Epoch:  0034 D loss:-0.4932 G loss:-2.917\n",
      "Epoch:  0034 D loss:-0.4861 G loss:-2.952\n",
      "Epoch:  0034 D loss:-0.4866 G loss:-2.602\n",
      "Epoch:  0034 D loss:-0.4565 G loss:-2.785\n",
      "Epoch:  0034 D loss:-0.5002 G loss:-2.26\n",
      "Epoch:  0034 D loss:-0.4711 G loss:-2.697\n",
      "Epoch:  0034 D loss:-0.4303 G loss:-2.378\n",
      "Epoch:  0034 D loss:-0.4717 G loss:-2.651\n",
      "Epoch:  0034 D loss:-0.3878 G loss:-2.673\n",
      "Epoch:  0034 D loss:-0.5557 G loss:-2.6\n",
      "Epoch:  0034 D loss:-0.4889 G loss:-2.676\n",
      "Epoch:  0034 D loss:-0.3486 G loss:-2.651\n",
      "Epoch:  0034 D loss:-0.3695 G loss:-2.663\n",
      "Epoch:  0034 D loss:-0.5651 G loss:-2.683\n",
      "Epoch:  0034 D loss:-0.3801 G loss:-2.756\n",
      "Epoch:  0034 D loss:-0.3775 G loss:-2.659\n",
      "Epoch:  0034 D loss:-0.3948 G loss:-2.832\n",
      "Epoch:  0034 D loss:-0.6091 G loss:-2.675\n",
      "Epoch:  0034 D loss:-0.4356 G loss:-2.926\n",
      "Epoch:  0034 D loss:-0.3594 G loss:-2.86\n",
      "Epoch:  0034 D loss:-0.3218 G loss:-2.788\n",
      "Epoch:  0034 D loss:-0.3139 G loss:-2.715\n",
      "Epoch:  0034 D loss:-0.3684 G loss:-2.713\n",
      "Epoch:  0034 D loss:-0.3483 G loss:-2.717\n",
      "Epoch:  0034 D loss:-0.5279 G loss:-2.629\n",
      "Epoch:  0034 D loss:-0.515 G loss:-2.721\n",
      "Epoch:  0034 D loss:-0.4047 G loss:-2.577\n",
      "Epoch:  0034 D loss:-0.4949 G loss:-2.616\n",
      "Epoch:  0034 D loss:-0.652 G loss:-2.417\n",
      "Epoch:  0034 D loss:-0.517 G loss:-2.397\n",
      "Epoch:  0034 D loss:-0.5173 G loss:-2.648\n",
      "Epoch:  0034 D loss:-0.4721 G loss:-2.832\n",
      "Epoch:  0034 D loss:-0.3995 G loss:-2.73\n",
      "Epoch:  0034 D loss:-0.5228 G loss:-2.781\n",
      "Epoch:  0034 D loss:-0.4688 G loss:-2.807\n",
      "Epoch:  0034 D loss:-0.3633 G loss:-2.602\n",
      "Epoch:  0034 D loss:-0.4986 G loss:-2.726\n",
      "Epoch:  0034 D loss:-0.5323 G loss:-2.595\n",
      "Epoch:  0034 D loss:-0.4759 G loss:-2.65\n",
      "Epoch:  0034 D loss:-0.5308 G loss:-2.433\n",
      "Epoch:  0034 D loss:-0.399 G loss:-2.68\n",
      "Epoch:  0034 D loss:-0.3071 G loss:-2.926\n",
      "Epoch:  0034 D loss:-0.5542 G loss:-2.585\n",
      "Epoch:  0034 D loss:-0.3375 G loss:-2.635\n",
      "Epoch:  0034 D loss:-0.5739 G loss:-2.577\n",
      "Epoch:  0034 D loss:-0.567 G loss:-2.249\n",
      "Epoch:  0034 D loss:-0.4965 G loss:-2.56\n",
      "Epoch:  0034 D loss:-0.3465 G loss:-2.515\n",
      "Epoch:  0034 D loss:-0.3868 G loss:-2.909\n",
      "Epoch:  0034 D loss:-0.5107 G loss:-2.757\n",
      "Epoch:  0034 D loss:-0.3992 G loss:-2.892\n",
      "Epoch:  0034 D loss:-0.4687 G loss:-2.791\n",
      "Epoch:  0034 D loss:-0.5266 G loss:-2.814\n",
      "Epoch:  0034 D loss:-0.477 G loss:-2.725\n",
      "Epoch:  0034 D loss:-0.4147 G loss:-2.615\n",
      "Epoch:  0034 D loss:-0.3103 G loss:-2.842\n",
      "Epoch:  0034 D loss:-0.4328 G loss:-2.525\n",
      "Epoch:  0034 D loss:-0.4997 G loss:-2.5\n",
      "Epoch:  0034 D loss:-0.4581 G loss:-2.645\n",
      "Epoch:  0034 D loss:-0.5887 G loss:-2.605\n",
      "Epoch:  0034 D loss:-0.4494 G loss:-2.77\n",
      "Epoch:  0034 D loss:-0.4252 G loss:-2.883\n",
      "Epoch:  0034 D loss:-0.4106 G loss:-2.769\n",
      "Epoch:  0034 D loss:-0.3997 G loss:-2.774\n",
      "Epoch:  0034 D loss:-0.4297 G loss:-2.944\n",
      "Epoch:  0034 D loss:-0.4588 G loss:-2.505\n",
      "Epoch:  0034 D loss:-0.3982 G loss:-2.739\n",
      "Epoch:  0034 D loss:-0.4138 G loss:-2.819\n",
      "Epoch:  0034 D loss:-0.4685 G loss:-2.702\n",
      "Epoch:  0034 D loss:-0.47 G loss:-2.834\n",
      "Epoch:  0034 D loss:-0.4424 G loss:-2.844\n",
      "Epoch:  0034 D loss:-0.4236 G loss:-2.623\n",
      "Epoch:  0034 D loss:-0.3092 G loss:-2.996\n",
      "Epoch:  0034 D loss:-0.3566 G loss:-2.793\n",
      "Epoch:  0034 D loss:-0.3791 G loss:-2.79\n",
      "Epoch:  0034 D loss:-0.4152 G loss:-2.68\n",
      "Epoch:  0034 D loss:-0.5739 G loss:-2.55\n",
      "Epoch:  0034 D loss:-0.3509 G loss:-3.007\n",
      "Epoch:  0034 D loss:-0.5252 G loss:-2.613\n",
      "Epoch:  0034 D loss:-0.4753 G loss:-2.611\n",
      "Epoch:  0034 D loss:-0.4828 G loss:-2.421\n",
      "Epoch:  0034 D loss:-0.4261 G loss:-2.766\n",
      "Epoch:  0034 D loss:-0.5211 G loss:-2.653\n",
      "Epoch:  0034 D loss:-0.4003 G loss:-2.847\n",
      "Epoch:  0034 D loss:-0.496 G loss:-2.874\n",
      "Epoch:  0034 D loss:-0.3801 G loss:-2.919\n",
      "Epoch:  0034 D loss:-0.3554 G loss:-2.934\n",
      "Epoch:  0034 D loss:-0.3552 G loss:-2.737\n",
      "Epoch:  0034 D loss:-0.3108 G loss:-2.731\n",
      "Epoch:  0034 D loss:-0.4988 G loss:-2.748\n",
      "Epoch:  0034 D loss:-0.4814 G loss:-2.498\n",
      "Epoch:  0034 D loss:-0.3124 G loss:-2.961\n",
      "Epoch:  0034 D loss:-0.5337 G loss:-2.611\n",
      "Epoch:  0034 D loss:-0.433 G loss:-2.56\n",
      "Epoch:  0034 D loss:-0.4045 G loss:-2.561\n",
      "Epoch:  0034 D loss:-0.4806 G loss:-2.876\n",
      "Epoch:  0034 D loss:-0.3943 G loss:-2.726\n",
      "Epoch:  0034 D loss:-0.481 G loss:-2.677\n",
      "Epoch:  0034 D loss:-0.4442 G loss:-2.753\n",
      "Epoch:  0034 D loss:-0.3326 G loss:-2.74\n",
      "Epoch:  0034 D loss:-0.4017 G loss:-2.742\n",
      "Epoch:  0034 D loss:-0.5544 G loss:-2.6\n",
      "Epoch:  0034 D loss:-0.4707 G loss:-2.721\n",
      "Epoch:  0034 D loss:-0.484 G loss:-2.661\n",
      "Epoch:  0034 D loss:-0.355 G loss:-2.531\n",
      "Epoch:  0034 D loss:-0.4785 G loss:-2.531\n",
      "Epoch:  0034 D loss:-0.5507 G loss:-2.766\n",
      "Epoch:  0034 D loss:-0.5272 G loss:-2.713\n",
      "Epoch:  0034 D loss:-0.344 G loss:-2.736\n",
      "Epoch:  0034 D loss:-0.5281 G loss:-2.545\n",
      "Epoch:  0034 D loss:-0.5269 G loss:-2.426\n",
      "Epoch:  0034 D loss:-0.434 G loss:-2.798\n",
      "Epoch:  0034 D loss:-0.441 G loss:-2.98\n",
      "Epoch:  0034 D loss:-0.4643 G loss:-3.071\n",
      "Epoch:  0034 D loss:-0.3502 G loss:-2.769\n",
      "Epoch:  0034 D loss:-0.3971 G loss:-3.03\n",
      "Epoch:  0034 D loss:-0.4073 G loss:-2.96\n",
      "Epoch:  0034 D loss:-0.3671 G loss:-2.994\n",
      "Epoch:  0034 D loss:-0.5454 G loss:-2.921\n",
      "Epoch:  0034 D loss:-0.4777 G loss:-2.874\n",
      "Epoch:  0034 D loss:-0.3629 G loss:-2.688\n",
      "Epoch:  0034 D loss:-0.3953 G loss:-2.58\n",
      "Epoch:  0034 D loss:-0.3765 G loss:-2.629\n",
      "Epoch:  0034 D loss:-0.4978 G loss:-2.652\n",
      "Epoch:  0034 D loss:-0.4615 G loss:-2.698\n",
      "Epoch:  0034 D loss:-0.4047 G loss:-2.556\n",
      "Epoch:  0034 D loss:-0.4693 G loss:-2.411\n",
      "Epoch:  0034 D loss:-0.4021 G loss:-2.508\n",
      "Epoch:  0034 D loss:-0.3969 G loss:-2.699\n",
      "Epoch:  0034 D loss:-0.454 G loss:-2.459\n",
      "Epoch:  0034 D loss:-0.3372 G loss:-2.826\n",
      "Epoch:  0034 D loss:-0.4062 G loss:-2.625\n",
      "Epoch:  0034 D loss:-0.454 G loss:-2.717\n",
      "Epoch:  0034 D loss:-0.4258 G loss:-2.729\n",
      "Epoch:  0034 D loss:-0.4599 G loss:-2.618\n",
      "Epoch:  0034 D loss:-0.4045 G loss:-2.8\n",
      "Epoch:  0034 D loss:-0.3725 G loss:-2.79\n",
      "Epoch:  0034 D loss:-0.397 G loss:-2.737\n",
      "Epoch:  0034 D loss:-0.472 G loss:-2.537\n",
      "Epoch:  0034 D loss:-0.4998 G loss:-2.491\n",
      "Epoch:  0034 D loss:-0.4908 G loss:-2.501\n",
      "Epoch:  0034 D loss:-0.4119 G loss:-2.873\n",
      "Epoch:  0034 D loss:-0.3378 G loss:-2.695\n",
      "Epoch:  0034 D loss:-0.4004 G loss:-2.599\n",
      "Epoch:  0034 D loss:-0.3229 G loss:-2.676\n",
      "Epoch:  0034 D loss:-0.5169 G loss:-2.74\n",
      "Epoch:  0034 D loss:-0.5096 G loss:-2.788\n",
      "Epoch:  0034 D loss:-0.2999 G loss:-2.727\n",
      "Epoch:  0034 D loss:-0.3827 G loss:-2.846\n",
      "Epoch:  0034 D loss:-0.4851 G loss:-2.828\n",
      "Epoch:  0034 D loss:-0.2929 G loss:-2.878\n",
      "Epoch:  0034 D loss:-0.3854 G loss:-2.637\n",
      "Epoch:  0034 D loss:-0.4097 G loss:-2.805\n",
      "Epoch:  0034 D loss:-0.488 G loss:-2.508\n",
      "Epoch:  0034 D loss:-0.3902 G loss:-2.649\n",
      "Epoch:  0034 D loss:-0.4604 G loss:-2.644\n",
      "Epoch:  0034 D loss:-0.3538 G loss:-2.834\n",
      "Epoch:  0034 D loss:-0.3198 G loss:-2.836\n",
      "Epoch:  0034 D loss:-0.3882 G loss:-2.921\n",
      "Epoch:  0034 D loss:-0.4863 G loss:-2.704\n",
      "Epoch:  0034 D loss:-0.3445 G loss:-2.715\n",
      "Epoch:  0034 D loss:-0.3784 G loss:-2.977\n",
      "Epoch:  0034 D loss:-0.5206 G loss:-2.822\n",
      "Epoch:  0034 D loss:-0.459 G loss:-2.672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0034 D loss:-0.4925 G loss:-2.77\n",
      "Epoch:  0034 D loss:-0.4385 G loss:-2.833\n",
      "Epoch:  0034 D loss:-0.4539 G loss:-2.465\n",
      "Epoch:  0034 D loss:-0.4716 G loss:-2.761\n",
      "Epoch:  0034 D loss:-0.3623 G loss:-2.754\n",
      "Epoch:  0034 D loss:-0.4828 G loss:-2.526\n",
      "Epoch:  0034 D loss:-0.4248 G loss:-2.641\n",
      "Epoch:  0034 D loss:-0.5124 G loss:-2.524\n",
      "Epoch:  0034 D loss:-0.3604 G loss:-2.653\n",
      "Epoch:  0034 D loss:-0.5416 G loss:-2.76\n",
      "Epoch:  0034 D loss:-0.3717 G loss:-2.994\n",
      "Epoch:  0034 D loss:-0.5525 G loss:-3.021\n",
      "Epoch:  0034 D loss:-0.459 G loss:-3.044\n",
      "Epoch:  0034 D loss:-0.613 G loss:-2.688\n",
      "Epoch:  0034 D loss:-0.5239 G loss:-2.529\n",
      "Epoch:  0034 D loss:-0.399 G loss:-2.577\n",
      "Epoch:  0034 D loss:-0.4749 G loss:-2.525\n",
      "Epoch:  0034 D loss:-0.3633 G loss:-2.527\n",
      "Epoch:  0034 D loss:-0.565 G loss:-2.623\n",
      "Epoch:  0034 D loss:-0.5383 G loss:-2.421\n",
      "Epoch:  0034 D loss:-0.5469 G loss:-2.336\n",
      "Epoch:  0034 D loss:-0.5052 G loss:-2.201\n",
      "Epoch:  0034 D loss:-0.4689 G loss:-2.503\n",
      "Epoch:  0034 D loss:-0.4658 G loss:-2.467\n",
      "Epoch:  0034 D loss:-0.4821 G loss:-2.608\n",
      "Epoch:  0034 D loss:-0.459 G loss:-2.75\n",
      "Epoch:  0034 D loss:-0.3516 G loss:-2.777\n",
      "Epoch:  0034 D loss:-0.4452 G loss:-2.588\n",
      "Epoch:  0034 D loss:-0.5846 G loss:-2.581\n",
      "Epoch:  0034 D loss:-0.34 G loss:-2.937\n",
      "Epoch:  0034 D loss:-0.4962 G loss:-2.514\n",
      "Epoch:  0034 D loss:-0.5119 G loss:-2.908\n",
      "Epoch:  0034 D loss:-0.5286 G loss:-2.717\n",
      "Epoch:  0034 D loss:-0.5102 G loss:-2.348\n",
      "Epoch:  0034 D loss:-0.5123 G loss:-2.458\n",
      "Epoch:  0034 D loss:-0.6598 G loss:-2.377\n",
      "Epoch:  0034 D loss:-0.5451 G loss:-2.557\n",
      "Epoch:  0034 D loss:-0.5895 G loss:-2.226\n",
      "Epoch:  0034 D loss:-0.4893 G loss:-2.521\n",
      "Epoch:  0034 D loss:-0.4983 G loss:-2.368\n",
      "Epoch:  0034 D loss:-0.4676 G loss:-2.332\n",
      "Epoch:  0034 D loss:-0.543 G loss:-2.368\n",
      "Epoch:  0034 D loss:-0.4517 G loss:-2.637\n",
      "Epoch:  0034 D loss:-0.4164 G loss:-2.463\n",
      "Epoch:  0034 D loss:-0.374 G loss:-2.661\n",
      "Epoch:  0034 D loss:-0.4267 G loss:-2.834\n",
      "Epoch:  0034 D loss:-0.6052 G loss:-2.685\n",
      "Epoch:  0034 D loss:-0.4634 G loss:-2.784\n",
      "Epoch:  0034 D loss:-0.558 G loss:-2.768\n",
      "Epoch:  0034 D loss:-0.5689 G loss:-2.637\n",
      "Epoch:  0034 D loss:-0.4827 G loss:-2.406\n",
      "Epoch:  0034 D loss:-0.4511 G loss:-2.693\n",
      "Epoch:  0034 D loss:-0.5587 G loss:-2.576\n",
      "Epoch:  0034 D loss:-0.7739 G loss:-2.193\n",
      "Epoch:  0034 D loss:-0.4879 G loss:-2.394\n",
      "Epoch:  0034 D loss:-0.4655 G loss:-2.554\n",
      "Epoch:  0034 D loss:-0.4292 G loss:-2.683\n",
      "Epoch:  0034 D loss:-0.5199 G loss:-2.519\n",
      "Epoch:  0034 D loss:-0.5795 G loss:-2.474\n",
      "Epoch:  0034 D loss:-0.6177 G loss:-2.548\n",
      "Epoch:  0034 D loss:-0.4451 G loss:-2.699\n",
      "Epoch:  0034 D loss:-0.5266 G loss:-2.704\n",
      "Epoch:  0034 D loss:-0.4735 G loss:-2.71\n",
      "Epoch:  0034 D loss:-0.6515 G loss:-2.72\n",
      "Epoch:  0034 D loss:-0.4443 G loss:-2.568\n",
      "Epoch:  0034 D loss:-0.5562 G loss:-2.514\n",
      "Epoch:  0034 D loss:-0.5083 G loss:-2.516\n",
      "Epoch:  0034 D loss:-0.4923 G loss:-2.585\n",
      "Epoch:  0034 D loss:-0.6131 G loss:-2.328\n",
      "Epoch:  0034 D loss:-0.5803 G loss:-2.453\n",
      "Epoch:  0034 D loss:-0.4325 G loss:-2.582\n",
      "Epoch:  0034 D loss:-0.4677 G loss:-2.448\n",
      "Epoch:  0034 D loss:-0.4715 G loss:-2.481\n",
      "Epoch:  0034 D loss:-0.4556 G loss:-2.721\n",
      "Epoch:  0034 D loss:-0.5846 G loss:-2.532\n",
      "Epoch:  0034 D loss:-0.5875 G loss:-2.672\n",
      "Epoch:  0034 D loss:-0.4452 G loss:-2.766\n",
      "Epoch:  0034 D loss:-0.4629 G loss:-2.813\n",
      "Epoch:  0034 D loss:-0.508 G loss:-2.734\n",
      "Epoch:  0034 D loss:-0.5641 G loss:-2.561\n",
      "Epoch:  0034 D loss:-0.5322 G loss:-2.436\n",
      "Epoch:  0034 D loss:-0.388 G loss:-2.714\n",
      "Epoch:  0034 D loss:-0.4631 G loss:-2.409\n",
      "Epoch:  0034 D loss:-0.4674 G loss:-2.507\n",
      "Epoch:  0034 D loss:-0.4097 G loss:-2.801\n",
      "Epoch:  0034 D loss:-0.4778 G loss:-2.513\n",
      "Epoch:  0034 D loss:-0.4962 G loss:-2.504\n",
      "Epoch:  0034 D loss:-0.4481 G loss:-2.524\n",
      "Epoch:  0034 D loss:-0.3679 G loss:-2.533\n",
      "Epoch:  0034 D loss:-0.2799 G loss:-2.666\n",
      "Epoch:  0034 D loss:-0.4156 G loss:-2.884\n",
      "Epoch:  0034 D loss:-0.3904 G loss:-2.605\n",
      "Epoch:  0034 D loss:-0.4255 G loss:-2.829\n",
      "Epoch:  0034 D loss:-0.3908 G loss:-2.874\n",
      "Epoch:  0034 D loss:-0.4524 G loss:-2.728\n",
      "Epoch:  0034 D loss:-0.5035 G loss:-2.828\n",
      "Epoch:  0034 D loss:-0.5365 G loss:-2.623\n",
      "Epoch:  0034 D loss:-0.4567 G loss:-2.925\n",
      "Epoch:  0034 D loss:-0.3545 G loss:-2.687\n",
      "Epoch:  0034 D loss:-0.6354 G loss:-2.903\n",
      "Epoch:  0034 D loss:-0.3653 G loss:-2.752\n",
      "Epoch:  0034 D loss:-0.5518 G loss:-2.674\n",
      "Epoch:  0034 D loss:-0.5679 G loss:-2.531\n",
      "Epoch:  0034 D loss:-0.4676 G loss:-2.475\n",
      "Epoch:  0034 D loss:-0.4475 G loss:-2.635\n",
      "Epoch:  0034 D loss:-0.4731 G loss:-2.695\n",
      "Epoch:  0034 D loss:-0.5516 G loss:-2.277\n",
      "Epoch:  0034 D loss:-0.4266 G loss:-2.633\n",
      "Epoch:  0034 D loss:-0.4043 G loss:-2.678\n",
      "Epoch:  0034 D loss:-0.4385 G loss:-2.515\n",
      "Epoch:  0034 D loss:-0.4151 G loss:-2.712\n",
      "Epoch:  0034 D loss:-0.6056 G loss:-2.625\n",
      "Epoch:  0034 D loss:-0.4435 G loss:-2.712\n",
      "Epoch:  0034 D loss:-0.4325 G loss:-2.919\n",
      "Epoch:  0034 D loss:-0.3161 G loss:-3.208\n",
      "Epoch:  0034 D loss:-0.3916 G loss:-2.963\n",
      "Epoch:  0034 D loss:-0.4425 G loss:-3.153\n",
      "Epoch:  0034 D loss:-0.412 G loss:-2.805\n",
      "Epoch:  0034 D loss:-0.4334 G loss:-2.836\n",
      "Epoch:  0034 D loss:-0.3059 G loss:-2.862\n",
      "Epoch:  0034 D loss:-0.3833 G loss:-2.914\n",
      "Epoch:  0034 D loss:-0.3893 G loss:-2.754\n",
      "Epoch:  0034 D loss:-0.4642 G loss:-2.567\n",
      "Epoch:  0034 D loss:-0.406 G loss:-2.676\n",
      "Epoch:  0034 D loss:-0.4223 G loss:-2.701\n",
      "Epoch:  0034 D loss:-0.4049 G loss:-2.718\n",
      "Epoch:  0034 D loss:-0.4041 G loss:-2.613\n",
      "Epoch:  0034 D loss:-0.3962 G loss:-2.782\n",
      "Epoch:  0034 D loss:-0.3983 G loss:-2.952\n",
      "Epoch:  0034 D loss:-0.3883 G loss:-2.69\n",
      "Epoch:  0034 D loss:-0.3883 G loss:-2.638\n",
      "Epoch:  0034 D loss:-0.3743 G loss:-2.713\n",
      "Epoch:  0034 D loss:-0.3961 G loss:-2.611\n",
      "Epoch:  0034 D loss:-0.279 G loss:-3.138\n",
      "Epoch:  0034 D loss:-0.4869 G loss:-2.782\n",
      "Epoch:  0034 D loss:-0.4332 G loss:-2.661\n",
      "Epoch:  0034 D loss:-0.3747 G loss:-2.944\n",
      "Epoch:  0034 D loss:-0.4114 G loss:-2.745\n",
      "Epoch:  0034 D loss:-0.3658 G loss:-2.809\n",
      "Epoch:  0034 D loss:-0.4203 G loss:-2.925\n",
      "Epoch:  0034 D loss:-0.4555 G loss:-3.219\n",
      "Epoch:  0034 D loss:-0.4941 G loss:-3.007\n",
      "Epoch:  0034 D loss:-0.3891 G loss:-3.243\n",
      "Epoch:  0034 D loss:-0.3986 G loss:-3.054\n",
      "Epoch:  0034 D loss:-0.3762 G loss:-2.977\n",
      "Epoch:  0034 D loss:-0.4269 G loss:-2.803\n",
      "Epoch:  0034 D loss:-0.4206 G loss:-2.831\n",
      "Epoch:  0034 D loss:-0.5081 G loss:-2.511\n",
      "Epoch:  0034 D loss:-0.3423 G loss:-2.746\n",
      "Epoch:  0034 D loss:-0.4099 G loss:-2.455\n",
      "Epoch:  0034 D loss:-0.4356 G loss:-2.469\n",
      "Epoch:  0034 D loss:-0.3724 G loss:-2.391\n",
      "Epoch:  0034 D loss:-0.3741 G loss:-2.874\n",
      "Epoch:  0034 D loss:-0.4053 G loss:-2.686\n",
      "Epoch:  0034 D loss:-0.5127 G loss:-2.699\n",
      "Epoch:  0034 D loss:-0.5466 G loss:-2.615\n",
      "Epoch:  0034 D loss:-0.3759 G loss:-2.673\n",
      "Epoch:  0034 D loss:-0.3159 G loss:-3.009\n",
      "Epoch:  0034 D loss:-0.4304 G loss:-2.841\n",
      "Epoch:  0034 D loss:-0.5491 G loss:-2.892\n",
      "Epoch:  0034 D loss:-0.4781 G loss:-2.927\n",
      "Epoch:  0034 D loss:-0.5089 G loss:-2.837\n",
      "Epoch:  0034 D loss:-0.4534 G loss:-2.838\n",
      "Epoch:  0034 D loss:-0.3698 G loss:-2.746\n",
      "Epoch:  0034 D loss:-0.4002 G loss:-2.788\n",
      "Epoch:  0034 D loss:-0.3939 G loss:-2.809\n",
      "Epoch:  0034 D loss:-0.3506 G loss:-2.591\n",
      "Epoch:  0034 D loss:-0.4315 G loss:-2.58\n",
      "Epoch:  0034 D loss:-0.5347 G loss:-2.567\n",
      "Epoch:  0034 D loss:-0.5089 G loss:-2.555\n",
      "Epoch:  0034 D loss:-0.3852 G loss:-2.504\n",
      "Epoch:  0034 D loss:-0.3636 G loss:-2.486\n",
      "Epoch:  0034 D loss:-0.4312 G loss:-2.616\n",
      "Epoch:  0034 D loss:-0.3936 G loss:-2.656\n",
      "Epoch:  0034 D loss:-0.444 G loss:-2.772\n",
      "Epoch:  0034 D loss:-0.3335 G loss:-2.775\n",
      "Epoch:  0034 D loss:-0.4344 G loss:-2.926\n",
      "Epoch:  0034 D loss:-0.3764 G loss:-2.967\n",
      "Epoch:  0034 D loss:-0.4822 G loss:-2.549\n",
      "Epoch:  0034 D loss:-0.4619 G loss:-2.794\n",
      "Epoch:  0034 D loss:-0.4933 G loss:-2.917\n",
      "Epoch:  0034 D loss:-0.4943 G loss:-2.813\n",
      "Epoch:  0034 D loss:-0.3573 G loss:-2.791\n",
      "Epoch:  0034 D loss:-0.4183 G loss:-2.603\n",
      "Epoch:  0034 D loss:-0.3134 G loss:-2.884\n",
      "Epoch:  0034 D loss:-0.3233 G loss:-3.003\n",
      "Epoch:  0034 D loss:-0.433 G loss:-2.622\n",
      "Epoch:  0034 D loss:-0.4685 G loss:-2.565\n",
      "Epoch:  0034 D loss:-0.4719 G loss:-2.538\n",
      "Epoch:  0034 D loss:-0.3461 G loss:-2.833\n",
      "Epoch:  0034 D loss:-0.4381 G loss:-2.466\n",
      "Epoch:  0034 D loss:-0.5486 G loss:-2.666\n",
      "Epoch:  0034 D loss:-0.4277 G loss:-2.438\n",
      "Epoch:  0034 D loss:-0.4236 G loss:-2.705\n",
      "Epoch:  0034 D loss:-0.5082 G loss:-2.94\n",
      "Epoch:  0034 D loss:-0.4841 G loss:-2.714\n",
      "Epoch:  0034 D loss:-0.4032 G loss:-2.695\n",
      "Epoch:  0034 D loss:-0.4202 G loss:-2.633\n",
      "Epoch:  0034 D loss:-0.3587 G loss:-2.657\n",
      "Epoch:  0034 D loss:-0.4875 G loss:-2.666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0034 D loss:-0.5701 G loss:-2.55\n",
      "Epoch:  0034 D loss:-0.3471 G loss:-2.776\n",
      "Epoch:  0034 D loss:-0.4058 G loss:-2.67\n",
      "Epoch:  0034 D loss:-0.5698 G loss:-2.364\n",
      "Epoch:  0034 D loss:-0.4206 G loss:-2.526\n",
      "Epoch:  0034 D loss:-0.5915 G loss:-2.822\n",
      "Epoch:  0034 D loss:-0.5654 G loss:-2.473\n",
      "Epoch:  0034 D loss:-0.483 G loss:-2.525\n",
      "Epoch:  0034 D loss:-0.4597 G loss:-2.66\n",
      "Epoch:  0034 D loss:-0.4924 G loss:-2.452\n",
      "Epoch:  0034 D loss:-0.4803 G loss:-2.502\n",
      "Epoch:  0034 D loss:-0.4878 G loss:-2.51\n",
      "Epoch:  0034 D loss:-0.4824 G loss:-2.73\n",
      "Epoch:  0034 D loss:-0.5818 G loss:-2.47\n",
      "Epoch:  0034 D loss:-0.566 G loss:-2.519\n",
      "Epoch:  0034 D loss:-0.4611 G loss:-2.5\n",
      "Epoch:  0034 D loss:-0.6798 G loss:-2.379\n",
      "Epoch:  0034 D loss:-0.6138 G loss:-2.351\n",
      "Epoch:  0034 D loss:-0.573 G loss:-2.692\n",
      "Epoch:  0034 D loss:-0.4923 G loss:-2.672\n",
      "Epoch:  0034 D loss:-0.3745 G loss:-2.639\n",
      "Epoch:  0034 D loss:-0.4601 G loss:-2.533\n",
      "Epoch:  0034 D loss:-0.5376 G loss:-2.75\n",
      "Epoch:  0034 D loss:-0.4084 G loss:-2.887\n",
      "Epoch:  0034 D loss:-0.4752 G loss:-2.445\n",
      "Epoch:  0034 D loss:-0.5314 G loss:-2.57\n",
      "Epoch:  0034 D loss:-0.5914 G loss:-2.676\n",
      "Epoch:  0034 D loss:-0.3884 G loss:-2.646\n",
      "Epoch:  0034 D loss:-0.5082 G loss:-2.539\n",
      "Epoch:  0034 D loss:-0.5651 G loss:-2.557\n",
      "Epoch:  0034 D loss:-0.4396 G loss:-2.356\n",
      "Epoch:  0034 D loss:-0.4327 G loss:-2.612\n",
      "Epoch:  0034 D loss:-0.433 G loss:-2.624\n",
      "Epoch:  0034 D loss:-0.5508 G loss:-2.662\n",
      "Epoch:  0034 D loss:-0.5248 G loss:-2.416\n",
      "Epoch:  0034 D loss:-0.4888 G loss:-2.606\n",
      "Epoch:  0034 D loss:-0.5588 G loss:-2.461\n",
      "Epoch:  0034 D loss:-0.4852 G loss:-2.513\n",
      "Epoch:  0034 D loss:-0.6105 G loss:-2.564\n",
      "Epoch:  0034 D loss:-0.6286 G loss:-2.568\n",
      "Epoch:  0034 D loss:-0.6375 G loss:-2.608\n",
      "Epoch:  0034 D loss:-0.3878 G loss:-2.594\n",
      "Epoch:  0034 D loss:-0.5216 G loss:-2.589\n",
      "Epoch:  0034 D loss:-0.458 G loss:-2.546\n",
      "Epoch:  0034 D loss:-0.5416 G loss:-2.394\n",
      "Epoch:  0034 D loss:-0.4737 G loss:-2.499\n",
      "Epoch:  0034 D loss:-0.3996 G loss:-2.261\n",
      "Epoch:  0034 D loss:-0.5026 G loss:-2.339\n",
      "Epoch:  0034 D loss:-0.6016 G loss:-2.246\n",
      "Epoch:  0034 D loss:-0.4472 G loss:-2.519\n",
      "Epoch:  0034 D loss:-0.3841 G loss:-2.584\n",
      "Epoch:  0034 D loss:-0.4925 G loss:-2.46\n",
      "Epoch:  0034 D loss:-0.4846 G loss:-2.604\n",
      "Epoch:  0034 D loss:-0.5822 G loss:-2.49\n",
      "Epoch:  0034 D loss:-0.5032 G loss:-2.439\n",
      "Epoch:  0034 D loss:-0.5436 G loss:-2.384\n",
      "Epoch:  0034 D loss:-0.5961 G loss:-2.211\n",
      "Epoch:  0034 D loss:-0.4058 G loss:-2.381\n",
      "Epoch:  0034 D loss:-0.4667 G loss:-2.701\n",
      "Epoch:  0034 D loss:-0.61 G loss:-2.503\n",
      "Epoch:  0034 D loss:-0.5583 G loss:-2.427\n",
      "Epoch:  0034 D loss:-0.4311 G loss:-2.458\n",
      "Epoch:  0034 D loss:-0.4776 G loss:-2.599\n",
      "Epoch:  0034 D loss:-0.5409 G loss:-2.399\n",
      "Epoch:  0034 D loss:-0.4826 G loss:-2.669\n",
      "Epoch:  0034 D loss:-0.4096 G loss:-2.777\n",
      "Epoch:  0034 D loss:-0.455 G loss:-2.539\n",
      "Epoch:  0034 D loss:-0.5143 G loss:-2.652\n",
      "Epoch:  0034 D loss:-0.4815 G loss:-2.729\n",
      "Epoch:  0034 D loss:-0.5464 G loss:-2.458\n",
      "Epoch:  0034 D loss:-0.517 G loss:-2.444\n",
      "Epoch:  0034 D loss:-0.5123 G loss:-2.712\n",
      "Epoch:  0034 D loss:-0.4744 G loss:-2.55\n",
      "Epoch:  0034 D loss:-0.4492 G loss:-2.788\n",
      "Epoch:  0034 D loss:-0.546 G loss:-2.801\n",
      "Epoch:  0034 D loss:-0.5462 G loss:-2.478\n",
      "Epoch:  0034 D loss:-0.4363 G loss:-2.595\n",
      "Epoch:  0034 D loss:-0.4644 G loss:-2.52\n",
      "Epoch:  0034 D loss:-0.4389 G loss:-2.667\n",
      "Epoch:  0034 D loss:-0.3775 G loss:-2.575\n",
      "Epoch:  0034 D loss:-0.3916 G loss:-2.544\n",
      "Epoch:  0034 D loss:-0.4891 G loss:-2.414\n",
      "Epoch:  0034 D loss:-0.4394 G loss:-2.463\n",
      "Epoch:  0034 D loss:-0.4895 G loss:-2.498\n",
      "Epoch:  0034 D loss:-0.4722 G loss:-2.403\n",
      "Epoch:  0034 D loss:-0.4085 G loss:-2.785\n",
      "Epoch:  0034 D loss:-0.517 G loss:-2.605\n",
      "Epoch:  0034 D loss:-0.4386 G loss:-2.726\n",
      "Epoch:  0034 D loss:-0.5753 G loss:-2.652\n",
      "Epoch:  0034 D loss:-0.4105 G loss:-2.797\n",
      "Epoch:  0034 D loss:-0.4463 G loss:-2.79\n",
      "Epoch:  0034 D loss:-0.4901 G loss:-2.535\n",
      "Epoch:  0034 D loss:-0.3282 G loss:-2.83\n",
      "Epoch:  0034 D loss:-0.4267 G loss:-2.613\n",
      "Epoch:  0034 D loss:-0.396 G loss:-2.611\n",
      "Epoch:  0034 D loss:-0.4743 G loss:-2.597\n",
      "Epoch:  0034 D loss:-0.5558 G loss:-2.561\n",
      "Epoch:  0034 D loss:-0.3764 G loss:-2.65\n",
      "Epoch:  0034 D loss:-0.4868 G loss:-2.428\n",
      "Epoch:  0034 D loss:-0.5281 G loss:-2.715\n",
      "Epoch:  0034 D loss:-0.4821 G loss:-2.445\n",
      "Epoch:  0034 D loss:-0.4132 G loss:-2.486\n",
      "Epoch:  0034 D loss:-0.3737 G loss:-2.787\n",
      "Epoch:  0034 D loss:-0.407 G loss:-2.645\n",
      "Epoch:  0034 D loss:-0.4212 G loss:-2.667\n",
      "Epoch:  0034 D loss:-0.4222 G loss:-2.68\n",
      "Epoch:  0034 D loss:-0.4329 G loss:-2.805\n",
      "Epoch:  0034 D loss:-0.4673 G loss:-2.756\n",
      "Epoch:  0034 D loss:-0.5621 G loss:-2.466\n",
      "Epoch:  0034 D loss:-0.4329 G loss:-2.816\n",
      "Epoch:  0034 D loss:-0.4799 G loss:-2.676\n",
      "Epoch:  0034 D loss:-0.4656 G loss:-2.959\n",
      "Epoch:  0034 D loss:-0.4985 G loss:-2.847\n",
      "Epoch:  0034 D loss:-0.5128 G loss:-2.608\n",
      "Epoch:  0034 D loss:-0.4485 G loss:-2.653\n",
      "Epoch:  0034 D loss:-0.4732 G loss:-2.714\n",
      "Epoch:  0034 D loss:-0.4256 G loss:-2.554\n",
      "Epoch:  0034 D loss:-0.4629 G loss:-2.701\n",
      "Epoch:  0034 D loss:-0.4191 G loss:-2.533\n",
      "Epoch:  0034 D loss:-0.4455 G loss:-2.58\n",
      "Epoch:  0034 D loss:-0.5859 G loss:-2.518\n",
      "Epoch:  0034 D loss:-0.4195 G loss:-2.454\n",
      "Epoch:  0034 D loss:-0.5423 G loss:-2.651\n",
      "Epoch:  0034 D loss:-0.4691 G loss:-2.745\n",
      "Epoch:  0034 D loss:-0.5377 G loss:-2.678\n",
      "Epoch:  0034 D loss:-0.3925 G loss:-2.877\n",
      "Epoch:  0034 D loss:-0.5091 G loss:-2.838\n",
      "Epoch:  0034 D loss:-0.4401 G loss:-2.649\n",
      "Epoch:  0034 D loss:-0.4091 G loss:-2.847\n",
      "Epoch:  0034 D loss:-0.4383 G loss:-2.82\n",
      "Epoch:  0034 D loss:-0.5691 G loss:-2.705\n",
      "Epoch:  0034 D loss:-0.4359 G loss:-2.506\n",
      "Epoch:  0034 D loss:-0.5008 G loss:-2.478\n",
      "Epoch:  0034 D loss:-0.5998 G loss:-2.417\n",
      "Epoch:  0034 D loss:-0.4356 G loss:-2.613\n",
      "Epoch:  0034 D loss:-0.4093 G loss:-2.749\n",
      "Epoch:  0034 D loss:-0.405 G loss:-2.613\n",
      "Epoch:  0034 D loss:-0.48 G loss:-2.668\n",
      "Epoch:  0034 D loss:-0.4512 G loss:-2.798\n",
      "Epoch:  0034 D loss:-0.3585 G loss:-2.705\n",
      "Epoch:  0034 D loss:-0.6593 G loss:-2.556\n",
      "Epoch:  0034 D loss:-0.4116 G loss:-2.57\n",
      "Epoch:  0034 D loss:-0.4509 G loss:-2.712\n",
      "Epoch:  0034 D loss:-0.4407 G loss:-2.888\n",
      "Epoch:  0034 D loss:-0.4216 G loss:-2.589\n",
      "Epoch:  0034 D loss:-0.4979 G loss:-2.366\n",
      "Epoch:  0034 D loss:-0.4705 G loss:-2.595\n",
      "Epoch:  0034 D loss:-0.4402 G loss:-2.616\n",
      "Epoch:  0034 D loss:-0.4963 G loss:-2.612\n",
      "Epoch:  0034 D loss:-0.5514 G loss:-2.418\n",
      "Epoch:  0034 D loss:-0.43 G loss:-2.674\n",
      "Epoch:  0034 D loss:-0.5067 G loss:-2.461\n",
      "Epoch:  0034 D loss:-0.4697 G loss:-2.621\n",
      "Epoch:  0034 D loss:-0.3103 G loss:-2.579\n",
      "Epoch:  0034 D loss:-0.4203 G loss:-2.694\n",
      "Epoch:  0034 D loss:-0.549 G loss:-2.541\n",
      "Epoch:  0034 D loss:-0.5212 G loss:-2.377\n",
      "Epoch:  0034 D loss:-0.6323 G loss:-2.259\n",
      "Epoch:  0034 D loss:-0.4848 G loss:-2.691\n",
      "Epoch:  0034 D loss:-0.4147 G loss:-2.468\n",
      "Epoch:  0034 D loss:-0.4987 G loss:-2.741\n",
      "Epoch:  0034 D loss:-0.4215 G loss:-2.517\n",
      "Epoch:  0034 D loss:-0.3253 G loss:-2.806\n",
      "Epoch:  0034 D loss:-0.3452 G loss:-2.895\n",
      "Epoch:  0034 D loss:-0.4749 G loss:-2.859\n",
      "Epoch:  0034 D loss:-0.5424 G loss:-2.676\n",
      "Epoch:  0034 D loss:-0.3632 G loss:-2.698\n",
      "Epoch:  0034 D loss:-0.4953 G loss:-2.672\n",
      "Epoch:  0034 D loss:-0.4802 G loss:-2.706\n",
      "Epoch:  0034 D loss:-0.5871 G loss:-2.4\n",
      "Epoch:  0034 D loss:-0.4625 G loss:-2.642\n",
      "Epoch:  0034 D loss:-0.4265 G loss:-2.498\n",
      "Epoch:  0034 D loss:-0.4006 G loss:-2.463\n",
      "Epoch:  0034 D loss:-0.6166 G loss:-2.359\n",
      "Epoch:  0034 D loss:-0.3221 G loss:-2.61\n",
      "Epoch:  0034 D loss:-0.5792 G loss:-2.413\n",
      "Epoch:  0034 D loss:-0.4658 G loss:-2.293\n",
      "Epoch:  0034 D loss:-0.4346 G loss:-2.498\n",
      "Epoch:  0034 D loss:-0.52 G loss:-2.43\n",
      "Epoch:  0034 D loss:-0.4392 G loss:-2.339\n",
      "Epoch:  0034 D loss:-0.4788 G loss:-2.819\n",
      "Epoch:  0034 D loss:-0.4249 G loss:-2.687\n",
      "Epoch:  0034 D loss:-0.4414 G loss:-2.943\n",
      "Epoch:  0034 D loss:-0.4354 G loss:-2.678\n",
      "Epoch:  0035 D loss:-0.4928 G loss:-2.66\n",
      "Epoch:  0035 D loss:-0.5263 G loss:-2.851\n",
      "Epoch:  0035 D loss:-0.4716 G loss:-2.959\n",
      "Epoch:  0035 D loss:-0.4757 G loss:-2.754\n",
      "Epoch:  0035 D loss:-0.4511 G loss:-2.857\n",
      "Epoch:  0035 D loss:-0.5379 G loss:-2.593\n",
      "Epoch:  0035 D loss:-0.5297 G loss:-2.585\n",
      "Epoch:  0035 D loss:-0.4481 G loss:-2.394\n",
      "Epoch:  0035 D loss:-0.505 G loss:-2.393\n",
      "Epoch:  0035 D loss:-0.4012 G loss:-2.442\n",
      "Epoch:  0035 D loss:-0.5263 G loss:-2.109\n",
      "Epoch:  0035 D loss:-0.4928 G loss:-2.341\n",
      "Epoch:  0035 D loss:-0.5323 G loss:-2.304\n",
      "Epoch:  0035 D loss:-0.4792 G loss:-2.47\n",
      "Epoch:  0035 D loss:-0.5803 G loss:-2.555\n",
      "Epoch:  0035 D loss:-0.4598 G loss:-2.752\n",
      "Epoch:  0035 D loss:-0.6159 G loss:-2.417\n",
      "Epoch:  0035 D loss:-0.5627 G loss:-2.69\n",
      "Epoch:  0035 D loss:-0.4756 G loss:-2.91\n",
      "Epoch:  0035 D loss:-0.4558 G loss:-2.815\n",
      "Epoch:  0035 D loss:-0.4923 G loss:-2.744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0035 D loss:-0.4522 G loss:-2.756\n",
      "Epoch:  0035 D loss:-0.6158 G loss:-2.631\n",
      "Epoch:  0035 D loss:-0.5084 G loss:-2.658\n",
      "Epoch:  0035 D loss:-0.5604 G loss:-2.279\n",
      "Epoch:  0035 D loss:-0.479 G loss:-2.151\n",
      "Epoch:  0035 D loss:-0.5786 G loss:-2.085\n",
      "Epoch:  0035 D loss:-0.4767 G loss:-2.295\n",
      "Epoch:  0035 D loss:-0.6194 G loss:-2.202\n",
      "Epoch:  0035 D loss:-0.4879 G loss:-2.264\n",
      "Epoch:  0035 D loss:-0.5565 G loss:-2.335\n",
      "Epoch:  0035 D loss:-0.5706 G loss:-2.699\n",
      "Epoch:  0035 D loss:-0.4284 G loss:-2.736\n",
      "Epoch:  0035 D loss:-0.4502 G loss:-2.618\n",
      "Epoch:  0035 D loss:-0.4663 G loss:-2.907\n",
      "Epoch:  0035 D loss:-0.5148 G loss:-2.942\n",
      "Epoch:  0035 D loss:-0.437 G loss:-3.117\n",
      "Epoch:  0035 D loss:-0.5321 G loss:-2.876\n",
      "Epoch:  0035 D loss:-0.5467 G loss:-2.918\n",
      "Epoch:  0035 D loss:-0.4373 G loss:-2.481\n",
      "Epoch:  0035 D loss:-0.4873 G loss:-2.64\n",
      "Epoch:  0035 D loss:-0.4966 G loss:-2.464\n",
      "Epoch:  0035 D loss:-0.5583 G loss:-2.271\n",
      "Epoch:  0035 D loss:-0.4739 G loss:-2.31\n",
      "Epoch:  0035 D loss:-0.533 G loss:-2.229\n",
      "Epoch:  0035 D loss:-0.5295 G loss:-2.456\n",
      "Epoch:  0035 D loss:-0.5915 G loss:-2.296\n",
      "Epoch:  0035 D loss:-0.6376 G loss:-2.388\n",
      "Epoch:  0035 D loss:-0.5824 G loss:-2.437\n",
      "Epoch:  0035 D loss:-0.5074 G loss:-2.643\n",
      "Epoch:  0035 D loss:-0.4911 G loss:-2.701\n",
      "Epoch:  0035 D loss:-0.6133 G loss:-2.679\n",
      "Epoch:  0035 D loss:-0.4339 G loss:-2.733\n",
      "Epoch:  0035 D loss:-0.386 G loss:-2.737\n",
      "Epoch:  0035 D loss:-0.5203 G loss:-2.642\n",
      "Epoch:  0035 D loss:-0.5439 G loss:-2.81\n",
      "Epoch:  0035 D loss:-0.4294 G loss:-2.798\n",
      "Epoch:  0035 D loss:-0.4508 G loss:-2.657\n",
      "Epoch:  0035 D loss:-0.5413 G loss:-2.644\n",
      "Epoch:  0035 D loss:-0.4586 G loss:-2.665\n",
      "Epoch:  0035 D loss:-0.5236 G loss:-2.763\n",
      "Epoch:  0035 D loss:-0.5395 G loss:-2.583\n",
      "Epoch:  0035 D loss:-0.5232 G loss:-2.519\n",
      "Epoch:  0035 D loss:-0.442 G loss:-2.655\n",
      "Epoch:  0035 D loss:-0.4545 G loss:-2.69\n",
      "Epoch:  0035 D loss:-0.5559 G loss:-2.229\n",
      "Epoch:  0035 D loss:-0.4044 G loss:-2.617\n",
      "Epoch:  0035 D loss:-0.5067 G loss:-2.563\n",
      "Epoch:  0035 D loss:-0.5604 G loss:-2.544\n",
      "Epoch:  0035 D loss:-0.3489 G loss:-2.835\n",
      "Epoch:  0035 D loss:-0.4759 G loss:-3.082\n",
      "Epoch:  0035 D loss:-0.634 G loss:-2.687\n",
      "Epoch:  0035 D loss:-0.3878 G loss:-3.184\n",
      "Epoch:  0035 D loss:-0.6147 G loss:-2.748\n",
      "Epoch:  0035 D loss:-0.426 G loss:-2.91\n",
      "Epoch:  0035 D loss:-0.4661 G loss:-2.777\n",
      "Epoch:  0035 D loss:-0.6295 G loss:-2.654\n",
      "Epoch:  0035 D loss:-0.4712 G loss:-2.367\n",
      "Epoch:  0035 D loss:-0.569 G loss:-2.587\n",
      "Epoch:  0035 D loss:-0.4949 G loss:-2.369\n",
      "Epoch:  0035 D loss:-0.4501 G loss:-2.448\n",
      "Epoch:  0035 D loss:-0.6062 G loss:-2.324\n",
      "Epoch:  0035 D loss:-0.3695 G loss:-2.548\n",
      "Epoch:  0035 D loss:-0.3829 G loss:-2.575\n",
      "Epoch:  0035 D loss:-0.4299 G loss:-2.679\n",
      "Epoch:  0035 D loss:-0.5653 G loss:-2.649\n",
      "Epoch:  0035 D loss:-0.4406 G loss:-2.837\n",
      "Epoch:  0035 D loss:-0.4794 G loss:-2.979\n",
      "Epoch:  0035 D loss:-0.5106 G loss:-2.931\n",
      "Epoch:  0035 D loss:-0.4675 G loss:-2.936\n",
      "Epoch:  0035 D loss:-0.5192 G loss:-2.426\n",
      "Epoch:  0035 D loss:-0.491 G loss:-2.693\n",
      "Epoch:  0035 D loss:-0.7016 G loss:-2.307\n",
      "Epoch:  0035 D loss:-0.5178 G loss:-2.412\n",
      "Epoch:  0035 D loss:-0.4573 G loss:-2.632\n",
      "Epoch:  0035 D loss:-0.3981 G loss:-2.44\n",
      "Epoch:  0035 D loss:-0.54 G loss:-2.532\n",
      "Epoch:  0035 D loss:-0.4319 G loss:-2.535\n",
      "Epoch:  0035 D loss:-0.4202 G loss:-2.876\n",
      "Epoch:  0035 D loss:-0.5507 G loss:-2.857\n",
      "Epoch:  0035 D loss:-0.4861 G loss:-2.726\n",
      "Epoch:  0035 D loss:-0.5307 G loss:-2.517\n",
      "Epoch:  0035 D loss:-0.467 G loss:-2.533\n",
      "Epoch:  0035 D loss:-0.5916 G loss:-2.623\n",
      "Epoch:  0035 D loss:-0.3585 G loss:-2.774\n",
      "Epoch:  0035 D loss:-0.4522 G loss:-2.735\n",
      "Epoch:  0035 D loss:-0.6592 G loss:-2.644\n",
      "Epoch:  0035 D loss:-0.515 G loss:-2.615\n",
      "Epoch:  0035 D loss:-0.5061 G loss:-2.684\n",
      "Epoch:  0035 D loss:-0.3649 G loss:-2.723\n",
      "Epoch:  0035 D loss:-0.4181 G loss:-2.698\n",
      "Epoch:  0035 D loss:-0.6454 G loss:-2.446\n",
      "Epoch:  0035 D loss:-0.5657 G loss:-2.664\n",
      "Epoch:  0035 D loss:-0.4905 G loss:-2.581\n",
      "Epoch:  0035 D loss:-0.4011 G loss:-2.875\n",
      "Epoch:  0035 D loss:-0.6634 G loss:-2.584\n",
      "Epoch:  0035 D loss:-0.4672 G loss:-2.65\n",
      "Epoch:  0035 D loss:-0.467 G loss:-2.459\n",
      "Epoch:  0035 D loss:-0.5289 G loss:-2.341\n",
      "Epoch:  0035 D loss:-0.6094 G loss:-2.282\n",
      "Epoch:  0035 D loss:-0.403 G loss:-2.63\n",
      "Epoch:  0035 D loss:-0.6113 G loss:-2.405\n",
      "Epoch:  0035 D loss:-0.4077 G loss:-2.68\n",
      "Epoch:  0035 D loss:-0.4545 G loss:-2.821\n",
      "Epoch:  0035 D loss:-0.4561 G loss:-2.757\n",
      "Epoch:  0035 D loss:-0.419 G loss:-2.831\n",
      "Epoch:  0035 D loss:-0.5891 G loss:-2.621\n",
      "Epoch:  0035 D loss:-0.3831 G loss:-2.94\n",
      "Epoch:  0035 D loss:-0.4155 G loss:-2.688\n",
      "Epoch:  0035 D loss:-0.4466 G loss:-2.678\n",
      "Epoch:  0035 D loss:-0.3879 G loss:-2.866\n",
      "Epoch:  0035 D loss:-0.5199 G loss:-2.556\n",
      "Epoch:  0035 D loss:-0.5697 G loss:-2.723\n",
      "Epoch:  0035 D loss:-0.3539 G loss:-2.57\n",
      "Epoch:  0035 D loss:-0.6364 G loss:-2.417\n",
      "Epoch:  0035 D loss:-0.466 G loss:-2.474\n",
      "Epoch:  0035 D loss:-0.4869 G loss:-2.648\n",
      "Epoch:  0035 D loss:-0.4009 G loss:-2.684\n",
      "Epoch:  0035 D loss:-0.4159 G loss:-2.681\n",
      "Epoch:  0035 D loss:-0.4793 G loss:-2.5\n",
      "Epoch:  0035 D loss:-0.3931 G loss:-2.466\n",
      "Epoch:  0035 D loss:-0.4619 G loss:-2.634\n",
      "Epoch:  0035 D loss:-0.4645 G loss:-2.615\n",
      "Epoch:  0035 D loss:-0.4698 G loss:-2.669\n",
      "Epoch:  0035 D loss:-0.4382 G loss:-2.707\n",
      "Epoch:  0035 D loss:-0.4661 G loss:-2.816\n",
      "Epoch:  0035 D loss:-0.5081 G loss:-2.636\n",
      "Epoch:  0035 D loss:-0.5532 G loss:-2.494\n",
      "Epoch:  0035 D loss:-0.4541 G loss:-2.632\n",
      "Epoch:  0035 D loss:-0.4698 G loss:-2.408\n",
      "Epoch:  0035 D loss:-0.413 G loss:-2.69\n",
      "Epoch:  0035 D loss:-0.4906 G loss:-2.662\n",
      "Epoch:  0035 D loss:-0.5069 G loss:-2.706\n",
      "Epoch:  0035 D loss:-0.5011 G loss:-2.496\n",
      "Epoch:  0035 D loss:-0.4941 G loss:-2.531\n",
      "Epoch:  0035 D loss:-0.5102 G loss:-2.348\n",
      "Epoch:  0035 D loss:-0.4928 G loss:-2.361\n",
      "Epoch:  0035 D loss:-0.4476 G loss:-2.657\n",
      "Epoch:  0035 D loss:-0.3755 G loss:-2.863\n",
      "Epoch:  0035 D loss:-0.5131 G loss:-2.582\n",
      "Epoch:  0035 D loss:-0.4205 G loss:-2.771\n",
      "Epoch:  0035 D loss:-0.5301 G loss:-2.693\n",
      "Epoch:  0035 D loss:-0.4123 G loss:-2.81\n",
      "Epoch:  0035 D loss:-0.4517 G loss:-2.664\n",
      "Epoch:  0035 D loss:-0.5175 G loss:-2.926\n",
      "Epoch:  0035 D loss:-0.3577 G loss:-3.015\n",
      "Epoch:  0035 D loss:-0.3265 G loss:-2.971\n",
      "Epoch:  0035 D loss:-0.4925 G loss:-2.582\n",
      "Epoch:  0035 D loss:-0.53 G loss:-2.754\n",
      "Epoch:  0035 D loss:-0.389 G loss:-2.647\n",
      "Epoch:  0035 D loss:-0.4201 G loss:-2.836\n",
      "Epoch:  0035 D loss:-0.5351 G loss:-2.615\n",
      "Epoch:  0035 D loss:-0.4835 G loss:-2.56\n",
      "Epoch:  0035 D loss:-0.4431 G loss:-2.766\n",
      "Epoch:  0035 D loss:-0.5253 G loss:-2.532\n",
      "Epoch:  0035 D loss:-0.489 G loss:-2.64\n",
      "Epoch:  0035 D loss:-0.3561 G loss:-2.962\n",
      "Epoch:  0035 D loss:-0.3581 G loss:-2.866\n",
      "Epoch:  0035 D loss:-0.4183 G loss:-2.946\n",
      "Epoch:  0035 D loss:-0.481 G loss:-2.917\n",
      "Epoch:  0035 D loss:-0.5194 G loss:-2.926\n",
      "Epoch:  0035 D loss:-0.391 G loss:-2.718\n",
      "Epoch:  0035 D loss:-0.4088 G loss:-2.66\n",
      "Epoch:  0035 D loss:-0.5143 G loss:-2.573\n",
      "Epoch:  0035 D loss:-0.3846 G loss:-2.377\n",
      "Epoch:  0035 D loss:-0.3793 G loss:-2.433\n",
      "Epoch:  0035 D loss:-0.4817 G loss:-2.341\n",
      "Epoch:  0035 D loss:-0.5425 G loss:-2.331\n",
      "Epoch:  0035 D loss:-0.4876 G loss:-2.719\n",
      "Epoch:  0035 D loss:-0.4503 G loss:-2.638\n",
      "Epoch:  0035 D loss:-0.7388 G loss:-2.48\n",
      "Epoch:  0035 D loss:-0.4692 G loss:-2.949\n",
      "Epoch:  0035 D loss:-0.4925 G loss:-3.048\n",
      "Epoch:  0035 D loss:-0.5005 G loss:-2.895\n",
      "Epoch:  0035 D loss:-0.538 G loss:-2.691\n",
      "Epoch:  0035 D loss:-0.476 G loss:-2.644\n",
      "Epoch:  0035 D loss:-0.5165 G loss:-2.812\n",
      "Epoch:  0035 D loss:-0.5424 G loss:-2.664\n",
      "Epoch:  0035 D loss:-0.4713 G loss:-2.588\n",
      "Epoch:  0035 D loss:-0.3952 G loss:-2.534\n",
      "Epoch:  0035 D loss:-0.4103 G loss:-2.723\n",
      "Epoch:  0035 D loss:-0.5152 G loss:-2.367\n",
      "Epoch:  0035 D loss:-0.4315 G loss:-2.398\n",
      "Epoch:  0035 D loss:-0.4783 G loss:-2.556\n",
      "Epoch:  0035 D loss:-0.4177 G loss:-2.425\n",
      "Epoch:  0035 D loss:-0.3989 G loss:-2.829\n",
      "Epoch:  0035 D loss:-0.4798 G loss:-2.615\n",
      "Epoch:  0035 D loss:-0.4909 G loss:-2.541\n",
      "Epoch:  0035 D loss:-0.3963 G loss:-2.86\n",
      "Epoch:  0035 D loss:-0.4629 G loss:-2.72\n",
      "Epoch:  0035 D loss:-0.5615 G loss:-2.582\n",
      "Epoch:  0035 D loss:-0.4686 G loss:-2.654\n",
      "Epoch:  0035 D loss:-0.5466 G loss:-2.732\n",
      "Epoch:  0035 D loss:-0.6747 G loss:-2.461\n",
      "Epoch:  0035 D loss:-0.3823 G loss:-2.576\n",
      "Epoch:  0035 D loss:-0.5935 G loss:-2.528\n",
      "Epoch:  0035 D loss:-0.372 G loss:-2.282\n",
      "Epoch:  0035 D loss:-0.461 G loss:-2.401\n",
      "Epoch:  0035 D loss:-0.5692 G loss:-2.578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0035 D loss:-0.5533 G loss:-2.391\n",
      "Epoch:  0035 D loss:-0.5091 G loss:-2.488\n",
      "Epoch:  0035 D loss:-0.4105 G loss:-2.74\n",
      "Epoch:  0035 D loss:-0.4167 G loss:-2.441\n",
      "Epoch:  0035 D loss:-0.5609 G loss:-2.356\n",
      "Epoch:  0035 D loss:-0.6032 G loss:-2.382\n",
      "Epoch:  0035 D loss:-0.448 G loss:-2.772\n",
      "Epoch:  0035 D loss:-0.6378 G loss:-2.522\n",
      "Epoch:  0035 D loss:-0.4112 G loss:-2.768\n",
      "Epoch:  0035 D loss:-0.3895 G loss:-2.706\n",
      "Epoch:  0035 D loss:-0.5598 G loss:-2.575\n",
      "Epoch:  0035 D loss:-0.4851 G loss:-2.774\n",
      "Epoch:  0035 D loss:-0.5363 G loss:-2.706\n",
      "Epoch:  0035 D loss:-0.5382 G loss:-2.755\n",
      "Epoch:  0035 D loss:-0.4048 G loss:-2.619\n",
      "Epoch:  0035 D loss:-0.4549 G loss:-2.651\n",
      "Epoch:  0035 D loss:-0.534 G loss:-2.751\n",
      "Epoch:  0035 D loss:-0.4752 G loss:-2.657\n",
      "Epoch:  0035 D loss:-0.5291 G loss:-2.281\n",
      "Epoch:  0035 D loss:-0.6382 G loss:-2.69\n",
      "Epoch:  0035 D loss:-0.4497 G loss:-2.573\n",
      "Epoch:  0035 D loss:-0.4368 G loss:-2.447\n",
      "Epoch:  0035 D loss:-0.5576 G loss:-2.348\n",
      "Epoch:  0035 D loss:-0.4477 G loss:-2.507\n",
      "Epoch:  0035 D loss:-0.5143 G loss:-2.719\n",
      "Epoch:  0035 D loss:-0.5727 G loss:-2.586\n",
      "Epoch:  0035 D loss:-0.4811 G loss:-2.626\n",
      "Epoch:  0035 D loss:-0.4931 G loss:-2.655\n",
      "Epoch:  0035 D loss:-0.5759 G loss:-2.596\n",
      "Epoch:  0035 D loss:-0.4394 G loss:-2.897\n",
      "Epoch:  0035 D loss:-0.4323 G loss:-2.686\n",
      "Epoch:  0035 D loss:-0.4377 G loss:-2.49\n",
      "Epoch:  0035 D loss:-0.6393 G loss:-2.245\n",
      "Epoch:  0035 D loss:-0.4193 G loss:-2.659\n",
      "Epoch:  0035 D loss:-0.5691 G loss:-2.769\n",
      "Epoch:  0035 D loss:-0.4323 G loss:-2.674\n",
      "Epoch:  0035 D loss:-0.481 G loss:-2.547\n",
      "Epoch:  0035 D loss:-0.4902 G loss:-2.417\n",
      "Epoch:  0035 D loss:-0.3929 G loss:-2.679\n",
      "Epoch:  0035 D loss:-0.6295 G loss:-2.472\n",
      "Epoch:  0035 D loss:-0.4891 G loss:-2.504\n",
      "Epoch:  0035 D loss:-0.5866 G loss:-2.622\n",
      "Epoch:  0035 D loss:-0.3804 G loss:-2.542\n",
      "Epoch:  0035 D loss:-0.5009 G loss:-2.578\n",
      "Epoch:  0035 D loss:-0.4573 G loss:-2.523\n",
      "Epoch:  0035 D loss:-0.544 G loss:-2.43\n",
      "Epoch:  0035 D loss:-0.4212 G loss:-2.865\n",
      "Epoch:  0035 D loss:-0.4928 G loss:-2.713\n",
      "Epoch:  0035 D loss:-0.4244 G loss:-2.817\n",
      "Epoch:  0035 D loss:-0.5217 G loss:-2.618\n",
      "Epoch:  0035 D loss:-0.5077 G loss:-2.795\n",
      "Epoch:  0035 D loss:-0.3276 G loss:-2.744\n",
      "Epoch:  0035 D loss:-0.5359 G loss:-2.691\n",
      "Epoch:  0035 D loss:-0.4738 G loss:-2.847\n",
      "Epoch:  0035 D loss:-0.4502 G loss:-2.733\n",
      "Epoch:  0035 D loss:-0.3398 G loss:-2.788\n",
      "Epoch:  0035 D loss:-0.5444 G loss:-2.173\n",
      "Epoch:  0035 D loss:-0.4013 G loss:-2.532\n",
      "Epoch:  0035 D loss:-0.3813 G loss:-2.854\n",
      "Epoch:  0035 D loss:-0.4241 G loss:-2.573\n",
      "Epoch:  0035 D loss:-0.512 G loss:-2.598\n",
      "Epoch:  0035 D loss:-0.4566 G loss:-2.843\n",
      "Epoch:  0035 D loss:-0.4187 G loss:-2.654\n",
      "Epoch:  0035 D loss:-0.4572 G loss:-2.397\n",
      "Epoch:  0035 D loss:-0.4541 G loss:-2.515\n",
      "Epoch:  0035 D loss:-0.4909 G loss:-2.49\n",
      "Epoch:  0035 D loss:-0.4622 G loss:-2.381\n",
      "Epoch:  0035 D loss:-0.7367 G loss:-2.235\n",
      "Epoch:  0035 D loss:-0.4668 G loss:-2.898\n",
      "Epoch:  0035 D loss:-0.5354 G loss:-2.625\n",
      "Epoch:  0035 D loss:-0.5487 G loss:-2.522\n",
      "Epoch:  0035 D loss:-0.4865 G loss:-2.642\n",
      "Epoch:  0035 D loss:-0.4796 G loss:-2.548\n",
      "Epoch:  0035 D loss:-0.3561 G loss:-2.716\n",
      "Epoch:  0035 D loss:-0.4592 G loss:-2.668\n",
      "Epoch:  0035 D loss:-0.5761 G loss:-2.692\n",
      "Epoch:  0035 D loss:-0.489 G loss:-2.612\n",
      "Epoch:  0035 D loss:-0.4342 G loss:-2.471\n",
      "Epoch:  0035 D loss:-0.527 G loss:-2.58\n",
      "Epoch:  0035 D loss:-0.4882 G loss:-2.909\n",
      "Epoch:  0035 D loss:-0.6282 G loss:-2.473\n",
      "Epoch:  0035 D loss:-0.5085 G loss:-2.398\n",
      "Epoch:  0035 D loss:-0.5272 G loss:-2.618\n",
      "Epoch:  0035 D loss:-0.6375 G loss:-2.325\n",
      "Epoch:  0035 D loss:-0.433 G loss:-2.617\n",
      "Epoch:  0035 D loss:-0.5633 G loss:-2.406\n",
      "Epoch:  0035 D loss:-0.4565 G loss:-2.106\n",
      "Epoch:  0035 D loss:-0.5131 G loss:-2.308\n",
      "Epoch:  0035 D loss:-0.4029 G loss:-2.698\n",
      "Epoch:  0035 D loss:-0.4443 G loss:-2.575\n",
      "Epoch:  0035 D loss:-0.4798 G loss:-2.605\n",
      "Epoch:  0035 D loss:-0.4906 G loss:-2.667\n",
      "Epoch:  0035 D loss:-0.4007 G loss:-2.747\n",
      "Epoch:  0035 D loss:-0.3824 G loss:-2.886\n",
      "Epoch:  0035 D loss:-0.3612 G loss:-3.123\n",
      "Epoch:  0035 D loss:-0.5181 G loss:-3.092\n",
      "Epoch:  0035 D loss:-0.5036 G loss:-2.921\n",
      "Epoch:  0035 D loss:-0.447 G loss:-3.069\n",
      "Epoch:  0035 D loss:-0.4322 G loss:-2.841\n",
      "Epoch:  0035 D loss:-0.382 G loss:-2.817\n",
      "Epoch:  0035 D loss:-0.3761 G loss:-2.678\n",
      "Epoch:  0035 D loss:-0.5385 G loss:-2.604\n",
      "Epoch:  0035 D loss:-0.3933 G loss:-2.646\n",
      "Epoch:  0035 D loss:-0.5229 G loss:-2.655\n",
      "Epoch:  0035 D loss:-0.4684 G loss:-2.675\n",
      "Epoch:  0035 D loss:-0.5659 G loss:-2.482\n",
      "Epoch:  0035 D loss:-0.3811 G loss:-2.514\n",
      "Epoch:  0035 D loss:-0.4541 G loss:-2.506\n",
      "Epoch:  0035 D loss:-0.3962 G loss:-2.348\n",
      "Epoch:  0035 D loss:-0.5325 G loss:-2.459\n",
      "Epoch:  0035 D loss:-0.3871 G loss:-2.585\n",
      "Epoch:  0035 D loss:-0.5045 G loss:-2.346\n",
      "Epoch:  0035 D loss:-0.4135 G loss:-2.69\n",
      "Epoch:  0035 D loss:-0.4321 G loss:-2.985\n",
      "Epoch:  0035 D loss:-0.4742 G loss:-2.819\n",
      "Epoch:  0035 D loss:-0.5519 G loss:-2.777\n",
      "Epoch:  0035 D loss:-0.3793 G loss:-2.825\n",
      "Epoch:  0035 D loss:-0.4996 G loss:-2.958\n",
      "Epoch:  0035 D loss:-0.4943 G loss:-2.837\n",
      "Epoch:  0035 D loss:-0.3987 G loss:-2.943\n",
      "Epoch:  0035 D loss:-0.4164 G loss:-2.653\n",
      "Epoch:  0035 D loss:-0.3349 G loss:-2.733\n",
      "Epoch:  0035 D loss:-0.5019 G loss:-2.527\n",
      "Epoch:  0035 D loss:-0.4014 G loss:-2.658\n",
      "Epoch:  0035 D loss:-0.4685 G loss:-2.379\n",
      "Epoch:  0035 D loss:-0.4821 G loss:-2.365\n",
      "Epoch:  0035 D loss:-0.3771 G loss:-2.624\n",
      "Epoch:  0035 D loss:-0.4972 G loss:-2.639\n",
      "Epoch:  0035 D loss:-0.4258 G loss:-2.668\n",
      "Epoch:  0035 D loss:-0.5551 G loss:-2.523\n",
      "Epoch:  0035 D loss:-0.5175 G loss:-2.507\n",
      "Epoch:  0035 D loss:-0.4124 G loss:-2.838\n",
      "Epoch:  0035 D loss:-0.4623 G loss:-2.522\n",
      "Epoch:  0035 D loss:-0.3425 G loss:-2.822\n",
      "Epoch:  0035 D loss:-0.4644 G loss:-2.538\n",
      "Epoch:  0035 D loss:-0.4522 G loss:-2.802\n",
      "Epoch:  0035 D loss:-0.4479 G loss:-2.601\n",
      "Epoch:  0035 D loss:-0.487 G loss:-2.76\n",
      "Epoch:  0035 D loss:-0.4421 G loss:-2.739\n",
      "Epoch:  0035 D loss:-0.4112 G loss:-2.484\n",
      "Epoch:  0035 D loss:-0.3624 G loss:-2.82\n",
      "Epoch:  0035 D loss:-0.388 G loss:-2.617\n",
      "Epoch:  0035 D loss:-0.4659 G loss:-2.509\n",
      "Epoch:  0035 D loss:-0.4706 G loss:-2.68\n",
      "Epoch:  0035 D loss:-0.4423 G loss:-2.555\n",
      "Epoch:  0035 D loss:-0.4674 G loss:-2.288\n",
      "Epoch:  0035 D loss:-0.5132 G loss:-2.538\n",
      "Epoch:  0035 D loss:-0.4291 G loss:-2.505\n",
      "Epoch:  0035 D loss:-0.4148 G loss:-2.715\n",
      "Epoch:  0035 D loss:-0.402 G loss:-2.804\n",
      "Epoch:  0035 D loss:-0.4116 G loss:-2.921\n",
      "Epoch:  0035 D loss:-0.4501 G loss:-2.702\n",
      "Epoch:  0035 D loss:-0.5083 G loss:-2.653\n",
      "Epoch:  0035 D loss:-0.5381 G loss:-2.489\n",
      "Epoch:  0035 D loss:-0.4515 G loss:-2.56\n",
      "Epoch:  0035 D loss:-0.4248 G loss:-2.757\n",
      "Epoch:  0035 D loss:-0.4688 G loss:-2.526\n",
      "Epoch:  0035 D loss:-0.5653 G loss:-2.73\n",
      "Epoch:  0035 D loss:-0.4745 G loss:-2.426\n",
      "Epoch:  0035 D loss:-0.5296 G loss:-2.49\n",
      "Epoch:  0035 D loss:-0.5384 G loss:-2.292\n",
      "Epoch:  0035 D loss:-0.4504 G loss:-2.51\n",
      "Epoch:  0035 D loss:-0.5574 G loss:-2.587\n",
      "Epoch:  0035 D loss:-0.4562 G loss:-2.626\n",
      "Epoch:  0035 D loss:-0.5131 G loss:-2.594\n",
      "Epoch:  0035 D loss:-0.3926 G loss:-2.679\n",
      "Epoch:  0035 D loss:-0.6095 G loss:-2.636\n",
      "Epoch:  0035 D loss:-0.4581 G loss:-2.494\n",
      "Epoch:  0035 D loss:-0.5261 G loss:-2.727\n",
      "Epoch:  0035 D loss:-0.475 G loss:-2.511\n",
      "Epoch:  0035 D loss:-0.515 G loss:-2.672\n",
      "Epoch:  0035 D loss:-0.5064 G loss:-2.498\n",
      "Epoch:  0035 D loss:-0.582 G loss:-2.504\n",
      "Epoch:  0035 D loss:-0.5132 G loss:-2.568\n",
      "Epoch:  0035 D loss:-0.4751 G loss:-2.276\n",
      "Epoch:  0035 D loss:-0.4014 G loss:-2.702\n",
      "Epoch:  0035 D loss:-0.5466 G loss:-2.519\n",
      "Epoch:  0035 D loss:-0.5287 G loss:-2.43\n",
      "Epoch:  0035 D loss:-0.4405 G loss:-2.675\n",
      "Epoch:  0035 D loss:-0.5016 G loss:-2.364\n",
      "Epoch:  0035 D loss:-0.5529 G loss:-2.341\n",
      "Epoch:  0035 D loss:-0.5845 G loss:-2.648\n",
      "Epoch:  0035 D loss:-0.5558 G loss:-2.259\n",
      "Epoch:  0035 D loss:-0.4813 G loss:-2.455\n",
      "Epoch:  0035 D loss:-0.5199 G loss:-2.529\n",
      "Epoch:  0035 D loss:-0.4897 G loss:-2.693\n",
      "Epoch:  0035 D loss:-0.4229 G loss:-2.744\n",
      "Epoch:  0035 D loss:-0.4333 G loss:-2.435\n",
      "Epoch:  0035 D loss:-0.522 G loss:-2.559\n",
      "Epoch:  0035 D loss:-0.6284 G loss:-2.518\n",
      "Epoch:  0035 D loss:-0.5797 G loss:-2.565\n",
      "Epoch:  0035 D loss:-0.4818 G loss:-2.661\n",
      "Epoch:  0035 D loss:-0.503 G loss:-2.463\n",
      "Epoch:  0035 D loss:-0.5554 G loss:-2.371\n",
      "Epoch:  0035 D loss:-0.4548 G loss:-2.396\n",
      "Epoch:  0035 D loss:-0.5106 G loss:-2.335\n",
      "Epoch:  0035 D loss:-0.3992 G loss:-2.62\n",
      "Epoch:  0035 D loss:-0.4436 G loss:-2.411\n",
      "Epoch:  0035 D loss:-0.5079 G loss:-2.504\n",
      "Epoch:  0035 D loss:-0.4755 G loss:-2.601\n",
      "Epoch:  0035 D loss:-0.4631 G loss:-2.425\n",
      "Epoch:  0035 D loss:-0.4662 G loss:-2.612\n",
      "Epoch:  0035 D loss:-0.5525 G loss:-2.437\n",
      "Epoch:  0035 D loss:-0.4662 G loss:-2.719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0035 D loss:-0.5286 G loss:-2.787\n",
      "Epoch:  0035 D loss:-0.5543 G loss:-2.696\n",
      "Epoch:  0035 D loss:-0.5204 G loss:-2.828\n",
      "Epoch:  0035 D loss:-0.4506 G loss:-2.564\n",
      "Epoch:  0035 D loss:-0.531 G loss:-2.619\n",
      "Epoch:  0035 D loss:-0.4966 G loss:-2.696\n",
      "Epoch:  0035 D loss:-0.367 G loss:-2.654\n",
      "Epoch:  0035 D loss:-0.5515 G loss:-2.488\n",
      "Epoch:  0035 D loss:-0.6017 G loss:-2.4\n",
      "Epoch:  0035 D loss:-0.6078 G loss:-2.122\n",
      "Epoch:  0035 D loss:-0.4978 G loss:-2.495\n",
      "Epoch:  0035 D loss:-0.5516 G loss:-2.537\n",
      "Epoch:  0035 D loss:-0.5225 G loss:-2.349\n",
      "Epoch:  0035 D loss:-0.5248 G loss:-2.459\n",
      "Epoch:  0035 D loss:-0.6291 G loss:-2.326\n",
      "Epoch:  0035 D loss:-0.5875 G loss:-2.417\n",
      "Epoch:  0035 D loss:-0.5044 G loss:-2.674\n",
      "Epoch:  0035 D loss:-0.6312 G loss:-2.676\n",
      "Epoch:  0035 D loss:-0.5689 G loss:-2.53\n",
      "Epoch:  0035 D loss:-0.4617 G loss:-2.89\n",
      "Epoch:  0035 D loss:-0.5188 G loss:-2.482\n",
      "Epoch:  0035 D loss:-0.3906 G loss:-2.667\n",
      "Epoch:  0035 D loss:-0.4241 G loss:-2.747\n",
      "Epoch:  0035 D loss:-0.4061 G loss:-2.775\n",
      "Epoch:  0035 D loss:-0.4639 G loss:-2.656\n",
      "Epoch:  0035 D loss:-0.4057 G loss:-2.578\n",
      "Epoch:  0035 D loss:-0.6532 G loss:-2.477\n",
      "Epoch:  0035 D loss:-0.5105 G loss:-2.592\n",
      "Epoch:  0035 D loss:-0.4013 G loss:-2.611\n",
      "Epoch:  0035 D loss:-0.6249 G loss:-2.596\n",
      "Epoch:  0035 D loss:-0.3782 G loss:-2.677\n",
      "Epoch:  0035 D loss:-0.5194 G loss:-2.667\n",
      "Epoch:  0035 D loss:-0.4819 G loss:-2.527\n",
      "Epoch:  0035 D loss:-0.431 G loss:-2.692\n",
      "Epoch:  0035 D loss:-0.4207 G loss:-2.753\n",
      "Epoch:  0035 D loss:-0.3809 G loss:-2.599\n",
      "Epoch:  0035 D loss:-0.448 G loss:-2.492\n",
      "Epoch:  0035 D loss:-0.4412 G loss:-2.668\n",
      "Epoch:  0035 D loss:-0.4512 G loss:-2.869\n",
      "Epoch:  0035 D loss:-0.4199 G loss:-2.677\n",
      "Epoch:  0035 D loss:-0.4924 G loss:-2.72\n",
      "Epoch:  0035 D loss:-0.5098 G loss:-2.638\n",
      "Epoch:  0035 D loss:-0.5805 G loss:-2.614\n",
      "Epoch:  0035 D loss:-0.4824 G loss:-2.91\n",
      "Epoch:  0035 D loss:-0.4447 G loss:-2.414\n",
      "Epoch:  0035 D loss:-0.4371 G loss:-2.453\n",
      "Epoch:  0035 D loss:-0.424 G loss:-2.569\n",
      "Epoch:  0035 D loss:-0.4057 G loss:-2.743\n",
      "Epoch:  0035 D loss:-0.4335 G loss:-2.479\n",
      "Epoch:  0035 D loss:-0.3715 G loss:-2.748\n",
      "Epoch:  0035 D loss:-0.4205 G loss:-2.713\n",
      "Epoch:  0035 D loss:-0.5275 G loss:-2.837\n",
      "Epoch:  0035 D loss:-0.5331 G loss:-2.586\n",
      "Epoch:  0035 D loss:-0.4441 G loss:-2.46\n",
      "Epoch:  0035 D loss:-0.425 G loss:-2.547\n",
      "Epoch:  0035 D loss:-0.4009 G loss:-2.762\n",
      "Epoch:  0035 D loss:-0.4269 G loss:-2.591\n",
      "Epoch:  0035 D loss:-0.4518 G loss:-2.446\n",
      "Epoch:  0035 D loss:-0.4919 G loss:-2.727\n",
      "Epoch:  0035 D loss:-0.6298 G loss:-2.402\n",
      "Epoch:  0035 D loss:-0.4698 G loss:-2.784\n",
      "Epoch:  0035 D loss:-0.5772 G loss:-2.86\n",
      "Epoch:  0035 D loss:-0.4374 G loss:-2.738\n",
      "Epoch:  0035 D loss:-0.6137 G loss:-2.74\n",
      "Epoch:  0035 D loss:-0.4231 G loss:-2.781\n",
      "Epoch:  0035 D loss:-0.4673 G loss:-2.705\n",
      "Epoch:  0035 D loss:-0.4544 G loss:-2.862\n",
      "Epoch:  0035 D loss:-0.5078 G loss:-2.617\n",
      "Epoch:  0035 D loss:-0.6038 G loss:-2.356\n",
      "Epoch:  0035 D loss:-0.4563 G loss:-2.478\n",
      "Epoch:  0035 D loss:-0.4615 G loss:-2.519\n",
      "Epoch:  0035 D loss:-0.5627 G loss:-2.485\n",
      "Epoch:  0035 D loss:-0.4843 G loss:-2.426\n",
      "Epoch:  0035 D loss:-0.4985 G loss:-2.714\n",
      "Epoch:  0035 D loss:-0.4577 G loss:-2.498\n",
      "Epoch:  0035 D loss:-0.5213 G loss:-2.635\n",
      "Epoch:  0035 D loss:-0.5081 G loss:-2.691\n",
      "Epoch:  0035 D loss:-0.4903 G loss:-2.714\n",
      "Epoch:  0035 D loss:-0.4184 G loss:-2.706\n",
      "Epoch:  0035 D loss:-0.5469 G loss:-2.716\n",
      "Epoch:  0035 D loss:-0.4809 G loss:-2.577\n",
      "Epoch:  0035 D loss:-0.5771 G loss:-2.826\n",
      "Epoch:  0035 D loss:-0.5341 G loss:-2.628\n",
      "Epoch:  0035 D loss:-0.6423 G loss:-2.551\n",
      "Epoch:  0035 D loss:-0.5032 G loss:-2.479\n",
      "Epoch:  0035 D loss:-0.5134 G loss:-2.623\n",
      "Epoch:  0035 D loss:-0.6711 G loss:-2.338\n",
      "Epoch:  0035 D loss:-0.5456 G loss:-2.691\n",
      "Epoch:  0035 D loss:-0.4476 G loss:-2.596\n",
      "Epoch:  0035 D loss:-0.564 G loss:-2.398\n",
      "Epoch:  0035 D loss:-0.5403 G loss:-2.542\n",
      "Epoch:  0035 D loss:-0.481 G loss:-2.496\n",
      "Epoch:  0035 D loss:-0.603 G loss:-2.595\n",
      "Epoch:  0035 D loss:-0.6254 G loss:-2.422\n",
      "Epoch:  0035 D loss:-0.4416 G loss:-2.534\n",
      "Epoch:  0035 D loss:-0.4484 G loss:-2.685\n",
      "Epoch:  0035 D loss:-0.4844 G loss:-2.532\n",
      "Epoch:  0035 D loss:-0.5946 G loss:-2.566\n",
      "Epoch:  0035 D loss:-0.5681 G loss:-2.507\n",
      "Epoch:  0035 D loss:-0.5505 G loss:-2.547\n",
      "Epoch:  0035 D loss:-0.6385 G loss:-2.319\n",
      "Epoch:  0035 D loss:-0.5541 G loss:-2.49\n",
      "Epoch:  0035 D loss:-0.4416 G loss:-2.621\n",
      "Epoch:  0035 D loss:-0.5236 G loss:-2.631\n",
      "Epoch:  0035 D loss:-0.5448 G loss:-2.474\n",
      "Epoch:  0035 D loss:-0.5021 G loss:-2.648\n",
      "Epoch:  0035 D loss:-0.6111 G loss:-2.782\n",
      "Epoch:  0035 D loss:-0.4538 G loss:-2.719\n",
      "Epoch:  0035 D loss:-0.4852 G loss:-2.598\n",
      "Epoch:  0035 D loss:-0.5158 G loss:-2.64\n",
      "Epoch:  0035 D loss:-0.4459 G loss:-2.612\n",
      "Epoch:  0035 D loss:-0.48 G loss:-2.772\n",
      "Epoch:  0035 D loss:-0.5242 G loss:-2.578\n",
      "Epoch:  0035 D loss:-0.45 G loss:-2.617\n",
      "Epoch:  0035 D loss:-0.5371 G loss:-2.657\n",
      "Epoch:  0035 D loss:-0.5447 G loss:-2.602\n",
      "Epoch:  0035 D loss:-0.4145 G loss:-2.778\n",
      "Epoch:  0035 D loss:-0.5898 G loss:-2.514\n",
      "Epoch:  0035 D loss:-0.5271 G loss:-2.609\n",
      "Epoch:  0035 D loss:-0.3912 G loss:-2.832\n",
      "Epoch:  0035 D loss:-0.5687 G loss:-2.76\n",
      "Epoch:  0035 D loss:-0.666 G loss:-2.683\n",
      "Epoch:  0035 D loss:-0.461 G loss:-2.533\n",
      "Epoch:  0035 D loss:-0.4363 G loss:-2.739\n",
      "Epoch:  0035 D loss:-0.6292 G loss:-2.766\n",
      "Epoch:  0035 D loss:-0.5004 G loss:-2.805\n",
      "Epoch:  0035 D loss:-0.4721 G loss:-2.64\n",
      "Epoch:  0036 D loss:-0.5447 G loss:-2.584\n",
      "Epoch:  0036 D loss:-0.5445 G loss:-2.664\n",
      "Epoch:  0036 D loss:-0.5229 G loss:-2.684\n",
      "Epoch:  0036 D loss:-0.4601 G loss:-2.623\n",
      "Epoch:  0036 D loss:-0.3842 G loss:-2.576\n",
      "Epoch:  0036 D loss:-0.4637 G loss:-2.692\n",
      "Epoch:  0036 D loss:-0.6147 G loss:-2.712\n",
      "Epoch:  0036 D loss:-0.4912 G loss:-2.503\n",
      "Epoch:  0036 D loss:-0.5048 G loss:-2.554\n",
      "Epoch:  0036 D loss:-0.4363 G loss:-2.56\n",
      "Epoch:  0036 D loss:-0.5068 G loss:-2.694\n",
      "Epoch:  0036 D loss:-0.5377 G loss:-2.642\n",
      "Epoch:  0036 D loss:-0.4697 G loss:-2.714\n",
      "Epoch:  0036 D loss:-0.6558 G loss:-2.376\n",
      "Epoch:  0036 D loss:-0.4547 G loss:-2.377\n",
      "Epoch:  0036 D loss:-0.5459 G loss:-2.48\n",
      "Epoch:  0036 D loss:-0.543 G loss:-2.508\n",
      "Epoch:  0036 D loss:-0.5099 G loss:-2.629\n",
      "Epoch:  0036 D loss:-0.5531 G loss:-2.807\n",
      "Epoch:  0036 D loss:-0.3502 G loss:-2.891\n",
      "Epoch:  0036 D loss:-0.5023 G loss:-2.686\n",
      "Epoch:  0036 D loss:-0.4354 G loss:-2.65\n",
      "Epoch:  0036 D loss:-0.3993 G loss:-2.717\n",
      "Epoch:  0036 D loss:-0.4086 G loss:-2.735\n",
      "Epoch:  0036 D loss:-0.4683 G loss:-2.781\n",
      "Epoch:  0036 D loss:-0.466 G loss:-2.602\n",
      "Epoch:  0036 D loss:-0.4491 G loss:-2.668\n",
      "Epoch:  0036 D loss:-0.5494 G loss:-2.601\n",
      "Epoch:  0036 D loss:-0.3866 G loss:-2.783\n",
      "Epoch:  0036 D loss:-0.4739 G loss:-2.666\n",
      "Epoch:  0036 D loss:-0.5199 G loss:-2.56\n",
      "Epoch:  0036 D loss:-0.3838 G loss:-2.805\n",
      "Epoch:  0036 D loss:-0.382 G loss:-2.545\n",
      "Epoch:  0036 D loss:-0.3969 G loss:-2.588\n",
      "Epoch:  0036 D loss:-0.5453 G loss:-2.421\n",
      "Epoch:  0036 D loss:-0.519 G loss:-2.762\n",
      "Epoch:  0036 D loss:-0.4469 G loss:-2.474\n",
      "Epoch:  0036 D loss:-0.6632 G loss:-2.445\n",
      "Epoch:  0036 D loss:-0.4369 G loss:-2.839\n",
      "Epoch:  0036 D loss:-0.596 G loss:-2.638\n",
      "Epoch:  0036 D loss:-0.4865 G loss:-2.718\n",
      "Epoch:  0036 D loss:-0.5157 G loss:-2.846\n",
      "Epoch:  0036 D loss:-0.5169 G loss:-2.893\n",
      "Epoch:  0036 D loss:-0.5598 G loss:-2.875\n",
      "Epoch:  0036 D loss:-0.5112 G loss:-2.658\n",
      "Epoch:  0036 D loss:-0.4994 G loss:-2.554\n",
      "Epoch:  0036 D loss:-0.5639 G loss:-2.58\n",
      "Epoch:  0036 D loss:-0.4282 G loss:-2.135\n",
      "Epoch:  0036 D loss:-0.5692 G loss:-2.202\n",
      "Epoch:  0036 D loss:-0.5015 G loss:-2.343\n",
      "Epoch:  0036 D loss:-0.5627 G loss:-2.342\n",
      "Epoch:  0036 D loss:-0.5363 G loss:-2.356\n",
      "Epoch:  0036 D loss:-0.6113 G loss:-2.614\n",
      "Epoch:  0036 D loss:-0.5112 G loss:-2.469\n",
      "Epoch:  0036 D loss:-0.4522 G loss:-2.467\n",
      "Epoch:  0036 D loss:-0.5803 G loss:-2.302\n",
      "Epoch:  0036 D loss:-0.4158 G loss:-2.526\n",
      "Epoch:  0036 D loss:-0.3814 G loss:-2.697\n",
      "Epoch:  0036 D loss:-0.3482 G loss:-2.921\n",
      "Epoch:  0036 D loss:-0.5749 G loss:-2.943\n",
      "Epoch:  0036 D loss:-0.5182 G loss:-2.906\n",
      "Epoch:  0036 D loss:-0.4222 G loss:-2.847\n",
      "Epoch:  0036 D loss:-0.5548 G loss:-2.906\n",
      "Epoch:  0036 D loss:-0.5036 G loss:-2.601\n",
      "Epoch:  0036 D loss:-0.5478 G loss:-2.618\n",
      "Epoch:  0036 D loss:-0.4376 G loss:-2.671\n",
      "Epoch:  0036 D loss:-0.5424 G loss:-2.473\n",
      "Epoch:  0036 D loss:-0.4244 G loss:-2.506\n",
      "Epoch:  0036 D loss:-0.4417 G loss:-2.435\n",
      "Epoch:  0036 D loss:-0.4618 G loss:-2.447\n",
      "Epoch:  0036 D loss:-0.4266 G loss:-2.462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0036 D loss:-0.5356 G loss:-2.464\n",
      "Epoch:  0036 D loss:-0.3899 G loss:-2.736\n",
      "Epoch:  0036 D loss:-0.3853 G loss:-2.825\n",
      "Epoch:  0036 D loss:-0.5678 G loss:-2.927\n",
      "Epoch:  0036 D loss:-0.7135 G loss:-2.588\n",
      "Epoch:  0036 D loss:-0.4331 G loss:-2.916\n",
      "Epoch:  0036 D loss:-0.4893 G loss:-2.71\n",
      "Epoch:  0036 D loss:-0.4674 G loss:-2.698\n",
      "Epoch:  0036 D loss:-0.4483 G loss:-2.669\n",
      "Epoch:  0036 D loss:-0.5351 G loss:-2.859\n",
      "Epoch:  0036 D loss:-0.3836 G loss:-2.643\n",
      "Epoch:  0036 D loss:-0.4984 G loss:-2.74\n",
      "Epoch:  0036 D loss:-0.5042 G loss:-2.503\n",
      "Epoch:  0036 D loss:-0.4267 G loss:-2.465\n",
      "Epoch:  0036 D loss:-0.5665 G loss:-2.405\n",
      "Epoch:  0036 D loss:-0.5236 G loss:-2.382\n",
      "Epoch:  0036 D loss:-0.458 G loss:-2.517\n",
      "Epoch:  0036 D loss:-0.4413 G loss:-2.67\n",
      "Epoch:  0036 D loss:-0.4673 G loss:-2.6\n",
      "Epoch:  0036 D loss:-0.5614 G loss:-2.299\n",
      "Epoch:  0036 D loss:-0.4426 G loss:-2.621\n",
      "Epoch:  0036 D loss:-0.529 G loss:-2.604\n",
      "Epoch:  0036 D loss:-0.552 G loss:-2.559\n",
      "Epoch:  0036 D loss:-0.5276 G loss:-2.461\n",
      "Epoch:  0036 D loss:-0.4069 G loss:-2.576\n",
      "Epoch:  0036 D loss:-0.4439 G loss:-2.565\n",
      "Epoch:  0036 D loss:-0.5603 G loss:-2.56\n",
      "Epoch:  0036 D loss:-0.4772 G loss:-2.688\n",
      "Epoch:  0036 D loss:-0.5034 G loss:-2.585\n",
      "Epoch:  0036 D loss:-0.4693 G loss:-2.372\n",
      "Epoch:  0036 D loss:-0.3555 G loss:-2.794\n",
      "Epoch:  0036 D loss:-0.6017 G loss:-2.708\n",
      "Epoch:  0036 D loss:-0.4493 G loss:-2.791\n",
      "Epoch:  0036 D loss:-0.4354 G loss:-2.654\n",
      "Epoch:  0036 D loss:-0.4839 G loss:-2.912\n",
      "Epoch:  0036 D loss:-0.4685 G loss:-2.666\n",
      "Epoch:  0036 D loss:-0.334 G loss:-3.031\n",
      "Epoch:  0036 D loss:-0.5061 G loss:-2.896\n",
      "Epoch:  0036 D loss:-0.4179 G loss:-2.98\n",
      "Epoch:  0036 D loss:-0.7067 G loss:-2.539\n",
      "Epoch:  0036 D loss:-0.454 G loss:-2.522\n",
      "Epoch:  0036 D loss:-0.5203 G loss:-2.492\n",
      "Epoch:  0036 D loss:-0.5171 G loss:-2.435\n",
      "Epoch:  0036 D loss:-0.5356 G loss:-2.727\n",
      "Epoch:  0036 D loss:-0.386 G loss:-2.383\n",
      "Epoch:  0036 D loss:-0.4486 G loss:-2.677\n",
      "Epoch:  0036 D loss:-0.4709 G loss:-2.587\n",
      "Epoch:  0036 D loss:-0.481 G loss:-2.67\n",
      "Epoch:  0036 D loss:-0.5382 G loss:-2.689\n",
      "Epoch:  0036 D loss:-0.4516 G loss:-2.507\n",
      "Epoch:  0036 D loss:-0.5473 G loss:-2.537\n",
      "Epoch:  0036 D loss:-0.3462 G loss:-2.895\n",
      "Epoch:  0036 D loss:-0.3671 G loss:-2.656\n",
      "Epoch:  0036 D loss:-0.6094 G loss:-2.556\n",
      "Epoch:  0036 D loss:-0.4665 G loss:-2.846\n",
      "Epoch:  0036 D loss:-0.3983 G loss:-2.862\n",
      "Epoch:  0036 D loss:-0.5696 G loss:-2.514\n",
      "Epoch:  0036 D loss:-0.4257 G loss:-2.707\n",
      "Epoch:  0036 D loss:-0.4853 G loss:-2.529\n",
      "Epoch:  0036 D loss:-0.5139 G loss:-2.333\n",
      "Epoch:  0036 D loss:-0.547 G loss:-2.321\n",
      "Epoch:  0036 D loss:-0.603 G loss:-2.476\n",
      "Epoch:  0036 D loss:-0.4183 G loss:-2.679\n",
      "Epoch:  0036 D loss:-0.3815 G loss:-2.497\n",
      "Epoch:  0036 D loss:-0.6066 G loss:-2.609\n",
      "Epoch:  0036 D loss:-0.5066 G loss:-2.522\n",
      "Epoch:  0036 D loss:-0.5379 G loss:-2.335\n",
      "Epoch:  0036 D loss:-0.5156 G loss:-2.408\n",
      "Epoch:  0036 D loss:-0.4143 G loss:-2.889\n",
      "Epoch:  0036 D loss:-0.5506 G loss:-2.651\n",
      "Epoch:  0036 D loss:-0.7356 G loss:-2.701\n",
      "Epoch:  0036 D loss:-0.5044 G loss:-2.471\n",
      "Epoch:  0036 D loss:-0.5175 G loss:-2.484\n",
      "Epoch:  0036 D loss:-0.4919 G loss:-2.769\n",
      "Epoch:  0036 D loss:-0.4507 G loss:-2.671\n",
      "Epoch:  0036 D loss:-0.4832 G loss:-2.581\n",
      "Epoch:  0036 D loss:-0.5268 G loss:-2.488\n",
      "Epoch:  0036 D loss:-0.5407 G loss:-2.439\n",
      "Epoch:  0036 D loss:-0.4556 G loss:-2.797\n",
      "Epoch:  0036 D loss:-0.4276 G loss:-2.696\n",
      "Epoch:  0036 D loss:-0.344 G loss:-2.503\n",
      "Epoch:  0036 D loss:-0.62 G loss:-2.525\n",
      "Epoch:  0036 D loss:-0.4837 G loss:-2.447\n",
      "Epoch:  0036 D loss:-0.5744 G loss:-2.407\n",
      "Epoch:  0036 D loss:-0.4889 G loss:-2.342\n",
      "Epoch:  0036 D loss:-0.478 G loss:-2.652\n",
      "Epoch:  0036 D loss:-0.5972 G loss:-2.274\n",
      "Epoch:  0036 D loss:-0.4707 G loss:-2.409\n",
      "Epoch:  0036 D loss:-0.477 G loss:-2.368\n",
      "Epoch:  0036 D loss:-0.4791 G loss:-2.364\n",
      "Epoch:  0036 D loss:-0.3557 G loss:-2.651\n",
      "Epoch:  0036 D loss:-0.4436 G loss:-2.558\n",
      "Epoch:  0036 D loss:-0.522 G loss:-2.425\n",
      "Epoch:  0036 D loss:-0.5239 G loss:-2.563\n",
      "Epoch:  0036 D loss:-0.5852 G loss:-2.604\n",
      "Epoch:  0036 D loss:-0.4572 G loss:-2.463\n",
      "Epoch:  0036 D loss:-0.6006 G loss:-2.491\n",
      "Epoch:  0036 D loss:-0.4744 G loss:-2.787\n",
      "Epoch:  0036 D loss:-0.6447 G loss:-2.505\n",
      "Epoch:  0036 D loss:-0.4923 G loss:-2.449\n",
      "Epoch:  0036 D loss:-0.5986 G loss:-2.423\n",
      "Epoch:  0036 D loss:-0.4832 G loss:-2.612\n",
      "Epoch:  0036 D loss:-0.589 G loss:-2.278\n",
      "Epoch:  0036 D loss:-0.4449 G loss:-2.422\n",
      "Epoch:  0036 D loss:-0.5301 G loss:-2.339\n",
      "Epoch:  0036 D loss:-0.6229 G loss:-2.351\n",
      "Epoch:  0036 D loss:-0.4511 G loss:-2.291\n",
      "Epoch:  0036 D loss:-0.5304 G loss:-2.421\n",
      "Epoch:  0036 D loss:-0.5659 G loss:-2.417\n",
      "Epoch:  0036 D loss:-0.4887 G loss:-2.435\n",
      "Epoch:  0036 D loss:-0.532 G loss:-2.5\n",
      "Epoch:  0036 D loss:-0.6236 G loss:-2.484\n",
      "Epoch:  0036 D loss:-0.5561 G loss:-2.489\n",
      "Epoch:  0036 D loss:-0.6082 G loss:-2.293\n",
      "Epoch:  0036 D loss:-0.5045 G loss:-2.5\n",
      "Epoch:  0036 D loss:-0.3835 G loss:-2.523\n",
      "Epoch:  0036 D loss:-0.439 G loss:-2.301\n",
      "Epoch:  0036 D loss:-0.5073 G loss:-2.44\n",
      "Epoch:  0036 D loss:-0.5608 G loss:-2.377\n",
      "Epoch:  0036 D loss:-0.6204 G loss:-2.379\n",
      "Epoch:  0036 D loss:-0.5544 G loss:-2.625\n",
      "Epoch:  0036 D loss:-0.4791 G loss:-2.517\n",
      "Epoch:  0036 D loss:-0.6784 G loss:-2.455\n",
      "Epoch:  0036 D loss:-0.4054 G loss:-2.498\n",
      "Epoch:  0036 D loss:-0.3785 G loss:-2.474\n",
      "Epoch:  0036 D loss:-0.6439 G loss:-2.259\n",
      "Epoch:  0036 D loss:-0.5538 G loss:-2.359\n",
      "Epoch:  0036 D loss:-0.5957 G loss:-2.381\n",
      "Epoch:  0036 D loss:-0.4957 G loss:-2.388\n",
      "Epoch:  0036 D loss:-0.5267 G loss:-2.367\n",
      "Epoch:  0036 D loss:-0.6255 G loss:-2.333\n",
      "Epoch:  0036 D loss:-0.4904 G loss:-2.542\n",
      "Epoch:  0036 D loss:-0.5752 G loss:-2.73\n",
      "Epoch:  0036 D loss:-0.6272 G loss:-2.522\n",
      "Epoch:  0036 D loss:-0.5413 G loss:-2.436\n",
      "Epoch:  0036 D loss:-0.4537 G loss:-2.311\n",
      "Epoch:  0036 D loss:-0.6072 G loss:-2.053\n",
      "Epoch:  0036 D loss:-0.577 G loss:-2.24\n",
      "Epoch:  0036 D loss:-0.5935 G loss:-2.212\n",
      "Epoch:  0036 D loss:-0.6052 G loss:-2.473\n",
      "Epoch:  0036 D loss:-0.5007 G loss:-2.238\n",
      "Epoch:  0036 D loss:-0.5593 G loss:-2.09\n",
      "Epoch:  0036 D loss:-0.6208 G loss:-2.464\n",
      "Epoch:  0036 D loss:-0.7136 G loss:-2.261\n",
      "Epoch:  0036 D loss:-0.685 G loss:-2.331\n",
      "Epoch:  0036 D loss:-0.6008 G loss:-2.465\n",
      "Epoch:  0036 D loss:-0.4544 G loss:-2.532\n",
      "Epoch:  0036 D loss:-0.5264 G loss:-2.396\n",
      "Epoch:  0036 D loss:-0.444 G loss:-2.391\n",
      "Epoch:  0036 D loss:-0.4797 G loss:-2.447\n",
      "Epoch:  0036 D loss:-0.5162 G loss:-2.629\n",
      "Epoch:  0036 D loss:-0.5252 G loss:-2.626\n",
      "Epoch:  0036 D loss:-0.4583 G loss:-2.504\n",
      "Epoch:  0036 D loss:-0.5845 G loss:-2.706\n",
      "Epoch:  0036 D loss:-0.4945 G loss:-2.533\n",
      "Epoch:  0036 D loss:-0.565 G loss:-2.531\n",
      "Epoch:  0036 D loss:-0.534 G loss:-2.571\n",
      "Epoch:  0036 D loss:-0.5374 G loss:-2.614\n",
      "Epoch:  0036 D loss:-0.6171 G loss:-2.087\n",
      "Epoch:  0036 D loss:-0.496 G loss:-2.285\n",
      "Epoch:  0036 D loss:-0.4598 G loss:-2.49\n",
      "Epoch:  0036 D loss:-0.5115 G loss:-2.588\n",
      "Epoch:  0036 D loss:-0.426 G loss:-2.458\n",
      "Epoch:  0036 D loss:-0.5573 G loss:-2.242\n",
      "Epoch:  0036 D loss:-0.5362 G loss:-2.508\n",
      "Epoch:  0036 D loss:-0.4893 G loss:-2.613\n",
      "Epoch:  0036 D loss:-0.4495 G loss:-2.589\n",
      "Epoch:  0036 D loss:-0.5786 G loss:-2.769\n",
      "Epoch:  0036 D loss:-0.5327 G loss:-2.506\n",
      "Epoch:  0036 D loss:-0.6569 G loss:-2.772\n",
      "Epoch:  0036 D loss:-0.5987 G loss:-2.56\n",
      "Epoch:  0036 D loss:-0.5681 G loss:-2.582\n",
      "Epoch:  0036 D loss:-0.5757 G loss:-2.726\n",
      "Epoch:  0036 D loss:-0.4565 G loss:-2.376\n",
      "Epoch:  0036 D loss:-0.4541 G loss:-2.416\n",
      "Epoch:  0036 D loss:-0.6272 G loss:-2.334\n",
      "Epoch:  0036 D loss:-0.507 G loss:-2.488\n",
      "Epoch:  0036 D loss:-0.6948 G loss:-2.26\n",
      "Epoch:  0036 D loss:-0.5193 G loss:-2.581\n",
      "Epoch:  0036 D loss:-0.5369 G loss:-2.458\n",
      "Epoch:  0036 D loss:-0.4776 G loss:-2.33\n",
      "Epoch:  0036 D loss:-0.5823 G loss:-2.344\n",
      "Epoch:  0036 D loss:-0.6236 G loss:-2.176\n",
      "Epoch:  0036 D loss:-0.418 G loss:-2.652\n",
      "Epoch:  0036 D loss:-0.5305 G loss:-2.293\n",
      "Epoch:  0036 D loss:-0.6506 G loss:-2.234\n",
      "Epoch:  0036 D loss:-0.5386 G loss:-2.382\n",
      "Epoch:  0036 D loss:-0.5209 G loss:-2.626\n",
      "Epoch:  0036 D loss:-0.5192 G loss:-2.704\n",
      "Epoch:  0036 D loss:-0.5153 G loss:-2.598\n",
      "Epoch:  0036 D loss:-0.509 G loss:-2.667\n",
      "Epoch:  0036 D loss:-0.569 G loss:-2.534\n",
      "Epoch:  0036 D loss:-0.6378 G loss:-2.573\n",
      "Epoch:  0036 D loss:-0.5232 G loss:-2.744\n",
      "Epoch:  0036 D loss:-0.5325 G loss:-2.399\n",
      "Epoch:  0036 D loss:-0.535 G loss:-2.373\n",
      "Epoch:  0036 D loss:-0.6831 G loss:-2.184\n",
      "Epoch:  0036 D loss:-0.4587 G loss:-2.25\n",
      "Epoch:  0036 D loss:-0.6276 G loss:-2.062\n",
      "Epoch:  0036 D loss:-0.4983 G loss:-2.268\n",
      "Epoch:  0036 D loss:-0.603 G loss:-2.309\n",
      "Epoch:  0036 D loss:-0.5365 G loss:-2.37\n",
      "Epoch:  0036 D loss:-0.482 G loss:-2.624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0036 D loss:-0.5309 G loss:-2.503\n",
      "Epoch:  0036 D loss:-0.3455 G loss:-2.618\n",
      "Epoch:  0036 D loss:-0.5259 G loss:-2.727\n",
      "Epoch:  0036 D loss:-0.5596 G loss:-2.674\n",
      "Epoch:  0036 D loss:-0.583 G loss:-2.581\n",
      "Epoch:  0036 D loss:-0.4762 G loss:-2.806\n",
      "Epoch:  0036 D loss:-0.4824 G loss:-2.537\n",
      "Epoch:  0036 D loss:-0.4924 G loss:-2.847\n",
      "Epoch:  0036 D loss:-0.408 G loss:-2.777\n",
      "Epoch:  0036 D loss:-0.3704 G loss:-2.947\n",
      "Epoch:  0036 D loss:-0.5853 G loss:-2.63\n",
      "Epoch:  0036 D loss:-0.4146 G loss:-2.625\n",
      "Epoch:  0036 D loss:-0.4714 G loss:-2.416\n",
      "Epoch:  0036 D loss:-0.4351 G loss:-2.505\n",
      "Epoch:  0036 D loss:-0.5061 G loss:-2.296\n",
      "Epoch:  0036 D loss:-0.5374 G loss:-2.434\n",
      "Epoch:  0036 D loss:-0.5056 G loss:-2.33\n",
      "Epoch:  0036 D loss:-0.4497 G loss:-2.559\n",
      "Epoch:  0036 D loss:-0.5136 G loss:-2.547\n",
      "Epoch:  0036 D loss:-0.8047 G loss:-2.522\n",
      "Epoch:  0036 D loss:-0.414 G loss:-2.85\n",
      "Epoch:  0036 D loss:-0.5522 G loss:-2.719\n",
      "Epoch:  0036 D loss:-0.4757 G loss:-2.715\n",
      "Epoch:  0036 D loss:-0.4889 G loss:-2.806\n",
      "Epoch:  0036 D loss:-0.4445 G loss:-2.583\n",
      "Epoch:  0036 D loss:-0.4721 G loss:-2.582\n",
      "Epoch:  0036 D loss:-0.4762 G loss:-2.59\n",
      "Epoch:  0036 D loss:-0.4347 G loss:-2.323\n",
      "Epoch:  0036 D loss:-0.4505 G loss:-2.375\n",
      "Epoch:  0036 D loss:-0.4826 G loss:-2.436\n",
      "Epoch:  0036 D loss:-0.683 G loss:-2.533\n",
      "Epoch:  0036 D loss:-0.4529 G loss:-2.623\n",
      "Epoch:  0036 D loss:-0.4545 G loss:-2.703\n",
      "Epoch:  0036 D loss:-0.4258 G loss:-2.484\n",
      "Epoch:  0036 D loss:-0.4446 G loss:-2.481\n",
      "Epoch:  0036 D loss:-0.5191 G loss:-2.879\n",
      "Epoch:  0036 D loss:-0.4664 G loss:-2.84\n",
      "Epoch:  0036 D loss:-0.5557 G loss:-2.672\n",
      "Epoch:  0036 D loss:-0.4289 G loss:-3.021\n",
      "Epoch:  0036 D loss:-0.4895 G loss:-2.765\n",
      "Epoch:  0036 D loss:-0.4531 G loss:-2.512\n",
      "Epoch:  0036 D loss:-0.4008 G loss:-2.747\n",
      "Epoch:  0036 D loss:-0.4736 G loss:-2.569\n",
      "Epoch:  0036 D loss:-0.5119 G loss:-2.335\n",
      "Epoch:  0036 D loss:-0.4375 G loss:-2.498\n",
      "Epoch:  0036 D loss:-0.4904 G loss:-2.747\n",
      "Epoch:  0036 D loss:-0.4856 G loss:-2.291\n",
      "Epoch:  0036 D loss:-0.3587 G loss:-2.719\n",
      "Epoch:  0036 D loss:-0.518 G loss:-2.433\n",
      "Epoch:  0036 D loss:-0.3795 G loss:-2.777\n",
      "Epoch:  0036 D loss:-0.4249 G loss:-2.651\n",
      "Epoch:  0036 D loss:-0.4165 G loss:-2.575\n",
      "Epoch:  0036 D loss:-0.4931 G loss:-2.533\n",
      "Epoch:  0036 D loss:-0.4202 G loss:-2.662\n",
      "Epoch:  0036 D loss:-0.3777 G loss:-2.746\n",
      "Epoch:  0036 D loss:-0.4277 G loss:-2.514\n",
      "Epoch:  0036 D loss:-0.4039 G loss:-2.713\n",
      "Epoch:  0036 D loss:-0.4276 G loss:-2.719\n",
      "Epoch:  0036 D loss:-0.5912 G loss:-2.957\n",
      "Epoch:  0036 D loss:-0.442 G loss:-2.747\n",
      "Epoch:  0036 D loss:-0.4728 G loss:-2.692\n",
      "Epoch:  0036 D loss:-0.4899 G loss:-2.647\n",
      "Epoch:  0036 D loss:-0.4342 G loss:-2.716\n",
      "Epoch:  0036 D loss:-0.5226 G loss:-2.688\n",
      "Epoch:  0036 D loss:-0.3929 G loss:-2.611\n",
      "Epoch:  0036 D loss:-0.4743 G loss:-2.237\n",
      "Epoch:  0036 D loss:-0.5367 G loss:-2.451\n",
      "Epoch:  0036 D loss:-0.4843 G loss:-2.404\n",
      "Epoch:  0036 D loss:-0.4346 G loss:-2.731\n",
      "Epoch:  0036 D loss:-0.3739 G loss:-2.543\n",
      "Epoch:  0036 D loss:-0.4883 G loss:-2.654\n",
      "Epoch:  0036 D loss:-0.4491 G loss:-2.393\n",
      "Epoch:  0036 D loss:-0.4482 G loss:-2.782\n",
      "Epoch:  0036 D loss:-0.5593 G loss:-2.719\n",
      "Epoch:  0036 D loss:-0.4909 G loss:-2.725\n",
      "Epoch:  0036 D loss:-0.5416 G loss:-2.621\n",
      "Epoch:  0036 D loss:-0.4322 G loss:-2.782\n",
      "Epoch:  0036 D loss:-0.5872 G loss:-2.634\n",
      "Epoch:  0036 D loss:-0.512 G loss:-2.67\n",
      "Epoch:  0036 D loss:-0.529 G loss:-2.599\n",
      "Epoch:  0036 D loss:-0.4412 G loss:-2.732\n",
      "Epoch:  0036 D loss:-0.5351 G loss:-2.523\n",
      "Epoch:  0036 D loss:-0.5882 G loss:-2.339\n",
      "Epoch:  0036 D loss:-0.543 G loss:-2.451\n",
      "Epoch:  0036 D loss:-0.6 G loss:-2.33\n",
      "Epoch:  0036 D loss:-0.5574 G loss:-2.417\n",
      "Epoch:  0036 D loss:-0.5656 G loss:-2.147\n",
      "Epoch:  0036 D loss:-0.4971 G loss:-2.318\n",
      "Epoch:  0036 D loss:-0.5984 G loss:-2.369\n",
      "Epoch:  0036 D loss:-0.6178 G loss:-2.232\n",
      "Epoch:  0036 D loss:-0.695 G loss:-2.418\n",
      "Epoch:  0036 D loss:-0.7262 G loss:-2.368\n",
      "Epoch:  0036 D loss:-0.5866 G loss:-2.563\n",
      "Epoch:  0036 D loss:-0.6028 G loss:-2.268\n",
      "Epoch:  0036 D loss:-0.6108 G loss:-2.816\n",
      "Epoch:  0036 D loss:-0.5773 G loss:-2.561\n",
      "Epoch:  0036 D loss:-0.5127 G loss:-2.628\n",
      "Epoch:  0036 D loss:-0.5612 G loss:-2.475\n",
      "Epoch:  0036 D loss:-0.5262 G loss:-2.413\n",
      "Epoch:  0036 D loss:-0.5425 G loss:-2.262\n",
      "Epoch:  0036 D loss:-0.6989 G loss:-2.385\n",
      "Epoch:  0036 D loss:-0.5743 G loss:-2.48\n",
      "Epoch:  0036 D loss:-0.6691 G loss:-2.14\n",
      "Epoch:  0036 D loss:-0.5216 G loss:-2.297\n",
      "Epoch:  0036 D loss:-0.6512 G loss:-2.081\n",
      "Epoch:  0036 D loss:-0.5662 G loss:-2.237\n",
      "Epoch:  0036 D loss:-0.5817 G loss:-2.305\n",
      "Epoch:  0036 D loss:-0.6804 G loss:-2.292\n",
      "Epoch:  0036 D loss:-0.413 G loss:-2.735\n",
      "Epoch:  0036 D loss:-0.4569 G loss:-2.494\n",
      "Epoch:  0036 D loss:-0.4924 G loss:-2.693\n",
      "Epoch:  0036 D loss:-0.5935 G loss:-2.472\n",
      "Epoch:  0036 D loss:-0.5354 G loss:-2.679\n",
      "Epoch:  0036 D loss:-0.5725 G loss:-2.694\n",
      "Epoch:  0036 D loss:-0.6025 G loss:-2.887\n",
      "Epoch:  0036 D loss:-0.5008 G loss:-2.686\n",
      "Epoch:  0036 D loss:-0.6461 G loss:-2.48\n",
      "Epoch:  0036 D loss:-0.5817 G loss:-2.297\n",
      "Epoch:  0036 D loss:-0.5853 G loss:-2.308\n",
      "Epoch:  0036 D loss:-0.6143 G loss:-2.303\n",
      "Epoch:  0036 D loss:-0.6384 G loss:-2.278\n",
      "Epoch:  0036 D loss:-0.5428 G loss:-2.246\n",
      "Epoch:  0036 D loss:-0.5542 G loss:-2.138\n",
      "Epoch:  0036 D loss:-0.6502 G loss:-2.114\n",
      "Epoch:  0036 D loss:-0.6321 G loss:-2.151\n",
      "Epoch:  0036 D loss:-0.729 G loss:-2.023\n",
      "Epoch:  0036 D loss:-0.6848 G loss:-2.207\n",
      "Epoch:  0036 D loss:-0.6766 G loss:-2.384\n",
      "Epoch:  0036 D loss:-0.6563 G loss:-2.661\n",
      "Epoch:  0036 D loss:-0.7177 G loss:-2.687\n",
      "Epoch:  0036 D loss:-0.4624 G loss:-2.714\n",
      "Epoch:  0036 D loss:-0.7788 G loss:-2.307\n",
      "Epoch:  0036 D loss:-0.4911 G loss:-2.6\n",
      "Epoch:  0036 D loss:-0.5699 G loss:-2.211\n",
      "Epoch:  0036 D loss:-0.4482 G loss:-2.516\n",
      "Epoch:  0036 D loss:-0.5084 G loss:-2.601\n",
      "Epoch:  0036 D loss:-0.5942 G loss:-2.286\n",
      "Epoch:  0036 D loss:-0.5835 G loss:-2.38\n",
      "Epoch:  0036 D loss:-0.5013 G loss:-2.502\n",
      "Epoch:  0036 D loss:-0.7344 G loss:-2.111\n",
      "Epoch:  0036 D loss:-0.6295 G loss:-2.317\n",
      "Epoch:  0036 D loss:-0.7067 G loss:-2.224\n",
      "Epoch:  0036 D loss:-0.7093 G loss:-2.47\n",
      "Epoch:  0036 D loss:-0.487 G loss:-2.418\n",
      "Epoch:  0036 D loss:-0.5579 G loss:-2.503\n",
      "Epoch:  0036 D loss:-0.4589 G loss:-2.435\n",
      "Epoch:  0036 D loss:-0.4481 G loss:-2.555\n",
      "Epoch:  0036 D loss:-0.6295 G loss:-2.506\n",
      "Epoch:  0036 D loss:-0.6015 G loss:-2.395\n",
      "Epoch:  0036 D loss:-0.5267 G loss:-2.394\n",
      "Epoch:  0036 D loss:-0.4418 G loss:-2.385\n",
      "Epoch:  0036 D loss:-0.6785 G loss:-2.448\n",
      "Epoch:  0036 D loss:-0.7123 G loss:-2.382\n",
      "Epoch:  0036 D loss:-0.5796 G loss:-2.506\n",
      "Epoch:  0036 D loss:-0.4866 G loss:-2.535\n",
      "Epoch:  0036 D loss:-0.4209 G loss:-2.669\n",
      "Epoch:  0036 D loss:-0.5633 G loss:-2.248\n",
      "Epoch:  0036 D loss:-0.5318 G loss:-2.229\n",
      "Epoch:  0036 D loss:-0.5088 G loss:-2.526\n",
      "Epoch:  0036 D loss:-0.5855 G loss:-2.393\n",
      "Epoch:  0036 D loss:-0.5558 G loss:-2.727\n",
      "Epoch:  0036 D loss:-0.5083 G loss:-2.297\n",
      "Epoch:  0036 D loss:-0.3892 G loss:-2.49\n",
      "Epoch:  0036 D loss:-0.5486 G loss:-2.391\n",
      "Epoch:  0036 D loss:-0.5265 G loss:-2.489\n",
      "Epoch:  0036 D loss:-0.4877 G loss:-2.402\n",
      "Epoch:  0036 D loss:-0.4793 G loss:-2.419\n",
      "Epoch:  0036 D loss:-0.4631 G loss:-2.545\n",
      "Epoch:  0036 D loss:-0.5253 G loss:-2.654\n",
      "Epoch:  0036 D loss:-0.4405 G loss:-2.735\n",
      "Epoch:  0036 D loss:-0.5772 G loss:-2.696\n",
      "Epoch:  0036 D loss:-0.5271 G loss:-2.71\n",
      "Epoch:  0036 D loss:-0.4861 G loss:-2.644\n",
      "Epoch:  0036 D loss:-0.7092 G loss:-2.216\n",
      "Epoch:  0036 D loss:-0.389 G loss:-2.489\n",
      "Epoch:  0036 D loss:-0.4367 G loss:-2.317\n",
      "Epoch:  0036 D loss:-0.5739 G loss:-2.402\n",
      "Epoch:  0036 D loss:-0.3834 G loss:-2.549\n",
      "Epoch:  0036 D loss:-0.6106 G loss:-2.312\n",
      "Epoch:  0036 D loss:-0.5661 G loss:-2.28\n",
      "Epoch:  0036 D loss:-0.4603 G loss:-2.429\n",
      "Epoch:  0036 D loss:-0.4933 G loss:-2.58\n",
      "Epoch:  0036 D loss:-0.5619 G loss:-2.489\n",
      "Epoch:  0036 D loss:-0.5027 G loss:-2.885\n",
      "Epoch:  0036 D loss:-0.4934 G loss:-2.821\n",
      "Epoch:  0036 D loss:-0.3711 G loss:-2.671\n",
      "Epoch:  0036 D loss:-0.4442 G loss:-2.894\n",
      "Epoch:  0036 D loss:-0.5874 G loss:-2.586\n",
      "Epoch:  0036 D loss:-0.4673 G loss:-2.718\n",
      "Epoch:  0036 D loss:-0.5171 G loss:-2.503\n",
      "Epoch:  0036 D loss:-0.4154 G loss:-2.671\n",
      "Epoch:  0036 D loss:-0.4147 G loss:-2.661\n",
      "Epoch:  0036 D loss:-0.5112 G loss:-2.483\n",
      "Epoch:  0036 D loss:-0.3654 G loss:-2.358\n",
      "Epoch:  0036 D loss:-0.6107 G loss:-2.534\n",
      "Epoch:  0036 D loss:-0.4478 G loss:-2.592\n",
      "Epoch:  0036 D loss:-0.3847 G loss:-2.52\n",
      "Epoch:  0036 D loss:-0.4522 G loss:-2.429\n",
      "Epoch:  0036 D loss:-0.5604 G loss:-2.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0036 D loss:-0.5225 G loss:-2.579\n",
      "Epoch:  0036 D loss:-0.4101 G loss:-2.726\n",
      "Epoch:  0036 D loss:-0.4962 G loss:-2.558\n",
      "Epoch:  0036 D loss:-0.3834 G loss:-2.608\n",
      "Epoch:  0036 D loss:-0.4895 G loss:-2.656\n",
      "Epoch:  0036 D loss:-0.4528 G loss:-2.911\n",
      "Epoch:  0036 D loss:-0.5547 G loss:-2.775\n",
      "Epoch:  0036 D loss:-0.3673 G loss:-2.827\n",
      "Epoch:  0036 D loss:-0.3994 G loss:-2.879\n",
      "Epoch:  0036 D loss:-0.4797 G loss:-2.869\n",
      "Epoch:  0036 D loss:-0.4492 G loss:-2.499\n",
      "Epoch:  0036 D loss:-0.407 G loss:-2.444\n",
      "Epoch:  0036 D loss:-0.5243 G loss:-2.346\n",
      "Epoch:  0036 D loss:-0.4332 G loss:-2.478\n",
      "Epoch:  0036 D loss:-0.4637 G loss:-2.403\n",
      "Epoch:  0036 D loss:-0.5087 G loss:-2.313\n",
      "Epoch:  0036 D loss:-0.4965 G loss:-2.415\n",
      "Epoch:  0036 D loss:-0.4965 G loss:-2.577\n",
      "Epoch:  0036 D loss:-0.4561 G loss:-2.83\n",
      "Epoch:  0036 D loss:-0.5242 G loss:-2.397\n",
      "Epoch:  0036 D loss:-0.4569 G loss:-2.617\n",
      "Epoch:  0036 D loss:-0.4851 G loss:-2.615\n",
      "Epoch:  0036 D loss:-0.4682 G loss:-2.551\n",
      "Epoch:  0036 D loss:-0.5542 G loss:-2.546\n",
      "Epoch:  0036 D loss:-0.5086 G loss:-2.814\n",
      "Epoch:  0036 D loss:-0.4539 G loss:-2.588\n",
      "Epoch:  0036 D loss:-0.4619 G loss:-2.616\n",
      "Epoch:  0036 D loss:-0.3954 G loss:-2.583\n",
      "Epoch:  0036 D loss:-0.5741 G loss:-2.784\n",
      "Epoch:  0036 D loss:-0.6452 G loss:-2.483\n",
      "Epoch:  0036 D loss:-0.536 G loss:-2.504\n",
      "Epoch:  0036 D loss:-0.5026 G loss:-2.375\n",
      "Epoch:  0036 D loss:-0.4942 G loss:-2.234\n",
      "Epoch:  0036 D loss:-0.5595 G loss:-2.371\n",
      "Epoch:  0036 D loss:-0.5352 G loss:-2.299\n",
      "Epoch:  0036 D loss:-0.4777 G loss:-2.249\n",
      "Epoch:  0036 D loss:-0.5128 G loss:-2.417\n",
      "Epoch:  0036 D loss:-0.4484 G loss:-2.402\n",
      "Epoch:  0036 D loss:-0.6074 G loss:-2.422\n",
      "Epoch:  0036 D loss:-0.5498 G loss:-2.325\n",
      "Epoch:  0036 D loss:-0.7148 G loss:-2.623\n",
      "Epoch:  0036 D loss:-0.5326 G loss:-2.49\n",
      "Epoch:  0036 D loss:-0.4729 G loss:-2.397\n",
      "Epoch:  0036 D loss:-0.5969 G loss:-2.306\n",
      "Epoch:  0036 D loss:-0.463 G loss:-2.418\n",
      "Epoch:  0036 D loss:-0.54 G loss:-2.53\n",
      "Epoch:  0036 D loss:-0.5774 G loss:-2.456\n",
      "Epoch:  0036 D loss:-0.478 G loss:-2.668\n",
      "Epoch:  0036 D loss:-0.5676 G loss:-2.628\n",
      "Epoch:  0036 D loss:-0.7026 G loss:-2.427\n",
      "Epoch:  0036 D loss:-0.5102 G loss:-2.332\n",
      "Epoch:  0036 D loss:-0.4337 G loss:-2.485\n",
      "Epoch:  0036 D loss:-0.5175 G loss:-2.113\n",
      "Epoch:  0036 D loss:-0.5869 G loss:-2.018\n",
      "Epoch:  0036 D loss:-0.492 G loss:-2.288\n",
      "Epoch:  0036 D loss:-0.5257 G loss:-2.208\n",
      "Epoch:  0036 D loss:-0.4889 G loss:-2.304\n",
      "Epoch:  0036 D loss:-0.4701 G loss:-2.294\n",
      "Epoch:  0036 D loss:-0.6665 G loss:-2.388\n",
      "Epoch:  0036 D loss:-0.6485 G loss:-2.569\n",
      "Epoch:  0036 D loss:-0.4206 G loss:-2.758\n",
      "Epoch:  0036 D loss:-0.5084 G loss:-2.473\n",
      "Epoch:  0036 D loss:-0.5253 G loss:-2.563\n",
      "Epoch:  0036 D loss:-0.5545 G loss:-2.59\n",
      "Epoch:  0036 D loss:-0.5464 G loss:-2.473\n",
      "Epoch:  0036 D loss:-0.5595 G loss:-2.354\n",
      "Epoch:  0036 D loss:-0.6617 G loss:-2.534\n",
      "Epoch:  0036 D loss:-0.6053 G loss:-2.301\n",
      "Epoch:  0036 D loss:-0.5 G loss:-2.361\n",
      "Epoch:  0036 D loss:-0.5915 G loss:-2.161\n",
      "Epoch:  0036 D loss:-0.6588 G loss:-2.113\n",
      "Epoch:  0036 D loss:-0.6685 G loss:-2.321\n",
      "Epoch:  0036 D loss:-0.6273 G loss:-2.274\n",
      "Epoch:  0036 D loss:-0.6077 G loss:-2.202\n",
      "Epoch:  0036 D loss:-0.4859 G loss:-2.284\n",
      "Epoch:  0036 D loss:-0.5905 G loss:-2.463\n",
      "Epoch:  0036 D loss:-0.5933 G loss:-2.383\n",
      "Epoch:  0037 D loss:-0.5507 G loss:-2.291\n",
      "Epoch:  0037 D loss:-0.4565 G loss:-2.358\n",
      "Epoch:  0037 D loss:-0.5697 G loss:-2.59\n",
      "Epoch:  0037 D loss:-0.5671 G loss:-2.283\n",
      "Epoch:  0037 D loss:-0.4962 G loss:-2.552\n",
      "Epoch:  0037 D loss:-0.4939 G loss:-2.499\n",
      "Epoch:  0037 D loss:-0.5684 G loss:-2.56\n",
      "Epoch:  0037 D loss:-0.7112 G loss:-2.625\n",
      "Epoch:  0037 D loss:-0.5825 G loss:-2.667\n",
      "Epoch:  0037 D loss:-0.4422 G loss:-2.492\n",
      "Epoch:  0037 D loss:-0.493 G loss:-2.244\n",
      "Epoch:  0037 D loss:-0.5408 G loss:-2.344\n",
      "Epoch:  0037 D loss:-0.5394 G loss:-2.324\n",
      "Epoch:  0037 D loss:-0.5174 G loss:-2.551\n",
      "Epoch:  0037 D loss:-0.5221 G loss:-2.558\n",
      "Epoch:  0037 D loss:-0.6263 G loss:-2.21\n",
      "Epoch:  0037 D loss:-0.5785 G loss:-2.467\n",
      "Epoch:  0037 D loss:-0.6317 G loss:-2.306\n",
      "Epoch:  0037 D loss:-0.4942 G loss:-2.257\n",
      "Epoch:  0037 D loss:-0.4944 G loss:-2.262\n",
      "Epoch:  0037 D loss:-0.5455 G loss:-2.222\n",
      "Epoch:  0037 D loss:-0.5914 G loss:-2.316\n",
      "Epoch:  0037 D loss:-0.4745 G loss:-2.506\n",
      "Epoch:  0037 D loss:-0.646 G loss:-2.643\n",
      "Epoch:  0037 D loss:-0.4628 G loss:-2.65\n",
      "Epoch:  0037 D loss:-0.554 G loss:-2.525\n",
      "Epoch:  0037 D loss:-0.5835 G loss:-2.568\n",
      "Epoch:  0037 D loss:-0.6327 G loss:-2.332\n",
      "Epoch:  0037 D loss:-0.7124 G loss:-2.095\n",
      "Epoch:  0037 D loss:-0.5283 G loss:-2.293\n",
      "Epoch:  0037 D loss:-0.5082 G loss:-2.407\n",
      "Epoch:  0037 D loss:-0.5426 G loss:-2.425\n",
      "Epoch:  0037 D loss:-0.6142 G loss:-2.336\n",
      "Epoch:  0037 D loss:-0.5054 G loss:-2.401\n",
      "Epoch:  0037 D loss:-0.5745 G loss:-2.504\n",
      "Epoch:  0037 D loss:-0.5164 G loss:-2.537\n",
      "Epoch:  0037 D loss:-0.6236 G loss:-2.382\n",
      "Epoch:  0037 D loss:-0.5331 G loss:-2.474\n",
      "Epoch:  0037 D loss:-0.38 G loss:-2.75\n",
      "Epoch:  0037 D loss:-0.5787 G loss:-2.56\n",
      "Epoch:  0037 D loss:-0.407 G loss:-2.742\n",
      "Epoch:  0037 D loss:-0.5589 G loss:-2.566\n",
      "Epoch:  0037 D loss:-0.4535 G loss:-2.667\n",
      "Epoch:  0037 D loss:-0.5219 G loss:-2.415\n",
      "Epoch:  0037 D loss:-0.481 G loss:-2.684\n",
      "Epoch:  0037 D loss:-0.5016 G loss:-2.77\n",
      "Epoch:  0037 D loss:-0.5303 G loss:-2.649\n",
      "Epoch:  0037 D loss:-0.4844 G loss:-2.732\n",
      "Epoch:  0037 D loss:-0.5262 G loss:-2.725\n",
      "Epoch:  0037 D loss:-0.4974 G loss:-2.409\n",
      "Epoch:  0037 D loss:-0.6238 G loss:-2.369\n",
      "Epoch:  0037 D loss:-0.6473 G loss:-2.226\n",
      "Epoch:  0037 D loss:-0.6487 G loss:-2.291\n",
      "Epoch:  0037 D loss:-0.5191 G loss:-2.291\n",
      "Epoch:  0037 D loss:-0.7295 G loss:-1.988\n",
      "Epoch:  0037 D loss:-0.6076 G loss:-2.013\n",
      "Epoch:  0037 D loss:-0.4655 G loss:-2.338\n",
      "Epoch:  0037 D loss:-0.5789 G loss:-2.146\n",
      "Epoch:  0037 D loss:-0.5158 G loss:-2.265\n",
      "Epoch:  0037 D loss:-0.4931 G loss:-2.594\n",
      "Epoch:  0037 D loss:-0.5779 G loss:-2.667\n",
      "Epoch:  0037 D loss:-0.4399 G loss:-2.603\n",
      "Epoch:  0037 D loss:-0.5183 G loss:-2.81\n",
      "Epoch:  0037 D loss:-0.5796 G loss:-2.602\n",
      "Epoch:  0037 D loss:-0.4836 G loss:-2.659\n",
      "Epoch:  0037 D loss:-0.4071 G loss:-2.905\n",
      "Epoch:  0037 D loss:-0.4771 G loss:-2.728\n",
      "Epoch:  0037 D loss:-0.5186 G loss:-2.5\n",
      "Epoch:  0037 D loss:-0.4602 G loss:-2.418\n",
      "Epoch:  0037 D loss:-0.479 G loss:-2.634\n",
      "Epoch:  0037 D loss:-0.4497 G loss:-2.442\n",
      "Epoch:  0037 D loss:-0.6497 G loss:-2.3\n",
      "Epoch:  0037 D loss:-0.4552 G loss:-2.29\n",
      "Epoch:  0037 D loss:-0.4836 G loss:-2.386\n",
      "Epoch:  0037 D loss:-0.4737 G loss:-2.6\n",
      "Epoch:  0037 D loss:-0.4436 G loss:-2.423\n",
      "Epoch:  0037 D loss:-0.4896 G loss:-2.554\n",
      "Epoch:  0037 D loss:-0.5283 G loss:-2.509\n",
      "Epoch:  0037 D loss:-0.4828 G loss:-2.582\n",
      "Epoch:  0037 D loss:-0.5131 G loss:-2.623\n",
      "Epoch:  0037 D loss:-0.6781 G loss:-2.661\n",
      "Epoch:  0037 D loss:-0.4904 G loss:-2.505\n",
      "Epoch:  0037 D loss:-0.4118 G loss:-2.646\n",
      "Epoch:  0037 D loss:-0.5679 G loss:-2.351\n",
      "Epoch:  0037 D loss:-0.595 G loss:-2.457\n",
      "Epoch:  0037 D loss:-0.5827 G loss:-2.319\n",
      "Epoch:  0037 D loss:-0.5053 G loss:-2.295\n",
      "Epoch:  0037 D loss:-0.5179 G loss:-2.313\n",
      "Epoch:  0037 D loss:-0.6514 G loss:-2.143\n",
      "Epoch:  0037 D loss:-0.6201 G loss:-2.3\n",
      "Epoch:  0037 D loss:-0.4952 G loss:-2.391\n",
      "Epoch:  0037 D loss:-0.4661 G loss:-2.329\n",
      "Epoch:  0037 D loss:-0.5147 G loss:-2.349\n",
      "Epoch:  0037 D loss:-0.4997 G loss:-2.548\n",
      "Epoch:  0037 D loss:-0.528 G loss:-2.582\n",
      "Epoch:  0037 D loss:-0.4808 G loss:-2.459\n",
      "Epoch:  0037 D loss:-0.6198 G loss:-2.3\n",
      "Epoch:  0037 D loss:-0.5386 G loss:-2.433\n",
      "Epoch:  0037 D loss:-0.499 G loss:-2.377\n",
      "Epoch:  0037 D loss:-0.4895 G loss:-2.636\n",
      "Epoch:  0037 D loss:-0.5423 G loss:-2.598\n",
      "Epoch:  0037 D loss:-0.503 G loss:-2.902\n",
      "Epoch:  0037 D loss:-0.555 G loss:-2.547\n",
      "Epoch:  0037 D loss:-0.559 G loss:-2.564\n",
      "Epoch:  0037 D loss:-0.4642 G loss:-2.457\n",
      "Epoch:  0037 D loss:-0.489 G loss:-2.392\n",
      "Epoch:  0037 D loss:-0.4664 G loss:-2.652\n",
      "Epoch:  0037 D loss:-0.6117 G loss:-2.358\n",
      "Epoch:  0037 D loss:-0.5408 G loss:-2.45\n",
      "Epoch:  0037 D loss:-0.4592 G loss:-2.295\n",
      "Epoch:  0037 D loss:-0.5068 G loss:-2.261\n",
      "Epoch:  0037 D loss:-0.6253 G loss:-2.406\n",
      "Epoch:  0037 D loss:-0.5637 G loss:-2.401\n",
      "Epoch:  0037 D loss:-0.444 G loss:-2.392\n",
      "Epoch:  0037 D loss:-0.5033 G loss:-2.371\n",
      "Epoch:  0037 D loss:-0.4918 G loss:-2.572\n",
      "Epoch:  0037 D loss:-0.4596 G loss:-2.645\n",
      "Epoch:  0037 D loss:-0.5382 G loss:-2.327\n",
      "Epoch:  0037 D loss:-0.4421 G loss:-2.477\n",
      "Epoch:  0037 D loss:-0.4944 G loss:-2.587\n",
      "Epoch:  0037 D loss:-0.393 G loss:-2.644\n",
      "Epoch:  0037 D loss:-0.5183 G loss:-2.48\n",
      "Epoch:  0037 D loss:-0.5088 G loss:-2.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0037 D loss:-0.5869 G loss:-2.402\n",
      "Epoch:  0037 D loss:-0.4757 G loss:-2.557\n",
      "Epoch:  0037 D loss:-0.4318 G loss:-2.541\n",
      "Epoch:  0037 D loss:-0.5488 G loss:-2.6\n",
      "Epoch:  0037 D loss:-0.462 G loss:-2.527\n",
      "Epoch:  0037 D loss:-0.5026 G loss:-2.509\n",
      "Epoch:  0037 D loss:-0.4754 G loss:-2.391\n",
      "Epoch:  0037 D loss:-0.4673 G loss:-2.526\n",
      "Epoch:  0037 D loss:-0.4834 G loss:-2.656\n",
      "Epoch:  0037 D loss:-0.4366 G loss:-2.477\n",
      "Epoch:  0037 D loss:-0.4567 G loss:-2.589\n",
      "Epoch:  0037 D loss:-0.5741 G loss:-2.6\n",
      "Epoch:  0037 D loss:-0.5854 G loss:-2.722\n",
      "Epoch:  0037 D loss:-0.5207 G loss:-2.544\n",
      "Epoch:  0037 D loss:-0.4794 G loss:-2.622\n",
      "Epoch:  0037 D loss:-0.5344 G loss:-2.517\n",
      "Epoch:  0037 D loss:-0.5067 G loss:-2.38\n",
      "Epoch:  0037 D loss:-0.5244 G loss:-2.175\n",
      "Epoch:  0037 D loss:-0.5641 G loss:-2.257\n",
      "Epoch:  0037 D loss:-0.4951 G loss:-2.273\n",
      "Epoch:  0037 D loss:-0.493 G loss:-2.281\n",
      "Epoch:  0037 D loss:-0.5871 G loss:-2.231\n",
      "Epoch:  0037 D loss:-0.6164 G loss:-2.097\n",
      "Epoch:  0037 D loss:-0.428 G loss:-2.436\n",
      "Epoch:  0037 D loss:-0.5031 G loss:-2.431\n",
      "Epoch:  0037 D loss:-0.4829 G loss:-2.552\n",
      "Epoch:  0037 D loss:-0.5805 G loss:-2.266\n",
      "Epoch:  0037 D loss:-0.5014 G loss:-2.553\n",
      "Epoch:  0037 D loss:-0.4941 G loss:-2.681\n",
      "Epoch:  0037 D loss:-0.5162 G loss:-2.64\n",
      "Epoch:  0037 D loss:-0.5892 G loss:-2.709\n",
      "Epoch:  0037 D loss:-0.5414 G loss:-2.541\n",
      "Epoch:  0037 D loss:-0.5143 G loss:-2.54\n",
      "Epoch:  0037 D loss:-0.4633 G loss:-2.434\n",
      "Epoch:  0037 D loss:-0.5612 G loss:-2.545\n",
      "Epoch:  0037 D loss:-0.4648 G loss:-2.69\n",
      "Epoch:  0037 D loss:-0.5297 G loss:-2.556\n",
      "Epoch:  0037 D loss:-0.5307 G loss:-2.254\n",
      "Epoch:  0037 D loss:-0.6595 G loss:-2.475\n",
      "Epoch:  0037 D loss:-0.5137 G loss:-2.291\n",
      "Epoch:  0037 D loss:-0.4806 G loss:-2.297\n",
      "Epoch:  0037 D loss:-0.5155 G loss:-2.275\n",
      "Epoch:  0037 D loss:-0.6177 G loss:-2.27\n",
      "Epoch:  0037 D loss:-0.6519 G loss:-2.287\n",
      "Epoch:  0037 D loss:-0.5876 G loss:-2.028\n",
      "Epoch:  0037 D loss:-0.5414 G loss:-2.243\n",
      "Epoch:  0037 D loss:-0.5397 G loss:-2.418\n",
      "Epoch:  0037 D loss:-0.604 G loss:-2.273\n",
      "Epoch:  0037 D loss:-0.4853 G loss:-2.199\n",
      "Epoch:  0037 D loss:-0.5542 G loss:-2.339\n",
      "Epoch:  0037 D loss:-0.6191 G loss:-2.398\n",
      "Epoch:  0037 D loss:-0.5484 G loss:-2.349\n",
      "Epoch:  0037 D loss:-0.5885 G loss:-2.439\n",
      "Epoch:  0037 D loss:-0.4891 G loss:-2.456\n",
      "Epoch:  0037 D loss:-0.5755 G loss:-2.554\n",
      "Epoch:  0037 D loss:-0.5169 G loss:-2.789\n",
      "Epoch:  0037 D loss:-0.5909 G loss:-2.828\n",
      "Epoch:  0037 D loss:-0.5385 G loss:-2.923\n",
      "Epoch:  0037 D loss:-0.4537 G loss:-2.805\n",
      "Epoch:  0037 D loss:-0.5193 G loss:-2.414\n",
      "Epoch:  0037 D loss:-0.4665 G loss:-2.507\n",
      "Epoch:  0037 D loss:-0.6267 G loss:-2.533\n",
      "Epoch:  0037 D loss:-0.5564 G loss:-2.4\n",
      "Epoch:  0037 D loss:-0.5436 G loss:-2.476\n",
      "Epoch:  0037 D loss:-0.5157 G loss:-2.479\n",
      "Epoch:  0037 D loss:-0.6202 G loss:-2.24\n",
      "Epoch:  0037 D loss:-0.5982 G loss:-2.266\n",
      "Epoch:  0037 D loss:-0.4849 G loss:-2.199\n",
      "Epoch:  0037 D loss:-0.4518 G loss:-2.03\n",
      "Epoch:  0037 D loss:-0.4653 G loss:-2.32\n",
      "Epoch:  0037 D loss:-0.4596 G loss:-2.58\n",
      "Epoch:  0037 D loss:-0.6092 G loss:-2.331\n",
      "Epoch:  0037 D loss:-0.4887 G loss:-2.146\n",
      "Epoch:  0037 D loss:-0.6251 G loss:-2.471\n",
      "Epoch:  0037 D loss:-0.4872 G loss:-2.568\n",
      "Epoch:  0037 D loss:-0.435 G loss:-2.618\n",
      "Epoch:  0037 D loss:-0.5213 G loss:-2.666\n",
      "Epoch:  0037 D loss:-0.4769 G loss:-2.784\n",
      "Epoch:  0037 D loss:-0.552 G loss:-2.731\n",
      "Epoch:  0037 D loss:-0.5835 G loss:-2.618\n",
      "Epoch:  0037 D loss:-0.4168 G loss:-2.624\n",
      "Epoch:  0037 D loss:-0.5634 G loss:-2.589\n",
      "Epoch:  0037 D loss:-0.5455 G loss:-2.358\n",
      "Epoch:  0037 D loss:-0.5226 G loss:-2.464\n",
      "Epoch:  0037 D loss:-0.5718 G loss:-2.236\n",
      "Epoch:  0037 D loss:-0.5184 G loss:-2.181\n",
      "Epoch:  0037 D loss:-0.5338 G loss:-2.201\n",
      "Epoch:  0037 D loss:-0.4068 G loss:-2.376\n",
      "Epoch:  0037 D loss:-0.4877 G loss:-2.262\n",
      "Epoch:  0037 D loss:-0.5966 G loss:-2.462\n",
      "Epoch:  0037 D loss:-0.5163 G loss:-2.435\n",
      "Epoch:  0037 D loss:-0.5772 G loss:-2.505\n",
      "Epoch:  0037 D loss:-0.6301 G loss:-2.654\n",
      "Epoch:  0037 D loss:-0.4355 G loss:-2.545\n",
      "Epoch:  0037 D loss:-0.5488 G loss:-2.503\n",
      "Epoch:  0037 D loss:-0.5898 G loss:-2.504\n",
      "Epoch:  0037 D loss:-0.5173 G loss:-2.435\n",
      "Epoch:  0037 D loss:-0.6186 G loss:-2.309\n",
      "Epoch:  0037 D loss:-0.5642 G loss:-2.487\n",
      "Epoch:  0037 D loss:-0.4758 G loss:-2.463\n",
      "Epoch:  0037 D loss:-0.4193 G loss:-2.453\n",
      "Epoch:  0037 D loss:-0.5041 G loss:-2.551\n",
      "Epoch:  0037 D loss:-0.5469 G loss:-2.407\n",
      "Epoch:  0037 D loss:-0.474 G loss:-2.417\n",
      "Epoch:  0037 D loss:-0.5253 G loss:-2.475\n",
      "Epoch:  0037 D loss:-0.4903 G loss:-2.481\n",
      "Epoch:  0037 D loss:-0.4961 G loss:-2.48\n",
      "Epoch:  0037 D loss:-0.3775 G loss:-2.447\n",
      "Epoch:  0037 D loss:-0.5703 G loss:-2.377\n",
      "Epoch:  0037 D loss:-0.6297 G loss:-2.294\n",
      "Epoch:  0037 D loss:-0.5167 G loss:-2.544\n",
      "Epoch:  0037 D loss:-0.5029 G loss:-2.464\n",
      "Epoch:  0037 D loss:-0.5118 G loss:-2.292\n",
      "Epoch:  0037 D loss:-0.4963 G loss:-2.56\n",
      "Epoch:  0037 D loss:-0.5944 G loss:-2.426\n",
      "Epoch:  0037 D loss:-0.5092 G loss:-2.415\n",
      "Epoch:  0037 D loss:-0.4983 G loss:-2.233\n",
      "Epoch:  0037 D loss:-0.4146 G loss:-2.541\n",
      "Epoch:  0037 D loss:-0.545 G loss:-2.184\n",
      "Epoch:  0037 D loss:-0.5614 G loss:-2.271\n",
      "Epoch:  0037 D loss:-0.5657 G loss:-2.627\n",
      "Epoch:  0037 D loss:-0.478 G loss:-2.599\n",
      "Epoch:  0037 D loss:-0.648 G loss:-2.27\n",
      "Epoch:  0037 D loss:-0.607 G loss:-2.743\n",
      "Epoch:  0037 D loss:-0.6332 G loss:-2.331\n",
      "Epoch:  0037 D loss:-0.5107 G loss:-2.436\n",
      "Epoch:  0037 D loss:-0.6956 G loss:-2.478\n",
      "Epoch:  0037 D loss:-0.5045 G loss:-2.614\n",
      "Epoch:  0037 D loss:-0.4982 G loss:-2.46\n",
      "Epoch:  0037 D loss:-0.5366 G loss:-2.431\n",
      "Epoch:  0037 D loss:-0.5786 G loss:-2.582\n",
      "Epoch:  0037 D loss:-0.5086 G loss:-2.068\n",
      "Epoch:  0037 D loss:-0.5138 G loss:-2.279\n",
      "Epoch:  0037 D loss:-0.5842 G loss:-2.37\n",
      "Epoch:  0037 D loss:-0.5253 G loss:-2.238\n",
      "Epoch:  0037 D loss:-0.5023 G loss:-2.554\n",
      "Epoch:  0037 D loss:-0.512 G loss:-2.325\n",
      "Epoch:  0037 D loss:-0.5247 G loss:-2.483\n",
      "Epoch:  0037 D loss:-0.5709 G loss:-2.589\n",
      "Epoch:  0037 D loss:-0.6478 G loss:-2.411\n",
      "Epoch:  0037 D loss:-0.4608 G loss:-2.451\n",
      "Epoch:  0037 D loss:-0.5119 G loss:-2.577\n",
      "Epoch:  0037 D loss:-0.4932 G loss:-2.567\n",
      "Epoch:  0037 D loss:-0.4995 G loss:-2.52\n",
      "Epoch:  0037 D loss:-0.5475 G loss:-2.521\n",
      "Epoch:  0037 D loss:-0.432 G loss:-2.41\n",
      "Epoch:  0037 D loss:-0.6965 G loss:-2.469\n",
      "Epoch:  0037 D loss:-0.451 G loss:-2.563\n",
      "Epoch:  0037 D loss:-0.5236 G loss:-2.669\n",
      "Epoch:  0037 D loss:-0.598 G loss:-2.3\n",
      "Epoch:  0037 D loss:-0.4282 G loss:-2.611\n",
      "Epoch:  0037 D loss:-0.5203 G loss:-2.291\n",
      "Epoch:  0037 D loss:-0.5257 G loss:-2.369\n",
      "Epoch:  0037 D loss:-0.513 G loss:-2.569\n",
      "Epoch:  0037 D loss:-0.4202 G loss:-2.604\n",
      "Epoch:  0037 D loss:-0.5968 G loss:-2.446\n",
      "Epoch:  0037 D loss:-0.5099 G loss:-2.503\n",
      "Epoch:  0037 D loss:-0.4477 G loss:-2.637\n",
      "Epoch:  0037 D loss:-0.4063 G loss:-2.542\n",
      "Epoch:  0037 D loss:-0.4843 G loss:-2.746\n",
      "Epoch:  0037 D loss:-0.5176 G loss:-2.55\n",
      "Epoch:  0037 D loss:-0.6649 G loss:-2.785\n",
      "Epoch:  0037 D loss:-0.5851 G loss:-2.568\n",
      "Epoch:  0037 D loss:-0.4721 G loss:-2.341\n",
      "Epoch:  0037 D loss:-0.5908 G loss:-2.23\n",
      "Epoch:  0037 D loss:-0.4004 G loss:-2.289\n",
      "Epoch:  0037 D loss:-0.548 G loss:-2.353\n",
      "Epoch:  0037 D loss:-0.3881 G loss:-2.515\n",
      "Epoch:  0037 D loss:-0.4189 G loss:-2.759\n",
      "Epoch:  0037 D loss:-0.5989 G loss:-2.412\n",
      "Epoch:  0037 D loss:-0.5283 G loss:-2.555\n",
      "Epoch:  0037 D loss:-0.3781 G loss:-2.331\n",
      "Epoch:  0037 D loss:-0.4483 G loss:-2.536\n",
      "Epoch:  0037 D loss:-0.633 G loss:-2.333\n",
      "Epoch:  0037 D loss:-0.388 G loss:-2.881\n",
      "Epoch:  0037 D loss:-0.4144 G loss:-2.489\n",
      "Epoch:  0037 D loss:-0.5455 G loss:-2.67\n",
      "Epoch:  0037 D loss:-0.5925 G loss:-2.655\n",
      "Epoch:  0037 D loss:-0.4436 G loss:-2.441\n",
      "Epoch:  0037 D loss:-0.5958 G loss:-2.412\n",
      "Epoch:  0037 D loss:-0.6852 G loss:-2.265\n",
      "Epoch:  0037 D loss:-0.4952 G loss:-2.426\n",
      "Epoch:  0037 D loss:-0.4141 G loss:-2.35\n",
      "Epoch:  0037 D loss:-0.4529 G loss:-2.697\n",
      "Epoch:  0037 D loss:-0.5365 G loss:-2.322\n",
      "Epoch:  0037 D loss:-0.5037 G loss:-2.314\n",
      "Epoch:  0037 D loss:-0.5673 G loss:-2.586\n",
      "Epoch:  0037 D loss:-0.5093 G loss:-2.728\n",
      "Epoch:  0037 D loss:-0.5006 G loss:-2.361\n",
      "Epoch:  0037 D loss:-0.551 G loss:-2.163\n",
      "Epoch:  0037 D loss:-0.5158 G loss:-2.401\n",
      "Epoch:  0037 D loss:-0.6041 G loss:-2.357\n",
      "Epoch:  0037 D loss:-0.6086 G loss:-2.405\n",
      "Epoch:  0037 D loss:-0.3491 G loss:-2.858\n",
      "Epoch:  0037 D loss:-0.6031 G loss:-2.416\n",
      "Epoch:  0037 D loss:-0.4642 G loss:-2.714\n",
      "Epoch:  0037 D loss:-0.5553 G loss:-2.281\n",
      "Epoch:  0037 D loss:-0.5329 G loss:-2.64\n",
      "Epoch:  0037 D loss:-0.6167 G loss:-2.602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0037 D loss:-0.5062 G loss:-2.382\n",
      "Epoch:  0037 D loss:-0.5425 G loss:-2.293\n",
      "Epoch:  0037 D loss:-0.4878 G loss:-2.547\n",
      "Epoch:  0037 D loss:-0.5457 G loss:-2.249\n",
      "Epoch:  0037 D loss:-0.5832 G loss:-2.479\n",
      "Epoch:  0037 D loss:-0.7003 G loss:-2.18\n",
      "Epoch:  0037 D loss:-0.4675 G loss:-2.407\n",
      "Epoch:  0037 D loss:-0.508 G loss:-2.302\n",
      "Epoch:  0037 D loss:-0.5298 G loss:-2.207\n",
      "Epoch:  0037 D loss:-0.5076 G loss:-2.342\n",
      "Epoch:  0037 D loss:-0.5173 G loss:-2.266\n",
      "Epoch:  0037 D loss:-0.6702 G loss:-2.361\n",
      "Epoch:  0037 D loss:-0.6234 G loss:-2.224\n",
      "Epoch:  0037 D loss:-0.5048 G loss:-2.402\n",
      "Epoch:  0037 D loss:-0.6423 G loss:-2.12\n",
      "Epoch:  0037 D loss:-0.6271 G loss:-2.344\n",
      "Epoch:  0037 D loss:-0.5316 G loss:-2.773\n",
      "Epoch:  0037 D loss:-0.5385 G loss:-2.356\n",
      "Epoch:  0037 D loss:-0.5649 G loss:-2.448\n",
      "Epoch:  0037 D loss:-0.5299 G loss:-2.574\n",
      "Epoch:  0037 D loss:-0.5629 G loss:-2.346\n",
      "Epoch:  0037 D loss:-0.4887 G loss:-2.724\n",
      "Epoch:  0037 D loss:-0.526 G loss:-2.497\n",
      "Epoch:  0037 D loss:-0.5411 G loss:-2.464\n",
      "Epoch:  0037 D loss:-0.6762 G loss:-2.099\n",
      "Epoch:  0037 D loss:-0.4617 G loss:-2.472\n",
      "Epoch:  0037 D loss:-0.4745 G loss:-2.475\n",
      "Epoch:  0037 D loss:-0.5364 G loss:-2.473\n",
      "Epoch:  0037 D loss:-0.5784 G loss:-2.345\n",
      "Epoch:  0037 D loss:-0.653 G loss:-2.33\n",
      "Epoch:  0037 D loss:-0.638 G loss:-2.358\n",
      "Epoch:  0037 D loss:-0.5347 G loss:-2.45\n",
      "Epoch:  0037 D loss:-0.6818 G loss:-2.493\n",
      "Epoch:  0037 D loss:-0.4401 G loss:-2.561\n",
      "Epoch:  0037 D loss:-0.5687 G loss:-2.64\n",
      "Epoch:  0037 D loss:-0.4755 G loss:-2.799\n",
      "Epoch:  0037 D loss:-0.5274 G loss:-2.641\n",
      "Epoch:  0037 D loss:-0.6958 G loss:-2.438\n",
      "Epoch:  0037 D loss:-0.4063 G loss:-2.513\n",
      "Epoch:  0037 D loss:-0.671 G loss:-2.393\n",
      "Epoch:  0037 D loss:-0.4916 G loss:-2.336\n",
      "Epoch:  0037 D loss:-0.6506 G loss:-2.257\n",
      "Epoch:  0037 D loss:-0.5919 G loss:-2.273\n",
      "Epoch:  0037 D loss:-0.5096 G loss:-2.332\n",
      "Epoch:  0037 D loss:-0.5318 G loss:-2.147\n",
      "Epoch:  0037 D loss:-0.5838 G loss:-2.281\n",
      "Epoch:  0037 D loss:-0.6327 G loss:-2.177\n",
      "Epoch:  0037 D loss:-0.5483 G loss:-2.534\n",
      "Epoch:  0037 D loss:-0.5844 G loss:-2.6\n",
      "Epoch:  0037 D loss:-0.5644 G loss:-2.734\n",
      "Epoch:  0037 D loss:-0.5785 G loss:-2.613\n",
      "Epoch:  0037 D loss:-0.4765 G loss:-2.766\n",
      "Epoch:  0037 D loss:-0.5706 G loss:-2.676\n",
      "Epoch:  0037 D loss:-0.5198 G loss:-2.696\n",
      "Epoch:  0037 D loss:-0.5817 G loss:-2.48\n",
      "Epoch:  0037 D loss:-0.4026 G loss:-2.569\n",
      "Epoch:  0037 D loss:-0.5731 G loss:-2.362\n",
      "Epoch:  0037 D loss:-0.5595 G loss:-2.263\n",
      "Epoch:  0037 D loss:-0.5479 G loss:-2.216\n",
      "Epoch:  0037 D loss:-0.5342 G loss:-2.151\n",
      "Epoch:  0037 D loss:-0.6089 G loss:-2.22\n",
      "Epoch:  0037 D loss:-0.4881 G loss:-2.267\n",
      "Epoch:  0037 D loss:-0.588 G loss:-2.387\n",
      "Epoch:  0037 D loss:-0.4738 G loss:-2.463\n",
      "Epoch:  0037 D loss:-0.5331 G loss:-2.356\n",
      "Epoch:  0037 D loss:-0.5238 G loss:-2.478\n",
      "Epoch:  0037 D loss:-0.5931 G loss:-2.716\n",
      "Epoch:  0037 D loss:-0.5977 G loss:-2.579\n",
      "Epoch:  0037 D loss:-0.6728 G loss:-2.558\n",
      "Epoch:  0037 D loss:-0.5448 G loss:-2.301\n",
      "Epoch:  0037 D loss:-0.4888 G loss:-2.455\n",
      "Epoch:  0037 D loss:-0.5913 G loss:-2.487\n",
      "Epoch:  0037 D loss:-0.61 G loss:-2.172\n",
      "Epoch:  0037 D loss:-0.5441 G loss:-2.405\n",
      "Epoch:  0037 D loss:-0.5641 G loss:-2.322\n",
      "Epoch:  0037 D loss:-0.6492 G loss:-2.301\n",
      "Epoch:  0037 D loss:-0.464 G loss:-2.304\n",
      "Epoch:  0037 D loss:-0.45 G loss:-2.347\n",
      "Epoch:  0037 D loss:-0.5935 G loss:-2.297\n",
      "Epoch:  0037 D loss:-0.6112 G loss:-2.456\n",
      "Epoch:  0037 D loss:-0.6162 G loss:-2.261\n",
      "Epoch:  0037 D loss:-0.4948 G loss:-2.47\n",
      "Epoch:  0037 D loss:-0.442 G loss:-2.315\n",
      "Epoch:  0037 D loss:-0.4464 G loss:-2.309\n",
      "Epoch:  0037 D loss:-0.619 G loss:-2.469\n",
      "Epoch:  0037 D loss:-0.5246 G loss:-2.392\n",
      "Epoch:  0037 D loss:-0.5968 G loss:-2.394\n",
      "Epoch:  0037 D loss:-0.5191 G loss:-2.546\n",
      "Epoch:  0037 D loss:-0.4919 G loss:-2.65\n",
      "Epoch:  0037 D loss:-0.4635 G loss:-2.468\n",
      "Epoch:  0037 D loss:-0.5523 G loss:-2.554\n",
      "Epoch:  0037 D loss:-0.4666 G loss:-2.654\n",
      "Epoch:  0037 D loss:-0.5901 G loss:-2.52\n",
      "Epoch:  0037 D loss:-0.4455 G loss:-2.583\n",
      "Epoch:  0037 D loss:-0.5168 G loss:-2.522\n",
      "Epoch:  0037 D loss:-0.5135 G loss:-2.508\n",
      "Epoch:  0037 D loss:-0.4263 G loss:-2.373\n",
      "Epoch:  0037 D loss:-0.5921 G loss:-2.15\n",
      "Epoch:  0037 D loss:-0.57 G loss:-2.403\n",
      "Epoch:  0037 D loss:-0.4884 G loss:-2.292\n",
      "Epoch:  0037 D loss:-0.6211 G loss:-2.331\n",
      "Epoch:  0037 D loss:-0.5986 G loss:-2.173\n",
      "Epoch:  0037 D loss:-0.6233 G loss:-2.377\n",
      "Epoch:  0037 D loss:-0.5157 G loss:-2.409\n",
      "Epoch:  0037 D loss:-0.5241 G loss:-2.403\n",
      "Epoch:  0037 D loss:-0.5877 G loss:-2.347\n",
      "Epoch:  0037 D loss:-0.5978 G loss:-2.309\n",
      "Epoch:  0037 D loss:-0.4752 G loss:-2.506\n",
      "Epoch:  0037 D loss:-0.6697 G loss:-2.343\n",
      "Epoch:  0037 D loss:-0.4716 G loss:-2.509\n",
      "Epoch:  0037 D loss:-0.5219 G loss:-2.655\n",
      "Epoch:  0037 D loss:-0.5119 G loss:-2.595\n",
      "Epoch:  0037 D loss:-0.5226 G loss:-2.789\n",
      "Epoch:  0037 D loss:-0.5321 G loss:-2.294\n",
      "Epoch:  0037 D loss:-0.6483 G loss:-2.267\n",
      "Epoch:  0037 D loss:-0.6129 G loss:-2.097\n",
      "Epoch:  0037 D loss:-0.5714 G loss:-2.09\n",
      "Epoch:  0037 D loss:-0.5268 G loss:-2.327\n",
      "Epoch:  0037 D loss:-0.5445 G loss:-2.432\n",
      "Epoch:  0037 D loss:-0.5845 G loss:-2.433\n",
      "Epoch:  0037 D loss:-0.5636 G loss:-2.503\n",
      "Epoch:  0037 D loss:-0.493 G loss:-2.399\n",
      "Epoch:  0037 D loss:-0.5443 G loss:-2.267\n",
      "Epoch:  0037 D loss:-0.42 G loss:-2.536\n",
      "Epoch:  0037 D loss:-0.5225 G loss:-2.419\n",
      "Epoch:  0037 D loss:-0.5252 G loss:-2.42\n",
      "Epoch:  0037 D loss:-0.4484 G loss:-2.624\n",
      "Epoch:  0037 D loss:-0.5563 G loss:-2.528\n",
      "Epoch:  0037 D loss:-0.514 G loss:-2.734\n",
      "Epoch:  0037 D loss:-0.5679 G loss:-2.662\n",
      "Epoch:  0037 D loss:-0.6154 G loss:-2.514\n",
      "Epoch:  0037 D loss:-0.7055 G loss:-2.349\n",
      "Epoch:  0037 D loss:-0.5397 G loss:-2.368\n",
      "Epoch:  0037 D loss:-0.5668 G loss:-2.343\n",
      "Epoch:  0037 D loss:-0.5501 G loss:-2.429\n",
      "Epoch:  0037 D loss:-0.5407 G loss:-2.429\n",
      "Epoch:  0037 D loss:-0.5278 G loss:-2.269\n",
      "Epoch:  0037 D loss:-0.5459 G loss:-2.503\n",
      "Epoch:  0037 D loss:-0.4779 G loss:-2.526\n",
      "Epoch:  0037 D loss:-0.5745 G loss:-2.278\n",
      "Epoch:  0037 D loss:-0.4539 G loss:-2.565\n",
      "Epoch:  0037 D loss:-0.6401 G loss:-2.228\n",
      "Epoch:  0037 D loss:-0.6007 G loss:-2.329\n",
      "Epoch:  0037 D loss:-0.5155 G loss:-2.413\n",
      "Epoch:  0037 D loss:-0.5724 G loss:-2.256\n",
      "Epoch:  0037 D loss:-0.5891 G loss:-2.528\n",
      "Epoch:  0037 D loss:-0.6782 G loss:-2.006\n",
      "Epoch:  0037 D loss:-0.485 G loss:-2.452\n",
      "Epoch:  0037 D loss:-0.5038 G loss:-2.606\n",
      "Epoch:  0037 D loss:-0.5537 G loss:-2.479\n",
      "Epoch:  0037 D loss:-0.5165 G loss:-2.246\n",
      "Epoch:  0037 D loss:-0.4307 G loss:-2.57\n",
      "Epoch:  0037 D loss:-0.6073 G loss:-2.658\n",
      "Epoch:  0037 D loss:-0.4984 G loss:-2.7\n",
      "Epoch:  0037 D loss:-0.4903 G loss:-2.591\n",
      "Epoch:  0037 D loss:-0.5727 G loss:-2.753\n",
      "Epoch:  0037 D loss:-0.5493 G loss:-2.456\n",
      "Epoch:  0037 D loss:-0.4612 G loss:-2.697\n",
      "Epoch:  0037 D loss:-0.5392 G loss:-2.647\n",
      "Epoch:  0037 D loss:-0.549 G loss:-2.717\n",
      "Epoch:  0037 D loss:-0.5171 G loss:-2.404\n",
      "Epoch:  0037 D loss:-0.6539 G loss:-2.558\n",
      "Epoch:  0037 D loss:-0.4197 G loss:-2.441\n",
      "Epoch:  0037 D loss:-0.4847 G loss:-2.23\n",
      "Epoch:  0037 D loss:-0.4397 G loss:-2.261\n",
      "Epoch:  0037 D loss:-0.5294 G loss:-2.425\n",
      "Epoch:  0037 D loss:-0.642 G loss:-2.195\n",
      "Epoch:  0037 D loss:-0.5847 G loss:-2.435\n",
      "Epoch:  0037 D loss:-0.4937 G loss:-2.625\n",
      "Epoch:  0037 D loss:-0.6225 G loss:-2.222\n",
      "Epoch:  0037 D loss:-0.4789 G loss:-2.483\n",
      "Epoch:  0037 D loss:-0.4893 G loss:-2.618\n",
      "Epoch:  0037 D loss:-0.4237 G loss:-2.634\n",
      "Epoch:  0037 D loss:-0.5621 G loss:-2.507\n",
      "Epoch:  0037 D loss:-0.6078 G loss:-2.291\n",
      "Epoch:  0037 D loss:-0.4976 G loss:-2.557\n",
      "Epoch:  0037 D loss:-0.5427 G loss:-2.347\n",
      "Epoch:  0037 D loss:-0.5752 G loss:-2.228\n",
      "Epoch:  0037 D loss:-0.5812 G loss:-2.164\n",
      "Epoch:  0037 D loss:-0.5336 G loss:-2.166\n",
      "Epoch:  0037 D loss:-0.5105 G loss:-2.209\n",
      "Epoch:  0037 D loss:-0.5898 G loss:-2.016\n",
      "Epoch:  0037 D loss:-0.5487 G loss:-2.191\n",
      "Epoch:  0037 D loss:-0.4729 G loss:-2.405\n",
      "Epoch:  0037 D loss:-0.5255 G loss:-2.357\n",
      "Epoch:  0037 D loss:-0.5676 G loss:-2.487\n",
      "Epoch:  0037 D loss:-0.4914 G loss:-2.788\n",
      "Epoch:  0037 D loss:-0.6363 G loss:-2.433\n",
      "Epoch:  0037 D loss:-0.366 G loss:-2.68\n",
      "Epoch:  0037 D loss:-0.5946 G loss:-2.453\n",
      "Epoch:  0037 D loss:-0.5327 G loss:-2.44\n",
      "Epoch:  0037 D loss:-0.4856 G loss:-2.484\n",
      "Epoch:  0037 D loss:-0.481 G loss:-2.787\n",
      "Epoch:  0037 D loss:-0.3749 G loss:-2.686\n",
      "Epoch:  0037 D loss:-0.6072 G loss:-2.654\n",
      "Epoch:  0037 D loss:-0.5276 G loss:-2.478\n",
      "Epoch:  0037 D loss:-0.5599 G loss:-2.605\n",
      "Epoch:  0037 D loss:-0.4252 G loss:-2.818\n",
      "Epoch:  0037 D loss:-0.535 G loss:-2.477\n",
      "Epoch:  0037 D loss:-0.5097 G loss:-2.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0037 D loss:-0.5754 G loss:-2.337\n",
      "Epoch:  0037 D loss:-0.497 G loss:-2.138\n",
      "Epoch:  0037 D loss:-0.5098 G loss:-2.236\n",
      "Epoch:  0037 D loss:-0.5725 G loss:-2.241\n",
      "Epoch:  0037 D loss:-0.5245 G loss:-2.251\n",
      "Epoch:  0037 D loss:-0.5307 G loss:-2.301\n",
      "Epoch:  0037 D loss:-0.5539 G loss:-2.435\n",
      "Epoch:  0037 D loss:-0.5896 G loss:-2.499\n",
      "Epoch:  0037 D loss:-0.6307 G loss:-2.379\n",
      "Epoch:  0037 D loss:-0.5931 G loss:-2.752\n",
      "Epoch:  0037 D loss:-0.56 G loss:-2.299\n",
      "Epoch:  0037 D loss:-0.6264 G loss:-2.377\n",
      "Epoch:  0037 D loss:-0.469 G loss:-2.511\n",
      "Epoch:  0037 D loss:-0.4165 G loss:-2.54\n",
      "Epoch:  0037 D loss:-0.5732 G loss:-2.507\n",
      "Epoch:  0037 D loss:-0.5422 G loss:-2.623\n",
      "Epoch:  0037 D loss:-0.6066 G loss:-2.426\n",
      "Epoch:  0037 D loss:-0.5231 G loss:-2.556\n",
      "Epoch:  0037 D loss:-0.5789 G loss:-2.357\n",
      "Epoch:  0037 D loss:-0.6994 G loss:-2.051\n",
      "Epoch:  0037 D loss:-0.7106 G loss:-2.125\n",
      "Epoch:  0037 D loss:-0.5133 G loss:-2.064\n",
      "Epoch:  0037 D loss:-0.6274 G loss:-2.256\n",
      "Epoch:  0037 D loss:-0.5258 G loss:-2.222\n",
      "Epoch:  0037 D loss:-0.4498 G loss:-2.302\n",
      "Epoch:  0037 D loss:-0.6133 G loss:-2.337\n",
      "Epoch:  0037 D loss:-0.6876 G loss:-2.419\n",
      "Epoch:  0037 D loss:-0.4702 G loss:-2.268\n",
      "Epoch:  0038 D loss:-0.5139 G loss:-2.444\n",
      "Epoch:  0038 D loss:-0.4867 G loss:-2.581\n",
      "Epoch:  0038 D loss:-0.5183 G loss:-2.543\n",
      "Epoch:  0038 D loss:-0.8517 G loss:-2.377\n",
      "Epoch:  0038 D loss:-0.6258 G loss:-2.323\n",
      "Epoch:  0038 D loss:-0.5722 G loss:-2.418\n",
      "Epoch:  0038 D loss:-0.6025 G loss:-2.51\n",
      "Epoch:  0038 D loss:-0.4699 G loss:-2.432\n",
      "Epoch:  0038 D loss:-0.7072 G loss:-2.32\n",
      "Epoch:  0038 D loss:-0.591 G loss:-2.435\n",
      "Epoch:  0038 D loss:-0.4367 G loss:-2.561\n",
      "Epoch:  0038 D loss:-0.5214 G loss:-2.415\n",
      "Epoch:  0038 D loss:-0.5802 G loss:-2.384\n",
      "Epoch:  0038 D loss:-0.5646 G loss:-2.354\n",
      "Epoch:  0038 D loss:-0.4521 G loss:-2.596\n",
      "Epoch:  0038 D loss:-0.5334 G loss:-2.329\n",
      "Epoch:  0038 D loss:-0.6946 G loss:-2.296\n",
      "Epoch:  0038 D loss:-0.5847 G loss:-2.279\n",
      "Epoch:  0038 D loss:-0.5472 G loss:-2.431\n",
      "Epoch:  0038 D loss:-0.5974 G loss:-2.17\n",
      "Epoch:  0038 D loss:-0.4925 G loss:-2.296\n",
      "Epoch:  0038 D loss:-0.5667 G loss:-2.267\n",
      "Epoch:  0038 D loss:-0.4869 G loss:-2.239\n",
      "Epoch:  0038 D loss:-0.5564 G loss:-2.51\n",
      "Epoch:  0038 D loss:-0.5763 G loss:-2.684\n",
      "Epoch:  0038 D loss:-0.6473 G loss:-2.678\n",
      "Epoch:  0038 D loss:-0.4412 G loss:-2.69\n",
      "Epoch:  0038 D loss:-0.4979 G loss:-2.618\n",
      "Epoch:  0038 D loss:-0.5863 G loss:-2.715\n",
      "Epoch:  0038 D loss:-0.6502 G loss:-2.501\n",
      "Epoch:  0038 D loss:-0.524 G loss:-2.501\n",
      "Epoch:  0038 D loss:-0.5102 G loss:-2.439\n",
      "Epoch:  0038 D loss:-0.6931 G loss:-2.108\n",
      "Epoch:  0038 D loss:-0.5548 G loss:-2.161\n",
      "Epoch:  0038 D loss:-0.5285 G loss:-2.369\n",
      "Epoch:  0038 D loss:-0.6996 G loss:-2.145\n",
      "Epoch:  0038 D loss:-0.7176 G loss:-2.271\n",
      "Epoch:  0038 D loss:-0.7156 G loss:-1.989\n",
      "Epoch:  0038 D loss:-0.6095 G loss:-2.282\n",
      "Epoch:  0038 D loss:-0.5711 G loss:-1.975\n",
      "Epoch:  0038 D loss:-0.5763 G loss:-2.243\n",
      "Epoch:  0038 D loss:-0.5454 G loss:-2.377\n",
      "Epoch:  0038 D loss:-0.4868 G loss:-2.247\n",
      "Epoch:  0038 D loss:-0.5625 G loss:-2.376\n",
      "Epoch:  0038 D loss:-0.6247 G loss:-2.581\n",
      "Epoch:  0038 D loss:-0.5424 G loss:-2.152\n",
      "Epoch:  0038 D loss:-0.7133 G loss:-2.245\n",
      "Epoch:  0038 D loss:-0.6128 G loss:-2.409\n",
      "Epoch:  0038 D loss:-0.6374 G loss:-2.343\n",
      "Epoch:  0038 D loss:-0.6303 G loss:-2.346\n",
      "Epoch:  0038 D loss:-0.6397 G loss:-2.234\n",
      "Epoch:  0038 D loss:-0.5173 G loss:-2.547\n",
      "Epoch:  0038 D loss:-0.6999 G loss:-2.168\n",
      "Epoch:  0038 D loss:-0.4841 G loss:-2.167\n",
      "Epoch:  0038 D loss:-0.5833 G loss:-2.272\n",
      "Epoch:  0038 D loss:-0.5364 G loss:-2.381\n",
      "Epoch:  0038 D loss:-0.5999 G loss:-2.051\n",
      "Epoch:  0038 D loss:-0.5305 G loss:-2.284\n",
      "Epoch:  0038 D loss:-0.4864 G loss:-2.3\n",
      "Epoch:  0038 D loss:-0.5463 G loss:-2.196\n",
      "Epoch:  0038 D loss:-0.5942 G loss:-2.261\n",
      "Epoch:  0038 D loss:-0.5408 G loss:-2.43\n",
      "Epoch:  0038 D loss:-0.6516 G loss:-2.263\n",
      "Epoch:  0038 D loss:-0.4362 G loss:-2.418\n",
      "Epoch:  0038 D loss:-0.5317 G loss:-2.363\n",
      "Epoch:  0038 D loss:-0.5414 G loss:-2.586\n",
      "Epoch:  0038 D loss:-0.5682 G loss:-2.384\n",
      "Epoch:  0038 D loss:-0.5168 G loss:-2.258\n",
      "Epoch:  0038 D loss:-0.5058 G loss:-2.186\n",
      "Epoch:  0038 D loss:-0.5999 G loss:-2.217\n",
      "Epoch:  0038 D loss:-0.5463 G loss:-2.345\n",
      "Epoch:  0038 D loss:-0.6479 G loss:-2.247\n",
      "Epoch:  0038 D loss:-0.5271 G loss:-2.237\n",
      "Epoch:  0038 D loss:-0.4963 G loss:-2.257\n",
      "Epoch:  0038 D loss:-0.6575 G loss:-2.415\n",
      "Epoch:  0038 D loss:-0.6039 G loss:-2.089\n",
      "Epoch:  0038 D loss:-0.5578 G loss:-2.157\n",
      "Epoch:  0038 D loss:-0.499 G loss:-2.25\n",
      "Epoch:  0038 D loss:-0.5746 G loss:-2.2\n",
      "Epoch:  0038 D loss:-0.5717 G loss:-2.249\n",
      "Epoch:  0038 D loss:-0.5724 G loss:-2.407\n",
      "Epoch:  0038 D loss:-0.5638 G loss:-2.508\n",
      "Epoch:  0038 D loss:-0.5865 G loss:-2.502\n",
      "Epoch:  0038 D loss:-0.6909 G loss:-2.413\n",
      "Epoch:  0038 D loss:-0.5697 G loss:-2.478\n",
      "Epoch:  0038 D loss:-0.5148 G loss:-2.416\n",
      "Epoch:  0038 D loss:-0.5917 G loss:-2.397\n",
      "Epoch:  0038 D loss:-0.5523 G loss:-2.156\n",
      "Epoch:  0038 D loss:-0.6029 G loss:-2.165\n",
      "Epoch:  0038 D loss:-0.5989 G loss:-2.407\n",
      "Epoch:  0038 D loss:-0.5602 G loss:-2.229\n",
      "Epoch:  0038 D loss:-0.5616 G loss:-2.177\n",
      "Epoch:  0038 D loss:-0.4885 G loss:-2.353\n",
      "Epoch:  0038 D loss:-0.5372 G loss:-2.471\n",
      "Epoch:  0038 D loss:-0.6834 G loss:-2.279\n",
      "Epoch:  0038 D loss:-0.5742 G loss:-2.379\n",
      "Epoch:  0038 D loss:-0.6496 G loss:-2.608\n",
      "Epoch:  0038 D loss:-0.4946 G loss:-2.484\n",
      "Epoch:  0038 D loss:-0.5629 G loss:-2.308\n",
      "Epoch:  0038 D loss:-0.6043 G loss:-2.206\n",
      "Epoch:  0038 D loss:-0.5751 G loss:-2.494\n",
      "Epoch:  0038 D loss:-0.6582 G loss:-2.256\n",
      "Epoch:  0038 D loss:-0.6743 G loss:-2.182\n",
      "Epoch:  0038 D loss:-0.5824 G loss:-2.262\n",
      "Epoch:  0038 D loss:-0.5119 G loss:-2.441\n",
      "Epoch:  0038 D loss:-0.5733 G loss:-2.206\n",
      "Epoch:  0038 D loss:-0.6279 G loss:-2.171\n",
      "Epoch:  0038 D loss:-0.4936 G loss:-2.306\n",
      "Epoch:  0038 D loss:-0.5222 G loss:-2.486\n",
      "Epoch:  0038 D loss:-0.5247 G loss:-2.41\n",
      "Epoch:  0038 D loss:-0.589 G loss:-2.501\n",
      "Epoch:  0038 D loss:-0.6996 G loss:-2.284\n",
      "Epoch:  0038 D loss:-0.6359 G loss:-2.307\n",
      "Epoch:  0038 D loss:-0.5955 G loss:-2.176\n",
      "Epoch:  0038 D loss:-0.6717 G loss:-2.276\n",
      "Epoch:  0038 D loss:-0.5677 G loss:-2.12\n",
      "Epoch:  0038 D loss:-0.4888 G loss:-2.201\n",
      "Epoch:  0038 D loss:-0.3947 G loss:-2.447\n",
      "Epoch:  0038 D loss:-0.5708 G loss:-2.318\n",
      "Epoch:  0038 D loss:-0.4862 G loss:-2.26\n",
      "Epoch:  0038 D loss:-0.6548 G loss:-2.434\n",
      "Epoch:  0038 D loss:-0.5088 G loss:-2.646\n",
      "Epoch:  0038 D loss:-0.5206 G loss:-2.51\n",
      "Epoch:  0038 D loss:-0.4527 G loss:-2.968\n",
      "Epoch:  0038 D loss:-0.5661 G loss:-2.833\n",
      "Epoch:  0038 D loss:-0.6094 G loss:-2.675\n",
      "Epoch:  0038 D loss:-0.4666 G loss:-2.642\n",
      "Epoch:  0038 D loss:-0.5101 G loss:-2.659\n",
      "Epoch:  0038 D loss:-0.5987 G loss:-2.483\n",
      "Epoch:  0038 D loss:-0.453 G loss:-2.415\n",
      "Epoch:  0038 D loss:-0.5323 G loss:-2.224\n",
      "Epoch:  0038 D loss:-0.5408 G loss:-2.117\n",
      "Epoch:  0038 D loss:-0.6098 G loss:-2.013\n",
      "Epoch:  0038 D loss:-0.5493 G loss:-2.453\n",
      "Epoch:  0038 D loss:-0.4401 G loss:-2.303\n",
      "Epoch:  0038 D loss:-0.5873 G loss:-2.511\n",
      "Epoch:  0038 D loss:-0.4589 G loss:-2.471\n",
      "Epoch:  0038 D loss:-0.6087 G loss:-2.347\n",
      "Epoch:  0038 D loss:-0.614 G loss:-2.553\n",
      "Epoch:  0038 D loss:-0.641 G loss:-2.215\n",
      "Epoch:  0038 D loss:-0.4703 G loss:-2.602\n",
      "Epoch:  0038 D loss:-0.4102 G loss:-2.487\n",
      "Epoch:  0038 D loss:-0.4608 G loss:-2.436\n",
      "Epoch:  0038 D loss:-0.3977 G loss:-2.591\n",
      "Epoch:  0038 D loss:-0.5581 G loss:-2.552\n",
      "Epoch:  0038 D loss:-0.511 G loss:-2.325\n",
      "Epoch:  0038 D loss:-0.5869 G loss:-2.18\n",
      "Epoch:  0038 D loss:-0.5699 G loss:-2.238\n",
      "Epoch:  0038 D loss:-0.4546 G loss:-2.563\n",
      "Epoch:  0038 D loss:-0.5969 G loss:-2.566\n",
      "Epoch:  0038 D loss:-0.5577 G loss:-2.317\n",
      "Epoch:  0038 D loss:-0.5757 G loss:-2.423\n",
      "Epoch:  0038 D loss:-0.5627 G loss:-2.444\n",
      "Epoch:  0038 D loss:-0.4751 G loss:-2.487\n",
      "Epoch:  0038 D loss:-0.6836 G loss:-2.487\n",
      "Epoch:  0038 D loss:-0.5284 G loss:-2.363\n",
      "Epoch:  0038 D loss:-0.4408 G loss:-2.539\n",
      "Epoch:  0038 D loss:-0.4962 G loss:-2.485\n",
      "Epoch:  0038 D loss:-0.6186 G loss:-2.355\n",
      "Epoch:  0038 D loss:-0.6857 G loss:-2.314\n",
      "Epoch:  0038 D loss:-0.3956 G loss:-2.369\n",
      "Epoch:  0038 D loss:-0.4129 G loss:-2.604\n",
      "Epoch:  0038 D loss:-0.3728 G loss:-2.581\n",
      "Epoch:  0038 D loss:-0.6386 G loss:-2.454\n",
      "Epoch:  0038 D loss:-0.4374 G loss:-2.321\n",
      "Epoch:  0038 D loss:-0.4895 G loss:-2.65\n",
      "Epoch:  0038 D loss:-0.5657 G loss:-2.761\n",
      "Epoch:  0038 D loss:-0.5935 G loss:-2.426\n",
      "Epoch:  0038 D loss:-0.5963 G loss:-2.47\n",
      "Epoch:  0038 D loss:-0.6158 G loss:-2.369\n",
      "Epoch:  0038 D loss:-0.5918 G loss:-2.182\n",
      "Epoch:  0038 D loss:-0.722 G loss:-2.253\n",
      "Epoch:  0038 D loss:-0.479 G loss:-2.527\n",
      "Epoch:  0038 D loss:-0.491 G loss:-2.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0038 D loss:-0.467 G loss:-2.501\n",
      "Epoch:  0038 D loss:-0.5486 G loss:-2.342\n",
      "Epoch:  0038 D loss:-0.5244 G loss:-2.279\n",
      "Epoch:  0038 D loss:-0.4289 G loss:-2.669\n",
      "Epoch:  0038 D loss:-0.3888 G loss:-2.604\n",
      "Epoch:  0038 D loss:-0.4808 G loss:-2.522\n",
      "Epoch:  0038 D loss:-0.57 G loss:-2.214\n",
      "Epoch:  0038 D loss:-0.5548 G loss:-2.4\n",
      "Epoch:  0038 D loss:-0.53 G loss:-2.413\n",
      "Epoch:  0038 D loss:-0.5478 G loss:-2.261\n",
      "Epoch:  0038 D loss:-0.6644 G loss:-2.254\n",
      "Epoch:  0038 D loss:-0.6967 G loss:-2.37\n",
      "Epoch:  0038 D loss:-0.54 G loss:-2.511\n",
      "Epoch:  0038 D loss:-0.5679 G loss:-2.387\n",
      "Epoch:  0038 D loss:-0.5433 G loss:-2.364\n",
      "Epoch:  0038 D loss:-0.5147 G loss:-2.55\n",
      "Epoch:  0038 D loss:-0.4213 G loss:-2.696\n",
      "Epoch:  0038 D loss:-0.5826 G loss:-2.451\n",
      "Epoch:  0038 D loss:-0.4732 G loss:-2.407\n",
      "Epoch:  0038 D loss:-0.6174 G loss:-2.278\n",
      "Epoch:  0038 D loss:-0.6136 G loss:-2.138\n",
      "Epoch:  0038 D loss:-0.6728 G loss:-2.279\n",
      "Epoch:  0038 D loss:-0.6101 G loss:-2.337\n",
      "Epoch:  0038 D loss:-0.749 G loss:-1.994\n",
      "Epoch:  0038 D loss:-0.6697 G loss:-2.226\n",
      "Epoch:  0038 D loss:-0.5468 G loss:-2.409\n",
      "Epoch:  0038 D loss:-0.65 G loss:-2.021\n",
      "Epoch:  0038 D loss:-0.5595 G loss:-2.297\n",
      "Epoch:  0038 D loss:-0.6277 G loss:-2.347\n",
      "Epoch:  0038 D loss:-0.4952 G loss:-2.241\n",
      "Epoch:  0038 D loss:-0.7949 G loss:-2.373\n",
      "Epoch:  0038 D loss:-0.6302 G loss:-2.185\n",
      "Epoch:  0038 D loss:-0.596 G loss:-2.301\n",
      "Epoch:  0038 D loss:-0.5352 G loss:-2.456\n",
      "Epoch:  0038 D loss:-0.5671 G loss:-2.265\n",
      "Epoch:  0038 D loss:-0.4734 G loss:-2.449\n",
      "Epoch:  0038 D loss:-0.5755 G loss:-2.189\n",
      "Epoch:  0038 D loss:-0.6598 G loss:-2.427\n",
      "Epoch:  0038 D loss:-0.6174 G loss:-2.376\n",
      "Epoch:  0038 D loss:-0.4803 G loss:-2.396\n",
      "Epoch:  0038 D loss:-0.6424 G loss:-2.157\n",
      "Epoch:  0038 D loss:-0.5556 G loss:-2.271\n",
      "Epoch:  0038 D loss:-0.6331 G loss:-2.056\n",
      "Epoch:  0038 D loss:-0.6372 G loss:-2.258\n",
      "Epoch:  0038 D loss:-0.5738 G loss:-2.267\n",
      "Epoch:  0038 D loss:-0.486 G loss:-2.363\n",
      "Epoch:  0038 D loss:-0.6511 G loss:-2.275\n",
      "Epoch:  0038 D loss:-0.5472 G loss:-2.306\n",
      "Epoch:  0038 D loss:-0.6501 G loss:-2.357\n",
      "Epoch:  0038 D loss:-0.6101 G loss:-2.251\n",
      "Epoch:  0038 D loss:-0.5053 G loss:-2.273\n",
      "Epoch:  0038 D loss:-0.4626 G loss:-2.61\n",
      "Epoch:  0038 D loss:-0.4856 G loss:-2.599\n",
      "Epoch:  0038 D loss:-0.637 G loss:-2.412\n",
      "Epoch:  0038 D loss:-0.581 G loss:-2.351\n",
      "Epoch:  0038 D loss:-0.5731 G loss:-2.546\n",
      "Epoch:  0038 D loss:-0.4135 G loss:-2.434\n",
      "Epoch:  0038 D loss:-0.5555 G loss:-2.447\n",
      "Epoch:  0038 D loss:-0.7255 G loss:-2.234\n",
      "Epoch:  0038 D loss:-0.5633 G loss:-2.242\n",
      "Epoch:  0038 D loss:-0.533 G loss:-2.273\n",
      "Epoch:  0038 D loss:-0.4834 G loss:-2.236\n",
      "Epoch:  0038 D loss:-0.6927 G loss:-2.291\n",
      "Epoch:  0038 D loss:-0.5387 G loss:-2.148\n",
      "Epoch:  0038 D loss:-0.4894 G loss:-2.362\n",
      "Epoch:  0038 D loss:-0.5494 G loss:-2.507\n",
      "Epoch:  0038 D loss:-0.7306 G loss:-2.424\n",
      "Epoch:  0038 D loss:-0.5308 G loss:-2.413\n",
      "Epoch:  0038 D loss:-0.5579 G loss:-2.402\n",
      "Epoch:  0038 D loss:-0.5483 G loss:-2.353\n",
      "Epoch:  0038 D loss:-0.5894 G loss:-2.302\n",
      "Epoch:  0038 D loss:-0.5735 G loss:-2.368\n",
      "Epoch:  0038 D loss:-0.5106 G loss:-2.275\n",
      "Epoch:  0038 D loss:-0.4933 G loss:-2.237\n",
      "Epoch:  0038 D loss:-0.62 G loss:-2.273\n",
      "Epoch:  0038 D loss:-0.4835 G loss:-2.46\n",
      "Epoch:  0038 D loss:-0.6624 G loss:-2.449\n",
      "Epoch:  0038 D loss:-0.4479 G loss:-2.556\n",
      "Epoch:  0038 D loss:-0.421 G loss:-2.676\n",
      "Epoch:  0038 D loss:-0.4467 G loss:-2.349\n",
      "Epoch:  0038 D loss:-0.5236 G loss:-2.499\n",
      "Epoch:  0038 D loss:-0.5275 G loss:-2.484\n",
      "Epoch:  0038 D loss:-0.5515 G loss:-2.528\n",
      "Epoch:  0038 D loss:-0.4365 G loss:-2.517\n",
      "Epoch:  0038 D loss:-0.6477 G loss:-2.234\n",
      "Epoch:  0038 D loss:-0.484 G loss:-2.351\n",
      "Epoch:  0038 D loss:-0.5689 G loss:-2.352\n",
      "Epoch:  0038 D loss:-0.6105 G loss:-2.243\n",
      "Epoch:  0038 D loss:-0.5221 G loss:-2.517\n",
      "Epoch:  0038 D loss:-0.5184 G loss:-2.222\n",
      "Epoch:  0038 D loss:-0.561 G loss:-2.34\n",
      "Epoch:  0038 D loss:-0.5708 G loss:-2.546\n",
      "Epoch:  0038 D loss:-0.5979 G loss:-2.585\n",
      "Epoch:  0038 D loss:-0.5397 G loss:-2.488\n",
      "Epoch:  0038 D loss:-0.6291 G loss:-2.476\n",
      "Epoch:  0038 D loss:-0.6517 G loss:-2.459\n",
      "Epoch:  0038 D loss:-0.5652 G loss:-2.506\n",
      "Epoch:  0038 D loss:-0.7582 G loss:-2.483\n",
      "Epoch:  0038 D loss:-0.4976 G loss:-2.474\n",
      "Epoch:  0038 D loss:-0.5453 G loss:-2.445\n",
      "Epoch:  0038 D loss:-0.648 G loss:-2.163\n",
      "Epoch:  0038 D loss:-0.6431 G loss:-2.392\n",
      "Epoch:  0038 D loss:-0.5044 G loss:-2.208\n",
      "Epoch:  0038 D loss:-0.5358 G loss:-2.233\n",
      "Epoch:  0038 D loss:-0.4637 G loss:-2.283\n",
      "Epoch:  0038 D loss:-0.6025 G loss:-2.405\n",
      "Epoch:  0038 D loss:-0.4953 G loss:-2.156\n",
      "Epoch:  0038 D loss:-0.6252 G loss:-2.338\n",
      "Epoch:  0038 D loss:-0.4774 G loss:-2.484\n",
      "Epoch:  0038 D loss:-0.6 G loss:-2.385\n",
      "Epoch:  0038 D loss:-0.463 G loss:-2.414\n",
      "Epoch:  0038 D loss:-0.532 G loss:-2.842\n",
      "Epoch:  0038 D loss:-0.4549 G loss:-2.492\n",
      "Epoch:  0038 D loss:-0.4661 G loss:-2.644\n",
      "Epoch:  0038 D loss:-0.5568 G loss:-2.508\n",
      "Epoch:  0038 D loss:-0.4629 G loss:-2.692\n",
      "Epoch:  0038 D loss:-0.5735 G loss:-2.47\n",
      "Epoch:  0038 D loss:-0.4901 G loss:-2.619\n",
      "Epoch:  0038 D loss:-0.5169 G loss:-2.446\n",
      "Epoch:  0038 D loss:-0.5787 G loss:-2.298\n",
      "Epoch:  0038 D loss:-0.4798 G loss:-2.355\n",
      "Epoch:  0038 D loss:-0.5835 G loss:-2.138\n",
      "Epoch:  0038 D loss:-0.6229 G loss:-2.49\n",
      "Epoch:  0038 D loss:-0.5145 G loss:-2.316\n",
      "Epoch:  0038 D loss:-0.4925 G loss:-2.487\n",
      "Epoch:  0038 D loss:-0.5154 G loss:-2.431\n",
      "Epoch:  0038 D loss:-0.5818 G loss:-2.248\n",
      "Epoch:  0038 D loss:-0.5064 G loss:-2.431\n",
      "Epoch:  0038 D loss:-0.4755 G loss:-2.494\n",
      "Epoch:  0038 D loss:-0.5351 G loss:-2.53\n",
      "Epoch:  0038 D loss:-0.5514 G loss:-2.557\n",
      "Epoch:  0038 D loss:-0.6459 G loss:-2.501\n",
      "Epoch:  0038 D loss:-0.606 G loss:-2.895\n",
      "Epoch:  0038 D loss:-0.466 G loss:-2.497\n",
      "Epoch:  0038 D loss:-0.7395 G loss:-2.22\n",
      "Epoch:  0038 D loss:-0.4505 G loss:-2.566\n",
      "Epoch:  0038 D loss:-0.4837 G loss:-2.394\n",
      "Epoch:  0038 D loss:-0.4714 G loss:-2.684\n",
      "Epoch:  0038 D loss:-0.4385 G loss:-2.667\n",
      "Epoch:  0038 D loss:-0.3523 G loss:-2.624\n",
      "Epoch:  0038 D loss:-0.4967 G loss:-2.509\n",
      "Epoch:  0038 D loss:-0.6517 G loss:-2.42\n",
      "Epoch:  0038 D loss:-0.6546 G loss:-2.275\n",
      "Epoch:  0038 D loss:-0.6403 G loss:-2.218\n",
      "Epoch:  0038 D loss:-0.7148 G loss:-2.16\n",
      "Epoch:  0038 D loss:-0.546 G loss:-2.095\n",
      "Epoch:  0038 D loss:-0.4775 G loss:-2.189\n",
      "Epoch:  0038 D loss:-0.6141 G loss:-2.182\n",
      "Epoch:  0038 D loss:-0.5583 G loss:-2.414\n",
      "Epoch:  0038 D loss:-0.5729 G loss:-2.381\n",
      "Epoch:  0038 D loss:-0.4711 G loss:-2.43\n",
      "Epoch:  0038 D loss:-0.5575 G loss:-2.538\n",
      "Epoch:  0038 D loss:-0.6413 G loss:-2.566\n",
      "Epoch:  0038 D loss:-0.5483 G loss:-2.358\n",
      "Epoch:  0038 D loss:-0.6773 G loss:-2.299\n",
      "Epoch:  0038 D loss:-0.4871 G loss:-2.414\n",
      "Epoch:  0038 D loss:-0.5809 G loss:-2.288\n",
      "Epoch:  0038 D loss:-0.6017 G loss:-2.228\n",
      "Epoch:  0038 D loss:-0.7039 G loss:-2.253\n",
      "Epoch:  0038 D loss:-0.5509 G loss:-2.278\n",
      "Epoch:  0038 D loss:-0.4347 G loss:-2.473\n",
      "Epoch:  0038 D loss:-0.5367 G loss:-2.271\n",
      "Epoch:  0038 D loss:-0.6439 G loss:-2.622\n",
      "Epoch:  0038 D loss:-0.5714 G loss:-2.246\n",
      "Epoch:  0038 D loss:-0.5281 G loss:-2.42\n",
      "Epoch:  0038 D loss:-0.6095 G loss:-2.319\n",
      "Epoch:  0038 D loss:-0.5099 G loss:-2.146\n",
      "Epoch:  0038 D loss:-0.6068 G loss:-2.139\n",
      "Epoch:  0038 D loss:-0.6564 G loss:-2.235\n",
      "Epoch:  0038 D loss:-0.6795 G loss:-2.221\n",
      "Epoch:  0038 D loss:-0.7088 G loss:-2.275\n",
      "Epoch:  0038 D loss:-0.5849 G loss:-2.415\n",
      "Epoch:  0038 D loss:-0.6969 G loss:-2.067\n",
      "Epoch:  0038 D loss:-0.496 G loss:-2.131\n",
      "Epoch:  0038 D loss:-0.7285 G loss:-2.279\n",
      "Epoch:  0038 D loss:-0.7206 G loss:-2.142\n",
      "Epoch:  0038 D loss:-0.751 G loss:-2.029\n",
      "Epoch:  0038 D loss:-0.5934 G loss:-2.449\n",
      "Epoch:  0038 D loss:-0.5369 G loss:-2.311\n",
      "Epoch:  0038 D loss:-0.5683 G loss:-2.413\n",
      "Epoch:  0038 D loss:-0.4982 G loss:-2.358\n",
      "Epoch:  0038 D loss:-0.5042 G loss:-2.377\n",
      "Epoch:  0038 D loss:-0.6039 G loss:-2.23\n",
      "Epoch:  0038 D loss:-0.4689 G loss:-2.472\n",
      "Epoch:  0038 D loss:-0.7354 G loss:-2.062\n",
      "Epoch:  0038 D loss:-0.6063 G loss:-2.24\n",
      "Epoch:  0038 D loss:-0.5706 G loss:-2.148\n",
      "Epoch:  0038 D loss:-0.5453 G loss:-2.373\n",
      "Epoch:  0038 D loss:-0.6458 G loss:-2.171\n",
      "Epoch:  0038 D loss:-0.7389 G loss:-2.005\n",
      "Epoch:  0038 D loss:-0.5485 G loss:-2.218\n",
      "Epoch:  0038 D loss:-0.4474 G loss:-2.551\n",
      "Epoch:  0038 D loss:-0.5264 G loss:-2.495\n",
      "Epoch:  0038 D loss:-0.6709 G loss:-2.394\n",
      "Epoch:  0038 D loss:-0.6189 G loss:-2.471\n",
      "Epoch:  0038 D loss:-0.4971 G loss:-2.483\n",
      "Epoch:  0038 D loss:-0.6594 G loss:-2.311\n",
      "Epoch:  0038 D loss:-0.4877 G loss:-2.348\n",
      "Epoch:  0038 D loss:-0.5107 G loss:-2.237\n",
      "Epoch:  0038 D loss:-0.5101 G loss:-2.274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0038 D loss:-0.6405 G loss:-2.346\n",
      "Epoch:  0038 D loss:-0.6666 G loss:-2.138\n",
      "Epoch:  0038 D loss:-0.5235 G loss:-2.578\n",
      "Epoch:  0038 D loss:-0.5038 G loss:-2.697\n",
      "Epoch:  0038 D loss:-0.6454 G loss:-2.425\n",
      "Epoch:  0038 D loss:-0.4391 G loss:-2.516\n",
      "Epoch:  0038 D loss:-0.5616 G loss:-2.317\n",
      "Epoch:  0038 D loss:-0.496 G loss:-2.229\n",
      "Epoch:  0038 D loss:-0.543 G loss:-2.229\n",
      "Epoch:  0038 D loss:-0.5091 G loss:-2.226\n",
      "Epoch:  0038 D loss:-0.6974 G loss:-2.102\n",
      "Epoch:  0038 D loss:-0.6915 G loss:-2.255\n",
      "Epoch:  0038 D loss:-0.6422 G loss:-2.033\n",
      "Epoch:  0038 D loss:-0.5902 G loss:-2.459\n",
      "Epoch:  0038 D loss:-0.5489 G loss:-2.44\n",
      "Epoch:  0038 D loss:-0.6811 G loss:-2.451\n",
      "Epoch:  0038 D loss:-0.4842 G loss:-2.488\n",
      "Epoch:  0038 D loss:-0.581 G loss:-2.506\n",
      "Epoch:  0038 D loss:-0.424 G loss:-2.476\n",
      "Epoch:  0038 D loss:-0.5279 G loss:-2.347\n",
      "Epoch:  0038 D loss:-0.5094 G loss:-2.258\n",
      "Epoch:  0038 D loss:-0.5318 G loss:-2.791\n",
      "Epoch:  0038 D loss:-0.4299 G loss:-2.8\n",
      "Epoch:  0038 D loss:-0.7333 G loss:-2.415\n",
      "Epoch:  0038 D loss:-0.4581 G loss:-2.694\n",
      "Epoch:  0038 D loss:-0.5052 G loss:-2.69\n",
      "Epoch:  0038 D loss:-0.5561 G loss:-2.326\n",
      "Epoch:  0038 D loss:-0.4456 G loss:-2.224\n",
      "Epoch:  0038 D loss:-0.5275 G loss:-2.402\n",
      "Epoch:  0038 D loss:-0.4802 G loss:-2.565\n",
      "Epoch:  0038 D loss:-0.5632 G loss:-2.304\n",
      "Epoch:  0038 D loss:-0.3989 G loss:-2.495\n",
      "Epoch:  0038 D loss:-0.5052 G loss:-2.541\n",
      "Epoch:  0038 D loss:-0.6074 G loss:-2.46\n",
      "Epoch:  0038 D loss:-0.4993 G loss:-2.217\n",
      "Epoch:  0038 D loss:-0.5755 G loss:-2.404\n",
      "Epoch:  0038 D loss:-0.666 G loss:-2.163\n",
      "Epoch:  0038 D loss:-0.5371 G loss:-2.354\n",
      "Epoch:  0038 D loss:-0.4763 G loss:-2.445\n",
      "Epoch:  0038 D loss:-0.4677 G loss:-2.379\n",
      "Epoch:  0038 D loss:-0.4919 G loss:-2.411\n",
      "Epoch:  0038 D loss:-0.5927 G loss:-2.367\n",
      "Epoch:  0038 D loss:-0.6651 G loss:-2.343\n",
      "Epoch:  0038 D loss:-0.4083 G loss:-2.71\n",
      "Epoch:  0038 D loss:-0.3816 G loss:-2.718\n",
      "Epoch:  0038 D loss:-0.4781 G loss:-2.916\n",
      "Epoch:  0038 D loss:-0.6065 G loss:-2.436\n",
      "Epoch:  0038 D loss:-0.5863 G loss:-2.46\n",
      "Epoch:  0038 D loss:-0.6292 G loss:-2.406\n",
      "Epoch:  0038 D loss:-0.5853 G loss:-2.738\n",
      "Epoch:  0038 D loss:-0.6779 G loss:-2.589\n",
      "Epoch:  0038 D loss:-0.5631 G loss:-2.537\n",
      "Epoch:  0038 D loss:-0.3497 G loss:-2.541\n",
      "Epoch:  0038 D loss:-0.6158 G loss:-2.324\n",
      "Epoch:  0038 D loss:-0.6152 G loss:-2.302\n",
      "Epoch:  0038 D loss:-0.5012 G loss:-2.218\n",
      "Epoch:  0038 D loss:-0.5331 G loss:-2.119\n",
      "Epoch:  0038 D loss:-0.5774 G loss:-2.061\n",
      "Epoch:  0038 D loss:-0.5408 G loss:-2.037\n",
      "Epoch:  0038 D loss:-0.5493 G loss:-2.307\n",
      "Epoch:  0038 D loss:-0.4484 G loss:-2.498\n",
      "Epoch:  0038 D loss:-0.5769 G loss:-2.598\n",
      "Epoch:  0038 D loss:-0.5307 G loss:-2.731\n",
      "Epoch:  0038 D loss:-0.6045 G loss:-2.438\n",
      "Epoch:  0038 D loss:-0.6622 G loss:-2.423\n",
      "Epoch:  0038 D loss:-0.5631 G loss:-2.457\n",
      "Epoch:  0038 D loss:-0.5109 G loss:-2.517\n",
      "Epoch:  0038 D loss:-0.4821 G loss:-2.537\n",
      "Epoch:  0038 D loss:-0.4339 G loss:-2.423\n",
      "Epoch:  0038 D loss:-0.5511 G loss:-2.56\n",
      "Epoch:  0038 D loss:-0.5123 G loss:-2.526\n",
      "Epoch:  0038 D loss:-0.5301 G loss:-2.536\n",
      "Epoch:  0038 D loss:-0.4199 G loss:-2.404\n",
      "Epoch:  0038 D loss:-0.3676 G loss:-2.622\n",
      "Epoch:  0038 D loss:-0.481 G loss:-2.492\n",
      "Epoch:  0038 D loss:-0.4268 G loss:-2.434\n",
      "Epoch:  0038 D loss:-0.4747 G loss:-2.547\n",
      "Epoch:  0038 D loss:-0.397 G loss:-2.49\n",
      "Epoch:  0038 D loss:-0.4723 G loss:-2.615\n",
      "Epoch:  0038 D loss:-0.5114 G loss:-2.621\n",
      "Epoch:  0038 D loss:-0.5354 G loss:-2.611\n",
      "Epoch:  0038 D loss:-0.4948 G loss:-2.762\n",
      "Epoch:  0038 D loss:-0.5446 G loss:-2.677\n",
      "Epoch:  0038 D loss:-0.4674 G loss:-2.499\n",
      "Epoch:  0038 D loss:-0.6114 G loss:-2.263\n",
      "Epoch:  0038 D loss:-0.4023 G loss:-2.418\n",
      "Epoch:  0038 D loss:-0.5514 G loss:-2.314\n",
      "Epoch:  0038 D loss:-0.6436 G loss:-2.125\n",
      "Epoch:  0038 D loss:-0.5108 G loss:-2.259\n",
      "Epoch:  0038 D loss:-0.5747 G loss:-2.3\n",
      "Epoch:  0038 D loss:-0.4676 G loss:-2.615\n",
      "Epoch:  0038 D loss:-0.3328 G loss:-2.855\n",
      "Epoch:  0038 D loss:-0.5365 G loss:-2.484\n",
      "Epoch:  0038 D loss:-0.5116 G loss:-2.865\n",
      "Epoch:  0038 D loss:-0.4676 G loss:-2.735\n",
      "Epoch:  0038 D loss:-0.6375 G loss:-2.691\n",
      "Epoch:  0038 D loss:-0.4526 G loss:-2.528\n",
      "Epoch:  0038 D loss:-0.6593 G loss:-2.458\n",
      "Epoch:  0038 D loss:-0.6176 G loss:-2.322\n",
      "Epoch:  0038 D loss:-0.4457 G loss:-2.283\n",
      "Epoch:  0038 D loss:-0.5841 G loss:-2.188\n",
      "Epoch:  0038 D loss:-0.6547 G loss:-2.25\n",
      "Epoch:  0038 D loss:-0.5647 G loss:-2.336\n",
      "Epoch:  0038 D loss:-0.5992 G loss:-2.307\n",
      "Epoch:  0038 D loss:-0.4566 G loss:-2.528\n",
      "Epoch:  0038 D loss:-0.632 G loss:-2.254\n",
      "Epoch:  0038 D loss:-0.5255 G loss:-2.566\n",
      "Epoch:  0038 D loss:-0.627 G loss:-2.343\n",
      "Epoch:  0038 D loss:-0.5086 G loss:-2.362\n",
      "Epoch:  0038 D loss:-0.6051 G loss:-2.404\n",
      "Epoch:  0038 D loss:-0.6031 G loss:-2.53\n",
      "Epoch:  0038 D loss:-0.6452 G loss:-2.365\n",
      "Epoch:  0038 D loss:-0.5375 G loss:-2.296\n",
      "Epoch:  0038 D loss:-0.4986 G loss:-2.487\n",
      "Epoch:  0038 D loss:-0.4568 G loss:-2.595\n",
      "Epoch:  0038 D loss:-0.7246 G loss:-2.174\n",
      "Epoch:  0038 D loss:-0.568 G loss:-2.415\n",
      "Epoch:  0038 D loss:-0.6604 G loss:-2.208\n",
      "Epoch:  0038 D loss:-0.5268 G loss:-2.437\n",
      "Epoch:  0038 D loss:-0.4997 G loss:-2.465\n",
      "Epoch:  0038 D loss:-0.4677 G loss:-2.324\n",
      "Epoch:  0038 D loss:-0.4138 G loss:-2.585\n",
      "Epoch:  0038 D loss:-0.5741 G loss:-2.354\n",
      "Epoch:  0038 D loss:-0.5334 G loss:-2.483\n",
      "Epoch:  0038 D loss:-0.5925 G loss:-2.479\n",
      "Epoch:  0038 D loss:-0.5885 G loss:-2.236\n",
      "Epoch:  0038 D loss:-0.5699 G loss:-2.352\n",
      "Epoch:  0038 D loss:-0.6133 G loss:-2.268\n",
      "Epoch:  0038 D loss:-0.5098 G loss:-2.379\n",
      "Epoch:  0038 D loss:-0.6885 G loss:-2.191\n",
      "Epoch:  0038 D loss:-0.439 G loss:-2.527\n",
      "Epoch:  0038 D loss:-0.812 G loss:-2.322\n",
      "Epoch:  0038 D loss:-0.6162 G loss:-2.306\n",
      "Epoch:  0038 D loss:-0.7307 G loss:-2.189\n",
      "Epoch:  0038 D loss:-0.606 G loss:-2.01\n",
      "Epoch:  0038 D loss:-0.67 G loss:-1.868\n",
      "Epoch:  0038 D loss:-0.792 G loss:-1.979\n",
      "Epoch:  0038 D loss:-0.6704 G loss:-2.111\n",
      "Epoch:  0038 D loss:-0.5784 G loss:-2.356\n",
      "Epoch:  0038 D loss:-0.6977 G loss:-2.354\n",
      "Epoch:  0038 D loss:-0.4301 G loss:-2.676\n",
      "Epoch:  0038 D loss:-0.6008 G loss:-2.522\n",
      "Epoch:  0038 D loss:-0.485 G loss:-2.607\n",
      "Epoch:  0038 D loss:-0.69 G loss:-2.729\n",
      "Epoch:  0038 D loss:-0.5737 G loss:-2.626\n",
      "Epoch:  0038 D loss:-0.6489 G loss:-2.544\n",
      "Epoch:  0038 D loss:-0.6778 G loss:-2.13\n",
      "Epoch:  0038 D loss:-0.5612 G loss:-2.399\n",
      "Epoch:  0038 D loss:-0.6889 G loss:-2.25\n",
      "Epoch:  0038 D loss:-0.6959 G loss:-1.838\n",
      "Epoch:  0038 D loss:-0.5983 G loss:-2.036\n",
      "Epoch:  0038 D loss:-0.6086 G loss:-2.159\n",
      "Epoch:  0038 D loss:-0.6921 G loss:-2.037\n",
      "Epoch:  0038 D loss:-0.564 G loss:-2.069\n",
      "Epoch:  0038 D loss:-0.5452 G loss:-2.131\n",
      "Epoch:  0038 D loss:-0.6094 G loss:-2.062\n",
      "Epoch:  0038 D loss:-0.7699 G loss:-2.29\n",
      "Epoch:  0038 D loss:-0.6767 G loss:-2.25\n",
      "Epoch:  0038 D loss:-0.593 G loss:-2.428\n",
      "Epoch:  0038 D loss:-0.5026 G loss:-2.361\n",
      "Epoch:  0038 D loss:-0.5579 G loss:-2.344\n",
      "Epoch:  0038 D loss:-0.6222 G loss:-2.416\n",
      "Epoch:  0038 D loss:-0.4888 G loss:-2.44\n",
      "Epoch:  0038 D loss:-0.5898 G loss:-2.384\n",
      "Epoch:  0038 D loss:-0.6638 G loss:-2.326\n",
      "Epoch:  0038 D loss:-0.6164 G loss:-2.216\n",
      "Epoch:  0038 D loss:-0.6609 G loss:-2.374\n",
      "Epoch:  0038 D loss:-0.781 G loss:-2.208\n",
      "Epoch:  0038 D loss:-0.8627 G loss:-1.935\n",
      "Epoch:  0038 D loss:-0.7979 G loss:-2.16\n",
      "Epoch:  0038 D loss:-0.5131 G loss:-2.264\n",
      "Epoch:  0038 D loss:-0.6405 G loss:-2.15\n",
      "Epoch:  0038 D loss:-0.4754 G loss:-2.374\n",
      "Epoch:  0038 D loss:-0.606 G loss:-2.225\n",
      "Epoch:  0038 D loss:-0.4207 G loss:-2.576\n",
      "Epoch:  0038 D loss:-0.5996 G loss:-2.227\n",
      "Epoch:  0039 D loss:-0.3817 G loss:-2.549\n",
      "Epoch:  0039 D loss:-0.6404 G loss:-2.478\n",
      "Epoch:  0039 D loss:-0.7168 G loss:-2.572\n",
      "Epoch:  0039 D loss:-0.6123 G loss:-2.362\n",
      "Epoch:  0039 D loss:-0.6458 G loss:-2.534\n",
      "Epoch:  0039 D loss:-0.4994 G loss:-2.318\n",
      "Epoch:  0039 D loss:-0.5842 G loss:-2.208\n",
      "Epoch:  0039 D loss:-0.4373 G loss:-2.284\n",
      "Epoch:  0039 D loss:-0.4325 G loss:-2.479\n",
      "Epoch:  0039 D loss:-0.5511 G loss:-2.172\n",
      "Epoch:  0039 D loss:-0.6179 G loss:-2.237\n",
      "Epoch:  0039 D loss:-0.5604 G loss:-1.967\n",
      "Epoch:  0039 D loss:-0.4863 G loss:-2.436\n",
      "Epoch:  0039 D loss:-0.4974 G loss:-2.294\n",
      "Epoch:  0039 D loss:-0.6462 G loss:-2.045\n",
      "Epoch:  0039 D loss:-0.5384 G loss:-2.274\n",
      "Epoch:  0039 D loss:-0.4903 G loss:-2.316\n",
      "Epoch:  0039 D loss:-0.5794 G loss:-2.383\n",
      "Epoch:  0039 D loss:-0.5574 G loss:-2.226\n",
      "Epoch:  0039 D loss:-0.4265 G loss:-2.854\n",
      "Epoch:  0039 D loss:-0.5378 G loss:-2.369\n",
      "Epoch:  0039 D loss:-0.5612 G loss:-2.352\n",
      "Epoch:  0039 D loss:-0.6131 G loss:-2.307\n",
      "Epoch:  0039 D loss:-0.5066 G loss:-2.618\n",
      "Epoch:  0039 D loss:-0.5848 G loss:-2.523\n",
      "Epoch:  0039 D loss:-0.6365 G loss:-2.7\n",
      "Epoch:  0039 D loss:-0.4553 G loss:-2.467\n",
      "Epoch:  0039 D loss:-0.4076 G loss:-2.393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0039 D loss:-0.4159 G loss:-2.559\n",
      "Epoch:  0039 D loss:-0.5496 G loss:-2.461\n",
      "Epoch:  0039 D loss:-0.5428 G loss:-2.4\n",
      "Epoch:  0039 D loss:-0.5992 G loss:-2.278\n",
      "Epoch:  0039 D loss:-0.4884 G loss:-2.437\n",
      "Epoch:  0039 D loss:-0.5095 G loss:-2.262\n",
      "Epoch:  0039 D loss:-0.4929 G loss:-2.432\n",
      "Epoch:  0039 D loss:-0.5406 G loss:-2.381\n",
      "Epoch:  0039 D loss:-0.4965 G loss:-2.52\n",
      "Epoch:  0039 D loss:-0.5385 G loss:-2.246\n",
      "Epoch:  0039 D loss:-0.4761 G loss:-2.461\n",
      "Epoch:  0039 D loss:-0.4123 G loss:-2.564\n",
      "Epoch:  0039 D loss:-0.4705 G loss:-2.447\n",
      "Epoch:  0039 D loss:-0.5221 G loss:-2.482\n",
      "Epoch:  0039 D loss:-0.45 G loss:-2.522\n",
      "Epoch:  0039 D loss:-0.4418 G loss:-2.458\n",
      "Epoch:  0039 D loss:-0.5615 G loss:-2.497\n",
      "Epoch:  0039 D loss:-0.5139 G loss:-2.618\n",
      "Epoch:  0039 D loss:-0.4889 G loss:-2.725\n",
      "Epoch:  0039 D loss:-0.5148 G loss:-2.474\n",
      "Epoch:  0039 D loss:-0.5513 G loss:-2.224\n",
      "Epoch:  0039 D loss:-0.4276 G loss:-2.4\n",
      "Epoch:  0039 D loss:-0.392 G loss:-2.591\n",
      "Epoch:  0039 D loss:-0.4306 G loss:-2.279\n",
      "Epoch:  0039 D loss:-0.5192 G loss:-2.518\n",
      "Epoch:  0039 D loss:-0.5149 G loss:-2.269\n",
      "Epoch:  0039 D loss:-0.58 G loss:-2.228\n",
      "Epoch:  0039 D loss:-0.4268 G loss:-2.405\n",
      "Epoch:  0039 D loss:-0.5265 G loss:-2.26\n",
      "Epoch:  0039 D loss:-0.4087 G loss:-2.531\n",
      "Epoch:  0039 D loss:-0.4397 G loss:-2.562\n",
      "Epoch:  0039 D loss:-0.5859 G loss:-2.772\n",
      "Epoch:  0039 D loss:-0.4276 G loss:-2.715\n",
      "Epoch:  0039 D loss:-0.3844 G loss:-2.474\n",
      "Epoch:  0039 D loss:-0.4628 G loss:-2.845\n",
      "Epoch:  0039 D loss:-0.4997 G loss:-2.514\n",
      "Epoch:  0039 D loss:-0.5666 G loss:-2.526\n",
      "Epoch:  0039 D loss:-0.5246 G loss:-2.483\n",
      "Epoch:  0039 D loss:-0.5983 G loss:-2.481\n",
      "Epoch:  0039 D loss:-0.4714 G loss:-2.478\n",
      "Epoch:  0039 D loss:-0.4532 G loss:-2.424\n",
      "Epoch:  0039 D loss:-0.5701 G loss:-2.173\n",
      "Epoch:  0039 D loss:-0.5627 G loss:-2.308\n",
      "Epoch:  0039 D loss:-0.5311 G loss:-2.391\n",
      "Epoch:  0039 D loss:-0.48 G loss:-2.416\n",
      "Epoch:  0039 D loss:-0.7006 G loss:-2.533\n",
      "Epoch:  0039 D loss:-0.5168 G loss:-2.413\n",
      "Epoch:  0039 D loss:-0.4527 G loss:-2.373\n",
      "Epoch:  0039 D loss:-0.6687 G loss:-2.215\n",
      "Epoch:  0039 D loss:-0.5903 G loss:-2.419\n",
      "Epoch:  0039 D loss:-0.505 G loss:-2.594\n",
      "Epoch:  0039 D loss:-0.5691 G loss:-2.563\n",
      "Epoch:  0039 D loss:-0.5084 G loss:-2.502\n",
      "Epoch:  0039 D loss:-0.6125 G loss:-2.338\n",
      "Epoch:  0039 D loss:-0.5642 G loss:-2.349\n",
      "Epoch:  0039 D loss:-0.441 G loss:-2.455\n",
      "Epoch:  0039 D loss:-0.4957 G loss:-2.228\n",
      "Epoch:  0039 D loss:-0.5579 G loss:-2.248\n",
      "Epoch:  0039 D loss:-0.5405 G loss:-2.23\n",
      "Epoch:  0039 D loss:-0.5996 G loss:-2.169\n",
      "Epoch:  0039 D loss:-0.5306 G loss:-2.347\n",
      "Epoch:  0039 D loss:-0.6609 G loss:-2.22\n",
      "Epoch:  0039 D loss:-0.535 G loss:-2.129\n",
      "Epoch:  0039 D loss:-0.4962 G loss:-2.372\n",
      "Epoch:  0039 D loss:-0.4902 G loss:-2.499\n",
      "Epoch:  0039 D loss:-0.5427 G loss:-2.519\n",
      "Epoch:  0039 D loss:-0.4092 G loss:-2.678\n",
      "Epoch:  0039 D loss:-0.4786 G loss:-2.422\n",
      "Epoch:  0039 D loss:-0.5486 G loss:-2.48\n",
      "Epoch:  0039 D loss:-0.441 G loss:-2.606\n",
      "Epoch:  0039 D loss:-0.6088 G loss:-2.379\n",
      "Epoch:  0039 D loss:-0.6653 G loss:-2.435\n",
      "Epoch:  0039 D loss:-0.4908 G loss:-2.579\n",
      "Epoch:  0039 D loss:-0.4284 G loss:-2.46\n",
      "Epoch:  0039 D loss:-0.4652 G loss:-2.499\n",
      "Epoch:  0039 D loss:-0.5087 G loss:-2.614\n",
      "Epoch:  0039 D loss:-0.5956 G loss:-2.461\n",
      "Epoch:  0039 D loss:-0.6161 G loss:-2.317\n",
      "Epoch:  0039 D loss:-0.4974 G loss:-2.299\n",
      "Epoch:  0039 D loss:-0.495 G loss:-2.323\n",
      "Epoch:  0039 D loss:-0.4524 G loss:-2.174\n",
      "Epoch:  0039 D loss:-0.6968 G loss:-2.284\n",
      "Epoch:  0039 D loss:-0.6231 G loss:-2.462\n",
      "Epoch:  0039 D loss:-0.5324 G loss:-2.39\n",
      "Epoch:  0039 D loss:-0.5307 G loss:-2.474\n",
      "Epoch:  0039 D loss:-0.6039 G loss:-2.181\n",
      "Epoch:  0039 D loss:-0.6308 G loss:-2.393\n",
      "Epoch:  0039 D loss:-0.5802 G loss:-2.457\n",
      "Epoch:  0039 D loss:-0.5216 G loss:-2.137\n",
      "Epoch:  0039 D loss:-0.5764 G loss:-2.37\n",
      "Epoch:  0039 D loss:-0.5444 G loss:-2.335\n",
      "Epoch:  0039 D loss:-0.6646 G loss:-2.279\n",
      "Epoch:  0039 D loss:-0.5994 G loss:-2.394\n",
      "Epoch:  0039 D loss:-0.6277 G loss:-2.542\n",
      "Epoch:  0039 D loss:-0.6059 G loss:-2.302\n",
      "Epoch:  0039 D loss:-0.5678 G loss:-2.333\n",
      "Epoch:  0039 D loss:-0.4854 G loss:-2.185\n",
      "Epoch:  0039 D loss:-0.6024 G loss:-2.162\n",
      "Epoch:  0039 D loss:-0.5636 G loss:-2.276\n",
      "Epoch:  0039 D loss:-0.6791 G loss:-2.065\n",
      "Epoch:  0039 D loss:-0.6931 G loss:-2.068\n",
      "Epoch:  0039 D loss:-0.5514 G loss:-2.33\n",
      "Epoch:  0039 D loss:-0.6153 G loss:-2.275\n",
      "Epoch:  0039 D loss:-0.5934 G loss:-2.402\n",
      "Epoch:  0039 D loss:-0.6449 G loss:-2.522\n",
      "Epoch:  0039 D loss:-0.6407 G loss:-2.407\n",
      "Epoch:  0039 D loss:-0.6599 G loss:-2.384\n",
      "Epoch:  0039 D loss:-0.6718 G loss:-2.565\n",
      "Epoch:  0039 D loss:-0.6178 G loss:-2.43\n",
      "Epoch:  0039 D loss:-0.4873 G loss:-2.346\n",
      "Epoch:  0039 D loss:-0.5823 G loss:-2.525\n",
      "Epoch:  0039 D loss:-0.5211 G loss:-2.527\n",
      "Epoch:  0039 D loss:-0.5947 G loss:-2.194\n",
      "Epoch:  0039 D loss:-0.6427 G loss:-2.32\n",
      "Epoch:  0039 D loss:-0.6777 G loss:-2.238\n",
      "Epoch:  0039 D loss:-0.6147 G loss:-2.222\n",
      "Epoch:  0039 D loss:-0.6473 G loss:-2.269\n",
      "Epoch:  0039 D loss:-0.5521 G loss:-2.318\n",
      "Epoch:  0039 D loss:-0.4743 G loss:-2.557\n",
      "Epoch:  0039 D loss:-0.5528 G loss:-2.351\n",
      "Epoch:  0039 D loss:-0.5152 G loss:-2.162\n",
      "Epoch:  0039 D loss:-0.6435 G loss:-2.039\n",
      "Epoch:  0039 D loss:-0.7259 G loss:-2.156\n",
      "Epoch:  0039 D loss:-0.8524 G loss:-2.145\n",
      "Epoch:  0039 D loss:-0.5946 G loss:-2.44\n",
      "Epoch:  0039 D loss:-0.6415 G loss:-2.378\n",
      "Epoch:  0039 D loss:-0.5798 G loss:-2.465\n",
      "Epoch:  0039 D loss:-0.7111 G loss:-2.428\n",
      "Epoch:  0039 D loss:-0.6228 G loss:-2.242\n",
      "Epoch:  0039 D loss:-0.7604 G loss:-2.304\n",
      "Epoch:  0039 D loss:-0.5792 G loss:-2.358\n",
      "Epoch:  0039 D loss:-0.5576 G loss:-2.263\n",
      "Epoch:  0039 D loss:-0.6731 G loss:-2.128\n",
      "Epoch:  0039 D loss:-0.6139 G loss:-2.442\n",
      "Epoch:  0039 D loss:-0.6112 G loss:-2.394\n",
      "Epoch:  0039 D loss:-0.4878 G loss:-2.238\n",
      "Epoch:  0039 D loss:-0.6306 G loss:-2.361\n",
      "Epoch:  0039 D loss:-0.488 G loss:-2.254\n",
      "Epoch:  0039 D loss:-0.5935 G loss:-2.198\n",
      "Epoch:  0039 D loss:-0.5402 G loss:-2.025\n",
      "Epoch:  0039 D loss:-0.5683 G loss:-2.22\n",
      "Epoch:  0039 D loss:-0.7983 G loss:-2.121\n",
      "Epoch:  0039 D loss:-0.5814 G loss:-2.262\n",
      "Epoch:  0039 D loss:-0.7298 G loss:-2.237\n",
      "Epoch:  0039 D loss:-0.5648 G loss:-2.247\n",
      "Epoch:  0039 D loss:-0.4803 G loss:-2.424\n",
      "Epoch:  0039 D loss:-0.5705 G loss:-2.183\n",
      "Epoch:  0039 D loss:-0.4651 G loss:-2.162\n",
      "Epoch:  0039 D loss:-0.6748 G loss:-2.514\n",
      "Epoch:  0039 D loss:-0.512 G loss:-2.635\n",
      "Epoch:  0039 D loss:-0.6798 G loss:-2.502\n",
      "Epoch:  0039 D loss:-0.5794 G loss:-2.369\n",
      "Epoch:  0039 D loss:-0.5557 G loss:-2.398\n",
      "Epoch:  0039 D loss:-0.491 G loss:-2.342\n",
      "Epoch:  0039 D loss:-0.4804 G loss:-2.422\n",
      "Epoch:  0039 D loss:-0.5754 G loss:-2.263\n",
      "Epoch:  0039 D loss:-0.5581 G loss:-2.374\n",
      "Epoch:  0039 D loss:-0.574 G loss:-2.355\n",
      "Epoch:  0039 D loss:-0.4436 G loss:-2.43\n",
      "Epoch:  0039 D loss:-0.6218 G loss:-2.356\n",
      "Epoch:  0039 D loss:-0.5132 G loss:-2.655\n",
      "Epoch:  0039 D loss:-0.5304 G loss:-2.393\n",
      "Epoch:  0039 D loss:-0.6278 G loss:-2.218\n",
      "Epoch:  0039 D loss:-0.6452 G loss:-2.278\n",
      "Epoch:  0039 D loss:-0.5179 G loss:-2.875\n",
      "Epoch:  0039 D loss:-0.5056 G loss:-2.748\n",
      "Epoch:  0039 D loss:-0.4996 G loss:-2.758\n",
      "Epoch:  0039 D loss:-0.3832 G loss:-2.784\n",
      "Epoch:  0039 D loss:-0.6598 G loss:-2.443\n",
      "Epoch:  0039 D loss:-0.5037 G loss:-2.448\n",
      "Epoch:  0039 D loss:-0.5174 G loss:-2.391\n",
      "Epoch:  0039 D loss:-0.5403 G loss:-2.322\n",
      "Epoch:  0039 D loss:-0.5691 G loss:-2.263\n",
      "Epoch:  0039 D loss:-0.4249 G loss:-2.338\n",
      "Epoch:  0039 D loss:-0.481 G loss:-2.245\n",
      "Epoch:  0039 D loss:-0.4601 G loss:-2.63\n",
      "Epoch:  0039 D loss:-0.5703 G loss:-2.444\n",
      "Epoch:  0039 D loss:-0.4477 G loss:-2.742\n",
      "Epoch:  0039 D loss:-0.5427 G loss:-2.935\n",
      "Epoch:  0039 D loss:-0.6875 G loss:-2.67\n",
      "Epoch:  0039 D loss:-0.4366 G loss:-2.724\n",
      "Epoch:  0039 D loss:-0.4925 G loss:-2.759\n",
      "Epoch:  0039 D loss:-0.5061 G loss:-2.626\n",
      "Epoch:  0039 D loss:-0.4281 G loss:-2.611\n",
      "Epoch:  0039 D loss:-0.3855 G loss:-2.663\n",
      "Epoch:  0039 D loss:-0.4515 G loss:-2.523\n",
      "Epoch:  0039 D loss:-0.5356 G loss:-2.473\n",
      "Epoch:  0039 D loss:-0.518 G loss:-2.435\n",
      "Epoch:  0039 D loss:-0.5189 G loss:-2.719\n",
      "Epoch:  0039 D loss:-0.5933 G loss:-2.725\n",
      "Epoch:  0039 D loss:-0.4694 G loss:-2.6\n",
      "Epoch:  0039 D loss:-0.6052 G loss:-2.696\n",
      "Epoch:  0039 D loss:-0.3959 G loss:-2.747\n",
      "Epoch:  0039 D loss:-0.4157 G loss:-2.657\n",
      "Epoch:  0039 D loss:-0.5391 G loss:-2.629\n",
      "Epoch:  0039 D loss:-0.4049 G loss:-2.89\n",
      "Epoch:  0039 D loss:-0.4679 G loss:-2.854\n",
      "Epoch:  0039 D loss:-0.5108 G loss:-2.7\n",
      "Epoch:  0039 D loss:-0.3975 G loss:-2.641\n",
      "Epoch:  0039 D loss:-0.4316 G loss:-2.755\n",
      "Epoch:  0039 D loss:-0.4812 G loss:-2.666\n",
      "Epoch:  0039 D loss:-0.5004 G loss:-2.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0039 D loss:-0.4903 G loss:-2.314\n",
      "Epoch:  0039 D loss:-0.4937 G loss:-2.523\n",
      "Epoch:  0039 D loss:-0.4603 G loss:-2.481\n",
      "Epoch:  0039 D loss:-0.4585 G loss:-2.604\n",
      "Epoch:  0039 D loss:-0.3971 G loss:-2.685\n",
      "Epoch:  0039 D loss:-0.4738 G loss:-2.484\n",
      "Epoch:  0039 D loss:-0.6359 G loss:-2.759\n",
      "Epoch:  0039 D loss:-0.5301 G loss:-2.874\n",
      "Epoch:  0039 D loss:-0.5114 G loss:-2.609\n",
      "Epoch:  0039 D loss:-0.5698 G loss:-2.447\n",
      "Epoch:  0039 D loss:-0.4467 G loss:-2.596\n",
      "Epoch:  0039 D loss:-0.51 G loss:-2.496\n",
      "Epoch:  0039 D loss:-0.5365 G loss:-2.365\n",
      "Epoch:  0039 D loss:-0.5307 G loss:-2.339\n",
      "Epoch:  0039 D loss:-0.6749 G loss:-2.25\n",
      "Epoch:  0039 D loss:-0.6291 G loss:-2.474\n",
      "Epoch:  0039 D loss:-0.6024 G loss:-2.222\n",
      "Epoch:  0039 D loss:-0.5521 G loss:-2.64\n",
      "Epoch:  0039 D loss:-0.5757 G loss:-2.526\n",
      "Epoch:  0039 D loss:-0.6045 G loss:-2.509\n",
      "Epoch:  0039 D loss:-0.49 G loss:-2.432\n",
      "Epoch:  0039 D loss:-0.6237 G loss:-2.305\n",
      "Epoch:  0039 D loss:-0.4928 G loss:-2.419\n",
      "Epoch:  0039 D loss:-0.6109 G loss:-2.542\n",
      "Epoch:  0039 D loss:-0.5021 G loss:-2.351\n",
      "Epoch:  0039 D loss:-0.4734 G loss:-2.429\n",
      "Epoch:  0039 D loss:-0.5561 G loss:-2.568\n",
      "Epoch:  0039 D loss:-0.6126 G loss:-2.535\n",
      "Epoch:  0039 D loss:-0.5659 G loss:-2.549\n",
      "Epoch:  0039 D loss:-0.5944 G loss:-2.453\n",
      "Epoch:  0039 D loss:-0.4689 G loss:-2.741\n",
      "Epoch:  0039 D loss:-0.5648 G loss:-2.432\n",
      "Epoch:  0039 D loss:-0.6526 G loss:-2.339\n",
      "Epoch:  0039 D loss:-0.5828 G loss:-2.372\n",
      "Epoch:  0039 D loss:-0.581 G loss:-2.765\n",
      "Epoch:  0039 D loss:-0.7191 G loss:-2.268\n",
      "Epoch:  0039 D loss:-0.5249 G loss:-2.733\n",
      "Epoch:  0039 D loss:-0.5511 G loss:-2.372\n",
      "Epoch:  0039 D loss:-0.6536 G loss:-2.482\n",
      "Epoch:  0039 D loss:-0.5034 G loss:-2.6\n",
      "Epoch:  0039 D loss:-0.6429 G loss:-2.389\n",
      "Epoch:  0039 D loss:-0.4525 G loss:-2.393\n",
      "Epoch:  0039 D loss:-0.689 G loss:-2.507\n",
      "Epoch:  0039 D loss:-0.5941 G loss:-2.297\n",
      "Epoch:  0039 D loss:-0.4615 G loss:-2.489\n",
      "Epoch:  0039 D loss:-0.5207 G loss:-2.391\n",
      "Epoch:  0039 D loss:-0.6366 G loss:-2.606\n",
      "Epoch:  0039 D loss:-0.5238 G loss:-2.498\n",
      "Epoch:  0039 D loss:-0.5232 G loss:-2.41\n",
      "Epoch:  0039 D loss:-0.6268 G loss:-2.273\n",
      "Epoch:  0039 D loss:-0.6163 G loss:-2.344\n",
      "Epoch:  0039 D loss:-0.5182 G loss:-2.398\n",
      "Epoch:  0039 D loss:-0.4932 G loss:-2.591\n",
      "Epoch:  0039 D loss:-0.5783 G loss:-2.541\n",
      "Epoch:  0039 D loss:-0.5315 G loss:-2.72\n",
      "Epoch:  0039 D loss:-0.5585 G loss:-2.543\n",
      "Epoch:  0039 D loss:-0.669 G loss:-2.392\n",
      "Epoch:  0039 D loss:-0.5608 G loss:-2.422\n",
      "Epoch:  0039 D loss:-0.7518 G loss:-2.317\n",
      "Epoch:  0039 D loss:-0.6661 G loss:-2.289\n",
      "Epoch:  0039 D loss:-0.5288 G loss:-2.227\n",
      "Epoch:  0039 D loss:-0.5932 G loss:-2.351\n",
      "Epoch:  0039 D loss:-0.579 G loss:-2.194\n",
      "Epoch:  0039 D loss:-0.5985 G loss:-2.486\n",
      "Epoch:  0039 D loss:-0.5122 G loss:-2.292\n",
      "Epoch:  0039 D loss:-0.5714 G loss:-2.133\n",
      "Epoch:  0039 D loss:-0.6328 G loss:-2.243\n",
      "Epoch:  0039 D loss:-0.6565 G loss:-2.266\n",
      "Epoch:  0039 D loss:-0.5581 G loss:-2.59\n",
      "Epoch:  0039 D loss:-0.5624 G loss:-2.497\n",
      "Epoch:  0039 D loss:-0.5562 G loss:-2.715\n",
      "Epoch:  0039 D loss:-0.5166 G loss:-2.627\n",
      "Epoch:  0039 D loss:-0.5254 G loss:-2.408\n",
      "Epoch:  0039 D loss:-0.6404 G loss:-2.413\n",
      "Epoch:  0039 D loss:-0.4554 G loss:-2.454\n",
      "Epoch:  0039 D loss:-0.632 G loss:-2.364\n",
      "Epoch:  0039 D loss:-0.5778 G loss:-2.307\n",
      "Epoch:  0039 D loss:-0.5247 G loss:-2.403\n",
      "Epoch:  0039 D loss:-0.5609 G loss:-2.228\n",
      "Epoch:  0039 D loss:-0.6201 G loss:-2.355\n",
      "Epoch:  0039 D loss:-0.4525 G loss:-2.365\n",
      "Epoch:  0039 D loss:-0.5626 G loss:-2.318\n",
      "Epoch:  0039 D loss:-0.6039 G loss:-2.374\n",
      "Epoch:  0039 D loss:-0.5234 G loss:-2.231\n",
      "Epoch:  0039 D loss:-0.4712 G loss:-2.392\n",
      "Epoch:  0039 D loss:-0.6179 G loss:-2.269\n",
      "Epoch:  0039 D loss:-0.665 G loss:-2.468\n",
      "Epoch:  0039 D loss:-0.5303 G loss:-2.382\n",
      "Epoch:  0039 D loss:-0.5719 G loss:-2.593\n",
      "Epoch:  0039 D loss:-0.567 G loss:-2.598\n",
      "Epoch:  0039 D loss:-0.6266 G loss:-2.16\n",
      "Epoch:  0039 D loss:-0.5761 G loss:-2.175\n",
      "Epoch:  0039 D loss:-0.4741 G loss:-2.345\n",
      "Epoch:  0039 D loss:-0.4098 G loss:-2.482\n",
      "Epoch:  0039 D loss:-0.612 G loss:-2.216\n",
      "Epoch:  0039 D loss:-0.5256 G loss:-2.499\n",
      "Epoch:  0039 D loss:-0.5867 G loss:-2.161\n",
      "Epoch:  0039 D loss:-0.5929 G loss:-2.197\n",
      "Epoch:  0039 D loss:-0.6781 G loss:-2.031\n",
      "Epoch:  0039 D loss:-0.5491 G loss:-2.351\n",
      "Epoch:  0039 D loss:-0.6577 G loss:-2.461\n",
      "Epoch:  0039 D loss:-0.5519 G loss:-2.411\n",
      "Epoch:  0039 D loss:-0.5225 G loss:-2.36\n",
      "Epoch:  0039 D loss:-0.4821 G loss:-2.613\n",
      "Epoch:  0039 D loss:-0.6681 G loss:-2.403\n",
      "Epoch:  0039 D loss:-0.6061 G loss:-2.481\n",
      "Epoch:  0039 D loss:-0.494 G loss:-2.175\n",
      "Epoch:  0039 D loss:-0.5679 G loss:-2.162\n",
      "Epoch:  0039 D loss:-0.5962 G loss:-2.194\n",
      "Epoch:  0039 D loss:-0.5318 G loss:-2.221\n",
      "Epoch:  0039 D loss:-0.5903 G loss:-2.129\n",
      "Epoch:  0039 D loss:-0.4261 G loss:-2.315\n",
      "Epoch:  0039 D loss:-0.6368 G loss:-2.374\n",
      "Epoch:  0039 D loss:-0.5789 G loss:-2.192\n",
      "Epoch:  0039 D loss:-0.5472 G loss:-2.266\n",
      "Epoch:  0039 D loss:-0.5881 G loss:-2.419\n",
      "Epoch:  0039 D loss:-0.5038 G loss:-2.648\n",
      "Epoch:  0039 D loss:-0.5028 G loss:-2.492\n",
      "Epoch:  0039 D loss:-0.562 G loss:-2.348\n",
      "Epoch:  0039 D loss:-0.5232 G loss:-2.33\n",
      "Epoch:  0039 D loss:-0.5838 G loss:-2.293\n",
      "Epoch:  0039 D loss:-0.6391 G loss:-2.078\n",
      "Epoch:  0039 D loss:-0.5352 G loss:-2.237\n",
      "Epoch:  0039 D loss:-0.4853 G loss:-2.335\n",
      "Epoch:  0039 D loss:-0.5322 G loss:-2.207\n",
      "Epoch:  0039 D loss:-0.6374 G loss:-2.288\n",
      "Epoch:  0039 D loss:-0.4099 G loss:-2.441\n",
      "Epoch:  0039 D loss:-0.5002 G loss:-2.506\n",
      "Epoch:  0039 D loss:-0.4785 G loss:-2.36\n",
      "Epoch:  0039 D loss:-0.4848 G loss:-2.452\n",
      "Epoch:  0039 D loss:-0.4773 G loss:-2.617\n",
      "Epoch:  0039 D loss:-0.7071 G loss:-2.66\n",
      "Epoch:  0039 D loss:-0.43 G loss:-2.461\n",
      "Epoch:  0039 D loss:-0.4299 G loss:-2.624\n",
      "Epoch:  0039 D loss:-0.5344 G loss:-2.434\n",
      "Epoch:  0039 D loss:-0.4972 G loss:-2.326\n",
      "Epoch:  0039 D loss:-0.4641 G loss:-2.339\n",
      "Epoch:  0039 D loss:-0.5541 G loss:-2.333\n",
      "Epoch:  0039 D loss:-0.5381 G loss:-2.284\n",
      "Epoch:  0039 D loss:-0.4774 G loss:-2.292\n",
      "Epoch:  0039 D loss:-0.4102 G loss:-2.217\n",
      "Epoch:  0039 D loss:-0.4551 G loss:-2.505\n",
      "Epoch:  0039 D loss:-0.4556 G loss:-2.428\n",
      "Epoch:  0039 D loss:-0.6663 G loss:-2.146\n",
      "Epoch:  0039 D loss:-0.5201 G loss:-2.221\n",
      "Epoch:  0039 D loss:-0.5975 G loss:-2.228\n",
      "Epoch:  0039 D loss:-0.5945 G loss:-2.293\n",
      "Epoch:  0039 D loss:-0.6541 G loss:-2.253\n",
      "Epoch:  0039 D loss:-0.5379 G loss:-2.526\n",
      "Epoch:  0039 D loss:-0.55 G loss:-2.509\n",
      "Epoch:  0039 D loss:-0.4313 G loss:-2.643\n",
      "Epoch:  0039 D loss:-0.5448 G loss:-2.341\n",
      "Epoch:  0039 D loss:-0.6761 G loss:-2.341\n",
      "Epoch:  0039 D loss:-0.4425 G loss:-2.743\n",
      "Epoch:  0039 D loss:-0.5715 G loss:-2.444\n",
      "Epoch:  0039 D loss:-0.5951 G loss:-2.129\n",
      "Epoch:  0039 D loss:-0.4753 G loss:-2.293\n",
      "Epoch:  0039 D loss:-0.5468 G loss:-2.128\n",
      "Epoch:  0039 D loss:-0.4751 G loss:-2.289\n",
      "Epoch:  0039 D loss:-0.7279 G loss:-2.361\n",
      "Epoch:  0039 D loss:-0.5495 G loss:-2.186\n",
      "Epoch:  0039 D loss:-0.6309 G loss:-2.254\n",
      "Epoch:  0039 D loss:-0.5547 G loss:-2.397\n",
      "Epoch:  0039 D loss:-0.6135 G loss:-2.204\n",
      "Epoch:  0039 D loss:-0.495 G loss:-2.682\n",
      "Epoch:  0039 D loss:-0.4842 G loss:-2.466\n",
      "Epoch:  0039 D loss:-0.556 G loss:-2.387\n",
      "Epoch:  0039 D loss:-0.5637 G loss:-2.418\n",
      "Epoch:  0039 D loss:-0.425 G loss:-2.247\n",
      "Epoch:  0039 D loss:-0.5743 G loss:-2.305\n",
      "Epoch:  0039 D loss:-0.4911 G loss:-2.368\n",
      "Epoch:  0039 D loss:-0.5391 G loss:-2.31\n",
      "Epoch:  0039 D loss:-0.5142 G loss:-2.47\n",
      "Epoch:  0039 D loss:-0.4786 G loss:-2.335\n",
      "Epoch:  0039 D loss:-0.5337 G loss:-2.305\n",
      "Epoch:  0039 D loss:-0.4572 G loss:-2.454\n",
      "Epoch:  0039 D loss:-0.5114 G loss:-2.388\n",
      "Epoch:  0039 D loss:-0.4259 G loss:-2.366\n",
      "Epoch:  0039 D loss:-0.4618 G loss:-2.493\n",
      "Epoch:  0039 D loss:-0.444 G loss:-2.804\n",
      "Epoch:  0039 D loss:-0.612 G loss:-2.435\n",
      "Epoch:  0039 D loss:-0.4911 G loss:-2.652\n",
      "Epoch:  0039 D loss:-0.6787 G loss:-2.535\n",
      "Epoch:  0039 D loss:-0.4872 G loss:-2.633\n",
      "Epoch:  0039 D loss:-0.4698 G loss:-2.549\n",
      "Epoch:  0039 D loss:-0.6111 G loss:-2.355\n",
      "Epoch:  0039 D loss:-0.5392 G loss:-2.566\n",
      "Epoch:  0039 D loss:-0.4882 G loss:-2.389\n",
      "Epoch:  0039 D loss:-0.584 G loss:-2.176\n",
      "Epoch:  0039 D loss:-0.5263 G loss:-2.506\n",
      "Epoch:  0039 D loss:-0.588 G loss:-2.258\n",
      "Epoch:  0039 D loss:-0.5364 G loss:-2.147\n",
      "Epoch:  0039 D loss:-0.6397 G loss:-2.45\n",
      "Epoch:  0039 D loss:-0.5299 G loss:-2.329\n",
      "Epoch:  0039 D loss:-0.757 G loss:-2.119\n",
      "Epoch:  0039 D loss:-0.6459 G loss:-2.352\n",
      "Epoch:  0039 D loss:-0.7201 G loss:-1.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0039 D loss:-0.5874 G loss:-2.263\n",
      "Epoch:  0039 D loss:-0.6366 G loss:-2.359\n",
      "Epoch:  0039 D loss:-0.5036 G loss:-2.452\n",
      "Epoch:  0039 D loss:-0.6354 G loss:-2.462\n",
      "Epoch:  0039 D loss:-0.5626 G loss:-2.427\n",
      "Epoch:  0039 D loss:-0.4829 G loss:-2.594\n",
      "Epoch:  0039 D loss:-0.5336 G loss:-2.565\n",
      "Epoch:  0039 D loss:-0.6406 G loss:-2.268\n",
      "Epoch:  0039 D loss:-0.704 G loss:-2.258\n",
      "Epoch:  0039 D loss:-0.4599 G loss:-2.227\n",
      "Epoch:  0039 D loss:-0.559 G loss:-2.236\n",
      "Epoch:  0039 D loss:-0.5941 G loss:-2.278\n",
      "Epoch:  0039 D loss:-0.6416 G loss:-2.127\n",
      "Epoch:  0039 D loss:-0.6009 G loss:-2.098\n",
      "Epoch:  0039 D loss:-0.5534 G loss:-2.07\n",
      "Epoch:  0039 D loss:-0.6193 G loss:-2.027\n",
      "Epoch:  0039 D loss:-0.7087 G loss:-2.221\n",
      "Epoch:  0039 D loss:-0.6111 G loss:-2.082\n",
      "Epoch:  0039 D loss:-0.7534 G loss:-2.131\n",
      "Epoch:  0039 D loss:-0.4695 G loss:-2.552\n",
      "Epoch:  0039 D loss:-0.5817 G loss:-2.307\n",
      "Epoch:  0039 D loss:-0.6607 G loss:-2.303\n",
      "Epoch:  0039 D loss:-0.5068 G loss:-2.372\n",
      "Epoch:  0039 D loss:-0.488 G loss:-2.459\n",
      "Epoch:  0039 D loss:-0.6054 G loss:-2.398\n",
      "Epoch:  0039 D loss:-0.6419 G loss:-2.211\n",
      "Epoch:  0039 D loss:-0.6666 G loss:-2.15\n",
      "Epoch:  0039 D loss:-0.5814 G loss:-2.105\n",
      "Epoch:  0039 D loss:-0.6461 G loss:-2.31\n",
      "Epoch:  0039 D loss:-0.7501 G loss:-2.28\n",
      "Epoch:  0039 D loss:-0.6588 G loss:-2.263\n",
      "Epoch:  0039 D loss:-0.685 G loss:-2.33\n",
      "Epoch:  0039 D loss:-0.6729 G loss:-2.324\n",
      "Epoch:  0039 D loss:-0.662 G loss:-2.298\n",
      "Epoch:  0039 D loss:-0.6587 G loss:-2.272\n",
      "Epoch:  0039 D loss:-0.7136 G loss:-2.36\n",
      "Epoch:  0039 D loss:-0.5151 G loss:-2.225\n",
      "Epoch:  0039 D loss:-0.582 G loss:-2.424\n",
      "Epoch:  0039 D loss:-0.6298 G loss:-2.224\n",
      "Epoch:  0039 D loss:-0.7081 G loss:-2.279\n",
      "Epoch:  0039 D loss:-0.6856 G loss:-2.164\n",
      "Epoch:  0039 D loss:-0.7844 G loss:-2.101\n",
      "Epoch:  0039 D loss:-0.5478 G loss:-2.202\n",
      "Epoch:  0039 D loss:-0.5855 G loss:-2.364\n",
      "Epoch:  0039 D loss:-0.6511 G loss:-2.35\n",
      "Epoch:  0039 D loss:-0.566 G loss:-2.431\n",
      "Epoch:  0039 D loss:-0.6293 G loss:-2.225\n",
      "Epoch:  0039 D loss:-0.6609 G loss:-2.325\n",
      "Epoch:  0039 D loss:-0.6033 G loss:-2.156\n",
      "Epoch:  0039 D loss:-0.5402 G loss:-2.22\n",
      "Epoch:  0039 D loss:-0.5067 G loss:-2.259\n",
      "Epoch:  0039 D loss:-0.6194 G loss:-2.355\n",
      "Epoch:  0039 D loss:-0.5623 G loss:-2.187\n",
      "Epoch:  0039 D loss:-0.5886 G loss:-2.313\n",
      "Epoch:  0039 D loss:-0.5653 G loss:-2.308\n",
      "Epoch:  0039 D loss:-0.4942 G loss:-2.599\n",
      "Epoch:  0039 D loss:-0.6764 G loss:-2.645\n",
      "Epoch:  0039 D loss:-0.5583 G loss:-2.573\n",
      "Epoch:  0039 D loss:-0.6348 G loss:-2.384\n",
      "Epoch:  0039 D loss:-0.6439 G loss:-2.39\n",
      "Epoch:  0039 D loss:-0.6443 G loss:-2.314\n",
      "Epoch:  0039 D loss:-0.6422 G loss:-2.318\n",
      "Epoch:  0039 D loss:-0.5279 G loss:-2.438\n",
      "Epoch:  0039 D loss:-0.6025 G loss:-2.363\n",
      "Epoch:  0039 D loss:-0.7637 G loss:-1.978\n",
      "Epoch:  0039 D loss:-0.5776 G loss:-2.368\n",
      "Epoch:  0039 D loss:-0.645 G loss:-2.456\n",
      "Epoch:  0039 D loss:-0.5227 G loss:-2.354\n",
      "Epoch:  0039 D loss:-0.5142 G loss:-2.346\n",
      "Epoch:  0039 D loss:-0.5213 G loss:-2.295\n",
      "Epoch:  0039 D loss:-0.7149 G loss:-2.351\n",
      "Epoch:  0039 D loss:-0.5071 G loss:-2.463\n",
      "Epoch:  0039 D loss:-0.5857 G loss:-2.46\n",
      "Epoch:  0039 D loss:-0.4971 G loss:-2.675\n",
      "Epoch:  0039 D loss:-0.5681 G loss:-2.55\n",
      "Epoch:  0039 D loss:-0.582 G loss:-2.545\n",
      "Epoch:  0039 D loss:-0.5338 G loss:-2.685\n",
      "Epoch:  0039 D loss:-0.5334 G loss:-2.672\n",
      "Epoch:  0039 D loss:-0.5786 G loss:-2.752\n",
      "Epoch:  0039 D loss:-0.6119 G loss:-2.582\n",
      "Epoch:  0039 D loss:-0.6698 G loss:-2.5\n",
      "Epoch:  0039 D loss:-0.7793 G loss:-2.297\n",
      "Epoch:  0039 D loss:-0.6144 G loss:-2.378\n",
      "Epoch:  0039 D loss:-0.5704 G loss:-2.219\n",
      "Epoch:  0039 D loss:-0.5163 G loss:-2.079\n",
      "Epoch:  0039 D loss:-0.5639 G loss:-2.152\n",
      "Epoch:  0039 D loss:-0.4941 G loss:-2.328\n",
      "Epoch:  0039 D loss:-0.6125 G loss:-2.341\n",
      "Epoch:  0039 D loss:-0.543 G loss:-2.305\n",
      "Epoch:  0039 D loss:-0.5718 G loss:-2.368\n",
      "Epoch:  0039 D loss:-0.5476 G loss:-2.684\n",
      "Epoch:  0039 D loss:-0.5862 G loss:-2.455\n",
      "Epoch:  0039 D loss:-0.5607 G loss:-2.746\n",
      "Epoch:  0039 D loss:-0.515 G loss:-2.434\n",
      "Epoch:  0039 D loss:-0.5135 G loss:-2.414\n",
      "Epoch:  0039 D loss:-0.4555 G loss:-2.832\n",
      "Epoch:  0039 D loss:-0.5205 G loss:-2.695\n",
      "Epoch:  0039 D loss:-0.5713 G loss:-2.458\n",
      "Epoch:  0039 D loss:-0.5355 G loss:-2.555\n",
      "Epoch:  0039 D loss:-0.4499 G loss:-2.62\n",
      "Epoch:  0039 D loss:-0.6174 G loss:-2.45\n",
      "Epoch:  0039 D loss:-0.6516 G loss:-2.374\n",
      "Epoch:  0039 D loss:-0.5087 G loss:-2.27\n",
      "Epoch:  0039 D loss:-0.564 G loss:-2.322\n",
      "Epoch:  0039 D loss:-0.5016 G loss:-2.624\n",
      "Epoch:  0039 D loss:-0.3704 G loss:-2.634\n",
      "Epoch:  0039 D loss:-0.5351 G loss:-2.44\n",
      "Epoch:  0039 D loss:-0.4919 G loss:-2.633\n",
      "Epoch:  0039 D loss:-0.5461 G loss:-2.451\n",
      "Epoch:  0039 D loss:-0.4122 G loss:-2.864\n",
      "Epoch:  0039 D loss:-0.5308 G loss:-2.709\n",
      "Epoch:  0039 D loss:-0.5911 G loss:-2.6\n",
      "Epoch:  0039 D loss:-0.5338 G loss:-2.474\n",
      "Epoch:  0039 D loss:-0.5638 G loss:-2.604\n",
      "Epoch:  0039 D loss:-0.5671 G loss:-2.59\n",
      "Epoch:  0039 D loss:-0.4963 G loss:-2.463\n",
      "Epoch:  0039 D loss:-0.6337 G loss:-2.374\n",
      "Epoch:  0039 D loss:-0.5521 G loss:-2.427\n",
      "Epoch:  0039 D loss:-0.4603 G loss:-2.471\n",
      "Epoch:  0039 D loss:-0.4647 G loss:-2.601\n",
      "Epoch:  0039 D loss:-0.4284 G loss:-2.349\n",
      "Epoch:  0039 D loss:-0.7236 G loss:-2.512\n",
      "Epoch:  0039 D loss:-0.5849 G loss:-2.572\n",
      "Epoch:  0040 D loss:-0.5078 G loss:-2.497\n",
      "Epoch:  0040 D loss:-0.4515 G loss:-2.493\n",
      "Epoch:  0040 D loss:-0.6167 G loss:-2.363\n",
      "Epoch:  0040 D loss:-0.4844 G loss:-2.772\n",
      "Epoch:  0040 D loss:-0.6346 G loss:-2.288\n",
      "Epoch:  0040 D loss:-0.5255 G loss:-2.577\n",
      "Epoch:  0040 D loss:-0.4636 G loss:-3.012\n",
      "Epoch:  0040 D loss:-0.6766 G loss:-2.609\n",
      "Epoch:  0040 D loss:-0.4081 G loss:-2.662\n",
      "Epoch:  0040 D loss:-0.5962 G loss:-2.713\n",
      "Epoch:  0040 D loss:-0.5007 G loss:-2.676\n",
      "Epoch:  0040 D loss:-0.6017 G loss:-2.524\n",
      "Epoch:  0040 D loss:-0.5498 G loss:-2.418\n",
      "Epoch:  0040 D loss:-0.4801 G loss:-2.435\n",
      "Epoch:  0040 D loss:-0.485 G loss:-2.401\n",
      "Epoch:  0040 D loss:-0.666 G loss:-2.118\n",
      "Epoch:  0040 D loss:-0.5369 G loss:-2.205\n",
      "Epoch:  0040 D loss:-0.6361 G loss:-2.349\n",
      "Epoch:  0040 D loss:-0.5997 G loss:-2.337\n",
      "Epoch:  0040 D loss:-0.5564 G loss:-2.39\n",
      "Epoch:  0040 D loss:-0.4669 G loss:-2.632\n",
      "Epoch:  0040 D loss:-0.6112 G loss:-2.559\n",
      "Epoch:  0040 D loss:-0.4463 G loss:-2.734\n",
      "Epoch:  0040 D loss:-0.63 G loss:-2.823\n",
      "Epoch:  0040 D loss:-0.5222 G loss:-2.513\n",
      "Epoch:  0040 D loss:-0.5583 G loss:-2.644\n",
      "Epoch:  0040 D loss:-0.5758 G loss:-2.596\n",
      "Epoch:  0040 D loss:-0.624 G loss:-2.434\n",
      "Epoch:  0040 D loss:-0.445 G loss:-2.628\n",
      "Epoch:  0040 D loss:-0.5451 G loss:-2.509\n",
      "Epoch:  0040 D loss:-0.7224 G loss:-2.407\n",
      "Epoch:  0040 D loss:-0.5955 G loss:-2.416\n",
      "Epoch:  0040 D loss:-0.5481 G loss:-2.323\n",
      "Epoch:  0040 D loss:-0.7249 G loss:-2.248\n",
      "Epoch:  0040 D loss:-0.5433 G loss:-2.131\n",
      "Epoch:  0040 D loss:-0.6298 G loss:-2.414\n",
      "Epoch:  0040 D loss:-0.6209 G loss:-2.367\n",
      "Epoch:  0040 D loss:-0.5519 G loss:-2.303\n",
      "Epoch:  0040 D loss:-0.594 G loss:-2.257\n",
      "Epoch:  0040 D loss:-0.6167 G loss:-2.16\n",
      "Epoch:  0040 D loss:-0.5423 G loss:-2.46\n",
      "Epoch:  0040 D loss:-0.6373 G loss:-2.669\n",
      "Epoch:  0040 D loss:-0.6762 G loss:-2.63\n",
      "Epoch:  0040 D loss:-0.6079 G loss:-2.474\n",
      "Epoch:  0040 D loss:-0.6618 G loss:-2.455\n",
      "Epoch:  0040 D loss:-0.6361 G loss:-2.397\n",
      "Epoch:  0040 D loss:-0.5841 G loss:-2.545\n",
      "Epoch:  0040 D loss:-0.6282 G loss:-2.294\n",
      "Epoch:  0040 D loss:-0.566 G loss:-2.39\n",
      "Epoch:  0040 D loss:-0.5086 G loss:-2.281\n",
      "Epoch:  0040 D loss:-0.5662 G loss:-2.28\n",
      "Epoch:  0040 D loss:-0.5355 G loss:-2.191\n",
      "Epoch:  0040 D loss:-0.7758 G loss:-2.38\n",
      "Epoch:  0040 D loss:-0.6457 G loss:-2.28\n",
      "Epoch:  0040 D loss:-0.6956 G loss:-2.411\n",
      "Epoch:  0040 D loss:-0.7239 G loss:-2.487\n",
      "Epoch:  0040 D loss:-0.6032 G loss:-2.501\n",
      "Epoch:  0040 D loss:-0.6414 G loss:-2.305\n",
      "Epoch:  0040 D loss:-0.5994 G loss:-2.683\n",
      "Epoch:  0040 D loss:-0.548 G loss:-2.514\n",
      "Epoch:  0040 D loss:-0.6014 G loss:-2.371\n",
      "Epoch:  0040 D loss:-0.6694 G loss:-2.352\n",
      "Epoch:  0040 D loss:-0.54 G loss:-2.373\n",
      "Epoch:  0040 D loss:-0.5782 G loss:-2.57\n",
      "Epoch:  0040 D loss:-0.4658 G loss:-2.51\n",
      "Epoch:  0040 D loss:-0.6005 G loss:-2.553\n",
      "Epoch:  0040 D loss:-0.5668 G loss:-2.315\n",
      "Epoch:  0040 D loss:-0.5191 G loss:-2.224\n",
      "Epoch:  0040 D loss:-0.522 G loss:-2.526\n",
      "Epoch:  0040 D loss:-0.4596 G loss:-2.362\n",
      "Epoch:  0040 D loss:-0.4756 G loss:-2.47\n",
      "Epoch:  0040 D loss:-0.5719 G loss:-2.429\n",
      "Epoch:  0040 D loss:-0.5934 G loss:-2.399\n",
      "Epoch:  0040 D loss:-0.6924 G loss:-2.49\n",
      "Epoch:  0040 D loss:-0.6488 G loss:-2.137\n",
      "Epoch:  0040 D loss:-0.5447 G loss:-2.587\n",
      "Epoch:  0040 D loss:-0.6087 G loss:-2.683\n",
      "Epoch:  0040 D loss:-0.6749 G loss:-2.546\n",
      "Epoch:  0040 D loss:-0.5568 G loss:-2.332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0040 D loss:-0.5057 G loss:-2.627\n",
      "Epoch:  0040 D loss:-0.5306 G loss:-2.628\n",
      "Epoch:  0040 D loss:-0.5209 G loss:-2.388\n",
      "Epoch:  0040 D loss:-0.5721 G loss:-2.216\n",
      "Epoch:  0040 D loss:-0.621 G loss:-2.097\n",
      "Epoch:  0040 D loss:-0.6512 G loss:-2.194\n",
      "Epoch:  0040 D loss:-0.7294 G loss:-2.251\n",
      "Epoch:  0040 D loss:-0.7393 G loss:-1.963\n",
      "Epoch:  0040 D loss:-0.5138 G loss:-2.105\n",
      "Epoch:  0040 D loss:-0.6754 G loss:-2.272\n",
      "Epoch:  0040 D loss:-0.698 G loss:-2.33\n",
      "Epoch:  0040 D loss:-0.6235 G loss:-2.13\n",
      "Epoch:  0040 D loss:-0.4586 G loss:-2.38\n",
      "Epoch:  0040 D loss:-0.5927 G loss:-2.422\n",
      "Epoch:  0040 D loss:-0.7358 G loss:-2.383\n",
      "Epoch:  0040 D loss:-0.564 G loss:-2.63\n",
      "Epoch:  0040 D loss:-0.6081 G loss:-2.501\n",
      "Epoch:  0040 D loss:-0.6079 G loss:-2.558\n",
      "Epoch:  0040 D loss:-0.5929 G loss:-2.365\n",
      "Epoch:  0040 D loss:-0.4805 G loss:-2.536\n",
      "Epoch:  0040 D loss:-0.5604 G loss:-2.373\n",
      "Epoch:  0040 D loss:-0.7372 G loss:-2.311\n",
      "Epoch:  0040 D loss:-0.4744 G loss:-2.125\n",
      "Epoch:  0040 D loss:-0.5405 G loss:-2.219\n",
      "Epoch:  0040 D loss:-0.688 G loss:-2.251\n",
      "Epoch:  0040 D loss:-0.735 G loss:-2.072\n",
      "Epoch:  0040 D loss:-0.4848 G loss:-2.275\n",
      "Epoch:  0040 D loss:-0.5737 G loss:-2.42\n",
      "Epoch:  0040 D loss:-0.7767 G loss:-2.232\n",
      "Epoch:  0040 D loss:-0.7152 G loss:-2.174\n",
      "Epoch:  0040 D loss:-0.6342 G loss:-2.419\n",
      "Epoch:  0040 D loss:-0.6696 G loss:-2.267\n",
      "Epoch:  0040 D loss:-0.6308 G loss:-2.207\n",
      "Epoch:  0040 D loss:-0.9192 G loss:-2.167\n",
      "Epoch:  0040 D loss:-0.6706 G loss:-2.009\n",
      "Epoch:  0040 D loss:-0.8092 G loss:-2.116\n",
      "Epoch:  0040 D loss:-0.6082 G loss:-2.152\n",
      "Epoch:  0040 D loss:-0.6996 G loss:-1.923\n",
      "Epoch:  0040 D loss:-0.7209 G loss:-1.994\n",
      "Epoch:  0040 D loss:-0.6728 G loss:-1.946\n",
      "Epoch:  0040 D loss:-0.6737 G loss:-2.239\n",
      "Epoch:  0040 D loss:-0.8334 G loss:-2.194\n",
      "Epoch:  0040 D loss:-0.5332 G loss:-2.527\n",
      "Epoch:  0040 D loss:-0.6333 G loss:-2.447\n",
      "Epoch:  0040 D loss:-0.7678 G loss:-2.467\n",
      "Epoch:  0040 D loss:-0.8417 G loss:-2.423\n",
      "Epoch:  0040 D loss:-0.6163 G loss:-2.271\n",
      "Epoch:  0040 D loss:-0.5768 G loss:-2.153\n",
      "Epoch:  0040 D loss:-0.6675 G loss:-2.278\n",
      "Epoch:  0040 D loss:-0.5652 G loss:-2.192\n",
      "Epoch:  0040 D loss:-0.5911 G loss:-2.047\n",
      "Epoch:  0040 D loss:-0.6523 G loss:-2.276\n",
      "Epoch:  0040 D loss:-0.6024 G loss:-2.261\n",
      "Epoch:  0040 D loss:-0.5059 G loss:-2.227\n",
      "Epoch:  0040 D loss:-0.4611 G loss:-2.525\n",
      "Epoch:  0040 D loss:-0.4767 G loss:-2.327\n",
      "Epoch:  0040 D loss:-0.5514 G loss:-2.504\n",
      "Epoch:  0040 D loss:-0.6503 G loss:-2.155\n",
      "Epoch:  0040 D loss:-0.6223 G loss:-2.278\n",
      "Epoch:  0040 D loss:-0.6565 G loss:-2.486\n",
      "Epoch:  0040 D loss:-0.7609 G loss:-2.263\n",
      "Epoch:  0040 D loss:-0.5705 G loss:-2.541\n",
      "Epoch:  0040 D loss:-0.5569 G loss:-2.503\n",
      "Epoch:  0040 D loss:-0.5554 G loss:-2.299\n",
      "Epoch:  0040 D loss:-0.4764 G loss:-2.738\n",
      "Epoch:  0040 D loss:-0.6057 G loss:-2.337\n",
      "Epoch:  0040 D loss:-0.6136 G loss:-2.294\n",
      "Epoch:  0040 D loss:-0.5541 G loss:-2.423\n",
      "Epoch:  0040 D loss:-0.5192 G loss:-2.403\n",
      "Epoch:  0040 D loss:-0.5097 G loss:-2.353\n",
      "Epoch:  0040 D loss:-0.6277 G loss:-2.203\n",
      "Epoch:  0040 D loss:-0.5457 G loss:-2.435\n",
      "Epoch:  0040 D loss:-0.525 G loss:-2.513\n",
      "Epoch:  0040 D loss:-0.5315 G loss:-2.171\n",
      "Epoch:  0040 D loss:-0.4848 G loss:-2.369\n",
      "Epoch:  0040 D loss:-0.5256 G loss:-2.4\n",
      "Epoch:  0040 D loss:-0.5698 G loss:-2.331\n",
      "Epoch:  0040 D loss:-0.5152 G loss:-2.655\n",
      "Epoch:  0040 D loss:-0.5446 G loss:-2.496\n",
      "Epoch:  0040 D loss:-0.7558 G loss:-2.391\n",
      "Epoch:  0040 D loss:-0.4817 G loss:-2.456\n",
      "Epoch:  0040 D loss:-0.5733 G loss:-2.425\n",
      "Epoch:  0040 D loss:-0.5648 G loss:-2.465\n",
      "Epoch:  0040 D loss:-0.6555 G loss:-2.525\n",
      "Epoch:  0040 D loss:-0.5593 G loss:-2.562\n",
      "Epoch:  0040 D loss:-0.5914 G loss:-2.412\n",
      "Epoch:  0040 D loss:-0.5592 G loss:-2.321\n",
      "Epoch:  0040 D loss:-0.5495 G loss:-2.297\n",
      "Epoch:  0040 D loss:-0.6199 G loss:-2.133\n",
      "Epoch:  0040 D loss:-0.6096 G loss:-2.259\n",
      "Epoch:  0040 D loss:-0.522 G loss:-2.395\n",
      "Epoch:  0040 D loss:-0.5424 G loss:-2.34\n",
      "Epoch:  0040 D loss:-0.6095 G loss:-2.208\n",
      "Epoch:  0040 D loss:-0.4099 G loss:-2.676\n",
      "Epoch:  0040 D loss:-0.496 G loss:-2.421\n",
      "Epoch:  0040 D loss:-0.5515 G loss:-2.44\n",
      "Epoch:  0040 D loss:-0.4686 G loss:-2.582\n",
      "Epoch:  0040 D loss:-0.6683 G loss:-2.169\n",
      "Epoch:  0040 D loss:-0.5128 G loss:-2.43\n",
      "Epoch:  0040 D loss:-0.5805 G loss:-2.381\n",
      "Epoch:  0040 D loss:-0.5564 G loss:-2.435\n",
      "Epoch:  0040 D loss:-0.4754 G loss:-2.5\n",
      "Epoch:  0040 D loss:-0.5397 G loss:-2.66\n",
      "Epoch:  0040 D loss:-0.5094 G loss:-2.43\n",
      "Epoch:  0040 D loss:-0.5463 G loss:-2.625\n",
      "Epoch:  0040 D loss:-0.4672 G loss:-2.31\n",
      "Epoch:  0040 D loss:-0.5429 G loss:-2.242\n",
      "Epoch:  0040 D loss:-0.5357 G loss:-2.333\n",
      "Epoch:  0040 D loss:-0.6008 G loss:-2.506\n",
      "Epoch:  0040 D loss:-0.5846 G loss:-2.314\n",
      "Epoch:  0040 D loss:-0.4538 G loss:-2.585\n",
      "Epoch:  0040 D loss:-0.5121 G loss:-2.587\n",
      "Epoch:  0040 D loss:-0.5314 G loss:-2.515\n",
      "Epoch:  0040 D loss:-0.5988 G loss:-2.455\n",
      "Epoch:  0040 D loss:-0.5015 G loss:-2.425\n",
      "Epoch:  0040 D loss:-0.5711 G loss:-2.405\n",
      "Epoch:  0040 D loss:-0.6108 G loss:-2.603\n",
      "Epoch:  0040 D loss:-0.6391 G loss:-2.415\n",
      "Epoch:  0040 D loss:-0.7128 G loss:-2.545\n",
      "Epoch:  0040 D loss:-0.6227 G loss:-2.441\n",
      "Epoch:  0040 D loss:-0.6105 G loss:-2.244\n",
      "Epoch:  0040 D loss:-0.5738 G loss:-2.694\n",
      "Epoch:  0040 D loss:-0.4872 G loss:-2.475\n",
      "Epoch:  0040 D loss:-0.4922 G loss:-2.428\n",
      "Epoch:  0040 D loss:-0.61 G loss:-2.515\n",
      "Epoch:  0040 D loss:-0.602 G loss:-2.405\n",
      "Epoch:  0040 D loss:-0.5282 G loss:-2.346\n",
      "Epoch:  0040 D loss:-0.5662 G loss:-2.36\n",
      "Epoch:  0040 D loss:-0.6329 G loss:-2.298\n",
      "Epoch:  0040 D loss:-0.599 G loss:-2.282\n",
      "Epoch:  0040 D loss:-0.6429 G loss:-2.245\n",
      "Epoch:  0040 D loss:-0.5688 G loss:-2.356\n",
      "Epoch:  0040 D loss:-0.634 G loss:-2.633\n",
      "Epoch:  0040 D loss:-0.4619 G loss:-2.404\n",
      "Epoch:  0040 D loss:-0.7161 G loss:-2.278\n",
      "Epoch:  0040 D loss:-0.6744 G loss:-2.245\n",
      "Epoch:  0040 D loss:-0.5811 G loss:-2.236\n",
      "Epoch:  0040 D loss:-0.6656 G loss:-2.29\n",
      "Epoch:  0040 D loss:-0.5152 G loss:-2.442\n",
      "Epoch:  0040 D loss:-0.6702 G loss:-2.351\n",
      "Epoch:  0040 D loss:-0.5195 G loss:-2.408\n",
      "Epoch:  0040 D loss:-0.5514 G loss:-2.335\n",
      "Epoch:  0040 D loss:-0.6223 G loss:-2.362\n",
      "Epoch:  0040 D loss:-0.6664 G loss:-2.309\n",
      "Epoch:  0040 D loss:-0.5664 G loss:-2.48\n",
      "Epoch:  0040 D loss:-0.6738 G loss:-2.295\n",
      "Epoch:  0040 D loss:-0.5572 G loss:-2.093\n",
      "Epoch:  0040 D loss:-0.5636 G loss:-2.247\n",
      "Epoch:  0040 D loss:-0.5879 G loss:-2.168\n",
      "Epoch:  0040 D loss:-0.5541 G loss:-2.169\n",
      "Epoch:  0040 D loss:-0.7897 G loss:-2.036\n",
      "Epoch:  0040 D loss:-0.7763 G loss:-2.115\n",
      "Epoch:  0040 D loss:-0.5474 G loss:-2.624\n",
      "Epoch:  0040 D loss:-0.6009 G loss:-2.415\n",
      "Epoch:  0040 D loss:-0.5242 G loss:-2.652\n",
      "Epoch:  0040 D loss:-0.5799 G loss:-2.567\n",
      "Epoch:  0040 D loss:-0.7988 G loss:-2.523\n",
      "Epoch:  0040 D loss:-0.5457 G loss:-2.508\n",
      "Epoch:  0040 D loss:-0.5849 G loss:-2.552\n",
      "Epoch:  0040 D loss:-0.6859 G loss:-2.138\n",
      "Epoch:  0040 D loss:-0.5497 G loss:-2.14\n",
      "Epoch:  0040 D loss:-0.6309 G loss:-2.207\n",
      "Epoch:  0040 D loss:-0.5257 G loss:-2.141\n",
      "Epoch:  0040 D loss:-0.5247 G loss:-2.119\n",
      "Epoch:  0040 D loss:-0.6696 G loss:-1.965\n",
      "Epoch:  0040 D loss:-0.5856 G loss:-2.07\n",
      "Epoch:  0040 D loss:-0.6087 G loss:-2.101\n",
      "Epoch:  0040 D loss:-0.6558 G loss:-2.384\n",
      "Epoch:  0040 D loss:-0.7187 G loss:-2.366\n",
      "Epoch:  0040 D loss:-0.6459 G loss:-2.39\n",
      "Epoch:  0040 D loss:-0.5289 G loss:-2.329\n",
      "Epoch:  0040 D loss:-0.7363 G loss:-2.169\n",
      "Epoch:  0040 D loss:-0.6394 G loss:-2.324\n",
      "Epoch:  0040 D loss:-0.6303 G loss:-2.156\n",
      "Epoch:  0040 D loss:-0.5548 G loss:-2.558\n",
      "Epoch:  0040 D loss:-0.6166 G loss:-2.313\n",
      "Epoch:  0040 D loss:-0.7903 G loss:-2.3\n",
      "Epoch:  0040 D loss:-0.5969 G loss:-2.151\n",
      "Epoch:  0040 D loss:-0.4884 G loss:-2.326\n",
      "Epoch:  0040 D loss:-0.6049 G loss:-2.454\n",
      "Epoch:  0040 D loss:-0.542 G loss:-2.316\n",
      "Epoch:  0040 D loss:-0.6149 G loss:-2.329\n",
      "Epoch:  0040 D loss:-0.5626 G loss:-2.243\n",
      "Epoch:  0040 D loss:-0.6208 G loss:-2.19\n",
      "Epoch:  0040 D loss:-0.4978 G loss:-2.344\n",
      "Epoch:  0040 D loss:-0.6622 G loss:-2.235\n",
      "Epoch:  0040 D loss:-0.6842 G loss:-2.176\n",
      "Epoch:  0040 D loss:-0.6582 G loss:-2.275\n",
      "Epoch:  0040 D loss:-0.6338 G loss:-2.282\n",
      "Epoch:  0040 D loss:-0.5459 G loss:-2.542\n",
      "Epoch:  0040 D loss:-0.7994 G loss:-2.18\n",
      "Epoch:  0040 D loss:-0.5725 G loss:-2.647\n",
      "Epoch:  0040 D loss:-0.6471 G loss:-2.366\n",
      "Epoch:  0040 D loss:-0.5431 G loss:-2.401\n",
      "Epoch:  0040 D loss:-0.5423 G loss:-2.559\n",
      "Epoch:  0040 D loss:-0.6771 G loss:-2.897\n",
      "Epoch:  0040 D loss:-0.548 G loss:-2.548\n",
      "Epoch:  0040 D loss:-0.4994 G loss:-2.809\n",
      "Epoch:  0040 D loss:-0.5945 G loss:-2.582\n",
      "Epoch:  0040 D loss:-0.68 G loss:-2.393\n",
      "Epoch:  0040 D loss:-0.5887 G loss:-2.413\n",
      "Epoch:  0040 D loss:-0.7643 G loss:-2.252\n",
      "Epoch:  0040 D loss:-0.647 G loss:-2.162\n",
      "Epoch:  0040 D loss:-0.7051 G loss:-1.956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0040 D loss:-0.734 G loss:-1.975\n",
      "Epoch:  0040 D loss:-0.5367 G loss:-2.29\n",
      "Epoch:  0040 D loss:-0.6146 G loss:-2.08\n",
      "Epoch:  0040 D loss:-0.7338 G loss:-2.193\n",
      "Epoch:  0040 D loss:-0.4315 G loss:-2.581\n",
      "Epoch:  0040 D loss:-0.5553 G loss:-2.556\n",
      "Epoch:  0040 D loss:-0.6782 G loss:-2.511\n",
      "Epoch:  0040 D loss:-0.5724 G loss:-2.668\n",
      "Epoch:  0040 D loss:-0.6138 G loss:-2.799\n",
      "Epoch:  0040 D loss:-0.4905 G loss:-2.506\n",
      "Epoch:  0040 D loss:-0.4944 G loss:-2.475\n",
      "Epoch:  0040 D loss:-0.5058 G loss:-2.49\n",
      "Epoch:  0040 D loss:-0.567 G loss:-2.405\n",
      "Epoch:  0040 D loss:-0.6291 G loss:-2.202\n",
      "Epoch:  0040 D loss:-0.6649 G loss:-2.547\n",
      "Epoch:  0040 D loss:-0.5543 G loss:-2.149\n",
      "Epoch:  0040 D loss:-0.5738 G loss:-2.104\n",
      "Epoch:  0040 D loss:-0.5277 G loss:-2.238\n",
      "Epoch:  0040 D loss:-0.5061 G loss:-2.169\n",
      "Epoch:  0040 D loss:-0.5295 G loss:-2.367\n",
      "Epoch:  0040 D loss:-0.5716 G loss:-2.146\n",
      "Epoch:  0040 D loss:-0.5051 G loss:-2.211\n",
      "Epoch:  0040 D loss:-0.4558 G loss:-2.598\n",
      "Epoch:  0040 D loss:-0.5425 G loss:-2.505\n",
      "Epoch:  0040 D loss:-0.573 G loss:-2.693\n",
      "Epoch:  0040 D loss:-0.4235 G loss:-2.679\n",
      "Epoch:  0040 D loss:-0.5808 G loss:-2.599\n",
      "Epoch:  0040 D loss:-0.6605 G loss:-2.509\n",
      "Epoch:  0040 D loss:-0.6786 G loss:-2.555\n",
      "Epoch:  0040 D loss:-0.617 G loss:-2.567\n",
      "Epoch:  0040 D loss:-0.6348 G loss:-2.483\n",
      "Epoch:  0040 D loss:-0.5756 G loss:-2.436\n",
      "Epoch:  0040 D loss:-0.642 G loss:-2.162\n",
      "Epoch:  0040 D loss:-0.6194 G loss:-2.332\n",
      "Epoch:  0040 D loss:-0.6192 G loss:-2.262\n",
      "Epoch:  0040 D loss:-0.5541 G loss:-2.255\n",
      "Epoch:  0040 D loss:-0.6556 G loss:-1.998\n",
      "Epoch:  0040 D loss:-0.489 G loss:-2.409\n",
      "Epoch:  0040 D loss:-0.6129 G loss:-2.333\n",
      "Epoch:  0040 D loss:-0.5814 G loss:-2.236\n",
      "Epoch:  0040 D loss:-0.7235 G loss:-2.38\n",
      "Epoch:  0040 D loss:-0.438 G loss:-2.594\n",
      "Epoch:  0040 D loss:-0.646 G loss:-2.455\n",
      "Epoch:  0040 D loss:-0.6707 G loss:-2.442\n",
      "Epoch:  0040 D loss:-0.679 G loss:-2.597\n",
      "Epoch:  0040 D loss:-0.6974 G loss:-2.34\n",
      "Epoch:  0040 D loss:-0.5577 G loss:-2.25\n",
      "Epoch:  0040 D loss:-0.6061 G loss:-2.428\n",
      "Epoch:  0040 D loss:-0.6869 G loss:-2.374\n",
      "Epoch:  0040 D loss:-0.6312 G loss:-2.08\n",
      "Epoch:  0040 D loss:-0.6589 G loss:-2.214\n",
      "Epoch:  0040 D loss:-0.505 G loss:-2.307\n",
      "Epoch:  0040 D loss:-0.5842 G loss:-2.19\n",
      "Epoch:  0040 D loss:-0.6835 G loss:-2.122\n",
      "Epoch:  0040 D loss:-0.5799 G loss:-2.204\n",
      "Epoch:  0040 D loss:-0.7104 G loss:-2.099\n",
      "Epoch:  0040 D loss:-0.534 G loss:-2.347\n",
      "Epoch:  0040 D loss:-0.6562 G loss:-2.447\n",
      "Epoch:  0040 D loss:-0.6864 G loss:-2.3\n",
      "Epoch:  0040 D loss:-0.64 G loss:-2.581\n",
      "Epoch:  0040 D loss:-0.6117 G loss:-2.412\n",
      "Epoch:  0040 D loss:-0.6699 G loss:-2.461\n",
      "Epoch:  0040 D loss:-0.5875 G loss:-2.656\n",
      "Epoch:  0040 D loss:-0.787 G loss:-2.624\n",
      "Epoch:  0040 D loss:-0.5939 G loss:-2.298\n",
      "Epoch:  0040 D loss:-0.5372 G loss:-2.391\n",
      "Epoch:  0040 D loss:-0.5542 G loss:-2.199\n",
      "Epoch:  0040 D loss:-0.6064 G loss:-2.096\n",
      "Epoch:  0040 D loss:-0.6212 G loss:-2.235\n",
      "Epoch:  0040 D loss:-0.6598 G loss:-2.216\n",
      "Epoch:  0040 D loss:-0.5438 G loss:-2.375\n",
      "Epoch:  0040 D loss:-0.5286 G loss:-2.475\n",
      "Epoch:  0040 D loss:-0.5351 G loss:-2.267\n",
      "Epoch:  0040 D loss:-0.5985 G loss:-2.441\n",
      "Epoch:  0040 D loss:-0.6574 G loss:-2.533\n",
      "Epoch:  0040 D loss:-0.4713 G loss:-2.665\n",
      "Epoch:  0040 D loss:-0.6455 G loss:-2.642\n",
      "Epoch:  0040 D loss:-0.5603 G loss:-2.436\n",
      "Epoch:  0040 D loss:-0.6579 G loss:-2.496\n",
      "Epoch:  0040 D loss:-0.5974 G loss:-2.488\n",
      "Epoch:  0040 D loss:-0.6844 G loss:-2.5\n",
      "Epoch:  0040 D loss:-0.5323 G loss:-2.643\n",
      "Epoch:  0040 D loss:-0.5662 G loss:-2.426\n",
      "Epoch:  0040 D loss:-0.7491 G loss:-2.276\n",
      "Epoch:  0040 D loss:-0.5521 G loss:-2.153\n",
      "Epoch:  0040 D loss:-0.6316 G loss:-2.211\n",
      "Epoch:  0040 D loss:-0.5763 G loss:-2.219\n",
      "Epoch:  0040 D loss:-0.595 G loss:-2.105\n",
      "Epoch:  0040 D loss:-0.6491 G loss:-2.242\n",
      "Epoch:  0040 D loss:-0.507 G loss:-2.593\n",
      "Epoch:  0040 D loss:-0.8484 G loss:-2.22\n",
      "Epoch:  0040 D loss:-0.6554 G loss:-2.401\n",
      "Epoch:  0040 D loss:-0.6066 G loss:-2.693\n",
      "Epoch:  0040 D loss:-0.7568 G loss:-2.508\n",
      "Epoch:  0040 D loss:-0.5249 G loss:-2.645\n",
      "Epoch:  0040 D loss:-0.8032 G loss:-2.588\n",
      "Epoch:  0040 D loss:-0.4872 G loss:-2.572\n",
      "Epoch:  0040 D loss:-0.4162 G loss:-2.64\n",
      "Epoch:  0040 D loss:-0.559 G loss:-2.317\n",
      "Epoch:  0040 D loss:-0.6511 G loss:-2.269\n",
      "Epoch:  0040 D loss:-0.4055 G loss:-2.231\n",
      "Epoch:  0040 D loss:-0.4434 G loss:-2.635\n",
      "Epoch:  0040 D loss:-0.5611 G loss:-2.29\n",
      "Epoch:  0040 D loss:-0.6357 G loss:-2.256\n",
      "Epoch:  0040 D loss:-0.5981 G loss:-2.353\n",
      "Epoch:  0040 D loss:-0.525 G loss:-2.269\n",
      "Epoch:  0040 D loss:-0.5752 G loss:-2.24\n",
      "Epoch:  0040 D loss:-0.4931 G loss:-2.527\n",
      "Epoch:  0040 D loss:-0.5279 G loss:-2.781\n",
      "Epoch:  0040 D loss:-0.6043 G loss:-2.645\n",
      "Epoch:  0040 D loss:-0.6466 G loss:-2.449\n",
      "Epoch:  0040 D loss:-0.6439 G loss:-2.735\n",
      "Epoch:  0040 D loss:-0.5231 G loss:-2.691\n",
      "Epoch:  0040 D loss:-0.5963 G loss:-2.6\n",
      "Epoch:  0040 D loss:-0.532 G loss:-2.424\n",
      "Epoch:  0040 D loss:-0.544 G loss:-2.299\n",
      "Epoch:  0040 D loss:-0.7639 G loss:-2.186\n",
      "Epoch:  0040 D loss:-0.6093 G loss:-2.214\n",
      "Epoch:  0040 D loss:-0.6199 G loss:-2.044\n",
      "Epoch:  0040 D loss:-0.5037 G loss:-2.483\n",
      "Epoch:  0040 D loss:-0.4576 G loss:-2.623\n",
      "Epoch:  0040 D loss:-0.5301 G loss:-2.319\n",
      "Epoch:  0040 D loss:-0.442 G loss:-2.6\n",
      "Epoch:  0040 D loss:-0.5525 G loss:-2.51\n",
      "Epoch:  0040 D loss:-0.6824 G loss:-2.386\n",
      "Epoch:  0040 D loss:-0.5524 G loss:-2.471\n",
      "Epoch:  0040 D loss:-0.5256 G loss:-2.707\n",
      "Epoch:  0040 D loss:-0.5729 G loss:-2.553\n",
      "Epoch:  0040 D loss:-0.5908 G loss:-2.532\n",
      "Epoch:  0040 D loss:-0.55 G loss:-2.43\n",
      "Epoch:  0040 D loss:-0.5932 G loss:-2.484\n",
      "Epoch:  0040 D loss:-0.6225 G loss:-2.352\n",
      "Epoch:  0040 D loss:-0.5607 G loss:-2.694\n",
      "Epoch:  0040 D loss:-0.5219 G loss:-2.463\n",
      "Epoch:  0040 D loss:-0.5933 G loss:-2.249\n",
      "Epoch:  0040 D loss:-0.5227 G loss:-2.466\n",
      "Epoch:  0040 D loss:-0.7361 G loss:-2.262\n",
      "Epoch:  0040 D loss:-0.6449 G loss:-2.354\n",
      "Epoch:  0040 D loss:-0.4686 G loss:-2.477\n",
      "Epoch:  0040 D loss:-0.6311 G loss:-2.207\n",
      "Epoch:  0040 D loss:-0.6249 G loss:-2.226\n",
      "Epoch:  0040 D loss:-0.7025 G loss:-2.321\n",
      "Epoch:  0040 D loss:-0.5415 G loss:-2.343\n",
      "Epoch:  0040 D loss:-0.558 G loss:-2.599\n",
      "Epoch:  0040 D loss:-0.481 G loss:-2.662\n",
      "Epoch:  0040 D loss:-0.5629 G loss:-2.386\n",
      "Epoch:  0040 D loss:-0.5446 G loss:-2.594\n",
      "Epoch:  0040 D loss:-0.6464 G loss:-2.401\n",
      "Epoch:  0040 D loss:-0.5339 G loss:-2.4\n",
      "Epoch:  0040 D loss:-0.53 G loss:-2.57\n",
      "Epoch:  0040 D loss:-0.479 G loss:-2.452\n",
      "Epoch:  0040 D loss:-0.6543 G loss:-2.268\n",
      "Epoch:  0040 D loss:-0.6529 G loss:-2.219\n",
      "Epoch:  0040 D loss:-0.587 G loss:-2.36\n",
      "Epoch:  0040 D loss:-0.4961 G loss:-2.369\n",
      "Epoch:  0040 D loss:-0.7167 G loss:-2.163\n",
      "Epoch:  0040 D loss:-0.4849 G loss:-2.28\n",
      "Epoch:  0040 D loss:-0.5857 G loss:-2.363\n",
      "Epoch:  0040 D loss:-0.4673 G loss:-2.575\n",
      "Epoch:  0040 D loss:-0.5731 G loss:-2.315\n",
      "Epoch:  0040 D loss:-0.8449 G loss:-2.456\n",
      "Epoch:  0040 D loss:-0.5366 G loss:-2.462\n",
      "Epoch:  0040 D loss:-0.4541 G loss:-2.432\n",
      "Epoch:  0040 D loss:-0.5605 G loss:-2.541\n",
      "Epoch:  0040 D loss:-0.5128 G loss:-2.449\n",
      "Epoch:  0040 D loss:-0.456 G loss:-2.432\n",
      "Epoch:  0040 D loss:-0.5098 G loss:-2.401\n",
      "Epoch:  0040 D loss:-0.5457 G loss:-2.436\n",
      "Epoch:  0040 D loss:-0.7152 G loss:-2.323\n",
      "Epoch:  0040 D loss:-0.5083 G loss:-2.104\n",
      "Epoch:  0040 D loss:-0.5425 G loss:-2.441\n",
      "Epoch:  0040 D loss:-0.6033 G loss:-2.374\n",
      "Epoch:  0040 D loss:-0.5297 G loss:-2.583\n",
      "Epoch:  0040 D loss:-0.7926 G loss:-2.693\n",
      "Epoch:  0040 D loss:-0.5094 G loss:-2.474\n",
      "Epoch:  0040 D loss:-0.5472 G loss:-2.501\n",
      "Epoch:  0040 D loss:-0.5004 G loss:-2.212\n",
      "Epoch:  0040 D loss:-0.6077 G loss:-2.047\n",
      "Epoch:  0040 D loss:-0.5385 G loss:-1.998\n",
      "Epoch:  0040 D loss:-0.6461 G loss:-2.021\n",
      "Epoch:  0040 D loss:-0.6806 G loss:-2.113\n",
      "Epoch:  0040 D loss:-0.5875 G loss:-2.297\n",
      "Epoch:  0040 D loss:-0.6473 G loss:-2.199\n",
      "Epoch:  0040 D loss:-0.5261 G loss:-2.293\n",
      "Epoch:  0040 D loss:-0.5912 G loss:-2.441\n",
      "Epoch:  0040 D loss:-0.5673 G loss:-2.217\n",
      "Epoch:  0040 D loss:-0.5296 G loss:-2.292\n",
      "Epoch:  0040 D loss:-0.4707 G loss:-2.56\n",
      "Epoch:  0040 D loss:-0.526 G loss:-2.371\n",
      "Epoch:  0040 D loss:-0.4738 G loss:-2.392\n",
      "Epoch:  0040 D loss:-0.5647 G loss:-2.227\n",
      "Epoch:  0040 D loss:-0.5254 G loss:-2.198\n",
      "Epoch:  0040 D loss:-0.6561 G loss:-2.229\n",
      "Epoch:  0040 D loss:-0.5274 G loss:-2.248\n",
      "Epoch:  0040 D loss:-0.5899 G loss:-2.351\n",
      "Epoch:  0040 D loss:-0.5123 G loss:-2.399\n",
      "Epoch:  0040 D loss:-0.732 G loss:-2.065\n",
      "Epoch:  0040 D loss:-0.6331 G loss:-2.151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0040 D loss:-0.6008 G loss:-2.126\n",
      "Epoch:  0040 D loss:-0.4555 G loss:-2.338\n",
      "Epoch:  0040 D loss:-0.6275 G loss:-2.182\n",
      "Epoch:  0040 D loss:-0.6356 G loss:-2.18\n",
      "Epoch:  0040 D loss:-0.5777 G loss:-2.328\n",
      "Epoch:  0040 D loss:-0.5072 G loss:-2.422\n",
      "Epoch:  0040 D loss:-0.6606 G loss:-2.281\n",
      "Epoch:  0040 D loss:-0.521 G loss:-2.2\n",
      "Epoch:  0040 D loss:-0.4245 G loss:-2.348\n",
      "Epoch:  0040 D loss:-0.6397 G loss:-2.449\n",
      "Epoch:  0040 D loss:-0.5456 G loss:-2.321\n",
      "Epoch:  0040 D loss:-0.4959 G loss:-2.469\n",
      "Epoch:  0040 D loss:-0.519 G loss:-2.634\n",
      "Epoch:  0040 D loss:-0.4883 G loss:-2.488\n",
      "Epoch:  0040 D loss:-0.4766 G loss:-2.407\n",
      "Epoch:  0040 D loss:-0.5289 G loss:-2.723\n",
      "Epoch:  0040 D loss:-0.5137 G loss:-2.447\n",
      "Epoch:  0040 D loss:-0.5782 G loss:-2.374\n",
      "Epoch:  0040 D loss:-0.5623 G loss:-2.34\n",
      "Epoch:  0040 D loss:-0.5652 G loss:-2.159\n",
      "Epoch:  0040 D loss:-0.4589 G loss:-2.267\n",
      "Epoch:  0040 D loss:-0.5 G loss:-2.229\n",
      "Epoch:  0040 D loss:-0.5247 G loss:-2.269\n",
      "Epoch:  0040 D loss:-0.4819 G loss:-2.271\n",
      "Epoch:  0040 D loss:-0.4387 G loss:-2.451\n",
      "Epoch:  0040 D loss:-0.5658 G loss:-2.473\n",
      "Epoch:  0040 D loss:-0.495 G loss:-2.539\n",
      "Epoch:  0040 D loss:-0.5457 G loss:-2.817\n",
      "Epoch:  0040 D loss:-0.634 G loss:-2.703\n",
      "Epoch:  0040 D loss:-0.6355 G loss:-2.475\n",
      "Epoch:  0040 D loss:-0.518 G loss:-2.463\n",
      "Epoch:  0040 D loss:-0.499 G loss:-2.453\n",
      "Epoch:  0040 D loss:-0.6027 G loss:-2.39\n",
      "Epoch:  0040 D loss:-0.506 G loss:-2.076\n",
      "Epoch:  0040 D loss:-0.5255 G loss:-2.258\n",
      "Epoch:  0040 D loss:-0.5066 G loss:-2.219\n",
      "Epoch:  0040 D loss:-0.5516 G loss:-2.034\n",
      "Epoch:  0040 D loss:-0.5671 G loss:-2.195\n",
      "Epoch:  0040 D loss:-0.5922 G loss:-2.288\n",
      "Epoch:  0040 D loss:-0.5254 G loss:-2.43\n",
      "Epoch:  0040 D loss:-0.4629 G loss:-2.491\n",
      "Epoch:  0040 D loss:-0.586 G loss:-2.834\n",
      "Epoch:  0040 D loss:-0.4722 G loss:-2.501\n",
      "Epoch:  0040 D loss:-0.5892 G loss:-2.557\n",
      "Epoch:  0040 D loss:-0.5137 G loss:-2.478\n",
      "Epoch:  0040 D loss:-0.6462 G loss:-2.389\n",
      "Epoch:  0040 D loss:-0.5229 G loss:-2.477\n",
      "Epoch:  0040 D loss:-0.4768 G loss:-2.406\n",
      "Epoch:  0040 D loss:-0.5813 G loss:-2.292\n",
      "Epoch:  0040 D loss:-0.4872 G loss:-2.239\n",
      "Epoch:  0040 D loss:-0.6612 G loss:-1.982\n",
      "Epoch:  0040 D loss:-0.5398 G loss:-2.422\n",
      "Epoch:  0040 D loss:-0.5065 G loss:-2.326\n",
      "Epoch:  0040 D loss:-0.5646 G loss:-2.213\n",
      "Epoch:  0040 D loss:-0.5803 G loss:-2.214\n",
      "Epoch:  0040 D loss:-0.5071 G loss:-2.214\n",
      "Epoch:  0040 D loss:-0.5516 G loss:-2.2\n",
      "Epoch:  0040 D loss:-0.503 G loss:-2.335\n",
      "Epoch:  0040 D loss:-0.4865 G loss:-2.45\n",
      "Epoch:  0040 D loss:-0.4145 G loss:-2.268\n",
      "Epoch:  0040 D loss:-0.5266 G loss:-2.345\n",
      "Epoch:  0040 D loss:-0.6107 G loss:-2.22\n",
      "Epoch:  0040 D loss:-0.5468 G loss:-2.499\n",
      "Epoch:  0040 D loss:-0.4657 G loss:-2.66\n",
      "Epoch:  0040 D loss:-0.4969 G loss:-2.457\n",
      "Epoch:  0040 D loss:-0.5443 G loss:-2.452\n",
      "Epoch:  0040 D loss:-0.6883 G loss:-2.417\n",
      "Epoch:  0040 D loss:-0.6222 G loss:-2.5\n",
      "Epoch:  0040 D loss:-0.4832 G loss:-2.469\n",
      "Epoch:  0041 D loss:-0.5656 G loss:-2.287\n",
      "Epoch:  0041 D loss:-0.5311 G loss:-2.348\n",
      "Epoch:  0041 D loss:-0.5285 G loss:-2.452\n",
      "Epoch:  0041 D loss:-0.6952 G loss:-2.181\n",
      "Epoch:  0041 D loss:-0.6731 G loss:-2.152\n",
      "Epoch:  0041 D loss:-0.5327 G loss:-2.548\n",
      "Epoch:  0041 D loss:-0.6879 G loss:-2.311\n",
      "Epoch:  0041 D loss:-0.6495 G loss:-2.154\n",
      "Epoch:  0041 D loss:-0.5449 G loss:-2.227\n",
      "Epoch:  0041 D loss:-0.4718 G loss:-2.343\n",
      "Epoch:  0041 D loss:-0.5067 G loss:-2.192\n",
      "Epoch:  0041 D loss:-0.7081 G loss:-2.321\n",
      "Epoch:  0041 D loss:-0.5683 G loss:-2.296\n",
      "Epoch:  0041 D loss:-0.6723 G loss:-2.046\n",
      "Epoch:  0041 D loss:-0.5641 G loss:-2.169\n",
      "Epoch:  0041 D loss:-0.5542 G loss:-2.326\n",
      "Epoch:  0041 D loss:-0.6401 G loss:-2.254\n",
      "Epoch:  0041 D loss:-0.5808 G loss:-2.402\n",
      "Epoch:  0041 D loss:-0.7382 G loss:-2.131\n",
      "Epoch:  0041 D loss:-0.5545 G loss:-2.273\n",
      "Epoch:  0041 D loss:-0.6632 G loss:-2.156\n",
      "Epoch:  0041 D loss:-0.6005 G loss:-2.109\n",
      "Epoch:  0041 D loss:-0.6569 G loss:-2.215\n",
      "Epoch:  0041 D loss:-0.6628 G loss:-2.149\n",
      "Epoch:  0041 D loss:-0.5857 G loss:-2.195\n",
      "Epoch:  0041 D loss:-0.6266 G loss:-2.374\n",
      "Epoch:  0041 D loss:-0.6824 G loss:-2.34\n",
      "Epoch:  0041 D loss:-0.642 G loss:-2.231\n",
      "Epoch:  0041 D loss:-0.6667 G loss:-2.243\n",
      "Epoch:  0041 D loss:-0.5353 G loss:-2.201\n",
      "Epoch:  0041 D loss:-0.6617 G loss:-2.284\n",
      "Epoch:  0041 D loss:-0.6203 G loss:-2.402\n",
      "Epoch:  0041 D loss:-0.5698 G loss:-2.384\n",
      "Epoch:  0041 D loss:-0.5831 G loss:-2.45\n",
      "Epoch:  0041 D loss:-0.6705 G loss:-2.366\n",
      "Epoch:  0041 D loss:-0.7585 G loss:-2.198\n",
      "Epoch:  0041 D loss:-0.6373 G loss:-2.43\n",
      "Epoch:  0041 D loss:-0.6272 G loss:-2.044\n",
      "Epoch:  0041 D loss:-0.6267 G loss:-2.208\n",
      "Epoch:  0041 D loss:-0.6435 G loss:-1.987\n",
      "Epoch:  0041 D loss:-0.6724 G loss:-2.122\n",
      "Epoch:  0041 D loss:-0.5776 G loss:-2.217\n",
      "Epoch:  0041 D loss:-0.6696 G loss:-2.202\n",
      "Epoch:  0041 D loss:-0.5953 G loss:-2.242\n",
      "Epoch:  0041 D loss:-0.6391 G loss:-2.103\n",
      "Epoch:  0041 D loss:-0.6342 G loss:-2.181\n",
      "Epoch:  0041 D loss:-0.5173 G loss:-2.254\n",
      "Epoch:  0041 D loss:-0.6809 G loss:-2.221\n",
      "Epoch:  0041 D loss:-0.6546 G loss:-2.186\n",
      "Epoch:  0041 D loss:-0.6566 G loss:-2.276\n",
      "Epoch:  0041 D loss:-0.607 G loss:-2.326\n",
      "Epoch:  0041 D loss:-0.7136 G loss:-2.277\n",
      "Epoch:  0041 D loss:-0.5116 G loss:-2.437\n",
      "Epoch:  0041 D loss:-0.6321 G loss:-2.36\n",
      "Epoch:  0041 D loss:-0.5792 G loss:-2.367\n",
      "Epoch:  0041 D loss:-0.6513 G loss:-2.212\n",
      "Epoch:  0041 D loss:-0.6353 G loss:-2.468\n",
      "Epoch:  0041 D loss:-0.4964 G loss:-2.3\n",
      "Epoch:  0041 D loss:-0.5584 G loss:-2.326\n",
      "Epoch:  0041 D loss:-0.5662 G loss:-2.176\n",
      "Epoch:  0041 D loss:-0.5355 G loss:-2.199\n",
      "Epoch:  0041 D loss:-0.6842 G loss:-2.245\n",
      "Epoch:  0041 D loss:-0.6827 G loss:-2.165\n",
      "Epoch:  0041 D loss:-0.6107 G loss:-2.401\n",
      "Epoch:  0041 D loss:-0.5651 G loss:-2.392\n",
      "Epoch:  0041 D loss:-0.5581 G loss:-2.289\n",
      "Epoch:  0041 D loss:-0.4886 G loss:-2.146\n",
      "Epoch:  0041 D loss:-0.6315 G loss:-2.166\n",
      "Epoch:  0041 D loss:-0.5721 G loss:-2.397\n",
      "Epoch:  0041 D loss:-0.469 G loss:-2.519\n",
      "Epoch:  0041 D loss:-0.5003 G loss:-2.186\n",
      "Epoch:  0041 D loss:-0.5263 G loss:-2.658\n",
      "Epoch:  0041 D loss:-0.712 G loss:-2.129\n",
      "Epoch:  0041 D loss:-0.615 G loss:-2.26\n",
      "Epoch:  0041 D loss:-0.5319 G loss:-2.242\n",
      "Epoch:  0041 D loss:-0.5091 G loss:-2.358\n",
      "Epoch:  0041 D loss:-0.6079 G loss:-2.325\n",
      "Epoch:  0041 D loss:-0.5934 G loss:-2.258\n",
      "Epoch:  0041 D loss:-0.6018 G loss:-2.206\n",
      "Epoch:  0041 D loss:-0.6733 G loss:-2.323\n",
      "Epoch:  0041 D loss:-0.466 G loss:-2.204\n",
      "Epoch:  0041 D loss:-0.5552 G loss:-2.49\n",
      "Epoch:  0041 D loss:-0.5711 G loss:-2.252\n",
      "Epoch:  0041 D loss:-0.6125 G loss:-2.373\n",
      "Epoch:  0041 D loss:-0.5754 G loss:-2.417\n",
      "Epoch:  0041 D loss:-0.4887 G loss:-2.415\n",
      "Epoch:  0041 D loss:-0.5474 G loss:-2.432\n",
      "Epoch:  0041 D loss:-0.6046 G loss:-2.394\n",
      "Epoch:  0041 D loss:-0.3879 G loss:-2.54\n",
      "Epoch:  0041 D loss:-0.4812 G loss:-2.535\n",
      "Epoch:  0041 D loss:-0.514 G loss:-2.697\n",
      "Epoch:  0041 D loss:-0.5353 G loss:-2.304\n",
      "Epoch:  0041 D loss:-0.6067 G loss:-2.433\n",
      "Epoch:  0041 D loss:-0.5261 G loss:-2.221\n",
      "Epoch:  0041 D loss:-0.7221 G loss:-2.311\n",
      "Epoch:  0041 D loss:-0.6888 G loss:-2.295\n",
      "Epoch:  0041 D loss:-0.6106 G loss:-2.264\n",
      "Epoch:  0041 D loss:-0.5427 G loss:-2.429\n",
      "Epoch:  0041 D loss:-0.658 G loss:-2.311\n",
      "Epoch:  0041 D loss:-0.6296 G loss:-2.102\n",
      "Epoch:  0041 D loss:-0.4912 G loss:-2.192\n",
      "Epoch:  0041 D loss:-0.6083 G loss:-2.402\n",
      "Epoch:  0041 D loss:-0.4247 G loss:-2.592\n",
      "Epoch:  0041 D loss:-0.4625 G loss:-2.544\n",
      "Epoch:  0041 D loss:-0.5731 G loss:-2.635\n",
      "Epoch:  0041 D loss:-0.6064 G loss:-2.207\n",
      "Epoch:  0041 D loss:-0.6827 G loss:-2.376\n",
      "Epoch:  0041 D loss:-0.5853 G loss:-2.375\n",
      "Epoch:  0041 D loss:-0.5512 G loss:-2.437\n",
      "Epoch:  0041 D loss:-0.5831 G loss:-2.308\n",
      "Epoch:  0041 D loss:-0.5447 G loss:-2.328\n",
      "Epoch:  0041 D loss:-0.6544 G loss:-2.317\n",
      "Epoch:  0041 D loss:-0.5556 G loss:-2.244\n",
      "Epoch:  0041 D loss:-0.619 G loss:-2.311\n",
      "Epoch:  0041 D loss:-0.4003 G loss:-2.222\n",
      "Epoch:  0041 D loss:-0.5711 G loss:-2.232\n",
      "Epoch:  0041 D loss:-0.5845 G loss:-2.236\n",
      "Epoch:  0041 D loss:-0.6382 G loss:-2.258\n",
      "Epoch:  0041 D loss:-0.5303 G loss:-2.319\n",
      "Epoch:  0041 D loss:-0.4868 G loss:-2.503\n",
      "Epoch:  0041 D loss:-0.5456 G loss:-2.071\n",
      "Epoch:  0041 D loss:-0.6715 G loss:-2.201\n",
      "Epoch:  0041 D loss:-0.6101 G loss:-2.434\n",
      "Epoch:  0041 D loss:-0.5996 G loss:-2.491\n",
      "Epoch:  0041 D loss:-0.617 G loss:-2.191\n",
      "Epoch:  0041 D loss:-0.5554 G loss:-2.488\n",
      "Epoch:  0041 D loss:-0.5211 G loss:-2.497\n",
      "Epoch:  0041 D loss:-0.5671 G loss:-2.284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0041 D loss:-0.522 G loss:-2.493\n",
      "Epoch:  0041 D loss:-0.6227 G loss:-2.181\n",
      "Epoch:  0041 D loss:-0.5312 G loss:-2.1\n",
      "Epoch:  0041 D loss:-0.5704 G loss:-2.099\n",
      "Epoch:  0041 D loss:-0.5498 G loss:-2.326\n",
      "Epoch:  0041 D loss:-0.4799 G loss:-2.333\n",
      "Epoch:  0041 D loss:-0.6163 G loss:-2.26\n",
      "Epoch:  0041 D loss:-0.5842 G loss:-2.334\n",
      "Epoch:  0041 D loss:-0.53 G loss:-2.085\n",
      "Epoch:  0041 D loss:-0.5786 G loss:-2.307\n",
      "Epoch:  0041 D loss:-0.762 G loss:-2.48\n",
      "Epoch:  0041 D loss:-0.5086 G loss:-2.292\n",
      "Epoch:  0041 D loss:-0.5778 G loss:-2.065\n",
      "Epoch:  0041 D loss:-0.6022 G loss:-2.297\n",
      "Epoch:  0041 D loss:-0.4925 G loss:-2.399\n",
      "Epoch:  0041 D loss:-0.6341 G loss:-2.395\n",
      "Epoch:  0041 D loss:-0.4832 G loss:-2.359\n",
      "Epoch:  0041 D loss:-0.4534 G loss:-2.307\n",
      "Epoch:  0041 D loss:-0.7001 G loss:-2.385\n",
      "Epoch:  0041 D loss:-0.5897 G loss:-2.372\n",
      "Epoch:  0041 D loss:-0.6548 G loss:-2.495\n",
      "Epoch:  0041 D loss:-0.5161 G loss:-2.38\n",
      "Epoch:  0041 D loss:-0.6893 G loss:-2.507\n",
      "Epoch:  0041 D loss:-0.5801 G loss:-2.431\n",
      "Epoch:  0041 D loss:-0.6062 G loss:-2.188\n",
      "Epoch:  0041 D loss:-0.5441 G loss:-2.055\n",
      "Epoch:  0041 D loss:-0.4864 G loss:-2.164\n",
      "Epoch:  0041 D loss:-0.5241 G loss:-2.286\n",
      "Epoch:  0041 D loss:-0.479 G loss:-2.414\n",
      "Epoch:  0041 D loss:-0.5173 G loss:-2.423\n",
      "Epoch:  0041 D loss:-0.6389 G loss:-2.237\n",
      "Epoch:  0041 D loss:-0.5575 G loss:-2.381\n",
      "Epoch:  0041 D loss:-0.6382 G loss:-2.414\n",
      "Epoch:  0041 D loss:-0.5345 G loss:-2.438\n",
      "Epoch:  0041 D loss:-0.6242 G loss:-2.281\n",
      "Epoch:  0041 D loss:-0.6003 G loss:-2.336\n",
      "Epoch:  0041 D loss:-0.5844 G loss:-2.49\n",
      "Epoch:  0041 D loss:-0.5743 G loss:-2.468\n",
      "Epoch:  0041 D loss:-0.4956 G loss:-2.472\n",
      "Epoch:  0041 D loss:-0.5534 G loss:-2.248\n",
      "Epoch:  0041 D loss:-0.4801 G loss:-2.571\n",
      "Epoch:  0041 D loss:-0.4859 G loss:-2.665\n",
      "Epoch:  0041 D loss:-0.6323 G loss:-2.27\n",
      "Epoch:  0041 D loss:-0.5279 G loss:-2.396\n",
      "Epoch:  0041 D loss:-0.5548 G loss:-2.333\n",
      "Epoch:  0041 D loss:-0.5151 G loss:-2.241\n",
      "Epoch:  0041 D loss:-0.5944 G loss:-2.434\n",
      "Epoch:  0041 D loss:-0.5887 G loss:-2.421\n",
      "Epoch:  0041 D loss:-0.5575 G loss:-2.263\n",
      "Epoch:  0041 D loss:-0.4082 G loss:-2.637\n",
      "Epoch:  0041 D loss:-0.657 G loss:-2.442\n",
      "Epoch:  0041 D loss:-0.574 G loss:-2.258\n",
      "Epoch:  0041 D loss:-0.4676 G loss:-2.357\n",
      "Epoch:  0041 D loss:-0.495 G loss:-2.258\n",
      "Epoch:  0041 D loss:-0.5006 G loss:-2.407\n",
      "Epoch:  0041 D loss:-0.6323 G loss:-2.376\n",
      "Epoch:  0041 D loss:-0.5183 G loss:-2.297\n",
      "Epoch:  0041 D loss:-0.6172 G loss:-2.452\n",
      "Epoch:  0041 D loss:-0.6888 G loss:-2.404\n",
      "Epoch:  0041 D loss:-0.547 G loss:-2.347\n",
      "Epoch:  0041 D loss:-0.5719 G loss:-2.588\n",
      "Epoch:  0041 D loss:-0.5482 G loss:-2.518\n",
      "Epoch:  0041 D loss:-0.4876 G loss:-2.446\n",
      "Epoch:  0041 D loss:-0.4805 G loss:-2.369\n",
      "Epoch:  0041 D loss:-0.497 G loss:-2.475\n",
      "Epoch:  0041 D loss:-0.4907 G loss:-2.648\n",
      "Epoch:  0041 D loss:-0.5414 G loss:-2.454\n",
      "Epoch:  0041 D loss:-0.6956 G loss:-2.665\n",
      "Epoch:  0041 D loss:-0.5218 G loss:-2.442\n",
      "Epoch:  0041 D loss:-0.6294 G loss:-2.434\n",
      "Epoch:  0041 D loss:-0.4531 G loss:-2.181\n",
      "Epoch:  0041 D loss:-0.6185 G loss:-2.391\n",
      "Epoch:  0041 D loss:-0.5927 G loss:-2.537\n",
      "Epoch:  0041 D loss:-0.4037 G loss:-2.495\n",
      "Epoch:  0041 D loss:-0.6813 G loss:-2.457\n",
      "Epoch:  0041 D loss:-0.4471 G loss:-2.555\n",
      "Epoch:  0041 D loss:-0.4872 G loss:-2.372\n",
      "Epoch:  0041 D loss:-0.5631 G loss:-2.502\n",
      "Epoch:  0041 D loss:-0.5467 G loss:-2.152\n",
      "Epoch:  0041 D loss:-0.4748 G loss:-2.577\n",
      "Epoch:  0041 D loss:-0.462 G loss:-2.484\n",
      "Epoch:  0041 D loss:-0.5215 G loss:-2.51\n",
      "Epoch:  0041 D loss:-0.4542 G loss:-2.42\n",
      "Epoch:  0041 D loss:-0.5972 G loss:-2.404\n",
      "Epoch:  0041 D loss:-0.4805 G loss:-2.548\n",
      "Epoch:  0041 D loss:-0.526 G loss:-2.741\n",
      "Epoch:  0041 D loss:-0.5148 G loss:-2.339\n",
      "Epoch:  0041 D loss:-0.5449 G loss:-2.326\n",
      "Epoch:  0041 D loss:-0.5965 G loss:-2.267\n",
      "Epoch:  0041 D loss:-0.5266 G loss:-2.474\n",
      "Epoch:  0041 D loss:-0.5665 G loss:-2.322\n",
      "Epoch:  0041 D loss:-0.4591 G loss:-2.424\n",
      "Epoch:  0041 D loss:-0.6233 G loss:-2.134\n",
      "Epoch:  0041 D loss:-0.4334 G loss:-2.36\n",
      "Epoch:  0041 D loss:-0.5442 G loss:-2.278\n",
      "Epoch:  0041 D loss:-0.4257 G loss:-2.372\n",
      "Epoch:  0041 D loss:-0.4662 G loss:-2.527\n",
      "Epoch:  0041 D loss:-0.5076 G loss:-2.597\n",
      "Epoch:  0041 D loss:-0.5687 G loss:-2.51\n",
      "Epoch:  0041 D loss:-0.4381 G loss:-2.565\n",
      "Epoch:  0041 D loss:-0.5197 G loss:-2.747\n",
      "Epoch:  0041 D loss:-0.4913 G loss:-2.654\n",
      "Epoch:  0041 D loss:-0.4281 G loss:-2.671\n",
      "Epoch:  0041 D loss:-0.5036 G loss:-2.464\n",
      "Epoch:  0041 D loss:-0.5377 G loss:-2.452\n",
      "Epoch:  0041 D loss:-0.472 G loss:-2.452\n",
      "Epoch:  0041 D loss:-0.6486 G loss:-2.246\n",
      "Epoch:  0041 D loss:-0.4599 G loss:-2.185\n",
      "Epoch:  0041 D loss:-0.3843 G loss:-2.363\n",
      "Epoch:  0041 D loss:-0.5506 G loss:-2.227\n",
      "Epoch:  0041 D loss:-0.458 G loss:-2.291\n",
      "Epoch:  0041 D loss:-0.7206 G loss:-2.34\n",
      "Epoch:  0041 D loss:-0.5234 G loss:-2.338\n",
      "Epoch:  0041 D loss:-0.5754 G loss:-2.531\n",
      "Epoch:  0041 D loss:-0.4949 G loss:-2.378\n",
      "Epoch:  0041 D loss:-0.7438 G loss:-2.153\n",
      "Epoch:  0041 D loss:-0.5797 G loss:-2.272\n",
      "Epoch:  0041 D loss:-0.5614 G loss:-2.334\n",
      "Epoch:  0041 D loss:-0.4807 G loss:-2.546\n",
      "Epoch:  0041 D loss:-0.5175 G loss:-2.411\n",
      "Epoch:  0041 D loss:-0.7491 G loss:-2.283\n",
      "Epoch:  0041 D loss:-0.6931 G loss:-2.15\n",
      "Epoch:  0041 D loss:-0.6122 G loss:-2.449\n",
      "Epoch:  0041 D loss:-0.568 G loss:-2.31\n",
      "Epoch:  0041 D loss:-0.5385 G loss:-2.512\n",
      "Epoch:  0041 D loss:-0.4549 G loss:-2.396\n",
      "Epoch:  0041 D loss:-0.5844 G loss:-2.319\n",
      "Epoch:  0041 D loss:-0.5195 G loss:-2.229\n",
      "Epoch:  0041 D loss:-0.5417 G loss:-2.027\n",
      "Epoch:  0041 D loss:-0.5919 G loss:-2.065\n",
      "Epoch:  0041 D loss:-0.6151 G loss:-2.284\n",
      "Epoch:  0041 D loss:-0.4306 G loss:-2.603\n",
      "Epoch:  0041 D loss:-0.5515 G loss:-2.187\n",
      "Epoch:  0041 D loss:-0.6673 G loss:-2.305\n",
      "Epoch:  0041 D loss:-0.5498 G loss:-2.26\n",
      "Epoch:  0041 D loss:-0.5486 G loss:-2.555\n",
      "Epoch:  0041 D loss:-0.562 G loss:-2.431\n",
      "Epoch:  0041 D loss:-0.6398 G loss:-2.37\n",
      "Epoch:  0041 D loss:-0.5589 G loss:-2.376\n",
      "Epoch:  0041 D loss:-0.4685 G loss:-2.321\n",
      "Epoch:  0041 D loss:-0.5718 G loss:-2.361\n",
      "Epoch:  0041 D loss:-0.6393 G loss:-2.258\n",
      "Epoch:  0041 D loss:-0.6182 G loss:-2.242\n",
      "Epoch:  0041 D loss:-0.6384 G loss:-2.122\n",
      "Epoch:  0041 D loss:-0.6475 G loss:-2.283\n",
      "Epoch:  0041 D loss:-0.496 G loss:-2.476\n",
      "Epoch:  0041 D loss:-0.5365 G loss:-2.688\n",
      "Epoch:  0041 D loss:-0.5484 G loss:-2.408\n",
      "Epoch:  0041 D loss:-0.5963 G loss:-2.32\n",
      "Epoch:  0041 D loss:-0.6392 G loss:-2.308\n",
      "Epoch:  0041 D loss:-0.6421 G loss:-2.248\n",
      "Epoch:  0041 D loss:-0.5684 G loss:-2.384\n",
      "Epoch:  0041 D loss:-0.691 G loss:-2.252\n",
      "Epoch:  0041 D loss:-0.5324 G loss:-2.237\n",
      "Epoch:  0041 D loss:-0.6038 G loss:-2.388\n",
      "Epoch:  0041 D loss:-0.7604 G loss:-2.005\n",
      "Epoch:  0041 D loss:-0.582 G loss:-2.158\n",
      "Epoch:  0041 D loss:-0.5533 G loss:-2.347\n",
      "Epoch:  0041 D loss:-0.6491 G loss:-2.178\n",
      "Epoch:  0041 D loss:-0.5249 G loss:-2.282\n",
      "Epoch:  0041 D loss:-0.5311 G loss:-2.184\n",
      "Epoch:  0041 D loss:-0.6985 G loss:-2.094\n",
      "Epoch:  0041 D loss:-0.5991 G loss:-2.239\n",
      "Epoch:  0041 D loss:-0.6588 G loss:-2.314\n",
      "Epoch:  0041 D loss:-0.688 G loss:-2.217\n",
      "Epoch:  0041 D loss:-0.444 G loss:-2.45\n",
      "Epoch:  0041 D loss:-0.6664 G loss:-2.66\n",
      "Epoch:  0041 D loss:-0.6767 G loss:-2.623\n",
      "Epoch:  0041 D loss:-0.5551 G loss:-2.446\n",
      "Epoch:  0041 D loss:-0.6254 G loss:-2.421\n",
      "Epoch:  0041 D loss:-0.6175 G loss:-2.13\n",
      "Epoch:  0041 D loss:-0.4899 G loss:-2.422\n",
      "Epoch:  0041 D loss:-0.7971 G loss:-1.904\n",
      "Epoch:  0041 D loss:-0.588 G loss:-1.944\n",
      "Epoch:  0041 D loss:-0.6634 G loss:-2.049\n",
      "Epoch:  0041 D loss:-0.615 G loss:-1.899\n",
      "Epoch:  0041 D loss:-0.595 G loss:-2.082\n",
      "Epoch:  0041 D loss:-0.6307 G loss:-2.051\n",
      "Epoch:  0041 D loss:-0.5853 G loss:-2.318\n",
      "Epoch:  0041 D loss:-0.557 G loss:-2.312\n",
      "Epoch:  0041 D loss:-0.6899 G loss:-2.349\n",
      "Epoch:  0041 D loss:-0.6029 G loss:-2.334\n",
      "Epoch:  0041 D loss:-0.5563 G loss:-2.562\n",
      "Epoch:  0041 D loss:-0.6094 G loss:-2.352\n",
      "Epoch:  0041 D loss:-0.5436 G loss:-2.626\n",
      "Epoch:  0041 D loss:-0.5835 G loss:-2.619\n",
      "Epoch:  0041 D loss:-0.6507 G loss:-2.55\n",
      "Epoch:  0041 D loss:-0.603 G loss:-2.446\n",
      "Epoch:  0041 D loss:-0.5995 G loss:-2.318\n",
      "Epoch:  0041 D loss:-0.5151 G loss:-2.32\n",
      "Epoch:  0041 D loss:-0.7317 G loss:-2.082\n",
      "Epoch:  0041 D loss:-0.6215 G loss:-2.018\n",
      "Epoch:  0041 D loss:-0.5997 G loss:-2.058\n",
      "Epoch:  0041 D loss:-0.6565 G loss:-2.019\n",
      "Epoch:  0041 D loss:-0.6216 G loss:-2.195\n",
      "Epoch:  0041 D loss:-0.5573 G loss:-2.121\n",
      "Epoch:  0041 D loss:-0.5753 G loss:-2.05\n",
      "Epoch:  0041 D loss:-0.6102 G loss:-2.086\n",
      "Epoch:  0041 D loss:-0.5653 G loss:-2.281\n",
      "Epoch:  0041 D loss:-0.5332 G loss:-2.298\n",
      "Epoch:  0041 D loss:-0.5509 G loss:-2.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0041 D loss:-0.5375 G loss:-2.287\n",
      "Epoch:  0041 D loss:-0.5837 G loss:-2.282\n",
      "Epoch:  0041 D loss:-0.451 G loss:-2.563\n",
      "Epoch:  0041 D loss:-0.4659 G loss:-2.583\n",
      "Epoch:  0041 D loss:-0.5282 G loss:-2.639\n",
      "Epoch:  0041 D loss:-0.558 G loss:-2.514\n",
      "Epoch:  0041 D loss:-0.4577 G loss:-2.814\n",
      "Epoch:  0041 D loss:-0.5072 G loss:-2.612\n",
      "Epoch:  0041 D loss:-0.6326 G loss:-2.518\n",
      "Epoch:  0041 D loss:-0.5695 G loss:-2.417\n",
      "Epoch:  0041 D loss:-0.4631 G loss:-2.405\n",
      "Epoch:  0041 D loss:-0.5059 G loss:-2.174\n",
      "Epoch:  0041 D loss:-0.5647 G loss:-2.399\n",
      "Epoch:  0041 D loss:-0.4976 G loss:-2.367\n",
      "Epoch:  0041 D loss:-0.4969 G loss:-2.278\n",
      "Epoch:  0041 D loss:-0.6564 G loss:-2.223\n",
      "Epoch:  0041 D loss:-0.585 G loss:-2.219\n",
      "Epoch:  0041 D loss:-0.5611 G loss:-2.222\n",
      "Epoch:  0041 D loss:-0.6238 G loss:-2.308\n",
      "Epoch:  0041 D loss:-0.5373 G loss:-2.42\n",
      "Epoch:  0041 D loss:-0.715 G loss:-2.115\n",
      "Epoch:  0041 D loss:-0.5957 G loss:-2.148\n",
      "Epoch:  0041 D loss:-0.5505 G loss:-2.441\n",
      "Epoch:  0041 D loss:-0.6307 G loss:-2.304\n",
      "Epoch:  0041 D loss:-0.7043 G loss:-2.339\n",
      "Epoch:  0041 D loss:-0.506 G loss:-2.42\n",
      "Epoch:  0041 D loss:-0.4922 G loss:-2.49\n",
      "Epoch:  0041 D loss:-0.6086 G loss:-2.358\n",
      "Epoch:  0041 D loss:-0.508 G loss:-2.61\n",
      "Epoch:  0041 D loss:-0.5297 G loss:-2.492\n",
      "Epoch:  0041 D loss:-0.6552 G loss:-2.186\n",
      "Epoch:  0041 D loss:-0.4822 G loss:-2.278\n",
      "Epoch:  0041 D loss:-0.562 G loss:-2.484\n",
      "Epoch:  0041 D loss:-0.6079 G loss:-2.506\n",
      "Epoch:  0041 D loss:-0.4652 G loss:-2.671\n",
      "Epoch:  0041 D loss:-0.4291 G loss:-2.417\n",
      "Epoch:  0041 D loss:-0.6307 G loss:-2.482\n",
      "Epoch:  0041 D loss:-0.6102 G loss:-2.15\n",
      "Epoch:  0041 D loss:-0.5501 G loss:-2.491\n",
      "Epoch:  0041 D loss:-0.6438 G loss:-2.312\n",
      "Epoch:  0041 D loss:-0.5184 G loss:-2.429\n",
      "Epoch:  0041 D loss:-0.5276 G loss:-2.164\n",
      "Epoch:  0041 D loss:-0.4851 G loss:-2.307\n",
      "Epoch:  0041 D loss:-0.5609 G loss:-2.21\n",
      "Epoch:  0041 D loss:-0.5432 G loss:-2.142\n",
      "Epoch:  0041 D loss:-0.5801 G loss:-2.166\n",
      "Epoch:  0041 D loss:-0.473 G loss:-2.469\n",
      "Epoch:  0041 D loss:-0.542 G loss:-2.086\n",
      "Epoch:  0041 D loss:-0.6028 G loss:-2.529\n",
      "Epoch:  0041 D loss:-0.5397 G loss:-2.483\n",
      "Epoch:  0041 D loss:-0.5085 G loss:-2.395\n",
      "Epoch:  0041 D loss:-0.4724 G loss:-2.595\n",
      "Epoch:  0041 D loss:-0.5979 G loss:-2.673\n",
      "Epoch:  0041 D loss:-0.5322 G loss:-2.758\n",
      "Epoch:  0041 D loss:-0.5791 G loss:-2.673\n",
      "Epoch:  0041 D loss:-0.6249 G loss:-2.494\n",
      "Epoch:  0041 D loss:-0.5556 G loss:-2.678\n",
      "Epoch:  0041 D loss:-0.4437 G loss:-2.662\n",
      "Epoch:  0041 D loss:-0.6502 G loss:-2.568\n",
      "Epoch:  0041 D loss:-0.4314 G loss:-2.63\n",
      "Epoch:  0041 D loss:-0.4502 G loss:-2.194\n",
      "Epoch:  0041 D loss:-0.4459 G loss:-2.394\n",
      "Epoch:  0041 D loss:-0.461 G loss:-2.494\n",
      "Epoch:  0041 D loss:-0.5807 G loss:-2.201\n",
      "Epoch:  0041 D loss:-0.7064 G loss:-2.213\n",
      "Epoch:  0041 D loss:-0.502 G loss:-2.339\n",
      "Epoch:  0041 D loss:-0.5025 G loss:-2.209\n",
      "Epoch:  0041 D loss:-0.5151 G loss:-2.429\n",
      "Epoch:  0041 D loss:-0.505 G loss:-2.352\n",
      "Epoch:  0041 D loss:-0.6477 G loss:-2.457\n",
      "Epoch:  0041 D loss:-0.6556 G loss:-2.434\n",
      "Epoch:  0041 D loss:-0.5689 G loss:-2.501\n",
      "Epoch:  0041 D loss:-0.5627 G loss:-2.811\n",
      "Epoch:  0041 D loss:-0.5992 G loss:-2.625\n",
      "Epoch:  0041 D loss:-0.6893 G loss:-2.441\n",
      "Epoch:  0041 D loss:-0.6657 G loss:-2.245\n",
      "Epoch:  0041 D loss:-0.5928 G loss:-2.442\n",
      "Epoch:  0041 D loss:-0.5517 G loss:-2.414\n",
      "Epoch:  0041 D loss:-0.646 G loss:-2.364\n",
      "Epoch:  0041 D loss:-0.5428 G loss:-2.291\n",
      "Epoch:  0041 D loss:-0.6091 G loss:-2.379\n",
      "Epoch:  0041 D loss:-0.4436 G loss:-2.465\n",
      "Epoch:  0041 D loss:-0.5083 G loss:-2.579\n",
      "Epoch:  0041 D loss:-0.4596 G loss:-2.529\n",
      "Epoch:  0041 D loss:-0.5229 G loss:-2.366\n",
      "Epoch:  0041 D loss:-0.5583 G loss:-2.482\n",
      "Epoch:  0041 D loss:-0.4775 G loss:-2.233\n",
      "Epoch:  0041 D loss:-0.4681 G loss:-2.517\n",
      "Epoch:  0041 D loss:-0.4866 G loss:-2.582\n",
      "Epoch:  0041 D loss:-0.5716 G loss:-2.338\n",
      "Epoch:  0041 D loss:-0.6277 G loss:-2.321\n",
      "Epoch:  0041 D loss:-0.5846 G loss:-2.543\n",
      "Epoch:  0041 D loss:-0.5405 G loss:-2.563\n",
      "Epoch:  0041 D loss:-0.5352 G loss:-2.347\n",
      "Epoch:  0041 D loss:-0.5558 G loss:-2.563\n",
      "Epoch:  0041 D loss:-0.5826 G loss:-2.377\n",
      "Epoch:  0041 D loss:-0.4958 G loss:-2.226\n",
      "Epoch:  0041 D loss:-0.457 G loss:-2.334\n",
      "Epoch:  0041 D loss:-0.5346 G loss:-2.282\n",
      "Epoch:  0041 D loss:-0.6187 G loss:-2.168\n",
      "Epoch:  0041 D loss:-0.4896 G loss:-2.383\n",
      "Epoch:  0041 D loss:-0.4676 G loss:-2.351\n",
      "Epoch:  0041 D loss:-0.5859 G loss:-2.064\n",
      "Epoch:  0041 D loss:-0.5481 G loss:-2.29\n",
      "Epoch:  0041 D loss:-0.4615 G loss:-2.534\n",
      "Epoch:  0041 D loss:-0.5388 G loss:-2.416\n",
      "Epoch:  0041 D loss:-0.5827 G loss:-2.427\n",
      "Epoch:  0041 D loss:-0.6302 G loss:-2.583\n",
      "Epoch:  0041 D loss:-0.5544 G loss:-2.349\n",
      "Epoch:  0041 D loss:-0.6068 G loss:-2.427\n",
      "Epoch:  0041 D loss:-0.6488 G loss:-2.322\n",
      "Epoch:  0041 D loss:-0.3989 G loss:-2.449\n",
      "Epoch:  0041 D loss:-0.5059 G loss:-2.301\n",
      "Epoch:  0041 D loss:-0.5657 G loss:-2.452\n",
      "Epoch:  0041 D loss:-0.6643 G loss:-2.292\n",
      "Epoch:  0041 D loss:-0.5674 G loss:-2.273\n",
      "Epoch:  0041 D loss:-0.6572 G loss:-2.478\n",
      "Epoch:  0041 D loss:-0.494 G loss:-2.298\n",
      "Epoch:  0041 D loss:-0.4573 G loss:-2.42\n",
      "Epoch:  0041 D loss:-0.5628 G loss:-2.24\n",
      "Epoch:  0041 D loss:-0.4922 G loss:-2.27\n",
      "Epoch:  0041 D loss:-0.5757 G loss:-2.244\n",
      "Epoch:  0041 D loss:-0.543 G loss:-2.166\n",
      "Epoch:  0041 D loss:-0.5851 G loss:-2.314\n",
      "Epoch:  0041 D loss:-0.6277 G loss:-2.431\n",
      "Epoch:  0041 D loss:-0.6526 G loss:-2.173\n",
      "Epoch:  0041 D loss:-0.5747 G loss:-2.569\n",
      "Epoch:  0041 D loss:-0.51 G loss:-2.408\n",
      "Epoch:  0041 D loss:-0.5069 G loss:-2.584\n",
      "Epoch:  0041 D loss:-0.6012 G loss:-2.419\n",
      "Epoch:  0041 D loss:-0.6512 G loss:-2.209\n",
      "Epoch:  0041 D loss:-0.6031 G loss:-2.252\n",
      "Epoch:  0041 D loss:-0.5968 G loss:-2.206\n",
      "Epoch:  0041 D loss:-0.557 G loss:-2.257\n",
      "Epoch:  0041 D loss:-0.4825 G loss:-2.41\n",
      "Epoch:  0041 D loss:-0.5919 G loss:-2.211\n",
      "Epoch:  0041 D loss:-0.4345 G loss:-2.566\n",
      "Epoch:  0041 D loss:-0.6081 G loss:-2.268\n",
      "Epoch:  0041 D loss:-0.5273 G loss:-2.503\n",
      "Epoch:  0041 D loss:-0.4992 G loss:-2.236\n",
      "Epoch:  0041 D loss:-0.5146 G loss:-2.535\n",
      "Epoch:  0041 D loss:-0.5517 G loss:-2.322\n",
      "Epoch:  0041 D loss:-0.523 G loss:-2.502\n",
      "Epoch:  0041 D loss:-0.6593 G loss:-2.737\n",
      "Epoch:  0041 D loss:-0.5147 G loss:-2.43\n",
      "Epoch:  0041 D loss:-0.5993 G loss:-2.613\n",
      "Epoch:  0041 D loss:-0.6738 G loss:-2.546\n",
      "Epoch:  0041 D loss:-0.5968 G loss:-2.509\n",
      "Epoch:  0041 D loss:-0.5264 G loss:-2.601\n",
      "Epoch:  0041 D loss:-0.6486 G loss:-2.358\n",
      "Epoch:  0041 D loss:-0.5661 G loss:-2.157\n",
      "Epoch:  0041 D loss:-0.4735 G loss:-2.182\n",
      "Epoch:  0041 D loss:-0.5552 G loss:-2.09\n",
      "Epoch:  0041 D loss:-0.598 G loss:-2.012\n",
      "Epoch:  0041 D loss:-0.6113 G loss:-2.17\n",
      "Epoch:  0041 D loss:-0.6169 G loss:-2.166\n",
      "Epoch:  0041 D loss:-0.529 G loss:-2.389\n",
      "Epoch:  0041 D loss:-0.5921 G loss:-2.385\n",
      "Epoch:  0041 D loss:-0.4821 G loss:-2.534\n",
      "Epoch:  0041 D loss:-0.3827 G loss:-2.457\n",
      "Epoch:  0041 D loss:-0.5895 G loss:-2.357\n",
      "Epoch:  0041 D loss:-0.613 G loss:-2.29\n",
      "Epoch:  0041 D loss:-0.6147 G loss:-2.281\n",
      "Epoch:  0041 D loss:-0.6092 G loss:-2.271\n",
      "Epoch:  0041 D loss:-0.6489 G loss:-2.186\n",
      "Epoch:  0041 D loss:-0.4677 G loss:-2.402\n",
      "Epoch:  0041 D loss:-0.5542 G loss:-2.269\n",
      "Epoch:  0041 D loss:-0.4479 G loss:-2.46\n",
      "Epoch:  0041 D loss:-0.5268 G loss:-2.293\n",
      "Epoch:  0041 D loss:-0.615 G loss:-2.279\n",
      "Epoch:  0041 D loss:-0.6663 G loss:-2.093\n",
      "Epoch:  0041 D loss:-0.6071 G loss:-2.194\n",
      "Epoch:  0041 D loss:-0.4939 G loss:-2.266\n",
      "Epoch:  0041 D loss:-0.5822 G loss:-2.406\n",
      "Epoch:  0041 D loss:-0.5819 G loss:-2.421\n",
      "Epoch:  0041 D loss:-0.6812 G loss:-2.276\n",
      "Epoch:  0041 D loss:-0.595 G loss:-2.475\n",
      "Epoch:  0041 D loss:-0.5319 G loss:-2.343\n",
      "Epoch:  0041 D loss:-0.5727 G loss:-2.42\n",
      "Epoch:  0041 D loss:-0.556 G loss:-2.58\n",
      "Epoch:  0041 D loss:-0.5104 G loss:-2.54\n",
      "Epoch:  0041 D loss:-0.6253 G loss:-2.336\n",
      "Epoch:  0041 D loss:-0.6376 G loss:-2.385\n",
      "Epoch:  0041 D loss:-0.6236 G loss:-2.322\n",
      "Epoch:  0041 D loss:-0.5506 G loss:-2.559\n",
      "Epoch:  0041 D loss:-0.5099 G loss:-2.366\n",
      "Epoch:  0041 D loss:-0.5617 G loss:-2.309\n",
      "Epoch:  0041 D loss:-0.6557 G loss:-2.224\n",
      "Epoch:  0041 D loss:-0.6631 G loss:-2.164\n",
      "Epoch:  0041 D loss:-0.4602 G loss:-2.46\n",
      "Epoch:  0041 D loss:-0.6062 G loss:-2.176\n",
      "Epoch:  0041 D loss:-0.4843 G loss:-2.18\n",
      "Epoch:  0041 D loss:-0.6288 G loss:-2.301\n",
      "Epoch:  0041 D loss:-0.5121 G loss:-2.507\n",
      "Epoch:  0041 D loss:-0.5097 G loss:-2.291\n",
      "Epoch:  0041 D loss:-0.5387 G loss:-2.561\n",
      "Epoch:  0041 D loss:-0.4894 G loss:-2.551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0041 D loss:-0.4678 G loss:-2.641\n",
      "Epoch:  0041 D loss:-0.4226 G loss:-2.707\n",
      "Epoch:  0041 D loss:-0.4949 G loss:-2.792\n",
      "Epoch:  0041 D loss:-0.42 G loss:-2.532\n",
      "Epoch:  0041 D loss:-0.5759 G loss:-2.439\n",
      "Epoch:  0041 D loss:-0.566 G loss:-2.624\n",
      "Epoch:  0041 D loss:-0.6236 G loss:-2.299\n",
      "Epoch:  0041 D loss:-0.5065 G loss:-2.247\n",
      "Epoch:  0041 D loss:-0.5089 G loss:-2.584\n",
      "Epoch:  0041 D loss:-0.5568 G loss:-2.315\n",
      "Epoch:  0041 D loss:-0.5666 G loss:-2.4\n",
      "Epoch:  0041 D loss:-0.5353 G loss:-2.222\n",
      "Epoch:  0041 D loss:-0.5297 G loss:-2.449\n",
      "Epoch:  0041 D loss:-0.6003 G loss:-2.591\n",
      "Epoch:  0041 D loss:-0.5435 G loss:-2.484\n",
      "Epoch:  0041 D loss:-0.4892 G loss:-2.571\n",
      "Epoch:  0041 D loss:-0.5256 G loss:-2.465\n",
      "Epoch:  0041 D loss:-0.5889 G loss:-2.478\n",
      "Epoch:  0041 D loss:-0.5916 G loss:-2.338\n",
      "Epoch:  0041 D loss:-0.4525 G loss:-2.472\n",
      "Epoch:  0041 D loss:-0.5918 G loss:-2.672\n",
      "Epoch:  0041 D loss:-0.5728 G loss:-2.291\n",
      "Epoch:  0041 D loss:-0.5007 G loss:-2.469\n",
      "Epoch:  0041 D loss:-0.6135 G loss:-2.37\n",
      "Epoch:  0042 D loss:-0.5308 G loss:-2.444\n",
      "Epoch:  0042 D loss:-0.4751 G loss:-2.369\n",
      "Epoch:  0042 D loss:-0.4529 G loss:-2.202\n",
      "Epoch:  0042 D loss:-0.5546 G loss:-2.125\n",
      "Epoch:  0042 D loss:-0.4851 G loss:-2.508\n",
      "Epoch:  0042 D loss:-0.5315 G loss:-2.154\n",
      "Epoch:  0042 D loss:-0.6833 G loss:-2.198\n",
      "Epoch:  0042 D loss:-0.5813 G loss:-2.433\n",
      "Epoch:  0042 D loss:-0.5105 G loss:-2.395\n",
      "Epoch:  0042 D loss:-0.5876 G loss:-2.662\n",
      "Epoch:  0042 D loss:-0.5393 G loss:-2.571\n",
      "Epoch:  0042 D loss:-0.5827 G loss:-2.616\n",
      "Epoch:  0042 D loss:-0.6124 G loss:-2.498\n",
      "Epoch:  0042 D loss:-0.5431 G loss:-2.511\n",
      "Epoch:  0042 D loss:-0.4265 G loss:-2.559\n",
      "Epoch:  0042 D loss:-0.4261 G loss:-2.395\n",
      "Epoch:  0042 D loss:-0.4045 G loss:-2.298\n",
      "Epoch:  0042 D loss:-0.4237 G loss:-2.694\n",
      "Epoch:  0042 D loss:-0.6003 G loss:-2.346\n",
      "Epoch:  0042 D loss:-0.5649 G loss:-2.168\n",
      "Epoch:  0042 D loss:-0.4528 G loss:-2.428\n",
      "Epoch:  0042 D loss:-0.414 G loss:-2.636\n",
      "Epoch:  0042 D loss:-0.4709 G loss:-2.56\n",
      "Epoch:  0042 D loss:-0.6094 G loss:-2.823\n",
      "Epoch:  0042 D loss:-0.6109 G loss:-2.562\n",
      "Epoch:  0042 D loss:-0.5465 G loss:-2.651\n",
      "Epoch:  0042 D loss:-0.5136 G loss:-2.393\n",
      "Epoch:  0042 D loss:-0.6947 G loss:-2.375\n",
      "Epoch:  0042 D loss:-0.5171 G loss:-2.235\n",
      "Epoch:  0042 D loss:-0.4824 G loss:-2.45\n",
      "Epoch:  0042 D loss:-0.573 G loss:-2.142\n",
      "Epoch:  0042 D loss:-0.7067 G loss:-2.121\n",
      "Epoch:  0042 D loss:-0.6528 G loss:-2.326\n",
      "Epoch:  0042 D loss:-0.7102 G loss:-2.519\n",
      "Epoch:  0042 D loss:-0.6272 G loss:-2.259\n",
      "Epoch:  0042 D loss:-0.6691 G loss:-2.294\n",
      "Epoch:  0042 D loss:-0.5489 G loss:-2.479\n",
      "Epoch:  0042 D loss:-0.5215 G loss:-2.278\n",
      "Epoch:  0042 D loss:-0.4879 G loss:-2.333\n",
      "Epoch:  0042 D loss:-0.5121 G loss:-2.443\n",
      "Epoch:  0042 D loss:-0.5469 G loss:-2.494\n",
      "Epoch:  0042 D loss:-0.6403 G loss:-2.423\n",
      "Epoch:  0042 D loss:-0.561 G loss:-2.407\n",
      "Epoch:  0042 D loss:-0.5365 G loss:-2.407\n",
      "Epoch:  0042 D loss:-0.6641 G loss:-2.298\n",
      "Epoch:  0042 D loss:-0.5792 G loss:-2.407\n",
      "Epoch:  0042 D loss:-0.4136 G loss:-2.532\n",
      "Epoch:  0042 D loss:-0.4999 G loss:-2.276\n",
      "Epoch:  0042 D loss:-0.5102 G loss:-2.474\n",
      "Epoch:  0042 D loss:-0.6139 G loss:-2.211\n",
      "Epoch:  0042 D loss:-0.5469 G loss:-2.332\n",
      "Epoch:  0042 D loss:-0.5362 G loss:-2.298\n",
      "Epoch:  0042 D loss:-0.6243 G loss:-2.253\n",
      "Epoch:  0042 D loss:-0.4047 G loss:-2.303\n",
      "Epoch:  0042 D loss:-0.6532 G loss:-2.472\n",
      "Epoch:  0042 D loss:-0.4377 G loss:-2.392\n",
      "Epoch:  0042 D loss:-0.6441 G loss:-2.265\n",
      "Epoch:  0042 D loss:-0.6486 G loss:-2.129\n",
      "Epoch:  0042 D loss:-0.5759 G loss:-2.158\n",
      "Epoch:  0042 D loss:-0.5633 G loss:-2.325\n",
      "Epoch:  0042 D loss:-0.5475 G loss:-2.436\n",
      "Epoch:  0042 D loss:-0.5285 G loss:-2.682\n",
      "Epoch:  0042 D loss:-0.5125 G loss:-2.487\n",
      "Epoch:  0042 D loss:-0.5232 G loss:-2.435\n",
      "Epoch:  0042 D loss:-0.6943 G loss:-2.161\n",
      "Epoch:  0042 D loss:-0.5333 G loss:-2.362\n",
      "Epoch:  0042 D loss:-0.4998 G loss:-2.453\n",
      "Epoch:  0042 D loss:-0.6204 G loss:-2.278\n",
      "Epoch:  0042 D loss:-0.6355 G loss:-2.305\n",
      "Epoch:  0042 D loss:-0.5277 G loss:-2.585\n",
      "Epoch:  0042 D loss:-0.5407 G loss:-2.328\n",
      "Epoch:  0042 D loss:-0.6285 G loss:-2.195\n",
      "Epoch:  0042 D loss:-0.6029 G loss:-2.524\n",
      "Epoch:  0042 D loss:-0.5379 G loss:-2.386\n",
      "Epoch:  0042 D loss:-0.5733 G loss:-2.279\n",
      "Epoch:  0042 D loss:-0.6139 G loss:-2.373\n",
      "Epoch:  0042 D loss:-0.6619 G loss:-2.45\n",
      "Epoch:  0042 D loss:-0.5932 G loss:-2.257\n",
      "Epoch:  0042 D loss:-0.4246 G loss:-2.348\n",
      "Epoch:  0042 D loss:-0.5123 G loss:-2.471\n",
      "Epoch:  0042 D loss:-0.6108 G loss:-2.248\n",
      "Epoch:  0042 D loss:-0.5162 G loss:-2.448\n",
      "Epoch:  0042 D loss:-0.6891 G loss:-2.315\n",
      "Epoch:  0042 D loss:-0.496 G loss:-2.514\n",
      "Epoch:  0042 D loss:-0.6584 G loss:-2.338\n",
      "Epoch:  0042 D loss:-0.6639 G loss:-2.266\n",
      "Epoch:  0042 D loss:-0.4617 G loss:-2.462\n",
      "Epoch:  0042 D loss:-0.5877 G loss:-2.078\n",
      "Epoch:  0042 D loss:-0.5099 G loss:-2.457\n",
      "Epoch:  0042 D loss:-0.5781 G loss:-2.144\n",
      "Epoch:  0042 D loss:-0.5586 G loss:-2.276\n",
      "Epoch:  0042 D loss:-0.6606 G loss:-2.052\n",
      "Epoch:  0042 D loss:-0.6356 G loss:-2.187\n",
      "Epoch:  0042 D loss:-0.5695 G loss:-2.217\n",
      "Epoch:  0042 D loss:-0.6204 G loss:-2.357\n",
      "Epoch:  0042 D loss:-0.5798 G loss:-2.441\n",
      "Epoch:  0042 D loss:-0.4894 G loss:-2.516\n",
      "Epoch:  0042 D loss:-0.5469 G loss:-2.508\n",
      "Epoch:  0042 D loss:-0.5669 G loss:-2.664\n",
      "Epoch:  0042 D loss:-0.5143 G loss:-2.402\n",
      "Epoch:  0042 D loss:-0.5841 G loss:-2.39\n",
      "Epoch:  0042 D loss:-0.4525 G loss:-2.506\n",
      "Epoch:  0042 D loss:-0.5275 G loss:-2.276\n",
      "Epoch:  0042 D loss:-0.6988 G loss:-2.204\n",
      "Epoch:  0042 D loss:-0.6646 G loss:-2.263\n",
      "Epoch:  0042 D loss:-0.493 G loss:-2.389\n",
      "Epoch:  0042 D loss:-0.646 G loss:-2.257\n",
      "Epoch:  0042 D loss:-0.5514 G loss:-2.198\n",
      "Epoch:  0042 D loss:-0.6167 G loss:-2.125\n",
      "Epoch:  0042 D loss:-0.5287 G loss:-2.359\n",
      "Epoch:  0042 D loss:-0.7518 G loss:-2.174\n",
      "Epoch:  0042 D loss:-0.4927 G loss:-2.373\n",
      "Epoch:  0042 D loss:-0.4704 G loss:-2.341\n",
      "Epoch:  0042 D loss:-0.558 G loss:-2.289\n",
      "Epoch:  0042 D loss:-0.6096 G loss:-2.295\n",
      "Epoch:  0042 D loss:-0.5175 G loss:-2.37\n",
      "Epoch:  0042 D loss:-0.4818 G loss:-2.557\n",
      "Epoch:  0042 D loss:-0.4907 G loss:-2.523\n",
      "Epoch:  0042 D loss:-0.6435 G loss:-2.385\n",
      "Epoch:  0042 D loss:-0.6044 G loss:-2.422\n",
      "Epoch:  0042 D loss:-0.5075 G loss:-2.337\n",
      "Epoch:  0042 D loss:-0.504 G loss:-2.491\n",
      "Epoch:  0042 D loss:-0.5133 G loss:-2.245\n",
      "Epoch:  0042 D loss:-0.5067 G loss:-2.497\n",
      "Epoch:  0042 D loss:-0.549 G loss:-2.337\n",
      "Epoch:  0042 D loss:-0.6829 G loss:-2.22\n",
      "Epoch:  0042 D loss:-0.5359 G loss:-2.4\n",
      "Epoch:  0042 D loss:-0.514 G loss:-2.342\n",
      "Epoch:  0042 D loss:-0.378 G loss:-2.494\n",
      "Epoch:  0042 D loss:-0.5681 G loss:-2.439\n",
      "Epoch:  0042 D loss:-0.5336 G loss:-2.261\n",
      "Epoch:  0042 D loss:-0.6363 G loss:-2.31\n",
      "Epoch:  0042 D loss:-0.6863 G loss:-2.335\n",
      "Epoch:  0042 D loss:-0.5664 G loss:-2.245\n",
      "Epoch:  0042 D loss:-0.5584 G loss:-2.26\n",
      "Epoch:  0042 D loss:-0.4353 G loss:-2.458\n",
      "Epoch:  0042 D loss:-0.4664 G loss:-2.459\n",
      "Epoch:  0042 D loss:-0.4882 G loss:-2.37\n",
      "Epoch:  0042 D loss:-0.5251 G loss:-2.495\n",
      "Epoch:  0042 D loss:-0.7286 G loss:-2.518\n",
      "Epoch:  0042 D loss:-0.5325 G loss:-2.518\n",
      "Epoch:  0042 D loss:-0.516 G loss:-2.444\n",
      "Epoch:  0042 D loss:-0.5069 G loss:-2.604\n",
      "Epoch:  0042 D loss:-0.4651 G loss:-2.363\n",
      "Epoch:  0042 D loss:-0.5878 G loss:-2.57\n",
      "Epoch:  0042 D loss:-0.5902 G loss:-2.268\n",
      "Epoch:  0042 D loss:-0.6609 G loss:-2.226\n",
      "Epoch:  0042 D loss:-0.5023 G loss:-2.416\n",
      "Epoch:  0042 D loss:-0.4897 G loss:-2.204\n",
      "Epoch:  0042 D loss:-0.4675 G loss:-2.452\n",
      "Epoch:  0042 D loss:-0.5101 G loss:-2.3\n",
      "Epoch:  0042 D loss:-0.6217 G loss:-2.301\n",
      "Epoch:  0042 D loss:-0.5023 G loss:-2.266\n",
      "Epoch:  0042 D loss:-0.4317 G loss:-2.409\n",
      "Epoch:  0042 D loss:-0.522 G loss:-2.496\n",
      "Epoch:  0042 D loss:-0.5802 G loss:-2.335\n",
      "Epoch:  0042 D loss:-0.5289 G loss:-2.548\n",
      "Epoch:  0042 D loss:-0.4916 G loss:-2.599\n",
      "Epoch:  0042 D loss:-0.5647 G loss:-2.517\n",
      "Epoch:  0042 D loss:-0.4445 G loss:-2.597\n",
      "Epoch:  0042 D loss:-0.4992 G loss:-2.535\n",
      "Epoch:  0042 D loss:-0.4963 G loss:-2.499\n",
      "Epoch:  0042 D loss:-0.6306 G loss:-2.517\n",
      "Epoch:  0042 D loss:-0.4296 G loss:-2.695\n",
      "Epoch:  0042 D loss:-0.5212 G loss:-2.331\n",
      "Epoch:  0042 D loss:-0.5519 G loss:-2.418\n",
      "Epoch:  0042 D loss:-0.4904 G loss:-2.491\n",
      "Epoch:  0042 D loss:-0.4238 G loss:-2.488\n",
      "Epoch:  0042 D loss:-0.3714 G loss:-2.467\n",
      "Epoch:  0042 D loss:-0.3848 G loss:-2.469\n",
      "Epoch:  0042 D loss:-0.5359 G loss:-2.255\n",
      "Epoch:  0042 D loss:-0.4727 G loss:-2.479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0042 D loss:-0.5703 G loss:-2.505\n",
      "Epoch:  0042 D loss:-0.6538 G loss:-2.504\n",
      "Epoch:  0042 D loss:-0.4465 G loss:-2.618\n",
      "Epoch:  0042 D loss:-0.5102 G loss:-2.752\n",
      "Epoch:  0042 D loss:-0.4065 G loss:-2.811\n",
      "Epoch:  0042 D loss:-0.4533 G loss:-2.727\n",
      "Epoch:  0042 D loss:-0.7306 G loss:-2.638\n",
      "Epoch:  0042 D loss:-0.4536 G loss:-2.397\n",
      "Epoch:  0042 D loss:-0.3945 G loss:-2.718\n",
      "Epoch:  0042 D loss:-0.5096 G loss:-2.722\n",
      "Epoch:  0042 D loss:-0.4078 G loss:-2.414\n",
      "Epoch:  0042 D loss:-0.5061 G loss:-2.521\n",
      "Epoch:  0042 D loss:-0.5472 G loss:-2.41\n",
      "Epoch:  0042 D loss:-0.4143 G loss:-2.349\n",
      "Epoch:  0042 D loss:-0.5966 G loss:-2.161\n",
      "Epoch:  0042 D loss:-0.5132 G loss:-2.405\n",
      "Epoch:  0042 D loss:-0.5345 G loss:-2.312\n",
      "Epoch:  0042 D loss:-0.4531 G loss:-2.315\n",
      "Epoch:  0042 D loss:-0.6495 G loss:-2.338\n",
      "Epoch:  0042 D loss:-0.4836 G loss:-2.512\n",
      "Epoch:  0042 D loss:-0.4961 G loss:-2.506\n",
      "Epoch:  0042 D loss:-0.4878 G loss:-2.569\n",
      "Epoch:  0042 D loss:-0.4632 G loss:-2.459\n",
      "Epoch:  0042 D loss:-0.7244 G loss:-2.742\n",
      "Epoch:  0042 D loss:-0.5634 G loss:-2.655\n",
      "Epoch:  0042 D loss:-0.5344 G loss:-2.42\n",
      "Epoch:  0042 D loss:-0.6503 G loss:-2.526\n",
      "Epoch:  0042 D loss:-0.653 G loss:-2.449\n",
      "Epoch:  0042 D loss:-0.4406 G loss:-2.333\n",
      "Epoch:  0042 D loss:-0.6163 G loss:-2.134\n",
      "Epoch:  0042 D loss:-0.5953 G loss:-2.154\n",
      "Epoch:  0042 D loss:-0.6061 G loss:-1.976\n",
      "Epoch:  0042 D loss:-0.5722 G loss:-2.192\n",
      "Epoch:  0042 D loss:-0.4922 G loss:-2.151\n",
      "Epoch:  0042 D loss:-0.5631 G loss:-2.453\n",
      "Epoch:  0042 D loss:-0.6266 G loss:-2.277\n",
      "Epoch:  0042 D loss:-0.518 G loss:-2.647\n",
      "Epoch:  0042 D loss:-0.5091 G loss:-2.545\n",
      "Epoch:  0042 D loss:-0.5945 G loss:-2.382\n",
      "Epoch:  0042 D loss:-0.5392 G loss:-2.601\n",
      "Epoch:  0042 D loss:-0.4617 G loss:-2.61\n",
      "Epoch:  0042 D loss:-0.4326 G loss:-2.416\n",
      "Epoch:  0042 D loss:-0.5138 G loss:-2.39\n",
      "Epoch:  0042 D loss:-0.4031 G loss:-2.479\n",
      "Epoch:  0042 D loss:-0.5641 G loss:-2.383\n",
      "Epoch:  0042 D loss:-0.5552 G loss:-2.269\n",
      "Epoch:  0042 D loss:-0.4938 G loss:-2.481\n",
      "Epoch:  0042 D loss:-0.4821 G loss:-2.496\n",
      "Epoch:  0042 D loss:-0.4394 G loss:-2.351\n",
      "Epoch:  0042 D loss:-0.5953 G loss:-2.141\n",
      "Epoch:  0042 D loss:-0.4943 G loss:-2.357\n",
      "Epoch:  0042 D loss:-0.5759 G loss:-2.325\n",
      "Epoch:  0042 D loss:-0.5192 G loss:-2.345\n",
      "Epoch:  0042 D loss:-0.6547 G loss:-2.38\n",
      "Epoch:  0042 D loss:-0.6392 G loss:-2.232\n",
      "Epoch:  0042 D loss:-0.5113 G loss:-2.33\n",
      "Epoch:  0042 D loss:-0.5722 G loss:-2.296\n",
      "Epoch:  0042 D loss:-0.5711 G loss:-2.145\n",
      "Epoch:  0042 D loss:-0.4389 G loss:-2.384\n",
      "Epoch:  0042 D loss:-0.5203 G loss:-2.49\n",
      "Epoch:  0042 D loss:-0.5589 G loss:-2.413\n",
      "Epoch:  0042 D loss:-0.5488 G loss:-2.439\n",
      "Epoch:  0042 D loss:-0.5615 G loss:-2.228\n",
      "Epoch:  0042 D loss:-0.5311 G loss:-2.399\n",
      "Epoch:  0042 D loss:-0.4668 G loss:-2.382\n",
      "Epoch:  0042 D loss:-0.4807 G loss:-2.321\n",
      "Epoch:  0042 D loss:-0.6654 G loss:-2.22\n",
      "Epoch:  0042 D loss:-0.5469 G loss:-2.275\n",
      "Epoch:  0042 D loss:-0.4899 G loss:-2.548\n",
      "Epoch:  0042 D loss:-0.6517 G loss:-2.577\n",
      "Epoch:  0042 D loss:-0.5228 G loss:-2.368\n",
      "Epoch:  0042 D loss:-0.6116 G loss:-2.597\n",
      "Epoch:  0042 D loss:-0.5492 G loss:-2.633\n",
      "Epoch:  0042 D loss:-0.6574 G loss:-2.124\n",
      "Epoch:  0042 D loss:-0.5689 G loss:-2.102\n",
      "Epoch:  0042 D loss:-0.6387 G loss:-2.305\n",
      "Epoch:  0042 D loss:-0.608 G loss:-2.2\n",
      "Epoch:  0042 D loss:-0.5912 G loss:-2.149\n",
      "Epoch:  0042 D loss:-0.5478 G loss:-2.25\n",
      "Epoch:  0042 D loss:-0.5075 G loss:-2.057\n",
      "Epoch:  0042 D loss:-0.5234 G loss:-2.242\n",
      "Epoch:  0042 D loss:-0.5763 G loss:-2.216\n",
      "Epoch:  0042 D loss:-0.4691 G loss:-2.411\n",
      "Epoch:  0042 D loss:-0.4934 G loss:-2.542\n",
      "Epoch:  0042 D loss:-0.5623 G loss:-2.486\n",
      "Epoch:  0042 D loss:-0.609 G loss:-2.38\n",
      "Epoch:  0042 D loss:-0.5403 G loss:-2.518\n",
      "Epoch:  0042 D loss:-0.4214 G loss:-2.429\n",
      "Epoch:  0042 D loss:-0.5091 G loss:-2.716\n",
      "Epoch:  0042 D loss:-0.5913 G loss:-2.461\n",
      "Epoch:  0042 D loss:-0.6218 G loss:-2.508\n",
      "Epoch:  0042 D loss:-0.5277 G loss:-2.404\n",
      "Epoch:  0042 D loss:-0.5688 G loss:-2.556\n",
      "Epoch:  0042 D loss:-0.5401 G loss:-2.415\n",
      "Epoch:  0042 D loss:-0.662 G loss:-2.434\n",
      "Epoch:  0042 D loss:-0.5666 G loss:-2.334\n",
      "Epoch:  0042 D loss:-0.5415 G loss:-2.158\n",
      "Epoch:  0042 D loss:-0.5982 G loss:-1.947\n",
      "Epoch:  0042 D loss:-0.724 G loss:-1.804\n",
      "Epoch:  0042 D loss:-0.679 G loss:-2.045\n",
      "Epoch:  0042 D loss:-0.585 G loss:-2.117\n",
      "Epoch:  0042 D loss:-0.6525 G loss:-2.035\n",
      "Epoch:  0042 D loss:-0.5647 G loss:-2.301\n",
      "Epoch:  0042 D loss:-0.6184 G loss:-2.337\n",
      "Epoch:  0042 D loss:-0.6205 G loss:-2.434\n",
      "Epoch:  0042 D loss:-0.6305 G loss:-2.481\n",
      "Epoch:  0042 D loss:-0.7952 G loss:-2.272\n",
      "Epoch:  0042 D loss:-0.5898 G loss:-2.294\n",
      "Epoch:  0042 D loss:-0.6116 G loss:-2.382\n",
      "Epoch:  0042 D loss:-0.615 G loss:-2.28\n",
      "Epoch:  0042 D loss:-0.4681 G loss:-2.507\n",
      "Epoch:  0042 D loss:-0.5461 G loss:-2.455\n",
      "Epoch:  0042 D loss:-0.7212 G loss:-2.465\n",
      "Epoch:  0042 D loss:-0.5059 G loss:-2.649\n",
      "Epoch:  0042 D loss:-0.6283 G loss:-2.379\n",
      "Epoch:  0042 D loss:-0.5147 G loss:-2.511\n",
      "Epoch:  0042 D loss:-0.4823 G loss:-2.302\n",
      "Epoch:  0042 D loss:-0.4699 G loss:-2.122\n",
      "Epoch:  0042 D loss:-0.5406 G loss:-2.407\n",
      "Epoch:  0042 D loss:-0.5227 G loss:-2.391\n",
      "Epoch:  0042 D loss:-0.6341 G loss:-2.492\n",
      "Epoch:  0042 D loss:-0.6099 G loss:-2.297\n",
      "Epoch:  0042 D loss:-0.5789 G loss:-2.305\n",
      "Epoch:  0042 D loss:-0.68 G loss:-2.26\n",
      "Epoch:  0042 D loss:-0.5745 G loss:-2.383\n",
      "Epoch:  0042 D loss:-0.5874 G loss:-2.374\n",
      "Epoch:  0042 D loss:-0.5479 G loss:-2.283\n",
      "Epoch:  0042 D loss:-0.5504 G loss:-2.549\n",
      "Epoch:  0042 D loss:-0.7224 G loss:-2.331\n",
      "Epoch:  0042 D loss:-0.4665 G loss:-2.426\n",
      "Epoch:  0042 D loss:-0.569 G loss:-2.339\n",
      "Epoch:  0042 D loss:-0.652 G loss:-2.347\n",
      "Epoch:  0042 D loss:-0.5011 G loss:-2.374\n",
      "Epoch:  0042 D loss:-0.4822 G loss:-2.572\n",
      "Epoch:  0042 D loss:-0.5448 G loss:-2.487\n",
      "Epoch:  0042 D loss:-0.5363 G loss:-2.364\n",
      "Epoch:  0042 D loss:-0.6919 G loss:-2.215\n",
      "Epoch:  0042 D loss:-0.5457 G loss:-2.57\n",
      "Epoch:  0042 D loss:-0.5532 G loss:-2.353\n",
      "Epoch:  0042 D loss:-0.4516 G loss:-2.274\n",
      "Epoch:  0042 D loss:-0.62 G loss:-2.187\n",
      "Epoch:  0042 D loss:-0.5787 G loss:-2.298\n",
      "Epoch:  0042 D loss:-0.4929 G loss:-2.368\n",
      "Epoch:  0042 D loss:-0.4689 G loss:-2.409\n",
      "Epoch:  0042 D loss:-0.5181 G loss:-2.331\n",
      "Epoch:  0042 D loss:-0.6671 G loss:-2.212\n",
      "Epoch:  0042 D loss:-0.5058 G loss:-2.53\n",
      "Epoch:  0042 D loss:-0.6036 G loss:-2.768\n",
      "Epoch:  0042 D loss:-0.6748 G loss:-2.71\n",
      "Epoch:  0042 D loss:-0.4894 G loss:-2.477\n",
      "Epoch:  0042 D loss:-0.6275 G loss:-2.656\n",
      "Epoch:  0042 D loss:-0.6042 G loss:-2.514\n",
      "Epoch:  0042 D loss:-0.6051 G loss:-2.539\n",
      "Epoch:  0042 D loss:-0.5809 G loss:-2.213\n",
      "Epoch:  0042 D loss:-0.4641 G loss:-2.302\n",
      "Epoch:  0042 D loss:-0.5941 G loss:-2.264\n",
      "Epoch:  0042 D loss:-0.5595 G loss:-2.295\n",
      "Epoch:  0042 D loss:-0.4981 G loss:-2.177\n",
      "Epoch:  0042 D loss:-0.3824 G loss:-2.339\n",
      "Epoch:  0042 D loss:-0.5055 G loss:-2.425\n",
      "Epoch:  0042 D loss:-0.4631 G loss:-2.43\n",
      "Epoch:  0042 D loss:-0.5416 G loss:-2.617\n",
      "Epoch:  0042 D loss:-0.5637 G loss:-2.395\n",
      "Epoch:  0042 D loss:-0.5273 G loss:-2.568\n",
      "Epoch:  0042 D loss:-0.5338 G loss:-2.596\n",
      "Epoch:  0042 D loss:-0.5803 G loss:-2.617\n",
      "Epoch:  0042 D loss:-0.437 G loss:-2.5\n",
      "Epoch:  0042 D loss:-0.5848 G loss:-2.57\n",
      "Epoch:  0042 D loss:-0.5672 G loss:-2.394\n",
      "Epoch:  0042 D loss:-0.6462 G loss:-1.99\n",
      "Epoch:  0042 D loss:-0.5935 G loss:-2.253\n",
      "Epoch:  0042 D loss:-0.6564 G loss:-2.274\n",
      "Epoch:  0042 D loss:-0.6107 G loss:-2.333\n",
      "Epoch:  0042 D loss:-0.639 G loss:-2.261\n",
      "Epoch:  0042 D loss:-0.515 G loss:-2.327\n",
      "Epoch:  0042 D loss:-0.5105 G loss:-2.138\n",
      "Epoch:  0042 D loss:-0.5774 G loss:-2.198\n",
      "Epoch:  0042 D loss:-0.6132 G loss:-2.075\n",
      "Epoch:  0042 D loss:-0.5174 G loss:-2.281\n",
      "Epoch:  0042 D loss:-0.4727 G loss:-2.467\n",
      "Epoch:  0042 D loss:-0.5695 G loss:-2.232\n",
      "Epoch:  0042 D loss:-0.6771 G loss:-2.239\n",
      "Epoch:  0042 D loss:-0.5931 G loss:-2.601\n",
      "Epoch:  0042 D loss:-0.6081 G loss:-2.588\n",
      "Epoch:  0042 D loss:-0.4861 G loss:-2.578\n",
      "Epoch:  0042 D loss:-0.6784 G loss:-2.436\n",
      "Epoch:  0042 D loss:-0.6907 G loss:-2.236\n",
      "Epoch:  0042 D loss:-0.6954 G loss:-2.215\n",
      "Epoch:  0042 D loss:-0.5884 G loss:-2.129\n",
      "Epoch:  0042 D loss:-0.5892 G loss:-2.411\n",
      "Epoch:  0042 D loss:-0.5617 G loss:-2.433\n",
      "Epoch:  0042 D loss:-0.5869 G loss:-2.398\n",
      "Epoch:  0042 D loss:-0.5722 G loss:-2.251\n",
      "Epoch:  0042 D loss:-0.4707 G loss:-2.253\n",
      "Epoch:  0042 D loss:-0.5532 G loss:-2.024\n",
      "Epoch:  0042 D loss:-0.6139 G loss:-2.254\n",
      "Epoch:  0042 D loss:-0.4245 G loss:-2.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0042 D loss:-0.5396 G loss:-2.643\n",
      "Epoch:  0042 D loss:-0.5712 G loss:-2.263\n",
      "Epoch:  0042 D loss:-0.7199 G loss:-2.193\n",
      "Epoch:  0042 D loss:-0.6303 G loss:-2.335\n",
      "Epoch:  0042 D loss:-0.5879 G loss:-2.552\n",
      "Epoch:  0042 D loss:-0.5683 G loss:-2.278\n",
      "Epoch:  0042 D loss:-0.6658 G loss:-2.393\n",
      "Epoch:  0042 D loss:-0.6631 G loss:-2.447\n",
      "Epoch:  0042 D loss:-0.5909 G loss:-2.591\n",
      "Epoch:  0042 D loss:-0.5205 G loss:-2.197\n",
      "Epoch:  0042 D loss:-0.4761 G loss:-2.182\n",
      "Epoch:  0042 D loss:-0.6201 G loss:-2.217\n",
      "Epoch:  0042 D loss:-0.4559 G loss:-2.305\n",
      "Epoch:  0042 D loss:-0.5251 G loss:-2.273\n",
      "Epoch:  0042 D loss:-0.6694 G loss:-1.996\n",
      "Epoch:  0042 D loss:-0.529 G loss:-2.121\n",
      "Epoch:  0042 D loss:-0.6136 G loss:-2.119\n",
      "Epoch:  0042 D loss:-0.6748 G loss:-2.407\n",
      "Epoch:  0042 D loss:-0.5562 G loss:-2.06\n",
      "Epoch:  0042 D loss:-0.5587 G loss:-2.487\n",
      "Epoch:  0042 D loss:-0.621 G loss:-2.218\n",
      "Epoch:  0042 D loss:-0.5984 G loss:-2.253\n",
      "Epoch:  0042 D loss:-0.5245 G loss:-2.324\n",
      "Epoch:  0042 D loss:-0.5958 G loss:-2.347\n",
      "Epoch:  0042 D loss:-0.5204 G loss:-2.359\n",
      "Epoch:  0042 D loss:-0.4923 G loss:-2.488\n",
      "Epoch:  0042 D loss:-0.6518 G loss:-2.444\n",
      "Epoch:  0042 D loss:-0.678 G loss:-2.267\n",
      "Epoch:  0042 D loss:-0.5889 G loss:-2.131\n",
      "Epoch:  0042 D loss:-0.7932 G loss:-2.128\n",
      "Epoch:  0042 D loss:-0.5738 G loss:-2.529\n",
      "Epoch:  0042 D loss:-0.6138 G loss:-2.128\n",
      "Epoch:  0042 D loss:-0.5791 G loss:-2.21\n",
      "Epoch:  0042 D loss:-0.5799 G loss:-2.152\n",
      "Epoch:  0042 D loss:-0.5311 G loss:-2.304\n",
      "Epoch:  0042 D loss:-0.5704 G loss:-2.25\n",
      "Epoch:  0042 D loss:-0.5129 G loss:-2.234\n",
      "Epoch:  0042 D loss:-0.5888 G loss:-2.097\n",
      "Epoch:  0042 D loss:-0.5701 G loss:-1.907\n",
      "Epoch:  0042 D loss:-0.5988 G loss:-2.29\n",
      "Epoch:  0042 D loss:-0.6702 G loss:-2.164\n",
      "Epoch:  0042 D loss:-0.6365 G loss:-2.155\n",
      "Epoch:  0042 D loss:-0.4717 G loss:-2.425\n",
      "Epoch:  0042 D loss:-0.6417 G loss:-2.631\n",
      "Epoch:  0042 D loss:-0.5039 G loss:-2.543\n",
      "Epoch:  0042 D loss:-0.6515 G loss:-2.356\n",
      "Epoch:  0042 D loss:-0.4478 G loss:-2.578\n",
      "Epoch:  0042 D loss:-0.6338 G loss:-2.584\n",
      "Epoch:  0042 D loss:-0.5072 G loss:-2.311\n",
      "Epoch:  0042 D loss:-0.4908 G loss:-2.327\n",
      "Epoch:  0042 D loss:-0.6125 G loss:-2.251\n",
      "Epoch:  0042 D loss:-0.5248 G loss:-2.257\n",
      "Epoch:  0042 D loss:-0.7 G loss:-1.964\n",
      "Epoch:  0042 D loss:-0.4789 G loss:-2.34\n",
      "Epoch:  0042 D loss:-0.4666 G loss:-2.419\n",
      "Epoch:  0042 D loss:-0.6486 G loss:-2.426\n",
      "Epoch:  0042 D loss:-0.6668 G loss:-2.284\n",
      "Epoch:  0042 D loss:-0.6838 G loss:-2.301\n",
      "Epoch:  0042 D loss:-0.6707 G loss:-2.312\n",
      "Epoch:  0042 D loss:-0.6071 G loss:-2.35\n",
      "Epoch:  0042 D loss:-0.46 G loss:-2.751\n",
      "Epoch:  0042 D loss:-0.5299 G loss:-2.449\n",
      "Epoch:  0042 D loss:-0.632 G loss:-2.376\n",
      "Epoch:  0042 D loss:-0.4971 G loss:-2.441\n",
      "Epoch:  0042 D loss:-0.408 G loss:-2.327\n",
      "Epoch:  0042 D loss:-0.4855 G loss:-2.298\n",
      "Epoch:  0042 D loss:-0.5555 G loss:-2.451\n",
      "Epoch:  0042 D loss:-0.5376 G loss:-2.476\n",
      "Epoch:  0042 D loss:-0.6105 G loss:-2.22\n",
      "Epoch:  0042 D loss:-0.6091 G loss:-2.473\n",
      "Epoch:  0042 D loss:-0.5329 G loss:-2.229\n",
      "Epoch:  0042 D loss:-0.4682 G loss:-2.39\n",
      "Epoch:  0042 D loss:-0.5237 G loss:-2.327\n",
      "Epoch:  0042 D loss:-0.5433 G loss:-2.4\n",
      "Epoch:  0042 D loss:-0.4371 G loss:-2.496\n",
      "Epoch:  0042 D loss:-0.5532 G loss:-2.481\n",
      "Epoch:  0042 D loss:-0.6442 G loss:-2.252\n",
      "Epoch:  0042 D loss:-0.4693 G loss:-2.558\n",
      "Epoch:  0042 D loss:-0.5561 G loss:-2.381\n",
      "Epoch:  0042 D loss:-0.4811 G loss:-2.28\n",
      "Epoch:  0042 D loss:-0.6172 G loss:-2.187\n",
      "Epoch:  0042 D loss:-0.5375 G loss:-2.316\n",
      "Epoch:  0042 D loss:-0.5833 G loss:-2.396\n",
      "Epoch:  0042 D loss:-0.5971 G loss:-2.278\n",
      "Epoch:  0042 D loss:-0.5823 G loss:-2.205\n",
      "Epoch:  0042 D loss:-0.4567 G loss:-2.401\n",
      "Epoch:  0042 D loss:-0.4245 G loss:-2.538\n",
      "Epoch:  0042 D loss:-0.6312 G loss:-2.152\n",
      "Epoch:  0042 D loss:-0.6908 G loss:-2.187\n",
      "Epoch:  0042 D loss:-0.5658 G loss:-2.301\n",
      "Epoch:  0042 D loss:-0.5304 G loss:-2.568\n",
      "Epoch:  0042 D loss:-0.5899 G loss:-2.4\n",
      "Epoch:  0042 D loss:-0.4498 G loss:-2.426\n",
      "Epoch:  0042 D loss:-0.5943 G loss:-2.576\n",
      "Epoch:  0042 D loss:-0.509 G loss:-2.386\n",
      "Epoch:  0042 D loss:-0.5844 G loss:-2.248\n",
      "Epoch:  0042 D loss:-0.5886 G loss:-2.245\n",
      "Epoch:  0042 D loss:-0.4516 G loss:-2.237\n",
      "Epoch:  0042 D loss:-0.6095 G loss:-2.366\n",
      "Epoch:  0042 D loss:-0.5772 G loss:-2.211\n",
      "Epoch:  0042 D loss:-0.4648 G loss:-2.459\n",
      "Epoch:  0042 D loss:-0.5653 G loss:-2.516\n",
      "Epoch:  0042 D loss:-0.5582 G loss:-2.533\n",
      "Epoch:  0042 D loss:-0.6318 G loss:-2.312\n",
      "Epoch:  0042 D loss:-0.5483 G loss:-2.281\n",
      "Epoch:  0042 D loss:-0.5678 G loss:-2.344\n",
      "Epoch:  0042 D loss:-0.4685 G loss:-2.474\n",
      "Epoch:  0042 D loss:-0.5355 G loss:-2.355\n",
      "Epoch:  0042 D loss:-0.478 G loss:-2.457\n",
      "Epoch:  0042 D loss:-0.4964 G loss:-2.41\n",
      "Epoch:  0042 D loss:-0.5724 G loss:-2.441\n",
      "Epoch:  0042 D loss:-0.65 G loss:-2.318\n",
      "Epoch:  0042 D loss:-0.5646 G loss:-2.383\n",
      "Epoch:  0042 D loss:-0.5216 G loss:-2.511\n",
      "Epoch:  0042 D loss:-0.6634 G loss:-2.347\n",
      "Epoch:  0042 D loss:-0.5119 G loss:-2.375\n",
      "Epoch:  0042 D loss:-0.5526 G loss:-2.296\n",
      "Epoch:  0042 D loss:-0.5417 G loss:-2.419\n",
      "Epoch:  0042 D loss:-0.5287 G loss:-2.407\n",
      "Epoch:  0042 D loss:-0.6162 G loss:-2.282\n",
      "Epoch:  0042 D loss:-0.4128 G loss:-2.355\n",
      "Epoch:  0042 D loss:-0.5666 G loss:-2.418\n",
      "Epoch:  0042 D loss:-0.5571 G loss:-2.232\n",
      "Epoch:  0042 D loss:-0.5863 G loss:-2.282\n",
      "Epoch:  0042 D loss:-0.4939 G loss:-2.238\n",
      "Epoch:  0042 D loss:-0.4519 G loss:-2.423\n",
      "Epoch:  0042 D loss:-0.5432 G loss:-2.362\n",
      "Epoch:  0042 D loss:-0.5602 G loss:-2.235\n",
      "Epoch:  0042 D loss:-0.4702 G loss:-2.588\n",
      "Epoch:  0042 D loss:-0.582 G loss:-2.435\n",
      "Epoch:  0042 D loss:-0.565 G loss:-2.672\n",
      "Epoch:  0042 D loss:-0.4691 G loss:-2.474\n",
      "Epoch:  0042 D loss:-0.5911 G loss:-2.289\n",
      "Epoch:  0042 D loss:-0.507 G loss:-2.42\n",
      "Epoch:  0042 D loss:-0.491 G loss:-2.499\n",
      "Epoch:  0042 D loss:-0.5563 G loss:-2.599\n",
      "Epoch:  0042 D loss:-0.4814 G loss:-2.551\n",
      "Epoch:  0042 D loss:-0.6544 G loss:-2.443\n",
      "Epoch:  0042 D loss:-0.6679 G loss:-2.626\n",
      "Epoch:  0042 D loss:-0.6166 G loss:-2.433\n",
      "Epoch:  0042 D loss:-0.5898 G loss:-2.665\n",
      "Epoch:  0042 D loss:-0.445 G loss:-2.31\n",
      "Epoch:  0042 D loss:-0.4557 G loss:-2.416\n",
      "Epoch:  0042 D loss:-0.4839 G loss:-2.28\n",
      "Epoch:  0042 D loss:-0.4801 G loss:-2.272\n",
      "Epoch:  0042 D loss:-0.5932 G loss:-2.385\n",
      "Epoch:  0042 D loss:-0.5509 G loss:-2.363\n",
      "Epoch:  0042 D loss:-0.4594 G loss:-2.53\n",
      "Epoch:  0042 D loss:-0.5867 G loss:-2.176\n",
      "Epoch:  0042 D loss:-0.4601 G loss:-2.553\n",
      "Epoch:  0042 D loss:-0.5837 G loss:-2.506\n",
      "Epoch:  0042 D loss:-0.5123 G loss:-2.513\n",
      "Epoch:  0042 D loss:-0.5383 G loss:-2.421\n",
      "Epoch:  0042 D loss:-0.6163 G loss:-2.465\n",
      "Epoch:  0042 D loss:-0.643 G loss:-2.52\n",
      "Epoch:  0042 D loss:-0.5262 G loss:-2.291\n",
      "Epoch:  0042 D loss:-0.464 G loss:-2.509\n",
      "Epoch:  0042 D loss:-0.6024 G loss:-2.183\n",
      "Epoch:  0042 D loss:-0.5729 G loss:-2.271\n",
      "Epoch:  0042 D loss:-0.6005 G loss:-2.118\n",
      "Epoch:  0042 D loss:-0.5722 G loss:-2.401\n",
      "Epoch:  0042 D loss:-0.6557 G loss:-2.158\n",
      "Epoch:  0042 D loss:-0.6281 G loss:-2.237\n",
      "Epoch:  0042 D loss:-0.5625 G loss:-2.324\n",
      "Epoch:  0042 D loss:-0.6812 G loss:-2.269\n",
      "Epoch:  0042 D loss:-0.5966 G loss:-2.354\n",
      "Epoch:  0042 D loss:-0.4738 G loss:-2.536\n",
      "Epoch:  0042 D loss:-0.6954 G loss:-2.283\n",
      "Epoch:  0042 D loss:-0.5639 G loss:-2.425\n",
      "Epoch:  0042 D loss:-0.645 G loss:-2.347\n",
      "Epoch:  0042 D loss:-0.6606 G loss:-2.219\n",
      "Epoch:  0042 D loss:-0.6084 G loss:-2.227\n",
      "Epoch:  0042 D loss:-0.5099 G loss:-2.226\n",
      "Epoch:  0042 D loss:-0.4283 G loss:-2.488\n",
      "Epoch:  0042 D loss:-0.749 G loss:-2.149\n",
      "Epoch:  0042 D loss:-0.5671 G loss:-2.35\n",
      "Epoch:  0042 D loss:-0.579 G loss:-2.316\n",
      "Epoch:  0042 D loss:-0.4724 G loss:-2.304\n",
      "Epoch:  0042 D loss:-0.6523 G loss:-2.321\n",
      "Epoch:  0042 D loss:-0.6251 G loss:-2.297\n",
      "Epoch:  0042 D loss:-0.6092 G loss:-2.396\n",
      "Epoch:  0043 D loss:-0.6003 G loss:-2.211\n",
      "Epoch:  0043 D loss:-0.5589 G loss:-2.212\n",
      "Epoch:  0043 D loss:-0.619 G loss:-2.521\n",
      "Epoch:  0043 D loss:-0.572 G loss:-2.57\n",
      "Epoch:  0043 D loss:-0.6002 G loss:-2.453\n",
      "Epoch:  0043 D loss:-0.701 G loss:-2.144\n",
      "Epoch:  0043 D loss:-0.6762 G loss:-2.42\n",
      "Epoch:  0043 D loss:-0.5171 G loss:-2.463\n",
      "Epoch:  0043 D loss:-0.482 G loss:-2.279\n",
      "Epoch:  0043 D loss:-0.6105 G loss:-2.351\n",
      "Epoch:  0043 D loss:-0.555 G loss:-2.308\n",
      "Epoch:  0043 D loss:-0.6888 G loss:-2.01\n",
      "Epoch:  0043 D loss:-0.6646 G loss:-2.317\n",
      "Epoch:  0043 D loss:-0.6553 G loss:-2.339\n",
      "Epoch:  0043 D loss:-0.555 G loss:-2.144\n",
      "Epoch:  0043 D loss:-0.682 G loss:-2.088\n",
      "Epoch:  0043 D loss:-0.7307 G loss:-2.03\n",
      "Epoch:  0043 D loss:-0.5591 G loss:-2.306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0043 D loss:-0.5759 G loss:-2.491\n",
      "Epoch:  0043 D loss:-0.6733 G loss:-2.516\n",
      "Epoch:  0043 D loss:-0.5888 G loss:-2.869\n",
      "Epoch:  0043 D loss:-0.5301 G loss:-2.595\n",
      "Epoch:  0043 D loss:-0.622 G loss:-2.636\n",
      "Epoch:  0043 D loss:-0.6049 G loss:-2.432\n",
      "Epoch:  0043 D loss:-0.5657 G loss:-2.633\n",
      "Epoch:  0043 D loss:-0.5195 G loss:-2.564\n",
      "Epoch:  0043 D loss:-0.6988 G loss:-2.266\n",
      "Epoch:  0043 D loss:-0.7481 G loss:-2.118\n",
      "Epoch:  0043 D loss:-0.8808 G loss:-2.003\n",
      "Epoch:  0043 D loss:-0.6127 G loss:-2.156\n",
      "Epoch:  0043 D loss:-0.5914 G loss:-1.935\n",
      "Epoch:  0043 D loss:-0.7022 G loss:-1.929\n",
      "Epoch:  0043 D loss:-0.7197 G loss:-1.873\n",
      "Epoch:  0043 D loss:-0.5299 G loss:-2.315\n",
      "Epoch:  0043 D loss:-0.6899 G loss:-2.123\n",
      "Epoch:  0043 D loss:-0.6358 G loss:-2.327\n",
      "Epoch:  0043 D loss:-0.6119 G loss:-2.265\n",
      "Epoch:  0043 D loss:-0.4614 G loss:-2.625\n",
      "Epoch:  0043 D loss:-0.6695 G loss:-2.493\n",
      "Epoch:  0043 D loss:-0.6852 G loss:-2.337\n",
      "Epoch:  0043 D loss:-0.5015 G loss:-2.48\n",
      "Epoch:  0043 D loss:-0.5677 G loss:-2.426\n",
      "Epoch:  0043 D loss:-0.5711 G loss:-2.483\n",
      "Epoch:  0043 D loss:-0.8044 G loss:-2.253\n",
      "Epoch:  0043 D loss:-0.6318 G loss:-2.553\n",
      "Epoch:  0043 D loss:-0.6081 G loss:-2.249\n",
      "Epoch:  0043 D loss:-0.5949 G loss:-2.306\n",
      "Epoch:  0043 D loss:-0.6469 G loss:-2.254\n",
      "Epoch:  0043 D loss:-0.5333 G loss:-2.369\n",
      "Epoch:  0043 D loss:-0.5954 G loss:-2.198\n",
      "Epoch:  0043 D loss:-0.6014 G loss:-2.235\n",
      "Epoch:  0043 D loss:-0.6306 G loss:-2.381\n",
      "Epoch:  0043 D loss:-0.5949 G loss:-2.203\n",
      "Epoch:  0043 D loss:-0.6475 G loss:-2.163\n",
      "Epoch:  0043 D loss:-0.6812 G loss:-2.2\n",
      "Epoch:  0043 D loss:-0.4318 G loss:-2.402\n",
      "Epoch:  0043 D loss:-0.511 G loss:-2.378\n",
      "Epoch:  0043 D loss:-0.8723 G loss:-2.013\n",
      "Epoch:  0043 D loss:-0.5962 G loss:-2.677\n",
      "Epoch:  0043 D loss:-0.6088 G loss:-2.481\n",
      "Epoch:  0043 D loss:-0.5172 G loss:-2.611\n",
      "Epoch:  0043 D loss:-0.4574 G loss:-2.704\n",
      "Epoch:  0043 D loss:-0.5755 G loss:-2.297\n",
      "Epoch:  0043 D loss:-0.4822 G loss:-2.589\n",
      "Epoch:  0043 D loss:-0.7708 G loss:-2.312\n",
      "Epoch:  0043 D loss:-0.541 G loss:-2.436\n",
      "Epoch:  0043 D loss:-0.5722 G loss:-2.254\n",
      "Epoch:  0043 D loss:-0.637 G loss:-2.02\n",
      "Epoch:  0043 D loss:-0.568 G loss:-2.211\n",
      "Epoch:  0043 D loss:-0.5882 G loss:-2.332\n",
      "Epoch:  0043 D loss:-0.6128 G loss:-2.16\n",
      "Epoch:  0043 D loss:-0.5084 G loss:-2.357\n",
      "Epoch:  0043 D loss:-0.7254 G loss:-2.258\n",
      "Epoch:  0043 D loss:-0.4916 G loss:-2.584\n",
      "Epoch:  0043 D loss:-0.49 G loss:-2.521\n",
      "Epoch:  0043 D loss:-0.5826 G loss:-2.37\n",
      "Epoch:  0043 D loss:-0.5061 G loss:-2.475\n",
      "Epoch:  0043 D loss:-0.5921 G loss:-2.455\n",
      "Epoch:  0043 D loss:-0.5649 G loss:-2.58\n",
      "Epoch:  0043 D loss:-0.5557 G loss:-2.332\n",
      "Epoch:  0043 D loss:-0.4765 G loss:-2.426\n",
      "Epoch:  0043 D loss:-0.6148 G loss:-2.36\n",
      "Epoch:  0043 D loss:-0.5828 G loss:-2.266\n",
      "Epoch:  0043 D loss:-0.476 G loss:-2.469\n",
      "Epoch:  0043 D loss:-0.5302 G loss:-2.232\n",
      "Epoch:  0043 D loss:-0.6318 G loss:-2.241\n",
      "Epoch:  0043 D loss:-0.5713 G loss:-2.547\n",
      "Epoch:  0043 D loss:-0.5823 G loss:-2.372\n",
      "Epoch:  0043 D loss:-0.5687 G loss:-2.271\n",
      "Epoch:  0043 D loss:-0.4678 G loss:-2.383\n",
      "Epoch:  0043 D loss:-0.6192 G loss:-2.49\n",
      "Epoch:  0043 D loss:-0.6081 G loss:-2.362\n",
      "Epoch:  0043 D loss:-0.6774 G loss:-2.344\n",
      "Epoch:  0043 D loss:-0.5427 G loss:-2.357\n",
      "Epoch:  0043 D loss:-0.5277 G loss:-2.385\n",
      "Epoch:  0043 D loss:-0.5093 G loss:-2.382\n",
      "Epoch:  0043 D loss:-0.5861 G loss:-2.262\n",
      "Epoch:  0043 D loss:-0.4931 G loss:-2.421\n",
      "Epoch:  0043 D loss:-0.4485 G loss:-2.43\n",
      "Epoch:  0043 D loss:-0.5473 G loss:-2.469\n",
      "Epoch:  0043 D loss:-0.6199 G loss:-2.4\n",
      "Epoch:  0043 D loss:-0.4498 G loss:-2.494\n",
      "Epoch:  0043 D loss:-0.587 G loss:-2.389\n",
      "Epoch:  0043 D loss:-0.6173 G loss:-2.282\n",
      "Epoch:  0043 D loss:-0.3922 G loss:-2.572\n",
      "Epoch:  0043 D loss:-0.5237 G loss:-2.292\n",
      "Epoch:  0043 D loss:-0.511 G loss:-2.333\n",
      "Epoch:  0043 D loss:-0.4759 G loss:-2.34\n",
      "Epoch:  0043 D loss:-0.4958 G loss:-2.219\n",
      "Epoch:  0043 D loss:-0.4822 G loss:-2.327\n",
      "Epoch:  0043 D loss:-0.6503 G loss:-2.42\n",
      "Epoch:  0043 D loss:-0.5156 G loss:-2.316\n",
      "Epoch:  0043 D loss:-0.6595 G loss:-2.262\n",
      "Epoch:  0043 D loss:-0.6165 G loss:-2.252\n",
      "Epoch:  0043 D loss:-0.5352 G loss:-2.317\n",
      "Epoch:  0043 D loss:-0.5067 G loss:-2.374\n",
      "Epoch:  0043 D loss:-0.4844 G loss:-2.201\n",
      "Epoch:  0043 D loss:-0.6368 G loss:-2.238\n",
      "Epoch:  0043 D loss:-0.5516 G loss:-2.28\n",
      "Epoch:  0043 D loss:-0.627 G loss:-2.289\n",
      "Epoch:  0043 D loss:-0.4952 G loss:-2.584\n",
      "Epoch:  0043 D loss:-0.5035 G loss:-2.325\n",
      "Epoch:  0043 D loss:-0.4996 G loss:-2.171\n",
      "Epoch:  0043 D loss:-0.5511 G loss:-2.428\n",
      "Epoch:  0043 D loss:-0.6112 G loss:-2.298\n",
      "Epoch:  0043 D loss:-0.569 G loss:-2.575\n",
      "Epoch:  0043 D loss:-0.4548 G loss:-2.542\n",
      "Epoch:  0043 D loss:-0.5034 G loss:-2.491\n",
      "Epoch:  0043 D loss:-0.5855 G loss:-2.484\n",
      "Epoch:  0043 D loss:-0.5244 G loss:-2.475\n",
      "Epoch:  0043 D loss:-0.4967 G loss:-2.53\n",
      "Epoch:  0043 D loss:-0.492 G loss:-2.745\n",
      "Epoch:  0043 D loss:-0.4328 G loss:-2.65\n",
      "Epoch:  0043 D loss:-0.5427 G loss:-2.439\n",
      "Epoch:  0043 D loss:-0.5874 G loss:-2.25\n",
      "Epoch:  0043 D loss:-0.6542 G loss:-2.169\n",
      "Epoch:  0043 D loss:-0.5256 G loss:-2.247\n",
      "Epoch:  0043 D loss:-0.5804 G loss:-2.24\n",
      "Epoch:  0043 D loss:-0.4872 G loss:-2.233\n",
      "Epoch:  0043 D loss:-0.5032 G loss:-2.206\n",
      "Epoch:  0043 D loss:-0.4847 G loss:-2.233\n",
      "Epoch:  0043 D loss:-0.4803 G loss:-2.274\n",
      "Epoch:  0043 D loss:-0.5192 G loss:-2.567\n",
      "Epoch:  0043 D loss:-0.463 G loss:-2.48\n",
      "Epoch:  0043 D loss:-0.5731 G loss:-2.664\n",
      "Epoch:  0043 D loss:-0.5763 G loss:-2.446\n",
      "Epoch:  0043 D loss:-0.5607 G loss:-2.414\n",
      "Epoch:  0043 D loss:-0.518 G loss:-2.619\n",
      "Epoch:  0043 D loss:-0.6626 G loss:-2.648\n",
      "Epoch:  0043 D loss:-0.5676 G loss:-2.5\n",
      "Epoch:  0043 D loss:-0.6485 G loss:-2.423\n",
      "Epoch:  0043 D loss:-0.57 G loss:-2.099\n",
      "Epoch:  0043 D loss:-0.448 G loss:-2.449\n",
      "Epoch:  0043 D loss:-0.6411 G loss:-2.266\n",
      "Epoch:  0043 D loss:-0.535 G loss:-2.216\n",
      "Epoch:  0043 D loss:-0.5707 G loss:-2.205\n",
      "Epoch:  0043 D loss:-0.5391 G loss:-2.222\n",
      "Epoch:  0043 D loss:-0.4639 G loss:-2.298\n",
      "Epoch:  0043 D loss:-0.5389 G loss:-2.251\n",
      "Epoch:  0043 D loss:-0.4038 G loss:-2.351\n",
      "Epoch:  0043 D loss:-0.5525 G loss:-1.935\n",
      "Epoch:  0043 D loss:-0.6334 G loss:-2.41\n",
      "Epoch:  0043 D loss:-0.55 G loss:-2.274\n",
      "Epoch:  0043 D loss:-0.5664 G loss:-2.368\n",
      "Epoch:  0043 D loss:-0.5645 G loss:-2.622\n",
      "Epoch:  0043 D loss:-0.7133 G loss:-2.295\n",
      "Epoch:  0043 D loss:-0.5306 G loss:-2.729\n",
      "Epoch:  0043 D loss:-0.6382 G loss:-2.226\n",
      "Epoch:  0043 D loss:-0.6014 G loss:-2.229\n",
      "Epoch:  0043 D loss:-0.5983 G loss:-2.198\n",
      "Epoch:  0043 D loss:-0.5168 G loss:-2.297\n",
      "Epoch:  0043 D loss:-0.4424 G loss:-2.171\n",
      "Epoch:  0043 D loss:-0.5063 G loss:-2.322\n",
      "Epoch:  0043 D loss:-0.5329 G loss:-2.439\n",
      "Epoch:  0043 D loss:-0.6366 G loss:-2.414\n",
      "Epoch:  0043 D loss:-0.661 G loss:-2.2\n",
      "Epoch:  0043 D loss:-0.6889 G loss:-2.003\n",
      "Epoch:  0043 D loss:-0.508 G loss:-2.55\n",
      "Epoch:  0043 D loss:-0.5759 G loss:-2.261\n",
      "Epoch:  0043 D loss:-0.6649 G loss:-2.082\n",
      "Epoch:  0043 D loss:-0.5458 G loss:-2.279\n",
      "Epoch:  0043 D loss:-0.6135 G loss:-2.107\n",
      "Epoch:  0043 D loss:-0.6697 G loss:-2.293\n",
      "Epoch:  0043 D loss:-0.5476 G loss:-2.354\n",
      "Epoch:  0043 D loss:-0.5339 G loss:-2.435\n",
      "Epoch:  0043 D loss:-0.6719 G loss:-2.297\n",
      "Epoch:  0043 D loss:-0.7615 G loss:-2.144\n",
      "Epoch:  0043 D loss:-0.5868 G loss:-2.396\n",
      "Epoch:  0043 D loss:-0.6675 G loss:-2.365\n",
      "Epoch:  0043 D loss:-0.5301 G loss:-2.368\n",
      "Epoch:  0043 D loss:-0.4988 G loss:-2.404\n",
      "Epoch:  0043 D loss:-0.6656 G loss:-2.13\n",
      "Epoch:  0043 D loss:-0.7207 G loss:-2.214\n",
      "Epoch:  0043 D loss:-0.554 G loss:-2.211\n",
      "Epoch:  0043 D loss:-0.6855 G loss:-2.419\n",
      "Epoch:  0043 D loss:-0.555 G loss:-2.372\n",
      "Epoch:  0043 D loss:-0.6293 G loss:-2.364\n",
      "Epoch:  0043 D loss:-0.6405 G loss:-2.213\n",
      "Epoch:  0043 D loss:-0.6593 G loss:-2.223\n",
      "Epoch:  0043 D loss:-0.5605 G loss:-1.97\n",
      "Epoch:  0043 D loss:-0.4575 G loss:-2.405\n",
      "Epoch:  0043 D loss:-0.6389 G loss:-2.047\n",
      "Epoch:  0043 D loss:-0.649 G loss:-2.102\n",
      "Epoch:  0043 D loss:-0.5463 G loss:-2.12\n",
      "Epoch:  0043 D loss:-0.4866 G loss:-2.46\n",
      "Epoch:  0043 D loss:-0.5639 G loss:-2.197\n",
      "Epoch:  0043 D loss:-0.6874 G loss:-2.362\n",
      "Epoch:  0043 D loss:-0.5299 G loss:-2.508\n",
      "Epoch:  0043 D loss:-0.6377 G loss:-2.239\n",
      "Epoch:  0043 D loss:-0.6727 G loss:-2.518\n",
      "Epoch:  0043 D loss:-0.5147 G loss:-2.53\n",
      "Epoch:  0043 D loss:-0.4748 G loss:-2.451\n",
      "Epoch:  0043 D loss:-0.6113 G loss:-2.483\n",
      "Epoch:  0043 D loss:-0.6466 G loss:-2.406\n",
      "Epoch:  0043 D loss:-0.5108 G loss:-2.488\n",
      "Epoch:  0043 D loss:-0.4647 G loss:-2.374\n",
      "Epoch:  0043 D loss:-0.6931 G loss:-2.432\n",
      "Epoch:  0043 D loss:-0.6918 G loss:-2.132\n",
      "Epoch:  0043 D loss:-0.6931 G loss:-2.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0043 D loss:-0.5555 G loss:-2.334\n",
      "Epoch:  0043 D loss:-0.4837 G loss:-2.099\n",
      "Epoch:  0043 D loss:-0.6209 G loss:-1.953\n",
      "Epoch:  0043 D loss:-0.5915 G loss:-2.04\n",
      "Epoch:  0043 D loss:-0.5786 G loss:-2.182\n",
      "Epoch:  0043 D loss:-0.5867 G loss:-1.97\n",
      "Epoch:  0043 D loss:-0.5946 G loss:-2.152\n",
      "Epoch:  0043 D loss:-0.5238 G loss:-2.455\n",
      "Epoch:  0043 D loss:-0.6637 G loss:-2.185\n",
      "Epoch:  0043 D loss:-0.6676 G loss:-2.402\n",
      "Epoch:  0043 D loss:-0.5423 G loss:-2.5\n",
      "Epoch:  0043 D loss:-0.6308 G loss:-2.412\n",
      "Epoch:  0043 D loss:-0.6712 G loss:-2.55\n",
      "Epoch:  0043 D loss:-0.5156 G loss:-2.539\n",
      "Epoch:  0043 D loss:-0.5021 G loss:-2.573\n",
      "Epoch:  0043 D loss:-0.543 G loss:-2.262\n",
      "Epoch:  0043 D loss:-0.5752 G loss:-2.46\n",
      "Epoch:  0043 D loss:-0.4714 G loss:-2.165\n",
      "Epoch:  0043 D loss:-0.7163 G loss:-2.243\n",
      "Epoch:  0043 D loss:-0.6422 G loss:-2.256\n",
      "Epoch:  0043 D loss:-0.504 G loss:-2.064\n",
      "Epoch:  0043 D loss:-0.5144 G loss:-2.232\n",
      "Epoch:  0043 D loss:-0.529 G loss:-2.335\n",
      "Epoch:  0043 D loss:-0.5157 G loss:-2.198\n",
      "Epoch:  0043 D loss:-0.4133 G loss:-2.294\n",
      "Epoch:  0043 D loss:-0.6479 G loss:-1.988\n",
      "Epoch:  0043 D loss:-0.4382 G loss:-2.516\n",
      "Epoch:  0043 D loss:-0.6021 G loss:-2.408\n",
      "Epoch:  0043 D loss:-0.6181 G loss:-2.56\n",
      "Epoch:  0043 D loss:-0.5785 G loss:-2.457\n",
      "Epoch:  0043 D loss:-0.5858 G loss:-2.473\n",
      "Epoch:  0043 D loss:-0.5563 G loss:-2.356\n",
      "Epoch:  0043 D loss:-0.4328 G loss:-2.121\n",
      "Epoch:  0043 D loss:-0.5192 G loss:-2.517\n",
      "Epoch:  0043 D loss:-0.5694 G loss:-2.248\n",
      "Epoch:  0043 D loss:-0.5734 G loss:-2.356\n",
      "Epoch:  0043 D loss:-0.5857 G loss:-2.438\n",
      "Epoch:  0043 D loss:-0.5523 G loss:-2.18\n",
      "Epoch:  0043 D loss:-0.5644 G loss:-2.295\n",
      "Epoch:  0043 D loss:-0.4666 G loss:-2.389\n",
      "Epoch:  0043 D loss:-0.6482 G loss:-2.166\n",
      "Epoch:  0043 D loss:-0.555 G loss:-2.194\n",
      "Epoch:  0043 D loss:-0.5701 G loss:-2.456\n",
      "Epoch:  0043 D loss:-0.5128 G loss:-2.573\n",
      "Epoch:  0043 D loss:-0.6985 G loss:-2.646\n",
      "Epoch:  0043 D loss:-0.6913 G loss:-2.504\n",
      "Epoch:  0043 D loss:-0.7287 G loss:-2.364\n",
      "Epoch:  0043 D loss:-0.488 G loss:-2.193\n",
      "Epoch:  0043 D loss:-0.5525 G loss:-2.24\n",
      "Epoch:  0043 D loss:-0.5481 G loss:-2.103\n",
      "Epoch:  0043 D loss:-0.5354 G loss:-1.989\n",
      "Epoch:  0043 D loss:-0.5619 G loss:-2.06\n",
      "Epoch:  0043 D loss:-0.5276 G loss:-2.285\n",
      "Epoch:  0043 D loss:-0.5653 G loss:-2.211\n",
      "Epoch:  0043 D loss:-0.6105 G loss:-2.281\n",
      "Epoch:  0043 D loss:-0.5976 G loss:-2.097\n",
      "Epoch:  0043 D loss:-0.5892 G loss:-2.271\n",
      "Epoch:  0043 D loss:-0.6417 G loss:-2.291\n",
      "Epoch:  0043 D loss:-0.5881 G loss:-2.296\n",
      "Epoch:  0043 D loss:-0.548 G loss:-2.525\n",
      "Epoch:  0043 D loss:-0.5146 G loss:-2.442\n",
      "Epoch:  0043 D loss:-0.6552 G loss:-2.474\n",
      "Epoch:  0043 D loss:-0.6527 G loss:-2.431\n",
      "Epoch:  0043 D loss:-0.5648 G loss:-2.493\n",
      "Epoch:  0043 D loss:-0.6102 G loss:-2.322\n",
      "Epoch:  0043 D loss:-0.468 G loss:-2.405\n",
      "Epoch:  0043 D loss:-0.5097 G loss:-2.455\n",
      "Epoch:  0043 D loss:-0.644 G loss:-2.156\n",
      "Epoch:  0043 D loss:-0.5704 G loss:-2.236\n",
      "Epoch:  0043 D loss:-0.5588 G loss:-2.48\n",
      "Epoch:  0043 D loss:-0.4187 G loss:-2.358\n",
      "Epoch:  0043 D loss:-0.6714 G loss:-2.307\n",
      "Epoch:  0043 D loss:-0.5843 G loss:-2.295\n",
      "Epoch:  0043 D loss:-0.7377 G loss:-2.332\n",
      "Epoch:  0043 D loss:-0.6728 G loss:-2.516\n",
      "Epoch:  0043 D loss:-0.6476 G loss:-2.287\n",
      "Epoch:  0043 D loss:-0.4488 G loss:-2.462\n",
      "Epoch:  0043 D loss:-0.5621 G loss:-2.57\n",
      "Epoch:  0043 D loss:-0.6454 G loss:-2.362\n",
      "Epoch:  0043 D loss:-0.6557 G loss:-2.277\n",
      "Epoch:  0043 D loss:-0.5883 G loss:-2.173\n",
      "Epoch:  0043 D loss:-0.5483 G loss:-2.37\n",
      "Epoch:  0043 D loss:-0.5037 G loss:-2.528\n",
      "Epoch:  0043 D loss:-0.4727 G loss:-2.394\n",
      "Epoch:  0043 D loss:-0.4882 G loss:-2.295\n",
      "Epoch:  0043 D loss:-0.6678 G loss:-2.174\n",
      "Epoch:  0043 D loss:-0.6389 G loss:-2.485\n",
      "Epoch:  0043 D loss:-0.6036 G loss:-2.439\n",
      "Epoch:  0043 D loss:-0.4823 G loss:-2.585\n",
      "Epoch:  0043 D loss:-0.5619 G loss:-2.811\n",
      "Epoch:  0043 D loss:-0.4537 G loss:-2.399\n",
      "Epoch:  0043 D loss:-0.488 G loss:-2.406\n",
      "Epoch:  0043 D loss:-0.5158 G loss:-2.483\n",
      "Epoch:  0043 D loss:-0.4939 G loss:-2.687\n",
      "Epoch:  0043 D loss:-0.6018 G loss:-2.306\n",
      "Epoch:  0043 D loss:-0.4434 G loss:-2.527\n",
      "Epoch:  0043 D loss:-0.5625 G loss:-2.49\n",
      "Epoch:  0043 D loss:-0.4338 G loss:-2.536\n",
      "Epoch:  0043 D loss:-0.5545 G loss:-2.683\n",
      "Epoch:  0043 D loss:-0.5145 G loss:-2.388\n",
      "Epoch:  0043 D loss:-0.6537 G loss:-2.316\n",
      "Epoch:  0043 D loss:-0.4672 G loss:-2.377\n",
      "Epoch:  0043 D loss:-0.546 G loss:-2.57\n",
      "Epoch:  0043 D loss:-0.495 G loss:-2.462\n",
      "Epoch:  0043 D loss:-0.5757 G loss:-2.237\n",
      "Epoch:  0043 D loss:-0.5768 G loss:-2.246\n",
      "Epoch:  0043 D loss:-0.5343 G loss:-2.334\n",
      "Epoch:  0043 D loss:-0.5344 G loss:-2.194\n",
      "Epoch:  0043 D loss:-0.4711 G loss:-2.649\n",
      "Epoch:  0043 D loss:-0.5587 G loss:-2.586\n",
      "Epoch:  0043 D loss:-0.4962 G loss:-2.607\n",
      "Epoch:  0043 D loss:-0.5642 G loss:-2.429\n",
      "Epoch:  0043 D loss:-0.6208 G loss:-2.43\n",
      "Epoch:  0043 D loss:-0.4887 G loss:-2.24\n",
      "Epoch:  0043 D loss:-0.5153 G loss:-2.433\n",
      "Epoch:  0043 D loss:-0.485 G loss:-2.327\n",
      "Epoch:  0043 D loss:-0.5183 G loss:-2.453\n",
      "Epoch:  0043 D loss:-0.6356 G loss:-2.301\n",
      "Epoch:  0043 D loss:-0.5829 G loss:-2.379\n",
      "Epoch:  0043 D loss:-0.5623 G loss:-2.278\n",
      "Epoch:  0043 D loss:-0.5448 G loss:-2.524\n",
      "Epoch:  0043 D loss:-0.6512 G loss:-2.152\n",
      "Epoch:  0043 D loss:-0.5571 G loss:-2.262\n",
      "Epoch:  0043 D loss:-0.5923 G loss:-2.165\n",
      "Epoch:  0043 D loss:-0.6598 G loss:-2.236\n",
      "Epoch:  0043 D loss:-0.4041 G loss:-2.312\n",
      "Epoch:  0043 D loss:-0.5256 G loss:-2.166\n",
      "Epoch:  0043 D loss:-0.445 G loss:-2.46\n",
      "Epoch:  0043 D loss:-0.6082 G loss:-2.291\n",
      "Epoch:  0043 D loss:-0.4128 G loss:-2.725\n",
      "Epoch:  0043 D loss:-0.6018 G loss:-2.323\n",
      "Epoch:  0043 D loss:-0.5204 G loss:-2.683\n",
      "Epoch:  0043 D loss:-0.5476 G loss:-2.368\n",
      "Epoch:  0043 D loss:-0.6039 G loss:-2.521\n",
      "Epoch:  0043 D loss:-0.6427 G loss:-2.269\n",
      "Epoch:  0043 D loss:-0.5779 G loss:-2.459\n",
      "Epoch:  0043 D loss:-0.5643 G loss:-2.256\n",
      "Epoch:  0043 D loss:-0.469 G loss:-2.342\n",
      "Epoch:  0043 D loss:-0.5851 G loss:-2.041\n",
      "Epoch:  0043 D loss:-0.5568 G loss:-2.133\n",
      "Epoch:  0043 D loss:-0.5036 G loss:-2.309\n",
      "Epoch:  0043 D loss:-0.5437 G loss:-2.253\n",
      "Epoch:  0043 D loss:-0.4549 G loss:-2.183\n",
      "Epoch:  0043 D loss:-0.5376 G loss:-2.306\n",
      "Epoch:  0043 D loss:-0.5549 G loss:-2.187\n",
      "Epoch:  0043 D loss:-0.5322 G loss:-2.344\n",
      "Epoch:  0043 D loss:-0.5158 G loss:-2.454\n",
      "Epoch:  0043 D loss:-0.5289 G loss:-2.576\n",
      "Epoch:  0043 D loss:-0.5771 G loss:-2.686\n",
      "Epoch:  0043 D loss:-0.5635 G loss:-2.477\n",
      "Epoch:  0043 D loss:-0.5909 G loss:-2.618\n",
      "Epoch:  0043 D loss:-0.471 G loss:-2.619\n",
      "Epoch:  0043 D loss:-0.5079 G loss:-2.592\n",
      "Epoch:  0043 D loss:-0.5351 G loss:-2.45\n",
      "Epoch:  0043 D loss:-0.4737 G loss:-2.375\n",
      "Epoch:  0043 D loss:-0.474 G loss:-2.155\n",
      "Epoch:  0043 D loss:-0.5514 G loss:-2.183\n",
      "Epoch:  0043 D loss:-0.5584 G loss:-2.064\n",
      "Epoch:  0043 D loss:-0.4937 G loss:-2.258\n",
      "Epoch:  0043 D loss:-0.4741 G loss:-2.314\n",
      "Epoch:  0043 D loss:-0.5999 G loss:-2.104\n",
      "Epoch:  0043 D loss:-0.4582 G loss:-2.396\n",
      "Epoch:  0043 D loss:-0.4649 G loss:-2.415\n",
      "Epoch:  0043 D loss:-0.5592 G loss:-2.332\n",
      "Epoch:  0043 D loss:-0.5994 G loss:-2.295\n",
      "Epoch:  0043 D loss:-0.4713 G loss:-2.417\n",
      "Epoch:  0043 D loss:-0.4799 G loss:-2.486\n",
      "Epoch:  0043 D loss:-0.4931 G loss:-2.383\n",
      "Epoch:  0043 D loss:-0.4966 G loss:-2.478\n",
      "Epoch:  0043 D loss:-0.5538 G loss:-2.38\n",
      "Epoch:  0043 D loss:-0.5347 G loss:-2.652\n",
      "Epoch:  0043 D loss:-0.5515 G loss:-2.305\n",
      "Epoch:  0043 D loss:-0.5019 G loss:-2.465\n",
      "Epoch:  0043 D loss:-0.5752 G loss:-2.29\n",
      "Epoch:  0043 D loss:-0.6048 G loss:-2.209\n",
      "Epoch:  0043 D loss:-0.6026 G loss:-2.138\n",
      "Epoch:  0043 D loss:-0.5257 G loss:-2.225\n",
      "Epoch:  0043 D loss:-0.6588 G loss:-2.093\n",
      "Epoch:  0043 D loss:-0.6852 G loss:-2.125\n",
      "Epoch:  0043 D loss:-0.4827 G loss:-2.246\n",
      "Epoch:  0043 D loss:-0.7361 G loss:-1.993\n",
      "Epoch:  0043 D loss:-0.6279 G loss:-2.161\n",
      "Epoch:  0043 D loss:-0.6732 G loss:-2.178\n",
      "Epoch:  0043 D loss:-0.5284 G loss:-2.363\n",
      "Epoch:  0043 D loss:-0.6068 G loss:-2.191\n",
      "Epoch:  0043 D loss:-0.5071 G loss:-2.341\n",
      "Epoch:  0043 D loss:-0.565 G loss:-2.38\n",
      "Epoch:  0043 D loss:-0.4697 G loss:-2.328\n",
      "Epoch:  0043 D loss:-0.4874 G loss:-2.502\n",
      "Epoch:  0043 D loss:-0.526 G loss:-2.479\n",
      "Epoch:  0043 D loss:-0.4831 G loss:-2.536\n",
      "Epoch:  0043 D loss:-0.6455 G loss:-2.603\n",
      "Epoch:  0043 D loss:-0.5902 G loss:-2.583\n",
      "Epoch:  0043 D loss:-0.6008 G loss:-2.481\n",
      "Epoch:  0043 D loss:-0.4869 G loss:-2.564\n",
      "Epoch:  0043 D loss:-0.5082 G loss:-2.303\n",
      "Epoch:  0043 D loss:-0.4328 G loss:-2.442\n",
      "Epoch:  0043 D loss:-0.4454 G loss:-2.324\n",
      "Epoch:  0043 D loss:-0.7076 G loss:-2.028\n",
      "Epoch:  0043 D loss:-0.5641 G loss:-2.176\n",
      "Epoch:  0043 D loss:-0.5413 G loss:-2.341\n",
      "Epoch:  0043 D loss:-0.6194 G loss:-2.206\n",
      "Epoch:  0043 D loss:-0.5728 G loss:-2.097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0043 D loss:-0.464 G loss:-2.329\n",
      "Epoch:  0043 D loss:-0.5559 G loss:-2.296\n",
      "Epoch:  0043 D loss:-0.5378 G loss:-2.39\n",
      "Epoch:  0043 D loss:-0.5032 G loss:-2.474\n",
      "Epoch:  0043 D loss:-0.3395 G loss:-2.603\n",
      "Epoch:  0043 D loss:-0.6304 G loss:-2.561\n",
      "Epoch:  0043 D loss:-0.6678 G loss:-2.366\n",
      "Epoch:  0043 D loss:-0.7245 G loss:-2.372\n",
      "Epoch:  0043 D loss:-0.4999 G loss:-2.299\n",
      "Epoch:  0043 D loss:-0.604 G loss:-2.23\n",
      "Epoch:  0043 D loss:-0.5545 G loss:-2.265\n",
      "Epoch:  0043 D loss:-0.6091 G loss:-2.575\n",
      "Epoch:  0043 D loss:-0.5841 G loss:-2.46\n",
      "Epoch:  0043 D loss:-0.3787 G loss:-2.329\n",
      "Epoch:  0043 D loss:-0.5968 G loss:-2.272\n",
      "Epoch:  0043 D loss:-0.5527 G loss:-2.235\n",
      "Epoch:  0043 D loss:-0.6316 G loss:-2.095\n",
      "Epoch:  0043 D loss:-0.4621 G loss:-2.444\n",
      "Epoch:  0043 D loss:-0.5486 G loss:-2.544\n",
      "Epoch:  0043 D loss:-0.6175 G loss:-2.489\n",
      "Epoch:  0043 D loss:-0.4516 G loss:-2.616\n",
      "Epoch:  0043 D loss:-0.4945 G loss:-2.33\n",
      "Epoch:  0043 D loss:-0.599 G loss:-2.3\n",
      "Epoch:  0043 D loss:-0.5193 G loss:-2.567\n",
      "Epoch:  0043 D loss:-0.5601 G loss:-2.4\n",
      "Epoch:  0043 D loss:-0.5658 G loss:-2.204\n",
      "Epoch:  0043 D loss:-0.7563 G loss:-2.117\n",
      "Epoch:  0043 D loss:-0.4451 G loss:-2.447\n",
      "Epoch:  0043 D loss:-0.5888 G loss:-2.078\n",
      "Epoch:  0043 D loss:-0.5214 G loss:-2.435\n",
      "Epoch:  0043 D loss:-0.5699 G loss:-2.39\n",
      "Epoch:  0043 D loss:-0.4854 G loss:-2.373\n",
      "Epoch:  0043 D loss:-0.434 G loss:-2.25\n",
      "Epoch:  0043 D loss:-0.5463 G loss:-2.241\n",
      "Epoch:  0043 D loss:-0.4766 G loss:-2.514\n",
      "Epoch:  0043 D loss:-0.6059 G loss:-2.401\n",
      "Epoch:  0043 D loss:-0.5179 G loss:-2.509\n",
      "Epoch:  0043 D loss:-0.4541 G loss:-2.709\n",
      "Epoch:  0043 D loss:-0.5633 G loss:-2.529\n",
      "Epoch:  0043 D loss:-0.5491 G loss:-2.759\n",
      "Epoch:  0043 D loss:-0.5122 G loss:-2.735\n",
      "Epoch:  0043 D loss:-0.5499 G loss:-2.293\n",
      "Epoch:  0043 D loss:-0.5668 G loss:-2.412\n",
      "Epoch:  0043 D loss:-0.7071 G loss:-2.401\n",
      "Epoch:  0043 D loss:-0.4506 G loss:-2.481\n",
      "Epoch:  0043 D loss:-0.6381 G loss:-2.34\n",
      "Epoch:  0043 D loss:-0.5586 G loss:-2.33\n",
      "Epoch:  0043 D loss:-0.6145 G loss:-2.397\n",
      "Epoch:  0043 D loss:-0.5525 G loss:-2.483\n",
      "Epoch:  0043 D loss:-0.4483 G loss:-2.573\n",
      "Epoch:  0043 D loss:-0.5364 G loss:-2.524\n",
      "Epoch:  0043 D loss:-0.6124 G loss:-2.48\n",
      "Epoch:  0043 D loss:-0.5414 G loss:-2.527\n",
      "Epoch:  0043 D loss:-0.4539 G loss:-2.447\n",
      "Epoch:  0043 D loss:-0.5802 G loss:-2.514\n",
      "Epoch:  0043 D loss:-0.3865 G loss:-2.566\n",
      "Epoch:  0043 D loss:-0.5514 G loss:-2.207\n",
      "Epoch:  0043 D loss:-0.4853 G loss:-2.529\n",
      "Epoch:  0043 D loss:-0.5409 G loss:-2.183\n",
      "Epoch:  0043 D loss:-0.5656 G loss:-2.291\n",
      "Epoch:  0043 D loss:-0.5519 G loss:-2.383\n",
      "Epoch:  0043 D loss:-0.5508 G loss:-2.562\n",
      "Epoch:  0043 D loss:-0.6023 G loss:-2.554\n",
      "Epoch:  0043 D loss:-0.4118 G loss:-2.632\n",
      "Epoch:  0043 D loss:-0.657 G loss:-2.626\n",
      "Epoch:  0043 D loss:-0.5701 G loss:-2.327\n",
      "Epoch:  0043 D loss:-0.4905 G loss:-2.481\n",
      "Epoch:  0043 D loss:-0.5844 G loss:-2.376\n",
      "Epoch:  0043 D loss:-0.4576 G loss:-2.582\n",
      "Epoch:  0043 D loss:-0.5656 G loss:-2.471\n",
      "Epoch:  0043 D loss:-0.4416 G loss:-2.407\n",
      "Epoch:  0043 D loss:-0.4011 G loss:-2.399\n",
      "Epoch:  0043 D loss:-0.512 G loss:-2.246\n",
      "Epoch:  0043 D loss:-0.591 G loss:-2.327\n",
      "Epoch:  0043 D loss:-0.486 G loss:-2.477\n",
      "Epoch:  0043 D loss:-0.5856 G loss:-2.303\n",
      "Epoch:  0043 D loss:-0.5924 G loss:-2.478\n",
      "Epoch:  0043 D loss:-0.5475 G loss:-2.608\n",
      "Epoch:  0043 D loss:-0.5719 G loss:-2.451\n",
      "Epoch:  0043 D loss:-0.5812 G loss:-2.825\n",
      "Epoch:  0043 D loss:-0.6808 G loss:-2.426\n",
      "Epoch:  0043 D loss:-0.4972 G loss:-2.491\n",
      "Epoch:  0043 D loss:-0.6724 G loss:-2.044\n",
      "Epoch:  0043 D loss:-0.5756 G loss:-2.251\n",
      "Epoch:  0043 D loss:-0.4887 G loss:-2.184\n",
      "Epoch:  0043 D loss:-0.5652 G loss:-2.481\n",
      "Epoch:  0043 D loss:-0.5973 G loss:-2.387\n",
      "Epoch:  0043 D loss:-0.4167 G loss:-2.447\n",
      "Epoch:  0043 D loss:-0.6749 G loss:-2.495\n",
      "Epoch:  0043 D loss:-0.5802 G loss:-2.462\n",
      "Epoch:  0043 D loss:-0.5589 G loss:-2.461\n",
      "Epoch:  0043 D loss:-0.4834 G loss:-2.514\n",
      "Epoch:  0043 D loss:-0.5326 G loss:-2.288\n",
      "Epoch:  0043 D loss:-0.7088 G loss:-1.913\n",
      "Epoch:  0043 D loss:-0.5293 G loss:-2.226\n",
      "Epoch:  0043 D loss:-0.459 G loss:-2.358\n",
      "Epoch:  0043 D loss:-0.5669 G loss:-2.21\n",
      "Epoch:  0043 D loss:-0.5147 G loss:-2.331\n",
      "Epoch:  0043 D loss:-0.6284 G loss:-2.108\n",
      "Epoch:  0043 D loss:-0.5971 G loss:-2.389\n",
      "Epoch:  0043 D loss:-0.6665 G loss:-2.312\n",
      "Epoch:  0043 D loss:-0.6083 G loss:-2.226\n",
      "Epoch:  0043 D loss:-0.6164 G loss:-2.197\n",
      "Epoch:  0043 D loss:-0.5719 G loss:-2.38\n",
      "Epoch:  0043 D loss:-0.6281 G loss:-2.289\n",
      "Epoch:  0043 D loss:-0.5934 G loss:-2.368\n",
      "Epoch:  0043 D loss:-0.6155 G loss:-2.319\n",
      "Epoch:  0043 D loss:-0.6165 G loss:-2.376\n",
      "Epoch:  0043 D loss:-0.6838 G loss:-2.429\n",
      "Epoch:  0043 D loss:-0.672 G loss:-2.392\n",
      "Epoch:  0043 D loss:-0.5744 G loss:-2.246\n",
      "Epoch:  0043 D loss:-0.5481 G loss:-2.345\n",
      "Epoch:  0043 D loss:-0.6669 G loss:-2.349\n",
      "Epoch:  0043 D loss:-0.6798 G loss:-1.996\n",
      "Epoch:  0043 D loss:-0.6381 G loss:-2.199\n",
      "Epoch:  0043 D loss:-0.5843 G loss:-2.18\n",
      "Epoch:  0043 D loss:-0.552 G loss:-2.257\n",
      "Epoch:  0043 D loss:-0.6103 G loss:-2.286\n",
      "Epoch:  0043 D loss:-0.6454 G loss:-2.259\n",
      "Epoch:  0043 D loss:-0.5481 G loss:-2.193\n",
      "Epoch:  0043 D loss:-0.4595 G loss:-2.203\n",
      "Epoch:  0043 D loss:-0.5408 G loss:-2.334\n",
      "Epoch:  0043 D loss:-0.5721 G loss:-2.473\n",
      "Epoch:  0043 D loss:-0.5293 G loss:-2.413\n",
      "Epoch:  0043 D loss:-0.5748 G loss:-2.511\n",
      "Epoch:  0043 D loss:-0.6078 G loss:-2.421\n",
      "Epoch:  0043 D loss:-0.5379 G loss:-2.473\n",
      "Epoch:  0043 D loss:-0.5068 G loss:-2.227\n",
      "Epoch:  0044 D loss:-0.6815 G loss:-2.288\n",
      "Epoch:  0044 D loss:-0.5665 G loss:-2.501\n",
      "Epoch:  0044 D loss:-0.5203 G loss:-2.315\n",
      "Epoch:  0044 D loss:-0.5322 G loss:-2.394\n",
      "Epoch:  0044 D loss:-0.4945 G loss:-2.255\n",
      "Epoch:  0044 D loss:-0.6543 G loss:-2.147\n",
      "Epoch:  0044 D loss:-0.4309 G loss:-2.216\n",
      "Epoch:  0044 D loss:-0.6081 G loss:-2.326\n",
      "Epoch:  0044 D loss:-0.6437 G loss:-2.435\n",
      "Epoch:  0044 D loss:-0.6098 G loss:-2.407\n",
      "Epoch:  0044 D loss:-0.6178 G loss:-2.297\n",
      "Epoch:  0044 D loss:-0.6484 G loss:-2.222\n",
      "Epoch:  0044 D loss:-0.5067 G loss:-2.284\n",
      "Epoch:  0044 D loss:-0.5408 G loss:-2.21\n",
      "Epoch:  0044 D loss:-0.5531 G loss:-2.357\n",
      "Epoch:  0044 D loss:-0.6149 G loss:-2.297\n",
      "Epoch:  0044 D loss:-0.4509 G loss:-2.552\n",
      "Epoch:  0044 D loss:-0.4638 G loss:-2.472\n",
      "Epoch:  0044 D loss:-0.583 G loss:-2.385\n",
      "Epoch:  0044 D loss:-0.5673 G loss:-2.378\n",
      "Epoch:  0044 D loss:-0.5312 G loss:-2.432\n",
      "Epoch:  0044 D loss:-0.5357 G loss:-2.564\n",
      "Epoch:  0044 D loss:-0.5376 G loss:-2.377\n",
      "Epoch:  0044 D loss:-0.5158 G loss:-2.552\n",
      "Epoch:  0044 D loss:-0.6274 G loss:-2.27\n",
      "Epoch:  0044 D loss:-0.5135 G loss:-2.279\n",
      "Epoch:  0044 D loss:-0.5466 G loss:-2.122\n",
      "Epoch:  0044 D loss:-0.5115 G loss:-2.302\n",
      "Epoch:  0044 D loss:-0.5956 G loss:-2.278\n",
      "Epoch:  0044 D loss:-0.6984 G loss:-2.13\n",
      "Epoch:  0044 D loss:-0.6919 G loss:-2.193\n",
      "Epoch:  0044 D loss:-0.5816 G loss:-2.196\n",
      "Epoch:  0044 D loss:-0.4947 G loss:-2.396\n",
      "Epoch:  0044 D loss:-0.5772 G loss:-2.357\n",
      "Epoch:  0044 D loss:-0.5419 G loss:-2.499\n",
      "Epoch:  0044 D loss:-0.4445 G loss:-2.465\n",
      "Epoch:  0044 D loss:-0.622 G loss:-2.603\n",
      "Epoch:  0044 D loss:-0.5583 G loss:-2.589\n",
      "Epoch:  0044 D loss:-0.454 G loss:-2.45\n",
      "Epoch:  0044 D loss:-0.3742 G loss:-2.669\n",
      "Epoch:  0044 D loss:-0.5596 G loss:-2.39\n",
      "Epoch:  0044 D loss:-0.5716 G loss:-2.242\n",
      "Epoch:  0044 D loss:-0.5611 G loss:-2.206\n",
      "Epoch:  0044 D loss:-0.5938 G loss:-2.226\n",
      "Epoch:  0044 D loss:-0.6361 G loss:-2.364\n",
      "Epoch:  0044 D loss:-0.5638 G loss:-2.174\n",
      "Epoch:  0044 D loss:-0.6103 G loss:-2.103\n",
      "Epoch:  0044 D loss:-0.5028 G loss:-2.158\n",
      "Epoch:  0044 D loss:-0.4994 G loss:-2.29\n",
      "Epoch:  0044 D loss:-0.4816 G loss:-2.287\n",
      "Epoch:  0044 D loss:-0.4863 G loss:-2.524\n",
      "Epoch:  0044 D loss:-0.4923 G loss:-2.338\n",
      "Epoch:  0044 D loss:-0.5088 G loss:-2.508\n",
      "Epoch:  0044 D loss:-0.5705 G loss:-2.328\n",
      "Epoch:  0044 D loss:-0.6453 G loss:-2.428\n",
      "Epoch:  0044 D loss:-0.5253 G loss:-2.681\n",
      "Epoch:  0044 D loss:-0.577 G loss:-2.663\n",
      "Epoch:  0044 D loss:-0.5182 G loss:-2.721\n",
      "Epoch:  0044 D loss:-0.6211 G loss:-2.36\n",
      "Epoch:  0044 D loss:-0.5161 G loss:-2.258\n",
      "Epoch:  0044 D loss:-0.5028 G loss:-2.241\n",
      "Epoch:  0044 D loss:-0.5179 G loss:-2.264\n",
      "Epoch:  0044 D loss:-0.624 G loss:-2.329\n",
      "Epoch:  0044 D loss:-0.4773 G loss:-2.33\n",
      "Epoch:  0044 D loss:-0.5473 G loss:-2.352\n",
      "Epoch:  0044 D loss:-0.5651 G loss:-2.276\n",
      "Epoch:  0044 D loss:-0.4969 G loss:-2.298\n",
      "Epoch:  0044 D loss:-0.4837 G loss:-2.208\n",
      "Epoch:  0044 D loss:-0.4659 G loss:-2.618\n",
      "Epoch:  0044 D loss:-0.6659 G loss:-2.174\n",
      "Epoch:  0044 D loss:-0.5156 G loss:-2.301\n",
      "Epoch:  0044 D loss:-0.6323 G loss:-2.43\n",
      "Epoch:  0044 D loss:-0.5476 G loss:-2.374\n",
      "Epoch:  0044 D loss:-0.7013 G loss:-2.283\n",
      "Epoch:  0044 D loss:-0.4696 G loss:-2.4\n",
      "Epoch:  0044 D loss:-0.6024 G loss:-2.2\n",
      "Epoch:  0044 D loss:-0.594 G loss:-2.424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0044 D loss:-0.4736 G loss:-2.352\n",
      "Epoch:  0044 D loss:-0.534 G loss:-2.333\n",
      "Epoch:  0044 D loss:-0.4548 G loss:-2.504\n",
      "Epoch:  0044 D loss:-0.4769 G loss:-2.451\n",
      "Epoch:  0044 D loss:-0.4751 G loss:-2.571\n",
      "Epoch:  0044 D loss:-0.5042 G loss:-2.61\n",
      "Epoch:  0044 D loss:-0.6181 G loss:-2.609\n",
      "Epoch:  0044 D loss:-0.5723 G loss:-2.711\n",
      "Epoch:  0044 D loss:-0.6351 G loss:-2.553\n",
      "Epoch:  0044 D loss:-0.65 G loss:-2.371\n",
      "Epoch:  0044 D loss:-0.5429 G loss:-2.325\n",
      "Epoch:  0044 D loss:-0.7395 G loss:-2.074\n",
      "Epoch:  0044 D loss:-0.6629 G loss:-1.968\n",
      "Epoch:  0044 D loss:-0.6193 G loss:-2.261\n",
      "Epoch:  0044 D loss:-0.6018 G loss:-2.128\n",
      "Epoch:  0044 D loss:-0.5545 G loss:-2.3\n",
      "Epoch:  0044 D loss:-0.6994 G loss:-1.977\n",
      "Epoch:  0044 D loss:-0.6706 G loss:-2.172\n",
      "Epoch:  0044 D loss:-0.504 G loss:-2.157\n",
      "Epoch:  0044 D loss:-0.4946 G loss:-2.448\n",
      "Epoch:  0044 D loss:-0.5582 G loss:-2.37\n",
      "Epoch:  0044 D loss:-0.6306 G loss:-2.285\n",
      "Epoch:  0044 D loss:-0.6373 G loss:-2.242\n",
      "Epoch:  0044 D loss:-0.4525 G loss:-2.43\n",
      "Epoch:  0044 D loss:-0.5651 G loss:-2.295\n",
      "Epoch:  0044 D loss:-0.537 G loss:-2.639\n",
      "Epoch:  0044 D loss:-0.5619 G loss:-2.58\n",
      "Epoch:  0044 D loss:-0.5232 G loss:-2.627\n",
      "Epoch:  0044 D loss:-0.674 G loss:-2.517\n",
      "Epoch:  0044 D loss:-0.4785 G loss:-2.618\n",
      "Epoch:  0044 D loss:-0.6259 G loss:-2.3\n",
      "Epoch:  0044 D loss:-0.5251 G loss:-2.159\n",
      "Epoch:  0044 D loss:-0.5963 G loss:-2.224\n",
      "Epoch:  0044 D loss:-0.4821 G loss:-2.035\n",
      "Epoch:  0044 D loss:-0.6692 G loss:-2.144\n",
      "Epoch:  0044 D loss:-0.656 G loss:-2.031\n",
      "Epoch:  0044 D loss:-0.5899 G loss:-2.136\n",
      "Epoch:  0044 D loss:-0.7049 G loss:-2.131\n",
      "Epoch:  0044 D loss:-0.6536 G loss:-2.273\n",
      "Epoch:  0044 D loss:-0.4983 G loss:-2.235\n",
      "Epoch:  0044 D loss:-0.5191 G loss:-2.223\n",
      "Epoch:  0044 D loss:-0.5542 G loss:-2.18\n",
      "Epoch:  0044 D loss:-0.5705 G loss:-2.403\n",
      "Epoch:  0044 D loss:-0.5912 G loss:-2.445\n",
      "Epoch:  0044 D loss:-0.6806 G loss:-2.279\n",
      "Epoch:  0044 D loss:-0.5506 G loss:-2.418\n",
      "Epoch:  0044 D loss:-0.5014 G loss:-2.459\n",
      "Epoch:  0044 D loss:-0.5148 G loss:-2.358\n",
      "Epoch:  0044 D loss:-0.4612 G loss:-2.657\n",
      "Epoch:  0044 D loss:-0.5615 G loss:-2.352\n",
      "Epoch:  0044 D loss:-0.5753 G loss:-2.362\n",
      "Epoch:  0044 D loss:-0.6583 G loss:-2.437\n",
      "Epoch:  0044 D loss:-0.4736 G loss:-2.589\n",
      "Epoch:  0044 D loss:-0.5761 G loss:-2.302\n",
      "Epoch:  0044 D loss:-0.5475 G loss:-2.433\n",
      "Epoch:  0044 D loss:-0.6649 G loss:-2.41\n",
      "Epoch:  0044 D loss:-0.4996 G loss:-2.516\n",
      "Epoch:  0044 D loss:-0.6245 G loss:-2.507\n",
      "Epoch:  0044 D loss:-0.5454 G loss:-2.349\n",
      "Epoch:  0044 D loss:-0.5177 G loss:-2.159\n",
      "Epoch:  0044 D loss:-0.5793 G loss:-2.224\n",
      "Epoch:  0044 D loss:-0.5174 G loss:-2.578\n",
      "Epoch:  0044 D loss:-0.4909 G loss:-2.074\n",
      "Epoch:  0044 D loss:-0.4677 G loss:-2.248\n",
      "Epoch:  0044 D loss:-0.5572 G loss:-2.229\n",
      "Epoch:  0044 D loss:-0.5153 G loss:-2.293\n",
      "Epoch:  0044 D loss:-0.4656 G loss:-2.393\n",
      "Epoch:  0044 D loss:-0.6611 G loss:-2.243\n",
      "Epoch:  0044 D loss:-0.6412 G loss:-2.181\n",
      "Epoch:  0044 D loss:-0.5339 G loss:-2.418\n",
      "Epoch:  0044 D loss:-0.6172 G loss:-2.387\n",
      "Epoch:  0044 D loss:-0.503 G loss:-2.313\n",
      "Epoch:  0044 D loss:-0.5499 G loss:-2.652\n",
      "Epoch:  0044 D loss:-0.5103 G loss:-2.432\n",
      "Epoch:  0044 D loss:-0.5347 G loss:-2.325\n",
      "Epoch:  0044 D loss:-0.5604 G loss:-2.343\n",
      "Epoch:  0044 D loss:-0.5586 G loss:-2.308\n",
      "Epoch:  0044 D loss:-0.5015 G loss:-2.449\n",
      "Epoch:  0044 D loss:-0.6727 G loss:-2.269\n",
      "Epoch:  0044 D loss:-0.4333 G loss:-2.6\n",
      "Epoch:  0044 D loss:-0.656 G loss:-2.404\n",
      "Epoch:  0044 D loss:-0.5974 G loss:-2.193\n",
      "Epoch:  0044 D loss:-0.6722 G loss:-2.361\n",
      "Epoch:  0044 D loss:-0.54 G loss:-2.153\n",
      "Epoch:  0044 D loss:-0.589 G loss:-2.385\n",
      "Epoch:  0044 D loss:-0.6106 G loss:-2.37\n",
      "Epoch:  0044 D loss:-0.4879 G loss:-2.502\n",
      "Epoch:  0044 D loss:-0.5817 G loss:-2.32\n",
      "Epoch:  0044 D loss:-0.4859 G loss:-2.518\n",
      "Epoch:  0044 D loss:-0.5368 G loss:-2.523\n",
      "Epoch:  0044 D loss:-0.4254 G loss:-2.597\n",
      "Epoch:  0044 D loss:-0.6053 G loss:-2.54\n",
      "Epoch:  0044 D loss:-0.8428 G loss:-2.58\n",
      "Epoch:  0044 D loss:-0.5528 G loss:-2.338\n",
      "Epoch:  0044 D loss:-0.5865 G loss:-2.189\n",
      "Epoch:  0044 D loss:-0.6155 G loss:-2.403\n",
      "Epoch:  0044 D loss:-0.6085 G loss:-2.152\n",
      "Epoch:  0044 D loss:-0.633 G loss:-2.124\n",
      "Epoch:  0044 D loss:-0.5766 G loss:-2.377\n",
      "Epoch:  0044 D loss:-0.6064 G loss:-2.192\n",
      "Epoch:  0044 D loss:-0.6549 G loss:-2.088\n",
      "Epoch:  0044 D loss:-0.6308 G loss:-2.298\n",
      "Epoch:  0044 D loss:-0.5343 G loss:-2.304\n",
      "Epoch:  0044 D loss:-0.6471 G loss:-2.236\n",
      "Epoch:  0044 D loss:-0.6347 G loss:-2.264\n",
      "Epoch:  0044 D loss:-0.6359 G loss:-2.224\n",
      "Epoch:  0044 D loss:-0.6933 G loss:-2.11\n",
      "Epoch:  0044 D loss:-0.6752 G loss:-2.374\n",
      "Epoch:  0044 D loss:-0.6474 G loss:-2.28\n",
      "Epoch:  0044 D loss:-0.5419 G loss:-2.373\n",
      "Epoch:  0044 D loss:-0.5799 G loss:-2.226\n",
      "Epoch:  0044 D loss:-0.585 G loss:-2.418\n",
      "Epoch:  0044 D loss:-0.6087 G loss:-2.315\n",
      "Epoch:  0044 D loss:-0.5612 G loss:-2.531\n",
      "Epoch:  0044 D loss:-0.7122 G loss:-2.351\n",
      "Epoch:  0044 D loss:-0.6811 G loss:-2.242\n",
      "Epoch:  0044 D loss:-0.6204 G loss:-2.263\n",
      "Epoch:  0044 D loss:-0.566 G loss:-2.254\n",
      "Epoch:  0044 D loss:-0.5209 G loss:-2.191\n",
      "Epoch:  0044 D loss:-0.685 G loss:-2.167\n",
      "Epoch:  0044 D loss:-0.5366 G loss:-2.183\n",
      "Epoch:  0044 D loss:-0.8009 G loss:-2.182\n",
      "Epoch:  0044 D loss:-0.5648 G loss:-2.328\n",
      "Epoch:  0044 D loss:-0.6185 G loss:-2.469\n",
      "Epoch:  0044 D loss:-0.5266 G loss:-2.474\n",
      "Epoch:  0044 D loss:-0.5984 G loss:-2.452\n",
      "Epoch:  0044 D loss:-0.5226 G loss:-2.43\n",
      "Epoch:  0044 D loss:-0.6127 G loss:-2.4\n",
      "Epoch:  0044 D loss:-0.6387 G loss:-2.182\n",
      "Epoch:  0044 D loss:-0.5473 G loss:-2.345\n",
      "Epoch:  0044 D loss:-0.5314 G loss:-2.485\n",
      "Epoch:  0044 D loss:-0.5582 G loss:-2.273\n",
      "Epoch:  0044 D loss:-0.5302 G loss:-2.312\n",
      "Epoch:  0044 D loss:-0.6544 G loss:-2.276\n",
      "Epoch:  0044 D loss:-0.6024 G loss:-2.215\n",
      "Epoch:  0044 D loss:-0.5443 G loss:-2.294\n",
      "Epoch:  0044 D loss:-0.4766 G loss:-2.399\n",
      "Epoch:  0044 D loss:-0.5907 G loss:-2.445\n",
      "Epoch:  0044 D loss:-0.6543 G loss:-2.219\n",
      "Epoch:  0044 D loss:-0.548 G loss:-2.481\n",
      "Epoch:  0044 D loss:-0.5344 G loss:-2.633\n",
      "Epoch:  0044 D loss:-0.5159 G loss:-2.5\n",
      "Epoch:  0044 D loss:-0.605 G loss:-2.49\n",
      "Epoch:  0044 D loss:-0.4564 G loss:-2.673\n",
      "Epoch:  0044 D loss:-0.5978 G loss:-2.35\n",
      "Epoch:  0044 D loss:-0.53 G loss:-2.416\n",
      "Epoch:  0044 D loss:-0.6255 G loss:-2.374\n",
      "Epoch:  0044 D loss:-0.5099 G loss:-2.551\n",
      "Epoch:  0044 D loss:-0.4853 G loss:-2.383\n",
      "Epoch:  0044 D loss:-0.6572 G loss:-2.468\n",
      "Epoch:  0044 D loss:-0.5864 G loss:-2.155\n",
      "Epoch:  0044 D loss:-0.5065 G loss:-2.287\n",
      "Epoch:  0044 D loss:-0.5001 G loss:-2.56\n",
      "Epoch:  0044 D loss:-0.516 G loss:-2.416\n",
      "Epoch:  0044 D loss:-0.4227 G loss:-2.514\n",
      "Epoch:  0044 D loss:-0.6259 G loss:-2.582\n",
      "Epoch:  0044 D loss:-0.5898 G loss:-2.282\n",
      "Epoch:  0044 D loss:-0.5217 G loss:-2.411\n",
      "Epoch:  0044 D loss:-0.6263 G loss:-2.523\n",
      "Epoch:  0044 D loss:-0.5178 G loss:-2.552\n",
      "Epoch:  0044 D loss:-0.5123 G loss:-2.548\n",
      "Epoch:  0044 D loss:-0.457 G loss:-2.462\n",
      "Epoch:  0044 D loss:-0.5315 G loss:-2.499\n",
      "Epoch:  0044 D loss:-0.5538 G loss:-2.577\n",
      "Epoch:  0044 D loss:-0.638 G loss:-2.428\n",
      "Epoch:  0044 D loss:-0.6699 G loss:-2.585\n",
      "Epoch:  0044 D loss:-0.4959 G loss:-2.538\n",
      "Epoch:  0044 D loss:-0.5109 G loss:-2.336\n",
      "Epoch:  0044 D loss:-0.5412 G loss:-2.314\n",
      "Epoch:  0044 D loss:-0.4928 G loss:-2.302\n",
      "Epoch:  0044 D loss:-0.3675 G loss:-2.416\n",
      "Epoch:  0044 D loss:-0.5622 G loss:-2.34\n",
      "Epoch:  0044 D loss:-0.5332 G loss:-2.637\n",
      "Epoch:  0044 D loss:-0.6208 G loss:-2.326\n",
      "Epoch:  0044 D loss:-0.5025 G loss:-2.432\n",
      "Epoch:  0044 D loss:-0.6663 G loss:-2.566\n",
      "Epoch:  0044 D loss:-0.7206 G loss:-2.265\n",
      "Epoch:  0044 D loss:-0.5139 G loss:-2.333\n",
      "Epoch:  0044 D loss:-0.6186 G loss:-2.47\n",
      "Epoch:  0044 D loss:-0.7369 G loss:-2.673\n",
      "Epoch:  0044 D loss:-0.5315 G loss:-2.403\n",
      "Epoch:  0044 D loss:-0.4746 G loss:-2.521\n",
      "Epoch:  0044 D loss:-0.6043 G loss:-2.417\n",
      "Epoch:  0044 D loss:-0.5619 G loss:-2.16\n",
      "Epoch:  0044 D loss:-0.6046 G loss:-2.382\n",
      "Epoch:  0044 D loss:-0.5467 G loss:-2.453\n",
      "Epoch:  0044 D loss:-0.5414 G loss:-2.327\n",
      "Epoch:  0044 D loss:-0.5981 G loss:-2.345\n",
      "Epoch:  0044 D loss:-0.7257 G loss:-2.334\n",
      "Epoch:  0044 D loss:-0.5988 G loss:-2.557\n",
      "Epoch:  0044 D loss:-0.5695 G loss:-2.204\n",
      "Epoch:  0044 D loss:-0.5559 G loss:-2.29\n",
      "Epoch:  0044 D loss:-0.656 G loss:-2.276\n",
      "Epoch:  0044 D loss:-0.5639 G loss:-2.497\n",
      "Epoch:  0044 D loss:-0.5433 G loss:-2.559\n",
      "Epoch:  0044 D loss:-0.4979 G loss:-2.448\n",
      "Epoch:  0044 D loss:-0.6122 G loss:-2.397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0044 D loss:-0.623 G loss:-2.358\n",
      "Epoch:  0044 D loss:-0.695 G loss:-2.087\n",
      "Epoch:  0044 D loss:-0.7634 G loss:-2.147\n",
      "Epoch:  0044 D loss:-0.7693 G loss:-2.213\n",
      "Epoch:  0044 D loss:-0.6343 G loss:-2.193\n",
      "Epoch:  0044 D loss:-0.6418 G loss:-2.153\n",
      "Epoch:  0044 D loss:-0.5726 G loss:-1.999\n",
      "Epoch:  0044 D loss:-0.7394 G loss:-2.222\n",
      "Epoch:  0044 D loss:-0.5172 G loss:-2.388\n",
      "Epoch:  0044 D loss:-0.6606 G loss:-2.332\n",
      "Epoch:  0044 D loss:-0.5431 G loss:-2.304\n",
      "Epoch:  0044 D loss:-0.6097 G loss:-2.479\n",
      "Epoch:  0044 D loss:-0.6117 G loss:-2.296\n",
      "Epoch:  0044 D loss:-0.6847 G loss:-2.192\n",
      "Epoch:  0044 D loss:-0.6662 G loss:-2.497\n",
      "Epoch:  0044 D loss:-0.6458 G loss:-2.298\n",
      "Epoch:  0044 D loss:-0.6915 G loss:-2.247\n",
      "Epoch:  0044 D loss:-0.5361 G loss:-2.222\n",
      "Epoch:  0044 D loss:-0.7031 G loss:-2.061\n",
      "Epoch:  0044 D loss:-0.7472 G loss:-2.298\n",
      "Epoch:  0044 D loss:-0.5228 G loss:-2.222\n",
      "Epoch:  0044 D loss:-0.62 G loss:-2.214\n",
      "Epoch:  0044 D loss:-0.7482 G loss:-1.946\n",
      "Epoch:  0044 D loss:-0.5868 G loss:-2.194\n",
      "Epoch:  0044 D loss:-0.766 G loss:-2.129\n",
      "Epoch:  0044 D loss:-0.6817 G loss:-2.276\n",
      "Epoch:  0044 D loss:-0.6901 G loss:-2.335\n",
      "Epoch:  0044 D loss:-0.7982 G loss:-2.072\n",
      "Epoch:  0044 D loss:-0.5998 G loss:-2.521\n",
      "Epoch:  0044 D loss:-0.5588 G loss:-2.435\n",
      "Epoch:  0044 D loss:-0.5579 G loss:-2.407\n",
      "Epoch:  0044 D loss:-0.5602 G loss:-2.54\n",
      "Epoch:  0044 D loss:-0.5767 G loss:-2.509\n",
      "Epoch:  0044 D loss:-0.4687 G loss:-2.636\n",
      "Epoch:  0044 D loss:-0.4887 G loss:-2.446\n",
      "Epoch:  0044 D loss:-0.7195 G loss:-2.407\n",
      "Epoch:  0044 D loss:-0.7059 G loss:-2.265\n",
      "Epoch:  0044 D loss:-0.5364 G loss:-2.213\n",
      "Epoch:  0044 D loss:-0.6894 G loss:-2.419\n",
      "Epoch:  0044 D loss:-0.6759 G loss:-2.306\n",
      "Epoch:  0044 D loss:-0.5478 G loss:-2.254\n",
      "Epoch:  0044 D loss:-0.5307 G loss:-2.369\n",
      "Epoch:  0044 D loss:-0.5604 G loss:-2.227\n",
      "Epoch:  0044 D loss:-0.6743 G loss:-2.148\n",
      "Epoch:  0044 D loss:-0.7092 G loss:-2.067\n",
      "Epoch:  0044 D loss:-0.5177 G loss:-2.331\n",
      "Epoch:  0044 D loss:-0.5725 G loss:-2.172\n",
      "Epoch:  0044 D loss:-0.6912 G loss:-2.065\n",
      "Epoch:  0044 D loss:-0.7584 G loss:-2.172\n",
      "Epoch:  0044 D loss:-0.6294 G loss:-2.413\n",
      "Epoch:  0044 D loss:-0.5748 G loss:-2.388\n",
      "Epoch:  0044 D loss:-0.7248 G loss:-2.258\n",
      "Epoch:  0044 D loss:-0.6505 G loss:-2.354\n",
      "Epoch:  0044 D loss:-0.6337 G loss:-2.319\n",
      "Epoch:  0044 D loss:-0.5576 G loss:-2.508\n",
      "Epoch:  0044 D loss:-0.7696 G loss:-2.321\n",
      "Epoch:  0044 D loss:-0.6402 G loss:-2.304\n",
      "Epoch:  0044 D loss:-0.8757 G loss:-2.104\n",
      "Epoch:  0044 D loss:-0.6735 G loss:-2.027\n",
      "Epoch:  0044 D loss:-0.6007 G loss:-2.347\n",
      "Epoch:  0044 D loss:-0.5296 G loss:-2.258\n",
      "Epoch:  0044 D loss:-0.6126 G loss:-2.394\n",
      "Epoch:  0044 D loss:-0.6399 G loss:-2.138\n",
      "Epoch:  0044 D loss:-0.6992 G loss:-1.926\n",
      "Epoch:  0044 D loss:-0.517 G loss:-2.235\n",
      "Epoch:  0044 D loss:-0.5285 G loss:-2.155\n",
      "Epoch:  0044 D loss:-0.5497 G loss:-2.278\n",
      "Epoch:  0044 D loss:-0.5657 G loss:-2.233\n",
      "Epoch:  0044 D loss:-0.527 G loss:-2.191\n",
      "Epoch:  0044 D loss:-0.538 G loss:-2.509\n",
      "Epoch:  0044 D loss:-0.6311 G loss:-2.45\n",
      "Epoch:  0044 D loss:-0.4857 G loss:-2.628\n",
      "Epoch:  0044 D loss:-0.6357 G loss:-2.154\n",
      "Epoch:  0044 D loss:-0.6123 G loss:-2.206\n",
      "Epoch:  0044 D loss:-0.5254 G loss:-2.387\n",
      "Epoch:  0044 D loss:-0.5278 G loss:-2.235\n",
      "Epoch:  0044 D loss:-0.5455 G loss:-2.325\n",
      "Epoch:  0044 D loss:-0.588 G loss:-2.213\n",
      "Epoch:  0044 D loss:-0.7306 G loss:-2.189\n",
      "Epoch:  0044 D loss:-0.5473 G loss:-2.184\n",
      "Epoch:  0044 D loss:-0.4691 G loss:-2.373\n",
      "Epoch:  0044 D loss:-0.4851 G loss:-2.49\n",
      "Epoch:  0044 D loss:-0.5421 G loss:-2.42\n",
      "Epoch:  0044 D loss:-0.5536 G loss:-2.527\n",
      "Epoch:  0044 D loss:-0.4946 G loss:-2.35\n",
      "Epoch:  0044 D loss:-0.6167 G loss:-2.317\n",
      "Epoch:  0044 D loss:-0.6026 G loss:-2.378\n",
      "Epoch:  0044 D loss:-0.4892 G loss:-2.407\n",
      "Epoch:  0044 D loss:-0.5057 G loss:-2.347\n",
      "Epoch:  0044 D loss:-0.6418 G loss:-2.102\n",
      "Epoch:  0044 D loss:-0.6802 G loss:-2.236\n",
      "Epoch:  0044 D loss:-0.5683 G loss:-2.095\n",
      "Epoch:  0044 D loss:-0.6109 G loss:-2.331\n",
      "Epoch:  0044 D loss:-0.5138 G loss:-2.497\n",
      "Epoch:  0044 D loss:-0.4547 G loss:-2.4\n",
      "Epoch:  0044 D loss:-0.4913 G loss:-2.293\n",
      "Epoch:  0044 D loss:-0.565 G loss:-2.268\n",
      "Epoch:  0044 D loss:-0.5068 G loss:-2.207\n",
      "Epoch:  0044 D loss:-0.6844 G loss:-2.064\n",
      "Epoch:  0044 D loss:-0.6191 G loss:-2.305\n",
      "Epoch:  0044 D loss:-0.4733 G loss:-2.35\n",
      "Epoch:  0044 D loss:-0.5219 G loss:-2.208\n",
      "Epoch:  0044 D loss:-0.6456 G loss:-2.156\n",
      "Epoch:  0044 D loss:-0.6387 G loss:-2.345\n",
      "Epoch:  0044 D loss:-0.4905 G loss:-2.469\n",
      "Epoch:  0044 D loss:-0.5434 G loss:-2.182\n",
      "Epoch:  0044 D loss:-0.6777 G loss:-2.298\n",
      "Epoch:  0044 D loss:-0.6208 G loss:-2.251\n",
      "Epoch:  0044 D loss:-0.5494 G loss:-2.249\n",
      "Epoch:  0044 D loss:-0.493 G loss:-2.288\n",
      "Epoch:  0044 D loss:-0.6361 G loss:-2.297\n",
      "Epoch:  0044 D loss:-0.5987 G loss:-2.5\n",
      "Epoch:  0044 D loss:-0.5665 G loss:-2.513\n",
      "Epoch:  0044 D loss:-0.6363 G loss:-2.445\n",
      "Epoch:  0044 D loss:-0.6486 G loss:-2.343\n",
      "Epoch:  0044 D loss:-0.6039 G loss:-2.325\n",
      "Epoch:  0044 D loss:-0.5012 G loss:-2.188\n",
      "Epoch:  0044 D loss:-0.6172 G loss:-2.076\n",
      "Epoch:  0044 D loss:-0.6588 G loss:-2.129\n",
      "Epoch:  0044 D loss:-0.5528 G loss:-2.085\n",
      "Epoch:  0044 D loss:-0.5447 G loss:-2.033\n",
      "Epoch:  0044 D loss:-0.6502 G loss:-2.098\n",
      "Epoch:  0044 D loss:-0.5055 G loss:-2.268\n",
      "Epoch:  0044 D loss:-0.5784 G loss:-2.369\n",
      "Epoch:  0044 D loss:-0.6489 G loss:-2.339\n",
      "Epoch:  0044 D loss:-0.7029 G loss:-2.413\n",
      "Epoch:  0044 D loss:-0.5404 G loss:-2.239\n",
      "Epoch:  0044 D loss:-0.5644 G loss:-2.209\n",
      "Epoch:  0044 D loss:-0.5201 G loss:-2.399\n",
      "Epoch:  0044 D loss:-0.6405 G loss:-2.105\n",
      "Epoch:  0044 D loss:-0.674 G loss:-2.323\n",
      "Epoch:  0044 D loss:-0.5581 G loss:-2.47\n",
      "Epoch:  0044 D loss:-0.6277 G loss:-2.392\n",
      "Epoch:  0044 D loss:-0.5665 G loss:-2.18\n",
      "Epoch:  0044 D loss:-0.6133 G loss:-1.996\n",
      "Epoch:  0044 D loss:-0.6795 G loss:-2.222\n",
      "Epoch:  0044 D loss:-0.6614 G loss:-2.052\n",
      "Epoch:  0044 D loss:-0.5089 G loss:-2.35\n",
      "Epoch:  0044 D loss:-0.6083 G loss:-2.005\n",
      "Epoch:  0044 D loss:-0.5351 G loss:-2.484\n",
      "Epoch:  0044 D loss:-0.5375 G loss:-2.395\n",
      "Epoch:  0044 D loss:-0.6196 G loss:-2.43\n",
      "Epoch:  0044 D loss:-0.5085 G loss:-2.574\n",
      "Epoch:  0044 D loss:-0.4573 G loss:-2.661\n",
      "Epoch:  0044 D loss:-0.6574 G loss:-2.475\n",
      "Epoch:  0044 D loss:-0.5993 G loss:-2.7\n",
      "Epoch:  0044 D loss:-0.6134 G loss:-2.4\n",
      "Epoch:  0044 D loss:-0.6998 G loss:-2.399\n",
      "Epoch:  0044 D loss:-0.5466 G loss:-2.301\n",
      "Epoch:  0044 D loss:-0.67 G loss:-2.293\n",
      "Epoch:  0044 D loss:-0.7479 G loss:-2.05\n",
      "Epoch:  0044 D loss:-0.7616 G loss:-1.983\n",
      "Epoch:  0044 D loss:-0.5299 G loss:-1.879\n",
      "Epoch:  0044 D loss:-0.6508 G loss:-1.925\n",
      "Epoch:  0044 D loss:-0.6996 G loss:-1.953\n",
      "Epoch:  0044 D loss:-0.7549 G loss:-2.124\n",
      "Epoch:  0044 D loss:-0.572 G loss:-2.247\n",
      "Epoch:  0044 D loss:-0.6297 G loss:-2.149\n",
      "Epoch:  0044 D loss:-0.7104 G loss:-2.255\n",
      "Epoch:  0044 D loss:-0.6618 G loss:-2.224\n",
      "Epoch:  0044 D loss:-0.6602 G loss:-2.136\n",
      "Epoch:  0044 D loss:-0.6078 G loss:-2.42\n",
      "Epoch:  0044 D loss:-0.5831 G loss:-2.313\n",
      "Epoch:  0044 D loss:-0.5627 G loss:-2.528\n",
      "Epoch:  0044 D loss:-0.4753 G loss:-2.328\n",
      "Epoch:  0044 D loss:-0.5852 G loss:-2.348\n",
      "Epoch:  0044 D loss:-0.5591 G loss:-2.372\n",
      "Epoch:  0044 D loss:-0.7093 G loss:-2.129\n",
      "Epoch:  0044 D loss:-0.6161 G loss:-2.222\n",
      "Epoch:  0044 D loss:-0.6459 G loss:-2.125\n",
      "Epoch:  0044 D loss:-0.657 G loss:-2.128\n",
      "Epoch:  0044 D loss:-0.5523 G loss:-2.211\n",
      "Epoch:  0044 D loss:-0.6218 G loss:-2.063\n",
      "Epoch:  0044 D loss:-0.6227 G loss:-2.244\n",
      "Epoch:  0044 D loss:-0.7009 G loss:-2.132\n",
      "Epoch:  0044 D loss:-0.5125 G loss:-2.25\n",
      "Epoch:  0044 D loss:-0.5712 G loss:-2.147\n",
      "Epoch:  0044 D loss:-0.7722 G loss:-2.261\n",
      "Epoch:  0044 D loss:-0.5486 G loss:-2.263\n",
      "Epoch:  0044 D loss:-0.5297 G loss:-2.567\n",
      "Epoch:  0044 D loss:-0.5711 G loss:-2.375\n",
      "Epoch:  0044 D loss:-0.5329 G loss:-2.435\n",
      "Epoch:  0044 D loss:-0.7731 G loss:-2.137\n",
      "Epoch:  0044 D loss:-0.6374 G loss:-2.17\n",
      "Epoch:  0044 D loss:-0.7211 G loss:-2.117\n",
      "Epoch:  0044 D loss:-0.5488 G loss:-2.156\n",
      "Epoch:  0044 D loss:-0.5499 G loss:-2.114\n",
      "Epoch:  0044 D loss:-0.6464 G loss:-1.964\n",
      "Epoch:  0044 D loss:-0.7269 G loss:-2.024\n",
      "Epoch:  0044 D loss:-0.5484 G loss:-2.156\n",
      "Epoch:  0044 D loss:-0.6324 G loss:-2.391\n",
      "Epoch:  0044 D loss:-0.6211 G loss:-2.299\n",
      "Epoch:  0044 D loss:-0.6849 G loss:-2.195\n",
      "Epoch:  0044 D loss:-0.6661 G loss:-2.587\n",
      "Epoch:  0044 D loss:-0.668 G loss:-2.37\n",
      "Epoch:  0044 D loss:-0.5842 G loss:-2.534\n",
      "Epoch:  0044 D loss:-0.6748 G loss:-2.34\n",
      "Epoch:  0044 D loss:-0.6233 G loss:-2.17\n",
      "Epoch:  0044 D loss:-0.6952 G loss:-2.132\n",
      "Epoch:  0044 D loss:-0.6405 G loss:-2.036\n",
      "Epoch:  0044 D loss:-0.7852 G loss:-1.975\n",
      "Epoch:  0044 D loss:-0.6702 G loss:-2.134\n",
      "Epoch:  0044 D loss:-0.6176 G loss:-2.017\n",
      "Epoch:  0044 D loss:-0.6145 G loss:-2.173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0044 D loss:-0.5706 G loss:-2.184\n",
      "Epoch:  0044 D loss:-0.6196 G loss:-2.187\n",
      "Epoch:  0044 D loss:-0.5986 G loss:-2.49\n",
      "Epoch:  0044 D loss:-0.4417 G loss:-2.6\n",
      "Epoch:  0044 D loss:-0.6566 G loss:-2.49\n",
      "Epoch:  0044 D loss:-0.7163 G loss:-2.519\n",
      "Epoch:  0044 D loss:-0.6947 G loss:-2.489\n",
      "Epoch:  0044 D loss:-0.5249 G loss:-2.525\n",
      "Epoch:  0044 D loss:-0.4892 G loss:-2.445\n",
      "Epoch:  0044 D loss:-0.6503 G loss:-2.337\n",
      "Epoch:  0044 D loss:-0.5049 G loss:-2.418\n",
      "Epoch:  0044 D loss:-0.6333 G loss:-2.263\n",
      "Epoch:  0044 D loss:-0.6129 G loss:-2.124\n",
      "Epoch:  0044 D loss:-0.6475 G loss:-1.923\n",
      "Epoch:  0044 D loss:-0.6332 G loss:-1.955\n",
      "Epoch:  0044 D loss:-0.5973 G loss:-2.046\n",
      "Epoch:  0044 D loss:-0.7642 G loss:-2.155\n",
      "Epoch:  0044 D loss:-0.6463 G loss:-2.147\n",
      "Epoch:  0044 D loss:-0.6918 G loss:-2.313\n",
      "Epoch:  0044 D loss:-0.5879 G loss:-2.319\n",
      "Epoch:  0044 D loss:-0.5706 G loss:-2.275\n",
      "Epoch:  0044 D loss:-0.6327 G loss:-2.174\n",
      "Epoch:  0044 D loss:-0.5746 G loss:-2.334\n",
      "Epoch:  0044 D loss:-0.7328 G loss:-2.024\n",
      "Epoch:  0044 D loss:-0.7316 G loss:-2.34\n",
      "Epoch:  0044 D loss:-0.6531 G loss:-2.133\n",
      "Epoch:  0044 D loss:-0.5875 G loss:-2.464\n",
      "Epoch:  0044 D loss:-0.5778 G loss:-2.406\n",
      "Epoch:  0044 D loss:-0.6561 G loss:-2.443\n",
      "Epoch:  0044 D loss:-0.6573 G loss:-2.305\n",
      "Epoch:  0044 D loss:-0.6344 G loss:-2.152\n",
      "Epoch:  0044 D loss:-0.5315 G loss:-2.352\n",
      "Epoch:  0044 D loss:-0.627 G loss:-2.243\n",
      "Epoch:  0044 D loss:-0.5149 G loss:-2.379\n",
      "Epoch:  0044 D loss:-0.6547 G loss:-2.193\n",
      "Epoch:  0044 D loss:-0.461 G loss:-2.138\n",
      "Epoch:  0044 D loss:-0.6441 G loss:-2.391\n",
      "Epoch:  0044 D loss:-0.6487 G loss:-2.112\n",
      "Epoch:  0044 D loss:-0.5603 G loss:-1.885\n",
      "Epoch:  0044 D loss:-0.7119 G loss:-1.993\n",
      "Epoch:  0044 D loss:-0.7015 G loss:-1.918\n",
      "Epoch:  0044 D loss:-0.7071 G loss:-2.095\n",
      "Epoch:  0044 D loss:-0.6383 G loss:-2.235\n",
      "Epoch:  0044 D loss:-0.7519 G loss:-2.356\n",
      "Epoch:  0044 D loss:-0.5553 G loss:-2.277\n",
      "Epoch:  0044 D loss:-0.6685 G loss:-2.303\n",
      "Epoch:  0044 D loss:-0.5735 G loss:-2.463\n",
      "Epoch:  0044 D loss:-0.6325 G loss:-2.326\n",
      "Epoch:  0044 D loss:-0.5941 G loss:-2.199\n",
      "Epoch:  0044 D loss:-0.5043 G loss:-2.236\n",
      "Epoch:  0044 D loss:-0.5981 G loss:-2.46\n",
      "Epoch:  0044 D loss:-0.5115 G loss:-2.342\n",
      "Epoch:  0044 D loss:-0.6857 G loss:-1.955\n",
      "Epoch:  0044 D loss:-0.5387 G loss:-2.168\n",
      "Epoch:  0044 D loss:-0.4588 G loss:-2.1\n",
      "Epoch:  0044 D loss:-0.5485 G loss:-2.302\n",
      "Epoch:  0044 D loss:-0.5957 G loss:-2.268\n",
      "Epoch:  0044 D loss:-0.5765 G loss:-2.327\n",
      "Epoch:  0044 D loss:-0.619 G loss:-2.406\n",
      "Epoch:  0044 D loss:-0.5265 G loss:-2.37\n",
      "Epoch:  0044 D loss:-0.5818 G loss:-2.41\n",
      "Epoch:  0044 D loss:-0.5576 G loss:-2.297\n",
      "Epoch:  0044 D loss:-0.7674 G loss:-2.096\n",
      "Epoch:  0044 D loss:-0.5341 G loss:-2.342\n",
      "Epoch:  0044 D loss:-0.7129 G loss:-2.014\n",
      "Epoch:  0044 D loss:-0.6974 G loss:-2.261\n",
      "Epoch:  0044 D loss:-0.6105 G loss:-2.137\n",
      "Epoch:  0044 D loss:-0.5737 G loss:-2.251\n",
      "Epoch:  0044 D loss:-0.4949 G loss:-2.357\n",
      "Epoch:  0044 D loss:-0.6403 G loss:-2.335\n",
      "Epoch:  0044 D loss:-0.4844 G loss:-2.48\n",
      "Epoch:  0044 D loss:-0.4784 G loss:-2.26\n",
      "Epoch:  0045 D loss:-0.5305 G loss:-2.478\n",
      "Epoch:  0045 D loss:-0.5968 G loss:-2.371\n",
      "Epoch:  0045 D loss:-0.5799 G loss:-2.316\n",
      "Epoch:  0045 D loss:-0.5201 G loss:-2.479\n",
      "Epoch:  0045 D loss:-0.512 G loss:-2.596\n",
      "Epoch:  0045 D loss:-0.6412 G loss:-2.277\n",
      "Epoch:  0045 D loss:-0.4614 G loss:-2.613\n",
      "Epoch:  0045 D loss:-0.5966 G loss:-2.209\n",
      "Epoch:  0045 D loss:-0.5176 G loss:-2.401\n",
      "Epoch:  0045 D loss:-0.5938 G loss:-2.412\n",
      "Epoch:  0045 D loss:-0.4858 G loss:-2.501\n",
      "Epoch:  0045 D loss:-0.6203 G loss:-2.153\n",
      "Epoch:  0045 D loss:-0.609 G loss:-2.12\n",
      "Epoch:  0045 D loss:-0.5894 G loss:-2.213\n",
      "Epoch:  0045 D loss:-0.5265 G loss:-2.517\n",
      "Epoch:  0045 D loss:-0.5699 G loss:-2.166\n",
      "Epoch:  0045 D loss:-0.537 G loss:-2.494\n",
      "Epoch:  0045 D loss:-0.543 G loss:-2.706\n",
      "Epoch:  0045 D loss:-0.7682 G loss:-2.221\n",
      "Epoch:  0045 D loss:-0.5796 G loss:-2.477\n",
      "Epoch:  0045 D loss:-0.6416 G loss:-2.269\n",
      "Epoch:  0045 D loss:-0.5552 G loss:-2.275\n",
      "Epoch:  0045 D loss:-0.5014 G loss:-2.142\n",
      "Epoch:  0045 D loss:-0.432 G loss:-2.476\n",
      "Epoch:  0045 D loss:-0.4856 G loss:-2.388\n",
      "Epoch:  0045 D loss:-0.593 G loss:-2.247\n",
      "Epoch:  0045 D loss:-0.6371 G loss:-2.367\n",
      "Epoch:  0045 D loss:-0.5748 G loss:-2.27\n",
      "Epoch:  0045 D loss:-0.6364 G loss:-2.024\n",
      "Epoch:  0045 D loss:-0.6269 G loss:-2.418\n",
      "Epoch:  0045 D loss:-0.5515 G loss:-2.267\n",
      "Epoch:  0045 D loss:-0.7003 G loss:-2.323\n",
      "Epoch:  0045 D loss:-0.5807 G loss:-2.41\n",
      "Epoch:  0045 D loss:-0.5322 G loss:-2.507\n",
      "Epoch:  0045 D loss:-0.4888 G loss:-2.257\n",
      "Epoch:  0045 D loss:-0.5882 G loss:-2.351\n",
      "Epoch:  0045 D loss:-0.5271 G loss:-2.348\n",
      "Epoch:  0045 D loss:-0.5452 G loss:-2.058\n",
      "Epoch:  0045 D loss:-0.5766 G loss:-2.361\n",
      "Epoch:  0045 D loss:-0.4714 G loss:-2.369\n",
      "Epoch:  0045 D loss:-0.4285 G loss:-2.201\n",
      "Epoch:  0045 D loss:-0.6838 G loss:-2.132\n",
      "Epoch:  0045 D loss:-0.5224 G loss:-2.287\n",
      "Epoch:  0045 D loss:-0.4425 G loss:-2.228\n",
      "Epoch:  0045 D loss:-0.6814 G loss:-2.157\n",
      "Epoch:  0045 D loss:-0.6088 G loss:-2.216\n",
      "Epoch:  0045 D loss:-0.5993 G loss:-2.502\n",
      "Epoch:  0045 D loss:-0.6098 G loss:-2.252\n",
      "Epoch:  0045 D loss:-0.5765 G loss:-2.389\n",
      "Epoch:  0045 D loss:-0.59 G loss:-2.418\n",
      "Epoch:  0045 D loss:-0.5626 G loss:-2.408\n",
      "Epoch:  0045 D loss:-0.4202 G loss:-2.541\n",
      "Epoch:  0045 D loss:-0.5625 G loss:-2.545\n",
      "Epoch:  0045 D loss:-0.6244 G loss:-2.531\n",
      "Epoch:  0045 D loss:-0.5617 G loss:-2.556\n",
      "Epoch:  0045 D loss:-0.6188 G loss:-2.636\n",
      "Epoch:  0045 D loss:-0.5559 G loss:-2.442\n",
      "Epoch:  0045 D loss:-0.6836 G loss:-2.336\n",
      "Epoch:  0045 D loss:-0.5189 G loss:-2.633\n",
      "Epoch:  0045 D loss:-0.5406 G loss:-2.194\n",
      "Epoch:  0045 D loss:-0.5997 G loss:-2.382\n",
      "Epoch:  0045 D loss:-0.5477 G loss:-2.355\n",
      "Epoch:  0045 D loss:-0.4942 G loss:-2.269\n",
      "Epoch:  0045 D loss:-0.8049 G loss:-2.017\n",
      "Epoch:  0045 D loss:-0.7288 G loss:-2.077\n",
      "Epoch:  0045 D loss:-0.639 G loss:-2.328\n",
      "Epoch:  0045 D loss:-0.8223 G loss:-1.939\n",
      "Epoch:  0045 D loss:-0.6917 G loss:-2.119\n",
      "Epoch:  0045 D loss:-0.731 G loss:-2.131\n",
      "Epoch:  0045 D loss:-0.7173 G loss:-2.337\n",
      "Epoch:  0045 D loss:-0.7993 G loss:-2.236\n",
      "Epoch:  0045 D loss:-0.5926 G loss:-1.998\n",
      "Epoch:  0045 D loss:-0.6756 G loss:-2.136\n",
      "Epoch:  0045 D loss:-0.5537 G loss:-2.363\n",
      "Epoch:  0045 D loss:-0.7012 G loss:-2.219\n",
      "Epoch:  0045 D loss:-0.6486 G loss:-2.048\n",
      "Epoch:  0045 D loss:-0.6125 G loss:-2.192\n",
      "Epoch:  0045 D loss:-0.7164 G loss:-2.141\n",
      "Epoch:  0045 D loss:-0.7061 G loss:-2.072\n",
      "Epoch:  0045 D loss:-0.6045 G loss:-2.089\n",
      "Epoch:  0045 D loss:-0.5251 G loss:-2.148\n",
      "Epoch:  0045 D loss:-0.7372 G loss:-1.966\n",
      "Epoch:  0045 D loss:-0.8334 G loss:-2.03\n",
      "Epoch:  0045 D loss:-0.7781 G loss:-2.053\n",
      "Epoch:  0045 D loss:-0.5467 G loss:-2.01\n",
      "Epoch:  0045 D loss:-0.7332 G loss:-2.092\n",
      "Epoch:  0045 D loss:-0.7039 G loss:-2.201\n",
      "Epoch:  0045 D loss:-0.775 G loss:-2.312\n",
      "Epoch:  0045 D loss:-0.4967 G loss:-2.23\n",
      "Epoch:  0045 D loss:-0.6673 G loss:-2.357\n",
      "Epoch:  0045 D loss:-0.654 G loss:-2.443\n",
      "Epoch:  0045 D loss:-0.8808 G loss:-2.137\n",
      "Epoch:  0045 D loss:-0.5192 G loss:-2.306\n",
      "Epoch:  0045 D loss:-0.8165 G loss:-2.069\n",
      "Epoch:  0045 D loss:-0.6993 G loss:-2.033\n",
      "Epoch:  0045 D loss:-0.7188 G loss:-2.073\n",
      "Epoch:  0045 D loss:-0.8086 G loss:-2.028\n",
      "Epoch:  0045 D loss:-0.6152 G loss:-1.985\n",
      "Epoch:  0045 D loss:-0.5607 G loss:-2.113\n",
      "Epoch:  0045 D loss:-0.6832 G loss:-2.197\n",
      "Epoch:  0045 D loss:-0.6028 G loss:-1.92\n",
      "Epoch:  0045 D loss:-0.6935 G loss:-2.199\n",
      "Epoch:  0045 D loss:-0.6413 G loss:-2.367\n",
      "Epoch:  0045 D loss:-0.592 G loss:-2.245\n",
      "Epoch:  0045 D loss:-0.6376 G loss:-2.29\n",
      "Epoch:  0045 D loss:-0.8036 G loss:-2.0\n",
      "Epoch:  0045 D loss:-0.6036 G loss:-2.335\n",
      "Epoch:  0045 D loss:-0.7475 G loss:-2.25\n",
      "Epoch:  0045 D loss:-0.5384 G loss:-2.154\n",
      "Epoch:  0045 D loss:-0.6703 G loss:-2.135\n",
      "Epoch:  0045 D loss:-0.7206 G loss:-2.179\n",
      "Epoch:  0045 D loss:-0.6001 G loss:-2.153\n",
      "Epoch:  0045 D loss:-0.5664 G loss:-2.319\n",
      "Epoch:  0045 D loss:-0.5684 G loss:-2.131\n",
      "Epoch:  0045 D loss:-0.7559 G loss:-2.02\n",
      "Epoch:  0045 D loss:-0.7872 G loss:-1.941\n",
      "Epoch:  0045 D loss:-0.5795 G loss:-2.251\n",
      "Epoch:  0045 D loss:-0.6095 G loss:-1.901\n",
      "Epoch:  0045 D loss:-0.6841 G loss:-2.05\n",
      "Epoch:  0045 D loss:-0.6799 G loss:-2.15\n",
      "Epoch:  0045 D loss:-0.5122 G loss:-2.104\n",
      "Epoch:  0045 D loss:-0.5281 G loss:-2.513\n",
      "Epoch:  0045 D loss:-0.7032 G loss:-2.63\n",
      "Epoch:  0045 D loss:-0.7057 G loss:-2.398\n",
      "Epoch:  0045 D loss:-0.459 G loss:-2.604\n",
      "Epoch:  0045 D loss:-0.6836 G loss:-2.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0045 D loss:-0.4944 G loss:-2.479\n",
      "Epoch:  0045 D loss:-0.606 G loss:-2.174\n",
      "Epoch:  0045 D loss:-0.5236 G loss:-2.338\n",
      "Epoch:  0045 D loss:-0.5058 G loss:-2.498\n",
      "Epoch:  0045 D loss:-0.5643 G loss:-2.164\n",
      "Epoch:  0045 D loss:-0.6314 G loss:-2.305\n",
      "Epoch:  0045 D loss:-0.5263 G loss:-2.203\n",
      "Epoch:  0045 D loss:-0.5801 G loss:-2.179\n",
      "Epoch:  0045 D loss:-0.4846 G loss:-2.373\n",
      "Epoch:  0045 D loss:-0.4854 G loss:-2.15\n",
      "Epoch:  0045 D loss:-0.471 G loss:-2.408\n",
      "Epoch:  0045 D loss:-0.5267 G loss:-2.718\n",
      "Epoch:  0045 D loss:-0.5175 G loss:-2.295\n",
      "Epoch:  0045 D loss:-0.5552 G loss:-2.486\n",
      "Epoch:  0045 D loss:-0.6167 G loss:-2.454\n",
      "Epoch:  0045 D loss:-0.4512 G loss:-2.627\n",
      "Epoch:  0045 D loss:-0.5328 G loss:-2.521\n",
      "Epoch:  0045 D loss:-0.6522 G loss:-2.298\n",
      "Epoch:  0045 D loss:-0.624 G loss:-2.107\n",
      "Epoch:  0045 D loss:-0.4186 G loss:-2.4\n",
      "Epoch:  0045 D loss:-0.5473 G loss:-2.13\n",
      "Epoch:  0045 D loss:-0.504 G loss:-2.207\n",
      "Epoch:  0045 D loss:-0.4885 G loss:-1.995\n",
      "Epoch:  0045 D loss:-0.5298 G loss:-2.314\n",
      "Epoch:  0045 D loss:-0.6036 G loss:-2.265\n",
      "Epoch:  0045 D loss:-0.5644 G loss:-2.358\n",
      "Epoch:  0045 D loss:-0.567 G loss:-2.157\n",
      "Epoch:  0045 D loss:-0.5434 G loss:-2.198\n",
      "Epoch:  0045 D loss:-0.6057 G loss:-2.143\n",
      "Epoch:  0045 D loss:-0.5463 G loss:-2.297\n",
      "Epoch:  0045 D loss:-0.4392 G loss:-2.385\n",
      "Epoch:  0045 D loss:-0.6184 G loss:-2.313\n",
      "Epoch:  0045 D loss:-0.4066 G loss:-2.362\n",
      "Epoch:  0045 D loss:-0.485 G loss:-2.462\n",
      "Epoch:  0045 D loss:-0.4714 G loss:-2.668\n",
      "Epoch:  0045 D loss:-0.5472 G loss:-2.46\n",
      "Epoch:  0045 D loss:-0.526 G loss:-2.4\n",
      "Epoch:  0045 D loss:-0.6501 G loss:-2.567\n",
      "Epoch:  0045 D loss:-0.469 G loss:-2.711\n",
      "Epoch:  0045 D loss:-0.4928 G loss:-2.474\n",
      "Epoch:  0045 D loss:-0.6397 G loss:-2.351\n",
      "Epoch:  0045 D loss:-0.6316 G loss:-2.298\n",
      "Epoch:  0045 D loss:-0.479 G loss:-2.251\n",
      "Epoch:  0045 D loss:-0.5249 G loss:-2.254\n",
      "Epoch:  0045 D loss:-0.6854 G loss:-1.992\n",
      "Epoch:  0045 D loss:-0.5264 G loss:-2.326\n",
      "Epoch:  0045 D loss:-0.5103 G loss:-2.278\n",
      "Epoch:  0045 D loss:-0.4981 G loss:-2.31\n",
      "Epoch:  0045 D loss:-0.5094 G loss:-2.239\n",
      "Epoch:  0045 D loss:-0.5624 G loss:-2.442\n",
      "Epoch:  0045 D loss:-0.6042 G loss:-2.154\n",
      "Epoch:  0045 D loss:-0.4792 G loss:-2.334\n",
      "Epoch:  0045 D loss:-0.507 G loss:-2.177\n",
      "Epoch:  0045 D loss:-0.5129 G loss:-2.338\n",
      "Epoch:  0045 D loss:-0.4515 G loss:-2.424\n",
      "Epoch:  0045 D loss:-0.5187 G loss:-2.434\n",
      "Epoch:  0045 D loss:-0.4527 G loss:-2.55\n",
      "Epoch:  0045 D loss:-0.6122 G loss:-2.67\n",
      "Epoch:  0045 D loss:-0.4975 G loss:-2.571\n",
      "Epoch:  0045 D loss:-0.5567 G loss:-2.504\n",
      "Epoch:  0045 D loss:-0.5832 G loss:-2.44\n",
      "Epoch:  0045 D loss:-0.5312 G loss:-2.419\n",
      "Epoch:  0045 D loss:-0.4254 G loss:-2.239\n",
      "Epoch:  0045 D loss:-0.5312 G loss:-2.153\n",
      "Epoch:  0045 D loss:-0.6204 G loss:-2.093\n",
      "Epoch:  0045 D loss:-0.5928 G loss:-2.169\n",
      "Epoch:  0045 D loss:-0.6464 G loss:-1.992\n",
      "Epoch:  0045 D loss:-0.4541 G loss:-2.383\n",
      "Epoch:  0045 D loss:-0.5441 G loss:-2.182\n",
      "Epoch:  0045 D loss:-0.4899 G loss:-2.416\n",
      "Epoch:  0045 D loss:-0.5203 G loss:-2.402\n",
      "Epoch:  0045 D loss:-0.4421 G loss:-2.49\n",
      "Epoch:  0045 D loss:-0.5543 G loss:-2.179\n",
      "Epoch:  0045 D loss:-0.579 G loss:-2.309\n",
      "Epoch:  0045 D loss:-0.552 G loss:-2.389\n",
      "Epoch:  0045 D loss:-0.5896 G loss:-2.142\n",
      "Epoch:  0045 D loss:-0.5747 G loss:-2.111\n",
      "Epoch:  0045 D loss:-0.5387 G loss:-2.167\n",
      "Epoch:  0045 D loss:-0.4341 G loss:-2.302\n",
      "Epoch:  0045 D loss:-0.6298 G loss:-2.074\n",
      "Epoch:  0045 D loss:-0.6325 G loss:-2.358\n",
      "Epoch:  0045 D loss:-0.5496 G loss:-2.154\n",
      "Epoch:  0045 D loss:-0.4897 G loss:-2.164\n",
      "Epoch:  0045 D loss:-0.6499 G loss:-2.203\n",
      "Epoch:  0045 D loss:-0.5196 G loss:-2.138\n",
      "Epoch:  0045 D loss:-0.4103 G loss:-2.245\n",
      "Epoch:  0045 D loss:-0.6519 G loss:-2.355\n",
      "Epoch:  0045 D loss:-0.6472 G loss:-2.367\n",
      "Epoch:  0045 D loss:-0.6572 G loss:-2.23\n",
      "Epoch:  0045 D loss:-0.5885 G loss:-2.196\n",
      "Epoch:  0045 D loss:-0.5481 G loss:-2.302\n",
      "Epoch:  0045 D loss:-0.6722 G loss:-2.55\n",
      "Epoch:  0045 D loss:-0.5891 G loss:-2.35\n",
      "Epoch:  0045 D loss:-0.6166 G loss:-2.237\n",
      "Epoch:  0045 D loss:-0.509 G loss:-2.398\n",
      "Epoch:  0045 D loss:-0.5095 G loss:-2.175\n",
      "Epoch:  0045 D loss:-0.5749 G loss:-2.241\n",
      "Epoch:  0045 D loss:-0.6108 G loss:-2.127\n",
      "Epoch:  0045 D loss:-0.603 G loss:-2.18\n",
      "Epoch:  0045 D loss:-0.5394 G loss:-1.913\n",
      "Epoch:  0045 D loss:-0.5871 G loss:-1.939\n",
      "Epoch:  0045 D loss:-0.6218 G loss:-2.191\n",
      "Epoch:  0045 D loss:-0.6383 G loss:-2.115\n",
      "Epoch:  0045 D loss:-0.6311 G loss:-2.267\n",
      "Epoch:  0045 D loss:-0.6227 G loss:-2.438\n",
      "Epoch:  0045 D loss:-0.5708 G loss:-2.303\n",
      "Epoch:  0045 D loss:-0.5803 G loss:-2.266\n",
      "Epoch:  0045 D loss:-0.5073 G loss:-2.459\n",
      "Epoch:  0045 D loss:-0.5896 G loss:-2.455\n",
      "Epoch:  0045 D loss:-0.6368 G loss:-2.271\n",
      "Epoch:  0045 D loss:-0.5848 G loss:-2.19\n",
      "Epoch:  0045 D loss:-0.6234 G loss:-2.197\n",
      "Epoch:  0045 D loss:-0.5172 G loss:-2.203\n",
      "Epoch:  0045 D loss:-0.5523 G loss:-2.368\n",
      "Epoch:  0045 D loss:-0.6588 G loss:-2.041\n",
      "Epoch:  0045 D loss:-0.587 G loss:-2.169\n",
      "Epoch:  0045 D loss:-0.5755 G loss:-2.338\n",
      "Epoch:  0045 D loss:-0.5576 G loss:-2.087\n",
      "Epoch:  0045 D loss:-0.5248 G loss:-2.233\n",
      "Epoch:  0045 D loss:-0.5621 G loss:-2.367\n",
      "Epoch:  0045 D loss:-0.485 G loss:-2.344\n",
      "Epoch:  0045 D loss:-0.5199 G loss:-2.285\n",
      "Epoch:  0045 D loss:-0.5693 G loss:-2.515\n",
      "Epoch:  0045 D loss:-0.5134 G loss:-2.333\n",
      "Epoch:  0045 D loss:-0.6835 G loss:-2.26\n",
      "Epoch:  0045 D loss:-0.5723 G loss:-2.226\n",
      "Epoch:  0045 D loss:-0.5941 G loss:-2.151\n",
      "Epoch:  0045 D loss:-0.6582 G loss:-2.228\n",
      "Epoch:  0045 D loss:-0.6277 G loss:-2.272\n",
      "Epoch:  0045 D loss:-0.6561 G loss:-2.141\n",
      "Epoch:  0045 D loss:-0.5987 G loss:-2.331\n",
      "Epoch:  0045 D loss:-0.6222 G loss:-2.389\n",
      "Epoch:  0045 D loss:-0.5415 G loss:-2.186\n",
      "Epoch:  0045 D loss:-0.5549 G loss:-2.151\n",
      "Epoch:  0045 D loss:-0.6355 G loss:-2.106\n",
      "Epoch:  0045 D loss:-0.5718 G loss:-1.919\n",
      "Epoch:  0045 D loss:-0.5928 G loss:-2.211\n",
      "Epoch:  0045 D loss:-0.6821 G loss:-2.034\n",
      "Epoch:  0045 D loss:-0.519 G loss:-2.223\n",
      "Epoch:  0045 D loss:-0.8115 G loss:-2.056\n",
      "Epoch:  0045 D loss:-0.7369 G loss:-2.135\n",
      "Epoch:  0045 D loss:-0.5852 G loss:-2.405\n",
      "Epoch:  0045 D loss:-0.6203 G loss:-2.162\n",
      "Epoch:  0045 D loss:-0.586 G loss:-2.157\n",
      "Epoch:  0045 D loss:-0.6507 G loss:-2.116\n",
      "Epoch:  0045 D loss:-0.6977 G loss:-2.214\n",
      "Epoch:  0045 D loss:-0.6545 G loss:-2.185\n",
      "Epoch:  0045 D loss:-0.6806 G loss:-2.26\n",
      "Epoch:  0045 D loss:-0.6734 G loss:-2.283\n",
      "Epoch:  0045 D loss:-0.7313 G loss:-2.149\n",
      "Epoch:  0045 D loss:-0.6719 G loss:-2.07\n",
      "Epoch:  0045 D loss:-0.5984 G loss:-2.181\n",
      "Epoch:  0045 D loss:-0.6188 G loss:-1.883\n",
      "Epoch:  0045 D loss:-0.6116 G loss:-1.99\n",
      "Epoch:  0045 D loss:-0.5812 G loss:-2.211\n",
      "Epoch:  0045 D loss:-0.6851 G loss:-2.009\n",
      "Epoch:  0045 D loss:-0.7195 G loss:-2.113\n",
      "Epoch:  0045 D loss:-0.5999 G loss:-2.14\n",
      "Epoch:  0045 D loss:-0.5703 G loss:-2.091\n",
      "Epoch:  0045 D loss:-0.6606 G loss:-2.351\n",
      "Epoch:  0045 D loss:-0.6575 G loss:-2.201\n",
      "Epoch:  0045 D loss:-0.5959 G loss:-2.232\n",
      "Epoch:  0045 D loss:-0.5832 G loss:-2.122\n",
      "Epoch:  0045 D loss:-0.6358 G loss:-2.075\n",
      "Epoch:  0045 D loss:-0.5487 G loss:-2.323\n",
      "Epoch:  0045 D loss:-0.5097 G loss:-2.358\n",
      "Epoch:  0045 D loss:-0.6473 G loss:-2.246\n",
      "Epoch:  0045 D loss:-0.6129 G loss:-2.15\n",
      "Epoch:  0045 D loss:-0.6898 G loss:-2.21\n",
      "Epoch:  0045 D loss:-0.6518 G loss:-2.035\n",
      "Epoch:  0045 D loss:-0.6199 G loss:-2.402\n",
      "Epoch:  0045 D loss:-0.567 G loss:-2.355\n",
      "Epoch:  0045 D loss:-0.7364 G loss:-2.248\n",
      "Epoch:  0045 D loss:-0.7112 G loss:-1.962\n",
      "Epoch:  0045 D loss:-0.704 G loss:-2.135\n",
      "Epoch:  0045 D loss:-0.6738 G loss:-2.212\n",
      "Epoch:  0045 D loss:-0.6937 G loss:-2.215\n",
      "Epoch:  0045 D loss:-0.5912 G loss:-2.097\n",
      "Epoch:  0045 D loss:-0.5536 G loss:-2.102\n",
      "Epoch:  0045 D loss:-0.6119 G loss:-2.162\n",
      "Epoch:  0045 D loss:-0.6412 G loss:-2.412\n",
      "Epoch:  0045 D loss:-0.6286 G loss:-2.201\n",
      "Epoch:  0045 D loss:-0.6803 G loss:-2.166\n",
      "Epoch:  0045 D loss:-0.7006 G loss:-2.125\n",
      "Epoch:  0045 D loss:-0.6613 G loss:-2.147\n",
      "Epoch:  0045 D loss:-0.6379 G loss:-2.157\n",
      "Epoch:  0045 D loss:-0.7295 G loss:-2.381\n",
      "Epoch:  0045 D loss:-0.6628 G loss:-2.202\n",
      "Epoch:  0045 D loss:-0.6408 G loss:-2.307\n",
      "Epoch:  0045 D loss:-0.6815 G loss:-2.02\n",
      "Epoch:  0045 D loss:-0.6984 G loss:-1.989\n",
      "Epoch:  0045 D loss:-0.5521 G loss:-2.19\n",
      "Epoch:  0045 D loss:-0.7061 G loss:-1.922\n",
      "Epoch:  0045 D loss:-0.5989 G loss:-2.03\n",
      "Epoch:  0045 D loss:-0.6126 G loss:-2.183\n",
      "Epoch:  0045 D loss:-0.7481 G loss:-1.898\n",
      "Epoch:  0045 D loss:-0.6717 G loss:-2.225\n",
      "Epoch:  0045 D loss:-0.7007 G loss:-2.08\n",
      "Epoch:  0045 D loss:-0.7437 G loss:-2.393\n",
      "Epoch:  0045 D loss:-0.5834 G loss:-2.608\n",
      "Epoch:  0045 D loss:-0.5959 G loss:-2.365\n",
      "Epoch:  0045 D loss:-0.5334 G loss:-2.619\n",
      "Epoch:  0045 D loss:-0.5783 G loss:-2.676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0045 D loss:-0.4815 G loss:-2.49\n",
      "Epoch:  0045 D loss:-0.7414 G loss:-2.039\n",
      "Epoch:  0045 D loss:-0.5928 G loss:-2.463\n",
      "Epoch:  0045 D loss:-0.5669 G loss:-2.395\n",
      "Epoch:  0045 D loss:-0.523 G loss:-2.25\n",
      "Epoch:  0045 D loss:-0.588 G loss:-2.166\n",
      "Epoch:  0045 D loss:-0.4226 G loss:-2.314\n",
      "Epoch:  0045 D loss:-0.6916 G loss:-2.038\n",
      "Epoch:  0045 D loss:-0.6226 G loss:-2.016\n",
      "Epoch:  0045 D loss:-0.5061 G loss:-2.059\n",
      "Epoch:  0045 D loss:-0.6941 G loss:-2.205\n",
      "Epoch:  0045 D loss:-0.5409 G loss:-2.409\n",
      "Epoch:  0045 D loss:-0.5575 G loss:-2.41\n",
      "Epoch:  0045 D loss:-0.5626 G loss:-2.675\n",
      "Epoch:  0045 D loss:-0.4768 G loss:-2.611\n",
      "Epoch:  0045 D loss:-0.6019 G loss:-2.528\n",
      "Epoch:  0045 D loss:-0.3892 G loss:-2.394\n",
      "Epoch:  0045 D loss:-0.6043 G loss:-2.347\n",
      "Epoch:  0045 D loss:-0.5153 G loss:-2.575\n",
      "Epoch:  0045 D loss:-0.5213 G loss:-2.342\n",
      "Epoch:  0045 D loss:-0.5795 G loss:-2.268\n",
      "Epoch:  0045 D loss:-0.4928 G loss:-2.335\n",
      "Epoch:  0045 D loss:-0.428 G loss:-2.48\n",
      "Epoch:  0045 D loss:-0.6002 G loss:-2.221\n",
      "Epoch:  0045 D loss:-0.6673 G loss:-2.364\n",
      "Epoch:  0045 D loss:-0.5064 G loss:-2.487\n",
      "Epoch:  0045 D loss:-0.5325 G loss:-2.276\n",
      "Epoch:  0045 D loss:-0.5548 G loss:-2.166\n",
      "Epoch:  0045 D loss:-0.5724 G loss:-2.147\n",
      "Epoch:  0045 D loss:-0.5315 G loss:-2.499\n",
      "Epoch:  0045 D loss:-0.6264 G loss:-2.325\n",
      "Epoch:  0045 D loss:-0.6328 G loss:-2.595\n",
      "Epoch:  0045 D loss:-0.6673 G loss:-2.211\n",
      "Epoch:  0045 D loss:-0.5624 G loss:-2.433\n",
      "Epoch:  0045 D loss:-0.4419 G loss:-2.398\n",
      "Epoch:  0045 D loss:-0.4297 G loss:-2.61\n",
      "Epoch:  0045 D loss:-0.5754 G loss:-2.434\n",
      "Epoch:  0045 D loss:-0.6255 G loss:-2.361\n",
      "Epoch:  0045 D loss:-0.4824 G loss:-2.245\n",
      "Epoch:  0045 D loss:-0.4163 G loss:-2.323\n",
      "Epoch:  0045 D loss:-0.601 G loss:-2.469\n",
      "Epoch:  0045 D loss:-0.5176 G loss:-2.432\n",
      "Epoch:  0045 D loss:-0.5044 G loss:-2.47\n",
      "Epoch:  0045 D loss:-0.5515 G loss:-2.278\n",
      "Epoch:  0045 D loss:-0.5104 G loss:-2.293\n",
      "Epoch:  0045 D loss:-0.488 G loss:-2.519\n",
      "Epoch:  0045 D loss:-0.6219 G loss:-2.256\n",
      "Epoch:  0045 D loss:-0.4823 G loss:-2.261\n",
      "Epoch:  0045 D loss:-0.5532 G loss:-2.415\n",
      "Epoch:  0045 D loss:-0.5497 G loss:-2.349\n",
      "Epoch:  0045 D loss:-0.4464 G loss:-2.389\n",
      "Epoch:  0045 D loss:-0.6182 G loss:-2.445\n",
      "Epoch:  0045 D loss:-0.5627 G loss:-2.13\n",
      "Epoch:  0045 D loss:-0.4533 G loss:-2.365\n",
      "Epoch:  0045 D loss:-0.5356 G loss:-2.338\n",
      "Epoch:  0045 D loss:-0.5809 G loss:-2.39\n",
      "Epoch:  0045 D loss:-0.5214 G loss:-2.31\n",
      "Epoch:  0045 D loss:-0.6581 G loss:-2.331\n",
      "Epoch:  0045 D loss:-0.5306 G loss:-2.215\n",
      "Epoch:  0045 D loss:-0.5771 G loss:-2.047\n",
      "Epoch:  0045 D loss:-0.5386 G loss:-2.089\n",
      "Epoch:  0045 D loss:-0.6411 G loss:-1.953\n",
      "Epoch:  0045 D loss:-0.6925 G loss:-2.052\n",
      "Epoch:  0045 D loss:-0.6332 G loss:-2.172\n",
      "Epoch:  0045 D loss:-0.4569 G loss:-2.264\n",
      "Epoch:  0045 D loss:-0.5373 G loss:-2.252\n",
      "Epoch:  0045 D loss:-0.7696 G loss:-2.211\n",
      "Epoch:  0045 D loss:-0.5901 G loss:-2.262\n",
      "Epoch:  0045 D loss:-0.5383 G loss:-2.371\n",
      "Epoch:  0045 D loss:-0.5885 G loss:-2.52\n",
      "Epoch:  0045 D loss:-0.5658 G loss:-2.539\n",
      "Epoch:  0045 D loss:-0.6039 G loss:-2.323\n",
      "Epoch:  0045 D loss:-0.7058 G loss:-2.271\n",
      "Epoch:  0045 D loss:-0.7187 G loss:-2.16\n",
      "Epoch:  0045 D loss:-0.6719 G loss:-2.165\n",
      "Epoch:  0045 D loss:-0.5391 G loss:-1.981\n",
      "Epoch:  0045 D loss:-0.5486 G loss:-1.865\n",
      "Epoch:  0045 D loss:-0.6078 G loss:-2.181\n",
      "Epoch:  0045 D loss:-0.7584 G loss:-1.995\n",
      "Epoch:  0045 D loss:-0.6807 G loss:-1.867\n",
      "Epoch:  0045 D loss:-0.56 G loss:-2.102\n",
      "Epoch:  0045 D loss:-0.6663 G loss:-2.043\n",
      "Epoch:  0045 D loss:-0.6441 G loss:-1.984\n",
      "Epoch:  0045 D loss:-0.602 G loss:-2.281\n",
      "Epoch:  0045 D loss:-0.6332 G loss:-2.16\n",
      "Epoch:  0045 D loss:-0.6887 G loss:-2.197\n",
      "Epoch:  0045 D loss:-0.5146 G loss:-2.494\n",
      "Epoch:  0045 D loss:-0.6297 G loss:-2.491\n",
      "Epoch:  0045 D loss:-0.548 G loss:-2.45\n",
      "Epoch:  0045 D loss:-0.5984 G loss:-2.672\n",
      "Epoch:  0045 D loss:-0.5607 G loss:-2.413\n",
      "Epoch:  0045 D loss:-0.5054 G loss:-2.364\n",
      "Epoch:  0045 D loss:-0.5287 G loss:-2.401\n",
      "Epoch:  0045 D loss:-0.6094 G loss:-2.433\n",
      "Epoch:  0045 D loss:-0.6037 G loss:-2.203\n",
      "Epoch:  0045 D loss:-0.5147 G loss:-2.027\n",
      "Epoch:  0045 D loss:-0.5943 G loss:-2.237\n",
      "Epoch:  0045 D loss:-0.4711 G loss:-2.136\n",
      "Epoch:  0045 D loss:-0.5973 G loss:-2.196\n",
      "Epoch:  0045 D loss:-0.6579 G loss:-2.334\n",
      "Epoch:  0045 D loss:-0.5473 G loss:-2.32\n",
      "Epoch:  0045 D loss:-0.5701 G loss:-2.303\n",
      "Epoch:  0045 D loss:-0.6458 G loss:-2.195\n",
      "Epoch:  0045 D loss:-0.5834 G loss:-2.266\n",
      "Epoch:  0045 D loss:-0.5834 G loss:-2.097\n",
      "Epoch:  0045 D loss:-0.6217 G loss:-2.236\n",
      "Epoch:  0045 D loss:-0.463 G loss:-2.314\n",
      "Epoch:  0045 D loss:-0.7103 G loss:-2.115\n",
      "Epoch:  0045 D loss:-0.4746 G loss:-2.293\n",
      "Epoch:  0045 D loss:-0.5665 G loss:-2.114\n",
      "Epoch:  0045 D loss:-0.7608 G loss:-2.22\n",
      "Epoch:  0045 D loss:-0.5893 G loss:-1.953\n",
      "Epoch:  0045 D loss:-0.5078 G loss:-2.069\n",
      "Epoch:  0045 D loss:-0.649 G loss:-1.997\n",
      "Epoch:  0045 D loss:-0.5296 G loss:-2.272\n",
      "Epoch:  0045 D loss:-0.5622 G loss:-2.242\n",
      "Epoch:  0045 D loss:-0.6613 G loss:-2.106\n",
      "Epoch:  0045 D loss:-0.7224 G loss:-2.043\n",
      "Epoch:  0045 D loss:-0.5745 G loss:-2.258\n",
      "Epoch:  0045 D loss:-0.4605 G loss:-2.386\n",
      "Epoch:  0045 D loss:-0.4638 G loss:-2.213\n",
      "Epoch:  0045 D loss:-0.6569 G loss:-2.212\n",
      "Epoch:  0045 D loss:-0.6082 G loss:-2.728\n",
      "Epoch:  0045 D loss:-0.6978 G loss:-2.262\n",
      "Epoch:  0045 D loss:-0.6164 G loss:-2.225\n",
      "Epoch:  0045 D loss:-0.6793 G loss:-2.382\n",
      "Epoch:  0045 D loss:-0.6312 G loss:-2.159\n",
      "Epoch:  0045 D loss:-0.5879 G loss:-2.174\n",
      "Epoch:  0045 D loss:-0.6625 G loss:-2.194\n",
      "Epoch:  0045 D loss:-0.6865 G loss:-2.174\n",
      "Epoch:  0045 D loss:-0.5739 G loss:-2.029\n",
      "Epoch:  0045 D loss:-0.5342 G loss:-1.967\n",
      "Epoch:  0045 D loss:-0.6117 G loss:-1.971\n",
      "Epoch:  0045 D loss:-0.7549 G loss:-2.06\n",
      "Epoch:  0045 D loss:-0.6013 G loss:-2.24\n",
      "Epoch:  0045 D loss:-0.7013 G loss:-2.028\n",
      "Epoch:  0045 D loss:-0.6568 G loss:-2.282\n",
      "Epoch:  0045 D loss:-0.6995 G loss:-2.279\n",
      "Epoch:  0045 D loss:-0.5228 G loss:-2.227\n",
      "Epoch:  0045 D loss:-0.6384 G loss:-2.235\n",
      "Epoch:  0045 D loss:-0.7091 G loss:-2.319\n",
      "Epoch:  0045 D loss:-0.6408 G loss:-2.102\n",
      "Epoch:  0045 D loss:-0.5607 G loss:-2.233\n",
      "Epoch:  0045 D loss:-0.6793 G loss:-2.153\n",
      "Epoch:  0045 D loss:-0.7357 G loss:-2.34\n",
      "Epoch:  0045 D loss:-0.5706 G loss:-2.31\n",
      "Epoch:  0045 D loss:-0.5658 G loss:-2.171\n",
      "Epoch:  0045 D loss:-0.5276 G loss:-2.391\n",
      "Epoch:  0045 D loss:-0.6662 G loss:-2.337\n",
      "Epoch:  0045 D loss:-0.6742 G loss:-2.167\n",
      "Epoch:  0045 D loss:-0.6282 G loss:-2.296\n",
      "Epoch:  0045 D loss:-0.6844 G loss:-2.212\n",
      "Epoch:  0045 D loss:-0.5946 G loss:-2.121\n",
      "Epoch:  0045 D loss:-0.7559 G loss:-1.875\n",
      "Epoch:  0045 D loss:-0.6358 G loss:-2.105\n",
      "Epoch:  0045 D loss:-0.5363 G loss:-2.117\n",
      "Epoch:  0045 D loss:-0.5362 G loss:-2.175\n",
      "Epoch:  0045 D loss:-0.5327 G loss:-2.377\n",
      "Epoch:  0045 D loss:-0.6298 G loss:-2.356\n",
      "Epoch:  0045 D loss:-0.6971 G loss:-2.061\n",
      "Epoch:  0045 D loss:-0.5765 G loss:-2.141\n",
      "Epoch:  0045 D loss:-0.5622 G loss:-2.273\n",
      "Epoch:  0045 D loss:-0.6164 G loss:-2.335\n",
      "Epoch:  0045 D loss:-0.686 G loss:-2.362\n",
      "Epoch:  0045 D loss:-0.6686 G loss:-2.254\n",
      "Epoch:  0045 D loss:-0.6681 G loss:-2.073\n",
      "Epoch:  0045 D loss:-0.547 G loss:-2.167\n",
      "Epoch:  0045 D loss:-0.7109 G loss:-2.097\n",
      "Epoch:  0045 D loss:-0.6258 G loss:-2.131\n",
      "Epoch:  0045 D loss:-0.615 G loss:-2.23\n",
      "Epoch:  0045 D loss:-0.6407 G loss:-1.986\n",
      "Epoch:  0045 D loss:-0.6026 G loss:-2.082\n",
      "Epoch:  0045 D loss:-0.5996 G loss:-2.118\n",
      "Epoch:  0045 D loss:-0.5489 G loss:-2.257\n",
      "Epoch:  0045 D loss:-0.5449 G loss:-2.239\n",
      "Epoch:  0045 D loss:-0.5176 G loss:-2.296\n",
      "Epoch:  0045 D loss:-0.7047 G loss:-2.239\n",
      "Epoch:  0045 D loss:-0.5204 G loss:-2.226\n",
      "Epoch:  0045 D loss:-0.6384 G loss:-2.086\n",
      "Epoch:  0045 D loss:-0.679 G loss:-2.111\n",
      "Epoch:  0045 D loss:-0.5759 G loss:-2.295\n",
      "Epoch:  0045 D loss:-0.5614 G loss:-2.442\n",
      "Epoch:  0045 D loss:-0.6217 G loss:-2.556\n",
      "Epoch:  0045 D loss:-0.5624 G loss:-2.293\n",
      "Epoch:  0045 D loss:-0.4878 G loss:-2.453\n",
      "Epoch:  0045 D loss:-0.5891 G loss:-2.112\n",
      "Epoch:  0045 D loss:-0.6876 G loss:-2.374\n",
      "Epoch:  0045 D loss:-0.5827 G loss:-2.096\n",
      "Epoch:  0045 D loss:-0.5541 G loss:-2.218\n",
      "Epoch:  0045 D loss:-0.6401 G loss:-2.132\n",
      "Epoch:  0045 D loss:-0.5703 G loss:-2.228\n",
      "Epoch:  0045 D loss:-0.5519 G loss:-2.257\n",
      "Epoch:  0045 D loss:-0.8118 G loss:-2.127\n",
      "Epoch:  0045 D loss:-0.5498 G loss:-2.195\n",
      "Epoch:  0045 D loss:-0.5965 G loss:-2.123\n",
      "Epoch:  0045 D loss:-0.7062 G loss:-1.914\n",
      "Epoch:  0045 D loss:-0.5702 G loss:-2.132\n",
      "Epoch:  0045 D loss:-0.61 G loss:-2.054\n",
      "Epoch:  0045 D loss:-0.5954 G loss:-2.199\n",
      "Epoch:  0045 D loss:-0.6229 G loss:-2.055\n",
      "Epoch:  0045 D loss:-0.6452 G loss:-2.436\n",
      "Epoch:  0045 D loss:-0.4858 G loss:-2.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0045 D loss:-0.606 G loss:-2.304\n",
      "Epoch:  0045 D loss:-0.4764 G loss:-2.529\n",
      "Epoch:  0045 D loss:-0.6656 G loss:-2.405\n",
      "Epoch:  0045 D loss:-0.6609 G loss:-2.294\n",
      "Epoch:  0045 D loss:-0.5956 G loss:-2.271\n",
      "Epoch:  0045 D loss:-0.601 G loss:-2.451\n",
      "Epoch:  0045 D loss:-0.5906 G loss:-2.329\n",
      "Epoch:  0045 D loss:-0.5917 G loss:-2.186\n",
      "Epoch:  0045 D loss:-0.5508 G loss:-2.284\n",
      "Epoch:  0045 D loss:-0.5193 G loss:-2.131\n",
      "Epoch:  0045 D loss:-0.5222 G loss:-2.242\n",
      "Epoch:  0045 D loss:-0.6628 G loss:-2.26\n",
      "Epoch:  0045 D loss:-0.6144 G loss:-2.104\n",
      "Epoch:  0045 D loss:-0.7719 G loss:-2.127\n",
      "Epoch:  0045 D loss:-0.6494 G loss:-2.247\n",
      "Epoch:  0045 D loss:-0.6474 G loss:-2.11\n",
      "Epoch:  0045 D loss:-0.663 G loss:-2.253\n",
      "Epoch:  0045 D loss:-0.6042 G loss:-2.239\n",
      "Epoch:  0045 D loss:-0.6668 G loss:-2.397\n",
      "Epoch:  0046 D loss:-0.6129 G loss:-2.196\n",
      "Epoch:  0046 D loss:-0.5511 G loss:-2.356\n",
      "Epoch:  0046 D loss:-0.5141 G loss:-2.42\n",
      "Epoch:  0046 D loss:-0.5793 G loss:-2.26\n",
      "Epoch:  0046 D loss:-0.4855 G loss:-2.334\n",
      "Epoch:  0046 D loss:-0.6885 G loss:-2.152\n",
      "Epoch:  0046 D loss:-0.6175 G loss:-2.058\n",
      "Epoch:  0046 D loss:-0.6469 G loss:-2.18\n",
      "Epoch:  0046 D loss:-0.5032 G loss:-2.354\n",
      "Epoch:  0046 D loss:-0.6152 G loss:-2.201\n",
      "Epoch:  0046 D loss:-0.5394 G loss:-2.562\n",
      "Epoch:  0046 D loss:-0.5023 G loss:-2.326\n",
      "Epoch:  0046 D loss:-0.5813 G loss:-2.457\n",
      "Epoch:  0046 D loss:-0.5438 G loss:-2.204\n",
      "Epoch:  0046 D loss:-0.4369 G loss:-2.292\n",
      "Epoch:  0046 D loss:-0.5705 G loss:-2.145\n",
      "Epoch:  0046 D loss:-0.6171 G loss:-2.035\n",
      "Epoch:  0046 D loss:-0.6173 G loss:-2.131\n",
      "Epoch:  0046 D loss:-0.5868 G loss:-2.277\n",
      "Epoch:  0046 D loss:-0.6068 G loss:-2.284\n",
      "Epoch:  0046 D loss:-0.6026 G loss:-2.149\n",
      "Epoch:  0046 D loss:-0.5979 G loss:-2.248\n",
      "Epoch:  0046 D loss:-0.5369 G loss:-2.478\n",
      "Epoch:  0046 D loss:-0.5678 G loss:-2.314\n",
      "Epoch:  0046 D loss:-0.5921 G loss:-2.5\n",
      "Epoch:  0046 D loss:-0.6344 G loss:-2.332\n",
      "Epoch:  0046 D loss:-0.6135 G loss:-2.318\n",
      "Epoch:  0046 D loss:-0.6658 G loss:-1.996\n",
      "Epoch:  0046 D loss:-0.5558 G loss:-2.304\n",
      "Epoch:  0046 D loss:-0.638 G loss:-2.248\n",
      "Epoch:  0046 D loss:-0.6642 G loss:-2.218\n",
      "Epoch:  0046 D loss:-0.5736 G loss:-2.132\n",
      "Epoch:  0046 D loss:-0.6683 G loss:-2.127\n",
      "Epoch:  0046 D loss:-0.5737 G loss:-2.266\n",
      "Epoch:  0046 D loss:-0.6194 G loss:-2.216\n",
      "Epoch:  0046 D loss:-0.6627 G loss:-2.109\n",
      "Epoch:  0046 D loss:-0.6591 G loss:-2.016\n",
      "Epoch:  0046 D loss:-0.6547 G loss:-2.091\n",
      "Epoch:  0046 D loss:-0.6039 G loss:-1.954\n",
      "Epoch:  0046 D loss:-0.4933 G loss:-2.267\n",
      "Epoch:  0046 D loss:-0.5873 G loss:-2.079\n",
      "Epoch:  0046 D loss:-0.5691 G loss:-2.332\n",
      "Epoch:  0046 D loss:-0.5887 G loss:-2.191\n",
      "Epoch:  0046 D loss:-0.7054 G loss:-2.235\n",
      "Epoch:  0046 D loss:-0.5348 G loss:-2.497\n",
      "Epoch:  0046 D loss:-0.7608 G loss:-2.345\n",
      "Epoch:  0046 D loss:-0.7787 G loss:-2.34\n",
      "Epoch:  0046 D loss:-0.509 G loss:-2.322\n",
      "Epoch:  0046 D loss:-0.7718 G loss:-2.248\n",
      "Epoch:  0046 D loss:-0.5825 G loss:-2.124\n",
      "Epoch:  0046 D loss:-0.6103 G loss:-2.146\n",
      "Epoch:  0046 D loss:-0.4964 G loss:-2.281\n",
      "Epoch:  0046 D loss:-0.4623 G loss:-2.222\n",
      "Epoch:  0046 D loss:-0.6915 G loss:-2.134\n",
      "Epoch:  0046 D loss:-0.6287 G loss:-2.167\n",
      "Epoch:  0046 D loss:-0.779 G loss:-1.869\n",
      "Epoch:  0046 D loss:-0.6668 G loss:-2.131\n",
      "Epoch:  0046 D loss:-0.5692 G loss:-2.266\n",
      "Epoch:  0046 D loss:-0.5786 G loss:-1.888\n",
      "Epoch:  0046 D loss:-0.7536 G loss:-1.9\n",
      "Epoch:  0046 D loss:-0.6747 G loss:-2.159\n",
      "Epoch:  0046 D loss:-0.6278 G loss:-2.117\n",
      "Epoch:  0046 D loss:-0.6239 G loss:-2.149\n",
      "Epoch:  0046 D loss:-0.5377 G loss:-2.288\n",
      "Epoch:  0046 D loss:-0.5052 G loss:-2.302\n",
      "Epoch:  0046 D loss:-0.6009 G loss:-2.139\n",
      "Epoch:  0046 D loss:-0.5475 G loss:-2.344\n",
      "Epoch:  0046 D loss:-0.5959 G loss:-2.028\n",
      "Epoch:  0046 D loss:-0.6962 G loss:-2.334\n",
      "Epoch:  0046 D loss:-0.5608 G loss:-2.339\n",
      "Epoch:  0046 D loss:-0.4922 G loss:-2.135\n",
      "Epoch:  0046 D loss:-0.6546 G loss:-2.301\n",
      "Epoch:  0046 D loss:-0.5999 G loss:-2.1\n",
      "Epoch:  0046 D loss:-0.5764 G loss:-2.048\n",
      "Epoch:  0046 D loss:-0.6341 G loss:-2.151\n",
      "Epoch:  0046 D loss:-0.5356 G loss:-2.457\n",
      "Epoch:  0046 D loss:-0.6276 G loss:-2.22\n",
      "Epoch:  0046 D loss:-0.5411 G loss:-2.205\n",
      "Epoch:  0046 D loss:-0.5543 G loss:-2.317\n",
      "Epoch:  0046 D loss:-0.5057 G loss:-2.283\n",
      "Epoch:  0046 D loss:-0.5515 G loss:-2.279\n",
      "Epoch:  0046 D loss:-0.6054 G loss:-2.069\n",
      "Epoch:  0046 D loss:-0.7173 G loss:-2.054\n",
      "Epoch:  0046 D loss:-0.5567 G loss:-1.88\n",
      "Epoch:  0046 D loss:-0.5493 G loss:-2.194\n",
      "Epoch:  0046 D loss:-0.6135 G loss:-2.229\n",
      "Epoch:  0046 D loss:-0.557 G loss:-2.124\n",
      "Epoch:  0046 D loss:-0.6041 G loss:-2.255\n",
      "Epoch:  0046 D loss:-0.5925 G loss:-2.263\n",
      "Epoch:  0046 D loss:-0.5447 G loss:-2.098\n",
      "Epoch:  0046 D loss:-0.5793 G loss:-2.18\n",
      "Epoch:  0046 D loss:-0.5131 G loss:-2.405\n",
      "Epoch:  0046 D loss:-0.5018 G loss:-2.289\n",
      "Epoch:  0046 D loss:-0.5798 G loss:-2.093\n",
      "Epoch:  0046 D loss:-0.6096 G loss:-2.361\n",
      "Epoch:  0046 D loss:-0.5842 G loss:-2.502\n",
      "Epoch:  0046 D loss:-0.5572 G loss:-2.417\n",
      "Epoch:  0046 D loss:-0.5672 G loss:-2.089\n",
      "Epoch:  0046 D loss:-0.4338 G loss:-2.415\n",
      "Epoch:  0046 D loss:-0.6055 G loss:-2.387\n",
      "Epoch:  0046 D loss:-0.5688 G loss:-2.42\n",
      "Epoch:  0046 D loss:-0.5008 G loss:-2.662\n",
      "Epoch:  0046 D loss:-0.6819 G loss:-2.246\n",
      "Epoch:  0046 D loss:-0.5055 G loss:-2.482\n",
      "Epoch:  0046 D loss:-0.5958 G loss:-2.068\n",
      "Epoch:  0046 D loss:-0.6269 G loss:-2.121\n",
      "Epoch:  0046 D loss:-0.5196 G loss:-2.202\n",
      "Epoch:  0046 D loss:-0.6651 G loss:-1.95\n",
      "Epoch:  0046 D loss:-0.6889 G loss:-2.122\n",
      "Epoch:  0046 D loss:-0.5274 G loss:-2.168\n",
      "Epoch:  0046 D loss:-0.6494 G loss:-2.113\n",
      "Epoch:  0046 D loss:-0.6546 G loss:-2.169\n",
      "Epoch:  0046 D loss:-0.5646 G loss:-2.28\n",
      "Epoch:  0046 D loss:-0.6319 G loss:-2.235\n",
      "Epoch:  0046 D loss:-0.4959 G loss:-2.267\n",
      "Epoch:  0046 D loss:-0.4912 G loss:-2.321\n",
      "Epoch:  0046 D loss:-0.5857 G loss:-2.227\n",
      "Epoch:  0046 D loss:-0.6688 G loss:-2.346\n",
      "Epoch:  0046 D loss:-0.5694 G loss:-2.286\n",
      "Epoch:  0046 D loss:-0.6218 G loss:-2.175\n",
      "Epoch:  0046 D loss:-0.7073 G loss:-2.052\n",
      "Epoch:  0046 D loss:-0.5669 G loss:-2.34\n",
      "Epoch:  0046 D loss:-0.7395 G loss:-1.994\n",
      "Epoch:  0046 D loss:-0.6265 G loss:-2.288\n",
      "Epoch:  0046 D loss:-0.5587 G loss:-2.289\n",
      "Epoch:  0046 D loss:-0.5714 G loss:-1.995\n",
      "Epoch:  0046 D loss:-0.5548 G loss:-2.171\n",
      "Epoch:  0046 D loss:-0.5277 G loss:-2.195\n",
      "Epoch:  0046 D loss:-0.5496 G loss:-2.242\n",
      "Epoch:  0046 D loss:-0.5909 G loss:-2.321\n",
      "Epoch:  0046 D loss:-0.5448 G loss:-2.477\n",
      "Epoch:  0046 D loss:-0.6904 G loss:-2.365\n",
      "Epoch:  0046 D loss:-0.5314 G loss:-2.319\n",
      "Epoch:  0046 D loss:-0.6177 G loss:-2.437\n",
      "Epoch:  0046 D loss:-0.6047 G loss:-2.437\n",
      "Epoch:  0046 D loss:-0.5353 G loss:-2.428\n",
      "Epoch:  0046 D loss:-0.5886 G loss:-2.276\n",
      "Epoch:  0046 D loss:-0.5913 G loss:-2.331\n",
      "Epoch:  0046 D loss:-0.5876 G loss:-2.163\n",
      "Epoch:  0046 D loss:-0.6056 G loss:-2.019\n",
      "Epoch:  0046 D loss:-0.6451 G loss:-1.875\n",
      "Epoch:  0046 D loss:-0.5181 G loss:-2.277\n",
      "Epoch:  0046 D loss:-0.5323 G loss:-1.972\n",
      "Epoch:  0046 D loss:-0.6763 G loss:-1.999\n",
      "Epoch:  0046 D loss:-0.5631 G loss:-2.431\n",
      "Epoch:  0046 D loss:-0.5665 G loss:-2.333\n",
      "Epoch:  0046 D loss:-0.5818 G loss:-2.525\n",
      "Epoch:  0046 D loss:-0.4966 G loss:-2.449\n",
      "Epoch:  0046 D loss:-0.5403 G loss:-2.649\n",
      "Epoch:  0046 D loss:-0.4974 G loss:-2.523\n",
      "Epoch:  0046 D loss:-0.6853 G loss:-2.443\n",
      "Epoch:  0046 D loss:-0.578 G loss:-2.692\n",
      "Epoch:  0046 D loss:-0.6615 G loss:-2.239\n",
      "Epoch:  0046 D loss:-0.6347 G loss:-2.374\n",
      "Epoch:  0046 D loss:-0.6176 G loss:-2.287\n",
      "Epoch:  0046 D loss:-0.6365 G loss:-2.239\n",
      "Epoch:  0046 D loss:-0.5254 G loss:-2.197\n",
      "Epoch:  0046 D loss:-0.4652 G loss:-2.298\n",
      "Epoch:  0046 D loss:-0.5902 G loss:-1.884\n",
      "Epoch:  0046 D loss:-0.6493 G loss:-1.782\n",
      "Epoch:  0046 D loss:-0.5572 G loss:-2.114\n",
      "Epoch:  0046 D loss:-0.5308 G loss:-2.071\n",
      "Epoch:  0046 D loss:-0.5888 G loss:-2.335\n",
      "Epoch:  0046 D loss:-0.6221 G loss:-2.332\n",
      "Epoch:  0046 D loss:-0.5607 G loss:-2.187\n",
      "Epoch:  0046 D loss:-0.6617 G loss:-2.2\n",
      "Epoch:  0046 D loss:-0.4758 G loss:-2.566\n",
      "Epoch:  0046 D loss:-0.5699 G loss:-2.358\n",
      "Epoch:  0046 D loss:-0.5261 G loss:-2.431\n",
      "Epoch:  0046 D loss:-0.6142 G loss:-2.578\n",
      "Epoch:  0046 D loss:-0.6243 G loss:-2.444\n",
      "Epoch:  0046 D loss:-0.8305 G loss:-2.104\n",
      "Epoch:  0046 D loss:-0.5829 G loss:-2.21\n",
      "Epoch:  0046 D loss:-0.5448 G loss:-2.208\n",
      "Epoch:  0046 D loss:-0.5579 G loss:-2.266\n",
      "Epoch:  0046 D loss:-0.5849 G loss:-2.321\n",
      "Epoch:  0046 D loss:-0.5436 G loss:-2.062\n",
      "Epoch:  0046 D loss:-0.609 G loss:-2.223\n",
      "Epoch:  0046 D loss:-0.5953 G loss:-2.267\n",
      "Epoch:  0046 D loss:-0.6171 G loss:-2.043\n",
      "Epoch:  0046 D loss:-0.5951 G loss:-2.217\n",
      "Epoch:  0046 D loss:-0.5851 G loss:-2.535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0046 D loss:-0.7698 G loss:-2.374\n",
      "Epoch:  0046 D loss:-0.6067 G loss:-2.146\n",
      "Epoch:  0046 D loss:-0.5177 G loss:-2.208\n",
      "Epoch:  0046 D loss:-0.6021 G loss:-2.148\n",
      "Epoch:  0046 D loss:-0.59 G loss:-1.986\n",
      "Epoch:  0046 D loss:-0.6226 G loss:-2.201\n",
      "Epoch:  0046 D loss:-0.656 G loss:-2.078\n",
      "Epoch:  0046 D loss:-0.682 G loss:-2.263\n",
      "Epoch:  0046 D loss:-0.6715 G loss:-2.145\n",
      "Epoch:  0046 D loss:-0.7152 G loss:-2.011\n",
      "Epoch:  0046 D loss:-0.6246 G loss:-2.283\n",
      "Epoch:  0046 D loss:-0.5881 G loss:-2.414\n",
      "Epoch:  0046 D loss:-0.6278 G loss:-2.229\n",
      "Epoch:  0046 D loss:-0.6899 G loss:-2.205\n",
      "Epoch:  0046 D loss:-0.7974 G loss:-2.142\n",
      "Epoch:  0046 D loss:-0.7166 G loss:-1.979\n",
      "Epoch:  0046 D loss:-0.6483 G loss:-1.952\n",
      "Epoch:  0046 D loss:-0.5992 G loss:-2.264\n",
      "Epoch:  0046 D loss:-0.7965 G loss:-1.923\n",
      "Epoch:  0046 D loss:-0.6782 G loss:-1.94\n",
      "Epoch:  0046 D loss:-0.6126 G loss:-2.318\n",
      "Epoch:  0046 D loss:-0.6973 G loss:-2.107\n",
      "Epoch:  0046 D loss:-0.662 G loss:-1.98\n",
      "Epoch:  0046 D loss:-0.6921 G loss:-2.174\n",
      "Epoch:  0046 D loss:-0.6269 G loss:-1.905\n",
      "Epoch:  0046 D loss:-0.6415 G loss:-2.086\n",
      "Epoch:  0046 D loss:-0.669 G loss:-2.211\n",
      "Epoch:  0046 D loss:-0.6106 G loss:-2.04\n",
      "Epoch:  0046 D loss:-0.6708 G loss:-2.069\n",
      "Epoch:  0046 D loss:-0.664 G loss:-2.14\n",
      "Epoch:  0046 D loss:-0.5744 G loss:-2.416\n",
      "Epoch:  0046 D loss:-0.6393 G loss:-2.292\n",
      "Epoch:  0046 D loss:-0.6044 G loss:-2.419\n",
      "Epoch:  0046 D loss:-0.6291 G loss:-2.405\n",
      "Epoch:  0046 D loss:-0.7171 G loss:-2.496\n",
      "Epoch:  0046 D loss:-0.8498 G loss:-2.107\n",
      "Epoch:  0046 D loss:-0.5929 G loss:-2.093\n",
      "Epoch:  0046 D loss:-0.6902 G loss:-1.963\n",
      "Epoch:  0046 D loss:-0.6438 G loss:-1.944\n",
      "Epoch:  0046 D loss:-0.6554 G loss:-1.999\n",
      "Epoch:  0046 D loss:-0.673 G loss:-1.888\n",
      "Epoch:  0046 D loss:-0.5344 G loss:-1.981\n",
      "Epoch:  0046 D loss:-0.6529 G loss:-1.918\n",
      "Epoch:  0046 D loss:-0.6235 G loss:-1.952\n",
      "Epoch:  0046 D loss:-0.5542 G loss:-2.047\n",
      "Epoch:  0046 D loss:-0.5353 G loss:-2.099\n",
      "Epoch:  0046 D loss:-0.5512 G loss:-2.16\n",
      "Epoch:  0046 D loss:-0.6145 G loss:-2.191\n",
      "Epoch:  0046 D loss:-0.6281 G loss:-2.295\n",
      "Epoch:  0046 D loss:-0.7814 G loss:-2.26\n",
      "Epoch:  0046 D loss:-0.7834 G loss:-2.315\n",
      "Epoch:  0046 D loss:-0.6113 G loss:-2.493\n",
      "Epoch:  0046 D loss:-0.5858 G loss:-2.475\n",
      "Epoch:  0046 D loss:-0.6141 G loss:-2.338\n",
      "Epoch:  0046 D loss:-0.5434 G loss:-2.212\n",
      "Epoch:  0046 D loss:-0.7434 G loss:-2.148\n",
      "Epoch:  0046 D loss:-0.6697 G loss:-2.037\n",
      "Epoch:  0046 D loss:-0.7966 G loss:-1.957\n",
      "Epoch:  0046 D loss:-0.8537 G loss:-1.794\n",
      "Epoch:  0046 D loss:-0.6457 G loss:-1.881\n",
      "Epoch:  0046 D loss:-0.6542 G loss:-2.018\n",
      "Epoch:  0046 D loss:-0.637 G loss:-2.021\n",
      "Epoch:  0046 D loss:-0.7165 G loss:-1.963\n",
      "Epoch:  0046 D loss:-0.631 G loss:-2.147\n",
      "Epoch:  0046 D loss:-0.7238 G loss:-2.295\n",
      "Epoch:  0046 D loss:-0.6985 G loss:-2.229\n",
      "Epoch:  0046 D loss:-0.6461 G loss:-2.268\n",
      "Epoch:  0046 D loss:-0.6465 G loss:-2.091\n",
      "Epoch:  0046 D loss:-0.743 G loss:-2.144\n",
      "Epoch:  0046 D loss:-0.6114 G loss:-2.165\n",
      "Epoch:  0046 D loss:-0.55 G loss:-2.089\n",
      "Epoch:  0046 D loss:-0.7483 G loss:-2.014\n",
      "Epoch:  0046 D loss:-0.6605 G loss:-1.976\n",
      "Epoch:  0046 D loss:-0.7251 G loss:-2.118\n",
      "Epoch:  0046 D loss:-0.5834 G loss:-1.888\n",
      "Epoch:  0046 D loss:-0.5376 G loss:-2.128\n",
      "Epoch:  0046 D loss:-0.6296 G loss:-1.968\n",
      "Epoch:  0046 D loss:-0.5736 G loss:-2.039\n",
      "Epoch:  0046 D loss:-0.591 G loss:-2.059\n",
      "Epoch:  0046 D loss:-0.5938 G loss:-2.041\n",
      "Epoch:  0046 D loss:-0.6108 G loss:-2.231\n",
      "Epoch:  0046 D loss:-0.6527 G loss:-2.343\n",
      "Epoch:  0046 D loss:-0.6052 G loss:-2.396\n",
      "Epoch:  0046 D loss:-0.7588 G loss:-2.744\n",
      "Epoch:  0046 D loss:-0.7078 G loss:-2.445\n",
      "Epoch:  0046 D loss:-0.5872 G loss:-2.171\n",
      "Epoch:  0046 D loss:-0.6459 G loss:-2.118\n",
      "Epoch:  0046 D loss:-0.7112 G loss:-2.273\n",
      "Epoch:  0046 D loss:-0.6352 G loss:-2.328\n",
      "Epoch:  0046 D loss:-0.6074 G loss:-2.317\n",
      "Epoch:  0046 D loss:-0.783 G loss:-2.078\n",
      "Epoch:  0046 D loss:-0.6739 G loss:-2.084\n",
      "Epoch:  0046 D loss:-0.6332 G loss:-2.149\n",
      "Epoch:  0046 D loss:-0.5756 G loss:-1.967\n",
      "Epoch:  0046 D loss:-0.5774 G loss:-2.068\n",
      "Epoch:  0046 D loss:-0.541 G loss:-2.077\n",
      "Epoch:  0046 D loss:-0.6182 G loss:-2.069\n",
      "Epoch:  0046 D loss:-0.6725 G loss:-2.274\n",
      "Epoch:  0046 D loss:-0.5531 G loss:-2.26\n",
      "Epoch:  0046 D loss:-0.6517 G loss:-2.139\n",
      "Epoch:  0046 D loss:-0.4737 G loss:-2.372\n",
      "Epoch:  0046 D loss:-0.6784 G loss:-2.293\n",
      "Epoch:  0046 D loss:-0.5853 G loss:-2.367\n",
      "Epoch:  0046 D loss:-0.6297 G loss:-2.495\n",
      "Epoch:  0046 D loss:-0.6216 G loss:-2.36\n",
      "Epoch:  0046 D loss:-0.5547 G loss:-2.325\n",
      "Epoch:  0046 D loss:-0.6797 G loss:-2.255\n",
      "Epoch:  0046 D loss:-0.5738 G loss:-2.431\n",
      "Epoch:  0046 D loss:-0.5491 G loss:-2.199\n",
      "Epoch:  0046 D loss:-0.567 G loss:-2.274\n",
      "Epoch:  0046 D loss:-0.6823 G loss:-2.134\n",
      "Epoch:  0046 D loss:-0.5039 G loss:-2.114\n",
      "Epoch:  0046 D loss:-0.5948 G loss:-2.081\n",
      "Epoch:  0046 D loss:-0.4133 G loss:-2.429\n",
      "Epoch:  0046 D loss:-0.5914 G loss:-2.328\n",
      "Epoch:  0046 D loss:-0.5587 G loss:-2.356\n",
      "Epoch:  0046 D loss:-0.6895 G loss:-2.018\n",
      "Epoch:  0046 D loss:-0.5976 G loss:-2.229\n",
      "Epoch:  0046 D loss:-0.5027 G loss:-2.051\n",
      "Epoch:  0046 D loss:-0.601 G loss:-2.134\n",
      "Epoch:  0046 D loss:-0.6298 G loss:-2.323\n",
      "Epoch:  0046 D loss:-0.588 G loss:-2.361\n",
      "Epoch:  0046 D loss:-0.5094 G loss:-2.373\n",
      "Epoch:  0046 D loss:-0.5428 G loss:-2.322\n",
      "Epoch:  0046 D loss:-0.5779 G loss:-2.208\n",
      "Epoch:  0046 D loss:-0.6448 G loss:-2.337\n",
      "Epoch:  0046 D loss:-0.68 G loss:-2.051\n",
      "Epoch:  0046 D loss:-0.5229 G loss:-2.024\n",
      "Epoch:  0046 D loss:-0.4403 G loss:-2.345\n",
      "Epoch:  0046 D loss:-0.647 G loss:-2.234\n",
      "Epoch:  0046 D loss:-0.6063 G loss:-2.089\n",
      "Epoch:  0046 D loss:-0.6279 G loss:-2.513\n",
      "Epoch:  0046 D loss:-0.4131 G loss:-2.495\n",
      "Epoch:  0046 D loss:-0.4683 G loss:-2.525\n",
      "Epoch:  0046 D loss:-0.6694 G loss:-2.429\n",
      "Epoch:  0046 D loss:-0.5499 G loss:-2.34\n",
      "Epoch:  0046 D loss:-0.5616 G loss:-2.425\n",
      "Epoch:  0046 D loss:-0.5165 G loss:-2.44\n",
      "Epoch:  0046 D loss:-0.6418 G loss:-2.394\n",
      "Epoch:  0046 D loss:-0.6594 G loss:-2.113\n",
      "Epoch:  0046 D loss:-0.6499 G loss:-2.362\n",
      "Epoch:  0046 D loss:-0.6083 G loss:-2.234\n",
      "Epoch:  0046 D loss:-0.6432 G loss:-2.173\n",
      "Epoch:  0046 D loss:-0.5924 G loss:-2.022\n",
      "Epoch:  0046 D loss:-0.4781 G loss:-2.176\n",
      "Epoch:  0046 D loss:-0.479 G loss:-2.271\n",
      "Epoch:  0046 D loss:-0.5875 G loss:-2.005\n",
      "Epoch:  0046 D loss:-0.5189 G loss:-2.095\n",
      "Epoch:  0046 D loss:-0.5185 G loss:-2.161\n",
      "Epoch:  0046 D loss:-0.5791 G loss:-2.203\n",
      "Epoch:  0046 D loss:-0.5721 G loss:-2.23\n",
      "Epoch:  0046 D loss:-0.6478 G loss:-2.239\n",
      "Epoch:  0046 D loss:-0.533 G loss:-2.331\n",
      "Epoch:  0046 D loss:-0.6434 G loss:-2.429\n",
      "Epoch:  0046 D loss:-0.6233 G loss:-2.443\n",
      "Epoch:  0046 D loss:-0.5604 G loss:-2.378\n",
      "Epoch:  0046 D loss:-0.5126 G loss:-2.486\n",
      "Epoch:  0046 D loss:-0.6097 G loss:-2.405\n",
      "Epoch:  0046 D loss:-0.6261 G loss:-2.354\n",
      "Epoch:  0046 D loss:-0.6036 G loss:-2.323\n",
      "Epoch:  0046 D loss:-0.5622 G loss:-2.294\n",
      "Epoch:  0046 D loss:-0.52 G loss:-2.131\n",
      "Epoch:  0046 D loss:-0.5719 G loss:-2.182\n",
      "Epoch:  0046 D loss:-0.5874 G loss:-2.026\n",
      "Epoch:  0046 D loss:-0.7354 G loss:-2.087\n",
      "Epoch:  0046 D loss:-0.6392 G loss:-2.201\n",
      "Epoch:  0046 D loss:-0.6433 G loss:-2.299\n",
      "Epoch:  0046 D loss:-0.5008 G loss:-2.471\n",
      "Epoch:  0046 D loss:-0.5128 G loss:-2.487\n",
      "Epoch:  0046 D loss:-0.6329 G loss:-2.354\n",
      "Epoch:  0046 D loss:-0.5258 G loss:-2.427\n",
      "Epoch:  0046 D loss:-0.596 G loss:-2.564\n",
      "Epoch:  0046 D loss:-0.7363 G loss:-2.319\n",
      "Epoch:  0046 D loss:-0.8323 G loss:-2.209\n",
      "Epoch:  0046 D loss:-0.6003 G loss:-2.228\n",
      "Epoch:  0046 D loss:-0.7282 G loss:-2.145\n",
      "Epoch:  0046 D loss:-0.7181 G loss:-2.004\n",
      "Epoch:  0046 D loss:-0.5235 G loss:-2.154\n",
      "Epoch:  0046 D loss:-0.6082 G loss:-1.994\n",
      "Epoch:  0046 D loss:-0.6785 G loss:-1.953\n",
      "Epoch:  0046 D loss:-0.6897 G loss:-1.97\n",
      "Epoch:  0046 D loss:-0.805 G loss:-1.845\n",
      "Epoch:  0046 D loss:-0.6527 G loss:-1.859\n",
      "Epoch:  0046 D loss:-0.6629 G loss:-2.072\n",
      "Epoch:  0046 D loss:-0.7472 G loss:-2.322\n",
      "Epoch:  0046 D loss:-0.7553 G loss:-2.133\n",
      "Epoch:  0046 D loss:-0.5862 G loss:-2.068\n",
      "Epoch:  0046 D loss:-0.6744 G loss:-2.326\n",
      "Epoch:  0046 D loss:-0.7195 G loss:-2.37\n",
      "Epoch:  0046 D loss:-0.8072 G loss:-2.097\n",
      "Epoch:  0046 D loss:-0.871 G loss:-2.029\n",
      "Epoch:  0046 D loss:-0.6478 G loss:-2.166\n",
      "Epoch:  0046 D loss:-0.6996 G loss:-2.302\n",
      "Epoch:  0046 D loss:-0.7061 G loss:-1.92\n",
      "Epoch:  0046 D loss:-0.867 G loss:-1.916\n",
      "Epoch:  0046 D loss:-0.6658 G loss:-1.904\n",
      "Epoch:  0046 D loss:-0.6426 G loss:-2.305\n",
      "Epoch:  0046 D loss:-0.6492 G loss:-2.011\n",
      "Epoch:  0046 D loss:-0.7712 G loss:-1.913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0046 D loss:-0.6838 G loss:-2.046\n",
      "Epoch:  0046 D loss:-0.6488 G loss:-1.957\n",
      "Epoch:  0046 D loss:-0.7504 G loss:-1.841\n",
      "Epoch:  0046 D loss:-0.8639 G loss:-2.058\n",
      "Epoch:  0046 D loss:-0.7567 G loss:-2.02\n",
      "Epoch:  0046 D loss:-0.7649 G loss:-2.056\n",
      "Epoch:  0046 D loss:-0.8838 G loss:-1.97\n",
      "Epoch:  0046 D loss:-0.6434 G loss:-1.91\n",
      "Epoch:  0046 D loss:-0.7333 G loss:-2.019\n",
      "Epoch:  0046 D loss:-0.7089 G loss:-1.897\n",
      "Epoch:  0046 D loss:-0.6795 G loss:-2.047\n",
      "Epoch:  0046 D loss:-0.8887 G loss:-1.66\n",
      "Epoch:  0046 D loss:-0.7436 G loss:-1.874\n",
      "Epoch:  0046 D loss:-0.7345 G loss:-1.968\n",
      "Epoch:  0046 D loss:-0.7409 G loss:-1.984\n",
      "Epoch:  0046 D loss:-0.8371 G loss:-1.78\n",
      "Epoch:  0046 D loss:-0.7427 G loss:-2.146\n",
      "Epoch:  0046 D loss:-0.6944 G loss:-2.164\n",
      "Epoch:  0046 D loss:-0.6647 G loss:-2.211\n",
      "Epoch:  0046 D loss:-0.6298 G loss:-2.105\n",
      "Epoch:  0046 D loss:-0.8106 G loss:-2.036\n",
      "Epoch:  0046 D loss:-0.6954 G loss:-2.014\n",
      "Epoch:  0046 D loss:-0.6652 G loss:-2.222\n",
      "Epoch:  0046 D loss:-0.6408 G loss:-2.236\n",
      "Epoch:  0046 D loss:-0.6031 G loss:-2.261\n",
      "Epoch:  0046 D loss:-0.7168 G loss:-2.158\n",
      "Epoch:  0046 D loss:-0.6804 G loss:-2.112\n",
      "Epoch:  0046 D loss:-0.5939 G loss:-2.065\n",
      "Epoch:  0046 D loss:-0.7541 G loss:-1.958\n",
      "Epoch:  0046 D loss:-0.7514 G loss:-1.953\n",
      "Epoch:  0046 D loss:-0.7554 G loss:-2.113\n",
      "Epoch:  0046 D loss:-0.6348 G loss:-1.977\n",
      "Epoch:  0046 D loss:-0.7263 G loss:-1.913\n",
      "Epoch:  0046 D loss:-0.6017 G loss:-2.069\n",
      "Epoch:  0046 D loss:-0.6269 G loss:-1.973\n",
      "Epoch:  0046 D loss:-0.7204 G loss:-2.017\n",
      "Epoch:  0046 D loss:-0.7356 G loss:-2.136\n",
      "Epoch:  0046 D loss:-0.7161 G loss:-2.168\n",
      "Epoch:  0046 D loss:-0.6969 G loss:-2.147\n",
      "Epoch:  0046 D loss:-0.7137 G loss:-2.041\n",
      "Epoch:  0046 D loss:-0.6256 G loss:-2.382\n",
      "Epoch:  0046 D loss:-0.5879 G loss:-2.304\n",
      "Epoch:  0046 D loss:-0.5414 G loss:-2.328\n",
      "Epoch:  0046 D loss:-0.5355 G loss:-2.245\n",
      "Epoch:  0046 D loss:-0.5667 G loss:-2.244\n",
      "Epoch:  0046 D loss:-0.6057 G loss:-2.025\n",
      "Epoch:  0046 D loss:-0.5797 G loss:-2.012\n",
      "Epoch:  0046 D loss:-0.6086 G loss:-2.119\n",
      "Epoch:  0046 D loss:-0.5433 G loss:-2.311\n",
      "Epoch:  0046 D loss:-0.6622 G loss:-2.248\n",
      "Epoch:  0046 D loss:-0.5411 G loss:-2.378\n",
      "Epoch:  0046 D loss:-0.6122 G loss:-2.5\n",
      "Epoch:  0046 D loss:-0.5569 G loss:-2.102\n",
      "Epoch:  0046 D loss:-0.4342 G loss:-2.381\n",
      "Epoch:  0046 D loss:-0.5565 G loss:-2.158\n",
      "Epoch:  0046 D loss:-0.7323 G loss:-2.56\n",
      "Epoch:  0046 D loss:-0.6222 G loss:-2.462\n",
      "Epoch:  0046 D loss:-0.574 G loss:-2.176\n",
      "Epoch:  0046 D loss:-0.5729 G loss:-2.313\n",
      "Epoch:  0046 D loss:-0.561 G loss:-2.513\n",
      "Epoch:  0046 D loss:-0.5222 G loss:-2.374\n",
      "Epoch:  0046 D loss:-0.6212 G loss:-2.355\n",
      "Epoch:  0046 D loss:-0.584 G loss:-2.342\n",
      "Epoch:  0046 D loss:-0.4748 G loss:-2.189\n",
      "Epoch:  0046 D loss:-0.6258 G loss:-2.296\n",
      "Epoch:  0046 D loss:-0.5412 G loss:-2.353\n",
      "Epoch:  0046 D loss:-0.6436 G loss:-2.436\n",
      "Epoch:  0046 D loss:-0.6467 G loss:-2.195\n",
      "Epoch:  0046 D loss:-0.7447 G loss:-2.014\n",
      "Epoch:  0046 D loss:-0.5173 G loss:-2.2\n",
      "Epoch:  0046 D loss:-0.5993 G loss:-2.299\n",
      "Epoch:  0046 D loss:-0.653 G loss:-2.133\n",
      "Epoch:  0046 D loss:-0.4879 G loss:-2.28\n",
      "Epoch:  0046 D loss:-0.6695 G loss:-2.381\n",
      "Epoch:  0046 D loss:-0.6195 G loss:-2.303\n",
      "Epoch:  0046 D loss:-0.6191 G loss:-2.257\n",
      "Epoch:  0046 D loss:-0.4723 G loss:-2.415\n",
      "Epoch:  0046 D loss:-0.6441 G loss:-2.412\n",
      "Epoch:  0046 D loss:-0.525 G loss:-2.465\n",
      "Epoch:  0046 D loss:-0.7015 G loss:-2.047\n",
      "Epoch:  0046 D loss:-0.7381 G loss:-2.213\n",
      "Epoch:  0046 D loss:-0.5421 G loss:-2.251\n",
      "Epoch:  0046 D loss:-0.595 G loss:-2.183\n",
      "Epoch:  0046 D loss:-0.4622 G loss:-2.238\n",
      "Epoch:  0046 D loss:-0.5394 G loss:-2.16\n",
      "Epoch:  0046 D loss:-0.7257 G loss:-2.004\n",
      "Epoch:  0046 D loss:-0.5753 G loss:-2.186\n",
      "Epoch:  0046 D loss:-0.6145 G loss:-2.113\n",
      "Epoch:  0046 D loss:-0.6877 G loss:-2.051\n",
      "Epoch:  0046 D loss:-0.6215 G loss:-2.296\n",
      "Epoch:  0046 D loss:-0.616 G loss:-2.134\n",
      "Epoch:  0046 D loss:-0.6289 G loss:-2.181\n",
      "Epoch:  0046 D loss:-0.6184 G loss:-2.356\n",
      "Epoch:  0046 D loss:-0.5471 G loss:-2.462\n",
      "Epoch:  0046 D loss:-0.6256 G loss:-2.287\n",
      "Epoch:  0046 D loss:-0.6211 G loss:-2.277\n",
      "Epoch:  0046 D loss:-0.5368 G loss:-2.194\n",
      "Epoch:  0046 D loss:-0.6435 G loss:-2.146\n",
      "Epoch:  0046 D loss:-0.6343 G loss:-2.357\n",
      "Epoch:  0046 D loss:-0.5433 G loss:-2.369\n",
      "Epoch:  0046 D loss:-0.6856 G loss:-2.162\n",
      "Epoch:  0046 D loss:-0.6153 G loss:-2.268\n",
      "Epoch:  0046 D loss:-0.6859 G loss:-1.959\n",
      "Epoch:  0046 D loss:-0.7175 G loss:-2.14\n",
      "Epoch:  0046 D loss:-0.8009 G loss:-1.893\n",
      "Epoch:  0046 D loss:-0.4666 G loss:-2.212\n",
      "Epoch:  0046 D loss:-0.6375 G loss:-2.033\n",
      "Epoch:  0046 D loss:-0.6621 G loss:-2.09\n",
      "Epoch:  0046 D loss:-0.5683 G loss:-2.083\n",
      "Epoch:  0046 D loss:-0.7399 G loss:-2.123\n",
      "Epoch:  0046 D loss:-0.6365 G loss:-2.361\n",
      "Epoch:  0046 D loss:-0.7041 G loss:-2.147\n",
      "Epoch:  0046 D loss:-0.5765 G loss:-2.228\n",
      "Epoch:  0046 D loss:-0.6163 G loss:-2.222\n",
      "Epoch:  0046 D loss:-0.6058 G loss:-2.169\n",
      "Epoch:  0046 D loss:-0.616 G loss:-2.171\n",
      "Epoch:  0046 D loss:-0.7484 G loss:-2.31\n",
      "Epoch:  0046 D loss:-0.7594 G loss:-2.021\n",
      "Epoch:  0046 D loss:-0.5707 G loss:-2.066\n",
      "Epoch:  0046 D loss:-0.6586 G loss:-2.218\n",
      "Epoch:  0046 D loss:-0.5372 G loss:-2.244\n",
      "Epoch:  0046 D loss:-0.6084 G loss:-2.083\n",
      "Epoch:  0046 D loss:-0.6958 G loss:-1.955\n",
      "Epoch:  0046 D loss:-0.5696 G loss:-2.147\n",
      "Epoch:  0046 D loss:-0.6261 G loss:-2.123\n",
      "Epoch:  0046 D loss:-0.7297 G loss:-2.126\n",
      "Epoch:  0046 D loss:-0.539 G loss:-2.429\n",
      "Epoch:  0046 D loss:-0.5969 G loss:-2.239\n",
      "Epoch:  0046 D loss:-0.5881 G loss:-2.152\n",
      "Epoch:  0046 D loss:-0.6413 G loss:-2.206\n",
      "Epoch:  0046 D loss:-0.7511 G loss:-2.044\n",
      "Epoch:  0046 D loss:-0.5543 G loss:-2.035\n",
      "Epoch:  0046 D loss:-0.6706 G loss:-2.122\n",
      "Epoch:  0046 D loss:-0.6904 G loss:-1.961\n",
      "Epoch:  0046 D loss:-0.7687 G loss:-2.028\n",
      "Epoch:  0046 D loss:-0.7205 G loss:-2.31\n",
      "Epoch:  0046 D loss:-0.7481 G loss:-2.045\n",
      "Epoch:  0046 D loss:-0.66 G loss:-1.904\n",
      "Epoch:  0046 D loss:-0.6981 G loss:-1.981\n",
      "Epoch:  0046 D loss:-0.8467 G loss:-1.838\n",
      "Epoch:  0046 D loss:-0.6757 G loss:-1.949\n",
      "Epoch:  0046 D loss:-0.7384 G loss:-2.094\n",
      "Epoch:  0046 D loss:-0.7262 G loss:-2.158\n",
      "Epoch:  0046 D loss:-0.777 G loss:-2.081\n",
      "Epoch:  0046 D loss:-0.5441 G loss:-2.475\n",
      "Epoch:  0046 D loss:-0.6606 G loss:-2.116\n",
      "Epoch:  0046 D loss:-0.7326 G loss:-2.268\n",
      "Epoch:  0046 D loss:-0.653 G loss:-2.023\n",
      "Epoch:  0046 D loss:-0.563 G loss:-2.224\n",
      "Epoch:  0046 D loss:-0.6779 G loss:-1.931\n",
      "Epoch:  0046 D loss:-0.8285 G loss:-1.879\n",
      "Epoch:  0046 D loss:-0.6932 G loss:-2.096\n",
      "Epoch:  0046 D loss:-0.7052 G loss:-2.198\n",
      "Epoch:  0046 D loss:-0.6535 G loss:-1.892\n",
      "Epoch:  0046 D loss:-0.7677 G loss:-2.026\n",
      "Epoch:  0046 D loss:-0.6583 G loss:-1.872\n",
      "Epoch:  0046 D loss:-0.7174 G loss:-2.124\n",
      "Epoch:  0046 D loss:-0.5227 G loss:-2.016\n",
      "Epoch:  0046 D loss:-0.6976 G loss:-2.05\n",
      "Epoch:  0046 D loss:-0.6073 G loss:-1.971\n",
      "Epoch:  0046 D loss:-0.7477 G loss:-1.97\n",
      "Epoch:  0046 D loss:-0.6229 G loss:-2.06\n",
      "Epoch:  0046 D loss:-0.7776 G loss:-1.996\n",
      "Epoch:  0046 D loss:-0.7068 G loss:-2.213\n",
      "Epoch:  0046 D loss:-0.694 G loss:-2.263\n",
      "Epoch:  0046 D loss:-0.6514 G loss:-2.11\n",
      "Epoch:  0046 D loss:-0.7777 G loss:-2.252\n",
      "Epoch:  0046 D loss:-0.7679 G loss:-2.086\n",
      "Epoch:  0046 D loss:-0.695 G loss:-2.21\n",
      "Epoch:  0047 D loss:-0.5951 G loss:-1.987\n",
      "Epoch:  0047 D loss:-0.6531 G loss:-2.274\n",
      "Epoch:  0047 D loss:-0.6466 G loss:-2.005\n",
      "Epoch:  0047 D loss:-0.6795 G loss:-2.019\n",
      "Epoch:  0047 D loss:-0.6231 G loss:-1.972\n",
      "Epoch:  0047 D loss:-0.7784 G loss:-1.952\n",
      "Epoch:  0047 D loss:-0.7111 G loss:-1.85\n",
      "Epoch:  0047 D loss:-0.5147 G loss:-2.008\n",
      "Epoch:  0047 D loss:-0.7139 G loss:-1.739\n",
      "Epoch:  0047 D loss:-0.5985 G loss:-2.081\n",
      "Epoch:  0047 D loss:-0.6037 G loss:-2.306\n",
      "Epoch:  0047 D loss:-0.5167 G loss:-2.229\n",
      "Epoch:  0047 D loss:-0.7723 G loss:-2.308\n",
      "Epoch:  0047 D loss:-0.535 G loss:-2.372\n",
      "Epoch:  0047 D loss:-0.6113 G loss:-2.274\n",
      "Epoch:  0047 D loss:-0.5489 G loss:-2.492\n",
      "Epoch:  0047 D loss:-0.724 G loss:-2.153\n",
      "Epoch:  0047 D loss:-0.6888 G loss:-2.494\n",
      "Epoch:  0047 D loss:-0.6176 G loss:-2.259\n",
      "Epoch:  0047 D loss:-0.6418 G loss:-2.265\n",
      "Epoch:  0047 D loss:-0.5586 G loss:-2.263\n",
      "Epoch:  0047 D loss:-0.6258 G loss:-2.111\n",
      "Epoch:  0047 D loss:-0.6239 G loss:-2.09\n",
      "Epoch:  0047 D loss:-0.657 G loss:-2.07\n",
      "Epoch:  0047 D loss:-0.6569 G loss:-1.944\n",
      "Epoch:  0047 D loss:-0.5648 G loss:-1.922\n",
      "Epoch:  0047 D loss:-0.6108 G loss:-2.006\n",
      "Epoch:  0047 D loss:-0.5761 G loss:-2.133\n",
      "Epoch:  0047 D loss:-0.5362 G loss:-2.144\n",
      "Epoch:  0047 D loss:-0.6646 G loss:-2.196\n",
      "Epoch:  0047 D loss:-0.6014 G loss:-2.11\n",
      "Epoch:  0047 D loss:-0.6673 G loss:-2.017\n",
      "Epoch:  0047 D loss:-0.5889 G loss:-2.149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0047 D loss:-0.5627 G loss:-2.072\n",
      "Epoch:  0047 D loss:-0.7941 G loss:-2.072\n",
      "Epoch:  0047 D loss:-0.5791 G loss:-2.323\n",
      "Epoch:  0047 D loss:-0.5094 G loss:-2.309\n",
      "Epoch:  0047 D loss:-0.6414 G loss:-2.132\n",
      "Epoch:  0047 D loss:-0.7546 G loss:-2.307\n",
      "Epoch:  0047 D loss:-0.574 G loss:-2.208\n",
      "Epoch:  0047 D loss:-0.675 G loss:-2.113\n",
      "Epoch:  0047 D loss:-0.5516 G loss:-2.241\n",
      "Epoch:  0047 D loss:-0.6382 G loss:-2.194\n",
      "Epoch:  0047 D loss:-0.5982 G loss:-2.144\n",
      "Epoch:  0047 D loss:-0.5882 G loss:-2.281\n",
      "Epoch:  0047 D loss:-0.613 G loss:-2.123\n",
      "Epoch:  0047 D loss:-0.6983 G loss:-2.206\n",
      "Epoch:  0047 D loss:-0.6653 G loss:-2.231\n",
      "Epoch:  0047 D loss:-0.6012 G loss:-2.021\n",
      "Epoch:  0047 D loss:-0.6681 G loss:-2.142\n",
      "Epoch:  0047 D loss:-0.5782 G loss:-2.451\n",
      "Epoch:  0047 D loss:-0.5329 G loss:-2.425\n",
      "Epoch:  0047 D loss:-0.5617 G loss:-2.208\n",
      "Epoch:  0047 D loss:-0.5786 G loss:-2.244\n",
      "Epoch:  0047 D loss:-0.5588 G loss:-2.163\n",
      "Epoch:  0047 D loss:-0.5668 G loss:-2.21\n",
      "Epoch:  0047 D loss:-0.6026 G loss:-2.317\n",
      "Epoch:  0047 D loss:-0.6875 G loss:-2.182\n",
      "Epoch:  0047 D loss:-0.6359 G loss:-2.307\n",
      "Epoch:  0047 D loss:-0.6464 G loss:-2.116\n",
      "Epoch:  0047 D loss:-0.6758 G loss:-2.322\n",
      "Epoch:  0047 D loss:-0.6101 G loss:-2.171\n",
      "Epoch:  0047 D loss:-0.6608 G loss:-2.071\n",
      "Epoch:  0047 D loss:-0.6074 G loss:-2.113\n",
      "Epoch:  0047 D loss:-0.5771 G loss:-2.084\n",
      "Epoch:  0047 D loss:-0.5203 G loss:-2.314\n",
      "Epoch:  0047 D loss:-0.6495 G loss:-2.188\n",
      "Epoch:  0047 D loss:-0.5249 G loss:-2.265\n",
      "Epoch:  0047 D loss:-0.7092 G loss:-2.022\n",
      "Epoch:  0047 D loss:-0.6055 G loss:-2.285\n",
      "Epoch:  0047 D loss:-0.5938 G loss:-2.418\n",
      "Epoch:  0047 D loss:-0.5666 G loss:-2.412\n",
      "Epoch:  0047 D loss:-0.5736 G loss:-2.203\n",
      "Epoch:  0047 D loss:-0.5467 G loss:-2.454\n",
      "Epoch:  0047 D loss:-0.5796 G loss:-2.385\n",
      "Epoch:  0047 D loss:-0.7466 G loss:-2.106\n",
      "Epoch:  0047 D loss:-0.5442 G loss:-2.308\n",
      "Epoch:  0047 D loss:-0.6868 G loss:-1.98\n",
      "Epoch:  0047 D loss:-0.5321 G loss:-2.136\n",
      "Epoch:  0047 D loss:-0.4945 G loss:-2.24\n",
      "Epoch:  0047 D loss:-0.5589 G loss:-2.186\n",
      "Epoch:  0047 D loss:-0.6652 G loss:-2.223\n",
      "Epoch:  0047 D loss:-0.6272 G loss:-2.286\n",
      "Epoch:  0047 D loss:-0.6671 G loss:-2.128\n",
      "Epoch:  0047 D loss:-0.7101 G loss:-2.187\n",
      "Epoch:  0047 D loss:-0.5471 G loss:-2.44\n",
      "Epoch:  0047 D loss:-0.6954 G loss:-2.242\n",
      "Epoch:  0047 D loss:-0.6593 G loss:-2.213\n",
      "Epoch:  0047 D loss:-0.7014 G loss:-2.331\n",
      "Epoch:  0047 D loss:-0.6265 G loss:-2.087\n",
      "Epoch:  0047 D loss:-0.5144 G loss:-2.282\n",
      "Epoch:  0047 D loss:-0.7056 G loss:-2.192\n",
      "Epoch:  0047 D loss:-0.5888 G loss:-2.042\n",
      "Epoch:  0047 D loss:-0.7226 G loss:-2.24\n",
      "Epoch:  0047 D loss:-0.6707 G loss:-2.412\n",
      "Epoch:  0047 D loss:-0.5029 G loss:-2.234\n",
      "Epoch:  0047 D loss:-0.5437 G loss:-2.214\n",
      "Epoch:  0047 D loss:-0.4611 G loss:-2.432\n",
      "Epoch:  0047 D loss:-0.6264 G loss:-2.262\n",
      "Epoch:  0047 D loss:-0.6545 G loss:-2.278\n",
      "Epoch:  0047 D loss:-0.7483 G loss:-2.086\n",
      "Epoch:  0047 D loss:-0.6719 G loss:-2.223\n",
      "Epoch:  0047 D loss:-0.4969 G loss:-2.452\n",
      "Epoch:  0047 D loss:-0.5891 G loss:-2.333\n",
      "Epoch:  0047 D loss:-0.5392 G loss:-2.269\n",
      "Epoch:  0047 D loss:-0.5758 G loss:-2.276\n",
      "Epoch:  0047 D loss:-0.4522 G loss:-2.359\n",
      "Epoch:  0047 D loss:-0.64 G loss:-2.259\n",
      "Epoch:  0047 D loss:-0.4858 G loss:-2.314\n",
      "Epoch:  0047 D loss:-0.6246 G loss:-2.267\n",
      "Epoch:  0047 D loss:-0.5941 G loss:-2.408\n",
      "Epoch:  0047 D loss:-0.5085 G loss:-2.284\n",
      "Epoch:  0047 D loss:-0.5744 G loss:-2.419\n",
      "Epoch:  0047 D loss:-0.4492 G loss:-2.553\n",
      "Epoch:  0047 D loss:-0.617 G loss:-2.221\n",
      "Epoch:  0047 D loss:-0.6434 G loss:-2.18\n",
      "Epoch:  0047 D loss:-0.5301 G loss:-2.29\n",
      "Epoch:  0047 D loss:-0.6682 G loss:-2.274\n",
      "Epoch:  0047 D loss:-0.7555 G loss:-2.087\n",
      "Epoch:  0047 D loss:-0.5792 G loss:-2.045\n",
      "Epoch:  0047 D loss:-0.6961 G loss:-1.893\n",
      "Epoch:  0047 D loss:-0.644 G loss:-2.021\n",
      "Epoch:  0047 D loss:-0.592 G loss:-2.268\n",
      "Epoch:  0047 D loss:-0.643 G loss:-2.272\n",
      "Epoch:  0047 D loss:-0.48 G loss:-2.381\n",
      "Epoch:  0047 D loss:-0.6651 G loss:-2.285\n",
      "Epoch:  0047 D loss:-0.6404 G loss:-2.149\n",
      "Epoch:  0047 D loss:-0.5754 G loss:-2.456\n",
      "Epoch:  0047 D loss:-0.5568 G loss:-2.337\n",
      "Epoch:  0047 D loss:-0.5646 G loss:-2.343\n",
      "Epoch:  0047 D loss:-0.6433 G loss:-2.264\n",
      "Epoch:  0047 D loss:-0.577 G loss:-2.148\n",
      "Epoch:  0047 D loss:-0.5748 G loss:-2.127\n",
      "Epoch:  0047 D loss:-0.5626 G loss:-1.957\n",
      "Epoch:  0047 D loss:-0.5377 G loss:-2.315\n",
      "Epoch:  0047 D loss:-0.7763 G loss:-2.006\n",
      "Epoch:  0047 D loss:-0.6326 G loss:-2.324\n",
      "Epoch:  0047 D loss:-0.5772 G loss:-2.054\n",
      "Epoch:  0047 D loss:-0.4962 G loss:-2.367\n",
      "Epoch:  0047 D loss:-0.6338 G loss:-2.402\n",
      "Epoch:  0047 D loss:-0.5559 G loss:-2.367\n",
      "Epoch:  0047 D loss:-0.6502 G loss:-2.339\n",
      "Epoch:  0047 D loss:-0.6098 G loss:-2.282\n",
      "Epoch:  0047 D loss:-0.5334 G loss:-2.325\n",
      "Epoch:  0047 D loss:-0.5737 G loss:-2.281\n",
      "Epoch:  0047 D loss:-0.6693 G loss:-2.31\n",
      "Epoch:  0047 D loss:-0.5202 G loss:-2.13\n",
      "Epoch:  0047 D loss:-0.6532 G loss:-2.187\n",
      "Epoch:  0047 D loss:-0.4635 G loss:-2.306\n",
      "Epoch:  0047 D loss:-0.6736 G loss:-1.982\n",
      "Epoch:  0047 D loss:-0.6459 G loss:-2.11\n",
      "Epoch:  0047 D loss:-0.8164 G loss:-2.037\n",
      "Epoch:  0047 D loss:-0.6539 G loss:-2.084\n",
      "Epoch:  0047 D loss:-0.6463 G loss:-2.2\n",
      "Epoch:  0047 D loss:-0.6741 G loss:-2.221\n",
      "Epoch:  0047 D loss:-0.7291 G loss:-2.189\n",
      "Epoch:  0047 D loss:-0.5123 G loss:-2.097\n",
      "Epoch:  0047 D loss:-0.6855 G loss:-2.114\n",
      "Epoch:  0047 D loss:-0.5927 G loss:-2.37\n",
      "Epoch:  0047 D loss:-0.5694 G loss:-2.335\n",
      "Epoch:  0047 D loss:-0.7319 G loss:-2.187\n",
      "Epoch:  0047 D loss:-0.7169 G loss:-2.232\n",
      "Epoch:  0047 D loss:-0.8274 G loss:-2.042\n",
      "Epoch:  0047 D loss:-0.5816 G loss:-2.147\n",
      "Epoch:  0047 D loss:-0.5198 G loss:-2.145\n",
      "Epoch:  0047 D loss:-0.6072 G loss:-2.238\n",
      "Epoch:  0047 D loss:-0.6276 G loss:-1.982\n",
      "Epoch:  0047 D loss:-0.6612 G loss:-2.245\n",
      "Epoch:  0047 D loss:-0.5211 G loss:-2.108\n",
      "Epoch:  0047 D loss:-0.8012 G loss:-1.943\n",
      "Epoch:  0047 D loss:-0.6651 G loss:-2.04\n",
      "Epoch:  0047 D loss:-0.6423 G loss:-2.073\n",
      "Epoch:  0047 D loss:-0.5952 G loss:-1.975\n",
      "Epoch:  0047 D loss:-0.7045 G loss:-1.911\n",
      "Epoch:  0047 D loss:-0.572 G loss:-2.263\n",
      "Epoch:  0047 D loss:-0.7374 G loss:-2.074\n",
      "Epoch:  0047 D loss:-0.7851 G loss:-2.313\n",
      "Epoch:  0047 D loss:-0.7017 G loss:-2.267\n",
      "Epoch:  0047 D loss:-0.5979 G loss:-2.024\n",
      "Epoch:  0047 D loss:-0.6465 G loss:-2.181\n",
      "Epoch:  0047 D loss:-0.6196 G loss:-2.366\n",
      "Epoch:  0047 D loss:-0.7042 G loss:-2.309\n",
      "Epoch:  0047 D loss:-0.6527 G loss:-2.252\n",
      "Epoch:  0047 D loss:-0.6049 G loss:-2.366\n",
      "Epoch:  0047 D loss:-0.5916 G loss:-2.559\n",
      "Epoch:  0047 D loss:-0.6293 G loss:-2.366\n",
      "Epoch:  0047 D loss:-0.6814 G loss:-2.226\n",
      "Epoch:  0047 D loss:-0.5287 G loss:-2.095\n",
      "Epoch:  0047 D loss:-0.7181 G loss:-1.895\n",
      "Epoch:  0047 D loss:-0.4915 G loss:-2.113\n",
      "Epoch:  0047 D loss:-0.6239 G loss:-2.053\n",
      "Epoch:  0047 D loss:-0.6169 G loss:-2.024\n",
      "Epoch:  0047 D loss:-0.3934 G loss:-2.359\n",
      "Epoch:  0047 D loss:-0.5972 G loss:-2.555\n",
      "Epoch:  0047 D loss:-0.601 G loss:-2.183\n",
      "Epoch:  0047 D loss:-0.5945 G loss:-2.2\n",
      "Epoch:  0047 D loss:-0.6821 G loss:-2.435\n",
      "Epoch:  0047 D loss:-0.5941 G loss:-2.394\n",
      "Epoch:  0047 D loss:-0.6179 G loss:-2.284\n",
      "Epoch:  0047 D loss:-0.6842 G loss:-2.255\n",
      "Epoch:  0047 D loss:-0.7779 G loss:-2.173\n",
      "Epoch:  0047 D loss:-0.5027 G loss:-2.23\n",
      "Epoch:  0047 D loss:-0.5998 G loss:-2.095\n",
      "Epoch:  0047 D loss:-0.7139 G loss:-2.081\n",
      "Epoch:  0047 D loss:-0.6179 G loss:-2.129\n",
      "Epoch:  0047 D loss:-0.6794 G loss:-2.061\n",
      "Epoch:  0047 D loss:-0.5552 G loss:-2.161\n",
      "Epoch:  0047 D loss:-0.6169 G loss:-2.077\n",
      "Epoch:  0047 D loss:-0.5538 G loss:-2.209\n",
      "Epoch:  0047 D loss:-0.5665 G loss:-2.182\n",
      "Epoch:  0047 D loss:-0.5536 G loss:-2.22\n",
      "Epoch:  0047 D loss:-0.6088 G loss:-2.538\n",
      "Epoch:  0047 D loss:-0.509 G loss:-2.378\n",
      "Epoch:  0047 D loss:-0.5445 G loss:-2.43\n",
      "Epoch:  0047 D loss:-0.5581 G loss:-2.256\n",
      "Epoch:  0047 D loss:-0.5022 G loss:-2.432\n",
      "Epoch:  0047 D loss:-0.4481 G loss:-2.383\n",
      "Epoch:  0047 D loss:-0.5557 G loss:-2.55\n",
      "Epoch:  0047 D loss:-0.5863 G loss:-2.511\n",
      "Epoch:  0047 D loss:-0.4897 G loss:-2.392\n",
      "Epoch:  0047 D loss:-0.526 G loss:-2.278\n",
      "Epoch:  0047 D loss:-0.5702 G loss:-2.327\n",
      "Epoch:  0047 D loss:-0.5176 G loss:-2.416\n",
      "Epoch:  0047 D loss:-0.5735 G loss:-2.286\n",
      "Epoch:  0047 D loss:-0.5751 G loss:-2.266\n",
      "Epoch:  0047 D loss:-0.6158 G loss:-2.091\n",
      "Epoch:  0047 D loss:-0.6151 G loss:-2.155\n",
      "Epoch:  0047 D loss:-0.5047 G loss:-2.119\n",
      "Epoch:  0047 D loss:-0.6264 G loss:-2.249\n",
      "Epoch:  0047 D loss:-0.5703 G loss:-2.191\n",
      "Epoch:  0047 D loss:-0.5296 G loss:-2.187\n",
      "Epoch:  0047 D loss:-0.5091 G loss:-2.236\n",
      "Epoch:  0047 D loss:-0.5163 G loss:-2.356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0047 D loss:-0.6597 G loss:-2.122\n",
      "Epoch:  0047 D loss:-0.5407 G loss:-2.413\n",
      "Epoch:  0047 D loss:-0.4861 G loss:-2.226\n",
      "Epoch:  0047 D loss:-0.521 G loss:-2.486\n",
      "Epoch:  0047 D loss:-0.6514 G loss:-2.391\n",
      "Epoch:  0047 D loss:-0.472 G loss:-2.533\n",
      "Epoch:  0047 D loss:-0.4448 G loss:-2.488\n",
      "Epoch:  0047 D loss:-0.4281 G loss:-2.427\n",
      "Epoch:  0047 D loss:-0.5839 G loss:-2.275\n",
      "Epoch:  0047 D loss:-0.6802 G loss:-2.207\n",
      "Epoch:  0047 D loss:-0.6734 G loss:-2.345\n",
      "Epoch:  0047 D loss:-0.609 G loss:-2.016\n",
      "Epoch:  0047 D loss:-0.5722 G loss:-2.153\n",
      "Epoch:  0047 D loss:-0.5422 G loss:-2.281\n",
      "Epoch:  0047 D loss:-0.686 G loss:-2.265\n",
      "Epoch:  0047 D loss:-0.6129 G loss:-1.995\n",
      "Epoch:  0047 D loss:-0.5725 G loss:-2.219\n",
      "Epoch:  0047 D loss:-0.5895 G loss:-2.285\n",
      "Epoch:  0047 D loss:-0.4729 G loss:-2.359\n",
      "Epoch:  0047 D loss:-0.4818 G loss:-2.51\n",
      "Epoch:  0047 D loss:-0.6159 G loss:-2.33\n",
      "Epoch:  0047 D loss:-0.5583 G loss:-2.313\n",
      "Epoch:  0047 D loss:-0.6398 G loss:-2.215\n",
      "Epoch:  0047 D loss:-0.538 G loss:-2.595\n",
      "Epoch:  0047 D loss:-0.6133 G loss:-2.242\n",
      "Epoch:  0047 D loss:-0.4997 G loss:-2.437\n",
      "Epoch:  0047 D loss:-0.5576 G loss:-2.216\n",
      "Epoch:  0047 D loss:-0.5393 G loss:-2.285\n",
      "Epoch:  0047 D loss:-0.5055 G loss:-2.359\n",
      "Epoch:  0047 D loss:-0.6189 G loss:-2.218\n",
      "Epoch:  0047 D loss:-0.5407 G loss:-2.041\n",
      "Epoch:  0047 D loss:-0.5551 G loss:-2.294\n",
      "Epoch:  0047 D loss:-0.5682 G loss:-2.268\n",
      "Epoch:  0047 D loss:-0.6593 G loss:-2.32\n",
      "Epoch:  0047 D loss:-0.5642 G loss:-2.235\n",
      "Epoch:  0047 D loss:-0.7 G loss:-2.176\n",
      "Epoch:  0047 D loss:-0.6081 G loss:-2.152\n",
      "Epoch:  0047 D loss:-0.6475 G loss:-1.997\n",
      "Epoch:  0047 D loss:-0.6744 G loss:-2.143\n",
      "Epoch:  0047 D loss:-0.6776 G loss:-2.167\n",
      "Epoch:  0047 D loss:-0.5879 G loss:-2.434\n",
      "Epoch:  0047 D loss:-0.5816 G loss:-2.569\n",
      "Epoch:  0047 D loss:-0.6001 G loss:-2.356\n",
      "Epoch:  0047 D loss:-0.6502 G loss:-2.655\n",
      "Epoch:  0047 D loss:-0.5708 G loss:-2.383\n",
      "Epoch:  0047 D loss:-0.6577 G loss:-2.251\n",
      "Epoch:  0047 D loss:-0.6305 G loss:-2.337\n",
      "Epoch:  0047 D loss:-0.6204 G loss:-2.315\n",
      "Epoch:  0047 D loss:-0.5829 G loss:-2.101\n",
      "Epoch:  0047 D loss:-0.4851 G loss:-2.199\n",
      "Epoch:  0047 D loss:-0.6421 G loss:-2.027\n",
      "Epoch:  0047 D loss:-0.5893 G loss:-1.995\n",
      "Epoch:  0047 D loss:-0.5352 G loss:-2.297\n",
      "Epoch:  0047 D loss:-0.5396 G loss:-2.195\n",
      "Epoch:  0047 D loss:-0.6966 G loss:-2.232\n",
      "Epoch:  0047 D loss:-0.7091 G loss:-2.405\n",
      "Epoch:  0047 D loss:-0.5469 G loss:-2.466\n",
      "Epoch:  0047 D loss:-0.6233 G loss:-2.338\n",
      "Epoch:  0047 D loss:-0.649 G loss:-2.445\n",
      "Epoch:  0047 D loss:-0.7161 G loss:-2.266\n",
      "Epoch:  0047 D loss:-0.5154 G loss:-2.342\n",
      "Epoch:  0047 D loss:-0.569 G loss:-2.434\n",
      "Epoch:  0047 D loss:-0.573 G loss:-2.57\n",
      "Epoch:  0047 D loss:-0.511 G loss:-2.344\n",
      "Epoch:  0047 D loss:-0.5746 G loss:-2.395\n",
      "Epoch:  0047 D loss:-0.585 G loss:-2.304\n",
      "Epoch:  0047 D loss:-0.5204 G loss:-2.445\n",
      "Epoch:  0047 D loss:-0.5803 G loss:-2.305\n",
      "Epoch:  0047 D loss:-0.5384 G loss:-2.317\n",
      "Epoch:  0047 D loss:-0.6256 G loss:-2.129\n",
      "Epoch:  0047 D loss:-0.5791 G loss:-2.11\n",
      "Epoch:  0047 D loss:-0.6036 G loss:-2.187\n",
      "Epoch:  0047 D loss:-0.5822 G loss:-2.004\n",
      "Epoch:  0047 D loss:-0.6357 G loss:-2.08\n",
      "Epoch:  0047 D loss:-0.6114 G loss:-1.982\n",
      "Epoch:  0047 D loss:-0.7813 G loss:-2.139\n",
      "Epoch:  0047 D loss:-0.5993 G loss:-2.358\n",
      "Epoch:  0047 D loss:-0.6233 G loss:-2.484\n",
      "Epoch:  0047 D loss:-0.7798 G loss:-2.12\n",
      "Epoch:  0047 D loss:-0.6449 G loss:-2.339\n",
      "Epoch:  0047 D loss:-0.6685 G loss:-2.278\n",
      "Epoch:  0047 D loss:-0.5105 G loss:-2.242\n",
      "Epoch:  0047 D loss:-0.5592 G loss:-2.231\n",
      "Epoch:  0047 D loss:-0.4671 G loss:-2.45\n",
      "Epoch:  0047 D loss:-0.6539 G loss:-2.214\n",
      "Epoch:  0047 D loss:-0.5541 G loss:-2.156\n",
      "Epoch:  0047 D loss:-0.515 G loss:-2.151\n",
      "Epoch:  0047 D loss:-0.6577 G loss:-2.219\n",
      "Epoch:  0047 D loss:-0.606 G loss:-2.047\n",
      "Epoch:  0047 D loss:-0.6464 G loss:-2.22\n",
      "Epoch:  0047 D loss:-0.6914 G loss:-2.172\n",
      "Epoch:  0047 D loss:-0.8374 G loss:-2.093\n",
      "Epoch:  0047 D loss:-0.5471 G loss:-2.276\n",
      "Epoch:  0047 D loss:-0.6502 G loss:-2.378\n",
      "Epoch:  0047 D loss:-0.5199 G loss:-2.457\n",
      "Epoch:  0047 D loss:-0.6066 G loss:-2.2\n",
      "Epoch:  0047 D loss:-0.6953 G loss:-2.178\n",
      "Epoch:  0047 D loss:-0.5369 G loss:-2.515\n",
      "Epoch:  0047 D loss:-0.7774 G loss:-2.085\n",
      "Epoch:  0047 D loss:-0.6007 G loss:-2.431\n",
      "Epoch:  0047 D loss:-0.6283 G loss:-2.153\n",
      "Epoch:  0047 D loss:-0.6671 G loss:-2.134\n",
      "Epoch:  0047 D loss:-0.5482 G loss:-2.122\n",
      "Epoch:  0047 D loss:-0.6742 G loss:-1.923\n",
      "Epoch:  0047 D loss:-0.5947 G loss:-2.169\n",
      "Epoch:  0047 D loss:-0.5008 G loss:-2.332\n",
      "Epoch:  0047 D loss:-0.573 G loss:-2.23\n",
      "Epoch:  0047 D loss:-0.6693 G loss:-2.25\n",
      "Epoch:  0047 D loss:-0.6248 G loss:-2.396\n",
      "Epoch:  0047 D loss:-0.6199 G loss:-2.256\n",
      "Epoch:  0047 D loss:-0.5306 G loss:-2.36\n",
      "Epoch:  0047 D loss:-0.672 G loss:-2.23\n",
      "Epoch:  0047 D loss:-0.5884 G loss:-2.499\n",
      "Epoch:  0047 D loss:-0.6191 G loss:-2.095\n",
      "Epoch:  0047 D loss:-0.7273 G loss:-2.199\n",
      "Epoch:  0047 D loss:-0.5861 G loss:-2.363\n",
      "Epoch:  0047 D loss:-0.6404 G loss:-2.18\n",
      "Epoch:  0047 D loss:-0.6644 G loss:-2.087\n",
      "Epoch:  0047 D loss:-0.5715 G loss:-2.174\n",
      "Epoch:  0047 D loss:-0.627 G loss:-2.18\n",
      "Epoch:  0047 D loss:-0.8166 G loss:-2.031\n",
      "Epoch:  0047 D loss:-0.6303 G loss:-1.909\n",
      "Epoch:  0047 D loss:-0.7289 G loss:-1.962\n",
      "Epoch:  0047 D loss:-0.617 G loss:-2.178\n",
      "Epoch:  0047 D loss:-0.7365 G loss:-1.988\n",
      "Epoch:  0047 D loss:-0.6218 G loss:-2.17\n",
      "Epoch:  0047 D loss:-0.6193 G loss:-2.437\n",
      "Epoch:  0047 D loss:-0.6449 G loss:-2.037\n",
      "Epoch:  0047 D loss:-0.5977 G loss:-2.495\n",
      "Epoch:  0047 D loss:-0.6948 G loss:-2.35\n",
      "Epoch:  0047 D loss:-0.5865 G loss:-2.243\n",
      "Epoch:  0047 D loss:-0.456 G loss:-2.782\n",
      "Epoch:  0047 D loss:-0.4843 G loss:-2.479\n",
      "Epoch:  0047 D loss:-0.5976 G loss:-2.351\n",
      "Epoch:  0047 D loss:-0.5506 G loss:-2.46\n",
      "Epoch:  0047 D loss:-0.5945 G loss:-2.296\n",
      "Epoch:  0047 D loss:-0.6858 G loss:-2.192\n",
      "Epoch:  0047 D loss:-0.6626 G loss:-2.194\n",
      "Epoch:  0047 D loss:-0.6955 G loss:-2.271\n",
      "Epoch:  0047 D loss:-0.5814 G loss:-2.289\n",
      "Epoch:  0047 D loss:-0.6423 G loss:-1.878\n",
      "Epoch:  0047 D loss:-0.5077 G loss:-2.214\n",
      "Epoch:  0047 D loss:-0.6751 G loss:-2.007\n",
      "Epoch:  0047 D loss:-0.5924 G loss:-2.152\n",
      "Epoch:  0047 D loss:-0.7803 G loss:-2.012\n",
      "Epoch:  0047 D loss:-0.5744 G loss:-1.992\n",
      "Epoch:  0047 D loss:-0.6151 G loss:-2.224\n",
      "Epoch:  0047 D loss:-0.6021 G loss:-2.058\n",
      "Epoch:  0047 D loss:-0.6301 G loss:-2.262\n",
      "Epoch:  0047 D loss:-0.6956 G loss:-2.4\n",
      "Epoch:  0047 D loss:-0.5936 G loss:-2.333\n",
      "Epoch:  0047 D loss:-0.669 G loss:-2.242\n",
      "Epoch:  0047 D loss:-0.6248 G loss:-2.104\n",
      "Epoch:  0047 D loss:-0.7012 G loss:-2.155\n",
      "Epoch:  0047 D loss:-0.5713 G loss:-2.419\n",
      "Epoch:  0047 D loss:-0.629 G loss:-2.06\n",
      "Epoch:  0047 D loss:-0.5654 G loss:-2.556\n",
      "Epoch:  0047 D loss:-0.6445 G loss:-2.233\n",
      "Epoch:  0047 D loss:-0.566 G loss:-2.549\n",
      "Epoch:  0047 D loss:-0.4635 G loss:-2.404\n",
      "Epoch:  0047 D loss:-0.5287 G loss:-2.361\n",
      "Epoch:  0047 D loss:-0.5761 G loss:-2.115\n",
      "Epoch:  0047 D loss:-0.5889 G loss:-1.967\n",
      "Epoch:  0047 D loss:-0.6321 G loss:-2.157\n",
      "Epoch:  0047 D loss:-0.6552 G loss:-2.282\n",
      "Epoch:  0047 D loss:-0.6698 G loss:-2.275\n",
      "Epoch:  0047 D loss:-0.7203 G loss:-2.156\n",
      "Epoch:  0047 D loss:-0.5086 G loss:-2.185\n",
      "Epoch:  0047 D loss:-0.5919 G loss:-2.164\n",
      "Epoch:  0047 D loss:-0.6595 G loss:-2.222\n",
      "Epoch:  0047 D loss:-0.6667 G loss:-2.274\n",
      "Epoch:  0047 D loss:-0.5822 G loss:-2.252\n",
      "Epoch:  0047 D loss:-0.5836 G loss:-2.215\n",
      "Epoch:  0047 D loss:-0.6007 G loss:-2.037\n",
      "Epoch:  0047 D loss:-0.6581 G loss:-2.115\n",
      "Epoch:  0047 D loss:-0.6972 G loss:-2.288\n",
      "Epoch:  0047 D loss:-0.6361 G loss:-2.06\n",
      "Epoch:  0047 D loss:-0.5982 G loss:-2.107\n",
      "Epoch:  0047 D loss:-0.7424 G loss:-1.837\n",
      "Epoch:  0047 D loss:-0.6704 G loss:-2.125\n",
      "Epoch:  0047 D loss:-0.6707 G loss:-1.983\n",
      "Epoch:  0047 D loss:-0.5583 G loss:-2.183\n",
      "Epoch:  0047 D loss:-0.5467 G loss:-2.12\n",
      "Epoch:  0047 D loss:-0.6034 G loss:-2.058\n",
      "Epoch:  0047 D loss:-0.7124 G loss:-2.419\n",
      "Epoch:  0047 D loss:-0.5989 G loss:-2.4\n",
      "Epoch:  0047 D loss:-0.5057 G loss:-2.451\n",
      "Epoch:  0047 D loss:-0.5745 G loss:-2.575\n",
      "Epoch:  0047 D loss:-0.7947 G loss:-2.185\n",
      "Epoch:  0047 D loss:-0.7423 G loss:-2.288\n",
      "Epoch:  0047 D loss:-0.5968 G loss:-2.134\n",
      "Epoch:  0047 D loss:-0.6761 G loss:-2.024\n",
      "Epoch:  0047 D loss:-0.5117 G loss:-2.061\n",
      "Epoch:  0047 D loss:-0.6621 G loss:-1.896\n",
      "Epoch:  0047 D loss:-0.6282 G loss:-1.902\n",
      "Epoch:  0047 D loss:-0.7509 G loss:-1.996\n",
      "Epoch:  0047 D loss:-0.6467 G loss:-1.979\n",
      "Epoch:  0047 D loss:-0.6006 G loss:-2.183\n",
      "Epoch:  0047 D loss:-0.4622 G loss:-2.249\n",
      "Epoch:  0047 D loss:-0.6395 G loss:-2.248\n",
      "Epoch:  0047 D loss:-0.6624 G loss:-2.292\n",
      "Epoch:  0047 D loss:-0.5617 G loss:-2.304\n",
      "Epoch:  0047 D loss:-0.5645 G loss:-2.387\n",
      "Epoch:  0047 D loss:-0.5556 G loss:-2.377\n",
      "Epoch:  0047 D loss:-0.603 G loss:-2.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0047 D loss:-0.4912 G loss:-2.336\n",
      "Epoch:  0047 D loss:-0.5151 G loss:-2.274\n",
      "Epoch:  0047 D loss:-0.6882 G loss:-2.268\n",
      "Epoch:  0047 D loss:-0.729 G loss:-2.31\n",
      "Epoch:  0047 D loss:-0.6707 G loss:-2.014\n",
      "Epoch:  0047 D loss:-0.6322 G loss:-2.049\n",
      "Epoch:  0047 D loss:-0.5796 G loss:-2.22\n",
      "Epoch:  0047 D loss:-0.5971 G loss:-2.276\n",
      "Epoch:  0047 D loss:-0.6435 G loss:-2.044\n",
      "Epoch:  0047 D loss:-0.4828 G loss:-2.089\n",
      "Epoch:  0047 D loss:-0.6383 G loss:-2.395\n",
      "Epoch:  0047 D loss:-0.5929 G loss:-2.165\n",
      "Epoch:  0047 D loss:-0.6156 G loss:-2.221\n",
      "Epoch:  0047 D loss:-0.647 G loss:-2.249\n",
      "Epoch:  0047 D loss:-0.6062 G loss:-2.284\n",
      "Epoch:  0047 D loss:-0.6793 G loss:-2.243\n",
      "Epoch:  0047 D loss:-0.6638 G loss:-2.141\n",
      "Epoch:  0047 D loss:-0.5753 G loss:-2.26\n",
      "Epoch:  0047 D loss:-0.5882 G loss:-2.027\n",
      "Epoch:  0047 D loss:-0.5896 G loss:-2.021\n",
      "Epoch:  0047 D loss:-0.5469 G loss:-2.059\n",
      "Epoch:  0047 D loss:-0.499 G loss:-2.16\n",
      "Epoch:  0047 D loss:-0.5237 G loss:-2.092\n",
      "Epoch:  0047 D loss:-0.5969 G loss:-1.994\n",
      "Epoch:  0047 D loss:-0.392 G loss:-2.501\n",
      "Epoch:  0047 D loss:-0.7233 G loss:-2.167\n",
      "Epoch:  0047 D loss:-0.6565 G loss:-2.3\n",
      "Epoch:  0047 D loss:-0.5779 G loss:-2.318\n",
      "Epoch:  0047 D loss:-0.5512 G loss:-2.259\n",
      "Epoch:  0047 D loss:-0.6313 G loss:-2.252\n",
      "Epoch:  0047 D loss:-0.546 G loss:-2.442\n",
      "Epoch:  0047 D loss:-0.6669 G loss:-2.24\n",
      "Epoch:  0047 D loss:-0.7157 G loss:-2.098\n",
      "Epoch:  0047 D loss:-0.5475 G loss:-1.986\n",
      "Epoch:  0047 D loss:-0.6283 G loss:-2.012\n",
      "Epoch:  0047 D loss:-0.5785 G loss:-2.062\n",
      "Epoch:  0047 D loss:-0.5687 G loss:-2.605\n",
      "Epoch:  0047 D loss:-0.5781 G loss:-2.165\n",
      "Epoch:  0047 D loss:-0.5639 G loss:-2.257\n",
      "Epoch:  0047 D loss:-0.5169 G loss:-2.197\n",
      "Epoch:  0047 D loss:-0.6257 G loss:-2.19\n",
      "Epoch:  0047 D loss:-0.532 G loss:-2.3\n",
      "Epoch:  0047 D loss:-0.5226 G loss:-2.298\n",
      "Epoch:  0047 D loss:-0.5448 G loss:-2.571\n",
      "Epoch:  0047 D loss:-0.651 G loss:-2.232\n",
      "Epoch:  0047 D loss:-0.6692 G loss:-2.223\n",
      "Epoch:  0047 D loss:-0.5466 G loss:-2.056\n",
      "Epoch:  0047 D loss:-0.6445 G loss:-2.182\n",
      "Epoch:  0047 D loss:-0.5461 G loss:-2.32\n",
      "Epoch:  0047 D loss:-0.6003 G loss:-2.353\n",
      "Epoch:  0047 D loss:-0.5925 G loss:-2.057\n",
      "Epoch:  0047 D loss:-0.6386 G loss:-2.233\n",
      "Epoch:  0047 D loss:-0.5901 G loss:-1.961\n",
      "Epoch:  0047 D loss:-0.5722 G loss:-2.205\n",
      "Epoch:  0047 D loss:-0.6249 G loss:-2.158\n",
      "Epoch:  0047 D loss:-0.5839 G loss:-2.056\n",
      "Epoch:  0047 D loss:-0.5117 G loss:-2.296\n",
      "Epoch:  0047 D loss:-0.3829 G loss:-2.378\n",
      "Epoch:  0047 D loss:-0.4897 G loss:-2.331\n",
      "Epoch:  0047 D loss:-0.6243 G loss:-2.152\n",
      "Epoch:  0047 D loss:-0.5333 G loss:-2.355\n",
      "Epoch:  0047 D loss:-0.5688 G loss:-2.331\n",
      "Epoch:  0047 D loss:-0.5337 G loss:-2.387\n",
      "Epoch:  0047 D loss:-0.6037 G loss:-2.383\n",
      "Epoch:  0047 D loss:-0.6318 G loss:-2.278\n",
      "Epoch:  0047 D loss:-0.5774 G loss:-2.423\n",
      "Epoch:  0047 D loss:-0.5854 G loss:-2.396\n",
      "Epoch:  0047 D loss:-0.6215 G loss:-2.242\n",
      "Epoch:  0047 D loss:-0.4219 G loss:-2.296\n",
      "Epoch:  0047 D loss:-0.5372 G loss:-2.208\n",
      "Epoch:  0047 D loss:-0.631 G loss:-2.193\n",
      "Epoch:  0047 D loss:-0.5699 G loss:-2.057\n",
      "Epoch:  0047 D loss:-0.7029 G loss:-2.065\n",
      "Epoch:  0047 D loss:-0.6362 G loss:-2.261\n",
      "Epoch:  0047 D loss:-0.5764 G loss:-2.19\n",
      "Epoch:  0047 D loss:-0.4971 G loss:-2.164\n",
      "Epoch:  0047 D loss:-0.5809 G loss:-2.175\n",
      "Epoch:  0047 D loss:-0.494 G loss:-2.166\n",
      "Epoch:  0047 D loss:-0.6106 G loss:-2.186\n",
      "Epoch:  0047 D loss:-0.4952 G loss:-2.282\n",
      "Epoch:  0047 D loss:-0.6111 G loss:-2.519\n",
      "Epoch:  0047 D loss:-0.608 G loss:-2.082\n",
      "Epoch:  0047 D loss:-0.4608 G loss:-2.297\n",
      "Epoch:  0047 D loss:-0.6249 G loss:-2.394\n",
      "Epoch:  0047 D loss:-0.5082 G loss:-2.42\n",
      "Epoch:  0047 D loss:-0.6356 G loss:-2.277\n",
      "Epoch:  0047 D loss:-0.5985 G loss:-2.208\n",
      "Epoch:  0047 D loss:-0.7217 G loss:-2.194\n",
      "Epoch:  0047 D loss:-0.5547 G loss:-2.065\n",
      "Epoch:  0047 D loss:-0.5285 G loss:-2.157\n",
      "Epoch:  0047 D loss:-0.6288 G loss:-2.112\n",
      "Epoch:  0047 D loss:-0.5066 G loss:-2.088\n",
      "Epoch:  0047 D loss:-0.5149 G loss:-2.093\n",
      "Epoch:  0047 D loss:-0.584 G loss:-2.329\n",
      "Epoch:  0047 D loss:-0.534 G loss:-2.221\n",
      "Epoch:  0047 D loss:-0.5123 G loss:-2.411\n",
      "Epoch:  0047 D loss:-0.6229 G loss:-2.34\n",
      "Epoch:  0047 D loss:-0.6256 G loss:-2.3\n",
      "Epoch:  0047 D loss:-0.5354 G loss:-2.454\n",
      "Epoch:  0047 D loss:-0.579 G loss:-2.408\n",
      "Epoch:  0047 D loss:-0.6131 G loss:-2.54\n",
      "Epoch:  0047 D loss:-0.5231 G loss:-2.294\n",
      "Epoch:  0047 D loss:-0.606 G loss:-2.209\n",
      "Epoch:  0047 D loss:-0.5342 G loss:-2.209\n",
      "Epoch:  0047 D loss:-0.468 G loss:-2.285\n",
      "Epoch:  0047 D loss:-0.703 G loss:-2.618\n",
      "Epoch:  0047 D loss:-0.6037 G loss:-2.428\n",
      "Epoch:  0047 D loss:-0.4844 G loss:-2.167\n",
      "Epoch:  0047 D loss:-0.749 G loss:-2.301\n",
      "Epoch:  0047 D loss:-0.5747 G loss:-2.228\n",
      "Epoch:  0047 D loss:-0.5096 G loss:-2.331\n",
      "Epoch:  0047 D loss:-0.6578 G loss:-2.273\n",
      "Epoch:  0048 D loss:-0.5565 G loss:-2.38\n",
      "Epoch:  0048 D loss:-0.5072 G loss:-2.26\n",
      "Epoch:  0048 D loss:-0.6777 G loss:-2.203\n",
      "Epoch:  0048 D loss:-0.5789 G loss:-2.176\n",
      "Epoch:  0048 D loss:-0.4998 G loss:-2.37\n",
      "Epoch:  0048 D loss:-0.5664 G loss:-2.328\n",
      "Epoch:  0048 D loss:-0.6398 G loss:-1.957\n",
      "Epoch:  0048 D loss:-0.6937 G loss:-2.29\n",
      "Epoch:  0048 D loss:-0.6507 G loss:-2.41\n",
      "Epoch:  0048 D loss:-0.5333 G loss:-2.332\n",
      "Epoch:  0048 D loss:-0.5023 G loss:-2.238\n",
      "Epoch:  0048 D loss:-0.5876 G loss:-2.191\n",
      "Epoch:  0048 D loss:-0.6665 G loss:-2.382\n",
      "Epoch:  0048 D loss:-0.6034 G loss:-2.102\n",
      "Epoch:  0048 D loss:-0.5574 G loss:-2.325\n",
      "Epoch:  0048 D loss:-0.5905 G loss:-2.064\n",
      "Epoch:  0048 D loss:-0.6811 G loss:-2.175\n",
      "Epoch:  0048 D loss:-0.5796 G loss:-2.389\n",
      "Epoch:  0048 D loss:-0.6356 G loss:-2.368\n",
      "Epoch:  0048 D loss:-0.5774 G loss:-2.322\n",
      "Epoch:  0048 D loss:-0.576 G loss:-2.378\n",
      "Epoch:  0048 D loss:-0.6907 G loss:-2.283\n",
      "Epoch:  0048 D loss:-0.6776 G loss:-2.133\n",
      "Epoch:  0048 D loss:-0.6596 G loss:-2.053\n",
      "Epoch:  0048 D loss:-0.5914 G loss:-2.205\n",
      "Epoch:  0048 D loss:-0.6564 G loss:-2.282\n",
      "Epoch:  0048 D loss:-0.6823 G loss:-2.154\n",
      "Epoch:  0048 D loss:-0.6611 G loss:-2.105\n",
      "Epoch:  0048 D loss:-0.6467 G loss:-2.091\n",
      "Epoch:  0048 D loss:-0.6764 G loss:-2.048\n",
      "Epoch:  0048 D loss:-0.7747 G loss:-1.985\n",
      "Epoch:  0048 D loss:-0.6924 G loss:-2.325\n",
      "Epoch:  0048 D loss:-0.5625 G loss:-2.38\n",
      "Epoch:  0048 D loss:-0.6074 G loss:-2.227\n",
      "Epoch:  0048 D loss:-0.5622 G loss:-2.296\n",
      "Epoch:  0048 D loss:-0.5945 G loss:-2.387\n",
      "Epoch:  0048 D loss:-0.6785 G loss:-2.061\n",
      "Epoch:  0048 D loss:-0.7632 G loss:-2.245\n",
      "Epoch:  0048 D loss:-0.6238 G loss:-2.268\n",
      "Epoch:  0048 D loss:-0.7285 G loss:-2.215\n",
      "Epoch:  0048 D loss:-0.6763 G loss:-2.226\n",
      "Epoch:  0048 D loss:-0.8793 G loss:-2.073\n",
      "Epoch:  0048 D loss:-0.683 G loss:-2.055\n",
      "Epoch:  0048 D loss:-0.681 G loss:-2.092\n",
      "Epoch:  0048 D loss:-0.7297 G loss:-2.048\n",
      "Epoch:  0048 D loss:-0.7268 G loss:-1.842\n",
      "Epoch:  0048 D loss:-0.6351 G loss:-1.897\n",
      "Epoch:  0048 D loss:-0.7345 G loss:-1.812\n",
      "Epoch:  0048 D loss:-0.6737 G loss:-2.222\n",
      "Epoch:  0048 D loss:-0.646 G loss:-2.089\n",
      "Epoch:  0048 D loss:-0.491 G loss:-2.277\n",
      "Epoch:  0048 D loss:-0.6111 G loss:-2.318\n",
      "Epoch:  0048 D loss:-0.5571 G loss:-2.316\n",
      "Epoch:  0048 D loss:-0.5975 G loss:-2.361\n",
      "Epoch:  0048 D loss:-0.6774 G loss:-2.456\n",
      "Epoch:  0048 D loss:-0.6929 G loss:-2.31\n",
      "Epoch:  0048 D loss:-0.6766 G loss:-2.328\n",
      "Epoch:  0048 D loss:-0.6489 G loss:-2.16\n",
      "Epoch:  0048 D loss:-0.6447 G loss:-1.983\n",
      "Epoch:  0048 D loss:-0.6307 G loss:-2.196\n",
      "Epoch:  0048 D loss:-0.5869 G loss:-2.112\n",
      "Epoch:  0048 D loss:-0.6291 G loss:-1.965\n",
      "Epoch:  0048 D loss:-0.6324 G loss:-1.984\n",
      "Epoch:  0048 D loss:-0.5984 G loss:-2.062\n",
      "Epoch:  0048 D loss:-0.5587 G loss:-1.889\n",
      "Epoch:  0048 D loss:-0.7638 G loss:-1.952\n",
      "Epoch:  0048 D loss:-0.6508 G loss:-1.887\n",
      "Epoch:  0048 D loss:-0.754 G loss:-1.975\n",
      "Epoch:  0048 D loss:-0.5524 G loss:-2.143\n",
      "Epoch:  0048 D loss:-0.5559 G loss:-2.262\n",
      "Epoch:  0048 D loss:-0.6439 G loss:-2.522\n",
      "Epoch:  0048 D loss:-0.7425 G loss:-2.349\n",
      "Epoch:  0048 D loss:-0.7451 G loss:-2.265\n",
      "Epoch:  0048 D loss:-0.82 G loss:-2.246\n",
      "Epoch:  0048 D loss:-0.5471 G loss:-2.424\n",
      "Epoch:  0048 D loss:-0.6157 G loss:-2.256\n",
      "Epoch:  0048 D loss:-0.7446 G loss:-2.177\n",
      "Epoch:  0048 D loss:-0.5803 G loss:-2.161\n",
      "Epoch:  0048 D loss:-0.6793 G loss:-2.156\n",
      "Epoch:  0048 D loss:-0.7058 G loss:-2.085\n",
      "Epoch:  0048 D loss:-0.6247 G loss:-2.256\n",
      "Epoch:  0048 D loss:-0.6221 G loss:-1.967\n",
      "Epoch:  0048 D loss:-0.5317 G loss:-2.103\n",
      "Epoch:  0048 D loss:-0.5815 G loss:-2.178\n",
      "Epoch:  0048 D loss:-0.6718 G loss:-2.133\n",
      "Epoch:  0048 D loss:-0.6483 G loss:-2.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0048 D loss:-0.493 G loss:-2.38\n",
      "Epoch:  0048 D loss:-0.6134 G loss:-2.469\n",
      "Epoch:  0048 D loss:-0.5718 G loss:-2.335\n",
      "Epoch:  0048 D loss:-0.599 G loss:-2.341\n",
      "Epoch:  0048 D loss:-0.6783 G loss:-2.153\n",
      "Epoch:  0048 D loss:-0.5333 G loss:-2.303\n",
      "Epoch:  0048 D loss:-0.6087 G loss:-2.305\n",
      "Epoch:  0048 D loss:-0.5807 G loss:-2.433\n",
      "Epoch:  0048 D loss:-0.5182 G loss:-2.286\n",
      "Epoch:  0048 D loss:-0.6965 G loss:-2.325\n",
      "Epoch:  0048 D loss:-0.652 G loss:-2.294\n",
      "Epoch:  0048 D loss:-0.5514 G loss:-2.23\n",
      "Epoch:  0048 D loss:-0.5828 G loss:-2.13\n",
      "Epoch:  0048 D loss:-0.7407 G loss:-2.182\n",
      "Epoch:  0048 D loss:-0.5371 G loss:-2.154\n",
      "Epoch:  0048 D loss:-0.6163 G loss:-2.141\n",
      "Epoch:  0048 D loss:-0.7317 G loss:-2.0\n",
      "Epoch:  0048 D loss:-0.726 G loss:-2.085\n",
      "Epoch:  0048 D loss:-0.7022 G loss:-1.836\n",
      "Epoch:  0048 D loss:-0.6724 G loss:-2.169\n",
      "Epoch:  0048 D loss:-0.6965 G loss:-2.19\n",
      "Epoch:  0048 D loss:-0.5104 G loss:-2.512\n",
      "Epoch:  0048 D loss:-0.5167 G loss:-2.245\n",
      "Epoch:  0048 D loss:-0.657 G loss:-2.233\n",
      "Epoch:  0048 D loss:-0.4921 G loss:-2.431\n",
      "Epoch:  0048 D loss:-0.5584 G loss:-2.171\n",
      "Epoch:  0048 D loss:-0.6344 G loss:-2.142\n",
      "Epoch:  0048 D loss:-0.5965 G loss:-2.395\n",
      "Epoch:  0048 D loss:-0.6821 G loss:-2.245\n",
      "Epoch:  0048 D loss:-0.5385 G loss:-2.363\n",
      "Epoch:  0048 D loss:-0.5562 G loss:-2.322\n",
      "Epoch:  0048 D loss:-0.6411 G loss:-2.044\n",
      "Epoch:  0048 D loss:-0.7101 G loss:-2.129\n",
      "Epoch:  0048 D loss:-0.6334 G loss:-2.072\n",
      "Epoch:  0048 D loss:-0.6467 G loss:-2.01\n",
      "Epoch:  0048 D loss:-0.6719 G loss:-2.055\n",
      "Epoch:  0048 D loss:-0.6118 G loss:-2.08\n",
      "Epoch:  0048 D loss:-0.7274 G loss:-1.912\n",
      "Epoch:  0048 D loss:-0.6592 G loss:-2.261\n",
      "Epoch:  0048 D loss:-0.6562 G loss:-2.267\n",
      "Epoch:  0048 D loss:-0.6588 G loss:-2.179\n",
      "Epoch:  0048 D loss:-0.6769 G loss:-2.185\n",
      "Epoch:  0048 D loss:-0.6208 G loss:-2.278\n",
      "Epoch:  0048 D loss:-0.6564 G loss:-2.181\n",
      "Epoch:  0048 D loss:-0.567 G loss:-2.074\n",
      "Epoch:  0048 D loss:-0.5553 G loss:-2.254\n",
      "Epoch:  0048 D loss:-0.6175 G loss:-2.372\n",
      "Epoch:  0048 D loss:-0.6009 G loss:-2.104\n",
      "Epoch:  0048 D loss:-0.6655 G loss:-2.253\n",
      "Epoch:  0048 D loss:-0.5935 G loss:-2.2\n",
      "Epoch:  0048 D loss:-0.6193 G loss:-2.162\n",
      "Epoch:  0048 D loss:-0.6847 G loss:-2.143\n",
      "Epoch:  0048 D loss:-0.5142 G loss:-2.305\n",
      "Epoch:  0048 D loss:-0.6863 G loss:-1.904\n",
      "Epoch:  0048 D loss:-0.6139 G loss:-1.951\n",
      "Epoch:  0048 D loss:-0.6409 G loss:-2.03\n",
      "Epoch:  0048 D loss:-0.4684 G loss:-2.157\n",
      "Epoch:  0048 D loss:-0.6403 G loss:-2.116\n",
      "Epoch:  0048 D loss:-0.7017 G loss:-1.997\n",
      "Epoch:  0048 D loss:-0.6234 G loss:-2.172\n",
      "Epoch:  0048 D loss:-0.5903 G loss:-2.347\n",
      "Epoch:  0048 D loss:-0.6308 G loss:-2.395\n",
      "Epoch:  0048 D loss:-0.5762 G loss:-2.204\n",
      "Epoch:  0048 D loss:-0.7264 G loss:-2.289\n",
      "Epoch:  0048 D loss:-0.6352 G loss:-2.282\n",
      "Epoch:  0048 D loss:-0.5998 G loss:-2.327\n",
      "Epoch:  0048 D loss:-0.7297 G loss:-2.013\n",
      "Epoch:  0048 D loss:-0.6214 G loss:-2.194\n",
      "Epoch:  0048 D loss:-0.5297 G loss:-2.243\n",
      "Epoch:  0048 D loss:-0.6229 G loss:-2.178\n",
      "Epoch:  0048 D loss:-0.5088 G loss:-2.291\n",
      "Epoch:  0048 D loss:-0.742 G loss:-2.179\n",
      "Epoch:  0048 D loss:-0.6346 G loss:-2.175\n",
      "Epoch:  0048 D loss:-0.6851 G loss:-2.015\n",
      "Epoch:  0048 D loss:-0.7029 G loss:-2.147\n",
      "Epoch:  0048 D loss:-0.5418 G loss:-2.244\n",
      "Epoch:  0048 D loss:-0.6836 G loss:-1.963\n",
      "Epoch:  0048 D loss:-0.6223 G loss:-2.213\n",
      "Epoch:  0048 D loss:-0.587 G loss:-2.03\n",
      "Epoch:  0048 D loss:-0.6 G loss:-2.271\n",
      "Epoch:  0048 D loss:-0.6123 G loss:-2.409\n",
      "Epoch:  0048 D loss:-0.5046 G loss:-2.497\n",
      "Epoch:  0048 D loss:-0.6075 G loss:-2.389\n",
      "Epoch:  0048 D loss:-0.6593 G loss:-2.589\n",
      "Epoch:  0048 D loss:-0.6624 G loss:-2.261\n",
      "Epoch:  0048 D loss:-0.4304 G loss:-2.44\n",
      "Epoch:  0048 D loss:-0.6884 G loss:-2.269\n",
      "Epoch:  0048 D loss:-0.61 G loss:-2.029\n",
      "Epoch:  0048 D loss:-0.5937 G loss:-2.14\n",
      "Epoch:  0048 D loss:-0.6073 G loss:-2.248\n",
      "Epoch:  0048 D loss:-0.67 G loss:-2.219\n",
      "Epoch:  0048 D loss:-0.6288 G loss:-2.028\n",
      "Epoch:  0048 D loss:-0.5981 G loss:-2.293\n",
      "Epoch:  0048 D loss:-0.6967 G loss:-2.19\n",
      "Epoch:  0048 D loss:-0.687 G loss:-2.042\n",
      "Epoch:  0048 D loss:-0.6384 G loss:-2.24\n",
      "Epoch:  0048 D loss:-0.5262 G loss:-2.115\n",
      "Epoch:  0048 D loss:-0.6454 G loss:-2.097\n",
      "Epoch:  0048 D loss:-0.5516 G loss:-2.16\n",
      "Epoch:  0048 D loss:-0.5422 G loss:-2.321\n",
      "Epoch:  0048 D loss:-0.4288 G loss:-2.373\n",
      "Epoch:  0048 D loss:-0.6398 G loss:-2.412\n",
      "Epoch:  0048 D loss:-0.6676 G loss:-2.548\n",
      "Epoch:  0048 D loss:-0.4388 G loss:-2.554\n",
      "Epoch:  0048 D loss:-0.4864 G loss:-2.475\n",
      "Epoch:  0048 D loss:-0.6132 G loss:-2.443\n",
      "Epoch:  0048 D loss:-0.6858 G loss:-2.321\n",
      "Epoch:  0048 D loss:-0.7206 G loss:-2.246\n",
      "Epoch:  0048 D loss:-0.6245 G loss:-2.309\n",
      "Epoch:  0048 D loss:-0.628 G loss:-2.002\n",
      "Epoch:  0048 D loss:-0.539 G loss:-2.039\n",
      "Epoch:  0048 D loss:-0.6634 G loss:-2.05\n",
      "Epoch:  0048 D loss:-0.6304 G loss:-2.071\n",
      "Epoch:  0048 D loss:-0.6796 G loss:-1.911\n",
      "Epoch:  0048 D loss:-0.6993 G loss:-2.092\n",
      "Epoch:  0048 D loss:-0.6767 G loss:-2.044\n",
      "Epoch:  0048 D loss:-0.8052 G loss:-1.903\n",
      "Epoch:  0048 D loss:-0.5494 G loss:-2.572\n",
      "Epoch:  0048 D loss:-0.453 G loss:-2.242\n",
      "Epoch:  0048 D loss:-0.6365 G loss:-2.459\n",
      "Epoch:  0048 D loss:-0.6533 G loss:-2.642\n",
      "Epoch:  0048 D loss:-0.6862 G loss:-2.481\n",
      "Epoch:  0048 D loss:-0.7506 G loss:-2.143\n",
      "Epoch:  0048 D loss:-0.6655 G loss:-2.21\n",
      "Epoch:  0048 D loss:-0.5968 G loss:-2.235\n",
      "Epoch:  0048 D loss:-0.6388 G loss:-2.279\n",
      "Epoch:  0048 D loss:-0.5527 G loss:-2.239\n",
      "Epoch:  0048 D loss:-0.8582 G loss:-2.083\n",
      "Epoch:  0048 D loss:-0.731 G loss:-1.825\n",
      "Epoch:  0048 D loss:-0.6822 G loss:-1.936\n",
      "Epoch:  0048 D loss:-0.7815 G loss:-1.821\n",
      "Epoch:  0048 D loss:-0.6085 G loss:-2.143\n",
      "Epoch:  0048 D loss:-0.7423 G loss:-1.926\n",
      "Epoch:  0048 D loss:-0.7766 G loss:-2.107\n",
      "Epoch:  0048 D loss:-0.8287 G loss:-2.088\n",
      "Epoch:  0048 D loss:-0.7237 G loss:-2.014\n",
      "Epoch:  0048 D loss:-0.56 G loss:-2.19\n",
      "Epoch:  0048 D loss:-0.6366 G loss:-2.262\n",
      "Epoch:  0048 D loss:-0.7205 G loss:-2.053\n",
      "Epoch:  0048 D loss:-0.7118 G loss:-2.196\n",
      "Epoch:  0048 D loss:-0.6406 G loss:-2.441\n",
      "Epoch:  0048 D loss:-0.577 G loss:-2.309\n",
      "Epoch:  0048 D loss:-0.5932 G loss:-2.161\n",
      "Epoch:  0048 D loss:-0.8614 G loss:-2.174\n",
      "Epoch:  0048 D loss:-0.8378 G loss:-2.032\n",
      "Epoch:  0048 D loss:-0.833 G loss:-1.879\n",
      "Epoch:  0048 D loss:-0.7249 G loss:-1.908\n",
      "Epoch:  0048 D loss:-0.6904 G loss:-1.904\n",
      "Epoch:  0048 D loss:-0.5405 G loss:-2.107\n",
      "Epoch:  0048 D loss:-0.688 G loss:-1.86\n",
      "Epoch:  0048 D loss:-0.6428 G loss:-1.901\n",
      "Epoch:  0048 D loss:-0.6469 G loss:-2.016\n",
      "Epoch:  0048 D loss:-0.6963 G loss:-2.136\n",
      "Epoch:  0048 D loss:-0.8357 G loss:-1.991\n",
      "Epoch:  0048 D loss:-0.7153 G loss:-2.059\n",
      "Epoch:  0048 D loss:-0.6499 G loss:-2.231\n",
      "Epoch:  0048 D loss:-0.734 G loss:-2.008\n",
      "Epoch:  0048 D loss:-0.7014 G loss:-2.123\n",
      "Epoch:  0048 D loss:-0.6829 G loss:-2.06\n",
      "Epoch:  0048 D loss:-0.6688 G loss:-2.045\n",
      "Epoch:  0048 D loss:-0.806 G loss:-1.905\n",
      "Epoch:  0048 D loss:-0.5526 G loss:-2.058\n",
      "Epoch:  0048 D loss:-0.5744 G loss:-2.06\n",
      "Epoch:  0048 D loss:-0.782 G loss:-2.055\n",
      "Epoch:  0048 D loss:-0.5732 G loss:-2.37\n",
      "Epoch:  0048 D loss:-0.6881 G loss:-2.051\n",
      "Epoch:  0048 D loss:-0.7229 G loss:-2.139\n",
      "Epoch:  0048 D loss:-0.5925 G loss:-1.941\n",
      "Epoch:  0048 D loss:-0.6243 G loss:-1.848\n",
      "Epoch:  0048 D loss:-0.5916 G loss:-1.97\n",
      "Epoch:  0048 D loss:-0.6345 G loss:-2.006\n",
      "Epoch:  0048 D loss:-0.668 G loss:-1.929\n",
      "Epoch:  0048 D loss:-0.57 G loss:-2.19\n",
      "Epoch:  0048 D loss:-0.6755 G loss:-2.005\n",
      "Epoch:  0048 D loss:-0.5882 G loss:-2.02\n",
      "Epoch:  0048 D loss:-0.5793 G loss:-2.351\n",
      "Epoch:  0048 D loss:-0.6455 G loss:-2.16\n",
      "Epoch:  0048 D loss:-0.5097 G loss:-2.668\n",
      "Epoch:  0048 D loss:-0.6641 G loss:-2.229\n",
      "Epoch:  0048 D loss:-0.5681 G loss:-2.49\n",
      "Epoch:  0048 D loss:-0.5944 G loss:-2.323\n",
      "Epoch:  0048 D loss:-0.5702 G loss:-2.258\n",
      "Epoch:  0048 D loss:-0.6939 G loss:-2.143\n",
      "Epoch:  0048 D loss:-0.6386 G loss:-2.03\n",
      "Epoch:  0048 D loss:-0.67 G loss:-2.103\n",
      "Epoch:  0048 D loss:-0.5833 G loss:-2.125\n",
      "Epoch:  0048 D loss:-0.5396 G loss:-2.029\n",
      "Epoch:  0048 D loss:-0.6451 G loss:-1.919\n",
      "Epoch:  0048 D loss:-0.6012 G loss:-2.054\n",
      "Epoch:  0048 D loss:-0.5991 G loss:-2.018\n",
      "Epoch:  0048 D loss:-0.5319 G loss:-1.966\n",
      "Epoch:  0048 D loss:-0.6896 G loss:-1.937\n",
      "Epoch:  0048 D loss:-0.5247 G loss:-2.184\n",
      "Epoch:  0048 D loss:-0.5777 G loss:-2.209\n",
      "Epoch:  0048 D loss:-0.53 G loss:-2.375\n",
      "Epoch:  0048 D loss:-0.5595 G loss:-2.224\n",
      "Epoch:  0048 D loss:-0.6914 G loss:-2.397\n",
      "Epoch:  0048 D loss:-0.5595 G loss:-2.226\n",
      "Epoch:  0048 D loss:-0.6071 G loss:-2.429\n",
      "Epoch:  0048 D loss:-0.5317 G loss:-2.473\n",
      "Epoch:  0048 D loss:-0.5616 G loss:-2.35\n",
      "Epoch:  0048 D loss:-0.5888 G loss:-1.989\n",
      "Epoch:  0048 D loss:-0.5309 G loss:-2.286\n",
      "Epoch:  0048 D loss:-0.5092 G loss:-2.221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0048 D loss:-0.5985 G loss:-1.826\n",
      "Epoch:  0048 D loss:-0.4547 G loss:-2.219\n",
      "Epoch:  0048 D loss:-0.6025 G loss:-2.182\n",
      "Epoch:  0048 D loss:-0.451 G loss:-2.518\n",
      "Epoch:  0048 D loss:-0.6047 G loss:-2.086\n",
      "Epoch:  0048 D loss:-0.5988 G loss:-2.454\n",
      "Epoch:  0048 D loss:-0.5217 G loss:-2.415\n",
      "Epoch:  0048 D loss:-0.6115 G loss:-2.203\n",
      "Epoch:  0048 D loss:-0.6307 G loss:-2.205\n",
      "Epoch:  0048 D loss:-0.6661 G loss:-1.977\n",
      "Epoch:  0048 D loss:-0.6322 G loss:-2.468\n",
      "Epoch:  0048 D loss:-0.5961 G loss:-2.208\n",
      "Epoch:  0048 D loss:-0.5482 G loss:-2.281\n",
      "Epoch:  0048 D loss:-0.6635 G loss:-2.014\n",
      "Epoch:  0048 D loss:-0.5813 G loss:-1.956\n",
      "Epoch:  0048 D loss:-0.7002 G loss:-2.144\n",
      "Epoch:  0048 D loss:-0.6538 G loss:-1.861\n",
      "Epoch:  0048 D loss:-0.7151 G loss:-1.881\n",
      "Epoch:  0048 D loss:-0.7112 G loss:-1.884\n",
      "Epoch:  0048 D loss:-0.7034 G loss:-1.952\n",
      "Epoch:  0048 D loss:-0.6357 G loss:-2.199\n",
      "Epoch:  0048 D loss:-0.5384 G loss:-2.312\n",
      "Epoch:  0048 D loss:-0.5888 G loss:-2.133\n",
      "Epoch:  0048 D loss:-0.6208 G loss:-2.44\n",
      "Epoch:  0048 D loss:-0.5179 G loss:-2.491\n",
      "Epoch:  0048 D loss:-0.5797 G loss:-2.463\n",
      "Epoch:  0048 D loss:-0.5942 G loss:-2.385\n",
      "Epoch:  0048 D loss:-0.7284 G loss:-2.297\n",
      "Epoch:  0048 D loss:-0.5588 G loss:-2.295\n",
      "Epoch:  0048 D loss:-0.6119 G loss:-2.228\n",
      "Epoch:  0048 D loss:-0.5959 G loss:-1.923\n",
      "Epoch:  0048 D loss:-0.5827 G loss:-1.956\n",
      "Epoch:  0048 D loss:-0.6384 G loss:-1.965\n",
      "Epoch:  0048 D loss:-0.5124 G loss:-2.107\n",
      "Epoch:  0048 D loss:-0.6895 G loss:-1.844\n",
      "Epoch:  0048 D loss:-0.5846 G loss:-1.994\n",
      "Epoch:  0048 D loss:-0.6554 G loss:-2.12\n",
      "Epoch:  0048 D loss:-0.6682 G loss:-2.206\n",
      "Epoch:  0048 D loss:-0.4649 G loss:-2.291\n",
      "Epoch:  0048 D loss:-0.7814 G loss:-2.183\n",
      "Epoch:  0048 D loss:-0.57 G loss:-2.473\n",
      "Epoch:  0048 D loss:-0.5644 G loss:-2.262\n",
      "Epoch:  0048 D loss:-0.555 G loss:-2.347\n",
      "Epoch:  0048 D loss:-0.6084 G loss:-2.288\n",
      "Epoch:  0048 D loss:-0.4778 G loss:-2.386\n",
      "Epoch:  0048 D loss:-0.5561 G loss:-2.486\n",
      "Epoch:  0048 D loss:-0.649 G loss:-2.135\n",
      "Epoch:  0048 D loss:-0.5766 G loss:-2.255\n",
      "Epoch:  0048 D loss:-0.5621 G loss:-2.371\n",
      "Epoch:  0048 D loss:-0.6102 G loss:-2.208\n",
      "Epoch:  0048 D loss:-0.7312 G loss:-2.138\n",
      "Epoch:  0048 D loss:-0.5457 G loss:-2.392\n",
      "Epoch:  0048 D loss:-0.6358 G loss:-2.161\n",
      "Epoch:  0048 D loss:-0.6542 G loss:-1.83\n",
      "Epoch:  0048 D loss:-0.6171 G loss:-1.94\n",
      "Epoch:  0048 D loss:-0.6389 G loss:-2.163\n",
      "Epoch:  0048 D loss:-0.8598 G loss:-1.978\n",
      "Epoch:  0048 D loss:-0.6789 G loss:-2.03\n",
      "Epoch:  0048 D loss:-0.7305 G loss:-2.151\n",
      "Epoch:  0048 D loss:-0.615 G loss:-2.214\n",
      "Epoch:  0048 D loss:-0.5949 G loss:-2.419\n",
      "Epoch:  0048 D loss:-0.7401 G loss:-2.111\n",
      "Epoch:  0048 D loss:-0.5908 G loss:-2.224\n",
      "Epoch:  0048 D loss:-0.8304 G loss:-2.125\n",
      "Epoch:  0048 D loss:-0.6536 G loss:-2.132\n",
      "Epoch:  0048 D loss:-0.6086 G loss:-2.04\n",
      "Epoch:  0048 D loss:-0.6853 G loss:-2.114\n",
      "Epoch:  0048 D loss:-0.6899 G loss:-2.263\n",
      "Epoch:  0048 D loss:-0.8596 G loss:-1.823\n",
      "Epoch:  0048 D loss:-0.7823 G loss:-1.849\n",
      "Epoch:  0048 D loss:-0.6413 G loss:-1.99\n",
      "Epoch:  0048 D loss:-0.6568 G loss:-2.085\n",
      "Epoch:  0048 D loss:-0.5965 G loss:-1.961\n",
      "Epoch:  0048 D loss:-0.5654 G loss:-2.105\n",
      "Epoch:  0048 D loss:-0.5549 G loss:-2.044\n",
      "Epoch:  0048 D loss:-0.7458 G loss:-2.091\n",
      "Epoch:  0048 D loss:-0.7524 G loss:-1.955\n",
      "Epoch:  0048 D loss:-0.6666 G loss:-2.206\n",
      "Epoch:  0048 D loss:-0.7509 G loss:-2.25\n",
      "Epoch:  0048 D loss:-0.5723 G loss:-2.163\n",
      "Epoch:  0048 D loss:-0.7555 G loss:-2.312\n",
      "Epoch:  0048 D loss:-0.6604 G loss:-2.346\n",
      "Epoch:  0048 D loss:-0.6803 G loss:-2.305\n",
      "Epoch:  0048 D loss:-0.7389 G loss:-2.164\n",
      "Epoch:  0048 D loss:-0.8864 G loss:-1.912\n",
      "Epoch:  0048 D loss:-0.6443 G loss:-2.25\n",
      "Epoch:  0048 D loss:-0.7004 G loss:-2.126\n",
      "Epoch:  0048 D loss:-0.6593 G loss:-2.105\n",
      "Epoch:  0048 D loss:-0.6861 G loss:-1.836\n",
      "Epoch:  0048 D loss:-0.6354 G loss:-2.01\n",
      "Epoch:  0048 D loss:-0.6801 G loss:-2.093\n",
      "Epoch:  0048 D loss:-0.7042 G loss:-1.921\n",
      "Epoch:  0048 D loss:-0.7017 G loss:-1.974\n",
      "Epoch:  0048 D loss:-0.7325 G loss:-2.036\n",
      "Epoch:  0048 D loss:-0.6946 G loss:-2.151\n",
      "Epoch:  0048 D loss:-0.7041 G loss:-2.114\n",
      "Epoch:  0048 D loss:-0.7508 G loss:-2.099\n",
      "Epoch:  0048 D loss:-0.4548 G loss:-2.349\n",
      "Epoch:  0048 D loss:-0.7315 G loss:-2.243\n",
      "Epoch:  0048 D loss:-0.7194 G loss:-2.184\n",
      "Epoch:  0048 D loss:-0.8262 G loss:-2.093\n",
      "Epoch:  0048 D loss:-0.8661 G loss:-2.196\n",
      "Epoch:  0048 D loss:-0.6116 G loss:-2.21\n",
      "Epoch:  0048 D loss:-0.7116 G loss:-2.051\n",
      "Epoch:  0048 D loss:-0.6389 G loss:-2.324\n",
      "Epoch:  0048 D loss:-0.6624 G loss:-2.19\n",
      "Epoch:  0048 D loss:-0.4911 G loss:-2.14\n",
      "Epoch:  0048 D loss:-0.7701 G loss:-2.021\n",
      "Epoch:  0048 D loss:-0.6321 G loss:-1.869\n",
      "Epoch:  0048 D loss:-0.9118 G loss:-2.005\n",
      "Epoch:  0048 D loss:-0.6601 G loss:-1.993\n",
      "Epoch:  0048 D loss:-0.6805 G loss:-2.033\n",
      "Epoch:  0048 D loss:-0.7372 G loss:-2.016\n",
      "Epoch:  0048 D loss:-0.8118 G loss:-1.735\n",
      "Epoch:  0048 D loss:-0.7501 G loss:-1.912\n",
      "Epoch:  0048 D loss:-0.8716 G loss:-1.859\n",
      "Epoch:  0048 D loss:-0.6847 G loss:-1.828\n",
      "Epoch:  0048 D loss:-0.68 G loss:-2.289\n",
      "Epoch:  0048 D loss:-0.7573 G loss:-2.26\n",
      "Epoch:  0048 D loss:-0.6936 G loss:-2.23\n",
      "Epoch:  0048 D loss:-0.5913 G loss:-2.276\n",
      "Epoch:  0048 D loss:-0.6714 G loss:-2.286\n",
      "Epoch:  0048 D loss:-0.6868 G loss:-2.065\n",
      "Epoch:  0048 D loss:-0.6962 G loss:-1.934\n",
      "Epoch:  0048 D loss:-0.588 G loss:-2.135\n",
      "Epoch:  0048 D loss:-0.6488 G loss:-2.095\n",
      "Epoch:  0048 D loss:-0.7197 G loss:-2.063\n",
      "Epoch:  0048 D loss:-0.694 G loss:-2.101\n",
      "Epoch:  0048 D loss:-0.7284 G loss:-2.34\n",
      "Epoch:  0048 D loss:-0.7191 G loss:-2.097\n",
      "Epoch:  0048 D loss:-0.7523 G loss:-2.342\n",
      "Epoch:  0048 D loss:-0.5977 G loss:-2.324\n",
      "Epoch:  0048 D loss:-0.7592 G loss:-2.15\n",
      "Epoch:  0048 D loss:-0.6233 G loss:-2.458\n",
      "Epoch:  0048 D loss:-0.6741 G loss:-2.089\n",
      "Epoch:  0048 D loss:-0.6513 G loss:-2.092\n",
      "Epoch:  0048 D loss:-0.6267 G loss:-2.25\n",
      "Epoch:  0048 D loss:-0.566 G loss:-2.087\n",
      "Epoch:  0048 D loss:-0.7144 G loss:-1.937\n",
      "Epoch:  0048 D loss:-0.6284 G loss:-2.151\n",
      "Epoch:  0048 D loss:-0.8187 G loss:-1.956\n",
      "Epoch:  0048 D loss:-0.6448 G loss:-1.877\n",
      "Epoch:  0048 D loss:-0.6159 G loss:-2.268\n",
      "Epoch:  0048 D loss:-0.7005 G loss:-2.223\n",
      "Epoch:  0048 D loss:-0.5889 G loss:-2.198\n",
      "Epoch:  0048 D loss:-0.608 G loss:-2.069\n",
      "Epoch:  0048 D loss:-0.6745 G loss:-2.342\n",
      "Epoch:  0048 D loss:-0.6534 G loss:-2.231\n",
      "Epoch:  0048 D loss:-0.5783 G loss:-2.153\n",
      "Epoch:  0048 D loss:-0.5992 G loss:-2.325\n",
      "Epoch:  0048 D loss:-0.6417 G loss:-2.38\n",
      "Epoch:  0048 D loss:-0.5935 G loss:-2.049\n",
      "Epoch:  0048 D loss:-0.7294 G loss:-2.194\n",
      "Epoch:  0048 D loss:-0.5445 G loss:-2.379\n",
      "Epoch:  0048 D loss:-0.6091 G loss:-2.085\n",
      "Epoch:  0048 D loss:-0.5964 G loss:-2.101\n",
      "Epoch:  0048 D loss:-0.6506 G loss:-2.139\n",
      "Epoch:  0048 D loss:-0.7333 G loss:-2.081\n",
      "Epoch:  0048 D loss:-0.5199 G loss:-2.167\n",
      "Epoch:  0048 D loss:-0.5592 G loss:-2.323\n",
      "Epoch:  0048 D loss:-0.5837 G loss:-2.225\n",
      "Epoch:  0048 D loss:-0.5043 G loss:-2.264\n",
      "Epoch:  0048 D loss:-0.5768 G loss:-2.163\n",
      "Epoch:  0048 D loss:-0.5346 G loss:-2.279\n",
      "Epoch:  0048 D loss:-0.6404 G loss:-2.247\n",
      "Epoch:  0048 D loss:-0.5214 G loss:-2.523\n",
      "Epoch:  0048 D loss:-0.5684 G loss:-2.106\n",
      "Epoch:  0048 D loss:-0.6227 G loss:-2.429\n",
      "Epoch:  0048 D loss:-0.5854 G loss:-2.416\n",
      "Epoch:  0048 D loss:-0.5817 G loss:-2.38\n",
      "Epoch:  0048 D loss:-0.576 G loss:-2.286\n",
      "Epoch:  0048 D loss:-0.7101 G loss:-2.292\n",
      "Epoch:  0048 D loss:-0.5331 G loss:-2.248\n",
      "Epoch:  0048 D loss:-0.7176 G loss:-2.112\n",
      "Epoch:  0048 D loss:-0.6291 G loss:-2.158\n",
      "Epoch:  0048 D loss:-0.6289 G loss:-1.934\n",
      "Epoch:  0048 D loss:-0.5251 G loss:-2.088\n",
      "Epoch:  0048 D loss:-0.6463 G loss:-2.135\n",
      "Epoch:  0048 D loss:-0.5423 G loss:-2.127\n",
      "Epoch:  0048 D loss:-0.6895 G loss:-2.308\n",
      "Epoch:  0048 D loss:-0.602 G loss:-2.376\n",
      "Epoch:  0048 D loss:-0.5636 G loss:-2.221\n",
      "Epoch:  0048 D loss:-0.6056 G loss:-2.228\n",
      "Epoch:  0048 D loss:-0.6694 G loss:-2.141\n",
      "Epoch:  0048 D loss:-0.7142 G loss:-2.082\n",
      "Epoch:  0048 D loss:-0.5266 G loss:-2.273\n",
      "Epoch:  0048 D loss:-0.5262 G loss:-2.476\n",
      "Epoch:  0048 D loss:-0.5336 G loss:-2.262\n",
      "Epoch:  0048 D loss:-0.5616 G loss:-2.341\n",
      "Epoch:  0048 D loss:-0.6067 G loss:-2.133\n",
      "Epoch:  0048 D loss:-0.5356 G loss:-2.164\n",
      "Epoch:  0048 D loss:-0.6747 G loss:-2.173\n",
      "Epoch:  0048 D loss:-0.6152 G loss:-2.112\n",
      "Epoch:  0048 D loss:-0.6374 G loss:-2.345\n",
      "Epoch:  0048 D loss:-0.5694 G loss:-2.257\n",
      "Epoch:  0048 D loss:-0.4672 G loss:-2.256\n",
      "Epoch:  0048 D loss:-0.585 G loss:-2.348\n",
      "Epoch:  0048 D loss:-0.6489 G loss:-2.235\n",
      "Epoch:  0048 D loss:-0.6156 G loss:-2.003\n",
      "Epoch:  0048 D loss:-0.6328 G loss:-2.154\n",
      "Epoch:  0048 D loss:-0.6776 G loss:-2.127\n",
      "Epoch:  0048 D loss:-0.5939 G loss:-2.237\n",
      "Epoch:  0048 D loss:-0.5663 G loss:-2.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0048 D loss:-0.6491 G loss:-2.168\n",
      "Epoch:  0048 D loss:-0.6517 G loss:-2.151\n",
      "Epoch:  0048 D loss:-0.6094 G loss:-2.185\n",
      "Epoch:  0048 D loss:-0.6611 G loss:-2.51\n",
      "Epoch:  0048 D loss:-0.7236 G loss:-2.255\n",
      "Epoch:  0048 D loss:-0.4948 G loss:-2.412\n",
      "Epoch:  0048 D loss:-0.5189 G loss:-2.438\n",
      "Epoch:  0048 D loss:-0.6954 G loss:-2.246\n",
      "Epoch:  0048 D loss:-0.5681 G loss:-2.488\n",
      "Epoch:  0048 D loss:-0.6106 G loss:-1.963\n",
      "Epoch:  0048 D loss:-0.5745 G loss:-2.29\n",
      "Epoch:  0048 D loss:-0.5509 G loss:-2.316\n",
      "Epoch:  0048 D loss:-0.6192 G loss:-2.423\n",
      "Epoch:  0048 D loss:-0.5095 G loss:-2.405\n",
      "Epoch:  0048 D loss:-0.4976 G loss:-2.23\n",
      "Epoch:  0048 D loss:-0.5963 G loss:-2.135\n",
      "Epoch:  0048 D loss:-0.6108 G loss:-2.069\n",
      "Epoch:  0048 D loss:-0.6355 G loss:-2.129\n",
      "Epoch:  0048 D loss:-0.7026 G loss:-1.996\n",
      "Epoch:  0048 D loss:-0.6706 G loss:-2.041\n",
      "Epoch:  0048 D loss:-0.538 G loss:-2.405\n",
      "Epoch:  0048 D loss:-0.6372 G loss:-2.178\n",
      "Epoch:  0048 D loss:-0.5739 G loss:-2.308\n",
      "Epoch:  0048 D loss:-0.6034 G loss:-2.285\n",
      "Epoch:  0048 D loss:-0.5416 G loss:-2.082\n",
      "Epoch:  0048 D loss:-0.5514 G loss:-2.218\n",
      "Epoch:  0048 D loss:-0.6421 G loss:-2.235\n",
      "Epoch:  0048 D loss:-0.5838 G loss:-2.219\n",
      "Epoch:  0048 D loss:-0.6244 G loss:-2.201\n",
      "Epoch:  0048 D loss:-0.508 G loss:-2.273\n",
      "Epoch:  0048 D loss:-0.5955 G loss:-2.416\n",
      "Epoch:  0048 D loss:-0.623 G loss:-2.26\n",
      "Epoch:  0048 D loss:-0.5253 G loss:-2.131\n",
      "Epoch:  0048 D loss:-0.679 G loss:-2.049\n",
      "Epoch:  0048 D loss:-0.6766 G loss:-2.153\n",
      "Epoch:  0048 D loss:-0.5922 G loss:-2.096\n",
      "Epoch:  0048 D loss:-0.6293 G loss:-2.105\n",
      "Epoch:  0048 D loss:-0.8665 G loss:-2.098\n",
      "Epoch:  0048 D loss:-0.5131 G loss:-2.159\n",
      "Epoch:  0048 D loss:-0.5841 G loss:-2.201\n",
      "Epoch:  0048 D loss:-0.6608 G loss:-2.105\n",
      "Epoch:  0048 D loss:-0.4963 G loss:-2.01\n",
      "Epoch:  0048 D loss:-0.572 G loss:-2.356\n",
      "Epoch:  0048 D loss:-0.6402 G loss:-2.371\n",
      "Epoch:  0048 D loss:-0.7198 G loss:-2.201\n",
      "Epoch:  0048 D loss:-0.6602 G loss:-2.304\n",
      "Epoch:  0048 D loss:-0.6932 G loss:-2.369\n",
      "Epoch:  0048 D loss:-0.688 G loss:-2.434\n",
      "Epoch:  0048 D loss:-0.632 G loss:-2.384\n",
      "Epoch:  0048 D loss:-0.6768 G loss:-2.329\n",
      "Epoch:  0048 D loss:-0.7506 G loss:-2.151\n",
      "Epoch:  0048 D loss:-0.6651 G loss:-2.113\n",
      "Epoch:  0048 D loss:-0.6216 G loss:-2.18\n",
      "Epoch:  0048 D loss:-0.749 G loss:-2.145\n",
      "Epoch:  0048 D loss:-0.576 G loss:-2.162\n",
      "Epoch:  0048 D loss:-0.6825 G loss:-1.993\n",
      "Epoch:  0048 D loss:-0.6532 G loss:-1.9\n",
      "Epoch:  0049 D loss:-0.7595 G loss:-1.983\n",
      "Epoch:  0049 D loss:-0.6923 G loss:-1.82\n",
      "Epoch:  0049 D loss:-0.5978 G loss:-2.197\n",
      "Epoch:  0049 D loss:-0.7947 G loss:-2.003\n",
      "Epoch:  0049 D loss:-0.6559 G loss:-2.144\n",
      "Epoch:  0049 D loss:-0.5854 G loss:-2.123\n",
      "Epoch:  0049 D loss:-0.7516 G loss:-2.272\n",
      "Epoch:  0049 D loss:-0.6052 G loss:-2.235\n",
      "Epoch:  0049 D loss:-0.75 G loss:-1.928\n",
      "Epoch:  0049 D loss:-0.6294 G loss:-2.348\n",
      "Epoch:  0049 D loss:-0.6099 G loss:-2.244\n",
      "Epoch:  0049 D loss:-0.7335 G loss:-2.142\n",
      "Epoch:  0049 D loss:-0.7396 G loss:-2.1\n",
      "Epoch:  0049 D loss:-0.648 G loss:-2.143\n",
      "Epoch:  0049 D loss:-0.8103 G loss:-2.001\n",
      "Epoch:  0049 D loss:-0.582 G loss:-2.106\n",
      "Epoch:  0049 D loss:-0.8365 G loss:-1.909\n",
      "Epoch:  0049 D loss:-0.6979 G loss:-1.973\n",
      "Epoch:  0049 D loss:-0.7796 G loss:-1.976\n",
      "Epoch:  0049 D loss:-0.7605 G loss:-1.931\n",
      "Epoch:  0049 D loss:-0.6911 G loss:-2.28\n",
      "Epoch:  0049 D loss:-0.6471 G loss:-2.058\n",
      "Epoch:  0049 D loss:-0.7738 G loss:-1.827\n",
      "Epoch:  0049 D loss:-0.6859 G loss:-1.885\n",
      "Epoch:  0049 D loss:-0.6527 G loss:-2.054\n",
      "Epoch:  0049 D loss:-0.5884 G loss:-2.135\n",
      "Epoch:  0049 D loss:-0.7214 G loss:-2.058\n",
      "Epoch:  0049 D loss:-0.7665 G loss:-1.834\n",
      "Epoch:  0049 D loss:-0.7408 G loss:-2.161\n",
      "Epoch:  0049 D loss:-0.7359 G loss:-2.12\n",
      "Epoch:  0049 D loss:-0.6538 G loss:-2.205\n",
      "Epoch:  0049 D loss:-0.7375 G loss:-2.346\n",
      "Epoch:  0049 D loss:-0.7098 G loss:-2.154\n",
      "Epoch:  0049 D loss:-0.5494 G loss:-2.416\n",
      "Epoch:  0049 D loss:-0.593 G loss:-2.068\n",
      "Epoch:  0049 D loss:-0.738 G loss:-2.201\n",
      "Epoch:  0049 D loss:-0.6668 G loss:-2.013\n",
      "Epoch:  0049 D loss:-0.4604 G loss:-2.327\n",
      "Epoch:  0049 D loss:-0.7257 G loss:-1.919\n",
      "Epoch:  0049 D loss:-0.6398 G loss:-2.057\n",
      "Epoch:  0049 D loss:-0.6022 G loss:-2.097\n",
      "Epoch:  0049 D loss:-0.7395 G loss:-2.118\n",
      "Epoch:  0049 D loss:-0.6778 G loss:-2.218\n",
      "Epoch:  0049 D loss:-0.6017 G loss:-2.371\n",
      "Epoch:  0049 D loss:-0.689 G loss:-2.003\n",
      "Epoch:  0049 D loss:-0.8279 G loss:-2.1\n",
      "Epoch:  0049 D loss:-0.6245 G loss:-2.153\n",
      "Epoch:  0049 D loss:-0.6033 G loss:-2.156\n",
      "Epoch:  0049 D loss:-0.5452 G loss:-2.322\n",
      "Epoch:  0049 D loss:-0.5813 G loss:-2.145\n",
      "Epoch:  0049 D loss:-0.6498 G loss:-2.13\n",
      "Epoch:  0049 D loss:-0.6493 G loss:-2.249\n",
      "Epoch:  0049 D loss:-0.5071 G loss:-2.169\n",
      "Epoch:  0049 D loss:-0.6844 G loss:-2.161\n",
      "Epoch:  0049 D loss:-0.6518 G loss:-2.13\n",
      "Epoch:  0049 D loss:-0.5929 G loss:-2.204\n",
      "Epoch:  0049 D loss:-0.6667 G loss:-2.212\n",
      "Epoch:  0049 D loss:-0.6136 G loss:-2.031\n",
      "Epoch:  0049 D loss:-0.6046 G loss:-2.119\n",
      "Epoch:  0049 D loss:-0.7221 G loss:-2.264\n",
      "Epoch:  0049 D loss:-0.8135 G loss:-2.253\n",
      "Epoch:  0049 D loss:-0.606 G loss:-2.296\n",
      "Epoch:  0049 D loss:-0.6541 G loss:-2.361\n",
      "Epoch:  0049 D loss:-0.6425 G loss:-2.038\n",
      "Epoch:  0049 D loss:-0.5928 G loss:-2.071\n",
      "Epoch:  0049 D loss:-0.5904 G loss:-2.103\n",
      "Epoch:  0049 D loss:-0.4579 G loss:-2.204\n",
      "Epoch:  0049 D loss:-0.6095 G loss:-2.205\n",
      "Epoch:  0049 D loss:-0.5493 G loss:-2.221\n",
      "Epoch:  0049 D loss:-0.6058 G loss:-2.28\n",
      "Epoch:  0049 D loss:-0.603 G loss:-2.249\n",
      "Epoch:  0049 D loss:-0.7169 G loss:-2.357\n",
      "Epoch:  0049 D loss:-0.6961 G loss:-2.135\n",
      "Epoch:  0049 D loss:-0.7805 G loss:-2.146\n",
      "Epoch:  0049 D loss:-0.468 G loss:-2.302\n",
      "Epoch:  0049 D loss:-0.6609 G loss:-2.116\n",
      "Epoch:  0049 D loss:-0.6191 G loss:-2.163\n",
      "Epoch:  0049 D loss:-0.6107 G loss:-2.041\n",
      "Epoch:  0049 D loss:-0.6103 G loss:-2.086\n",
      "Epoch:  0049 D loss:-0.7764 G loss:-2.05\n",
      "Epoch:  0049 D loss:-0.7979 G loss:-1.939\n",
      "Epoch:  0049 D loss:-0.6746 G loss:-2.002\n",
      "Epoch:  0049 D loss:-0.663 G loss:-1.828\n",
      "Epoch:  0049 D loss:-0.5963 G loss:-2.03\n",
      "Epoch:  0049 D loss:-0.6824 G loss:-2.118\n",
      "Epoch:  0049 D loss:-0.7004 G loss:-2.176\n",
      "Epoch:  0049 D loss:-0.5881 G loss:-2.153\n",
      "Epoch:  0049 D loss:-0.5792 G loss:-2.236\n",
      "Epoch:  0049 D loss:-0.5547 G loss:-2.26\n",
      "Epoch:  0049 D loss:-0.6019 G loss:-2.378\n",
      "Epoch:  0049 D loss:-0.6054 G loss:-2.421\n",
      "Epoch:  0049 D loss:-0.5935 G loss:-2.618\n",
      "Epoch:  0049 D loss:-0.5875 G loss:-2.398\n",
      "Epoch:  0049 D loss:-0.7793 G loss:-2.206\n",
      "Epoch:  0049 D loss:-0.6157 G loss:-2.061\n",
      "Epoch:  0049 D loss:-0.615 G loss:-2.252\n",
      "Epoch:  0049 D loss:-0.5648 G loss:-2.171\n",
      "Epoch:  0049 D loss:-0.5544 G loss:-2.076\n",
      "Epoch:  0049 D loss:-0.6739 G loss:-1.883\n",
      "Epoch:  0049 D loss:-0.6005 G loss:-1.833\n",
      "Epoch:  0049 D loss:-0.6827 G loss:-2.201\n",
      "Epoch:  0049 D loss:-0.6563 G loss:-2.171\n",
      "Epoch:  0049 D loss:-0.7159 G loss:-2.06\n",
      "Epoch:  0049 D loss:-0.5876 G loss:-2.185\n",
      "Epoch:  0049 D loss:-0.7886 G loss:-2.085\n",
      "Epoch:  0049 D loss:-0.837 G loss:-2.161\n",
      "Epoch:  0049 D loss:-0.6709 G loss:-2.091\n",
      "Epoch:  0049 D loss:-0.7737 G loss:-2.098\n",
      "Epoch:  0049 D loss:-0.5857 G loss:-2.087\n",
      "Epoch:  0049 D loss:-0.5326 G loss:-2.175\n",
      "Epoch:  0049 D loss:-0.7284 G loss:-2.177\n",
      "Epoch:  0049 D loss:-0.7202 G loss:-2.12\n",
      "Epoch:  0049 D loss:-0.6474 G loss:-2.166\n",
      "Epoch:  0049 D loss:-0.5385 G loss:-2.306\n",
      "Epoch:  0049 D loss:-0.7694 G loss:-1.996\n",
      "Epoch:  0049 D loss:-0.6011 G loss:-2.139\n",
      "Epoch:  0049 D loss:-0.6045 G loss:-2.385\n",
      "Epoch:  0049 D loss:-0.7585 G loss:-2.168\n",
      "Epoch:  0049 D loss:-0.6388 G loss:-2.491\n",
      "Epoch:  0049 D loss:-0.5959 G loss:-2.138\n",
      "Epoch:  0049 D loss:-0.7184 G loss:-1.996\n",
      "Epoch:  0049 D loss:-0.6224 G loss:-2.082\n",
      "Epoch:  0049 D loss:-0.4472 G loss:-2.212\n",
      "Epoch:  0049 D loss:-0.584 G loss:-2.187\n",
      "Epoch:  0049 D loss:-0.5831 G loss:-2.137\n",
      "Epoch:  0049 D loss:-0.496 G loss:-2.263\n",
      "Epoch:  0049 D loss:-0.7381 G loss:-2.023\n",
      "Epoch:  0049 D loss:-0.7514 G loss:-2.199\n",
      "Epoch:  0049 D loss:-0.6229 G loss:-2.358\n",
      "Epoch:  0049 D loss:-0.5551 G loss:-2.181\n",
      "Epoch:  0049 D loss:-0.6161 G loss:-2.145\n",
      "Epoch:  0049 D loss:-0.5806 G loss:-2.303\n",
      "Epoch:  0049 D loss:-0.5139 G loss:-2.125\n",
      "Epoch:  0049 D loss:-0.5106 G loss:-2.438\n",
      "Epoch:  0049 D loss:-0.6585 G loss:-2.104\n",
      "Epoch:  0049 D loss:-0.6164 G loss:-2.36\n",
      "Epoch:  0049 D loss:-0.6503 G loss:-2.157\n",
      "Epoch:  0049 D loss:-0.6705 G loss:-2.182\n",
      "Epoch:  0049 D loss:-0.6982 G loss:-2.344\n",
      "Epoch:  0049 D loss:-0.6288 G loss:-2.063\n",
      "Epoch:  0049 D loss:-0.7355 G loss:-2.142\n",
      "Epoch:  0049 D loss:-0.7327 G loss:-2.205\n",
      "Epoch:  0049 D loss:-0.6316 G loss:-2.19\n",
      "Epoch:  0049 D loss:-0.7781 G loss:-2.225\n",
      "Epoch:  0049 D loss:-0.5974 G loss:-2.036\n",
      "Epoch:  0049 D loss:-0.901 G loss:-2.012\n",
      "Epoch:  0049 D loss:-0.5831 G loss:-2.317\n",
      "Epoch:  0049 D loss:-0.6624 G loss:-2.142\n",
      "Epoch:  0049 D loss:-0.7015 G loss:-2.024\n",
      "Epoch:  0049 D loss:-0.7425 G loss:-2.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0049 D loss:-0.5371 G loss:-2.271\n",
      "Epoch:  0049 D loss:-0.6274 G loss:-2.229\n",
      "Epoch:  0049 D loss:-0.8197 G loss:-2.257\n",
      "Epoch:  0049 D loss:-0.6698 G loss:-2.262\n",
      "Epoch:  0049 D loss:-0.7932 G loss:-1.934\n",
      "Epoch:  0049 D loss:-0.562 G loss:-2.108\n",
      "Epoch:  0049 D loss:-0.6564 G loss:-2.038\n",
      "Epoch:  0049 D loss:-0.619 G loss:-2.003\n",
      "Epoch:  0049 D loss:-0.5482 G loss:-2.184\n",
      "Epoch:  0049 D loss:-0.7771 G loss:-2.313\n",
      "Epoch:  0049 D loss:-0.6535 G loss:-2.07\n",
      "Epoch:  0049 D loss:-0.5678 G loss:-2.212\n",
      "Epoch:  0049 D loss:-0.6938 G loss:-2.006\n",
      "Epoch:  0049 D loss:-0.6511 G loss:-2.144\n",
      "Epoch:  0049 D loss:-0.7139 G loss:-2.09\n",
      "Epoch:  0049 D loss:-0.5954 G loss:-2.253\n",
      "Epoch:  0049 D loss:-0.636 G loss:-2.325\n",
      "Epoch:  0049 D loss:-0.5241 G loss:-2.345\n",
      "Epoch:  0049 D loss:-0.7967 G loss:-2.26\n",
      "Epoch:  0049 D loss:-0.6838 G loss:-2.183\n",
      "Epoch:  0049 D loss:-0.6274 G loss:-2.355\n",
      "Epoch:  0049 D loss:-0.6795 G loss:-2.204\n",
      "Epoch:  0049 D loss:-0.7441 G loss:-2.081\n",
      "Epoch:  0049 D loss:-0.5946 G loss:-2.314\n",
      "Epoch:  0049 D loss:-0.7514 G loss:-2.037\n",
      "Epoch:  0049 D loss:-0.6695 G loss:-2.184\n",
      "Epoch:  0049 D loss:-0.6197 G loss:-2.189\n",
      "Epoch:  0049 D loss:-0.5673 G loss:-2.004\n",
      "Epoch:  0049 D loss:-0.7871 G loss:-1.779\n",
      "Epoch:  0049 D loss:-0.7481 G loss:-2.095\n",
      "Epoch:  0049 D loss:-0.8709 G loss:-1.939\n",
      "Epoch:  0049 D loss:-0.5824 G loss:-2.058\n",
      "Epoch:  0049 D loss:-0.5919 G loss:-2.081\n",
      "Epoch:  0049 D loss:-0.5103 G loss:-2.41\n",
      "Epoch:  0049 D loss:-0.7502 G loss:-2.258\n",
      "Epoch:  0049 D loss:-0.7057 G loss:-2.551\n",
      "Epoch:  0049 D loss:-0.5927 G loss:-2.292\n",
      "Epoch:  0049 D loss:-0.5719 G loss:-2.215\n",
      "Epoch:  0049 D loss:-0.7208 G loss:-2.202\n",
      "Epoch:  0049 D loss:-0.6131 G loss:-2.311\n",
      "Epoch:  0049 D loss:-0.7054 G loss:-2.103\n",
      "Epoch:  0049 D loss:-0.5133 G loss:-2.285\n",
      "Epoch:  0049 D loss:-0.5851 G loss:-2.177\n",
      "Epoch:  0049 D loss:-0.7003 G loss:-1.793\n",
      "Epoch:  0049 D loss:-0.671 G loss:-1.962\n",
      "Epoch:  0049 D loss:-0.6345 G loss:-1.924\n",
      "Epoch:  0049 D loss:-0.7741 G loss:-2.105\n",
      "Epoch:  0049 D loss:-0.6347 G loss:-2.058\n",
      "Epoch:  0049 D loss:-0.6378 G loss:-2.153\n",
      "Epoch:  0049 D loss:-0.7015 G loss:-2.021\n",
      "Epoch:  0049 D loss:-0.6692 G loss:-2.077\n",
      "Epoch:  0049 D loss:-0.7658 G loss:-2.194\n",
      "Epoch:  0049 D loss:-0.6611 G loss:-2.071\n",
      "Epoch:  0049 D loss:-0.6076 G loss:-2.35\n",
      "Epoch:  0049 D loss:-0.6253 G loss:-2.205\n",
      "Epoch:  0049 D loss:-0.6019 G loss:-2.144\n",
      "Epoch:  0049 D loss:-0.6227 G loss:-2.054\n",
      "Epoch:  0049 D loss:-0.6389 G loss:-2.034\n",
      "Epoch:  0049 D loss:-0.6488 G loss:-2.273\n",
      "Epoch:  0049 D loss:-0.6559 G loss:-2.2\n",
      "Epoch:  0049 D loss:-0.7877 G loss:-1.965\n",
      "Epoch:  0049 D loss:-0.604 G loss:-2.027\n",
      "Epoch:  0049 D loss:-0.5864 G loss:-2.12\n",
      "Epoch:  0049 D loss:-0.6487 G loss:-1.999\n",
      "Epoch:  0049 D loss:-0.702 G loss:-2.082\n",
      "Epoch:  0049 D loss:-0.6583 G loss:-2.1\n",
      "Epoch:  0049 D loss:-0.7269 G loss:-2.156\n",
      "Epoch:  0049 D loss:-0.582 G loss:-2.207\n",
      "Epoch:  0049 D loss:-0.6826 G loss:-2.009\n",
      "Epoch:  0049 D loss:-0.5341 G loss:-2.166\n",
      "Epoch:  0049 D loss:-0.5493 G loss:-2.478\n",
      "Epoch:  0049 D loss:-0.6284 G loss:-2.252\n",
      "Epoch:  0049 D loss:-0.819 G loss:-2.153\n",
      "Epoch:  0049 D loss:-0.7434 G loss:-2.189\n",
      "Epoch:  0049 D loss:-0.7019 G loss:-2.171\n",
      "Epoch:  0049 D loss:-0.6222 G loss:-2.243\n",
      "Epoch:  0049 D loss:-0.6827 G loss:-1.864\n",
      "Epoch:  0049 D loss:-0.741 G loss:-1.989\n",
      "Epoch:  0049 D loss:-0.7074 G loss:-2.202\n",
      "Epoch:  0049 D loss:-0.7404 G loss:-1.984\n",
      "Epoch:  0049 D loss:-0.6454 G loss:-2.177\n",
      "Epoch:  0049 D loss:-0.664 G loss:-2.131\n",
      "Epoch:  0049 D loss:-0.6428 G loss:-2.239\n",
      "Epoch:  0049 D loss:-0.6238 G loss:-2.2\n",
      "Epoch:  0049 D loss:-0.7661 G loss:-2.248\n",
      "Epoch:  0049 D loss:-0.6527 G loss:-2.157\n",
      "Epoch:  0049 D loss:-0.5253 G loss:-2.517\n",
      "Epoch:  0049 D loss:-0.6657 G loss:-2.213\n",
      "Epoch:  0049 D loss:-0.7976 G loss:-1.972\n",
      "Epoch:  0049 D loss:-0.6184 G loss:-2.129\n",
      "Epoch:  0049 D loss:-0.6175 G loss:-2.286\n",
      "Epoch:  0049 D loss:-0.7326 G loss:-2.2\n",
      "Epoch:  0049 D loss:-0.6168 G loss:-2.119\n",
      "Epoch:  0049 D loss:-0.7975 G loss:-1.986\n",
      "Epoch:  0049 D loss:-0.5395 G loss:-1.965\n",
      "Epoch:  0049 D loss:-0.6545 G loss:-2.161\n",
      "Epoch:  0049 D loss:-0.5826 G loss:-2.267\n",
      "Epoch:  0049 D loss:-0.658 G loss:-1.993\n",
      "Epoch:  0049 D loss:-0.7138 G loss:-2.007\n",
      "Epoch:  0049 D loss:-0.7518 G loss:-1.897\n",
      "Epoch:  0049 D loss:-0.5071 G loss:-2.213\n",
      "Epoch:  0049 D loss:-0.6045 G loss:-2.033\n",
      "Epoch:  0049 D loss:-0.6845 G loss:-2.105\n",
      "Epoch:  0049 D loss:-0.5931 G loss:-2.382\n",
      "Epoch:  0049 D loss:-0.7285 G loss:-2.029\n",
      "Epoch:  0049 D loss:-0.7616 G loss:-2.134\n",
      "Epoch:  0049 D loss:-0.7463 G loss:-2.108\n",
      "Epoch:  0049 D loss:-0.6683 G loss:-2.045\n",
      "Epoch:  0049 D loss:-0.5828 G loss:-2.295\n",
      "Epoch:  0049 D loss:-0.6891 G loss:-2.02\n",
      "Epoch:  0049 D loss:-0.7062 G loss:-1.923\n",
      "Epoch:  0049 D loss:-0.7227 G loss:-2.029\n",
      "Epoch:  0049 D loss:-0.4641 G loss:-1.964\n",
      "Epoch:  0049 D loss:-0.7035 G loss:-1.878\n",
      "Epoch:  0049 D loss:-0.5885 G loss:-1.974\n",
      "Epoch:  0049 D loss:-0.7525 G loss:-1.964\n",
      "Epoch:  0049 D loss:-0.7135 G loss:-2.292\n",
      "Epoch:  0049 D loss:-0.7297 G loss:-2.151\n",
      "Epoch:  0049 D loss:-0.7163 G loss:-2.308\n",
      "Epoch:  0049 D loss:-0.6056 G loss:-2.325\n",
      "Epoch:  0049 D loss:-0.7621 G loss:-2.132\n",
      "Epoch:  0049 D loss:-0.6706 G loss:-2.097\n",
      "Epoch:  0049 D loss:-0.7043 G loss:-2.129\n",
      "Epoch:  0049 D loss:-0.6816 G loss:-2.072\n",
      "Epoch:  0049 D loss:-0.718 G loss:-2.039\n",
      "Epoch:  0049 D loss:-0.7603 G loss:-2.154\n",
      "Epoch:  0049 D loss:-0.7477 G loss:-1.865\n",
      "Epoch:  0049 D loss:-0.583 G loss:-2.012\n",
      "Epoch:  0049 D loss:-0.6433 G loss:-1.994\n",
      "Epoch:  0049 D loss:-0.5976 G loss:-2.298\n",
      "Epoch:  0049 D loss:-0.855 G loss:-1.992\n",
      "Epoch:  0049 D loss:-0.835 G loss:-2.036\n",
      "Epoch:  0049 D loss:-0.6728 G loss:-2.066\n",
      "Epoch:  0049 D loss:-0.862 G loss:-1.854\n",
      "Epoch:  0049 D loss:-0.6338 G loss:-2.132\n",
      "Epoch:  0049 D loss:-0.804 G loss:-2.007\n",
      "Epoch:  0049 D loss:-0.601 G loss:-2.064\n",
      "Epoch:  0049 D loss:-0.7263 G loss:-2.205\n",
      "Epoch:  0049 D loss:-0.86 G loss:-2.054\n",
      "Epoch:  0049 D loss:-0.6399 G loss:-2.128\n",
      "Epoch:  0049 D loss:-0.6975 G loss:-1.984\n",
      "Epoch:  0049 D loss:-0.8121 G loss:-1.979\n",
      "Epoch:  0049 D loss:-0.6692 G loss:-2.245\n",
      "Epoch:  0049 D loss:-0.5595 G loss:-2.083\n",
      "Epoch:  0049 D loss:-0.678 G loss:-2.011\n",
      "Epoch:  0049 D loss:-0.8597 G loss:-1.954\n",
      "Epoch:  0049 D loss:-0.8551 G loss:-1.846\n",
      "Epoch:  0049 D loss:-0.7438 G loss:-2.304\n",
      "Epoch:  0049 D loss:-0.7058 G loss:-2.042\n",
      "Epoch:  0049 D loss:-0.8465 G loss:-1.901\n",
      "Epoch:  0049 D loss:-0.7131 G loss:-2.281\n",
      "Epoch:  0049 D loss:-0.6594 G loss:-2.092\n",
      "Epoch:  0049 D loss:-0.7036 G loss:-2.222\n",
      "Epoch:  0049 D loss:-0.6874 G loss:-2.119\n",
      "Epoch:  0049 D loss:-0.674 G loss:-2.051\n",
      "Epoch:  0049 D loss:-0.7595 G loss:-2.077\n",
      "Epoch:  0049 D loss:-0.5743 G loss:-2.108\n",
      "Epoch:  0049 D loss:-0.6405 G loss:-2.024\n",
      "Epoch:  0049 D loss:-0.6355 G loss:-1.983\n",
      "Epoch:  0049 D loss:-0.8603 G loss:-1.891\n",
      "Epoch:  0049 D loss:-0.5347 G loss:-2.221\n",
      "Epoch:  0049 D loss:-0.7025 G loss:-1.797\n",
      "Epoch:  0049 D loss:-0.6071 G loss:-2.295\n",
      "Epoch:  0049 D loss:-0.6446 G loss:-2.216\n",
      "Epoch:  0049 D loss:-0.6375 G loss:-2.236\n",
      "Epoch:  0049 D loss:-0.8143 G loss:-2.176\n",
      "Epoch:  0049 D loss:-0.585 G loss:-2.26\n",
      "Epoch:  0049 D loss:-0.6575 G loss:-2.332\n",
      "Epoch:  0049 D loss:-0.7522 G loss:-2.157\n",
      "Epoch:  0049 D loss:-0.765 G loss:-2.13\n",
      "Epoch:  0049 D loss:-0.5994 G loss:-2.025\n",
      "Epoch:  0049 D loss:-0.675 G loss:-2.131\n",
      "Epoch:  0049 D loss:-0.6489 G loss:-2.275\n",
      "Epoch:  0049 D loss:-0.702 G loss:-2.162\n",
      "Epoch:  0049 D loss:-0.6696 G loss:-2.067\n",
      "Epoch:  0049 D loss:-0.656 G loss:-2.16\n",
      "Epoch:  0049 D loss:-0.6903 G loss:-2.1\n",
      "Epoch:  0049 D loss:-0.7838 G loss:-2.093\n",
      "Epoch:  0049 D loss:-0.8236 G loss:-1.966\n",
      "Epoch:  0049 D loss:-0.5317 G loss:-2.155\n",
      "Epoch:  0049 D loss:-0.5592 G loss:-2.027\n",
      "Epoch:  0049 D loss:-0.6477 G loss:-2.001\n",
      "Epoch:  0049 D loss:-0.5491 G loss:-2.279\n",
      "Epoch:  0049 D loss:-0.6053 G loss:-2.175\n",
      "Epoch:  0049 D loss:-0.5145 G loss:-2.513\n",
      "Epoch:  0049 D loss:-0.6482 G loss:-2.309\n",
      "Epoch:  0049 D loss:-0.7404 G loss:-2.055\n",
      "Epoch:  0049 D loss:-0.5448 G loss:-2.187\n",
      "Epoch:  0049 D loss:-0.641 G loss:-2.114\n",
      "Epoch:  0049 D loss:-0.6485 G loss:-2.178\n",
      "Epoch:  0049 D loss:-0.654 G loss:-2.16\n",
      "Epoch:  0049 D loss:-0.7737 G loss:-2.328\n",
      "Epoch:  0049 D loss:-0.6331 G loss:-2.18\n",
      "Epoch:  0049 D loss:-0.5629 G loss:-2.102\n",
      "Epoch:  0049 D loss:-0.5874 G loss:-2.345\n",
      "Epoch:  0049 D loss:-0.6225 G loss:-2.124\n",
      "Epoch:  0049 D loss:-0.5797 G loss:-2.262\n",
      "Epoch:  0049 D loss:-0.6101 G loss:-2.136\n",
      "Epoch:  0049 D loss:-0.5828 G loss:-2.005\n",
      "Epoch:  0049 D loss:-0.6412 G loss:-2.035\n",
      "Epoch:  0049 D loss:-0.6021 G loss:-2.108\n",
      "Epoch:  0049 D loss:-0.6296 G loss:-2.276\n",
      "Epoch:  0049 D loss:-0.6564 G loss:-1.931\n",
      "Epoch:  0049 D loss:-0.6669 G loss:-2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0049 D loss:-0.5327 G loss:-2.184\n",
      "Epoch:  0049 D loss:-0.5904 G loss:-2.101\n",
      "Epoch:  0049 D loss:-0.7355 G loss:-1.923\n",
      "Epoch:  0049 D loss:-0.6024 G loss:-2.107\n",
      "Epoch:  0049 D loss:-0.6791 G loss:-2.071\n",
      "Epoch:  0049 D loss:-0.5624 G loss:-2.5\n",
      "Epoch:  0049 D loss:-0.658 G loss:-2.008\n",
      "Epoch:  0049 D loss:-0.6677 G loss:-2.358\n",
      "Epoch:  0049 D loss:-0.5356 G loss:-2.56\n",
      "Epoch:  0049 D loss:-0.7799 G loss:-2.111\n",
      "Epoch:  0049 D loss:-0.6472 G loss:-2.348\n",
      "Epoch:  0049 D loss:-0.5049 G loss:-2.158\n",
      "Epoch:  0049 D loss:-0.6294 G loss:-2.205\n",
      "Epoch:  0049 D loss:-0.6207 G loss:-2.094\n",
      "Epoch:  0049 D loss:-0.5658 G loss:-2.212\n",
      "Epoch:  0049 D loss:-0.6609 G loss:-2.309\n",
      "Epoch:  0049 D loss:-0.5402 G loss:-2.023\n",
      "Epoch:  0049 D loss:-0.6317 G loss:-1.914\n",
      "Epoch:  0049 D loss:-0.5682 G loss:-2.153\n",
      "Epoch:  0049 D loss:-0.686 G loss:-2.073\n",
      "Epoch:  0049 D loss:-0.5942 G loss:-2.157\n",
      "Epoch:  0049 D loss:-0.6683 G loss:-2.127\n",
      "Epoch:  0049 D loss:-0.6408 G loss:-2.132\n",
      "Epoch:  0049 D loss:-0.6114 G loss:-2.09\n",
      "Epoch:  0049 D loss:-0.6613 G loss:-2.01\n",
      "Epoch:  0049 D loss:-0.6235 G loss:-2.187\n",
      "Epoch:  0049 D loss:-0.7297 G loss:-2.115\n",
      "Epoch:  0049 D loss:-0.6535 G loss:-2.071\n",
      "Epoch:  0049 D loss:-0.755 G loss:-2.379\n",
      "Epoch:  0049 D loss:-0.7363 G loss:-2.244\n",
      "Epoch:  0049 D loss:-0.7531 G loss:-2.354\n",
      "Epoch:  0049 D loss:-0.7194 G loss:-2.375\n",
      "Epoch:  0049 D loss:-0.7071 G loss:-2.321\n",
      "Epoch:  0049 D loss:-0.6774 G loss:-2.097\n",
      "Epoch:  0049 D loss:-0.7039 G loss:-2.14\n",
      "Epoch:  0049 D loss:-0.4872 G loss:-2.282\n",
      "Epoch:  0049 D loss:-0.6165 G loss:-2.288\n",
      "Epoch:  0049 D loss:-0.5376 G loss:-2.299\n",
      "Epoch:  0049 D loss:-0.6119 G loss:-2.188\n",
      "Epoch:  0049 D loss:-0.7229 G loss:-2.04\n",
      "Epoch:  0049 D loss:-0.7184 G loss:-2.122\n",
      "Epoch:  0049 D loss:-0.6594 G loss:-2.184\n",
      "Epoch:  0049 D loss:-0.6097 G loss:-2.143\n",
      "Epoch:  0049 D loss:-0.7881 G loss:-2.076\n",
      "Epoch:  0049 D loss:-0.6372 G loss:-2.157\n",
      "Epoch:  0049 D loss:-0.6804 G loss:-2.128\n",
      "Epoch:  0049 D loss:-0.6166 G loss:-2.191\n",
      "Epoch:  0049 D loss:-0.6204 G loss:-2.322\n",
      "Epoch:  0049 D loss:-0.6689 G loss:-2.083\n",
      "Epoch:  0049 D loss:-0.6872 G loss:-2.332\n",
      "Epoch:  0049 D loss:-0.7398 G loss:-2.343\n",
      "Epoch:  0049 D loss:-0.6684 G loss:-2.466\n",
      "Epoch:  0049 D loss:-0.6978 G loss:-2.03\n",
      "Epoch:  0049 D loss:-0.4334 G loss:-2.146\n",
      "Epoch:  0049 D loss:-0.7243 G loss:-2.213\n",
      "Epoch:  0049 D loss:-0.6164 G loss:-2.131\n",
      "Epoch:  0049 D loss:-0.6156 G loss:-2.279\n",
      "Epoch:  0049 D loss:-0.6017 G loss:-2.22\n",
      "Epoch:  0049 D loss:-0.6127 G loss:-2.23\n",
      "Epoch:  0049 D loss:-0.6196 G loss:-2.526\n",
      "Epoch:  0049 D loss:-0.575 G loss:-2.322\n",
      "Epoch:  0049 D loss:-0.6195 G loss:-2.365\n",
      "Epoch:  0049 D loss:-0.6297 G loss:-2.192\n",
      "Epoch:  0049 D loss:-0.5581 G loss:-2.185\n",
      "Epoch:  0049 D loss:-0.5747 G loss:-2.541\n",
      "Epoch:  0049 D loss:-0.5753 G loss:-2.248\n",
      "Epoch:  0049 D loss:-0.5429 G loss:-2.379\n",
      "Epoch:  0049 D loss:-0.7691 G loss:-2.02\n",
      "Epoch:  0049 D loss:-0.5768 G loss:-2.133\n",
      "Epoch:  0049 D loss:-0.6642 G loss:-2.106\n",
      "Epoch:  0049 D loss:-0.7224 G loss:-1.972\n",
      "Epoch:  0049 D loss:-0.5529 G loss:-2.284\n",
      "Epoch:  0049 D loss:-0.7638 G loss:-1.99\n",
      "Epoch:  0049 D loss:-0.7317 G loss:-2.166\n",
      "Epoch:  0049 D loss:-0.6662 G loss:-2.282\n",
      "Epoch:  0049 D loss:-0.6047 G loss:-2.202\n",
      "Epoch:  0049 D loss:-0.6796 G loss:-2.114\n",
      "Epoch:  0049 D loss:-0.6456 G loss:-2.003\n",
      "Epoch:  0049 D loss:-0.6093 G loss:-2.096\n",
      "Epoch:  0049 D loss:-0.7482 G loss:-2.208\n",
      "Epoch:  0049 D loss:-0.7086 G loss:-1.936\n",
      "Epoch:  0049 D loss:-0.6563 G loss:-2.139\n",
      "Epoch:  0049 D loss:-0.5582 G loss:-2.501\n",
      "Epoch:  0049 D loss:-0.7292 G loss:-2.244\n",
      "Epoch:  0049 D loss:-0.6931 G loss:-2.031\n",
      "Epoch:  0049 D loss:-0.7549 G loss:-2.108\n",
      "Epoch:  0049 D loss:-0.7345 G loss:-2.105\n",
      "Epoch:  0049 D loss:-0.7443 G loss:-2.099\n",
      "Epoch:  0049 D loss:-0.7749 G loss:-1.909\n",
      "Epoch:  0049 D loss:-0.6072 G loss:-2.178\n",
      "Epoch:  0049 D loss:-0.7745 G loss:-2.161\n",
      "Epoch:  0049 D loss:-0.6239 G loss:-2.413\n",
      "Epoch:  0049 D loss:-0.6209 G loss:-2.385\n",
      "Epoch:  0049 D loss:-0.5628 G loss:-2.159\n",
      "Epoch:  0049 D loss:-0.5508 G loss:-2.22\n",
      "Epoch:  0049 D loss:-0.7876 G loss:-2.227\n",
      "Epoch:  0049 D loss:-0.6866 G loss:-2.264\n",
      "Epoch:  0049 D loss:-0.5156 G loss:-2.418\n",
      "Epoch:  0049 D loss:-0.6637 G loss:-2.336\n",
      "Epoch:  0049 D loss:-0.5902 G loss:-2.275\n",
      "Epoch:  0049 D loss:-0.5969 G loss:-2.254\n",
      "Epoch:  0049 D loss:-0.5903 G loss:-2.241\n",
      "Epoch:  0049 D loss:-0.5072 G loss:-2.205\n",
      "Epoch:  0049 D loss:-0.6707 G loss:-2.391\n",
      "Epoch:  0049 D loss:-0.5927 G loss:-2.1\n",
      "Epoch:  0049 D loss:-0.5808 G loss:-2.314\n",
      "Epoch:  0049 D loss:-0.7132 G loss:-2.184\n",
      "Epoch:  0049 D loss:-0.7038 G loss:-1.957\n",
      "Epoch:  0049 D loss:-0.6586 G loss:-2.036\n",
      "Epoch:  0049 D loss:-0.5097 G loss:-2.238\n",
      "Epoch:  0049 D loss:-0.8203 G loss:-2.059\n",
      "Epoch:  0049 D loss:-0.665 G loss:-2.267\n",
      "Epoch:  0049 D loss:-0.626 G loss:-2.239\n",
      "Epoch:  0049 D loss:-0.6311 G loss:-2.2\n",
      "Epoch:  0049 D loss:-0.5504 G loss:-2.126\n",
      "Epoch:  0049 D loss:-0.6915 G loss:-2.041\n",
      "Epoch:  0049 D loss:-0.5919 G loss:-2.27\n",
      "Epoch:  0049 D loss:-0.9395 G loss:-1.933\n",
      "Epoch:  0049 D loss:-0.5033 G loss:-2.199\n",
      "Epoch:  0049 D loss:-0.466 G loss:-2.454\n",
      "Epoch:  0049 D loss:-0.6314 G loss:-2.142\n",
      "Epoch:  0049 D loss:-0.6489 G loss:-2.034\n",
      "Epoch:  0049 D loss:-0.7367 G loss:-2.101\n",
      "Epoch:  0049 D loss:-0.6852 G loss:-2.13\n",
      "Epoch:  0049 D loss:-0.6123 G loss:-2.294\n",
      "Epoch:  0049 D loss:-0.6438 G loss:-2.176\n",
      "Epoch:  0049 D loss:-0.6817 G loss:-2.099\n",
      "Epoch:  0049 D loss:-0.7988 G loss:-2.085\n",
      "Epoch:  0049 D loss:-0.5814 G loss:-2.41\n",
      "Epoch:  0049 D loss:-0.6254 G loss:-2.156\n",
      "Epoch:  0049 D loss:-0.5454 G loss:-2.496\n",
      "Epoch:  0049 D loss:-0.6347 G loss:-2.048\n",
      "Epoch:  0049 D loss:-0.7021 G loss:-2.163\n",
      "Epoch:  0049 D loss:-0.6795 G loss:-2.22\n",
      "Epoch:  0049 D loss:-0.6278 G loss:-2.205\n",
      "Epoch:  0049 D loss:-0.633 G loss:-2.264\n",
      "Epoch:  0049 D loss:-0.4886 G loss:-2.437\n",
      "Epoch:  0049 D loss:-0.5579 G loss:-2.122\n",
      "Epoch:  0049 D loss:-0.6234 G loss:-2.45\n",
      "Epoch:  0049 D loss:-0.5359 G loss:-2.478\n",
      "Epoch:  0049 D loss:-0.7133 G loss:-2.29\n",
      "Epoch:  0049 D loss:-0.6624 G loss:-2.239\n",
      "Epoch:  0049 D loss:-0.6254 G loss:-2.535\n",
      "Epoch:  0049 D loss:-0.6219 G loss:-2.293\n",
      "Epoch:  0049 D loss:-0.5578 G loss:-2.138\n",
      "Epoch:  0049 D loss:-0.513 G loss:-2.265\n",
      "Epoch:  0049 D loss:-0.629 G loss:-1.942\n",
      "Epoch:  0049 D loss:-0.6201 G loss:-1.968\n",
      "Epoch:  0049 D loss:-0.5409 G loss:-2.117\n",
      "Epoch:  0049 D loss:-0.5886 G loss:-2.17\n",
      "Epoch:  0049 D loss:-0.6705 G loss:-2.27\n",
      "Epoch:  0049 D loss:-0.5887 G loss:-2.403\n",
      "Epoch:  0049 D loss:-0.7328 G loss:-2.449\n",
      "Epoch:  0049 D loss:-0.4785 G loss:-2.546\n",
      "Epoch:  0049 D loss:-0.5299 G loss:-2.444\n",
      "Epoch:  0049 D loss:-0.5437 G loss:-2.417\n",
      "Epoch:  0049 D loss:-0.5702 G loss:-2.384\n",
      "Epoch:  0049 D loss:-0.5565 G loss:-2.129\n",
      "Epoch:  0049 D loss:-0.5759 G loss:-2.219\n",
      "Epoch:  0049 D loss:-0.5783 G loss:-2.277\n",
      "Epoch:  0049 D loss:-0.8289 G loss:-2.116\n",
      "Epoch:  0049 D loss:-0.4855 G loss:-2.139\n",
      "Epoch:  0049 D loss:-0.5311 G loss:-2.246\n",
      "Epoch:  0049 D loss:-0.5903 G loss:-2.064\n",
      "Epoch:  0049 D loss:-0.6389 G loss:-2.056\n",
      "Epoch:  0049 D loss:-0.5678 G loss:-2.365\n",
      "Epoch:  0049 D loss:-0.5955 G loss:-2.098\n",
      "Epoch:  0049 D loss:-0.5154 G loss:-2.18\n",
      "Epoch:  0049 D loss:-0.6101 G loss:-2.001\n",
      "Epoch:  0049 D loss:-0.4925 G loss:-2.224\n",
      "Epoch:  0049 D loss:-0.488 G loss:-2.449\n",
      "Epoch:  0049 D loss:-0.6807 G loss:-2.249\n",
      "Epoch:  0049 D loss:-0.6366 G loss:-2.325\n",
      "Epoch:  0049 D loss:-0.6659 G loss:-2.241\n",
      "Epoch:  0049 D loss:-0.6347 G loss:-2.249\n",
      "Epoch:  0049 D loss:-0.4952 G loss:-2.447\n",
      "Epoch:  0049 D loss:-0.5428 G loss:-2.216\n",
      "Epoch:  0049 D loss:-0.7193 G loss:-2.185\n",
      "Epoch:  0049 D loss:-0.6808 G loss:-2.236\n",
      "Epoch:  0049 D loss:-0.7088 G loss:-2.235\n",
      "Epoch:  0049 D loss:-0.5872 G loss:-2.317\n",
      "Epoch:  0049 D loss:-0.6841 G loss:-2.117\n",
      "Epoch:  0049 D loss:-0.5976 G loss:-2.064\n",
      "Epoch:  0049 D loss:-0.6152 G loss:-2.301\n",
      "Epoch:  0049 D loss:-0.7178 G loss:-2.075\n",
      "Epoch:  0049 D loss:-0.6106 G loss:-2.179\n",
      "Epoch:  0049 D loss:-0.7924 G loss:-1.844\n",
      "Epoch:  0049 D loss:-0.8096 G loss:-1.885\n",
      "Epoch:  0049 D loss:-0.5873 G loss:-2.065\n",
      "Epoch:  0049 D loss:-0.4592 G loss:-2.051\n",
      "Epoch:  0049 D loss:-0.5988 G loss:-2.251\n",
      "Epoch:  0049 D loss:-0.641 G loss:-2.144\n",
      "Epoch:  0049 D loss:-0.7095 G loss:-2.215\n",
      "Epoch:  0049 D loss:-0.5731 G loss:-2.329\n",
      "Epoch:  0049 D loss:-0.5385 G loss:-2.291\n",
      "Epoch:  0049 D loss:-0.7104 G loss:-2.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0050 D loss:-0.602 G loss:-2.383\n",
      "Epoch:  0050 D loss:-0.4637 G loss:-2.478\n",
      "Epoch:  0050 D loss:-0.5692 G loss:-2.473\n",
      "Epoch:  0050 D loss:-0.7165 G loss:-2.098\n",
      "Epoch:  0050 D loss:-0.6396 G loss:-2.342\n",
      "Epoch:  0050 D loss:-0.7338 G loss:-2.161\n",
      "Epoch:  0050 D loss:-0.7621 G loss:-1.949\n",
      "Epoch:  0050 D loss:-0.5347 G loss:-2.073\n",
      "Epoch:  0050 D loss:-0.6354 G loss:-2.219\n",
      "Epoch:  0050 D loss:-0.7763 G loss:-2.215\n",
      "Epoch:  0050 D loss:-0.7436 G loss:-2.052\n",
      "Epoch:  0050 D loss:-0.754 G loss:-1.952\n",
      "Epoch:  0050 D loss:-0.7933 G loss:-1.898\n",
      "Epoch:  0050 D loss:-0.6337 G loss:-2.172\n",
      "Epoch:  0050 D loss:-0.6886 G loss:-2.202\n",
      "Epoch:  0050 D loss:-0.6475 G loss:-2.213\n",
      "Epoch:  0050 D loss:-0.6571 G loss:-2.216\n",
      "Epoch:  0050 D loss:-0.6345 G loss:-2.243\n",
      "Epoch:  0050 D loss:-0.5845 G loss:-2.148\n",
      "Epoch:  0050 D loss:-0.64 G loss:-2.112\n",
      "Epoch:  0050 D loss:-0.5576 G loss:-2.523\n",
      "Epoch:  0050 D loss:-0.6923 G loss:-2.313\n",
      "Epoch:  0050 D loss:-0.6047 G loss:-2.127\n",
      "Epoch:  0050 D loss:-0.6822 G loss:-1.861\n",
      "Epoch:  0050 D loss:-0.6134 G loss:-2.199\n",
      "Epoch:  0050 D loss:-0.6934 G loss:-2.022\n",
      "Epoch:  0050 D loss:-0.6819 G loss:-2.054\n",
      "Epoch:  0050 D loss:-0.6127 G loss:-1.951\n",
      "Epoch:  0050 D loss:-0.7168 G loss:-1.78\n",
      "Epoch:  0050 D loss:-0.6828 G loss:-1.879\n",
      "Epoch:  0050 D loss:-0.6005 G loss:-2.245\n",
      "Epoch:  0050 D loss:-0.6449 G loss:-2.082\n",
      "Epoch:  0050 D loss:-0.6422 G loss:-2.177\n",
      "Epoch:  0050 D loss:-0.7047 G loss:-2.34\n",
      "Epoch:  0050 D loss:-0.5994 G loss:-2.253\n",
      "Epoch:  0050 D loss:-0.4476 G loss:-2.176\n",
      "Epoch:  0050 D loss:-0.6575 G loss:-2.081\n",
      "Epoch:  0050 D loss:-0.6344 G loss:-2.172\n",
      "Epoch:  0050 D loss:-0.5682 G loss:-2.244\n",
      "Epoch:  0050 D loss:-0.6728 G loss:-2.04\n",
      "Epoch:  0050 D loss:-0.48 G loss:-2.192\n",
      "Epoch:  0050 D loss:-0.6041 G loss:-2.256\n",
      "Epoch:  0050 D loss:-0.5828 G loss:-2.351\n",
      "Epoch:  0050 D loss:-0.6528 G loss:-2.207\n",
      "Epoch:  0050 D loss:-0.7129 G loss:-2.11\n",
      "Epoch:  0050 D loss:-0.6369 G loss:-2.105\n",
      "Epoch:  0050 D loss:-0.6996 G loss:-2.054\n",
      "Epoch:  0050 D loss:-0.6444 G loss:-2.209\n",
      "Epoch:  0050 D loss:-0.7221 G loss:-2.288\n",
      "Epoch:  0050 D loss:-0.5881 G loss:-2.342\n",
      "Epoch:  0050 D loss:-0.7735 G loss:-2.363\n",
      "Epoch:  0050 D loss:-0.4904 G loss:-2.306\n",
      "Epoch:  0050 D loss:-0.7126 G loss:-2.207\n",
      "Epoch:  0050 D loss:-0.8075 G loss:-2.23\n",
      "Epoch:  0050 D loss:-0.6535 G loss:-2.114\n",
      "Epoch:  0050 D loss:-0.5492 G loss:-2.24\n",
      "Epoch:  0050 D loss:-0.6716 G loss:-2.224\n",
      "Epoch:  0050 D loss:-0.6528 G loss:-2.203\n",
      "Epoch:  0050 D loss:-0.6772 G loss:-1.893\n",
      "Epoch:  0050 D loss:-0.6862 G loss:-2.09\n",
      "Epoch:  0050 D loss:-0.6051 G loss:-2.134\n",
      "Epoch:  0050 D loss:-0.709 G loss:-2.048\n",
      "Epoch:  0050 D loss:-0.7692 G loss:-1.952\n",
      "Epoch:  0050 D loss:-0.6594 G loss:-1.939\n",
      "Epoch:  0050 D loss:-0.6807 G loss:-2.077\n",
      "Epoch:  0050 D loss:-0.6229 G loss:-2.362\n",
      "Epoch:  0050 D loss:-0.6144 G loss:-2.071\n",
      "Epoch:  0050 D loss:-0.6874 G loss:-2.205\n",
      "Epoch:  0050 D loss:-0.6602 G loss:-2.117\n",
      "Epoch:  0050 D loss:-0.6171 G loss:-2.312\n",
      "Epoch:  0050 D loss:-0.6554 G loss:-2.199\n",
      "Epoch:  0050 D loss:-0.6468 G loss:-2.079\n",
      "Epoch:  0050 D loss:-0.6008 G loss:-2.039\n",
      "Epoch:  0050 D loss:-0.6508 G loss:-2.08\n",
      "Epoch:  0050 D loss:-0.6128 G loss:-1.809\n",
      "Epoch:  0050 D loss:-0.6654 G loss:-2.044\n",
      "Epoch:  0050 D loss:-0.6566 G loss:-2.182\n",
      "Epoch:  0050 D loss:-0.569 G loss:-2.386\n",
      "Epoch:  0050 D loss:-0.6525 G loss:-2.06\n",
      "Epoch:  0050 D loss:-0.6622 G loss:-2.256\n",
      "Epoch:  0050 D loss:-0.6909 G loss:-2.044\n",
      "Epoch:  0050 D loss:-0.6556 G loss:-2.266\n",
      "Epoch:  0050 D loss:-0.7907 G loss:-2.214\n",
      "Epoch:  0050 D loss:-0.5567 G loss:-2.208\n",
      "Epoch:  0050 D loss:-0.5261 G loss:-2.117\n",
      "Epoch:  0050 D loss:-0.5765 G loss:-2.197\n",
      "Epoch:  0050 D loss:-0.6127 G loss:-2.308\n",
      "Epoch:  0050 D loss:-0.5394 G loss:-2.256\n",
      "Epoch:  0050 D loss:-0.5472 G loss:-2.313\n",
      "Epoch:  0050 D loss:-0.6752 G loss:-2.27\n",
      "Epoch:  0050 D loss:-0.4945 G loss:-2.358\n",
      "Epoch:  0050 D loss:-0.5603 G loss:-2.366\n",
      "Epoch:  0050 D loss:-0.5206 G loss:-2.215\n",
      "Epoch:  0050 D loss:-0.5673 G loss:-2.456\n",
      "Epoch:  0050 D loss:-0.5268 G loss:-2.409\n",
      "Epoch:  0050 D loss:-0.5132 G loss:-2.33\n",
      "Epoch:  0050 D loss:-0.6132 G loss:-2.176\n",
      "Epoch:  0050 D loss:-0.7173 G loss:-1.784\n",
      "Epoch:  0050 D loss:-0.5781 G loss:-2.221\n",
      "Epoch:  0050 D loss:-0.742 G loss:-1.951\n",
      "Epoch:  0050 D loss:-0.6446 G loss:-2.113\n",
      "Epoch:  0050 D loss:-0.6441 G loss:-2.273\n",
      "Epoch:  0050 D loss:-0.7374 G loss:-1.97\n",
      "Epoch:  0050 D loss:-0.5001 G loss:-2.437\n",
      "Epoch:  0050 D loss:-0.6039 G loss:-2.018\n",
      "Epoch:  0050 D loss:-0.5204 G loss:-2.39\n",
      "Epoch:  0050 D loss:-0.4748 G loss:-2.477\n",
      "Epoch:  0050 D loss:-0.7304 G loss:-2.621\n",
      "Epoch:  0050 D loss:-0.5459 G loss:-2.292\n",
      "Epoch:  0050 D loss:-0.6149 G loss:-2.36\n",
      "Epoch:  0050 D loss:-0.6339 G loss:-2.134\n",
      "Epoch:  0050 D loss:-0.7908 G loss:-2.325\n",
      "Epoch:  0050 D loss:-0.6196 G loss:-2.045\n",
      "Epoch:  0050 D loss:-0.4781 G loss:-2.465\n",
      "Epoch:  0050 D loss:-0.6692 G loss:-2.439\n",
      "Epoch:  0050 D loss:-0.4447 G loss:-2.309\n",
      "Epoch:  0050 D loss:-0.4894 G loss:-2.181\n",
      "Epoch:  0050 D loss:-0.5368 G loss:-1.859\n",
      "Epoch:  0050 D loss:-0.5856 G loss:-2.113\n",
      "Epoch:  0050 D loss:-0.638 G loss:-2.094\n",
      "Epoch:  0050 D loss:-0.6659 G loss:-2.126\n",
      "Epoch:  0050 D loss:-0.6173 G loss:-2.14\n",
      "Epoch:  0050 D loss:-0.6074 G loss:-2.538\n",
      "Epoch:  0050 D loss:-0.6765 G loss:-2.296\n",
      "Epoch:  0050 D loss:-0.578 G loss:-2.554\n",
      "Epoch:  0050 D loss:-0.4907 G loss:-2.35\n",
      "Epoch:  0050 D loss:-0.6225 G loss:-2.011\n",
      "Epoch:  0050 D loss:-0.6254 G loss:-2.246\n",
      "Epoch:  0050 D loss:-0.7187 G loss:-2.263\n",
      "Epoch:  0050 D loss:-0.6505 G loss:-2.165\n",
      "Epoch:  0050 D loss:-0.5799 G loss:-2.182\n",
      "Epoch:  0050 D loss:-0.5476 G loss:-2.313\n",
      "Epoch:  0050 D loss:-0.5574 G loss:-2.186\n",
      "Epoch:  0050 D loss:-0.5711 G loss:-2.22\n",
      "Epoch:  0050 D loss:-0.5327 G loss:-2.211\n",
      "Epoch:  0050 D loss:-0.5233 G loss:-2.26\n",
      "Epoch:  0050 D loss:-0.6039 G loss:-2.132\n",
      "Epoch:  0050 D loss:-0.521 G loss:-2.104\n",
      "Epoch:  0050 D loss:-0.6931 G loss:-2.048\n",
      "Epoch:  0050 D loss:-0.6575 G loss:-2.239\n",
      "Epoch:  0050 D loss:-0.6332 G loss:-2.167\n",
      "Epoch:  0050 D loss:-0.5562 G loss:-2.13\n",
      "Epoch:  0050 D loss:-0.5127 G loss:-2.116\n",
      "Epoch:  0050 D loss:-0.5912 G loss:-2.201\n",
      "Epoch:  0050 D loss:-0.5245 G loss:-2.335\n",
      "Epoch:  0050 D loss:-0.5862 G loss:-2.497\n",
      "Epoch:  0050 D loss:-0.5458 G loss:-2.54\n",
      "Epoch:  0050 D loss:-0.6717 G loss:-2.426\n",
      "Epoch:  0050 D loss:-0.6557 G loss:-2.217\n",
      "Epoch:  0050 D loss:-0.6806 G loss:-2.036\n",
      "Epoch:  0050 D loss:-0.626 G loss:-2.084\n",
      "Epoch:  0050 D loss:-0.723 G loss:-1.895\n",
      "Epoch:  0050 D loss:-0.5945 G loss:-2.387\n",
      "Epoch:  0050 D loss:-0.6265 G loss:-2.192\n",
      "Epoch:  0050 D loss:-0.5661 G loss:-2.029\n",
      "Epoch:  0050 D loss:-0.6057 G loss:-2.067\n",
      "Epoch:  0050 D loss:-0.7126 G loss:-1.982\n",
      "Epoch:  0050 D loss:-0.5876 G loss:-2.178\n",
      "Epoch:  0050 D loss:-0.6506 G loss:-1.914\n",
      "Epoch:  0050 D loss:-0.6304 G loss:-2.101\n",
      "Epoch:  0050 D loss:-0.5988 G loss:-2.363\n",
      "Epoch:  0050 D loss:-0.7523 G loss:-2.133\n",
      "Epoch:  0050 D loss:-0.6333 G loss:-2.172\n",
      "Epoch:  0050 D loss:-0.5085 G loss:-2.567\n",
      "Epoch:  0050 D loss:-0.6341 G loss:-2.156\n",
      "Epoch:  0050 D loss:-0.4945 G loss:-2.182\n",
      "Epoch:  0050 D loss:-0.4856 G loss:-2.46\n",
      "Epoch:  0050 D loss:-0.6793 G loss:-2.323\n",
      "Epoch:  0050 D loss:-0.5192 G loss:-2.135\n",
      "Epoch:  0050 D loss:-0.5575 G loss:-2.329\n",
      "Epoch:  0050 D loss:-0.5568 G loss:-2.245\n",
      "Epoch:  0050 D loss:-0.5082 G loss:-2.374\n",
      "Epoch:  0050 D loss:-0.558 G loss:-2.294\n",
      "Epoch:  0050 D loss:-0.5834 G loss:-2.232\n",
      "Epoch:  0050 D loss:-0.4886 G loss:-2.386\n",
      "Epoch:  0050 D loss:-0.5562 G loss:-2.657\n",
      "Epoch:  0050 D loss:-0.5089 G loss:-2.6\n",
      "Epoch:  0050 D loss:-0.4453 G loss:-2.281\n",
      "Epoch:  0050 D loss:-0.5759 G loss:-2.226\n",
      "Epoch:  0050 D loss:-0.5802 G loss:-2.373\n",
      "Epoch:  0050 D loss:-0.5747 G loss:-2.305\n",
      "Epoch:  0050 D loss:-0.5891 G loss:-1.996\n",
      "Epoch:  0050 D loss:-0.5499 G loss:-2.25\n",
      "Epoch:  0050 D loss:-0.5782 G loss:-2.172\n",
      "Epoch:  0050 D loss:-0.583 G loss:-2.187\n",
      "Epoch:  0050 D loss:-0.5973 G loss:-2.03\n",
      "Epoch:  0050 D loss:-0.602 G loss:-2.018\n",
      "Epoch:  0050 D loss:-0.5886 G loss:-2.262\n",
      "Epoch:  0050 D loss:-0.7423 G loss:-2.133\n",
      "Epoch:  0050 D loss:-0.5992 G loss:-2.421\n",
      "Epoch:  0050 D loss:-0.5568 G loss:-2.136\n",
      "Epoch:  0050 D loss:-0.6754 G loss:-2.36\n",
      "Epoch:  0050 D loss:-0.6896 G loss:-2.11\n",
      "Epoch:  0050 D loss:-0.6632 G loss:-2.208\n",
      "Epoch:  0050 D loss:-0.7952 G loss:-1.964\n",
      "Epoch:  0050 D loss:-0.5753 G loss:-2.219\n",
      "Epoch:  0050 D loss:-0.6276 G loss:-2.087\n",
      "Epoch:  0050 D loss:-0.5927 G loss:-2.171\n",
      "Epoch:  0050 D loss:-0.6461 G loss:-2.031\n",
      "Epoch:  0050 D loss:-0.702 G loss:-2.03\n",
      "Epoch:  0050 D loss:-0.708 G loss:-2.191\n",
      "Epoch:  0050 D loss:-0.5607 G loss:-1.996\n",
      "Epoch:  0050 D loss:-0.509 G loss:-2.307\n",
      "Epoch:  0050 D loss:-0.4713 G loss:-2.491\n",
      "Epoch:  0050 D loss:-0.6704 G loss:-2.254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0050 D loss:-0.5713 G loss:-2.514\n",
      "Epoch:  0050 D loss:-0.5411 G loss:-2.223\n",
      "Epoch:  0050 D loss:-0.6391 G loss:-2.115\n",
      "Epoch:  0050 D loss:-0.6657 G loss:-2.252\n",
      "Epoch:  0050 D loss:-0.684 G loss:-2.133\n",
      "Epoch:  0050 D loss:-0.6087 G loss:-1.91\n",
      "Epoch:  0050 D loss:-0.6493 G loss:-1.99\n",
      "Epoch:  0050 D loss:-0.6156 G loss:-2.213\n",
      "Epoch:  0050 D loss:-0.6245 G loss:-2.016\n",
      "Epoch:  0050 D loss:-0.6574 G loss:-2.069\n",
      "Epoch:  0050 D loss:-0.5744 G loss:-2.288\n",
      "Epoch:  0050 D loss:-0.4586 G loss:-2.217\n",
      "Epoch:  0050 D loss:-0.6261 G loss:-2.193\n",
      "Epoch:  0050 D loss:-0.5613 G loss:-2.239\n",
      "Epoch:  0050 D loss:-0.7799 G loss:-2.235\n",
      "Epoch:  0050 D loss:-0.5387 G loss:-2.345\n",
      "Epoch:  0050 D loss:-0.5111 G loss:-2.342\n",
      "Epoch:  0050 D loss:-0.6383 G loss:-2.248\n",
      "Epoch:  0050 D loss:-0.6258 G loss:-2.322\n",
      "Epoch:  0050 D loss:-0.5827 G loss:-2.572\n",
      "Epoch:  0050 D loss:-0.6683 G loss:-2.417\n",
      "Epoch:  0050 D loss:-0.5009 G loss:-2.284\n",
      "Epoch:  0050 D loss:-0.6299 G loss:-2.272\n",
      "Epoch:  0050 D loss:-0.541 G loss:-2.25\n",
      "Epoch:  0050 D loss:-0.6342 G loss:-2.442\n",
      "Epoch:  0050 D loss:-0.7337 G loss:-2.043\n",
      "Epoch:  0050 D loss:-0.5512 G loss:-1.963\n",
      "Epoch:  0050 D loss:-0.5445 G loss:-2.17\n",
      "Epoch:  0050 D loss:-0.8051 G loss:-2.021\n",
      "Epoch:  0050 D loss:-0.6198 G loss:-2.016\n",
      "Epoch:  0050 D loss:-0.5561 G loss:-2.149\n",
      "Epoch:  0050 D loss:-0.4673 G loss:-2.146\n",
      "Epoch:  0050 D loss:-0.5912 G loss:-2.171\n",
      "Epoch:  0050 D loss:-0.5937 G loss:-2.383\n",
      "Epoch:  0050 D loss:-0.6574 G loss:-2.31\n",
      "Epoch:  0050 D loss:-0.5706 G loss:-2.182\n",
      "Epoch:  0050 D loss:-0.6922 G loss:-2.177\n",
      "Epoch:  0050 D loss:-0.8055 G loss:-2.153\n",
      "Epoch:  0050 D loss:-0.5932 G loss:-2.133\n",
      "Epoch:  0050 D loss:-0.5774 G loss:-2.404\n",
      "Epoch:  0050 D loss:-0.6619 G loss:-2.499\n",
      "Epoch:  0050 D loss:-0.5978 G loss:-2.502\n",
      "Epoch:  0050 D loss:-0.709 G loss:-2.217\n",
      "Epoch:  0050 D loss:-0.5596 G loss:-2.212\n",
      "Epoch:  0050 D loss:-0.7115 G loss:-2.279\n",
      "Epoch:  0050 D loss:-0.6631 G loss:-2.119\n",
      "Epoch:  0050 D loss:-0.6882 G loss:-2.063\n",
      "Epoch:  0050 D loss:-0.723 G loss:-2.144\n",
      "Epoch:  0050 D loss:-0.7685 G loss:-1.887\n",
      "Epoch:  0050 D loss:-0.5573 G loss:-2.199\n",
      "Epoch:  0050 D loss:-0.5759 G loss:-2.108\n",
      "Epoch:  0050 D loss:-0.6352 G loss:-2.186\n",
      "Epoch:  0050 D loss:-0.7845 G loss:-1.86\n",
      "Epoch:  0050 D loss:-0.6192 G loss:-2.151\n",
      "Epoch:  0050 D loss:-0.4942 G loss:-2.287\n",
      "Epoch:  0050 D loss:-0.6537 G loss:-2.163\n",
      "Epoch:  0050 D loss:-0.5371 G loss:-2.34\n",
      "Epoch:  0050 D loss:-0.5895 G loss:-2.536\n",
      "Epoch:  0050 D loss:-0.6046 G loss:-2.482\n",
      "Epoch:  0050 D loss:-0.6025 G loss:-2.533\n",
      "Epoch:  0050 D loss:-0.5662 G loss:-2.395\n",
      "Epoch:  0050 D loss:-0.4854 G loss:-2.582\n",
      "Epoch:  0050 D loss:-0.5066 G loss:-2.409\n",
      "Epoch:  0050 D loss:-0.5471 G loss:-2.254\n",
      "Epoch:  0050 D loss:-0.7194 G loss:-2.146\n",
      "Epoch:  0050 D loss:-0.5773 G loss:-2.292\n",
      "Epoch:  0050 D loss:-0.56 G loss:-2.159\n",
      "Epoch:  0050 D loss:-0.5616 G loss:-2.093\n",
      "Epoch:  0050 D loss:-0.6734 G loss:-2.085\n",
      "Epoch:  0050 D loss:-0.6239 G loss:-2.117\n",
      "Epoch:  0050 D loss:-0.5028 G loss:-2.353\n",
      "Epoch:  0050 D loss:-0.5167 G loss:-2.318\n",
      "Epoch:  0050 D loss:-0.6643 G loss:-2.253\n",
      "Epoch:  0050 D loss:-0.4516 G loss:-2.374\n",
      "Epoch:  0050 D loss:-0.5886 G loss:-2.146\n",
      "Epoch:  0050 D loss:-0.6343 G loss:-2.316\n",
      "Epoch:  0050 D loss:-0.5959 G loss:-2.319\n",
      "Epoch:  0050 D loss:-0.4892 G loss:-2.296\n",
      "Epoch:  0050 D loss:-0.5865 G loss:-2.137\n",
      "Epoch:  0050 D loss:-0.5368 G loss:-2.303\n",
      "Epoch:  0050 D loss:-0.4801 G loss:-2.494\n",
      "Epoch:  0050 D loss:-0.5306 G loss:-2.461\n",
      "Epoch:  0050 D loss:-0.6189 G loss:-2.33\n",
      "Epoch:  0050 D loss:-0.7107 G loss:-2.118\n",
      "Epoch:  0050 D loss:-0.5332 G loss:-2.342\n",
      "Epoch:  0050 D loss:-0.624 G loss:-2.379\n",
      "Epoch:  0050 D loss:-0.578 G loss:-2.346\n",
      "Epoch:  0050 D loss:-0.7435 G loss:-2.325\n",
      "Epoch:  0050 D loss:-0.4558 G loss:-2.429\n",
      "Epoch:  0050 D loss:-0.5532 G loss:-2.314\n",
      "Epoch:  0050 D loss:-0.6782 G loss:-2.458\n",
      "Epoch:  0050 D loss:-0.5557 G loss:-2.361\n",
      "Epoch:  0050 D loss:-0.5546 G loss:-2.239\n",
      "Epoch:  0050 D loss:-0.7013 G loss:-2.447\n",
      "Epoch:  0050 D loss:-0.558 G loss:-2.273\n",
      "Epoch:  0050 D loss:-0.4237 G loss:-2.466\n",
      "Epoch:  0050 D loss:-0.4928 G loss:-2.008\n",
      "Epoch:  0050 D loss:-0.6338 G loss:-2.285\n",
      "Epoch:  0050 D loss:-0.7043 G loss:-1.999\n",
      "Epoch:  0050 D loss:-0.5873 G loss:-2.163\n",
      "Epoch:  0050 D loss:-0.7072 G loss:-2.412\n",
      "Epoch:  0050 D loss:-0.5887 G loss:-2.344\n",
      "Epoch:  0050 D loss:-0.5777 G loss:-2.321\n",
      "Epoch:  0050 D loss:-0.5828 G loss:-2.388\n",
      "Epoch:  0050 D loss:-0.637 G loss:-2.582\n",
      "Epoch:  0050 D loss:-0.5269 G loss:-2.355\n",
      "Epoch:  0050 D loss:-0.7471 G loss:-2.338\n",
      "Epoch:  0050 D loss:-0.7376 G loss:-2.197\n",
      "Epoch:  0050 D loss:-0.5406 G loss:-2.2\n",
      "Epoch:  0050 D loss:-0.6435 G loss:-2.132\n",
      "Epoch:  0050 D loss:-0.5612 G loss:-2.168\n",
      "Epoch:  0050 D loss:-0.5536 G loss:-2.131\n",
      "Epoch:  0050 D loss:-0.5336 G loss:-2.284\n",
      "Epoch:  0050 D loss:-0.7446 G loss:-2.177\n",
      "Epoch:  0050 D loss:-0.5129 G loss:-2.333\n",
      "Epoch:  0050 D loss:-0.5611 G loss:-2.323\n",
      "Epoch:  0050 D loss:-0.6889 G loss:-2.178\n",
      "Epoch:  0050 D loss:-0.7994 G loss:-2.179\n",
      "Epoch:  0050 D loss:-0.612 G loss:-2.528\n",
      "Epoch:  0050 D loss:-0.4642 G loss:-2.458\n",
      "Epoch:  0050 D loss:-0.5805 G loss:-2.417\n",
      "Epoch:  0050 D loss:-0.6949 G loss:-2.411\n",
      "Epoch:  0050 D loss:-0.5385 G loss:-2.383\n",
      "Epoch:  0050 D loss:-0.6254 G loss:-2.296\n",
      "Epoch:  0050 D loss:-0.6222 G loss:-2.26\n",
      "Epoch:  0050 D loss:-0.6957 G loss:-2.146\n",
      "Epoch:  0050 D loss:-0.7086 G loss:-2.025\n",
      "Epoch:  0050 D loss:-0.5166 G loss:-2.195\n",
      "Epoch:  0050 D loss:-0.6976 G loss:-1.955\n",
      "Epoch:  0050 D loss:-0.5891 G loss:-2.301\n",
      "Epoch:  0050 D loss:-0.5568 G loss:-2.125\n",
      "Epoch:  0050 D loss:-0.525 G loss:-2.327\n",
      "Epoch:  0050 D loss:-0.5892 G loss:-2.391\n",
      "Epoch:  0050 D loss:-0.4988 G loss:-2.404\n",
      "Epoch:  0050 D loss:-0.663 G loss:-2.313\n",
      "Epoch:  0050 D loss:-0.5772 G loss:-2.041\n",
      "Epoch:  0050 D loss:-0.6012 G loss:-2.184\n",
      "Epoch:  0050 D loss:-0.5597 G loss:-2.29\n",
      "Epoch:  0050 D loss:-0.607 G loss:-2.463\n",
      "Epoch:  0050 D loss:-0.4721 G loss:-2.445\n",
      "Epoch:  0050 D loss:-0.6004 G loss:-2.469\n",
      "Epoch:  0050 D loss:-0.5412 G loss:-2.541\n",
      "Epoch:  0050 D loss:-0.7661 G loss:-2.396\n",
      "Epoch:  0050 D loss:-0.575 G loss:-2.459\n",
      "Epoch:  0050 D loss:-0.6827 G loss:-2.467\n",
      "Epoch:  0050 D loss:-0.733 G loss:-2.056\n",
      "Epoch:  0050 D loss:-0.5715 G loss:-2.313\n",
      "Epoch:  0050 D loss:-0.6938 G loss:-2.232\n",
      "Epoch:  0050 D loss:-0.6089 G loss:-2.151\n",
      "Epoch:  0050 D loss:-0.728 G loss:-2.002\n",
      "Epoch:  0050 D loss:-0.5995 G loss:-1.974\n",
      "Epoch:  0050 D loss:-0.5751 G loss:-2.234\n",
      "Epoch:  0050 D loss:-0.6266 G loss:-2.223\n",
      "Epoch:  0050 D loss:-0.6043 G loss:-2.16\n",
      "Epoch:  0050 D loss:-0.61 G loss:-2.387\n",
      "Epoch:  0050 D loss:-0.6596 G loss:-2.059\n",
      "Epoch:  0050 D loss:-0.5224 G loss:-2.36\n",
      "Epoch:  0050 D loss:-0.5837 G loss:-2.396\n",
      "Epoch:  0050 D loss:-0.6325 G loss:-2.431\n",
      "Epoch:  0050 D loss:-0.5765 G loss:-2.462\n",
      "Epoch:  0050 D loss:-0.6052 G loss:-2.286\n",
      "Epoch:  0050 D loss:-0.6851 G loss:-2.086\n",
      "Epoch:  0050 D loss:-0.6645 G loss:-2.339\n",
      "Epoch:  0050 D loss:-0.6266 G loss:-2.163\n",
      "Epoch:  0050 D loss:-0.5311 G loss:-2.203\n",
      "Epoch:  0050 D loss:-0.7011 G loss:-1.93\n",
      "Epoch:  0050 D loss:-0.5815 G loss:-2.219\n",
      "Epoch:  0050 D loss:-0.4319 G loss:-2.388\n",
      "Epoch:  0050 D loss:-0.6686 G loss:-2.212\n",
      "Epoch:  0050 D loss:-0.5374 G loss:-2.139\n",
      "Epoch:  0050 D loss:-0.5867 G loss:-2.45\n",
      "Epoch:  0050 D loss:-0.7197 G loss:-2.165\n",
      "Epoch:  0050 D loss:-0.7483 G loss:-2.21\n",
      "Epoch:  0050 D loss:-0.7025 G loss:-2.239\n",
      "Epoch:  0050 D loss:-0.5429 G loss:-2.32\n",
      "Epoch:  0050 D loss:-0.5899 G loss:-2.301\n",
      "Epoch:  0050 D loss:-0.6922 G loss:-2.199\n",
      "Epoch:  0050 D loss:-0.6537 G loss:-2.049\n",
      "Epoch:  0050 D loss:-0.6391 G loss:-2.4\n",
      "Epoch:  0050 D loss:-0.5463 G loss:-2.279\n",
      "Epoch:  0050 D loss:-0.5351 G loss:-2.413\n",
      "Epoch:  0050 D loss:-0.523 G loss:-2.232\n",
      "Epoch:  0050 D loss:-0.5412 G loss:-2.454\n",
      "Epoch:  0050 D loss:-0.5812 G loss:-2.366\n",
      "Epoch:  0050 D loss:-0.7288 G loss:-2.162\n",
      "Epoch:  0050 D loss:-0.6103 G loss:-2.244\n",
      "Epoch:  0050 D loss:-0.6058 G loss:-2.18\n",
      "Epoch:  0050 D loss:-0.5305 G loss:-2.311\n",
      "Epoch:  0050 D loss:-0.4934 G loss:-2.347\n",
      "Epoch:  0050 D loss:-0.6002 G loss:-2.269\n",
      "Epoch:  0050 D loss:-0.5149 G loss:-2.35\n",
      "Epoch:  0050 D loss:-0.5331 G loss:-2.206\n",
      "Epoch:  0050 D loss:-0.5497 G loss:-2.306\n",
      "Epoch:  0050 D loss:-0.6763 G loss:-2.252\n",
      "Epoch:  0050 D loss:-0.6803 G loss:-2.242\n",
      "Epoch:  0050 D loss:-0.5274 G loss:-2.285\n",
      "Epoch:  0050 D loss:-0.7161 G loss:-2.156\n",
      "Epoch:  0050 D loss:-0.5367 G loss:-2.212\n",
      "Epoch:  0050 D loss:-0.5719 G loss:-2.265\n",
      "Epoch:  0050 D loss:-0.5551 G loss:-2.221\n",
      "Epoch:  0050 D loss:-0.6045 G loss:-2.126\n",
      "Epoch:  0050 D loss:-0.6224 G loss:-2.123\n",
      "Epoch:  0050 D loss:-0.5651 G loss:-2.299\n",
      "Epoch:  0050 D loss:-0.6229 G loss:-2.412\n",
      "Epoch:  0050 D loss:-0.5801 G loss:-2.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0050 D loss:-0.636 G loss:-2.353\n",
      "Epoch:  0050 D loss:-0.5476 G loss:-2.257\n",
      "Epoch:  0050 D loss:-0.5802 G loss:-2.28\n",
      "Epoch:  0050 D loss:-0.6278 G loss:-2.249\n",
      "Epoch:  0050 D loss:-0.5238 G loss:-2.303\n",
      "Epoch:  0050 D loss:-0.4956 G loss:-2.316\n",
      "Epoch:  0050 D loss:-0.459 G loss:-2.296\n",
      "Epoch:  0050 D loss:-0.5789 G loss:-2.188\n",
      "Epoch:  0050 D loss:-0.647 G loss:-2.171\n",
      "Epoch:  0050 D loss:-0.6516 G loss:-2.352\n",
      "Epoch:  0050 D loss:-0.5013 G loss:-2.398\n",
      "Epoch:  0050 D loss:-0.5028 G loss:-2.42\n",
      "Epoch:  0050 D loss:-0.4981 G loss:-2.571\n",
      "Epoch:  0050 D loss:-0.6497 G loss:-2.279\n",
      "Epoch:  0050 D loss:-0.5747 G loss:-2.301\n",
      "Epoch:  0050 D loss:-0.6711 G loss:-2.227\n",
      "Epoch:  0050 D loss:-0.6843 G loss:-2.185\n",
      "Epoch:  0050 D loss:-0.562 G loss:-2.113\n",
      "Epoch:  0050 D loss:-0.5749 G loss:-2.203\n",
      "Epoch:  0050 D loss:-0.5413 G loss:-2.031\n",
      "Epoch:  0050 D loss:-0.7257 G loss:-2.111\n",
      "Epoch:  0050 D loss:-0.7031 G loss:-2.189\n",
      "Epoch:  0050 D loss:-0.5975 G loss:-2.185\n",
      "Epoch:  0050 D loss:-0.668 G loss:-1.976\n",
      "Epoch:  0050 D loss:-0.7166 G loss:-1.983\n",
      "Epoch:  0050 D loss:-0.7363 G loss:-1.894\n",
      "Epoch:  0050 D loss:-0.6921 G loss:-1.976\n",
      "Epoch:  0050 D loss:-0.7599 G loss:-2.019\n",
      "Epoch:  0050 D loss:-0.6419 G loss:-2.123\n",
      "Epoch:  0050 D loss:-0.6602 G loss:-2.24\n",
      "Epoch:  0050 D loss:-0.6872 G loss:-2.147\n",
      "Epoch:  0050 D loss:-0.6411 G loss:-2.305\n",
      "Epoch:  0050 D loss:-0.6776 G loss:-2.395\n",
      "Epoch:  0050 D loss:-0.6634 G loss:-2.315\n",
      "Epoch:  0050 D loss:-0.7838 G loss:-2.343\n",
      "Epoch:  0050 D loss:-0.6438 G loss:-2.328\n",
      "Epoch:  0050 D loss:-0.6194 G loss:-2.238\n",
      "Epoch:  0050 D loss:-0.6249 G loss:-2.178\n",
      "Epoch:  0050 D loss:-0.6222 G loss:-2.315\n",
      "Epoch:  0050 D loss:-0.7238 G loss:-2.043\n",
      "Epoch:  0050 D loss:-0.8259 G loss:-1.97\n",
      "Epoch:  0050 D loss:-0.6613 G loss:-1.963\n",
      "Epoch:  0050 D loss:-0.6023 G loss:-2.039\n",
      "Epoch:  0050 D loss:-0.7612 G loss:-1.931\n",
      "Epoch:  0050 D loss:-0.7276 G loss:-2.029\n",
      "Epoch:  0050 D loss:-0.6727 G loss:-2.082\n",
      "Epoch:  0050 D loss:-0.6538 G loss:-1.987\n",
      "Epoch:  0050 D loss:-0.4635 G loss:-2.352\n",
      "Epoch:  0050 D loss:-0.4693 G loss:-2.414\n",
      "Epoch:  0050 D loss:-0.6901 G loss:-2.196\n",
      "Epoch:  0050 D loss:-0.5667 G loss:-2.304\n",
      "Epoch:  0050 D loss:-0.741 G loss:-2.282\n",
      "Epoch:  0050 D loss:-0.7104 G loss:-2.211\n",
      "Epoch:  0050 D loss:-0.7191 G loss:-2.171\n",
      "Epoch:  0050 D loss:-0.573 G loss:-2.105\n",
      "Epoch:  0050 D loss:-0.6128 G loss:-2.214\n",
      "Epoch:  0050 D loss:-0.6401 G loss:-2.063\n",
      "Epoch:  0050 D loss:-0.6115 G loss:-2.002\n",
      "Epoch:  0050 D loss:-0.7592 G loss:-2.124\n",
      "Epoch:  0050 D loss:-0.6103 G loss:-1.902\n",
      "Epoch:  0050 D loss:-0.6541 G loss:-2.13\n",
      "Epoch:  0050 D loss:-0.6172 G loss:-1.978\n",
      "Epoch:  0050 D loss:-0.5349 G loss:-2.198\n",
      "Epoch:  0050 D loss:-0.5652 G loss:-2.142\n",
      "Epoch:  0050 D loss:-0.5399 G loss:-2.204\n",
      "Epoch:  0050 D loss:-0.7768 G loss:-2.361\n",
      "Epoch:  0050 D loss:-0.6977 G loss:-2.051\n",
      "Epoch:  0050 D loss:-0.6527 G loss:-2.251\n",
      "Epoch:  0050 D loss:-0.652 G loss:-2.236\n",
      "Epoch:  0050 D loss:-0.5722 G loss:-2.196\n",
      "Epoch:  0050 D loss:-0.5404 G loss:-2.103\n",
      "Epoch:  0050 D loss:-0.7237 G loss:-1.995\n",
      "Epoch:  0050 D loss:-0.4875 G loss:-2.197\n",
      "Epoch:  0050 D loss:-0.6271 G loss:-2.23\n",
      "Epoch:  0050 D loss:-0.5297 G loss:-2.529\n",
      "Epoch:  0050 D loss:-0.6528 G loss:-2.274\n",
      "Epoch:  0050 D loss:-0.5631 G loss:-2.401\n",
      "Epoch:  0050 D loss:-0.6259 G loss:-2.301\n",
      "Epoch:  0050 D loss:-0.4926 G loss:-2.323\n",
      "Epoch:  0050 D loss:-0.6569 G loss:-2.163\n",
      "Epoch:  0050 D loss:-0.587 G loss:-2.022\n",
      "Epoch:  0050 D loss:-0.6923 G loss:-2.008\n",
      "Epoch:  0050 D loss:-0.6013 G loss:-2.087\n",
      "Epoch:  0050 D loss:-0.6107 G loss:-2.285\n",
      "Epoch:  0050 D loss:-0.5822 G loss:-2.357\n",
      "Epoch:  0050 D loss:-0.6325 G loss:-1.918\n",
      "Epoch:  0050 D loss:-0.6312 G loss:-2.105\n",
      "Epoch:  0050 D loss:-0.4984 G loss:-2.098\n",
      "Epoch:  0050 D loss:-0.6161 G loss:-2.285\n",
      "Epoch:  0050 D loss:-0.6429 G loss:-2.216\n",
      "Epoch:  0050 D loss:-0.6459 G loss:-2.2\n",
      "Epoch:  0050 D loss:-0.6492 G loss:-2.15\n",
      "Epoch:  0050 D loss:-0.5894 G loss:-2.082\n",
      "Epoch:  0050 D loss:-0.6582 G loss:-1.942\n",
      "Epoch:  0050 D loss:-0.8101 G loss:-2.08\n",
      "Epoch:  0050 D loss:-0.6959 G loss:-2.003\n",
      "Epoch:  0050 D loss:-0.6853 G loss:-2.315\n",
      "Epoch:  0050 D loss:-0.7182 G loss:-2.239\n",
      "Epoch:  0050 D loss:-0.5972 G loss:-2.294\n",
      "Epoch:  0050 D loss:-0.551 G loss:-2.194\n",
      "Epoch:  0050 D loss:-0.7587 G loss:-2.132\n",
      "Epoch:  0050 D loss:-0.5455 G loss:-2.404\n",
      "Epoch:  0050 D loss:-0.5787 G loss:-2.159\n",
      "Epoch:  0050 D loss:-0.7402 G loss:-1.796\n",
      "Epoch:  0050 D loss:-0.7256 G loss:-1.956\n",
      "Epoch:  0050 D loss:-0.6243 G loss:-1.956\n",
      "Epoch:  0050 D loss:-0.6436 G loss:-2.116\n",
      "Epoch:  0050 D loss:-0.5957 G loss:-2.114\n",
      "Epoch:  0050 D loss:-0.6608 G loss:-2.412\n",
      "Epoch:  0050 D loss:-0.6371 G loss:-2.255\n",
      "Epoch:  0050 D loss:-0.8086 G loss:-2.086\n",
      "Epoch:  0050 D loss:-0.6059 G loss:-2.257\n",
      "Epoch:  0050 D loss:-0.7064 G loss:-1.876\n",
      "Epoch:  0050 D loss:-0.6587 G loss:-2.104\n",
      "Epoch:  0050 D loss:-0.6348 G loss:-2.057\n",
      "Epoch:  0050 D loss:-0.5977 G loss:-2.057\n",
      "Epoch:  0050 D loss:-0.5694 G loss:-2.077\n",
      "Epoch:  0050 D loss:-0.6126 G loss:-2.161\n",
      "Epoch:  0050 D loss:-0.7032 G loss:-2.099\n",
      "Epoch:  0050 D loss:-0.5717 G loss:-2.406\n",
      "Epoch:  0050 D loss:-0.5268 G loss:-2.549\n",
      "Epoch:  0050 D loss:-0.6093 G loss:-2.187\n",
      "Epoch:  0050 D loss:-0.5369 G loss:-2.2\n",
      "Epoch:  0050 D loss:-0.5316 G loss:-2.199\n",
      "Epoch:  0050 D loss:-0.6155 G loss:-2.248\n",
      "Epoch:  0050 D loss:-0.5429 G loss:-2.138\n",
      "Epoch:  0050 D loss:-0.5934 G loss:-2.247\n",
      "Epoch:  0050 D loss:-0.6612 G loss:-2.036\n",
      "Epoch:  0050 D loss:-0.59 G loss:-2.191\n",
      "Epoch:  0050 D loss:-0.6465 G loss:-2.159\n",
      "Epoch:  0050 D loss:-0.6061 G loss:-2.089\n",
      "Epoch:  0050 D loss:-0.4786 G loss:-2.263\n",
      "Epoch:  0050 D loss:-0.5534 G loss:-2.195\n",
      "Epoch:  0050 D loss:-0.6816 G loss:-2.045\n",
      "Epoch:  0050 D loss:-0.572 G loss:-2.219\n",
      "Epoch:  0050 D loss:-0.5673 G loss:-2.327\n",
      "Epoch:  0050 D loss:-0.5669 G loss:-2.248\n",
      "Epoch:  0050 D loss:-0.5432 G loss:-2.465\n",
      "Epoch:  0050 D loss:-0.681 G loss:-2.366\n",
      "Epoch:  0050 D loss:-0.5665 G loss:-2.35\n",
      "Epoch:  0051 D loss:-0.5785 G loss:-2.166\n",
      "Epoch:  0051 D loss:-0.8764 G loss:-2.034\n",
      "Epoch:  0051 D loss:-0.6888 G loss:-2.168\n",
      "Epoch:  0051 D loss:-0.6869 G loss:-2.146\n",
      "Epoch:  0051 D loss:-0.5718 G loss:-2.195\n",
      "Epoch:  0051 D loss:-0.6878 G loss:-2.312\n",
      "Epoch:  0051 D loss:-0.5179 G loss:-2.02\n",
      "Epoch:  0051 D loss:-0.7402 G loss:-1.994\n",
      "Epoch:  0051 D loss:-0.7872 G loss:-2.013\n",
      "Epoch:  0051 D loss:-0.5207 G loss:-2.09\n",
      "Epoch:  0051 D loss:-0.652 G loss:-2.014\n",
      "Epoch:  0051 D loss:-0.6095 G loss:-2.063\n",
      "Epoch:  0051 D loss:-0.6042 G loss:-2.369\n",
      "Epoch:  0051 D loss:-0.6313 G loss:-2.023\n",
      "Epoch:  0051 D loss:-0.6376 G loss:-2.12\n",
      "Epoch:  0051 D loss:-0.645 G loss:-2.154\n",
      "Epoch:  0051 D loss:-0.5892 G loss:-2.209\n",
      "Epoch:  0051 D loss:-0.6889 G loss:-2.344\n",
      "Epoch:  0051 D loss:-0.6196 G loss:-2.244\n",
      "Epoch:  0051 D loss:-0.7595 G loss:-2.201\n",
      "Epoch:  0051 D loss:-0.512 G loss:-2.053\n",
      "Epoch:  0051 D loss:-0.8028 G loss:-2.158\n",
      "Epoch:  0051 D loss:-0.6217 G loss:-2.11\n",
      "Epoch:  0051 D loss:-0.6127 G loss:-2.482\n",
      "Epoch:  0051 D loss:-0.7409 G loss:-2.048\n",
      "Epoch:  0051 D loss:-0.6746 G loss:-2.488\n",
      "Epoch:  0051 D loss:-0.6873 G loss:-2.357\n",
      "Epoch:  0051 D loss:-0.4167 G loss:-2.338\n",
      "Epoch:  0051 D loss:-0.599 G loss:-2.296\n",
      "Epoch:  0051 D loss:-0.6171 G loss:-2.152\n",
      "Epoch:  0051 D loss:-0.6324 G loss:-2.236\n",
      "Epoch:  0051 D loss:-0.5068 G loss:-2.178\n",
      "Epoch:  0051 D loss:-0.6938 G loss:-2.004\n",
      "Epoch:  0051 D loss:-0.6161 G loss:-2.158\n",
      "Epoch:  0051 D loss:-0.5143 G loss:-2.186\n",
      "Epoch:  0051 D loss:-0.6483 G loss:-2.406\n",
      "Epoch:  0051 D loss:-0.6532 G loss:-2.213\n",
      "Epoch:  0051 D loss:-0.6551 G loss:-2.208\n",
      "Epoch:  0051 D loss:-0.5434 G loss:-2.205\n",
      "Epoch:  0051 D loss:-0.6457 G loss:-2.099\n",
      "Epoch:  0051 D loss:-0.5221 G loss:-2.203\n",
      "Epoch:  0051 D loss:-0.6659 G loss:-2.156\n",
      "Epoch:  0051 D loss:-0.6558 G loss:-2.279\n",
      "Epoch:  0051 D loss:-0.6052 G loss:-2.299\n",
      "Epoch:  0051 D loss:-0.5956 G loss:-2.373\n",
      "Epoch:  0051 D loss:-0.5563 G loss:-2.325\n",
      "Epoch:  0051 D loss:-0.7333 G loss:-2.402\n",
      "Epoch:  0051 D loss:-0.6109 G loss:-2.329\n",
      "Epoch:  0051 D loss:-0.542 G loss:-2.33\n",
      "Epoch:  0051 D loss:-0.5336 G loss:-2.158\n",
      "Epoch:  0051 D loss:-0.6095 G loss:-2.249\n",
      "Epoch:  0051 D loss:-0.7043 G loss:-2.106\n",
      "Epoch:  0051 D loss:-0.6585 G loss:-2.263\n",
      "Epoch:  0051 D loss:-0.5832 G loss:-2.396\n",
      "Epoch:  0051 D loss:-0.6437 G loss:-2.204\n",
      "Epoch:  0051 D loss:-0.6816 G loss:-2.23\n",
      "Epoch:  0051 D loss:-0.6429 G loss:-2.236\n",
      "Epoch:  0051 D loss:-0.6349 G loss:-2.187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0051 D loss:-0.6857 G loss:-2.075\n",
      "Epoch:  0051 D loss:-0.5242 G loss:-2.097\n",
      "Epoch:  0051 D loss:-0.7388 G loss:-2.09\n",
      "Epoch:  0051 D loss:-0.6341 G loss:-2.159\n",
      "Epoch:  0051 D loss:-0.7259 G loss:-2.147\n",
      "Epoch:  0051 D loss:-0.6478 G loss:-2.237\n",
      "Epoch:  0051 D loss:-0.604 G loss:-2.306\n",
      "Epoch:  0051 D loss:-0.6086 G loss:-2.438\n",
      "Epoch:  0051 D loss:-0.5202 G loss:-2.357\n",
      "Epoch:  0051 D loss:-0.6103 G loss:-2.302\n",
      "Epoch:  0051 D loss:-0.5743 G loss:-2.44\n",
      "Epoch:  0051 D loss:-0.5073 G loss:-2.336\n",
      "Epoch:  0051 D loss:-0.6906 G loss:-2.257\n",
      "Epoch:  0051 D loss:-0.5695 G loss:-2.328\n",
      "Epoch:  0051 D loss:-0.6023 G loss:-2.233\n",
      "Epoch:  0051 D loss:-0.6947 G loss:-2.428\n",
      "Epoch:  0051 D loss:-0.7031 G loss:-2.193\n",
      "Epoch:  0051 D loss:-0.6122 G loss:-2.317\n",
      "Epoch:  0051 D loss:-0.6353 G loss:-2.224\n",
      "Epoch:  0051 D loss:-0.6795 G loss:-2.09\n",
      "Epoch:  0051 D loss:-0.6077 G loss:-2.307\n",
      "Epoch:  0051 D loss:-0.6392 G loss:-2.403\n",
      "Epoch:  0051 D loss:-0.6771 G loss:-2.17\n",
      "Epoch:  0051 D loss:-0.6915 G loss:-2.057\n",
      "Epoch:  0051 D loss:-0.5999 G loss:-2.471\n",
      "Epoch:  0051 D loss:-0.7124 G loss:-2.213\n",
      "Epoch:  0051 D loss:-0.5022 G loss:-2.102\n",
      "Epoch:  0051 D loss:-0.5705 G loss:-2.295\n",
      "Epoch:  0051 D loss:-0.6596 G loss:-1.946\n",
      "Epoch:  0051 D loss:-0.6738 G loss:-2.042\n",
      "Epoch:  0051 D loss:-0.574 G loss:-2.224\n",
      "Epoch:  0051 D loss:-0.5316 G loss:-2.227\n",
      "Epoch:  0051 D loss:-0.6486 G loss:-2.281\n",
      "Epoch:  0051 D loss:-0.6693 G loss:-2.212\n",
      "Epoch:  0051 D loss:-0.6874 G loss:-2.326\n",
      "Epoch:  0051 D loss:-0.7091 G loss:-2.415\n",
      "Epoch:  0051 D loss:-0.6188 G loss:-2.258\n",
      "Epoch:  0051 D loss:-0.6756 G loss:-2.186\n",
      "Epoch:  0051 D loss:-0.6643 G loss:-2.199\n",
      "Epoch:  0051 D loss:-0.7458 G loss:-2.078\n",
      "Epoch:  0051 D loss:-0.586 G loss:-2.064\n",
      "Epoch:  0051 D loss:-0.6957 G loss:-2.098\n",
      "Epoch:  0051 D loss:-0.6376 G loss:-1.952\n",
      "Epoch:  0051 D loss:-0.6899 G loss:-1.981\n",
      "Epoch:  0051 D loss:-0.5272 G loss:-2.301\n",
      "Epoch:  0051 D loss:-0.7226 G loss:-2.601\n",
      "Epoch:  0051 D loss:-0.6919 G loss:-2.211\n",
      "Epoch:  0051 D loss:-0.7276 G loss:-2.29\n",
      "Epoch:  0051 D loss:-0.5671 G loss:-2.55\n",
      "Epoch:  0051 D loss:-0.5088 G loss:-2.656\n",
      "Epoch:  0051 D loss:-0.6262 G loss:-2.215\n",
      "Epoch:  0051 D loss:-0.5257 G loss:-2.323\n",
      "Epoch:  0051 D loss:-0.7072 G loss:-2.248\n",
      "Epoch:  0051 D loss:-0.5459 G loss:-2.311\n",
      "Epoch:  0051 D loss:-0.4738 G loss:-2.23\n",
      "Epoch:  0051 D loss:-0.6188 G loss:-2.124\n",
      "Epoch:  0051 D loss:-0.5928 G loss:-2.079\n",
      "Epoch:  0051 D loss:-0.642 G loss:-2.097\n",
      "Epoch:  0051 D loss:-0.616 G loss:-2.038\n",
      "Epoch:  0051 D loss:-0.6847 G loss:-2.147\n",
      "Epoch:  0051 D loss:-0.7211 G loss:-2.241\n",
      "Epoch:  0051 D loss:-0.6157 G loss:-2.286\n",
      "Epoch:  0051 D loss:-0.5362 G loss:-2.261\n",
      "Epoch:  0051 D loss:-0.615 G loss:-2.394\n",
      "Epoch:  0051 D loss:-0.6677 G loss:-2.309\n",
      "Epoch:  0051 D loss:-0.5631 G loss:-2.525\n",
      "Epoch:  0051 D loss:-0.6773 G loss:-2.43\n",
      "Epoch:  0051 D loss:-0.6183 G loss:-2.372\n",
      "Epoch:  0051 D loss:-0.6642 G loss:-2.035\n",
      "Epoch:  0051 D loss:-0.6816 G loss:-2.134\n",
      "Epoch:  0051 D loss:-0.5651 G loss:-2.107\n",
      "Epoch:  0051 D loss:-0.6449 G loss:-2.175\n",
      "Epoch:  0051 D loss:-0.8336 G loss:-1.88\n",
      "Epoch:  0051 D loss:-0.6193 G loss:-2.073\n",
      "Epoch:  0051 D loss:-0.6521 G loss:-1.87\n",
      "Epoch:  0051 D loss:-0.7037 G loss:-2.048\n",
      "Epoch:  0051 D loss:-0.7353 G loss:-2.01\n",
      "Epoch:  0051 D loss:-0.689 G loss:-2.173\n",
      "Epoch:  0051 D loss:-0.6081 G loss:-2.071\n",
      "Epoch:  0051 D loss:-0.6821 G loss:-2.225\n",
      "Epoch:  0051 D loss:-0.7275 G loss:-2.351\n",
      "Epoch:  0051 D loss:-0.6549 G loss:-2.137\n",
      "Epoch:  0051 D loss:-0.5129 G loss:-2.455\n",
      "Epoch:  0051 D loss:-0.6493 G loss:-2.314\n",
      "Epoch:  0051 D loss:-0.5583 G loss:-2.468\n",
      "Epoch:  0051 D loss:-0.5817 G loss:-2.419\n",
      "Epoch:  0051 D loss:-0.5902 G loss:-2.196\n",
      "Epoch:  0051 D loss:-0.6212 G loss:-2.282\n",
      "Epoch:  0051 D loss:-0.4751 G loss:-2.26\n",
      "Epoch:  0051 D loss:-0.7726 G loss:-2.249\n",
      "Epoch:  0051 D loss:-0.6442 G loss:-2.149\n",
      "Epoch:  0051 D loss:-0.5043 G loss:-2.331\n",
      "Epoch:  0051 D loss:-0.6 G loss:-2.043\n",
      "Epoch:  0051 D loss:-0.6956 G loss:-2.333\n",
      "Epoch:  0051 D loss:-0.6726 G loss:-2.072\n",
      "Epoch:  0051 D loss:-0.6162 G loss:-2.199\n",
      "Epoch:  0051 D loss:-0.5935 G loss:-2.014\n",
      "Epoch:  0051 D loss:-0.5933 G loss:-1.929\n",
      "Epoch:  0051 D loss:-0.5521 G loss:-2.049\n",
      "Epoch:  0051 D loss:-0.6349 G loss:-2.186\n",
      "Epoch:  0051 D loss:-0.5651 G loss:-2.287\n",
      "Epoch:  0051 D loss:-0.5911 G loss:-2.148\n",
      "Epoch:  0051 D loss:-0.6278 G loss:-2.316\n",
      "Epoch:  0051 D loss:-0.5447 G loss:-2.432\n",
      "Epoch:  0051 D loss:-0.5959 G loss:-2.166\n",
      "Epoch:  0051 D loss:-0.6078 G loss:-2.354\n",
      "Epoch:  0051 D loss:-0.6396 G loss:-2.228\n",
      "Epoch:  0051 D loss:-0.6436 G loss:-2.305\n",
      "Epoch:  0051 D loss:-0.7064 G loss:-2.395\n",
      "Epoch:  0051 D loss:-0.6275 G loss:-2.09\n",
      "Epoch:  0051 D loss:-0.6496 G loss:-2.254\n",
      "Epoch:  0051 D loss:-0.586 G loss:-2.174\n",
      "Epoch:  0051 D loss:-0.5999 G loss:-2.213\n",
      "Epoch:  0051 D loss:-0.809 G loss:-2.018\n",
      "Epoch:  0051 D loss:-0.5075 G loss:-2.394\n",
      "Epoch:  0051 D loss:-0.5799 G loss:-2.309\n",
      "Epoch:  0051 D loss:-0.7042 G loss:-2.487\n",
      "Epoch:  0051 D loss:-0.6482 G loss:-2.147\n",
      "Epoch:  0051 D loss:-0.5266 G loss:-2.345\n",
      "Epoch:  0051 D loss:-0.6753 G loss:-2.19\n",
      "Epoch:  0051 D loss:-0.5135 G loss:-2.306\n",
      "Epoch:  0051 D loss:-0.5228 G loss:-2.366\n",
      "Epoch:  0051 D loss:-0.6132 G loss:-2.269\n",
      "Epoch:  0051 D loss:-0.6677 G loss:-2.091\n",
      "Epoch:  0051 D loss:-0.674 G loss:-2.153\n",
      "Epoch:  0051 D loss:-0.7505 G loss:-2.086\n",
      "Epoch:  0051 D loss:-0.6426 G loss:-2.199\n",
      "Epoch:  0051 D loss:-0.6099 G loss:-1.994\n",
      "Epoch:  0051 D loss:-0.6334 G loss:-2.073\n",
      "Epoch:  0051 D loss:-0.7007 G loss:-1.991\n",
      "Epoch:  0051 D loss:-0.7058 G loss:-2.126\n",
      "Epoch:  0051 D loss:-0.5762 G loss:-2.053\n",
      "Epoch:  0051 D loss:-0.6654 G loss:-2.11\n",
      "Epoch:  0051 D loss:-0.6829 G loss:-2.295\n",
      "Epoch:  0051 D loss:-0.4756 G loss:-2.087\n",
      "Epoch:  0051 D loss:-0.6444 G loss:-2.224\n",
      "Epoch:  0051 D loss:-0.6705 G loss:-2.218\n",
      "Epoch:  0051 D loss:-0.6868 G loss:-2.448\n",
      "Epoch:  0051 D loss:-0.6433 G loss:-2.309\n",
      "Epoch:  0051 D loss:-0.555 G loss:-2.223\n",
      "Epoch:  0051 D loss:-0.6334 G loss:-2.178\n",
      "Epoch:  0051 D loss:-0.5728 G loss:-2.127\n",
      "Epoch:  0051 D loss:-0.5273 G loss:-2.181\n",
      "Epoch:  0051 D loss:-0.5466 G loss:-2.101\n",
      "Epoch:  0051 D loss:-0.5128 G loss:-2.196\n",
      "Epoch:  0051 D loss:-0.7413 G loss:-2.064\n",
      "Epoch:  0051 D loss:-0.74 G loss:-2.132\n",
      "Epoch:  0051 D loss:-0.7665 G loss:-2.071\n",
      "Epoch:  0051 D loss:-0.5887 G loss:-2.183\n",
      "Epoch:  0051 D loss:-0.7101 G loss:-2.104\n",
      "Epoch:  0051 D loss:-0.6373 G loss:-2.303\n",
      "Epoch:  0051 D loss:-0.6566 G loss:-2.125\n",
      "Epoch:  0051 D loss:-0.6312 G loss:-2.185\n",
      "Epoch:  0051 D loss:-0.5455 G loss:-2.302\n",
      "Epoch:  0051 D loss:-0.6252 G loss:-2.388\n",
      "Epoch:  0051 D loss:-0.7589 G loss:-2.165\n",
      "Epoch:  0051 D loss:-0.8216 G loss:-2.067\n",
      "Epoch:  0051 D loss:-0.6886 G loss:-2.394\n",
      "Epoch:  0051 D loss:-0.724 G loss:-2.239\n",
      "Epoch:  0051 D loss:-0.4813 G loss:-2.271\n",
      "Epoch:  0051 D loss:-0.7259 G loss:-2.133\n",
      "Epoch:  0051 D loss:-0.6511 G loss:-2.17\n",
      "Epoch:  0051 D loss:-0.6886 G loss:-2.026\n",
      "Epoch:  0051 D loss:-0.7689 G loss:-1.995\n",
      "Epoch:  0051 D loss:-0.6269 G loss:-2.109\n",
      "Epoch:  0051 D loss:-0.5759 G loss:-2.275\n",
      "Epoch:  0051 D loss:-0.7415 G loss:-1.972\n",
      "Epoch:  0051 D loss:-0.6884 G loss:-2.051\n",
      "Epoch:  0051 D loss:-0.6467 G loss:-1.861\n",
      "Epoch:  0051 D loss:-0.5369 G loss:-2.101\n",
      "Epoch:  0051 D loss:-0.6656 G loss:-2.136\n",
      "Epoch:  0051 D loss:-0.5766 G loss:-2.138\n",
      "Epoch:  0051 D loss:-0.5876 G loss:-2.195\n",
      "Epoch:  0051 D loss:-0.5773 G loss:-2.173\n",
      "Epoch:  0051 D loss:-0.6216 G loss:-2.448\n",
      "Epoch:  0051 D loss:-0.655 G loss:-2.21\n",
      "Epoch:  0051 D loss:-0.5022 G loss:-2.546\n",
      "Epoch:  0051 D loss:-0.7769 G loss:-2.305\n",
      "Epoch:  0051 D loss:-0.6641 G loss:-2.155\n",
      "Epoch:  0051 D loss:-0.5971 G loss:-2.0\n",
      "Epoch:  0051 D loss:-0.664 G loss:-1.882\n",
      "Epoch:  0051 D loss:-0.7162 G loss:-1.951\n",
      "Epoch:  0051 D loss:-0.5952 G loss:-2.087\n",
      "Epoch:  0051 D loss:-0.7402 G loss:-1.873\n",
      "Epoch:  0051 D loss:-0.5716 G loss:-1.925\n",
      "Epoch:  0051 D loss:-0.598 G loss:-2.011\n",
      "Epoch:  0051 D loss:-0.7292 G loss:-2.0\n",
      "Epoch:  0051 D loss:-0.7707 G loss:-2.164\n",
      "Epoch:  0051 D loss:-0.5618 G loss:-2.289\n",
      "Epoch:  0051 D loss:-0.7129 G loss:-2.424\n",
      "Epoch:  0051 D loss:-0.6395 G loss:-2.299\n",
      "Epoch:  0051 D loss:-0.5974 G loss:-2.366\n",
      "Epoch:  0051 D loss:-0.641 G loss:-2.231\n",
      "Epoch:  0051 D loss:-0.5557 G loss:-2.261\n",
      "Epoch:  0051 D loss:-0.7339 G loss:-2.248\n",
      "Epoch:  0051 D loss:-0.6422 G loss:-2.196\n",
      "Epoch:  0051 D loss:-0.7399 G loss:-2.251\n",
      "Epoch:  0051 D loss:-0.5912 G loss:-2.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0051 D loss:-0.5489 G loss:-2.081\n",
      "Epoch:  0051 D loss:-0.6037 G loss:-2.081\n",
      "Epoch:  0051 D loss:-0.6109 G loss:-2.031\n",
      "Epoch:  0051 D loss:-0.68 G loss:-2.001\n",
      "Epoch:  0051 D loss:-0.6757 G loss:-2.081\n",
      "Epoch:  0051 D loss:-0.7485 G loss:-2.063\n",
      "Epoch:  0051 D loss:-0.5617 G loss:-2.251\n",
      "Epoch:  0051 D loss:-0.6103 G loss:-2.389\n",
      "Epoch:  0051 D loss:-0.6292 G loss:-2.375\n",
      "Epoch:  0051 D loss:-0.6783 G loss:-2.117\n",
      "Epoch:  0051 D loss:-0.7156 G loss:-1.978\n",
      "Epoch:  0051 D loss:-0.615 G loss:-2.24\n",
      "Epoch:  0051 D loss:-0.5767 G loss:-2.369\n",
      "Epoch:  0051 D loss:-0.6211 G loss:-2.16\n",
      "Epoch:  0051 D loss:-0.6056 G loss:-2.265\n",
      "Epoch:  0051 D loss:-0.6338 G loss:-2.16\n",
      "Epoch:  0051 D loss:-0.5503 G loss:-2.132\n",
      "Epoch:  0051 D loss:-0.5049 G loss:-2.082\n",
      "Epoch:  0051 D loss:-0.6537 G loss:-2.282\n",
      "Epoch:  0051 D loss:-0.7939 G loss:-2.053\n",
      "Epoch:  0051 D loss:-0.5642 G loss:-2.111\n",
      "Epoch:  0051 D loss:-0.5796 G loss:-2.229\n",
      "Epoch:  0051 D loss:-0.6805 G loss:-2.115\n",
      "Epoch:  0051 D loss:-0.5691 G loss:-2.325\n",
      "Epoch:  0051 D loss:-0.4647 G loss:-2.41\n",
      "Epoch:  0051 D loss:-0.7058 G loss:-2.343\n",
      "Epoch:  0051 D loss:-0.6449 G loss:-2.346\n",
      "Epoch:  0051 D loss:-0.5686 G loss:-2.168\n",
      "Epoch:  0051 D loss:-0.6474 G loss:-2.154\n",
      "Epoch:  0051 D loss:-0.5544 G loss:-2.219\n",
      "Epoch:  0051 D loss:-0.5498 G loss:-2.186\n",
      "Epoch:  0051 D loss:-0.613 G loss:-1.988\n",
      "Epoch:  0051 D loss:-0.5736 G loss:-2.473\n",
      "Epoch:  0051 D loss:-0.5836 G loss:-2.306\n",
      "Epoch:  0051 D loss:-0.5453 G loss:-2.276\n",
      "Epoch:  0051 D loss:-0.7423 G loss:-2.261\n",
      "Epoch:  0051 D loss:-0.5602 G loss:-2.294\n",
      "Epoch:  0051 D loss:-0.5734 G loss:-2.3\n",
      "Epoch:  0051 D loss:-0.5558 G loss:-2.163\n",
      "Epoch:  0051 D loss:-0.7314 G loss:-2.174\n",
      "Epoch:  0051 D loss:-0.584 G loss:-2.291\n",
      "Epoch:  0051 D loss:-0.7226 G loss:-2.396\n",
      "Epoch:  0051 D loss:-0.7015 G loss:-2.037\n",
      "Epoch:  0051 D loss:-0.6638 G loss:-2.369\n",
      "Epoch:  0051 D loss:-0.5486 G loss:-2.45\n",
      "Epoch:  0051 D loss:-0.6065 G loss:-2.393\n",
      "Epoch:  0051 D loss:-0.7032 G loss:-2.313\n",
      "Epoch:  0051 D loss:-0.7513 G loss:-2.124\n",
      "Epoch:  0051 D loss:-0.4697 G loss:-2.213\n",
      "Epoch:  0051 D loss:-0.6735 G loss:-2.047\n",
      "Epoch:  0051 D loss:-0.5891 G loss:-2.305\n",
      "Epoch:  0051 D loss:-0.5548 G loss:-2.489\n",
      "Epoch:  0051 D loss:-0.6241 G loss:-2.321\n",
      "Epoch:  0051 D loss:-0.7543 G loss:-2.015\n",
      "Epoch:  0051 D loss:-0.6354 G loss:-2.171\n",
      "Epoch:  0051 D loss:-0.6629 G loss:-1.837\n",
      "Epoch:  0051 D loss:-0.6091 G loss:-2.093\n",
      "Epoch:  0051 D loss:-0.7164 G loss:-2.089\n",
      "Epoch:  0051 D loss:-0.683 G loss:-1.956\n",
      "Epoch:  0051 D loss:-0.5621 G loss:-2.437\n",
      "Epoch:  0051 D loss:-0.6325 G loss:-2.037\n",
      "Epoch:  0051 D loss:-0.7117 G loss:-2.499\n",
      "Epoch:  0051 D loss:-0.6146 G loss:-2.132\n",
      "Epoch:  0051 D loss:-0.5381 G loss:-2.515\n",
      "Epoch:  0051 D loss:-0.633 G loss:-2.076\n",
      "Epoch:  0051 D loss:-0.6695 G loss:-2.354\n",
      "Epoch:  0051 D loss:-0.5033 G loss:-2.343\n",
      "Epoch:  0051 D loss:-0.7212 G loss:-2.189\n",
      "Epoch:  0051 D loss:-0.5696 G loss:-2.255\n",
      "Epoch:  0051 D loss:-0.6235 G loss:-2.156\n",
      "Epoch:  0051 D loss:-0.6443 G loss:-2.125\n",
      "Epoch:  0051 D loss:-0.545 G loss:-2.43\n",
      "Epoch:  0051 D loss:-0.6993 G loss:-1.969\n",
      "Epoch:  0051 D loss:-0.562 G loss:-2.201\n",
      "Epoch:  0051 D loss:-0.6143 G loss:-2.05\n",
      "Epoch:  0051 D loss:-0.7517 G loss:-2.177\n",
      "Epoch:  0051 D loss:-0.5874 G loss:-2.104\n",
      "Epoch:  0051 D loss:-0.6605 G loss:-2.089\n",
      "Epoch:  0051 D loss:-0.6559 G loss:-2.074\n",
      "Epoch:  0051 D loss:-0.5784 G loss:-2.242\n",
      "Epoch:  0051 D loss:-0.6729 G loss:-2.124\n",
      "Epoch:  0051 D loss:-0.7235 G loss:-2.094\n",
      "Epoch:  0051 D loss:-0.6202 G loss:-2.45\n",
      "Epoch:  0051 D loss:-0.649 G loss:-2.073\n",
      "Epoch:  0051 D loss:-0.7063 G loss:-2.238\n",
      "Epoch:  0051 D loss:-0.5729 G loss:-2.508\n",
      "Epoch:  0051 D loss:-0.4818 G loss:-2.308\n",
      "Epoch:  0051 D loss:-0.6344 G loss:-2.282\n",
      "Epoch:  0051 D loss:-0.6913 G loss:-2.38\n",
      "Epoch:  0051 D loss:-0.7405 G loss:-2.306\n",
      "Epoch:  0051 D loss:-0.5292 G loss:-2.479\n",
      "Epoch:  0051 D loss:-0.6449 G loss:-2.385\n",
      "Epoch:  0051 D loss:-0.4858 G loss:-2.494\n",
      "Epoch:  0051 D loss:-0.6688 G loss:-2.136\n",
      "Epoch:  0051 D loss:-0.6399 G loss:-2.068\n",
      "Epoch:  0051 D loss:-0.6581 G loss:-2.004\n",
      "Epoch:  0051 D loss:-0.5543 G loss:-2.123\n",
      "Epoch:  0051 D loss:-0.5798 G loss:-2.264\n",
      "Epoch:  0051 D loss:-0.6327 G loss:-2.053\n",
      "Epoch:  0051 D loss:-0.6421 G loss:-2.132\n",
      "Epoch:  0051 D loss:-0.6641 G loss:-2.091\n",
      "Epoch:  0051 D loss:-0.504 G loss:-2.175\n",
      "Epoch:  0051 D loss:-0.6451 G loss:-2.153\n",
      "Epoch:  0051 D loss:-0.5122 G loss:-2.353\n",
      "Epoch:  0051 D loss:-0.6173 G loss:-2.19\n",
      "Epoch:  0051 D loss:-0.5507 G loss:-2.235\n",
      "Epoch:  0051 D loss:-0.6454 G loss:-2.408\n",
      "Epoch:  0051 D loss:-0.6204 G loss:-2.417\n",
      "Epoch:  0051 D loss:-0.5994 G loss:-2.446\n",
      "Epoch:  0051 D loss:-0.5712 G loss:-2.499\n",
      "Epoch:  0051 D loss:-0.5558 G loss:-2.355\n",
      "Epoch:  0051 D loss:-0.5551 G loss:-2.298\n",
      "Epoch:  0051 D loss:-0.6537 G loss:-2.104\n",
      "Epoch:  0051 D loss:-0.7069 G loss:-2.153\n",
      "Epoch:  0051 D loss:-0.6013 G loss:-2.188\n",
      "Epoch:  0051 D loss:-0.6092 G loss:-2.249\n",
      "Epoch:  0051 D loss:-0.6713 G loss:-2.236\n",
      "Epoch:  0051 D loss:-0.62 G loss:-2.362\n",
      "Epoch:  0051 D loss:-0.5718 G loss:-2.13\n",
      "Epoch:  0051 D loss:-0.5904 G loss:-2.102\n",
      "Epoch:  0051 D loss:-0.6475 G loss:-2.11\n",
      "Epoch:  0051 D loss:-0.4951 G loss:-2.429\n",
      "Epoch:  0051 D loss:-0.5719 G loss:-2.346\n",
      "Epoch:  0051 D loss:-0.4778 G loss:-2.657\n",
      "Epoch:  0051 D loss:-0.6012 G loss:-2.314\n",
      "Epoch:  0051 D loss:-0.4428 G loss:-2.529\n",
      "Epoch:  0051 D loss:-0.4875 G loss:-2.241\n",
      "Epoch:  0051 D loss:-0.5888 G loss:-2.341\n",
      "Epoch:  0051 D loss:-0.5706 G loss:-2.395\n",
      "Epoch:  0051 D loss:-0.4703 G loss:-2.307\n",
      "Epoch:  0051 D loss:-0.601 G loss:-2.222\n",
      "Epoch:  0051 D loss:-0.5868 G loss:-2.122\n",
      "Epoch:  0051 D loss:-0.6448 G loss:-2.016\n",
      "Epoch:  0051 D loss:-0.6719 G loss:-2.153\n",
      "Epoch:  0051 D loss:-0.6779 G loss:-2.102\n",
      "Epoch:  0051 D loss:-0.5556 G loss:-2.325\n",
      "Epoch:  0051 D loss:-0.6438 G loss:-2.43\n",
      "Epoch:  0051 D loss:-0.4674 G loss:-2.408\n",
      "Epoch:  0051 D loss:-0.6107 G loss:-2.354\n",
      "Epoch:  0051 D loss:-0.6278 G loss:-2.275\n",
      "Epoch:  0051 D loss:-0.6436 G loss:-2.164\n",
      "Epoch:  0051 D loss:-0.4975 G loss:-2.455\n",
      "Epoch:  0051 D loss:-0.4945 G loss:-2.479\n",
      "Epoch:  0051 D loss:-0.5295 G loss:-2.367\n",
      "Epoch:  0051 D loss:-0.6486 G loss:-2.284\n",
      "Epoch:  0051 D loss:-0.5115 G loss:-2.22\n",
      "Epoch:  0051 D loss:-0.6502 G loss:-2.269\n",
      "Epoch:  0051 D loss:-0.5235 G loss:-2.23\n",
      "Epoch:  0051 D loss:-0.7239 G loss:-2.371\n",
      "Epoch:  0051 D loss:-0.7344 G loss:-2.311\n",
      "Epoch:  0051 D loss:-0.7808 G loss:-2.222\n",
      "Epoch:  0051 D loss:-0.6352 G loss:-2.114\n",
      "Epoch:  0051 D loss:-0.6392 G loss:-2.093\n",
      "Epoch:  0051 D loss:-0.5861 G loss:-2.145\n",
      "Epoch:  0051 D loss:-0.558 G loss:-2.261\n",
      "Epoch:  0051 D loss:-0.6003 G loss:-2.199\n",
      "Epoch:  0051 D loss:-0.5853 G loss:-1.944\n",
      "Epoch:  0051 D loss:-0.5714 G loss:-2.175\n",
      "Epoch:  0051 D loss:-0.4795 G loss:-2.15\n",
      "Epoch:  0051 D loss:-0.6535 G loss:-2.269\n",
      "Epoch:  0051 D loss:-0.648 G loss:-2.241\n",
      "Epoch:  0051 D loss:-0.6772 G loss:-2.363\n",
      "Epoch:  0051 D loss:-0.6249 G loss:-2.38\n",
      "Epoch:  0051 D loss:-0.7348 G loss:-2.379\n",
      "Epoch:  0051 D loss:-0.5541 G loss:-2.389\n",
      "Epoch:  0051 D loss:-0.6821 G loss:-2.32\n",
      "Epoch:  0051 D loss:-0.5921 G loss:-2.173\n",
      "Epoch:  0051 D loss:-0.6148 G loss:-2.045\n",
      "Epoch:  0051 D loss:-0.5767 G loss:-2.019\n",
      "Epoch:  0051 D loss:-0.7333 G loss:-2.047\n",
      "Epoch:  0051 D loss:-0.8506 G loss:-1.986\n",
      "Epoch:  0051 D loss:-0.6945 G loss:-2.044\n",
      "Epoch:  0051 D loss:-0.8266 G loss:-1.875\n",
      "Epoch:  0051 D loss:-0.6215 G loss:-2.034\n",
      "Epoch:  0051 D loss:-0.6977 G loss:-2.03\n",
      "Epoch:  0051 D loss:-0.6316 G loss:-2.101\n",
      "Epoch:  0051 D loss:-0.5812 G loss:-2.119\n",
      "Epoch:  0051 D loss:-0.7021 G loss:-2.056\n",
      "Epoch:  0051 D loss:-0.5675 G loss:-2.176\n",
      "Epoch:  0051 D loss:-0.5172 G loss:-2.414\n",
      "Epoch:  0051 D loss:-0.4526 G loss:-2.541\n",
      "Epoch:  0051 D loss:-0.5741 G loss:-2.403\n",
      "Epoch:  0051 D loss:-0.719 G loss:-2.456\n",
      "Epoch:  0051 D loss:-0.7096 G loss:-2.356\n",
      "Epoch:  0051 D loss:-0.5575 G loss:-2.482\n",
      "Epoch:  0051 D loss:-0.6718 G loss:-2.499\n",
      "Epoch:  0051 D loss:-0.6146 G loss:-2.575\n",
      "Epoch:  0051 D loss:-0.6966 G loss:-2.179\n",
      "Epoch:  0051 D loss:-0.5498 G loss:-2.158\n",
      "Epoch:  0051 D loss:-0.5864 G loss:-2.148\n",
      "Epoch:  0051 D loss:-0.6671 G loss:-2.156\n",
      "Epoch:  0051 D loss:-0.6207 G loss:-2.121\n",
      "Epoch:  0051 D loss:-0.5609 G loss:-2.202\n",
      "Epoch:  0051 D loss:-0.5891 G loss:-2.185\n",
      "Epoch:  0051 D loss:-0.5964 G loss:-2.198\n",
      "Epoch:  0051 D loss:-0.5977 G loss:-2.208\n",
      "Epoch:  0051 D loss:-0.6005 G loss:-2.416\n",
      "Epoch:  0051 D loss:-0.5665 G loss:-2.326\n",
      "Epoch:  0051 D loss:-0.618 G loss:-2.408\n",
      "Epoch:  0051 D loss:-0.633 G loss:-2.211\n",
      "Epoch:  0051 D loss:-0.5611 G loss:-2.466\n",
      "Epoch:  0051 D loss:-0.5084 G loss:-2.362\n",
      "Epoch:  0051 D loss:-0.5834 G loss:-2.251\n",
      "Epoch:  0051 D loss:-0.6267 G loss:-2.234\n",
      "Epoch:  0051 D loss:-0.655 G loss:-2.217\n",
      "Epoch:  0051 D loss:-0.6283 G loss:-2.114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0051 D loss:-0.7208 G loss:-2.233\n",
      "Epoch:  0051 D loss:-0.6518 G loss:-2.183\n",
      "Epoch:  0051 D loss:-0.6534 G loss:-2.183\n",
      "Epoch:  0051 D loss:-0.6675 G loss:-2.108\n",
      "Epoch:  0051 D loss:-0.7104 G loss:-2.247\n",
      "Epoch:  0051 D loss:-0.6386 G loss:-1.969\n",
      "Epoch:  0051 D loss:-0.6396 G loss:-2.055\n",
      "Epoch:  0051 D loss:-0.5785 G loss:-2.159\n",
      "Epoch:  0051 D loss:-0.5938 G loss:-2.174\n",
      "Epoch:  0051 D loss:-0.6589 G loss:-1.987\n",
      "Epoch:  0051 D loss:-0.7103 G loss:-2.147\n",
      "Epoch:  0051 D loss:-0.6914 G loss:-2.04\n",
      "Epoch:  0051 D loss:-0.6223 G loss:-2.325\n",
      "Epoch:  0051 D loss:-0.5947 G loss:-2.591\n",
      "Epoch:  0051 D loss:-0.6712 G loss:-2.111\n",
      "Epoch:  0051 D loss:-0.494 G loss:-2.164\n",
      "Epoch:  0051 D loss:-0.5865 G loss:-2.271\n",
      "Epoch:  0051 D loss:-0.6433 G loss:-2.073\n",
      "Epoch:  0051 D loss:-0.5789 G loss:-2.21\n",
      "Epoch:  0051 D loss:-0.5587 G loss:-2.379\n",
      "Epoch:  0051 D loss:-0.5865 G loss:-2.14\n",
      "Epoch:  0051 D loss:-0.7096 G loss:-2.267\n",
      "Epoch:  0051 D loss:-0.5762 G loss:-2.127\n",
      "Epoch:  0051 D loss:-0.6643 G loss:-2.126\n",
      "Epoch:  0051 D loss:-0.5419 G loss:-2.215\n",
      "Epoch:  0051 D loss:-0.6894 G loss:-2.205\n",
      "Epoch:  0051 D loss:-0.712 G loss:-2.406\n",
      "Epoch:  0051 D loss:-0.5233 G loss:-2.358\n",
      "Epoch:  0051 D loss:-0.5695 G loss:-2.376\n",
      "Epoch:  0051 D loss:-0.6096 G loss:-2.226\n",
      "Epoch:  0051 D loss:-0.7001 G loss:-1.996\n",
      "Epoch:  0051 D loss:-0.6881 G loss:-1.939\n",
      "Epoch:  0051 D loss:-0.6963 G loss:-2.152\n",
      "Epoch:  0051 D loss:-0.6444 G loss:-2.2\n",
      "Epoch:  0051 D loss:-0.6585 G loss:-2.155\n",
      "Epoch:  0051 D loss:-0.5478 G loss:-2.391\n",
      "Epoch:  0051 D loss:-0.52 G loss:-2.416\n",
      "Epoch:  0051 D loss:-0.6141 G loss:-2.224\n",
      "Epoch:  0051 D loss:-0.5739 G loss:-2.462\n",
      "Epoch:  0051 D loss:-0.4754 G loss:-2.312\n",
      "Epoch:  0051 D loss:-0.4795 G loss:-2.321\n",
      "Epoch:  0051 D loss:-0.5807 G loss:-2.382\n",
      "Epoch:  0051 D loss:-0.5949 G loss:-2.359\n",
      "Epoch:  0051 D loss:-0.5452 G loss:-2.423\n",
      "Epoch:  0051 D loss:-0.7529 G loss:-2.276\n",
      "Epoch:  0051 D loss:-0.6832 G loss:-2.26\n",
      "Epoch:  0051 D loss:-0.6556 G loss:-2.256\n",
      "Epoch:  0051 D loss:-0.5726 G loss:-2.274\n",
      "Epoch:  0051 D loss:-0.6411 G loss:-2.072\n",
      "Epoch:  0051 D loss:-0.6127 G loss:-2.078\n",
      "Epoch:  0051 D loss:-0.654 G loss:-1.951\n",
      "Epoch:  0051 D loss:-0.5653 G loss:-2.199\n",
      "Epoch:  0051 D loss:-0.5786 G loss:-2.18\n",
      "Epoch:  0051 D loss:-0.6036 G loss:-2.102\n",
      "Epoch:  0051 D loss:-0.5843 G loss:-2.343\n",
      "Epoch:  0051 D loss:-0.5352 G loss:-2.093\n",
      "Epoch:  0051 D loss:-0.6805 G loss:-2.389\n",
      "Epoch:  0051 D loss:-0.5287 G loss:-2.335\n",
      "Epoch:  0051 D loss:-0.8183 G loss:-2.227\n",
      "Epoch:  0051 D loss:-0.6785 G loss:-2.423\n",
      "Epoch:  0051 D loss:-0.6445 G loss:-2.408\n",
      "Epoch:  0051 D loss:-0.5787 G loss:-2.242\n",
      "Epoch:  0051 D loss:-0.6688 G loss:-2.16\n",
      "Epoch:  0051 D loss:-0.5672 G loss:-2.342\n",
      "Epoch:  0051 D loss:-0.6785 G loss:-2.275\n",
      "Epoch:  0051 D loss:-0.6039 G loss:-2.273\n",
      "Epoch:  0051 D loss:-0.559 G loss:-2.321\n",
      "Epoch:  0051 D loss:-0.5354 G loss:-2.45\n",
      "Epoch:  0051 D loss:-0.701 G loss:-2.243\n",
      "Epoch:  0051 D loss:-0.6333 G loss:-2.207\n",
      "Epoch:  0051 D loss:-0.5202 G loss:-2.088\n",
      "Epoch:  0051 D loss:-0.6684 G loss:-1.954\n",
      "Epoch:  0051 D loss:-0.5185 G loss:-2.207\n",
      "Epoch:  0051 D loss:-0.7394 G loss:-2.112\n",
      "Epoch:  0051 D loss:-0.938 G loss:-1.817\n",
      "Epoch:  0051 D loss:-0.582 G loss:-2.186\n",
      "Epoch:  0051 D loss:-0.7729 G loss:-1.911\n",
      "Epoch:  0051 D loss:-0.6427 G loss:-2.016\n",
      "Epoch:  0051 D loss:-0.6107 G loss:-2.144\n",
      "Epoch:  0051 D loss:-0.657 G loss:-2.146\n",
      "Epoch:  0051 D loss:-0.6999 G loss:-2.191\n",
      "Epoch:  0051 D loss:-0.7057 G loss:-1.852\n",
      "Epoch:  0051 D loss:-0.5095 G loss:-2.264\n",
      "Epoch:  0051 D loss:-0.5644 G loss:-2.249\n",
      "Epoch:  0051 D loss:-0.6636 G loss:-2.25\n",
      "Epoch:  0051 D loss:-0.7526 G loss:-2.359\n",
      "Epoch:  0051 D loss:-0.6149 G loss:-2.349\n",
      "Epoch:  0051 D loss:-0.6077 G loss:-2.295\n",
      "Epoch:  0052 D loss:-0.5908 G loss:-2.099\n",
      "Epoch:  0052 D loss:-0.5992 G loss:-2.324\n",
      "Epoch:  0052 D loss:-0.5335 G loss:-2.205\n",
      "Epoch:  0052 D loss:-0.6079 G loss:-2.313\n",
      "Epoch:  0052 D loss:-0.6712 G loss:-2.131\n",
      "Epoch:  0052 D loss:-0.5821 G loss:-2.376\n",
      "Epoch:  0052 D loss:-0.6398 G loss:-2.085\n",
      "Epoch:  0052 D loss:-0.5685 G loss:-2.193\n",
      "Epoch:  0052 D loss:-0.6251 G loss:-2.156\n",
      "Epoch:  0052 D loss:-0.5967 G loss:-2.127\n",
      "Epoch:  0052 D loss:-0.6058 G loss:-2.169\n",
      "Epoch:  0052 D loss:-0.6115 G loss:-2.279\n",
      "Epoch:  0052 D loss:-0.5339 G loss:-2.032\n",
      "Epoch:  0052 D loss:-0.6509 G loss:-2.132\n",
      "Epoch:  0052 D loss:-0.5307 G loss:-2.221\n",
      "Epoch:  0052 D loss:-0.6139 G loss:-2.176\n",
      "Epoch:  0052 D loss:-0.5557 G loss:-2.264\n",
      "Epoch:  0052 D loss:-0.5521 G loss:-2.325\n",
      "Epoch:  0052 D loss:-0.6217 G loss:-2.171\n",
      "Epoch:  0052 D loss:-0.5778 G loss:-2.405\n",
      "Epoch:  0052 D loss:-0.6876 G loss:-2.368\n",
      "Epoch:  0052 D loss:-0.8084 G loss:-2.374\n",
      "Epoch:  0052 D loss:-0.8177 G loss:-2.413\n",
      "Epoch:  0052 D loss:-0.6435 G loss:-2.394\n",
      "Epoch:  0052 D loss:-0.687 G loss:-2.198\n",
      "Epoch:  0052 D loss:-0.623 G loss:-2.07\n",
      "Epoch:  0052 D loss:-0.6081 G loss:-2.223\n",
      "Epoch:  0052 D loss:-0.6572 G loss:-1.939\n",
      "Epoch:  0052 D loss:-0.6395 G loss:-1.94\n",
      "Epoch:  0052 D loss:-0.7005 G loss:-2.287\n",
      "Epoch:  0052 D loss:-0.6054 G loss:-2.15\n",
      "Epoch:  0052 D loss:-0.6314 G loss:-2.124\n",
      "Epoch:  0052 D loss:-0.6591 G loss:-2.031\n",
      "Epoch:  0052 D loss:-0.5175 G loss:-2.112\n",
      "Epoch:  0052 D loss:-0.6498 G loss:-2.166\n",
      "Epoch:  0052 D loss:-0.7578 G loss:-2.117\n",
      "Epoch:  0052 D loss:-0.7263 G loss:-2.358\n",
      "Epoch:  0052 D loss:-0.567 G loss:-2.393\n",
      "Epoch:  0052 D loss:-0.5389 G loss:-2.321\n",
      "Epoch:  0052 D loss:-0.6067 G loss:-2.373\n",
      "Epoch:  0052 D loss:-0.4784 G loss:-2.138\n",
      "Epoch:  0052 D loss:-0.5614 G loss:-2.266\n",
      "Epoch:  0052 D loss:-0.5448 G loss:-2.123\n",
      "Epoch:  0052 D loss:-0.4977 G loss:-2.125\n",
      "Epoch:  0052 D loss:-0.5581 G loss:-2.335\n",
      "Epoch:  0052 D loss:-0.6188 G loss:-2.186\n",
      "Epoch:  0052 D loss:-0.6381 G loss:-2.109\n",
      "Epoch:  0052 D loss:-0.6414 G loss:-1.952\n",
      "Epoch:  0052 D loss:-0.5901 G loss:-2.007\n",
      "Epoch:  0052 D loss:-0.5965 G loss:-2.211\n",
      "Epoch:  0052 D loss:-0.461 G loss:-2.32\n",
      "Epoch:  0052 D loss:-0.5387 G loss:-2.411\n",
      "Epoch:  0052 D loss:-0.6068 G loss:-2.591\n",
      "Epoch:  0052 D loss:-0.7875 G loss:-2.327\n",
      "Epoch:  0052 D loss:-0.5986 G loss:-2.276\n",
      "Epoch:  0052 D loss:-0.5971 G loss:-2.149\n",
      "Epoch:  0052 D loss:-0.6165 G loss:-2.059\n",
      "Epoch:  0052 D loss:-0.6729 G loss:-1.869\n",
      "Epoch:  0052 D loss:-0.5393 G loss:-1.965\n",
      "Epoch:  0052 D loss:-0.7168 G loss:-2.234\n",
      "Epoch:  0052 D loss:-0.6338 G loss:-2.097\n",
      "Epoch:  0052 D loss:-0.5493 G loss:-2.324\n",
      "Epoch:  0052 D loss:-0.6459 G loss:-2.113\n",
      "Epoch:  0052 D loss:-0.502 G loss:-2.351\n",
      "Epoch:  0052 D loss:-0.6118 G loss:-2.181\n",
      "Epoch:  0052 D loss:-0.5289 G loss:-2.357\n",
      "Epoch:  0052 D loss:-0.662 G loss:-2.09\n",
      "Epoch:  0052 D loss:-0.634 G loss:-2.385\n",
      "Epoch:  0052 D loss:-0.552 G loss:-2.266\n",
      "Epoch:  0052 D loss:-0.6258 G loss:-2.182\n",
      "Epoch:  0052 D loss:-0.4567 G loss:-2.446\n",
      "Epoch:  0052 D loss:-0.605 G loss:-2.228\n",
      "Epoch:  0052 D loss:-0.4887 G loss:-2.272\n",
      "Epoch:  0052 D loss:-0.6088 G loss:-2.4\n",
      "Epoch:  0052 D loss:-0.781 G loss:-2.128\n",
      "Epoch:  0052 D loss:-0.5605 G loss:-2.25\n",
      "Epoch:  0052 D loss:-0.6812 G loss:-2.048\n",
      "Epoch:  0052 D loss:-0.7072 G loss:-2.296\n",
      "Epoch:  0052 D loss:-0.7049 G loss:-2.06\n",
      "Epoch:  0052 D loss:-0.7108 G loss:-1.977\n",
      "Epoch:  0052 D loss:-0.6254 G loss:-2.073\n",
      "Epoch:  0052 D loss:-0.4946 G loss:-2.172\n",
      "Epoch:  0052 D loss:-0.6336 G loss:-2.018\n",
      "Epoch:  0052 D loss:-0.7465 G loss:-2.009\n",
      "Epoch:  0052 D loss:-0.7144 G loss:-2.081\n",
      "Epoch:  0052 D loss:-0.434 G loss:-2.29\n",
      "Epoch:  0052 D loss:-0.5857 G loss:-2.169\n",
      "Epoch:  0052 D loss:-0.5134 G loss:-2.654\n",
      "Epoch:  0052 D loss:-0.6514 G loss:-2.221\n",
      "Epoch:  0052 D loss:-0.6876 G loss:-2.198\n",
      "Epoch:  0052 D loss:-0.6796 G loss:-2.252\n",
      "Epoch:  0052 D loss:-0.6262 G loss:-2.304\n",
      "Epoch:  0052 D loss:-0.6211 G loss:-2.341\n",
      "Epoch:  0052 D loss:-0.5396 G loss:-2.307\n",
      "Epoch:  0052 D loss:-0.6533 G loss:-2.219\n",
      "Epoch:  0052 D loss:-0.6647 G loss:-2.225\n",
      "Epoch:  0052 D loss:-0.6038 G loss:-2.032\n",
      "Epoch:  0052 D loss:-0.5737 G loss:-2.529\n",
      "Epoch:  0052 D loss:-0.5973 G loss:-1.964\n",
      "Epoch:  0052 D loss:-0.7805 G loss:-2.106\n",
      "Epoch:  0052 D loss:-0.5713 G loss:-2.275\n",
      "Epoch:  0052 D loss:-0.6434 G loss:-2.081\n",
      "Epoch:  0052 D loss:-0.6279 G loss:-1.895\n",
      "Epoch:  0052 D loss:-0.5801 G loss:-2.168\n",
      "Epoch:  0052 D loss:-0.5432 G loss:-2.116\n",
      "Epoch:  0052 D loss:-0.6233 G loss:-2.169\n",
      "Epoch:  0052 D loss:-0.6535 G loss:-2.239\n",
      "Epoch:  0052 D loss:-0.6363 G loss:-2.125\n",
      "Epoch:  0052 D loss:-0.6249 G loss:-2.305\n",
      "Epoch:  0052 D loss:-0.6104 G loss:-2.316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0052 D loss:-0.5926 G loss:-2.595\n",
      "Epoch:  0052 D loss:-0.5078 G loss:-2.34\n",
      "Epoch:  0052 D loss:-0.6354 G loss:-2.177\n",
      "Epoch:  0052 D loss:-0.5792 G loss:-2.501\n",
      "Epoch:  0052 D loss:-0.5249 G loss:-2.42\n",
      "Epoch:  0052 D loss:-0.5773 G loss:-2.255\n",
      "Epoch:  0052 D loss:-0.6794 G loss:-2.255\n",
      "Epoch:  0052 D loss:-0.596 G loss:-2.084\n",
      "Epoch:  0052 D loss:-0.7203 G loss:-2.052\n",
      "Epoch:  0052 D loss:-0.6634 G loss:-2.251\n",
      "Epoch:  0052 D loss:-0.5246 G loss:-2.266\n",
      "Epoch:  0052 D loss:-0.618 G loss:-2.241\n",
      "Epoch:  0052 D loss:-0.6802 G loss:-2.169\n",
      "Epoch:  0052 D loss:-0.64 G loss:-2.182\n",
      "Epoch:  0052 D loss:-0.624 G loss:-2.06\n",
      "Epoch:  0052 D loss:-0.7795 G loss:-1.808\n",
      "Epoch:  0052 D loss:-0.7235 G loss:-2.061\n",
      "Epoch:  0052 D loss:-0.6904 G loss:-2.1\n",
      "Epoch:  0052 D loss:-0.5858 G loss:-2.208\n",
      "Epoch:  0052 D loss:-0.642 G loss:-2.235\n",
      "Epoch:  0052 D loss:-0.557 G loss:-2.366\n",
      "Epoch:  0052 D loss:-0.5766 G loss:-2.118\n",
      "Epoch:  0052 D loss:-0.6534 G loss:-2.211\n",
      "Epoch:  0052 D loss:-0.6058 G loss:-2.132\n",
      "Epoch:  0052 D loss:-0.6641 G loss:-2.117\n",
      "Epoch:  0052 D loss:-0.6312 G loss:-2.262\n",
      "Epoch:  0052 D loss:-0.6667 G loss:-2.314\n",
      "Epoch:  0052 D loss:-0.6748 G loss:-2.267\n",
      "Epoch:  0052 D loss:-0.5823 G loss:-2.385\n",
      "Epoch:  0052 D loss:-0.4922 G loss:-2.31\n",
      "Epoch:  0052 D loss:-0.6275 G loss:-2.454\n",
      "Epoch:  0052 D loss:-0.5247 G loss:-2.254\n",
      "Epoch:  0052 D loss:-0.7183 G loss:-2.202\n",
      "Epoch:  0052 D loss:-0.6646 G loss:-2.323\n",
      "Epoch:  0052 D loss:-0.5927 G loss:-2.317\n",
      "Epoch:  0052 D loss:-0.5029 G loss:-2.248\n",
      "Epoch:  0052 D loss:-0.6133 G loss:-2.056\n",
      "Epoch:  0052 D loss:-0.6676 G loss:-1.954\n",
      "Epoch:  0052 D loss:-0.6538 G loss:-2.067\n",
      "Epoch:  0052 D loss:-0.6441 G loss:-2.05\n",
      "Epoch:  0052 D loss:-0.5933 G loss:-2.202\n",
      "Epoch:  0052 D loss:-0.5727 G loss:-2.177\n",
      "Epoch:  0052 D loss:-0.5236 G loss:-2.309\n",
      "Epoch:  0052 D loss:-0.5301 G loss:-2.432\n",
      "Epoch:  0052 D loss:-0.6478 G loss:-2.255\n",
      "Epoch:  0052 D loss:-0.514 G loss:-2.208\n",
      "Epoch:  0052 D loss:-0.5315 G loss:-2.34\n",
      "Epoch:  0052 D loss:-0.4879 G loss:-2.442\n",
      "Epoch:  0052 D loss:-0.7141 G loss:-2.122\n",
      "Epoch:  0052 D loss:-0.6646 G loss:-1.99\n",
      "Epoch:  0052 D loss:-0.6389 G loss:-2.213\n",
      "Epoch:  0052 D loss:-0.6354 G loss:-2.06\n",
      "Epoch:  0052 D loss:-0.6228 G loss:-2.174\n",
      "Epoch:  0052 D loss:-0.6424 G loss:-1.932\n",
      "Epoch:  0052 D loss:-0.642 G loss:-2.056\n",
      "Epoch:  0052 D loss:-0.7151 G loss:-2.008\n",
      "Epoch:  0052 D loss:-0.6031 G loss:-2.122\n",
      "Epoch:  0052 D loss:-0.5209 G loss:-2.115\n",
      "Epoch:  0052 D loss:-0.7101 G loss:-1.958\n",
      "Epoch:  0052 D loss:-0.6018 G loss:-2.384\n",
      "Epoch:  0052 D loss:-0.5949 G loss:-2.291\n",
      "Epoch:  0052 D loss:-0.7484 G loss:-2.301\n",
      "Epoch:  0052 D loss:-0.5835 G loss:-2.099\n",
      "Epoch:  0052 D loss:-0.644 G loss:-2.269\n",
      "Epoch:  0052 D loss:-0.6165 G loss:-2.38\n",
      "Epoch:  0052 D loss:-0.595 G loss:-2.226\n",
      "Epoch:  0052 D loss:-0.6553 G loss:-2.242\n",
      "Epoch:  0052 D loss:-0.505 G loss:-2.201\n",
      "Epoch:  0052 D loss:-0.5406 G loss:-2.253\n",
      "Epoch:  0052 D loss:-0.6027 G loss:-2.221\n",
      "Epoch:  0052 D loss:-0.5777 G loss:-2.134\n",
      "Epoch:  0052 D loss:-0.6002 G loss:-2.207\n",
      "Epoch:  0052 D loss:-0.6658 G loss:-2.095\n",
      "Epoch:  0052 D loss:-0.5907 G loss:-2.349\n",
      "Epoch:  0052 D loss:-0.4933 G loss:-2.43\n",
      "Epoch:  0052 D loss:-0.6143 G loss:-2.18\n",
      "Epoch:  0052 D loss:-0.5628 G loss:-2.322\n",
      "Epoch:  0052 D loss:-0.5837 G loss:-2.42\n",
      "Epoch:  0052 D loss:-0.6105 G loss:-2.251\n",
      "Epoch:  0052 D loss:-0.6974 G loss:-2.301\n",
      "Epoch:  0052 D loss:-0.6019 G loss:-2.162\n",
      "Epoch:  0052 D loss:-0.7054 G loss:-2.202\n",
      "Epoch:  0052 D loss:-0.5042 G loss:-2.298\n",
      "Epoch:  0052 D loss:-0.5235 G loss:-2.113\n",
      "Epoch:  0052 D loss:-0.7793 G loss:-1.943\n",
      "Epoch:  0052 D loss:-0.7521 G loss:-2.093\n",
      "Epoch:  0052 D loss:-0.6576 G loss:-1.971\n",
      "Epoch:  0052 D loss:-0.6334 G loss:-1.966\n",
      "Epoch:  0052 D loss:-0.7291 G loss:-2.039\n",
      "Epoch:  0052 D loss:-0.6212 G loss:-2.098\n",
      "Epoch:  0052 D loss:-0.5454 G loss:-2.41\n",
      "Epoch:  0052 D loss:-0.5702 G loss:-2.422\n",
      "Epoch:  0052 D loss:-0.7106 G loss:-2.202\n",
      "Epoch:  0052 D loss:-0.5811 G loss:-2.337\n",
      "Epoch:  0052 D loss:-0.712 G loss:-2.067\n",
      "Epoch:  0052 D loss:-0.6353 G loss:-2.336\n",
      "Epoch:  0052 D loss:-0.4741 G loss:-2.369\n",
      "Epoch:  0052 D loss:-0.5962 G loss:-2.325\n",
      "Epoch:  0052 D loss:-0.7504 G loss:-2.15\n",
      "Epoch:  0052 D loss:-0.5282 G loss:-2.078\n",
      "Epoch:  0052 D loss:-0.6036 G loss:-2.133\n",
      "Epoch:  0052 D loss:-0.561 G loss:-2.307\n",
      "Epoch:  0052 D loss:-0.6562 G loss:-2.248\n",
      "Epoch:  0052 D loss:-0.5998 G loss:-2.342\n",
      "Epoch:  0052 D loss:-0.7519 G loss:-2.145\n",
      "Epoch:  0052 D loss:-0.7803 G loss:-2.249\n",
      "Epoch:  0052 D loss:-0.7807 G loss:-2.129\n",
      "Epoch:  0052 D loss:-0.5135 G loss:-2.184\n",
      "Epoch:  0052 D loss:-0.5899 G loss:-2.198\n",
      "Epoch:  0052 D loss:-0.516 G loss:-2.145\n",
      "Epoch:  0052 D loss:-0.6684 G loss:-2.115\n",
      "Epoch:  0052 D loss:-0.6272 G loss:-2.114\n",
      "Epoch:  0052 D loss:-0.5779 G loss:-2.289\n",
      "Epoch:  0052 D loss:-0.5605 G loss:-2.43\n",
      "Epoch:  0052 D loss:-0.626 G loss:-2.272\n",
      "Epoch:  0052 D loss:-0.5466 G loss:-2.41\n",
      "Epoch:  0052 D loss:-0.6993 G loss:-2.315\n",
      "Epoch:  0052 D loss:-0.6415 G loss:-2.469\n",
      "Epoch:  0052 D loss:-0.6002 G loss:-2.257\n",
      "Epoch:  0052 D loss:-0.6384 G loss:-2.357\n",
      "Epoch:  0052 D loss:-0.5628 G loss:-2.314\n",
      "Epoch:  0052 D loss:-0.5667 G loss:-2.101\n",
      "Epoch:  0052 D loss:-0.6379 G loss:-2.18\n",
      "Epoch:  0052 D loss:-0.5752 G loss:-2.313\n",
      "Epoch:  0052 D loss:-0.6101 G loss:-2.365\n",
      "Epoch:  0052 D loss:-0.5269 G loss:-2.252\n",
      "Epoch:  0052 D loss:-0.6414 G loss:-2.145\n",
      "Epoch:  0052 D loss:-0.6153 G loss:-2.236\n",
      "Epoch:  0052 D loss:-0.7649 G loss:-2.006\n",
      "Epoch:  0052 D loss:-0.5743 G loss:-2.245\n",
      "Epoch:  0052 D loss:-0.6467 G loss:-2.193\n",
      "Epoch:  0052 D loss:-0.6884 G loss:-2.178\n",
      "Epoch:  0052 D loss:-0.6128 G loss:-2.223\n",
      "Epoch:  0052 D loss:-0.6153 G loss:-2.314\n",
      "Epoch:  0052 D loss:-0.7021 G loss:-2.282\n",
      "Epoch:  0052 D loss:-0.7168 G loss:-1.951\n",
      "Epoch:  0052 D loss:-0.5484 G loss:-2.092\n",
      "Epoch:  0052 D loss:-0.4695 G loss:-2.168\n",
      "Epoch:  0052 D loss:-0.4793 G loss:-2.59\n",
      "Epoch:  0052 D loss:-0.6083 G loss:-2.22\n",
      "Epoch:  0052 D loss:-0.7419 G loss:-2.309\n",
      "Epoch:  0052 D loss:-0.5886 G loss:-2.451\n",
      "Epoch:  0052 D loss:-0.5134 G loss:-2.479\n",
      "Epoch:  0052 D loss:-0.6593 G loss:-2.208\n",
      "Epoch:  0052 D loss:-0.6374 G loss:-2.274\n",
      "Epoch:  0052 D loss:-0.5864 G loss:-2.113\n",
      "Epoch:  0052 D loss:-0.624 G loss:-2.204\n",
      "Epoch:  0052 D loss:-0.6322 G loss:-2.191\n",
      "Epoch:  0052 D loss:-0.6139 G loss:-2.121\n",
      "Epoch:  0052 D loss:-0.5745 G loss:-2.097\n",
      "Epoch:  0052 D loss:-0.6987 G loss:-2.045\n",
      "Epoch:  0052 D loss:-0.7255 G loss:-1.818\n",
      "Epoch:  0052 D loss:-0.5899 G loss:-2.051\n",
      "Epoch:  0052 D loss:-0.6781 G loss:-2.188\n",
      "Epoch:  0052 D loss:-0.6802 G loss:-2.229\n",
      "Epoch:  0052 D loss:-0.6308 G loss:-2.322\n",
      "Epoch:  0052 D loss:-0.6529 G loss:-2.339\n",
      "Epoch:  0052 D loss:-0.6036 G loss:-2.236\n",
      "Epoch:  0052 D loss:-0.6044 G loss:-2.273\n",
      "Epoch:  0052 D loss:-0.407 G loss:-2.418\n",
      "Epoch:  0052 D loss:-0.5304 G loss:-2.467\n",
      "Epoch:  0052 D loss:-0.5961 G loss:-2.461\n",
      "Epoch:  0052 D loss:-0.5582 G loss:-2.455\n",
      "Epoch:  0052 D loss:-0.6228 G loss:-2.122\n",
      "Epoch:  0052 D loss:-0.5269 G loss:-2.4\n",
      "Epoch:  0052 D loss:-0.5427 G loss:-2.297\n",
      "Epoch:  0052 D loss:-0.6513 G loss:-2.093\n",
      "Epoch:  0052 D loss:-0.5252 G loss:-2.105\n",
      "Epoch:  0052 D loss:-0.5162 G loss:-2.023\n",
      "Epoch:  0052 D loss:-0.5756 G loss:-2.142\n",
      "Epoch:  0052 D loss:-0.6052 G loss:-2.279\n",
      "Epoch:  0052 D loss:-0.6394 G loss:-2.129\n",
      "Epoch:  0052 D loss:-0.5854 G loss:-2.219\n",
      "Epoch:  0052 D loss:-0.6001 G loss:-2.152\n",
      "Epoch:  0052 D loss:-0.6102 G loss:-2.14\n",
      "Epoch:  0052 D loss:-0.6838 G loss:-2.271\n",
      "Epoch:  0052 D loss:-0.635 G loss:-2.373\n",
      "Epoch:  0052 D loss:-0.5994 G loss:-2.293\n",
      "Epoch:  0052 D loss:-0.6483 G loss:-2.434\n",
      "Epoch:  0052 D loss:-0.6833 G loss:-2.102\n",
      "Epoch:  0052 D loss:-0.7377 G loss:-2.084\n",
      "Epoch:  0052 D loss:-0.5712 G loss:-2.181\n",
      "Epoch:  0052 D loss:-0.6021 G loss:-2.26\n",
      "Epoch:  0052 D loss:-0.6578 G loss:-2.165\n",
      "Epoch:  0052 D loss:-0.634 G loss:-2.091\n",
      "Epoch:  0052 D loss:-0.59 G loss:-1.956\n",
      "Epoch:  0052 D loss:-0.7197 G loss:-1.964\n",
      "Epoch:  0052 D loss:-0.5627 G loss:-2.227\n",
      "Epoch:  0052 D loss:-0.5153 G loss:-2.055\n",
      "Epoch:  0052 D loss:-0.5984 G loss:-1.951\n",
      "Epoch:  0052 D loss:-0.635 G loss:-2.454\n",
      "Epoch:  0052 D loss:-0.5933 G loss:-2.176\n",
      "Epoch:  0052 D loss:-0.6201 G loss:-2.247\n",
      "Epoch:  0052 D loss:-0.6456 G loss:-2.384\n",
      "Epoch:  0052 D loss:-0.5916 G loss:-2.469\n",
      "Epoch:  0052 D loss:-0.5601 G loss:-2.39\n",
      "Epoch:  0052 D loss:-0.5475 G loss:-2.251\n",
      "Epoch:  0052 D loss:-0.6744 G loss:-1.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0052 D loss:-0.5552 G loss:-2.216\n",
      "Epoch:  0052 D loss:-0.6594 G loss:-2.001\n",
      "Epoch:  0052 D loss:-0.6043 G loss:-2.336\n",
      "Epoch:  0052 D loss:-0.5827 G loss:-2.231\n",
      "Epoch:  0052 D loss:-0.6155 G loss:-2.272\n",
      "Epoch:  0052 D loss:-0.6709 G loss:-1.999\n",
      "Epoch:  0052 D loss:-0.6645 G loss:-2.354\n",
      "Epoch:  0052 D loss:-0.8336 G loss:-2.047\n",
      "Epoch:  0052 D loss:-0.6323 G loss:-2.147\n",
      "Epoch:  0052 D loss:-0.5673 G loss:-2.233\n",
      "Epoch:  0052 D loss:-0.6403 G loss:-2.117\n",
      "Epoch:  0052 D loss:-0.7443 G loss:-2.172\n",
      "Epoch:  0052 D loss:-0.6633 G loss:-2.187\n",
      "Epoch:  0052 D loss:-0.603 G loss:-2.107\n",
      "Epoch:  0052 D loss:-0.597 G loss:-2.248\n",
      "Epoch:  0052 D loss:-0.5701 G loss:-2.318\n",
      "Epoch:  0052 D loss:-0.6489 G loss:-2.359\n",
      "Epoch:  0052 D loss:-0.5213 G loss:-2.393\n",
      "Epoch:  0052 D loss:-0.5091 G loss:-2.471\n",
      "Epoch:  0052 D loss:-0.5354 G loss:-2.244\n",
      "Epoch:  0052 D loss:-0.6515 G loss:-2.404\n",
      "Epoch:  0052 D loss:-0.6078 G loss:-2.396\n",
      "Epoch:  0052 D loss:-0.8712 G loss:-2.104\n",
      "Epoch:  0052 D loss:-0.6061 G loss:-2.214\n",
      "Epoch:  0052 D loss:-0.6741 G loss:-2.049\n",
      "Epoch:  0052 D loss:-0.7193 G loss:-1.914\n",
      "Epoch:  0052 D loss:-0.7336 G loss:-1.993\n",
      "Epoch:  0052 D loss:-0.6406 G loss:-2.088\n",
      "Epoch:  0052 D loss:-0.5488 G loss:-2.35\n",
      "Epoch:  0052 D loss:-0.5716 G loss:-2.145\n",
      "Epoch:  0052 D loss:-0.5443 G loss:-2.144\n",
      "Epoch:  0052 D loss:-0.5602 G loss:-2.162\n",
      "Epoch:  0052 D loss:-0.6474 G loss:-2.151\n",
      "Epoch:  0052 D loss:-0.6952 G loss:-2.236\n",
      "Epoch:  0052 D loss:-0.5597 G loss:-2.158\n",
      "Epoch:  0052 D loss:-0.6701 G loss:-2.119\n",
      "Epoch:  0052 D loss:-0.6896 G loss:-2.19\n",
      "Epoch:  0052 D loss:-0.6787 G loss:-2.269\n",
      "Epoch:  0052 D loss:-0.6029 G loss:-2.186\n",
      "Epoch:  0052 D loss:-0.6311 G loss:-2.129\n",
      "Epoch:  0052 D loss:-0.6086 G loss:-2.142\n",
      "Epoch:  0052 D loss:-0.5576 G loss:-2.257\n",
      "Epoch:  0052 D loss:-0.5314 G loss:-2.248\n",
      "Epoch:  0052 D loss:-0.6735 G loss:-2.174\n",
      "Epoch:  0052 D loss:-0.5006 G loss:-2.24\n",
      "Epoch:  0052 D loss:-0.6145 G loss:-2.279\n",
      "Epoch:  0052 D loss:-0.4742 G loss:-2.342\n",
      "Epoch:  0052 D loss:-0.5418 G loss:-2.459\n",
      "Epoch:  0052 D loss:-0.5362 G loss:-2.231\n",
      "Epoch:  0052 D loss:-0.4811 G loss:-2.387\n",
      "Epoch:  0052 D loss:-0.5844 G loss:-2.36\n",
      "Epoch:  0052 D loss:-0.494 G loss:-2.405\n",
      "Epoch:  0052 D loss:-0.5861 G loss:-2.129\n",
      "Epoch:  0052 D loss:-0.5725 G loss:-2.37\n",
      "Epoch:  0052 D loss:-0.6362 G loss:-2.045\n",
      "Epoch:  0052 D loss:-0.6378 G loss:-2.202\n",
      "Epoch:  0052 D loss:-0.6224 G loss:-2.034\n",
      "Epoch:  0052 D loss:-0.4832 G loss:-2.295\n",
      "Epoch:  0052 D loss:-0.7654 G loss:-2.033\n",
      "Epoch:  0052 D loss:-0.6322 G loss:-2.081\n",
      "Epoch:  0052 D loss:-0.5207 G loss:-2.272\n",
      "Epoch:  0052 D loss:-0.6284 G loss:-2.241\n",
      "Epoch:  0052 D loss:-0.6035 G loss:-2.329\n",
      "Epoch:  0052 D loss:-0.6043 G loss:-2.287\n",
      "Epoch:  0052 D loss:-0.6729 G loss:-2.384\n",
      "Epoch:  0052 D loss:-0.6204 G loss:-2.399\n",
      "Epoch:  0052 D loss:-0.5466 G loss:-2.272\n",
      "Epoch:  0052 D loss:-0.5627 G loss:-2.076\n",
      "Epoch:  0052 D loss:-0.6969 G loss:-2.141\n",
      "Epoch:  0052 D loss:-0.4861 G loss:-2.319\n",
      "Epoch:  0052 D loss:-0.6484 G loss:-2.078\n",
      "Epoch:  0052 D loss:-0.7608 G loss:-2.021\n",
      "Epoch:  0052 D loss:-0.587 G loss:-1.992\n",
      "Epoch:  0052 D loss:-0.7807 G loss:-2.076\n",
      "Epoch:  0052 D loss:-0.7016 G loss:-2.141\n",
      "Epoch:  0052 D loss:-0.631 G loss:-2.117\n",
      "Epoch:  0052 D loss:-0.5101 G loss:-2.334\n",
      "Epoch:  0052 D loss:-0.6531 G loss:-2.314\n",
      "Epoch:  0052 D loss:-0.5776 G loss:-2.324\n",
      "Epoch:  0052 D loss:-0.6767 G loss:-2.277\n",
      "Epoch:  0052 D loss:-0.6489 G loss:-1.975\n",
      "Epoch:  0052 D loss:-0.6066 G loss:-2.15\n",
      "Epoch:  0052 D loss:-0.7037 G loss:-2.176\n",
      "Epoch:  0052 D loss:-0.6611 G loss:-2.213\n",
      "Epoch:  0052 D loss:-0.7408 G loss:-2.083\n",
      "Epoch:  0052 D loss:-0.7473 G loss:-2.0\n",
      "Epoch:  0052 D loss:-0.6173 G loss:-1.937\n",
      "Epoch:  0052 D loss:-0.6432 G loss:-2.04\n",
      "Epoch:  0052 D loss:-0.548 G loss:-2.089\n",
      "Epoch:  0052 D loss:-0.718 G loss:-1.969\n",
      "Epoch:  0052 D loss:-0.6508 G loss:-1.992\n",
      "Epoch:  0052 D loss:-0.8031 G loss:-2.012\n",
      "Epoch:  0052 D loss:-0.7647 G loss:-1.927\n",
      "Epoch:  0052 D loss:-0.7203 G loss:-1.973\n",
      "Epoch:  0052 D loss:-0.644 G loss:-2.27\n",
      "Epoch:  0052 D loss:-0.6051 G loss:-2.344\n",
      "Epoch:  0052 D loss:-0.559 G loss:-2.35\n",
      "Epoch:  0052 D loss:-0.6242 G loss:-2.253\n",
      "Epoch:  0052 D loss:-0.7086 G loss:-2.279\n",
      "Epoch:  0052 D loss:-0.5874 G loss:-2.362\n",
      "Epoch:  0052 D loss:-0.6375 G loss:-2.131\n",
      "Epoch:  0052 D loss:-0.7539 G loss:-2.111\n",
      "Epoch:  0052 D loss:-0.6292 G loss:-2.262\n",
      "Epoch:  0052 D loss:-0.6462 G loss:-2.081\n",
      "Epoch:  0052 D loss:-0.662 G loss:-2.021\n",
      "Epoch:  0052 D loss:-0.759 G loss:-2.129\n",
      "Epoch:  0052 D loss:-0.6173 G loss:-2.142\n",
      "Epoch:  0052 D loss:-0.6579 G loss:-2.157\n",
      "Epoch:  0052 D loss:-0.7432 G loss:-1.944\n",
      "Epoch:  0052 D loss:-0.7753 G loss:-2.039\n",
      "Epoch:  0052 D loss:-0.7717 G loss:-2.188\n",
      "Epoch:  0052 D loss:-0.6744 G loss:-2.113\n",
      "Epoch:  0052 D loss:-0.6991 G loss:-2.028\n",
      "Epoch:  0052 D loss:-0.6858 G loss:-2.093\n",
      "Epoch:  0052 D loss:-0.6014 G loss:-2.167\n",
      "Epoch:  0052 D loss:-0.6403 G loss:-2.234\n",
      "Epoch:  0052 D loss:-0.6665 G loss:-2.259\n",
      "Epoch:  0052 D loss:-0.5777 G loss:-2.257\n",
      "Epoch:  0052 D loss:-0.6925 G loss:-1.989\n",
      "Epoch:  0052 D loss:-0.5509 G loss:-2.189\n",
      "Epoch:  0052 D loss:-0.717 G loss:-2.316\n",
      "Epoch:  0052 D loss:-0.7443 G loss:-2.345\n",
      "Epoch:  0052 D loss:-0.5559 G loss:-2.181\n",
      "Epoch:  0052 D loss:-0.6001 G loss:-2.149\n",
      "Epoch:  0052 D loss:-0.7469 G loss:-2.36\n",
      "Epoch:  0052 D loss:-0.6384 G loss:-2.068\n",
      "Epoch:  0052 D loss:-0.7061 G loss:-2.034\n",
      "Epoch:  0052 D loss:-0.539 G loss:-2.045\n",
      "Epoch:  0052 D loss:-0.8507 G loss:-1.92\n",
      "Epoch:  0052 D loss:-0.6496 G loss:-2.114\n",
      "Epoch:  0052 D loss:-0.5675 G loss:-1.998\n",
      "Epoch:  0052 D loss:-0.7024 G loss:-1.823\n",
      "Epoch:  0052 D loss:-0.5415 G loss:-2.005\n",
      "Epoch:  0052 D loss:-0.6535 G loss:-2.004\n",
      "Epoch:  0052 D loss:-0.583 G loss:-2.338\n",
      "Epoch:  0052 D loss:-0.5984 G loss:-2.281\n",
      "Epoch:  0052 D loss:-0.6284 G loss:-2.321\n",
      "Epoch:  0052 D loss:-0.4428 G loss:-2.388\n",
      "Epoch:  0052 D loss:-0.6863 G loss:-2.28\n",
      "Epoch:  0052 D loss:-0.6166 G loss:-2.221\n",
      "Epoch:  0052 D loss:-0.7466 G loss:-2.172\n",
      "Epoch:  0052 D loss:-0.6421 G loss:-2.107\n",
      "Epoch:  0052 D loss:-0.507 G loss:-2.275\n",
      "Epoch:  0052 D loss:-0.6558 G loss:-2.065\n",
      "Epoch:  0052 D loss:-0.6835 G loss:-2.104\n",
      "Epoch:  0052 D loss:-0.6986 G loss:-2.162\n",
      "Epoch:  0052 D loss:-0.5364 G loss:-2.103\n",
      "Epoch:  0052 D loss:-0.5358 G loss:-2.152\n",
      "Epoch:  0052 D loss:-0.581 G loss:-2.067\n",
      "Epoch:  0052 D loss:-0.6415 G loss:-1.955\n",
      "Epoch:  0052 D loss:-0.5827 G loss:-2.154\n",
      "Epoch:  0052 D loss:-0.5737 G loss:-2.052\n",
      "Epoch:  0052 D loss:-0.6329 G loss:-2.482\n",
      "Epoch:  0052 D loss:-0.6939 G loss:-2.194\n",
      "Epoch:  0052 D loss:-0.538 G loss:-2.345\n",
      "Epoch:  0052 D loss:-0.5833 G loss:-2.302\n",
      "Epoch:  0052 D loss:-0.5859 G loss:-2.229\n",
      "Epoch:  0052 D loss:-0.7638 G loss:-2.233\n",
      "Epoch:  0052 D loss:-0.5045 G loss:-2.285\n",
      "Epoch:  0052 D loss:-0.6582 G loss:-2.289\n",
      "Epoch:  0052 D loss:-0.6371 G loss:-2.176\n",
      "Epoch:  0052 D loss:-0.8017 G loss:-2.002\n",
      "Epoch:  0052 D loss:-0.6486 G loss:-2.126\n",
      "Epoch:  0052 D loss:-0.6188 G loss:-2.057\n",
      "Epoch:  0052 D loss:-0.6263 G loss:-2.165\n",
      "Epoch:  0052 D loss:-0.6811 G loss:-2.116\n",
      "Epoch:  0052 D loss:-0.5598 G loss:-2.14\n",
      "Epoch:  0052 D loss:-0.6114 G loss:-2.114\n",
      "Epoch:  0052 D loss:-0.614 G loss:-2.078\n",
      "Epoch:  0052 D loss:-0.5939 G loss:-2.134\n",
      "Epoch:  0052 D loss:-0.6105 G loss:-2.253\n",
      "Epoch:  0052 D loss:-0.7524 G loss:-2.031\n",
      "Epoch:  0052 D loss:-0.6724 G loss:-2.112\n",
      "Epoch:  0052 D loss:-0.6602 G loss:-1.936\n",
      "Epoch:  0052 D loss:-0.7141 G loss:-2.153\n",
      "Epoch:  0052 D loss:-0.588 G loss:-2.297\n",
      "Epoch:  0052 D loss:-0.8788 G loss:-2.0\n",
      "Epoch:  0052 D loss:-0.6296 G loss:-2.205\n",
      "Epoch:  0052 D loss:-0.5423 G loss:-2.182\n",
      "Epoch:  0052 D loss:-0.6085 G loss:-2.102\n",
      "Epoch:  0052 D loss:-0.5927 G loss:-2.297\n",
      "Epoch:  0052 D loss:-0.5949 G loss:-2.213\n",
      "Epoch:  0052 D loss:-0.6789 G loss:-2.161\n",
      "Epoch:  0052 D loss:-0.519 G loss:-2.311\n",
      "Epoch:  0052 D loss:-0.5718 G loss:-2.212\n",
      "Epoch:  0052 D loss:-0.635 G loss:-2.389\n",
      "Epoch:  0052 D loss:-0.5202 G loss:-2.269\n",
      "Epoch:  0052 D loss:-0.5991 G loss:-1.998\n",
      "Epoch:  0052 D loss:-0.6852 G loss:-2.174\n",
      "Epoch:  0052 D loss:-0.6146 G loss:-2.106\n",
      "Epoch:  0052 D loss:-0.6671 G loss:-1.952\n",
      "Epoch:  0052 D loss:-0.553 G loss:-2.1\n",
      "Epoch:  0052 D loss:-0.7133 G loss:-1.944\n",
      "Epoch:  0052 D loss:-0.6174 G loss:-1.984\n",
      "Epoch:  0052 D loss:-0.5461 G loss:-2.256\n",
      "Epoch:  0052 D loss:-0.5338 G loss:-2.265\n",
      "Epoch:  0052 D loss:-0.6548 G loss:-2.15\n",
      "Epoch:  0052 D loss:-0.5926 G loss:-2.177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0052 D loss:-0.5813 G loss:-2.374\n",
      "Epoch:  0052 D loss:-0.5306 G loss:-2.35\n",
      "Epoch:  0052 D loss:-0.5627 G loss:-2.393\n",
      "Epoch:  0052 D loss:-0.5392 G loss:-2.566\n",
      "Epoch:  0052 D loss:-0.5721 G loss:-2.3\n",
      "Epoch:  0052 D loss:-0.6052 G loss:-2.386\n",
      "Epoch:  0052 D loss:-0.703 G loss:-2.481\n",
      "Epoch:  0052 D loss:-0.543 G loss:-2.201\n",
      "Epoch:  0052 D loss:-0.6837 G loss:-2.213\n",
      "Epoch:  0052 D loss:-0.5859 G loss:-2.215\n",
      "Epoch:  0052 D loss:-0.6034 G loss:-2.229\n",
      "Epoch:  0052 D loss:-0.5843 G loss:-2.335\n",
      "Epoch:  0052 D loss:-0.6719 G loss:-1.829\n",
      "Epoch:  0052 D loss:-0.6465 G loss:-2.039\n",
      "Epoch:  0052 D loss:-0.5148 G loss:-2.317\n",
      "Epoch:  0052 D loss:-0.5826 G loss:-2.003\n",
      "Epoch:  0052 D loss:-0.6098 G loss:-2.1\n",
      "Epoch:  0052 D loss:-0.6762 G loss:-2.166\n",
      "Epoch:  0052 D loss:-0.6996 G loss:-2.018\n",
      "Epoch:  0052 D loss:-0.6961 G loss:-2.251\n",
      "Epoch:  0052 D loss:-0.6932 G loss:-2.2\n",
      "Epoch:  0052 D loss:-0.5802 G loss:-2.161\n",
      "Epoch:  0052 D loss:-0.5751 G loss:-2.423\n",
      "Epoch:  0052 D loss:-0.5498 G loss:-2.314\n",
      "Epoch:  0052 D loss:-0.5963 G loss:-2.046\n",
      "Epoch:  0052 D loss:-0.6863 G loss:-2.369\n",
      "Epoch:  0052 D loss:-0.5406 G loss:-2.119\n",
      "Epoch:  0052 D loss:-0.5806 G loss:-2.302\n",
      "Epoch:  0052 D loss:-0.5704 G loss:-2.067\n",
      "Epoch:  0052 D loss:-0.5231 G loss:-2.255\n",
      "Epoch:  0052 D loss:-0.6254 G loss:-2.488\n",
      "Epoch:  0052 D loss:-0.5795 G loss:-2.253\n",
      "Epoch:  0052 D loss:-0.7303 G loss:-2.252\n",
      "Epoch:  0052 D loss:-0.6657 G loss:-1.961\n",
      "Epoch:  0052 D loss:-0.5124 G loss:-2.282\n",
      "Epoch:  0052 D loss:-0.6642 G loss:-2.202\n",
      "Epoch:  0052 D loss:-0.6488 G loss:-2.144\n",
      "Epoch:  0052 D loss:-0.5449 G loss:-2.185\n",
      "Epoch:  0052 D loss:-0.4681 G loss:-2.374\n",
      "Epoch:  0052 D loss:-0.6313 G loss:-2.088\n",
      "Epoch:  0052 D loss:-0.756 G loss:-1.97\n",
      "Epoch:  0052 D loss:-0.6774 G loss:-2.515\n",
      "Epoch:  0052 D loss:-0.6898 G loss:-2.214\n",
      "Epoch:  0052 D loss:-0.5181 G loss:-2.377\n",
      "Epoch:  0053 D loss:-0.6285 G loss:-2.428\n",
      "Epoch:  0053 D loss:-0.577 G loss:-2.481\n",
      "Epoch:  0053 D loss:-0.4604 G loss:-2.636\n",
      "Epoch:  0053 D loss:-0.6267 G loss:-2.524\n",
      "Epoch:  0053 D loss:-0.6139 G loss:-2.488\n",
      "Epoch:  0053 D loss:-0.6707 G loss:-2.36\n",
      "Epoch:  0053 D loss:-0.4805 G loss:-2.582\n",
      "Epoch:  0053 D loss:-0.7261 G loss:-2.461\n",
      "Epoch:  0053 D loss:-0.5932 G loss:-2.256\n",
      "Epoch:  0053 D loss:-0.6323 G loss:-2.189\n",
      "Epoch:  0053 D loss:-0.6158 G loss:-1.943\n",
      "Epoch:  0053 D loss:-0.5509 G loss:-1.97\n",
      "Epoch:  0053 D loss:-0.4311 G loss:-2.367\n",
      "Epoch:  0053 D loss:-0.5846 G loss:-2.2\n",
      "Epoch:  0053 D loss:-0.5732 G loss:-2.152\n",
      "Epoch:  0053 D loss:-0.586 G loss:-2.423\n",
      "Epoch:  0053 D loss:-0.5609 G loss:-2.095\n",
      "Epoch:  0053 D loss:-0.5618 G loss:-2.501\n",
      "Epoch:  0053 D loss:-0.6419 G loss:-2.419\n",
      "Epoch:  0053 D loss:-0.6298 G loss:-2.357\n",
      "Epoch:  0053 D loss:-0.6015 G loss:-2.4\n",
      "Epoch:  0053 D loss:-0.7226 G loss:-2.589\n",
      "Epoch:  0053 D loss:-0.6896 G loss:-2.279\n",
      "Epoch:  0053 D loss:-0.5752 G loss:-2.3\n",
      "Epoch:  0053 D loss:-0.723 G loss:-2.127\n",
      "Epoch:  0053 D loss:-0.6553 G loss:-2.08\n",
      "Epoch:  0053 D loss:-0.5566 G loss:-2.159\n",
      "Epoch:  0053 D loss:-0.662 G loss:-2.127\n",
      "Epoch:  0053 D loss:-0.7223 G loss:-1.821\n",
      "Epoch:  0053 D loss:-0.6125 G loss:-2.318\n",
      "Epoch:  0053 D loss:-0.6126 G loss:-2.162\n",
      "Epoch:  0053 D loss:-0.5581 G loss:-2.046\n",
      "Epoch:  0053 D loss:-0.7962 G loss:-2.133\n",
      "Epoch:  0053 D loss:-0.8097 G loss:-1.72\n",
      "Epoch:  0053 D loss:-0.6235 G loss:-2.099\n",
      "Epoch:  0053 D loss:-0.5614 G loss:-2.316\n",
      "Epoch:  0053 D loss:-0.7374 G loss:-2.073\n",
      "Epoch:  0053 D loss:-0.5634 G loss:-2.337\n",
      "Epoch:  0053 D loss:-0.6198 G loss:-2.43\n",
      "Epoch:  0053 D loss:-0.6675 G loss:-2.587\n",
      "Epoch:  0053 D loss:-0.6003 G loss:-2.454\n",
      "Epoch:  0053 D loss:-0.6348 G loss:-2.522\n",
      "Epoch:  0053 D loss:-0.6762 G loss:-2.256\n",
      "Epoch:  0053 D loss:-0.8432 G loss:-2.313\n",
      "Epoch:  0053 D loss:-0.7986 G loss:-2.096\n",
      "Epoch:  0053 D loss:-0.728 G loss:-2.133\n",
      "Epoch:  0053 D loss:-0.7882 G loss:-2.07\n",
      "Epoch:  0053 D loss:-0.6943 G loss:-1.97\n",
      "Epoch:  0053 D loss:-0.5325 G loss:-2.096\n",
      "Epoch:  0053 D loss:-0.6138 G loss:-2.015\n",
      "Epoch:  0053 D loss:-0.6277 G loss:-2.067\n",
      "Epoch:  0053 D loss:-0.7442 G loss:-1.941\n",
      "Epoch:  0053 D loss:-0.7406 G loss:-2.11\n",
      "Epoch:  0053 D loss:-0.7272 G loss:-2.183\n",
      "Epoch:  0053 D loss:-0.6508 G loss:-2.277\n",
      "Epoch:  0053 D loss:-0.5011 G loss:-2.551\n",
      "Epoch:  0053 D loss:-0.7272 G loss:-2.482\n",
      "Epoch:  0053 D loss:-0.8276 G loss:-2.098\n",
      "Epoch:  0053 D loss:-0.8123 G loss:-2.27\n",
      "Epoch:  0053 D loss:-0.5606 G loss:-2.182\n",
      "Epoch:  0053 D loss:-0.7579 G loss:-2.095\n",
      "Epoch:  0053 D loss:-0.716 G loss:-2.118\n",
      "Epoch:  0053 D loss:-0.7555 G loss:-1.936\n",
      "Epoch:  0053 D loss:-0.7354 G loss:-2.013\n",
      "Epoch:  0053 D loss:-0.6834 G loss:-2.013\n",
      "Epoch:  0053 D loss:-0.6534 G loss:-1.961\n",
      "Epoch:  0053 D loss:-0.6954 G loss:-2.103\n",
      "Epoch:  0053 D loss:-0.6695 G loss:-2.192\n",
      "Epoch:  0053 D loss:-0.6705 G loss:-2.195\n",
      "Epoch:  0053 D loss:-0.5654 G loss:-2.298\n",
      "Epoch:  0053 D loss:-0.6622 G loss:-2.303\n",
      "Epoch:  0053 D loss:-0.6352 G loss:-2.319\n",
      "Epoch:  0053 D loss:-0.7668 G loss:-2.24\n",
      "Epoch:  0053 D loss:-0.7617 G loss:-2.145\n",
      "Epoch:  0053 D loss:-0.6053 G loss:-2.292\n",
      "Epoch:  0053 D loss:-0.7165 G loss:-2.006\n",
      "Epoch:  0053 D loss:-0.6932 G loss:-1.9\n",
      "Epoch:  0053 D loss:-0.608 G loss:-2.0\n",
      "Epoch:  0053 D loss:-0.5935 G loss:-1.953\n",
      "Epoch:  0053 D loss:-0.5744 G loss:-2.049\n",
      "Epoch:  0053 D loss:-0.6766 G loss:-2.156\n",
      "Epoch:  0053 D loss:-0.5727 G loss:-2.202\n",
      "Epoch:  0053 D loss:-0.5664 G loss:-2.269\n",
      "Epoch:  0053 D loss:-0.584 G loss:-2.273\n",
      "Epoch:  0053 D loss:-0.7186 G loss:-2.289\n",
      "Epoch:  0053 D loss:-0.6629 G loss:-2.462\n",
      "Epoch:  0053 D loss:-0.5211 G loss:-2.496\n",
      "Epoch:  0053 D loss:-0.6165 G loss:-2.467\n",
      "Epoch:  0053 D loss:-0.662 G loss:-2.361\n",
      "Epoch:  0053 D loss:-0.7729 G loss:-2.267\n",
      "Epoch:  0053 D loss:-0.5601 G loss:-2.208\n",
      "Epoch:  0053 D loss:-0.6625 G loss:-2.214\n",
      "Epoch:  0053 D loss:-0.7237 G loss:-1.957\n",
      "Epoch:  0053 D loss:-0.5045 G loss:-2.224\n",
      "Epoch:  0053 D loss:-0.6724 G loss:-2.236\n",
      "Epoch:  0053 D loss:-0.5998 G loss:-2.027\n",
      "Epoch:  0053 D loss:-0.6237 G loss:-2.02\n",
      "Epoch:  0053 D loss:-0.6794 G loss:-1.973\n",
      "Epoch:  0053 D loss:-0.5512 G loss:-2.564\n",
      "Epoch:  0053 D loss:-0.7273 G loss:-2.308\n",
      "Epoch:  0053 D loss:-0.6289 G loss:-2.514\n",
      "Epoch:  0053 D loss:-0.6615 G loss:-2.493\n",
      "Epoch:  0053 D loss:-0.6793 G loss:-2.325\n",
      "Epoch:  0053 D loss:-0.842 G loss:-2.259\n",
      "Epoch:  0053 D loss:-0.7899 G loss:-1.951\n",
      "Epoch:  0053 D loss:-0.9232 G loss:-1.893\n",
      "Epoch:  0053 D loss:-0.5923 G loss:-2.154\n",
      "Epoch:  0053 D loss:-0.5975 G loss:-1.968\n",
      "Epoch:  0053 D loss:-0.6278 G loss:-1.922\n",
      "Epoch:  0053 D loss:-0.6832 G loss:-2.184\n",
      "Epoch:  0053 D loss:-0.6768 G loss:-1.944\n",
      "Epoch:  0053 D loss:-0.6924 G loss:-2.016\n",
      "Epoch:  0053 D loss:-0.6348 G loss:-2.188\n",
      "Epoch:  0053 D loss:-0.6688 G loss:-2.056\n",
      "Epoch:  0053 D loss:-0.6847 G loss:-2.122\n",
      "Epoch:  0053 D loss:-0.7533 G loss:-2.031\n",
      "Epoch:  0053 D loss:-0.5444 G loss:-2.327\n",
      "Epoch:  0053 D loss:-0.5883 G loss:-2.279\n",
      "Epoch:  0053 D loss:-0.6645 G loss:-2.224\n",
      "Epoch:  0053 D loss:-0.6824 G loss:-2.403\n",
      "Epoch:  0053 D loss:-0.6276 G loss:-2.585\n",
      "Epoch:  0053 D loss:-0.6122 G loss:-2.357\n",
      "Epoch:  0053 D loss:-0.6546 G loss:-2.29\n",
      "Epoch:  0053 D loss:-0.7172 G loss:-2.071\n",
      "Epoch:  0053 D loss:-0.6978 G loss:-1.907\n",
      "Epoch:  0053 D loss:-0.6065 G loss:-2.138\n",
      "Epoch:  0053 D loss:-0.6881 G loss:-1.991\n",
      "Epoch:  0053 D loss:-0.6612 G loss:-1.845\n",
      "Epoch:  0053 D loss:-0.632 G loss:-1.963\n",
      "Epoch:  0053 D loss:-0.7388 G loss:-1.996\n",
      "Epoch:  0053 D loss:-0.7149 G loss:-1.878\n",
      "Epoch:  0053 D loss:-0.6354 G loss:-2.011\n",
      "Epoch:  0053 D loss:-0.5132 G loss:-2.145\n",
      "Epoch:  0053 D loss:-0.7775 G loss:-2.326\n",
      "Epoch:  0053 D loss:-0.5279 G loss:-2.342\n",
      "Epoch:  0053 D loss:-0.7388 G loss:-2.026\n",
      "Epoch:  0053 D loss:-0.6769 G loss:-2.177\n",
      "Epoch:  0053 D loss:-0.9118 G loss:-1.992\n",
      "Epoch:  0053 D loss:-0.6931 G loss:-2.102\n",
      "Epoch:  0053 D loss:-0.8369 G loss:-2.223\n",
      "Epoch:  0053 D loss:-0.6375 G loss:-1.911\n",
      "Epoch:  0053 D loss:-0.7501 G loss:-1.991\n",
      "Epoch:  0053 D loss:-0.5693 G loss:-2.354\n",
      "Epoch:  0053 D loss:-0.6805 G loss:-2.306\n",
      "Epoch:  0053 D loss:-0.7167 G loss:-2.179\n",
      "Epoch:  0053 D loss:-0.7738 G loss:-2.149\n",
      "Epoch:  0053 D loss:-0.6756 G loss:-2.368\n",
      "Epoch:  0053 D loss:-0.7636 G loss:-2.138\n",
      "Epoch:  0053 D loss:-0.8104 G loss:-2.041\n",
      "Epoch:  0053 D loss:-0.6926 G loss:-2.009\n",
      "Epoch:  0053 D loss:-0.6883 G loss:-2.061\n",
      "Epoch:  0053 D loss:-0.6535 G loss:-2.007\n",
      "Epoch:  0053 D loss:-0.629 G loss:-2.086\n",
      "Epoch:  0053 D loss:-0.6659 G loss:-1.879\n",
      "Epoch:  0053 D loss:-0.7021 G loss:-1.846\n",
      "Epoch:  0053 D loss:-0.649 G loss:-2.005\n",
      "Epoch:  0053 D loss:-0.6047 G loss:-2.1\n",
      "Epoch:  0053 D loss:-0.627 G loss:-2.226\n",
      "Epoch:  0053 D loss:-0.7197 G loss:-2.271\n",
      "Epoch:  0053 D loss:-0.6965 G loss:-2.16\n",
      "Epoch:  0053 D loss:-0.6769 G loss:-2.151\n",
      "Epoch:  0053 D loss:-0.5454 G loss:-2.513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0053 D loss:-0.6736 G loss:-2.193\n",
      "Epoch:  0053 D loss:-0.581 G loss:-2.435\n",
      "Epoch:  0053 D loss:-0.5271 G loss:-2.378\n",
      "Epoch:  0053 D loss:-0.6591 G loss:-2.327\n",
      "Epoch:  0053 D loss:-0.7891 G loss:-2.081\n",
      "Epoch:  0053 D loss:-0.6603 G loss:-2.118\n",
      "Epoch:  0053 D loss:-0.502 G loss:-2.16\n",
      "Epoch:  0053 D loss:-0.7398 G loss:-1.934\n",
      "Epoch:  0053 D loss:-0.6557 G loss:-2.297\n",
      "Epoch:  0053 D loss:-0.6718 G loss:-2.259\n",
      "Epoch:  0053 D loss:-0.5522 G loss:-2.125\n",
      "Epoch:  0053 D loss:-0.7457 G loss:-1.986\n",
      "Epoch:  0053 D loss:-0.5571 G loss:-2.148\n",
      "Epoch:  0053 D loss:-0.738 G loss:-2.198\n",
      "Epoch:  0053 D loss:-0.6059 G loss:-2.285\n",
      "Epoch:  0053 D loss:-0.6692 G loss:-2.036\n",
      "Epoch:  0053 D loss:-0.616 G loss:-2.195\n",
      "Epoch:  0053 D loss:-0.7456 G loss:-2.34\n",
      "Epoch:  0053 D loss:-0.6326 G loss:-2.186\n",
      "Epoch:  0053 D loss:-0.5428 G loss:-2.273\n",
      "Epoch:  0053 D loss:-0.5451 G loss:-2.194\n",
      "Epoch:  0053 D loss:-0.564 G loss:-2.311\n",
      "Epoch:  0053 D loss:-0.4821 G loss:-2.247\n",
      "Epoch:  0053 D loss:-0.5585 G loss:-2.234\n",
      "Epoch:  0053 D loss:-0.576 G loss:-2.36\n",
      "Epoch:  0053 D loss:-0.5831 G loss:-2.34\n",
      "Epoch:  0053 D loss:-0.6092 G loss:-2.362\n",
      "Epoch:  0053 D loss:-0.4573 G loss:-2.433\n",
      "Epoch:  0053 D loss:-0.6672 G loss:-2.173\n",
      "Epoch:  0053 D loss:-0.6278 G loss:-2.197\n",
      "Epoch:  0053 D loss:-0.5506 G loss:-2.247\n",
      "Epoch:  0053 D loss:-0.6831 G loss:-2.263\n",
      "Epoch:  0053 D loss:-0.5304 G loss:-2.335\n",
      "Epoch:  0053 D loss:-0.6633 G loss:-2.127\n",
      "Epoch:  0053 D loss:-0.5898 G loss:-2.213\n",
      "Epoch:  0053 D loss:-0.6111 G loss:-2.239\n",
      "Epoch:  0053 D loss:-0.5744 G loss:-2.013\n",
      "Epoch:  0053 D loss:-0.5804 G loss:-2.167\n",
      "Epoch:  0053 D loss:-0.5706 G loss:-2.222\n",
      "Epoch:  0053 D loss:-0.3998 G loss:-2.659\n",
      "Epoch:  0053 D loss:-0.5316 G loss:-2.554\n",
      "Epoch:  0053 D loss:-0.6406 G loss:-2.381\n",
      "Epoch:  0053 D loss:-0.4327 G loss:-2.548\n",
      "Epoch:  0053 D loss:-0.6544 G loss:-2.478\n",
      "Epoch:  0053 D loss:-0.465 G loss:-2.615\n",
      "Epoch:  0053 D loss:-0.6321 G loss:-2.156\n",
      "Epoch:  0053 D loss:-0.5446 G loss:-2.265\n",
      "Epoch:  0053 D loss:-0.6403 G loss:-2.266\n",
      "Epoch:  0053 D loss:-0.5648 G loss:-2.383\n",
      "Epoch:  0053 D loss:-0.5829 G loss:-2.159\n",
      "Epoch:  0053 D loss:-0.5227 G loss:-2.129\n",
      "Epoch:  0053 D loss:-0.5484 G loss:-2.021\n",
      "Epoch:  0053 D loss:-0.581 G loss:-2.206\n",
      "Epoch:  0053 D loss:-0.6437 G loss:-2.142\n",
      "Epoch:  0053 D loss:-0.6589 G loss:-2.14\n",
      "Epoch:  0053 D loss:-0.5501 G loss:-2.543\n",
      "Epoch:  0053 D loss:-0.5134 G loss:-2.602\n",
      "Epoch:  0053 D loss:-0.4226 G loss:-2.358\n",
      "Epoch:  0053 D loss:-0.583 G loss:-2.297\n",
      "Epoch:  0053 D loss:-0.6183 G loss:-2.366\n",
      "Epoch:  0053 D loss:-0.4878 G loss:-2.278\n",
      "Epoch:  0053 D loss:-0.5823 G loss:-2.363\n",
      "Epoch:  0053 D loss:-0.5489 G loss:-2.493\n",
      "Epoch:  0053 D loss:-0.6344 G loss:-2.373\n",
      "Epoch:  0053 D loss:-0.5488 G loss:-2.349\n",
      "Epoch:  0053 D loss:-0.463 G loss:-2.349\n",
      "Epoch:  0053 D loss:-0.6477 G loss:-2.271\n",
      "Epoch:  0053 D loss:-0.4759 G loss:-2.638\n",
      "Epoch:  0053 D loss:-0.4764 G loss:-2.326\n",
      "Epoch:  0053 D loss:-0.5568 G loss:-2.258\n",
      "Epoch:  0053 D loss:-0.6193 G loss:-2.344\n",
      "Epoch:  0053 D loss:-0.481 G loss:-2.599\n",
      "Epoch:  0053 D loss:-0.5024 G loss:-2.143\n",
      "Epoch:  0053 D loss:-0.7282 G loss:-2.024\n",
      "Epoch:  0053 D loss:-0.6362 G loss:-2.363\n",
      "Epoch:  0053 D loss:-0.5511 G loss:-2.42\n",
      "Epoch:  0053 D loss:-0.5764 G loss:-2.266\n",
      "Epoch:  0053 D loss:-0.5929 G loss:-2.274\n",
      "Epoch:  0053 D loss:-0.6283 G loss:-2.353\n",
      "Epoch:  0053 D loss:-0.488 G loss:-2.348\n",
      "Epoch:  0053 D loss:-0.5414 G loss:-2.332\n",
      "Epoch:  0053 D loss:-0.5111 G loss:-2.208\n",
      "Epoch:  0053 D loss:-0.6184 G loss:-2.312\n",
      "Epoch:  0053 D loss:-0.564 G loss:-2.049\n",
      "Epoch:  0053 D loss:-0.5377 G loss:-2.096\n",
      "Epoch:  0053 D loss:-0.6749 G loss:-1.975\n",
      "Epoch:  0053 D loss:-0.5748 G loss:-2.004\n",
      "Epoch:  0053 D loss:-0.6996 G loss:-2.036\n",
      "Epoch:  0053 D loss:-0.4577 G loss:-2.049\n",
      "Epoch:  0053 D loss:-0.553 G loss:-2.045\n",
      "Epoch:  0053 D loss:-0.6289 G loss:-1.988\n",
      "Epoch:  0053 D loss:-0.8009 G loss:-2.169\n",
      "Epoch:  0053 D loss:-0.551 G loss:-2.142\n",
      "Epoch:  0053 D loss:-0.6136 G loss:-2.19\n",
      "Epoch:  0053 D loss:-0.6354 G loss:-2.366\n",
      "Epoch:  0053 D loss:-0.5906 G loss:-2.397\n",
      "Epoch:  0053 D loss:-0.571 G loss:-2.293\n",
      "Epoch:  0053 D loss:-0.7019 G loss:-2.286\n",
      "Epoch:  0053 D loss:-0.6286 G loss:-2.275\n",
      "Epoch:  0053 D loss:-0.5175 G loss:-2.19\n",
      "Epoch:  0053 D loss:-0.55 G loss:-2.032\n",
      "Epoch:  0053 D loss:-0.6344 G loss:-2.211\n",
      "Epoch:  0053 D loss:-0.6846 G loss:-2.065\n",
      "Epoch:  0053 D loss:-0.5178 G loss:-2.184\n",
      "Epoch:  0053 D loss:-0.6258 G loss:-2.147\n",
      "Epoch:  0053 D loss:-0.5597 G loss:-2.181\n",
      "Epoch:  0053 D loss:-0.6356 G loss:-2.117\n",
      "Epoch:  0053 D loss:-0.4736 G loss:-2.202\n",
      "Epoch:  0053 D loss:-0.6979 G loss:-2.193\n",
      "Epoch:  0053 D loss:-0.7433 G loss:-2.152\n",
      "Epoch:  0053 D loss:-0.705 G loss:-2.025\n",
      "Epoch:  0053 D loss:-0.6802 G loss:-1.994\n",
      "Epoch:  0053 D loss:-0.5699 G loss:-2.218\n",
      "Epoch:  0053 D loss:-0.6807 G loss:-2.176\n",
      "Epoch:  0053 D loss:-0.6043 G loss:-2.272\n",
      "Epoch:  0053 D loss:-0.5269 G loss:-2.204\n",
      "Epoch:  0053 D loss:-0.7797 G loss:-2.234\n",
      "Epoch:  0053 D loss:-0.6798 G loss:-2.248\n",
      "Epoch:  0053 D loss:-0.7311 G loss:-2.124\n",
      "Epoch:  0053 D loss:-0.6275 G loss:-2.244\n",
      "Epoch:  0053 D loss:-0.8335 G loss:-2.194\n",
      "Epoch:  0053 D loss:-0.7996 G loss:-2.053\n",
      "Epoch:  0053 D loss:-0.6337 G loss:-2.12\n",
      "Epoch:  0053 D loss:-0.701 G loss:-2.055\n",
      "Epoch:  0053 D loss:-0.6945 G loss:-1.83\n",
      "Epoch:  0053 D loss:-0.6721 G loss:-1.907\n",
      "Epoch:  0053 D loss:-0.5897 G loss:-2.037\n",
      "Epoch:  0053 D loss:-0.8155 G loss:-1.961\n",
      "Epoch:  0053 D loss:-0.7045 G loss:-1.852\n",
      "Epoch:  0053 D loss:-0.7778 G loss:-1.969\n",
      "Epoch:  0053 D loss:-0.6489 G loss:-2.293\n",
      "Epoch:  0053 D loss:-0.5802 G loss:-2.254\n",
      "Epoch:  0053 D loss:-0.7616 G loss:-2.16\n",
      "Epoch:  0053 D loss:-0.6471 G loss:-2.311\n",
      "Epoch:  0053 D loss:-0.676 G loss:-2.311\n",
      "Epoch:  0053 D loss:-0.5639 G loss:-2.287\n",
      "Epoch:  0053 D loss:-0.6809 G loss:-2.221\n",
      "Epoch:  0053 D loss:-0.7055 G loss:-2.048\n",
      "Epoch:  0053 D loss:-0.6573 G loss:-2.344\n",
      "Epoch:  0053 D loss:-0.7554 G loss:-2.197\n",
      "Epoch:  0053 D loss:-0.7784 G loss:-2.168\n",
      "Epoch:  0053 D loss:-0.7307 G loss:-1.968\n",
      "Epoch:  0053 D loss:-0.6027 G loss:-2.134\n",
      "Epoch:  0053 D loss:-0.6841 G loss:-2.01\n",
      "Epoch:  0053 D loss:-0.7909 G loss:-1.967\n",
      "Epoch:  0053 D loss:-0.6259 G loss:-2.064\n",
      "Epoch:  0053 D loss:-0.6752 G loss:-2.04\n",
      "Epoch:  0053 D loss:-0.7398 G loss:-2.062\n",
      "Epoch:  0053 D loss:-0.7204 G loss:-1.992\n",
      "Epoch:  0053 D loss:-0.6606 G loss:-2.327\n",
      "Epoch:  0053 D loss:-0.5933 G loss:-2.41\n",
      "Epoch:  0053 D loss:-0.5962 G loss:-2.308\n",
      "Epoch:  0053 D loss:-0.6212 G loss:-2.222\n",
      "Epoch:  0053 D loss:-0.5795 G loss:-2.266\n",
      "Epoch:  0053 D loss:-0.6969 G loss:-2.169\n",
      "Epoch:  0053 D loss:-0.6686 G loss:-2.188\n",
      "Epoch:  0053 D loss:-0.6041 G loss:-2.344\n",
      "Epoch:  0053 D loss:-0.5759 G loss:-2.161\n",
      "Epoch:  0053 D loss:-0.6041 G loss:-2.385\n",
      "Epoch:  0053 D loss:-0.7096 G loss:-2.282\n",
      "Epoch:  0053 D loss:-0.7074 G loss:-2.247\n",
      "Epoch:  0053 D loss:-0.6852 G loss:-2.286\n",
      "Epoch:  0053 D loss:-0.6172 G loss:-2.299\n",
      "Epoch:  0053 D loss:-0.6649 G loss:-1.974\n",
      "Epoch:  0053 D loss:-0.7326 G loss:-2.05\n",
      "Epoch:  0053 D loss:-0.6187 G loss:-1.979\n",
      "Epoch:  0053 D loss:-0.6475 G loss:-1.906\n",
      "Epoch:  0053 D loss:-0.6825 G loss:-1.85\n",
      "Epoch:  0053 D loss:-0.6392 G loss:-2.043\n",
      "Epoch:  0053 D loss:-0.8118 G loss:-1.898\n",
      "Epoch:  0053 D loss:-0.7482 G loss:-1.981\n",
      "Epoch:  0053 D loss:-0.7679 G loss:-2.009\n",
      "Epoch:  0053 D loss:-0.6501 G loss:-2.133\n",
      "Epoch:  0053 D loss:-0.753 G loss:-2.44\n",
      "Epoch:  0053 D loss:-0.6714 G loss:-2.127\n",
      "Epoch:  0053 D loss:-0.6782 G loss:-2.276\n",
      "Epoch:  0053 D loss:-0.7822 G loss:-2.169\n",
      "Epoch:  0053 D loss:-0.6304 G loss:-2.353\n",
      "Epoch:  0053 D loss:-0.7413 G loss:-2.132\n",
      "Epoch:  0053 D loss:-0.7095 G loss:-2.063\n",
      "Epoch:  0053 D loss:-0.6086 G loss:-2.044\n",
      "Epoch:  0053 D loss:-0.582 G loss:-2.238\n",
      "Epoch:  0053 D loss:-0.6191 G loss:-1.905\n",
      "Epoch:  0053 D loss:-0.6093 G loss:-2.121\n",
      "Epoch:  0053 D loss:-0.6593 G loss:-2.095\n",
      "Epoch:  0053 D loss:-0.6526 G loss:-2.139\n",
      "Epoch:  0053 D loss:-0.5309 G loss:-2.325\n",
      "Epoch:  0053 D loss:-0.5933 G loss:-2.147\n",
      "Epoch:  0053 D loss:-0.6885 G loss:-2.177\n",
      "Epoch:  0053 D loss:-0.6537 G loss:-2.227\n",
      "Epoch:  0053 D loss:-0.6041 G loss:-2.208\n",
      "Epoch:  0053 D loss:-0.4897 G loss:-2.441\n",
      "Epoch:  0053 D loss:-0.7066 G loss:-2.703\n",
      "Epoch:  0053 D loss:-0.6527 G loss:-2.365\n",
      "Epoch:  0053 D loss:-0.5527 G loss:-2.432\n",
      "Epoch:  0053 D loss:-0.6338 G loss:-2.267\n",
      "Epoch:  0053 D loss:-0.6432 G loss:-2.283\n",
      "Epoch:  0053 D loss:-0.6981 G loss:-2.149\n",
      "Epoch:  0053 D loss:-0.667 G loss:-2.203\n",
      "Epoch:  0053 D loss:-0.7433 G loss:-1.944\n",
      "Epoch:  0053 D loss:-0.6608 G loss:-2.016\n",
      "Epoch:  0053 D loss:-0.6212 G loss:-1.984\n",
      "Epoch:  0053 D loss:-0.6786 G loss:-1.941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0053 D loss:-0.7272 G loss:-1.923\n",
      "Epoch:  0053 D loss:-0.6568 G loss:-2.029\n",
      "Epoch:  0053 D loss:-0.5916 G loss:-2.197\n",
      "Epoch:  0053 D loss:-0.5789 G loss:-2.264\n",
      "Epoch:  0053 D loss:-0.6337 G loss:-2.207\n",
      "Epoch:  0053 D loss:-0.7751 G loss:-2.337\n",
      "Epoch:  0053 D loss:-0.5329 G loss:-2.468\n",
      "Epoch:  0053 D loss:-0.643 G loss:-2.337\n",
      "Epoch:  0053 D loss:-0.57 G loss:-2.476\n",
      "Epoch:  0053 D loss:-0.701 G loss:-2.194\n",
      "Epoch:  0053 D loss:-0.5128 G loss:-2.324\n",
      "Epoch:  0053 D loss:-0.5316 G loss:-2.121\n",
      "Epoch:  0053 D loss:-0.6454 G loss:-2.06\n",
      "Epoch:  0053 D loss:-0.6375 G loss:-2.218\n",
      "Epoch:  0053 D loss:-0.5282 G loss:-2.234\n",
      "Epoch:  0053 D loss:-0.5073 G loss:-2.313\n",
      "Epoch:  0053 D loss:-0.6488 G loss:-2.264\n",
      "Epoch:  0053 D loss:-0.5906 G loss:-2.357\n",
      "Epoch:  0053 D loss:-0.5906 G loss:-2.285\n",
      "Epoch:  0053 D loss:-0.5861 G loss:-2.193\n",
      "Epoch:  0053 D loss:-0.6144 G loss:-2.202\n",
      "Epoch:  0053 D loss:-0.4833 G loss:-2.328\n",
      "Epoch:  0053 D loss:-0.7135 G loss:-2.218\n",
      "Epoch:  0053 D loss:-0.5538 G loss:-2.631\n",
      "Epoch:  0053 D loss:-0.6323 G loss:-2.422\n",
      "Epoch:  0053 D loss:-0.6324 G loss:-2.443\n",
      "Epoch:  0053 D loss:-0.6055 G loss:-2.313\n",
      "Epoch:  0053 D loss:-0.7411 G loss:-2.157\n",
      "Epoch:  0053 D loss:-0.6217 G loss:-2.115\n",
      "Epoch:  0053 D loss:-0.7059 G loss:-1.947\n",
      "Epoch:  0053 D loss:-0.7663 G loss:-1.91\n",
      "Epoch:  0053 D loss:-0.651 G loss:-2.195\n",
      "Epoch:  0053 D loss:-0.6022 G loss:-2.03\n",
      "Epoch:  0053 D loss:-0.6935 G loss:-2.017\n",
      "Epoch:  0053 D loss:-0.6346 G loss:-2.238\n",
      "Epoch:  0053 D loss:-0.5614 G loss:-2.363\n",
      "Epoch:  0053 D loss:-0.6391 G loss:-2.027\n",
      "Epoch:  0053 D loss:-0.636 G loss:-1.966\n",
      "Epoch:  0053 D loss:-0.7487 G loss:-2.392\n",
      "Epoch:  0053 D loss:-0.7281 G loss:-2.247\n",
      "Epoch:  0053 D loss:-0.5675 G loss:-2.367\n",
      "Epoch:  0053 D loss:-0.5573 G loss:-2.31\n",
      "Epoch:  0053 D loss:-0.839 G loss:-2.442\n",
      "Epoch:  0053 D loss:-0.7562 G loss:-2.096\n",
      "Epoch:  0053 D loss:-0.5752 G loss:-2.128\n",
      "Epoch:  0053 D loss:-0.7141 G loss:-2.122\n",
      "Epoch:  0053 D loss:-0.6977 G loss:-1.954\n",
      "Epoch:  0053 D loss:-0.6308 G loss:-2.265\n",
      "Epoch:  0053 D loss:-0.6538 G loss:-1.928\n",
      "Epoch:  0053 D loss:-0.7573 G loss:-1.927\n",
      "Epoch:  0053 D loss:-0.5739 G loss:-2.126\n",
      "Epoch:  0053 D loss:-0.488 G loss:-2.259\n",
      "Epoch:  0053 D loss:-0.6525 G loss:-1.938\n",
      "Epoch:  0053 D loss:-0.5789 G loss:-2.139\n",
      "Epoch:  0053 D loss:-0.4849 G loss:-2.242\n",
      "Epoch:  0053 D loss:-0.6265 G loss:-2.351\n",
      "Epoch:  0053 D loss:-0.6235 G loss:-2.294\n",
      "Epoch:  0053 D loss:-0.7475 G loss:-2.297\n",
      "Epoch:  0053 D loss:-0.6476 G loss:-2.319\n",
      "Epoch:  0053 D loss:-0.5032 G loss:-2.438\n",
      "Epoch:  0053 D loss:-0.5767 G loss:-2.181\n",
      "Epoch:  0053 D loss:-0.5645 G loss:-2.131\n",
      "Epoch:  0053 D loss:-0.5968 G loss:-2.262\n",
      "Epoch:  0053 D loss:-0.6322 G loss:-1.974\n",
      "Epoch:  0053 D loss:-0.5544 G loss:-2.353\n",
      "Epoch:  0053 D loss:-0.723 G loss:-2.142\n",
      "Epoch:  0053 D loss:-0.8094 G loss:-2.112\n",
      "Epoch:  0053 D loss:-0.7148 G loss:-2.149\n",
      "Epoch:  0053 D loss:-0.5821 G loss:-1.963\n",
      "Epoch:  0053 D loss:-0.5891 G loss:-2.116\n",
      "Epoch:  0053 D loss:-0.7145 G loss:-1.979\n",
      "Epoch:  0053 D loss:-0.7632 G loss:-1.894\n",
      "Epoch:  0053 D loss:-0.6097 G loss:-2.009\n",
      "Epoch:  0053 D loss:-0.7045 G loss:-1.995\n",
      "Epoch:  0053 D loss:-0.7185 G loss:-2.216\n",
      "Epoch:  0053 D loss:-0.6809 G loss:-2.258\n",
      "Epoch:  0053 D loss:-0.6218 G loss:-2.396\n",
      "Epoch:  0053 D loss:-0.5682 G loss:-2.285\n",
      "Epoch:  0053 D loss:-0.6019 G loss:-2.268\n",
      "Epoch:  0053 D loss:-0.6273 G loss:-2.0\n",
      "Epoch:  0053 D loss:-0.6942 G loss:-2.181\n",
      "Epoch:  0053 D loss:-0.6456 G loss:-2.214\n",
      "Epoch:  0053 D loss:-0.7203 G loss:-1.781\n",
      "Epoch:  0053 D loss:-0.698 G loss:-2.179\n",
      "Epoch:  0053 D loss:-0.6021 G loss:-2.032\n",
      "Epoch:  0053 D loss:-0.6294 G loss:-1.862\n",
      "Epoch:  0053 D loss:-0.654 G loss:-2.152\n",
      "Epoch:  0053 D loss:-0.7045 G loss:-2.044\n",
      "Epoch:  0053 D loss:-0.7469 G loss:-2.097\n",
      "Epoch:  0053 D loss:-0.5767 G loss:-2.248\n",
      "Epoch:  0053 D loss:-0.5857 G loss:-2.404\n",
      "Epoch:  0053 D loss:-0.6036 G loss:-2.131\n",
      "Epoch:  0053 D loss:-0.5928 G loss:-2.318\n",
      "Epoch:  0053 D loss:-0.6277 G loss:-2.309\n",
      "Epoch:  0053 D loss:-0.5039 G loss:-2.462\n",
      "Epoch:  0053 D loss:-0.6893 G loss:-2.264\n",
      "Epoch:  0053 D loss:-0.7464 G loss:-2.288\n",
      "Epoch:  0053 D loss:-0.639 G loss:-2.176\n",
      "Epoch:  0053 D loss:-0.7743 G loss:-1.847\n",
      "Epoch:  0053 D loss:-0.8031 G loss:-1.985\n",
      "Epoch:  0053 D loss:-0.618 G loss:-2.016\n",
      "Epoch:  0053 D loss:-0.6623 G loss:-2.007\n",
      "Epoch:  0053 D loss:-0.7039 G loss:-2.081\n",
      "Epoch:  0053 D loss:-0.6984 G loss:-2.277\n",
      "Epoch:  0053 D loss:-0.6183 G loss:-2.041\n",
      "Epoch:  0053 D loss:-0.6936 G loss:-2.001\n",
      "Epoch:  0053 D loss:-0.7171 G loss:-1.856\n",
      "Epoch:  0053 D loss:-0.7127 G loss:-2.083\n",
      "Epoch:  0053 D loss:-0.7575 G loss:-2.222\n",
      "Epoch:  0053 D loss:-0.6749 G loss:-2.078\n",
      "Epoch:  0053 D loss:-0.6779 G loss:-2.4\n",
      "Epoch:  0053 D loss:-0.7074 G loss:-2.204\n",
      "Epoch:  0053 D loss:-0.6438 G loss:-2.29\n",
      "Epoch:  0053 D loss:-0.6775 G loss:-2.241\n",
      "Epoch:  0053 D loss:-0.6435 G loss:-2.202\n",
      "Epoch:  0053 D loss:-0.514 G loss:-2.29\n",
      "Epoch:  0053 D loss:-0.7711 G loss:-2.277\n",
      "Epoch:  0053 D loss:-0.6936 G loss:-2.312\n",
      "Epoch:  0053 D loss:-0.6464 G loss:-2.265\n",
      "Epoch:  0053 D loss:-0.53 G loss:-2.255\n",
      "Epoch:  0053 D loss:-0.5592 G loss:-2.066\n",
      "Epoch:  0053 D loss:-0.6318 G loss:-2.06\n",
      "Epoch:  0053 D loss:-0.6615 G loss:-2.214\n",
      "Epoch:  0053 D loss:-0.6967 G loss:-1.761\n",
      "Epoch:  0053 D loss:-0.6439 G loss:-1.976\n",
      "Epoch:  0053 D loss:-0.6692 G loss:-2.093\n",
      "Epoch:  0053 D loss:-0.613 G loss:-2.175\n",
      "Epoch:  0053 D loss:-0.7178 G loss:-2.114\n",
      "Epoch:  0053 D loss:-0.5196 G loss:-2.154\n",
      "Epoch:  0053 D loss:-0.734 G loss:-2.324\n",
      "Epoch:  0053 D loss:-0.6104 G loss:-2.38\n",
      "Epoch:  0053 D loss:-0.6437 G loss:-2.385\n",
      "Epoch:  0053 D loss:-0.7637 G loss:-2.348\n",
      "Epoch:  0053 D loss:-0.5896 G loss:-2.311\n",
      "Epoch:  0053 D loss:-0.6381 G loss:-2.138\n",
      "Epoch:  0053 D loss:-0.4703 G loss:-2.317\n",
      "Epoch:  0053 D loss:-0.64 G loss:-2.129\n",
      "Epoch:  0053 D loss:-0.5976 G loss:-2.293\n",
      "Epoch:  0053 D loss:-0.585 G loss:-2.212\n",
      "Epoch:  0053 D loss:-0.5853 G loss:-2.224\n",
      "Epoch:  0053 D loss:-0.4784 G loss:-2.373\n",
      "Epoch:  0053 D loss:-0.6114 G loss:-2.073\n",
      "Epoch:  0053 D loss:-0.4828 G loss:-2.303\n",
      "Epoch:  0053 D loss:-0.627 G loss:-2.441\n",
      "Epoch:  0053 D loss:-0.5751 G loss:-2.157\n",
      "Epoch:  0053 D loss:-0.5006 G loss:-2.32\n",
      "Epoch:  0053 D loss:-0.6202 G loss:-2.044\n",
      "Epoch:  0053 D loss:-0.6281 G loss:-2.331\n",
      "Epoch:  0053 D loss:-0.565 G loss:-2.494\n",
      "Epoch:  0053 D loss:-0.5954 G loss:-2.428\n",
      "Epoch:  0053 D loss:-0.5231 G loss:-2.354\n",
      "Epoch:  0053 D loss:-0.5912 G loss:-2.551\n",
      "Epoch:  0053 D loss:-0.7912 G loss:-2.346\n",
      "Epoch:  0053 D loss:-0.5246 G loss:-2.237\n",
      "Epoch:  0053 D loss:-0.5449 G loss:-2.312\n",
      "Epoch:  0053 D loss:-0.7302 G loss:-2.023\n",
      "Epoch:  0053 D loss:-0.5813 G loss:-1.993\n",
      "Epoch:  0053 D loss:-0.5817 G loss:-2.1\n",
      "Epoch:  0053 D loss:-0.5622 G loss:-2.351\n",
      "Epoch:  0053 D loss:-0.6924 G loss:-2.052\n",
      "Epoch:  0053 D loss:-0.6546 G loss:-2.356\n",
      "Epoch:  0053 D loss:-0.6006 G loss:-2.269\n",
      "Epoch:  0053 D loss:-0.6913 G loss:-2.505\n",
      "Epoch:  0053 D loss:-0.7074 G loss:-2.209\n",
      "Epoch:  0053 D loss:-0.5831 G loss:-2.132\n",
      "Epoch:  0053 D loss:-0.5965 G loss:-2.307\n",
      "Epoch:  0053 D loss:-0.5967 G loss:-2.318\n",
      "Epoch:  0053 D loss:-0.5828 G loss:-2.229\n",
      "Epoch:  0053 D loss:-0.6072 G loss:-2.276\n",
      "Epoch:  0053 D loss:-0.7055 G loss:-2.09\n",
      "Epoch:  0053 D loss:-0.5876 G loss:-2.378\n",
      "Epoch:  0053 D loss:-0.5769 G loss:-2.18\n",
      "Epoch:  0053 D loss:-0.6333 G loss:-2.276\n",
      "Epoch:  0053 D loss:-0.5697 G loss:-2.038\n",
      "Epoch:  0053 D loss:-0.6431 G loss:-2.235\n",
      "Epoch:  0053 D loss:-0.6593 G loss:-2.23\n",
      "Epoch:  0053 D loss:-0.6099 G loss:-2.071\n",
      "Epoch:  0053 D loss:-0.64 G loss:-2.402\n",
      "Epoch:  0053 D loss:-0.6211 G loss:-2.266\n",
      "Epoch:  0053 D loss:-0.5719 G loss:-2.047\n",
      "Epoch:  0053 D loss:-0.5378 G loss:-2.201\n",
      "Epoch:  0053 D loss:-0.6392 G loss:-2.196\n",
      "Epoch:  0053 D loss:-0.4931 G loss:-2.226\n",
      "Epoch:  0053 D loss:-0.6043 G loss:-2.548\n",
      "Epoch:  0053 D loss:-0.5055 G loss:-2.472\n",
      "Epoch:  0054 D loss:-0.5975 G loss:-2.402\n",
      "Epoch:  0054 D loss:-0.6816 G loss:-2.186\n",
      "Epoch:  0054 D loss:-0.6325 G loss:-2.192\n",
      "Epoch:  0054 D loss:-0.7966 G loss:-1.986\n",
      "Epoch:  0054 D loss:-0.5036 G loss:-2.307\n",
      "Epoch:  0054 D loss:-0.5795 G loss:-2.237\n",
      "Epoch:  0054 D loss:-0.6829 G loss:-2.305\n",
      "Epoch:  0054 D loss:-0.5967 G loss:-2.205\n",
      "Epoch:  0054 D loss:-0.8007 G loss:-2.058\n",
      "Epoch:  0054 D loss:-0.6123 G loss:-2.274\n",
      "Epoch:  0054 D loss:-0.6138 G loss:-2.271\n",
      "Epoch:  0054 D loss:-0.5995 G loss:-2.173\n",
      "Epoch:  0054 D loss:-0.6613 G loss:-2.212\n",
      "Epoch:  0054 D loss:-0.6651 G loss:-2.041\n",
      "Epoch:  0054 D loss:-0.8168 G loss:-1.84\n",
      "Epoch:  0054 D loss:-0.5019 G loss:-2.159\n",
      "Epoch:  0054 D loss:-0.7575 G loss:-1.938\n",
      "Epoch:  0054 D loss:-0.532 G loss:-2.37\n",
      "Epoch:  0054 D loss:-0.619 G loss:-2.279\n",
      "Epoch:  0054 D loss:-0.6222 G loss:-2.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0054 D loss:-0.5272 G loss:-2.172\n",
      "Epoch:  0054 D loss:-0.6098 G loss:-2.354\n",
      "Epoch:  0054 D loss:-0.5768 G loss:-2.204\n",
      "Epoch:  0054 D loss:-0.5438 G loss:-2.22\n",
      "Epoch:  0054 D loss:-0.6325 G loss:-2.273\n",
      "Epoch:  0054 D loss:-0.7073 G loss:-2.127\n",
      "Epoch:  0054 D loss:-0.6577 G loss:-2.361\n",
      "Epoch:  0054 D loss:-0.6742 G loss:-2.065\n",
      "Epoch:  0054 D loss:-0.6807 G loss:-2.23\n",
      "Epoch:  0054 D loss:-0.559 G loss:-2.29\n",
      "Epoch:  0054 D loss:-0.6799 G loss:-1.959\n",
      "Epoch:  0054 D loss:-0.6654 G loss:-2.352\n",
      "Epoch:  0054 D loss:-0.4886 G loss:-2.149\n",
      "Epoch:  0054 D loss:-0.6497 G loss:-2.221\n",
      "Epoch:  0054 D loss:-0.5756 G loss:-2.276\n",
      "Epoch:  0054 D loss:-0.7006 G loss:-1.93\n",
      "Epoch:  0054 D loss:-0.6886 G loss:-2.021\n",
      "Epoch:  0054 D loss:-0.6179 G loss:-2.01\n",
      "Epoch:  0054 D loss:-0.8871 G loss:-1.951\n",
      "Epoch:  0054 D loss:-0.5967 G loss:-2.115\n",
      "Epoch:  0054 D loss:-0.4813 G loss:-2.147\n",
      "Epoch:  0054 D loss:-0.7199 G loss:-2.242\n",
      "Epoch:  0054 D loss:-0.6861 G loss:-2.449\n",
      "Epoch:  0054 D loss:-0.5933 G loss:-2.081\n",
      "Epoch:  0054 D loss:-0.6256 G loss:-2.163\n",
      "Epoch:  0054 D loss:-0.7246 G loss:-2.239\n",
      "Epoch:  0054 D loss:-0.6081 G loss:-2.099\n",
      "Epoch:  0054 D loss:-0.6295 G loss:-2.129\n",
      "Epoch:  0054 D loss:-0.635 G loss:-2.007\n",
      "Epoch:  0054 D loss:-0.6173 G loss:-2.216\n",
      "Epoch:  0054 D loss:-0.6836 G loss:-2.001\n",
      "Epoch:  0054 D loss:-0.6969 G loss:-2.071\n",
      "Epoch:  0054 D loss:-0.7018 G loss:-2.093\n",
      "Epoch:  0054 D loss:-0.7446 G loss:-1.828\n",
      "Epoch:  0054 D loss:-0.6629 G loss:-2.079\n",
      "Epoch:  0054 D loss:-0.6433 G loss:-2.316\n",
      "Epoch:  0054 D loss:-0.587 G loss:-2.095\n",
      "Epoch:  0054 D loss:-0.5815 G loss:-2.275\n",
      "Epoch:  0054 D loss:-0.4099 G loss:-2.51\n",
      "Epoch:  0054 D loss:-0.688 G loss:-2.162\n",
      "Epoch:  0054 D loss:-0.8848 G loss:-2.061\n",
      "Epoch:  0054 D loss:-0.7096 G loss:-2.379\n",
      "Epoch:  0054 D loss:-0.5864 G loss:-2.217\n",
      "Epoch:  0054 D loss:-0.7363 G loss:-2.177\n",
      "Epoch:  0054 D loss:-0.5602 G loss:-2.196\n",
      "Epoch:  0054 D loss:-0.6656 G loss:-2.058\n",
      "Epoch:  0054 D loss:-0.6693 G loss:-1.93\n",
      "Epoch:  0054 D loss:-0.7726 G loss:-1.956\n",
      "Epoch:  0054 D loss:-0.5166 G loss:-2.127\n",
      "Epoch:  0054 D loss:-0.6439 G loss:-1.941\n",
      "Epoch:  0054 D loss:-0.7165 G loss:-2.005\n",
      "Epoch:  0054 D loss:-0.5852 G loss:-2.153\n",
      "Epoch:  0054 D loss:-0.6807 G loss:-1.988\n",
      "Epoch:  0054 D loss:-0.7584 G loss:-2.114\n",
      "Epoch:  0054 D loss:-0.544 G loss:-2.132\n",
      "Epoch:  0054 D loss:-0.5961 G loss:-2.13\n",
      "Epoch:  0054 D loss:-0.6365 G loss:-2.177\n",
      "Epoch:  0054 D loss:-0.7471 G loss:-2.167\n",
      "Epoch:  0054 D loss:-0.684 G loss:-2.397\n",
      "Epoch:  0054 D loss:-0.6332 G loss:-2.186\n",
      "Epoch:  0054 D loss:-0.666 G loss:-1.979\n",
      "Epoch:  0054 D loss:-0.6206 G loss:-2.086\n",
      "Epoch:  0054 D loss:-0.7327 G loss:-2.205\n",
      "Epoch:  0054 D loss:-0.4599 G loss:-2.3\n",
      "Epoch:  0054 D loss:-0.6248 G loss:-2.147\n",
      "Epoch:  0054 D loss:-0.712 G loss:-1.781\n",
      "Epoch:  0054 D loss:-0.6043 G loss:-2.221\n",
      "Epoch:  0054 D loss:-0.8146 G loss:-2.039\n",
      "Epoch:  0054 D loss:-0.5375 G loss:-2.356\n",
      "Epoch:  0054 D loss:-0.6471 G loss:-2.188\n",
      "Epoch:  0054 D loss:-0.6595 G loss:-2.307\n",
      "Epoch:  0054 D loss:-0.6725 G loss:-2.204\n",
      "Epoch:  0054 D loss:-0.5998 G loss:-2.257\n",
      "Epoch:  0054 D loss:-0.6928 G loss:-2.134\n",
      "Epoch:  0054 D loss:-0.7088 G loss:-2.136\n",
      "Epoch:  0054 D loss:-0.7256 G loss:-2.12\n",
      "Epoch:  0054 D loss:-0.5376 G loss:-2.119\n",
      "Epoch:  0054 D loss:-0.7809 G loss:-2.124\n",
      "Epoch:  0054 D loss:-0.5215 G loss:-2.257\n",
      "Epoch:  0054 D loss:-0.584 G loss:-2.241\n",
      "Epoch:  0054 D loss:-0.5926 G loss:-2.125\n",
      "Epoch:  0054 D loss:-0.5911 G loss:-2.205\n",
      "Epoch:  0054 D loss:-0.4999 G loss:-2.286\n",
      "Epoch:  0054 D loss:-0.5981 G loss:-2.212\n",
      "Epoch:  0054 D loss:-0.5895 G loss:-2.327\n",
      "Epoch:  0054 D loss:-0.639 G loss:-2.06\n",
      "Epoch:  0054 D loss:-0.6157 G loss:-2.262\n",
      "Epoch:  0054 D loss:-0.5226 G loss:-2.384\n",
      "Epoch:  0054 D loss:-0.6534 G loss:-2.272\n",
      "Epoch:  0054 D loss:-0.6272 G loss:-2.361\n",
      "Epoch:  0054 D loss:-0.7163 G loss:-1.966\n",
      "Epoch:  0054 D loss:-0.6152 G loss:-2.216\n",
      "Epoch:  0054 D loss:-0.639 G loss:-2.449\n",
      "Epoch:  0054 D loss:-0.5841 G loss:-2.377\n",
      "Epoch:  0054 D loss:-0.7724 G loss:-2.124\n",
      "Epoch:  0054 D loss:-0.6062 G loss:-2.23\n",
      "Epoch:  0054 D loss:-0.5659 G loss:-1.98\n",
      "Epoch:  0054 D loss:-0.7014 G loss:-1.905\n",
      "Epoch:  0054 D loss:-0.5635 G loss:-2.117\n",
      "Epoch:  0054 D loss:-0.7583 G loss:-1.822\n",
      "Epoch:  0054 D loss:-0.5047 G loss:-2.098\n",
      "Epoch:  0054 D loss:-0.5713 G loss:-2.119\n",
      "Epoch:  0054 D loss:-0.68 G loss:-2.133\n",
      "Epoch:  0054 D loss:-0.7557 G loss:-2.338\n",
      "Epoch:  0054 D loss:-0.5518 G loss:-2.136\n",
      "Epoch:  0054 D loss:-0.6062 G loss:-2.112\n",
      "Epoch:  0054 D loss:-0.632 G loss:-2.149\n",
      "Epoch:  0054 D loss:-0.6821 G loss:-2.098\n",
      "Epoch:  0054 D loss:-0.713 G loss:-2.113\n",
      "Epoch:  0054 D loss:-0.713 G loss:-2.201\n",
      "Epoch:  0054 D loss:-0.5002 G loss:-2.378\n",
      "Epoch:  0054 D loss:-0.5969 G loss:-2.322\n",
      "Epoch:  0054 D loss:-0.5587 G loss:-2.363\n",
      "Epoch:  0054 D loss:-0.716 G loss:-1.975\n",
      "Epoch:  0054 D loss:-0.5718 G loss:-2.316\n",
      "Epoch:  0054 D loss:-0.6186 G loss:-2.136\n",
      "Epoch:  0054 D loss:-0.5947 G loss:-1.935\n",
      "Epoch:  0054 D loss:-0.7074 G loss:-2.242\n",
      "Epoch:  0054 D loss:-0.6598 G loss:-2.215\n",
      "Epoch:  0054 D loss:-0.5896 G loss:-2.205\n",
      "Epoch:  0054 D loss:-0.6465 G loss:-2.092\n",
      "Epoch:  0054 D loss:-0.5846 G loss:-2.239\n",
      "Epoch:  0054 D loss:-0.5895 G loss:-2.151\n",
      "Epoch:  0054 D loss:-0.5838 G loss:-2.095\n",
      "Epoch:  0054 D loss:-0.529 G loss:-2.183\n",
      "Epoch:  0054 D loss:-0.5006 G loss:-2.201\n",
      "Epoch:  0054 D loss:-0.5037 G loss:-2.26\n",
      "Epoch:  0054 D loss:-0.6264 G loss:-2.123\n",
      "Epoch:  0054 D loss:-0.4879 G loss:-2.352\n",
      "Epoch:  0054 D loss:-0.6516 G loss:-2.119\n",
      "Epoch:  0054 D loss:-0.4698 G loss:-2.301\n",
      "Epoch:  0054 D loss:-0.675 G loss:-2.317\n",
      "Epoch:  0054 D loss:-0.514 G loss:-2.297\n",
      "Epoch:  0054 D loss:-0.5487 G loss:-2.383\n",
      "Epoch:  0054 D loss:-0.6954 G loss:-2.203\n",
      "Epoch:  0054 D loss:-0.659 G loss:-2.047\n",
      "Epoch:  0054 D loss:-0.6775 G loss:-1.981\n",
      "Epoch:  0054 D loss:-0.5105 G loss:-2.3\n",
      "Epoch:  0054 D loss:-0.6514 G loss:-2.295\n",
      "Epoch:  0054 D loss:-0.7036 G loss:-2.48\n",
      "Epoch:  0054 D loss:-0.513 G loss:-2.175\n",
      "Epoch:  0054 D loss:-0.6018 G loss:-2.199\n",
      "Epoch:  0054 D loss:-0.5161 G loss:-2.387\n",
      "Epoch:  0054 D loss:-0.5915 G loss:-2.176\n",
      "Epoch:  0054 D loss:-0.4482 G loss:-2.237\n",
      "Epoch:  0054 D loss:-0.657 G loss:-2.134\n",
      "Epoch:  0054 D loss:-0.6075 G loss:-2.145\n",
      "Epoch:  0054 D loss:-0.757 G loss:-2.207\n",
      "Epoch:  0054 D loss:-0.6196 G loss:-2.276\n",
      "Epoch:  0054 D loss:-0.4785 G loss:-2.241\n",
      "Epoch:  0054 D loss:-0.5655 G loss:-2.152\n",
      "Epoch:  0054 D loss:-0.5908 G loss:-2.414\n",
      "Epoch:  0054 D loss:-0.5488 G loss:-2.375\n",
      "Epoch:  0054 D loss:-0.6491 G loss:-2.237\n",
      "Epoch:  0054 D loss:-0.7348 G loss:-2.372\n",
      "Epoch:  0054 D loss:-0.5136 G loss:-2.509\n",
      "Epoch:  0054 D loss:-0.4973 G loss:-2.453\n",
      "Epoch:  0054 D loss:-0.6111 G loss:-2.153\n",
      "Epoch:  0054 D loss:-0.6728 G loss:-2.063\n",
      "Epoch:  0054 D loss:-0.6227 G loss:-2.101\n",
      "Epoch:  0054 D loss:-0.5814 G loss:-2.182\n",
      "Epoch:  0054 D loss:-0.5863 G loss:-2.047\n",
      "Epoch:  0054 D loss:-0.6108 G loss:-1.947\n",
      "Epoch:  0054 D loss:-0.591 G loss:-2.228\n",
      "Epoch:  0054 D loss:-0.6719 G loss:-2.26\n",
      "Epoch:  0054 D loss:-0.6498 G loss:-2.324\n",
      "Epoch:  0054 D loss:-0.736 G loss:-2.156\n",
      "Epoch:  0054 D loss:-0.6342 G loss:-2.235\n",
      "Epoch:  0054 D loss:-0.5304 G loss:-2.53\n",
      "Epoch:  0054 D loss:-0.7282 G loss:-2.143\n",
      "Epoch:  0054 D loss:-0.5822 G loss:-2.196\n",
      "Epoch:  0054 D loss:-0.653 G loss:-2.119\n",
      "Epoch:  0054 D loss:-0.6259 G loss:-2.102\n",
      "Epoch:  0054 D loss:-0.6701 G loss:-2.057\n",
      "Epoch:  0054 D loss:-0.6531 G loss:-1.934\n",
      "Epoch:  0054 D loss:-0.5407 G loss:-2.352\n",
      "Epoch:  0054 D loss:-0.5482 G loss:-2.026\n",
      "Epoch:  0054 D loss:-0.6858 G loss:-2.258\n",
      "Epoch:  0054 D loss:-0.5708 G loss:-2.208\n",
      "Epoch:  0054 D loss:-0.7177 G loss:-2.456\n",
      "Epoch:  0054 D loss:-0.654 G loss:-2.047\n",
      "Epoch:  0054 D loss:-0.4564 G loss:-2.401\n",
      "Epoch:  0054 D loss:-0.6418 G loss:-2.185\n",
      "Epoch:  0054 D loss:-0.5545 G loss:-2.4\n",
      "Epoch:  0054 D loss:-0.6703 G loss:-2.246\n",
      "Epoch:  0054 D loss:-0.6842 G loss:-2.167\n",
      "Epoch:  0054 D loss:-0.63 G loss:-2.088\n",
      "Epoch:  0054 D loss:-0.6053 G loss:-2.164\n",
      "Epoch:  0054 D loss:-0.7006 G loss:-2.185\n",
      "Epoch:  0054 D loss:-0.5499 G loss:-2.283\n",
      "Epoch:  0054 D loss:-0.7593 G loss:-2.313\n",
      "Epoch:  0054 D loss:-0.5559 G loss:-2.377\n",
      "Epoch:  0054 D loss:-0.6003 G loss:-2.462\n",
      "Epoch:  0054 D loss:-0.6464 G loss:-2.487\n",
      "Epoch:  0054 D loss:-0.6932 G loss:-2.141\n",
      "Epoch:  0054 D loss:-0.6515 G loss:-2.097\n",
      "Epoch:  0054 D loss:-0.777 G loss:-1.956\n",
      "Epoch:  0054 D loss:-0.622 G loss:-2.116\n",
      "Epoch:  0054 D loss:-0.5267 G loss:-2.242\n",
      "Epoch:  0054 D loss:-0.5609 G loss:-2.127\n",
      "Epoch:  0054 D loss:-0.5687 G loss:-1.956\n",
      "Epoch:  0054 D loss:-0.7141 G loss:-1.914\n",
      "Epoch:  0054 D loss:-0.7681 G loss:-2.113\n",
      "Epoch:  0054 D loss:-0.6229 G loss:-2.129\n",
      "Epoch:  0054 D loss:-0.5967 G loss:-2.204\n",
      "Epoch:  0054 D loss:-0.6212 G loss:-2.316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0054 D loss:-0.5336 G loss:-2.259\n",
      "Epoch:  0054 D loss:-0.4732 G loss:-2.331\n",
      "Epoch:  0054 D loss:-0.472 G loss:-2.679\n",
      "Epoch:  0054 D loss:-0.6693 G loss:-2.437\n",
      "Epoch:  0054 D loss:-0.6684 G loss:-2.577\n",
      "Epoch:  0054 D loss:-0.7296 G loss:-2.52\n",
      "Epoch:  0054 D loss:-0.639 G loss:-2.482\n",
      "Epoch:  0054 D loss:-0.6606 G loss:-1.867\n",
      "Epoch:  0054 D loss:-0.6998 G loss:-1.989\n",
      "Epoch:  0054 D loss:-0.6762 G loss:-2.106\n",
      "Epoch:  0054 D loss:-0.6172 G loss:-2.113\n",
      "Epoch:  0054 D loss:-0.6531 G loss:-1.918\n",
      "Epoch:  0054 D loss:-0.8204 G loss:-1.857\n",
      "Epoch:  0054 D loss:-0.6429 G loss:-2.054\n",
      "Epoch:  0054 D loss:-0.6292 G loss:-1.96\n",
      "Epoch:  0054 D loss:-0.5317 G loss:-2.053\n",
      "Epoch:  0054 D loss:-0.5824 G loss:-2.185\n",
      "Epoch:  0054 D loss:-0.6307 G loss:-1.971\n",
      "Epoch:  0054 D loss:-0.4649 G loss:-2.412\n",
      "Epoch:  0054 D loss:-0.4928 G loss:-2.269\n",
      "Epoch:  0054 D loss:-0.5758 G loss:-2.373\n",
      "Epoch:  0054 D loss:-0.6117 G loss:-2.385\n",
      "Epoch:  0054 D loss:-0.5956 G loss:-2.454\n",
      "Epoch:  0054 D loss:-0.6077 G loss:-2.483\n",
      "Epoch:  0054 D loss:-0.6728 G loss:-2.314\n",
      "Epoch:  0054 D loss:-0.6339 G loss:-2.492\n",
      "Epoch:  0054 D loss:-0.5605 G loss:-2.225\n",
      "Epoch:  0054 D loss:-0.803 G loss:-2.046\n",
      "Epoch:  0054 D loss:-0.6812 G loss:-1.976\n",
      "Epoch:  0054 D loss:-0.672 G loss:-2.036\n",
      "Epoch:  0054 D loss:-0.7546 G loss:-1.943\n",
      "Epoch:  0054 D loss:-0.6983 G loss:-1.997\n",
      "Epoch:  0054 D loss:-0.8374 G loss:-1.814\n",
      "Epoch:  0054 D loss:-0.5147 G loss:-1.959\n",
      "Epoch:  0054 D loss:-0.667 G loss:-2.009\n",
      "Epoch:  0054 D loss:-0.6901 G loss:-1.995\n",
      "Epoch:  0054 D loss:-0.6588 G loss:-1.965\n",
      "Epoch:  0054 D loss:-0.5339 G loss:-2.373\n",
      "Epoch:  0054 D loss:-0.5483 G loss:-2.46\n",
      "Epoch:  0054 D loss:-0.6618 G loss:-2.507\n",
      "Epoch:  0054 D loss:-0.7982 G loss:-2.059\n",
      "Epoch:  0054 D loss:-0.516 G loss:-2.397\n",
      "Epoch:  0054 D loss:-0.6143 G loss:-2.284\n",
      "Epoch:  0054 D loss:-0.7689 G loss:-2.141\n",
      "Epoch:  0054 D loss:-0.6072 G loss:-2.359\n",
      "Epoch:  0054 D loss:-0.6454 G loss:-2.302\n",
      "Epoch:  0054 D loss:-0.5798 G loss:-2.241\n",
      "Epoch:  0054 D loss:-0.5764 G loss:-2.217\n",
      "Epoch:  0054 D loss:-0.5591 G loss:-2.134\n",
      "Epoch:  0054 D loss:-0.7933 G loss:-1.868\n",
      "Epoch:  0054 D loss:-0.5947 G loss:-2.178\n",
      "Epoch:  0054 D loss:-0.6845 G loss:-2.048\n",
      "Epoch:  0054 D loss:-0.837 G loss:-1.906\n",
      "Epoch:  0054 D loss:-0.5475 G loss:-2.162\n",
      "Epoch:  0054 D loss:-0.7032 G loss:-2.094\n",
      "Epoch:  0054 D loss:-0.7199 G loss:-2.192\n",
      "Epoch:  0054 D loss:-0.6027 G loss:-2.328\n",
      "Epoch:  0054 D loss:-0.6112 G loss:-2.054\n",
      "Epoch:  0054 D loss:-0.5815 G loss:-2.376\n",
      "Epoch:  0054 D loss:-0.6365 G loss:-2.311\n",
      "Epoch:  0054 D loss:-0.7744 G loss:-2.382\n",
      "Epoch:  0054 D loss:-0.6253 G loss:-2.35\n",
      "Epoch:  0054 D loss:-0.7473 G loss:-2.025\n",
      "Epoch:  0054 D loss:-0.6802 G loss:-2.215\n",
      "Epoch:  0054 D loss:-0.6718 G loss:-2.22\n",
      "Epoch:  0054 D loss:-0.6721 G loss:-2.072\n",
      "Epoch:  0054 D loss:-0.6366 G loss:-2.108\n",
      "Epoch:  0054 D loss:-0.6492 G loss:-1.961\n",
      "Epoch:  0054 D loss:-0.6505 G loss:-1.879\n",
      "Epoch:  0054 D loss:-0.5941 G loss:-2.124\n",
      "Epoch:  0054 D loss:-0.6671 G loss:-2.078\n",
      "Epoch:  0054 D loss:-0.5609 G loss:-2.185\n",
      "Epoch:  0054 D loss:-0.7325 G loss:-2.316\n",
      "Epoch:  0054 D loss:-0.5496 G loss:-2.357\n",
      "Epoch:  0054 D loss:-0.6243 G loss:-2.181\n",
      "Epoch:  0054 D loss:-0.5288 G loss:-2.59\n",
      "Epoch:  0054 D loss:-0.5435 G loss:-2.76\n",
      "Epoch:  0054 D loss:-0.7114 G loss:-2.321\n",
      "Epoch:  0054 D loss:-0.6338 G loss:-2.537\n",
      "Epoch:  0054 D loss:-0.6575 G loss:-2.558\n",
      "Epoch:  0054 D loss:-0.5384 G loss:-2.29\n",
      "Epoch:  0054 D loss:-0.6577 G loss:-2.221\n",
      "Epoch:  0054 D loss:-0.6169 G loss:-2.28\n",
      "Epoch:  0054 D loss:-0.5381 G loss:-2.147\n",
      "Epoch:  0054 D loss:-0.6617 G loss:-2.025\n",
      "Epoch:  0054 D loss:-0.7012 G loss:-2.005\n",
      "Epoch:  0054 D loss:-0.6724 G loss:-1.848\n",
      "Epoch:  0054 D loss:-0.5905 G loss:-2.006\n",
      "Epoch:  0054 D loss:-0.7175 G loss:-2.092\n",
      "Epoch:  0054 D loss:-0.7022 G loss:-2.008\n",
      "Epoch:  0054 D loss:-0.6556 G loss:-2.16\n",
      "Epoch:  0054 D loss:-0.4706 G loss:-2.139\n",
      "Epoch:  0054 D loss:-0.6262 G loss:-2.223\n",
      "Epoch:  0054 D loss:-0.6382 G loss:-2.402\n",
      "Epoch:  0054 D loss:-0.6162 G loss:-2.275\n",
      "Epoch:  0054 D loss:-0.5341 G loss:-2.212\n",
      "Epoch:  0054 D loss:-0.5314 G loss:-2.41\n",
      "Epoch:  0054 D loss:-0.4769 G loss:-2.067\n",
      "Epoch:  0054 D loss:-0.6192 G loss:-2.276\n",
      "Epoch:  0054 D loss:-0.6428 G loss:-2.137\n",
      "Epoch:  0054 D loss:-0.726 G loss:-2.233\n",
      "Epoch:  0054 D loss:-0.5842 G loss:-2.434\n",
      "Epoch:  0054 D loss:-0.4844 G loss:-2.212\n",
      "Epoch:  0054 D loss:-0.4971 G loss:-2.166\n",
      "Epoch:  0054 D loss:-0.5685 G loss:-2.323\n",
      "Epoch:  0054 D loss:-0.6396 G loss:-2.234\n",
      "Epoch:  0054 D loss:-0.5822 G loss:-2.24\n",
      "Epoch:  0054 D loss:-0.6502 G loss:-1.998\n",
      "Epoch:  0054 D loss:-0.6129 G loss:-2.052\n",
      "Epoch:  0054 D loss:-0.5083 G loss:-2.224\n",
      "Epoch:  0054 D loss:-0.5018 G loss:-1.993\n",
      "Epoch:  0054 D loss:-0.5278 G loss:-2.131\n",
      "Epoch:  0054 D loss:-0.5717 G loss:-2.212\n",
      "Epoch:  0054 D loss:-0.4714 G loss:-2.227\n",
      "Epoch:  0054 D loss:-0.6883 G loss:-2.151\n",
      "Epoch:  0054 D loss:-0.5113 G loss:-2.345\n",
      "Epoch:  0054 D loss:-0.4969 G loss:-2.37\n",
      "Epoch:  0054 D loss:-0.5319 G loss:-2.375\n",
      "Epoch:  0054 D loss:-0.5996 G loss:-2.488\n",
      "Epoch:  0054 D loss:-0.6885 G loss:-2.372\n",
      "Epoch:  0054 D loss:-0.7333 G loss:-2.116\n",
      "Epoch:  0054 D loss:-0.558 G loss:-2.194\n",
      "Epoch:  0054 D loss:-0.4154 G loss:-2.353\n",
      "Epoch:  0054 D loss:-0.5077 G loss:-2.158\n",
      "Epoch:  0054 D loss:-0.5281 G loss:-2.01\n",
      "Epoch:  0054 D loss:-0.6238 G loss:-2.188\n",
      "Epoch:  0054 D loss:-0.6921 G loss:-1.918\n",
      "Epoch:  0054 D loss:-0.6804 G loss:-2.125\n",
      "Epoch:  0054 D loss:-0.5528 G loss:-2.237\n",
      "Epoch:  0054 D loss:-0.5959 G loss:-2.297\n",
      "Epoch:  0054 D loss:-0.5706 G loss:-2.384\n",
      "Epoch:  0054 D loss:-0.7487 G loss:-2.229\n",
      "Epoch:  0054 D loss:-0.6656 G loss:-2.562\n",
      "Epoch:  0054 D loss:-0.6591 G loss:-2.246\n",
      "Epoch:  0054 D loss:-0.6423 G loss:-2.212\n",
      "Epoch:  0054 D loss:-0.6053 G loss:-2.173\n",
      "Epoch:  0054 D loss:-0.6211 G loss:-2.172\n",
      "Epoch:  0054 D loss:-0.5571 G loss:-2.214\n",
      "Epoch:  0054 D loss:-0.5744 G loss:-2.082\n",
      "Epoch:  0054 D loss:-0.5558 G loss:-1.876\n",
      "Epoch:  0054 D loss:-0.5488 G loss:-1.964\n",
      "Epoch:  0054 D loss:-0.5983 G loss:-2.193\n",
      "Epoch:  0054 D loss:-0.666 G loss:-2.256\n",
      "Epoch:  0054 D loss:-0.6131 G loss:-2.278\n",
      "Epoch:  0054 D loss:-0.6524 G loss:-2.249\n",
      "Epoch:  0054 D loss:-0.5279 G loss:-2.178\n",
      "Epoch:  0054 D loss:-0.6023 G loss:-2.127\n",
      "Epoch:  0054 D loss:-0.5825 G loss:-2.269\n",
      "Epoch:  0054 D loss:-0.5505 G loss:-2.281\n",
      "Epoch:  0054 D loss:-0.5529 G loss:-2.187\n",
      "Epoch:  0054 D loss:-0.6457 G loss:-2.043\n",
      "Epoch:  0054 D loss:-0.7588 G loss:-1.85\n",
      "Epoch:  0054 D loss:-0.5458 G loss:-2.18\n",
      "Epoch:  0054 D loss:-0.6751 G loss:-2.241\n",
      "Epoch:  0054 D loss:-0.6332 G loss:-1.914\n",
      "Epoch:  0054 D loss:-0.7117 G loss:-1.964\n",
      "Epoch:  0054 D loss:-0.57 G loss:-1.984\n",
      "Epoch:  0054 D loss:-0.5667 G loss:-2.375\n",
      "Epoch:  0054 D loss:-0.7096 G loss:-2.132\n",
      "Epoch:  0054 D loss:-0.6054 G loss:-2.306\n",
      "Epoch:  0054 D loss:-0.6219 G loss:-2.148\n",
      "Epoch:  0054 D loss:-0.5654 G loss:-2.215\n",
      "Epoch:  0054 D loss:-0.6241 G loss:-2.261\n",
      "Epoch:  0054 D loss:-0.7478 G loss:-1.976\n",
      "Epoch:  0054 D loss:-0.4911 G loss:-2.158\n",
      "Epoch:  0054 D loss:-0.6995 G loss:-2.009\n",
      "Epoch:  0054 D loss:-0.7763 G loss:-2.077\n",
      "Epoch:  0054 D loss:-0.5692 G loss:-2.148\n",
      "Epoch:  0054 D loss:-0.6218 G loss:-2.17\n",
      "Epoch:  0054 D loss:-0.5805 G loss:-2.219\n",
      "Epoch:  0054 D loss:-0.633 G loss:-2.392\n",
      "Epoch:  0054 D loss:-0.634 G loss:-2.182\n",
      "Epoch:  0054 D loss:-0.6456 G loss:-2.156\n",
      "Epoch:  0054 D loss:-0.6008 G loss:-2.32\n",
      "Epoch:  0054 D loss:-0.6003 G loss:-2.104\n",
      "Epoch:  0054 D loss:-0.5477 G loss:-2.415\n",
      "Epoch:  0054 D loss:-0.5436 G loss:-2.151\n",
      "Epoch:  0054 D loss:-0.5139 G loss:-2.143\n",
      "Epoch:  0054 D loss:-0.7114 G loss:-2.137\n",
      "Epoch:  0054 D loss:-0.5929 G loss:-2.206\n",
      "Epoch:  0054 D loss:-0.6725 G loss:-1.938\n",
      "Epoch:  0054 D loss:-0.5757 G loss:-2.228\n",
      "Epoch:  0054 D loss:-0.7054 G loss:-2.094\n",
      "Epoch:  0054 D loss:-0.5844 G loss:-2.075\n",
      "Epoch:  0054 D loss:-0.6541 G loss:-1.999\n",
      "Epoch:  0054 D loss:-0.5563 G loss:-2.05\n",
      "Epoch:  0054 D loss:-0.6048 G loss:-2.092\n",
      "Epoch:  0054 D loss:-0.6109 G loss:-2.189\n",
      "Epoch:  0054 D loss:-0.7567 G loss:-2.375\n",
      "Epoch:  0054 D loss:-0.5728 G loss:-2.226\n",
      "Epoch:  0054 D loss:-0.6753 G loss:-2.258\n",
      "Epoch:  0054 D loss:-0.7152 G loss:-2.195\n",
      "Epoch:  0054 D loss:-0.6672 G loss:-2.083\n",
      "Epoch:  0054 D loss:-0.6089 G loss:-2.092\n",
      "Epoch:  0054 D loss:-0.5714 G loss:-2.186\n",
      "Epoch:  0054 D loss:-0.5558 G loss:-2.208\n",
      "Epoch:  0054 D loss:-0.7715 G loss:-1.913\n",
      "Epoch:  0054 D loss:-0.594 G loss:-1.99\n",
      "Epoch:  0054 D loss:-0.6244 G loss:-2.196\n",
      "Epoch:  0054 D loss:-0.7414 G loss:-2.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0054 D loss:-0.5719 G loss:-2.19\n",
      "Epoch:  0054 D loss:-0.5573 G loss:-2.178\n",
      "Epoch:  0054 D loss:-0.6501 G loss:-2.062\n",
      "Epoch:  0054 D loss:-0.5999 G loss:-2.286\n",
      "Epoch:  0054 D loss:-0.6136 G loss:-2.165\n",
      "Epoch:  0054 D loss:-0.6371 G loss:-2.184\n",
      "Epoch:  0054 D loss:-0.6748 G loss:-2.279\n",
      "Epoch:  0054 D loss:-0.7339 G loss:-2.138\n",
      "Epoch:  0054 D loss:-0.6933 G loss:-2.052\n",
      "Epoch:  0054 D loss:-0.5516 G loss:-2.204\n",
      "Epoch:  0054 D loss:-0.6499 G loss:-2.134\n",
      "Epoch:  0054 D loss:-0.6576 G loss:-1.968\n",
      "Epoch:  0054 D loss:-0.5345 G loss:-2.094\n",
      "Epoch:  0054 D loss:-0.5748 G loss:-2.054\n",
      "Epoch:  0054 D loss:-0.572 G loss:-2.091\n",
      "Epoch:  0054 D loss:-0.7162 G loss:-2.05\n",
      "Epoch:  0054 D loss:-0.6749 G loss:-2.066\n",
      "Epoch:  0054 D loss:-0.5163 G loss:-2.205\n",
      "Epoch:  0054 D loss:-0.696 G loss:-2.42\n",
      "Epoch:  0054 D loss:-0.6234 G loss:-2.098\n",
      "Epoch:  0054 D loss:-0.7064 G loss:-2.474\n",
      "Epoch:  0054 D loss:-0.5617 G loss:-2.097\n",
      "Epoch:  0054 D loss:-0.6215 G loss:-2.27\n",
      "Epoch:  0054 D loss:-0.6435 G loss:-2.011\n",
      "Epoch:  0054 D loss:-0.5345 G loss:-2.244\n",
      "Epoch:  0054 D loss:-0.6419 G loss:-2.179\n",
      "Epoch:  0054 D loss:-0.5488 G loss:-2.167\n",
      "Epoch:  0054 D loss:-0.6937 G loss:-2.016\n",
      "Epoch:  0054 D loss:-0.6443 G loss:-1.998\n",
      "Epoch:  0054 D loss:-0.5924 G loss:-2.097\n",
      "Epoch:  0054 D loss:-0.4748 G loss:-2.123\n",
      "Epoch:  0054 D loss:-0.6991 G loss:-1.991\n",
      "Epoch:  0054 D loss:-0.833 G loss:-1.893\n",
      "Epoch:  0054 D loss:-0.6348 G loss:-2.196\n",
      "Epoch:  0054 D loss:-0.741 G loss:-2.108\n",
      "Epoch:  0054 D loss:-0.6831 G loss:-2.188\n",
      "Epoch:  0054 D loss:-0.47 G loss:-2.452\n",
      "Epoch:  0054 D loss:-0.6319 G loss:-2.572\n",
      "Epoch:  0054 D loss:-0.7073 G loss:-2.211\n",
      "Epoch:  0054 D loss:-0.601 G loss:-1.954\n",
      "Epoch:  0054 D loss:-0.5186 G loss:-2.33\n",
      "Epoch:  0054 D loss:-0.5844 G loss:-2.158\n",
      "Epoch:  0054 D loss:-0.6445 G loss:-2.147\n",
      "Epoch:  0054 D loss:-0.6152 G loss:-2.342\n",
      "Epoch:  0054 D loss:-0.6158 G loss:-2.217\n",
      "Epoch:  0054 D loss:-0.6231 G loss:-2.081\n",
      "Epoch:  0054 D loss:-0.6531 G loss:-2.107\n",
      "Epoch:  0054 D loss:-0.6841 G loss:-1.88\n",
      "Epoch:  0054 D loss:-0.6482 G loss:-2.023\n",
      "Epoch:  0054 D loss:-0.6917 G loss:-1.921\n",
      "Epoch:  0054 D loss:-0.686 G loss:-2.149\n",
      "Epoch:  0054 D loss:-0.5869 G loss:-2.154\n",
      "Epoch:  0054 D loss:-0.5565 G loss:-2.324\n",
      "Epoch:  0054 D loss:-0.6295 G loss:-2.326\n",
      "Epoch:  0054 D loss:-0.5918 G loss:-2.151\n",
      "Epoch:  0054 D loss:-0.6416 G loss:-2.177\n",
      "Epoch:  0054 D loss:-0.5625 G loss:-2.511\n",
      "Epoch:  0054 D loss:-0.5711 G loss:-2.517\n",
      "Epoch:  0054 D loss:-0.7128 G loss:-2.219\n",
      "Epoch:  0054 D loss:-0.6444 G loss:-2.367\n",
      "Epoch:  0054 D loss:-0.7623 G loss:-2.399\n",
      "Epoch:  0054 D loss:-0.6477 G loss:-2.388\n",
      "Epoch:  0054 D loss:-0.6159 G loss:-2.213\n",
      "Epoch:  0054 D loss:-0.5869 G loss:-2.172\n",
      "Epoch:  0054 D loss:-0.7264 G loss:-2.261\n",
      "Epoch:  0054 D loss:-0.7394 G loss:-2.033\n",
      "Epoch:  0054 D loss:-0.6639 G loss:-1.839\n",
      "Epoch:  0054 D loss:-0.7252 G loss:-1.805\n",
      "Epoch:  0054 D loss:-0.6116 G loss:-1.945\n",
      "Epoch:  0054 D loss:-0.5634 G loss:-2.157\n",
      "Epoch:  0054 D loss:-0.528 G loss:-2.031\n",
      "Epoch:  0054 D loss:-0.5905 G loss:-2.174\n",
      "Epoch:  0054 D loss:-0.6386 G loss:-1.986\n",
      "Epoch:  0054 D loss:-0.671 G loss:-1.969\n",
      "Epoch:  0054 D loss:-0.6276 G loss:-2.296\n",
      "Epoch:  0054 D loss:-0.6454 G loss:-2.393\n",
      "Epoch:  0054 D loss:-0.5539 G loss:-2.362\n",
      "Epoch:  0054 D loss:-0.5949 G loss:-2.597\n",
      "Epoch:  0054 D loss:-0.5857 G loss:-2.491\n",
      "Epoch:  0054 D loss:-0.7267 G loss:-2.324\n",
      "Epoch:  0054 D loss:-0.6127 G loss:-2.377\n",
      "Epoch:  0054 D loss:-0.7801 G loss:-2.207\n",
      "Epoch:  0054 D loss:-0.6945 G loss:-2.193\n",
      "Epoch:  0054 D loss:-0.5812 G loss:-2.194\n",
      "Epoch:  0054 D loss:-0.7469 G loss:-1.982\n",
      "Epoch:  0054 D loss:-0.555 G loss:-2.231\n",
      "Epoch:  0054 D loss:-0.5917 G loss:-1.983\n",
      "Epoch:  0054 D loss:-0.5378 G loss:-2.182\n",
      "Epoch:  0054 D loss:-0.5862 G loss:-2.277\n",
      "Epoch:  0054 D loss:-0.5065 G loss:-2.15\n",
      "Epoch:  0054 D loss:-0.602 G loss:-2.126\n",
      "Epoch:  0054 D loss:-0.6244 G loss:-1.994\n",
      "Epoch:  0054 D loss:-0.6391 G loss:-2.058\n",
      "Epoch:  0054 D loss:-0.5471 G loss:-2.173\n",
      "Epoch:  0054 D loss:-0.6055 G loss:-2.341\n",
      "Epoch:  0054 D loss:-0.7423 G loss:-2.111\n",
      "Epoch:  0054 D loss:-0.6854 G loss:-2.284\n",
      "Epoch:  0054 D loss:-0.6112 G loss:-2.412\n",
      "Epoch:  0054 D loss:-0.6002 G loss:-2.366\n",
      "Epoch:  0054 D loss:-0.6347 G loss:-2.272\n",
      "Epoch:  0054 D loss:-0.6501 G loss:-2.201\n",
      "Epoch:  0054 D loss:-0.5709 G loss:-2.097\n",
      "Epoch:  0054 D loss:-0.6242 G loss:-2.403\n",
      "Epoch:  0054 D loss:-0.6107 G loss:-2.121\n",
      "Epoch:  0054 D loss:-0.6027 G loss:-2.195\n",
      "Epoch:  0054 D loss:-0.6285 G loss:-2.046\n",
      "Epoch:  0054 D loss:-0.6233 G loss:-2.146\n",
      "Epoch:  0054 D loss:-0.682 G loss:-2.092\n",
      "Epoch:  0054 D loss:-0.6357 G loss:-2.024\n",
      "Epoch:  0054 D loss:-0.5815 G loss:-2.181\n",
      "Epoch:  0054 D loss:-0.617 G loss:-2.372\n",
      "Epoch:  0054 D loss:-0.8461 G loss:-2.088\n",
      "Epoch:  0054 D loss:-0.7071 G loss:-2.114\n",
      "Epoch:  0054 D loss:-0.812 G loss:-2.082\n",
      "Epoch:  0054 D loss:-0.5849 G loss:-2.145\n",
      "Epoch:  0054 D loss:-0.6081 G loss:-2.111\n",
      "Epoch:  0054 D loss:-0.5841 G loss:-2.152\n",
      "Epoch:  0054 D loss:-0.7445 G loss:-2.043\n",
      "Epoch:  0054 D loss:-0.5088 G loss:-2.291\n",
      "Epoch:  0054 D loss:-0.6518 G loss:-2.148\n",
      "Epoch:  0054 D loss:-0.6112 G loss:-2.471\n",
      "Epoch:  0054 D loss:-0.5978 G loss:-2.474\n",
      "Epoch:  0054 D loss:-0.7264 G loss:-2.283\n",
      "Epoch:  0054 D loss:-0.6281 G loss:-2.169\n",
      "Epoch:  0055 D loss:-0.6101 G loss:-2.166\n",
      "Epoch:  0055 D loss:-0.5929 G loss:-2.174\n",
      "Epoch:  0055 D loss:-0.5347 G loss:-2.259\n",
      "Epoch:  0055 D loss:-0.6844 G loss:-2.034\n",
      "Epoch:  0055 D loss:-0.6514 G loss:-2.251\n",
      "Epoch:  0055 D loss:-0.6562 G loss:-2.181\n",
      "Epoch:  0055 D loss:-0.675 G loss:-2.132\n",
      "Epoch:  0055 D loss:-0.5366 G loss:-2.193\n",
      "Epoch:  0055 D loss:-0.5904 G loss:-2.023\n",
      "Epoch:  0055 D loss:-0.7124 G loss:-1.88\n",
      "Epoch:  0055 D loss:-0.5721 G loss:-2.267\n",
      "Epoch:  0055 D loss:-0.7673 G loss:-2.078\n",
      "Epoch:  0055 D loss:-0.5473 G loss:-2.183\n",
      "Epoch:  0055 D loss:-0.4769 G loss:-2.344\n",
      "Epoch:  0055 D loss:-0.5858 G loss:-2.296\n",
      "Epoch:  0055 D loss:-0.6343 G loss:-2.384\n",
      "Epoch:  0055 D loss:-0.6614 G loss:-2.002\n",
      "Epoch:  0055 D loss:-0.4918 G loss:-2.249\n",
      "Epoch:  0055 D loss:-0.6017 G loss:-2.361\n",
      "Epoch:  0055 D loss:-0.6958 G loss:-2.178\n",
      "Epoch:  0055 D loss:-0.5388 G loss:-2.427\n",
      "Epoch:  0055 D loss:-0.5054 G loss:-2.376\n",
      "Epoch:  0055 D loss:-0.752 G loss:-2.174\n",
      "Epoch:  0055 D loss:-0.5397 G loss:-2.357\n",
      "Epoch:  0055 D loss:-0.7201 G loss:-2.047\n",
      "Epoch:  0055 D loss:-0.7107 G loss:-2.22\n",
      "Epoch:  0055 D loss:-0.689 G loss:-1.9\n",
      "Epoch:  0055 D loss:-0.7818 G loss:-1.822\n",
      "Epoch:  0055 D loss:-0.6705 G loss:-2.031\n",
      "Epoch:  0055 D loss:-0.6653 G loss:-2.187\n",
      "Epoch:  0055 D loss:-0.5162 G loss:-2.077\n",
      "Epoch:  0055 D loss:-0.7826 G loss:-2.188\n",
      "Epoch:  0055 D loss:-0.4975 G loss:-2.268\n",
      "Epoch:  0055 D loss:-0.6307 G loss:-2.165\n",
      "Epoch:  0055 D loss:-0.8162 G loss:-2.065\n",
      "Epoch:  0055 D loss:-0.6117 G loss:-2.413\n",
      "Epoch:  0055 D loss:-0.669 G loss:-2.085\n",
      "Epoch:  0055 D loss:-0.7426 G loss:-2.161\n",
      "Epoch:  0055 D loss:-0.6535 G loss:-2.115\n",
      "Epoch:  0055 D loss:-0.6965 G loss:-2.077\n",
      "Epoch:  0055 D loss:-0.7805 G loss:-1.975\n",
      "Epoch:  0055 D loss:-0.7358 G loss:-2.05\n",
      "Epoch:  0055 D loss:-0.6985 G loss:-2.063\n",
      "Epoch:  0055 D loss:-0.581 G loss:-2.154\n",
      "Epoch:  0055 D loss:-0.6994 G loss:-1.932\n",
      "Epoch:  0055 D loss:-0.5889 G loss:-1.962\n",
      "Epoch:  0055 D loss:-0.6796 G loss:-2.203\n",
      "Epoch:  0055 D loss:-0.7499 G loss:-2.134\n",
      "Epoch:  0055 D loss:-0.6297 G loss:-2.226\n",
      "Epoch:  0055 D loss:-0.6857 G loss:-2.294\n",
      "Epoch:  0055 D loss:-0.5944 G loss:-2.189\n",
      "Epoch:  0055 D loss:-0.7454 G loss:-2.179\n",
      "Epoch:  0055 D loss:-0.7957 G loss:-1.997\n",
      "Epoch:  0055 D loss:-0.6139 G loss:-2.235\n",
      "Epoch:  0055 D loss:-0.7028 G loss:-1.975\n",
      "Epoch:  0055 D loss:-0.6449 G loss:-2.138\n",
      "Epoch:  0055 D loss:-0.8563 G loss:-1.929\n",
      "Epoch:  0055 D loss:-0.6385 G loss:-2.054\n",
      "Epoch:  0055 D loss:-0.5194 G loss:-2.358\n",
      "Epoch:  0055 D loss:-0.6321 G loss:-2.328\n",
      "Epoch:  0055 D loss:-0.7373 G loss:-2.159\n",
      "Epoch:  0055 D loss:-0.6165 G loss:-2.183\n",
      "Epoch:  0055 D loss:-0.6082 G loss:-2.32\n",
      "Epoch:  0055 D loss:-0.6883 G loss:-2.352\n",
      "Epoch:  0055 D loss:-0.6948 G loss:-2.128\n",
      "Epoch:  0055 D loss:-0.6006 G loss:-2.169\n",
      "Epoch:  0055 D loss:-0.765 G loss:-2.013\n",
      "Epoch:  0055 D loss:-0.7897 G loss:-2.058\n",
      "Epoch:  0055 D loss:-0.6817 G loss:-1.947\n",
      "Epoch:  0055 D loss:-0.75 G loss:-2.018\n",
      "Epoch:  0055 D loss:-0.6222 G loss:-2.173\n",
      "Epoch:  0055 D loss:-0.6703 G loss:-2.013\n",
      "Epoch:  0055 D loss:-0.6489 G loss:-1.867\n",
      "Epoch:  0055 D loss:-0.5513 G loss:-2.306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0055 D loss:-0.6297 G loss:-2.361\n",
      "Epoch:  0055 D loss:-0.8159 G loss:-2.022\n",
      "Epoch:  0055 D loss:-0.6671 G loss:-2.309\n",
      "Epoch:  0055 D loss:-0.6561 G loss:-2.378\n",
      "Epoch:  0055 D loss:-0.7617 G loss:-1.924\n",
      "Epoch:  0055 D loss:-0.5833 G loss:-1.949\n",
      "Epoch:  0055 D loss:-0.5601 G loss:-1.977\n",
      "Epoch:  0055 D loss:-0.5665 G loss:-1.985\n",
      "Epoch:  0055 D loss:-0.606 G loss:-2.09\n",
      "Epoch:  0055 D loss:-0.6782 G loss:-1.94\n",
      "Epoch:  0055 D loss:-0.651 G loss:-1.967\n",
      "Epoch:  0055 D loss:-0.6378 G loss:-2.082\n",
      "Epoch:  0055 D loss:-0.6737 G loss:-1.932\n",
      "Epoch:  0055 D loss:-0.7041 G loss:-1.931\n",
      "Epoch:  0055 D loss:-0.6142 G loss:-1.912\n",
      "Epoch:  0055 D loss:-0.5807 G loss:-2.154\n",
      "Epoch:  0055 D loss:-0.7429 G loss:-2.351\n",
      "Epoch:  0055 D loss:-0.6524 G loss:-2.271\n",
      "Epoch:  0055 D loss:-0.5371 G loss:-2.203\n",
      "Epoch:  0055 D loss:-0.5859 G loss:-2.268\n",
      "Epoch:  0055 D loss:-0.6379 G loss:-2.107\n",
      "Epoch:  0055 D loss:-0.6112 G loss:-2.273\n",
      "Epoch:  0055 D loss:-0.5703 G loss:-2.287\n",
      "Epoch:  0055 D loss:-0.5644 G loss:-2.328\n",
      "Epoch:  0055 D loss:-0.7507 G loss:-2.194\n",
      "Epoch:  0055 D loss:-0.6876 G loss:-2.287\n",
      "Epoch:  0055 D loss:-0.5307 G loss:-2.183\n",
      "Epoch:  0055 D loss:-0.6628 G loss:-2.21\n",
      "Epoch:  0055 D loss:-0.5689 G loss:-2.265\n",
      "Epoch:  0055 D loss:-0.5655 G loss:-2.112\n",
      "Epoch:  0055 D loss:-0.6601 G loss:-2.034\n",
      "Epoch:  0055 D loss:-0.7242 G loss:-2.117\n",
      "Epoch:  0055 D loss:-0.6846 G loss:-2.056\n",
      "Epoch:  0055 D loss:-0.6718 G loss:-1.975\n",
      "Epoch:  0055 D loss:-0.6024 G loss:-2.023\n",
      "Epoch:  0055 D loss:-0.7306 G loss:-1.877\n",
      "Epoch:  0055 D loss:-0.7386 G loss:-2.016\n",
      "Epoch:  0055 D loss:-0.7395 G loss:-1.916\n",
      "Epoch:  0055 D loss:-0.6207 G loss:-2.279\n",
      "Epoch:  0055 D loss:-0.7216 G loss:-2.046\n",
      "Epoch:  0055 D loss:-0.7053 G loss:-2.181\n",
      "Epoch:  0055 D loss:-0.7561 G loss:-2.284\n",
      "Epoch:  0055 D loss:-0.6444 G loss:-2.193\n",
      "Epoch:  0055 D loss:-0.7417 G loss:-2.244\n",
      "Epoch:  0055 D loss:-0.6095 G loss:-2.327\n",
      "Epoch:  0055 D loss:-0.6318 G loss:-2.199\n",
      "Epoch:  0055 D loss:-0.5913 G loss:-2.137\n",
      "Epoch:  0055 D loss:-0.5674 G loss:-2.164\n",
      "Epoch:  0055 D loss:-0.5461 G loss:-2.198\n",
      "Epoch:  0055 D loss:-0.6493 G loss:-2.159\n",
      "Epoch:  0055 D loss:-0.6708 G loss:-2.183\n",
      "Epoch:  0055 D loss:-0.6956 G loss:-2.144\n",
      "Epoch:  0055 D loss:-0.4292 G loss:-2.167\n",
      "Epoch:  0055 D loss:-0.6293 G loss:-2.042\n",
      "Epoch:  0055 D loss:-0.634 G loss:-2.103\n",
      "Epoch:  0055 D loss:-0.6195 G loss:-2.059\n",
      "Epoch:  0055 D loss:-0.5658 G loss:-2.388\n",
      "Epoch:  0055 D loss:-0.5838 G loss:-2.091\n",
      "Epoch:  0055 D loss:-0.5882 G loss:-2.165\n",
      "Epoch:  0055 D loss:-0.6998 G loss:-2.161\n",
      "Epoch:  0055 D loss:-0.6285 G loss:-2.06\n",
      "Epoch:  0055 D loss:-0.5771 G loss:-2.338\n",
      "Epoch:  0055 D loss:-0.6403 G loss:-2.213\n",
      "Epoch:  0055 D loss:-0.6454 G loss:-2.262\n",
      "Epoch:  0055 D loss:-0.7306 G loss:-2.109\n",
      "Epoch:  0055 D loss:-0.6332 G loss:-2.138\n",
      "Epoch:  0055 D loss:-0.5521 G loss:-2.171\n",
      "Epoch:  0055 D loss:-0.6498 G loss:-2.29\n",
      "Epoch:  0055 D loss:-0.6961 G loss:-2.111\n",
      "Epoch:  0055 D loss:-0.5059 G loss:-2.188\n",
      "Epoch:  0055 D loss:-0.6143 G loss:-1.977\n",
      "Epoch:  0055 D loss:-0.5722 G loss:-2.04\n",
      "Epoch:  0055 D loss:-0.7001 G loss:-2.123\n",
      "Epoch:  0055 D loss:-0.6458 G loss:-2.117\n",
      "Epoch:  0055 D loss:-0.6662 G loss:-2.094\n",
      "Epoch:  0055 D loss:-0.5822 G loss:-2.319\n",
      "Epoch:  0055 D loss:-0.5876 G loss:-2.095\n",
      "Epoch:  0055 D loss:-0.6416 G loss:-2.085\n",
      "Epoch:  0055 D loss:-0.6075 G loss:-2.087\n",
      "Epoch:  0055 D loss:-0.7077 G loss:-2.177\n",
      "Epoch:  0055 D loss:-0.6561 G loss:-2.349\n",
      "Epoch:  0055 D loss:-0.5736 G loss:-2.163\n",
      "Epoch:  0055 D loss:-0.608 G loss:-2.213\n",
      "Epoch:  0055 D loss:-0.5953 G loss:-2.447\n",
      "Epoch:  0055 D loss:-0.6199 G loss:-2.254\n",
      "Epoch:  0055 D loss:-0.6082 G loss:-2.307\n",
      "Epoch:  0055 D loss:-0.5621 G loss:-2.246\n",
      "Epoch:  0055 D loss:-0.5842 G loss:-2.205\n",
      "Epoch:  0055 D loss:-0.4986 G loss:-2.132\n",
      "Epoch:  0055 D loss:-0.6718 G loss:-2.181\n",
      "Epoch:  0055 D loss:-0.6237 G loss:-2.024\n",
      "Epoch:  0055 D loss:-0.6659 G loss:-2.061\n",
      "Epoch:  0055 D loss:-0.7258 G loss:-2.115\n",
      "Epoch:  0055 D loss:-0.6084 G loss:-2.048\n",
      "Epoch:  0055 D loss:-0.647 G loss:-1.965\n",
      "Epoch:  0055 D loss:-0.5264 G loss:-1.996\n",
      "Epoch:  0055 D loss:-0.5911 G loss:-2.314\n",
      "Epoch:  0055 D loss:-0.6392 G loss:-2.066\n",
      "Epoch:  0055 D loss:-0.5933 G loss:-2.186\n",
      "Epoch:  0055 D loss:-0.6788 G loss:-2.434\n",
      "Epoch:  0055 D loss:-0.654 G loss:-2.409\n",
      "Epoch:  0055 D loss:-0.6535 G loss:-2.24\n",
      "Epoch:  0055 D loss:-0.6732 G loss:-2.249\n",
      "Epoch:  0055 D loss:-0.6173 G loss:-2.288\n",
      "Epoch:  0055 D loss:-0.6284 G loss:-2.414\n",
      "Epoch:  0055 D loss:-0.5836 G loss:-2.275\n",
      "Epoch:  0055 D loss:-0.6029 G loss:-2.275\n",
      "Epoch:  0055 D loss:-0.669 G loss:-1.846\n",
      "Epoch:  0055 D loss:-0.5663 G loss:-1.996\n",
      "Epoch:  0055 D loss:-0.6347 G loss:-1.996\n",
      "Epoch:  0055 D loss:-0.6173 G loss:-1.954\n",
      "Epoch:  0055 D loss:-0.6259 G loss:-1.976\n",
      "Epoch:  0055 D loss:-0.7253 G loss:-2.159\n",
      "Epoch:  0055 D loss:-0.7306 G loss:-2.046\n",
      "Epoch:  0055 D loss:-0.7922 G loss:-1.874\n",
      "Epoch:  0055 D loss:-0.6849 G loss:-2.121\n",
      "Epoch:  0055 D loss:-0.5961 G loss:-2.178\n",
      "Epoch:  0055 D loss:-0.5949 G loss:-2.442\n",
      "Epoch:  0055 D loss:-0.7688 G loss:-2.22\n",
      "Epoch:  0055 D loss:-0.5099 G loss:-2.508\n",
      "Epoch:  0055 D loss:-0.6832 G loss:-2.228\n",
      "Epoch:  0055 D loss:-0.5265 G loss:-2.455\n",
      "Epoch:  0055 D loss:-0.6836 G loss:-2.295\n",
      "Epoch:  0055 D loss:-0.6495 G loss:-2.283\n",
      "Epoch:  0055 D loss:-0.7693 G loss:-2.193\n",
      "Epoch:  0055 D loss:-0.6156 G loss:-2.064\n",
      "Epoch:  0055 D loss:-0.5309 G loss:-2.236\n",
      "Epoch:  0055 D loss:-0.6373 G loss:-1.99\n",
      "Epoch:  0055 D loss:-0.6278 G loss:-1.949\n",
      "Epoch:  0055 D loss:-0.7059 G loss:-1.899\n",
      "Epoch:  0055 D loss:-0.6362 G loss:-1.911\n",
      "Epoch:  0055 D loss:-0.6411 G loss:-1.808\n",
      "Epoch:  0055 D loss:-0.7274 G loss:-2.075\n",
      "Epoch:  0055 D loss:-0.683 G loss:-1.927\n",
      "Epoch:  0055 D loss:-0.6377 G loss:-1.901\n",
      "Epoch:  0055 D loss:-0.7083 G loss:-2.041\n",
      "Epoch:  0055 D loss:-0.6629 G loss:-2.269\n",
      "Epoch:  0055 D loss:-0.6716 G loss:-2.068\n",
      "Epoch:  0055 D loss:-0.7594 G loss:-2.11\n",
      "Epoch:  0055 D loss:-0.6669 G loss:-2.041\n",
      "Epoch:  0055 D loss:-0.7679 G loss:-2.071\n",
      "Epoch:  0055 D loss:-0.6141 G loss:-2.319\n",
      "Epoch:  0055 D loss:-0.5787 G loss:-2.173\n",
      "Epoch:  0055 D loss:-0.6495 G loss:-2.247\n",
      "Epoch:  0055 D loss:-0.5074 G loss:-2.052\n",
      "Epoch:  0055 D loss:-0.7179 G loss:-1.925\n",
      "Epoch:  0055 D loss:-0.7014 G loss:-2.025\n",
      "Epoch:  0055 D loss:-0.7694 G loss:-2.081\n",
      "Epoch:  0055 D loss:-0.7135 G loss:-1.954\n",
      "Epoch:  0055 D loss:-0.588 G loss:-2.179\n",
      "Epoch:  0055 D loss:-0.618 G loss:-2.265\n",
      "Epoch:  0055 D loss:-0.6156 G loss:-1.962\n",
      "Epoch:  0055 D loss:-0.6175 G loss:-2.148\n",
      "Epoch:  0055 D loss:-0.6061 G loss:-2.195\n",
      "Epoch:  0055 D loss:-0.6291 G loss:-2.02\n",
      "Epoch:  0055 D loss:-0.6043 G loss:-2.151\n",
      "Epoch:  0055 D loss:-0.6188 G loss:-2.097\n",
      "Epoch:  0055 D loss:-0.5398 G loss:-2.166\n",
      "Epoch:  0055 D loss:-0.637 G loss:-1.975\n",
      "Epoch:  0055 D loss:-0.5556 G loss:-2.272\n",
      "Epoch:  0055 D loss:-0.6933 G loss:-2.268\n",
      "Epoch:  0055 D loss:-0.5411 G loss:-2.242\n",
      "Epoch:  0055 D loss:-0.623 G loss:-2.255\n",
      "Epoch:  0055 D loss:-0.6726 G loss:-2.384\n",
      "Epoch:  0055 D loss:-0.6866 G loss:-2.043\n",
      "Epoch:  0055 D loss:-0.7404 G loss:-2.116\n",
      "Epoch:  0055 D loss:-0.6429 G loss:-2.147\n",
      "Epoch:  0055 D loss:-0.5768 G loss:-1.993\n",
      "Epoch:  0055 D loss:-0.4984 G loss:-2.049\n",
      "Epoch:  0055 D loss:-0.8136 G loss:-1.711\n",
      "Epoch:  0055 D loss:-0.6215 G loss:-1.899\n",
      "Epoch:  0055 D loss:-0.5974 G loss:-2.044\n",
      "Epoch:  0055 D loss:-0.633 G loss:-2.015\n",
      "Epoch:  0055 D loss:-0.4519 G loss:-2.22\n",
      "Epoch:  0055 D loss:-0.6714 G loss:-2.191\n",
      "Epoch:  0055 D loss:-0.5962 G loss:-2.23\n",
      "Epoch:  0055 D loss:-0.7335 G loss:-2.059\n",
      "Epoch:  0055 D loss:-0.6203 G loss:-2.234\n",
      "Epoch:  0055 D loss:-0.6912 G loss:-2.188\n",
      "Epoch:  0055 D loss:-0.6168 G loss:-2.085\n",
      "Epoch:  0055 D loss:-0.664 G loss:-2.148\n",
      "Epoch:  0055 D loss:-0.547 G loss:-2.221\n",
      "Epoch:  0055 D loss:-0.7849 G loss:-2.0\n",
      "Epoch:  0055 D loss:-0.573 G loss:-2.056\n",
      "Epoch:  0055 D loss:-0.7049 G loss:-1.987\n",
      "Epoch:  0055 D loss:-0.6343 G loss:-2.015\n",
      "Epoch:  0055 D loss:-0.7003 G loss:-1.754\n",
      "Epoch:  0055 D loss:-0.6301 G loss:-1.992\n",
      "Epoch:  0055 D loss:-0.6346 G loss:-1.921\n",
      "Epoch:  0055 D loss:-0.6244 G loss:-2.267\n",
      "Epoch:  0055 D loss:-0.678 G loss:-2.098\n",
      "Epoch:  0055 D loss:-0.5852 G loss:-2.109\n",
      "Epoch:  0055 D loss:-0.631 G loss:-1.967\n",
      "Epoch:  0055 D loss:-0.6513 G loss:-2.288\n",
      "Epoch:  0055 D loss:-0.5805 G loss:-1.902\n",
      "Epoch:  0055 D loss:-0.7514 G loss:-2.094\n",
      "Epoch:  0055 D loss:-0.5936 G loss:-2.304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0055 D loss:-0.7197 G loss:-2.044\n",
      "Epoch:  0055 D loss:-0.6115 G loss:-2.211\n",
      "Epoch:  0055 D loss:-0.7138 G loss:-2.093\n",
      "Epoch:  0055 D loss:-0.7508 G loss:-2.138\n",
      "Epoch:  0055 D loss:-0.7227 G loss:-1.867\n",
      "Epoch:  0055 D loss:-0.5129 G loss:-2.064\n",
      "Epoch:  0055 D loss:-0.6875 G loss:-1.965\n",
      "Epoch:  0055 D loss:-0.5675 G loss:-2.279\n",
      "Epoch:  0055 D loss:-0.7694 G loss:-1.898\n",
      "Epoch:  0055 D loss:-0.564 G loss:-2.054\n",
      "Epoch:  0055 D loss:-0.717 G loss:-2.066\n",
      "Epoch:  0055 D loss:-0.5986 G loss:-2.21\n",
      "Epoch:  0055 D loss:-0.541 G loss:-2.243\n",
      "Epoch:  0055 D loss:-0.556 G loss:-2.272\n",
      "Epoch:  0055 D loss:-0.6605 G loss:-2.202\n",
      "Epoch:  0055 D loss:-0.5854 G loss:-2.426\n",
      "Epoch:  0055 D loss:-0.6317 G loss:-2.452\n",
      "Epoch:  0055 D loss:-0.6101 G loss:-2.39\n",
      "Epoch:  0055 D loss:-0.7815 G loss:-2.192\n",
      "Epoch:  0055 D loss:-0.6167 G loss:-2.173\n",
      "Epoch:  0055 D loss:-0.5746 G loss:-2.227\n",
      "Epoch:  0055 D loss:-0.404 G loss:-2.168\n",
      "Epoch:  0055 D loss:-0.7809 G loss:-2.145\n",
      "Epoch:  0055 D loss:-0.6033 G loss:-2.08\n",
      "Epoch:  0055 D loss:-0.6353 G loss:-2.052\n",
      "Epoch:  0055 D loss:-0.6657 G loss:-2.001\n",
      "Epoch:  0055 D loss:-0.5281 G loss:-2.018\n",
      "Epoch:  0055 D loss:-0.7474 G loss:-2.064\n",
      "Epoch:  0055 D loss:-0.4871 G loss:-2.052\n",
      "Epoch:  0055 D loss:-0.6623 G loss:-2.213\n",
      "Epoch:  0055 D loss:-0.4613 G loss:-2.382\n",
      "Epoch:  0055 D loss:-0.5822 G loss:-2.24\n",
      "Epoch:  0055 D loss:-0.5358 G loss:-2.523\n",
      "Epoch:  0055 D loss:-0.6589 G loss:-2.403\n",
      "Epoch:  0055 D loss:-0.8053 G loss:-2.148\n",
      "Epoch:  0055 D loss:-0.6488 G loss:-2.375\n",
      "Epoch:  0055 D loss:-0.7315 G loss:-2.124\n",
      "Epoch:  0055 D loss:-0.6877 G loss:-2.232\n",
      "Epoch:  0055 D loss:-0.7816 G loss:-1.992\n",
      "Epoch:  0055 D loss:-0.6529 G loss:-2.007\n",
      "Epoch:  0055 D loss:-0.6864 G loss:-1.965\n",
      "Epoch:  0055 D loss:-0.6211 G loss:-2.023\n",
      "Epoch:  0055 D loss:-0.5456 G loss:-2.136\n",
      "Epoch:  0055 D loss:-0.6411 G loss:-2.009\n",
      "Epoch:  0055 D loss:-0.5775 G loss:-1.946\n",
      "Epoch:  0055 D loss:-0.7197 G loss:-2.001\n",
      "Epoch:  0055 D loss:-0.6786 G loss:-2.286\n",
      "Epoch:  0055 D loss:-0.7894 G loss:-2.263\n",
      "Epoch:  0055 D loss:-0.6686 G loss:-2.359\n",
      "Epoch:  0055 D loss:-0.7027 G loss:-2.174\n",
      "Epoch:  0055 D loss:-0.653 G loss:-2.074\n",
      "Epoch:  0055 D loss:-0.6115 G loss:-2.322\n",
      "Epoch:  0055 D loss:-0.6496 G loss:-2.207\n",
      "Epoch:  0055 D loss:-0.4344 G loss:-2.303\n",
      "Epoch:  0055 D loss:-0.5607 G loss:-2.171\n",
      "Epoch:  0055 D loss:-0.6331 G loss:-2.381\n",
      "Epoch:  0055 D loss:-0.5963 G loss:-2.056\n",
      "Epoch:  0055 D loss:-0.6259 G loss:-2.155\n",
      "Epoch:  0055 D loss:-0.7403 G loss:-1.969\n",
      "Epoch:  0055 D loss:-0.6663 G loss:-2.128\n",
      "Epoch:  0055 D loss:-0.6409 G loss:-2.224\n",
      "Epoch:  0055 D loss:-0.7591 G loss:-2.138\n",
      "Epoch:  0055 D loss:-0.72 G loss:-2.146\n",
      "Epoch:  0055 D loss:-0.7458 G loss:-2.046\n",
      "Epoch:  0055 D loss:-0.6685 G loss:-2.005\n",
      "Epoch:  0055 D loss:-0.71 G loss:-2.262\n",
      "Epoch:  0055 D loss:-0.6076 G loss:-2.164\n",
      "Epoch:  0055 D loss:-0.714 G loss:-2.069\n",
      "Epoch:  0055 D loss:-0.7758 G loss:-1.976\n",
      "Epoch:  0055 D loss:-0.5853 G loss:-2.145\n",
      "Epoch:  0055 D loss:-0.7194 G loss:-2.28\n",
      "Epoch:  0055 D loss:-0.7042 G loss:-2.102\n",
      "Epoch:  0055 D loss:-0.6201 G loss:-2.301\n",
      "Epoch:  0055 D loss:-0.7116 G loss:-2.023\n",
      "Epoch:  0055 D loss:-0.6139 G loss:-1.843\n",
      "Epoch:  0055 D loss:-0.6347 G loss:-2.127\n",
      "Epoch:  0055 D loss:-0.6954 G loss:-1.915\n",
      "Epoch:  0055 D loss:-0.8105 G loss:-1.937\n",
      "Epoch:  0055 D loss:-0.6129 G loss:-2.131\n",
      "Epoch:  0055 D loss:-0.6563 G loss:-2.117\n",
      "Epoch:  0055 D loss:-0.6593 G loss:-2.139\n",
      "Epoch:  0055 D loss:-0.5404 G loss:-2.393\n",
      "Epoch:  0055 D loss:-0.7374 G loss:-2.136\n",
      "Epoch:  0055 D loss:-0.6192 G loss:-2.045\n",
      "Epoch:  0055 D loss:-0.6224 G loss:-2.035\n",
      "Epoch:  0055 D loss:-0.73 G loss:-2.301\n",
      "Epoch:  0055 D loss:-0.5701 G loss:-2.421\n",
      "Epoch:  0055 D loss:-0.6147 G loss:-2.46\n",
      "Epoch:  0055 D loss:-0.7922 G loss:-2.102\n",
      "Epoch:  0055 D loss:-0.629 G loss:-2.09\n",
      "Epoch:  0055 D loss:-0.5698 G loss:-2.094\n",
      "Epoch:  0055 D loss:-0.6708 G loss:-2.278\n",
      "Epoch:  0055 D loss:-0.6726 G loss:-2.011\n",
      "Epoch:  0055 D loss:-0.7132 G loss:-2.139\n",
      "Epoch:  0055 D loss:-0.6924 G loss:-1.972\n",
      "Epoch:  0055 D loss:-0.791 G loss:-2.172\n",
      "Epoch:  0055 D loss:-0.5949 G loss:-2.177\n",
      "Epoch:  0055 D loss:-0.7348 G loss:-2.126\n",
      "Epoch:  0055 D loss:-0.6522 G loss:-2.272\n",
      "Epoch:  0055 D loss:-0.77 G loss:-2.052\n",
      "Epoch:  0055 D loss:-0.5523 G loss:-2.228\n",
      "Epoch:  0055 D loss:-0.5901 G loss:-2.189\n",
      "Epoch:  0055 D loss:-0.6015 G loss:-1.916\n",
      "Epoch:  0055 D loss:-0.7473 G loss:-1.878\n",
      "Epoch:  0055 D loss:-0.7066 G loss:-1.907\n",
      "Epoch:  0055 D loss:-0.6227 G loss:-2.161\n",
      "Epoch:  0055 D loss:-0.6036 G loss:-2.321\n",
      "Epoch:  0055 D loss:-0.7502 G loss:-2.36\n",
      "Epoch:  0055 D loss:-0.7313 G loss:-2.047\n",
      "Epoch:  0055 D loss:-0.7024 G loss:-2.249\n",
      "Epoch:  0055 D loss:-0.6233 G loss:-2.23\n",
      "Epoch:  0055 D loss:-0.7154 G loss:-2.315\n",
      "Epoch:  0055 D loss:-0.6872 G loss:-2.272\n",
      "Epoch:  0055 D loss:-0.6434 G loss:-2.484\n",
      "Epoch:  0055 D loss:-0.8679 G loss:-2.006\n",
      "Epoch:  0055 D loss:-0.7854 G loss:-2.109\n",
      "Epoch:  0055 D loss:-0.6821 G loss:-1.989\n",
      "Epoch:  0055 D loss:-0.7244 G loss:-2.173\n",
      "Epoch:  0055 D loss:-0.795 G loss:-1.812\n",
      "Epoch:  0055 D loss:-0.6972 G loss:-2.079\n",
      "Epoch:  0055 D loss:-0.5543 G loss:-2.188\n",
      "Epoch:  0055 D loss:-0.6678 G loss:-2.305\n",
      "Epoch:  0055 D loss:-0.6438 G loss:-1.953\n",
      "Epoch:  0055 D loss:-0.74 G loss:-2.132\n",
      "Epoch:  0055 D loss:-0.7003 G loss:-1.9\n",
      "Epoch:  0055 D loss:-0.7008 G loss:-1.987\n",
      "Epoch:  0055 D loss:-0.5659 G loss:-2.052\n",
      "Epoch:  0055 D loss:-0.5735 G loss:-2.234\n",
      "Epoch:  0055 D loss:-0.7353 G loss:-2.046\n",
      "Epoch:  0055 D loss:-0.6566 G loss:-2.182\n",
      "Epoch:  0055 D loss:-0.7251 G loss:-2.158\n",
      "Epoch:  0055 D loss:-0.5181 G loss:-2.261\n",
      "Epoch:  0055 D loss:-0.6816 G loss:-2.248\n",
      "Epoch:  0055 D loss:-0.5705 G loss:-2.445\n",
      "Epoch:  0055 D loss:-0.6715 G loss:-2.204\n",
      "Epoch:  0055 D loss:-0.6473 G loss:-2.195\n",
      "Epoch:  0055 D loss:-0.6534 G loss:-2.177\n",
      "Epoch:  0055 D loss:-0.6016 G loss:-2.207\n",
      "Epoch:  0055 D loss:-0.7916 G loss:-1.91\n",
      "Epoch:  0055 D loss:-0.6097 G loss:-2.051\n",
      "Epoch:  0055 D loss:-0.6638 G loss:-1.699\n",
      "Epoch:  0055 D loss:-0.6998 G loss:-1.926\n",
      "Epoch:  0055 D loss:-0.5802 G loss:-1.931\n",
      "Epoch:  0055 D loss:-0.6906 G loss:-2.157\n",
      "Epoch:  0055 D loss:-0.7217 G loss:-2.121\n",
      "Epoch:  0055 D loss:-0.7346 G loss:-2.242\n",
      "Epoch:  0055 D loss:-0.6133 G loss:-2.085\n",
      "Epoch:  0055 D loss:-0.6591 G loss:-2.262\n",
      "Epoch:  0055 D loss:-0.7054 G loss:-2.014\n",
      "Epoch:  0055 D loss:-0.5998 G loss:-2.253\n",
      "Epoch:  0055 D loss:-0.5899 G loss:-2.093\n",
      "Epoch:  0055 D loss:-0.6526 G loss:-2.187\n",
      "Epoch:  0055 D loss:-0.6512 G loss:-2.008\n",
      "Epoch:  0055 D loss:-0.7036 G loss:-2.064\n",
      "Epoch:  0055 D loss:-0.8322 G loss:-1.9\n",
      "Epoch:  0055 D loss:-0.706 G loss:-1.963\n",
      "Epoch:  0055 D loss:-0.5867 G loss:-2.121\n",
      "Epoch:  0055 D loss:-0.6244 G loss:-2.023\n",
      "Epoch:  0055 D loss:-0.7694 G loss:-2.132\n",
      "Epoch:  0055 D loss:-0.6334 G loss:-2.283\n",
      "Epoch:  0055 D loss:-0.7209 G loss:-2.067\n",
      "Epoch:  0055 D loss:-0.6391 G loss:-2.296\n",
      "Epoch:  0055 D loss:-0.6884 G loss:-2.131\n",
      "Epoch:  0055 D loss:-0.5157 G loss:-2.301\n",
      "Epoch:  0055 D loss:-0.6229 G loss:-2.046\n",
      "Epoch:  0055 D loss:-0.8636 G loss:-2.023\n",
      "Epoch:  0055 D loss:-0.6542 G loss:-2.0\n",
      "Epoch:  0055 D loss:-0.6897 G loss:-2.129\n",
      "Epoch:  0055 D loss:-0.7789 G loss:-2.084\n",
      "Epoch:  0055 D loss:-0.5876 G loss:-2.28\n",
      "Epoch:  0055 D loss:-0.8116 G loss:-1.996\n",
      "Epoch:  0055 D loss:-0.7852 G loss:-1.999\n",
      "Epoch:  0055 D loss:-0.7179 G loss:-1.9\n",
      "Epoch:  0055 D loss:-0.6725 G loss:-2.086\n",
      "Epoch:  0055 D loss:-0.7728 G loss:-1.887\n",
      "Epoch:  0055 D loss:-0.8811 G loss:-1.555\n",
      "Epoch:  0055 D loss:-0.7679 G loss:-1.918\n",
      "Epoch:  0055 D loss:-0.6504 G loss:-1.952\n",
      "Epoch:  0055 D loss:-0.661 G loss:-1.992\n",
      "Epoch:  0055 D loss:-0.7616 G loss:-1.809\n",
      "Epoch:  0055 D loss:-0.7962 G loss:-1.88\n",
      "Epoch:  0055 D loss:-0.9087 G loss:-2.083\n",
      "Epoch:  0055 D loss:-0.6832 G loss:-2.014\n",
      "Epoch:  0055 D loss:-0.6853 G loss:-1.947\n",
      "Epoch:  0055 D loss:-0.6313 G loss:-2.19\n",
      "Epoch:  0055 D loss:-0.7025 G loss:-2.331\n",
      "Epoch:  0055 D loss:-0.6795 G loss:-2.232\n",
      "Epoch:  0055 D loss:-0.5984 G loss:-2.076\n",
      "Epoch:  0055 D loss:-0.5907 G loss:-2.206\n",
      "Epoch:  0055 D loss:-0.6357 G loss:-1.981\n",
      "Epoch:  0055 D loss:-0.6347 G loss:-2.063\n",
      "Epoch:  0055 D loss:-0.5483 G loss:-2.072\n",
      "Epoch:  0055 D loss:-0.6685 G loss:-1.942\n",
      "Epoch:  0055 D loss:-0.6367 G loss:-2.313\n",
      "Epoch:  0055 D loss:-0.5895 G loss:-2.121\n",
      "Epoch:  0055 D loss:-0.6194 G loss:-2.048\n",
      "Epoch:  0055 D loss:-0.7371 G loss:-2.101\n",
      "Epoch:  0055 D loss:-0.6243 G loss:-2.027\n",
      "Epoch:  0055 D loss:-0.6739 G loss:-2.032\n",
      "Epoch:  0055 D loss:-0.6366 G loss:-2.138\n",
      "Epoch:  0055 D loss:-0.5608 G loss:-2.041\n",
      "Epoch:  0055 D loss:-0.6164 G loss:-2.06\n",
      "Epoch:  0055 D loss:-0.5376 G loss:-2.141\n",
      "Epoch:  0055 D loss:-0.5491 G loss:-2.181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0055 D loss:-0.5468 G loss:-2.272\n",
      "Epoch:  0055 D loss:-0.6448 G loss:-2.308\n",
      "Epoch:  0055 D loss:-0.5581 G loss:-2.354\n",
      "Epoch:  0055 D loss:-0.6038 G loss:-2.328\n",
      "Epoch:  0055 D loss:-0.6578 G loss:-2.236\n",
      "Epoch:  0055 D loss:-0.7337 G loss:-2.251\n",
      "Epoch:  0055 D loss:-0.5465 G loss:-2.324\n",
      "Epoch:  0055 D loss:-0.6345 G loss:-2.176\n",
      "Epoch:  0055 D loss:-0.6815 G loss:-2.093\n",
      "Epoch:  0055 D loss:-0.5563 G loss:-2.106\n",
      "Epoch:  0055 D loss:-0.6262 G loss:-1.93\n",
      "Epoch:  0055 D loss:-0.5947 G loss:-2.0\n",
      "Epoch:  0055 D loss:-0.623 G loss:-2.213\n",
      "Epoch:  0055 D loss:-0.5834 G loss:-2.02\n",
      "Epoch:  0055 D loss:-0.4925 G loss:-2.328\n",
      "Epoch:  0055 D loss:-0.691 G loss:-2.187\n",
      "Epoch:  0055 D loss:-0.5101 G loss:-2.356\n",
      "Epoch:  0055 D loss:-0.5412 G loss:-2.275\n",
      "Epoch:  0055 D loss:-0.6112 G loss:-2.177\n",
      "Epoch:  0055 D loss:-0.5791 G loss:-2.366\n",
      "Epoch:  0055 D loss:-0.583 G loss:-2.283\n",
      "Epoch:  0055 D loss:-0.5275 G loss:-2.076\n",
      "Epoch:  0055 D loss:-0.6749 G loss:-2.191\n",
      "Epoch:  0055 D loss:-0.5652 G loss:-2.22\n",
      "Epoch:  0055 D loss:-0.5647 G loss:-2.154\n",
      "Epoch:  0055 D loss:-0.62 G loss:-2.182\n",
      "Epoch:  0055 D loss:-0.5315 G loss:-2.228\n",
      "Epoch:  0055 D loss:-0.6439 G loss:-2.445\n",
      "Epoch:  0055 D loss:-0.5936 G loss:-2.31\n",
      "Epoch:  0055 D loss:-0.6678 G loss:-2.33\n",
      "Epoch:  0055 D loss:-0.4925 G loss:-2.388\n",
      "Epoch:  0055 D loss:-0.5118 G loss:-2.296\n",
      "Epoch:  0055 D loss:-0.5939 G loss:-2.147\n",
      "Epoch:  0055 D loss:-0.5922 G loss:-2.116\n",
      "Epoch:  0055 D loss:-0.5737 G loss:-2.088\n",
      "Epoch:  0055 D loss:-0.7528 G loss:-2.093\n",
      "Epoch:  0055 D loss:-0.6532 G loss:-2.116\n",
      "Epoch:  0055 D loss:-0.6808 G loss:-2.064\n",
      "Epoch:  0055 D loss:-0.5486 G loss:-2.111\n",
      "Epoch:  0055 D loss:-0.5736 G loss:-1.94\n",
      "Epoch:  0055 D loss:-0.6692 G loss:-1.987\n",
      "Epoch:  0055 D loss:-0.5699 G loss:-2.011\n",
      "Epoch:  0055 D loss:-0.639 G loss:-2.178\n",
      "Epoch:  0055 D loss:-0.6828 G loss:-2.136\n",
      "Epoch:  0055 D loss:-0.5639 G loss:-2.163\n",
      "Epoch:  0055 D loss:-0.5352 G loss:-2.261\n",
      "Epoch:  0055 D loss:-0.6032 G loss:-2.136\n",
      "Epoch:  0055 D loss:-0.5551 G loss:-2.245\n",
      "Epoch:  0055 D loss:-0.4413 G loss:-2.348\n",
      "Epoch:  0055 D loss:-0.5203 G loss:-2.178\n",
      "Epoch:  0055 D loss:-0.5455 G loss:-2.37\n",
      "Epoch:  0055 D loss:-0.5488 G loss:-2.206\n",
      "Epoch:  0055 D loss:-0.5774 G loss:-2.475\n",
      "Epoch:  0055 D loss:-0.4753 G loss:-2.234\n",
      "Epoch:  0055 D loss:-0.697 G loss:-2.181\n",
      "Epoch:  0055 D loss:-0.6948 G loss:-2.044\n",
      "Epoch:  0055 D loss:-0.6735 G loss:-2.305\n",
      "Epoch:  0055 D loss:-0.7804 G loss:-2.144\n",
      "Epoch:  0055 D loss:-0.5808 G loss:-2.207\n",
      "Epoch:  0055 D loss:-0.6314 G loss:-1.945\n",
      "Epoch:  0055 D loss:-0.6011 G loss:-1.972\n",
      "Epoch:  0055 D loss:-0.7614 G loss:-2.173\n",
      "Epoch:  0055 D loss:-0.6577 G loss:-2.144\n",
      "Epoch:  0055 D loss:-0.618 G loss:-2.041\n",
      "Epoch:  0055 D loss:-0.6864 G loss:-1.943\n",
      "Epoch:  0055 D loss:-0.5256 G loss:-2.285\n",
      "Epoch:  0055 D loss:-0.7436 G loss:-2.021\n",
      "Epoch:  0055 D loss:-0.641 G loss:-2.172\n",
      "Epoch:  0055 D loss:-0.5558 G loss:-2.212\n",
      "Epoch:  0055 D loss:-0.6589 G loss:-2.088\n",
      "Epoch:  0055 D loss:-0.6267 G loss:-1.996\n",
      "Epoch:  0055 D loss:-0.6453 G loss:-2.097\n",
      "Epoch:  0055 D loss:-0.6723 G loss:-2.23\n",
      "Epoch:  0055 D loss:-0.7602 G loss:-2.024\n",
      "Epoch:  0055 D loss:-0.7377 G loss:-2.101\n",
      "Epoch:  0056 D loss:-0.7502 G loss:-2.145\n",
      "Epoch:  0056 D loss:-0.6072 G loss:-2.018\n",
      "Epoch:  0056 D loss:-0.6285 G loss:-2.046\n",
      "Epoch:  0056 D loss:-0.6251 G loss:-1.962\n",
      "Epoch:  0056 D loss:-0.637 G loss:-2.177\n",
      "Epoch:  0056 D loss:-0.6516 G loss:-2.059\n",
      "Epoch:  0056 D loss:-0.5369 G loss:-2.029\n",
      "Epoch:  0056 D loss:-0.7016 G loss:-2.018\n",
      "Epoch:  0056 D loss:-0.6807 G loss:-1.968\n",
      "Epoch:  0056 D loss:-0.707 G loss:-1.979\n",
      "Epoch:  0056 D loss:-0.7241 G loss:-2.051\n",
      "Epoch:  0056 D loss:-0.5309 G loss:-2.224\n",
      "Epoch:  0056 D loss:-0.6852 G loss:-1.989\n",
      "Epoch:  0056 D loss:-0.6843 G loss:-2.184\n",
      "Epoch:  0056 D loss:-0.7501 G loss:-2.286\n",
      "Epoch:  0056 D loss:-0.5787 G loss:-2.341\n",
      "Epoch:  0056 D loss:-0.6687 G loss:-2.049\n",
      "Epoch:  0056 D loss:-0.7323 G loss:-2.089\n",
      "Epoch:  0056 D loss:-0.6443 G loss:-2.402\n",
      "Epoch:  0056 D loss:-0.7028 G loss:-2.023\n",
      "Epoch:  0056 D loss:-0.7256 G loss:-1.865\n",
      "Epoch:  0056 D loss:-0.6184 G loss:-2.067\n",
      "Epoch:  0056 D loss:-0.6676 G loss:-2.255\n",
      "Epoch:  0056 D loss:-0.7095 G loss:-2.179\n",
      "Epoch:  0056 D loss:-0.8228 G loss:-2.084\n",
      "Epoch:  0056 D loss:-0.7585 G loss:-2.083\n",
      "Epoch:  0056 D loss:-0.6802 G loss:-2.058\n",
      "Epoch:  0056 D loss:-0.7163 G loss:-1.926\n",
      "Epoch:  0056 D loss:-0.7395 G loss:-1.907\n",
      "Epoch:  0056 D loss:-0.651 G loss:-2.083\n",
      "Epoch:  0056 D loss:-0.6948 G loss:-2.097\n",
      "Epoch:  0056 D loss:-0.6469 G loss:-1.938\n",
      "Epoch:  0056 D loss:-0.6084 G loss:-2.196\n",
      "Epoch:  0056 D loss:-0.5858 G loss:-2.151\n",
      "Epoch:  0056 D loss:-0.6137 G loss:-2.183\n",
      "Epoch:  0056 D loss:-0.6135 G loss:-2.189\n",
      "Epoch:  0056 D loss:-0.6658 G loss:-1.956\n",
      "Epoch:  0056 D loss:-0.7029 G loss:-2.129\n",
      "Epoch:  0056 D loss:-0.6577 G loss:-2.133\n",
      "Epoch:  0056 D loss:-0.5958 G loss:-2.047\n",
      "Epoch:  0056 D loss:-0.7501 G loss:-1.99\n",
      "Epoch:  0056 D loss:-0.6645 G loss:-2.235\n",
      "Epoch:  0056 D loss:-0.8263 G loss:-1.996\n",
      "Epoch:  0056 D loss:-0.664 G loss:-2.211\n",
      "Epoch:  0056 D loss:-0.6919 G loss:-2.051\n",
      "Epoch:  0056 D loss:-0.7932 G loss:-2.104\n",
      "Epoch:  0056 D loss:-0.6408 G loss:-2.022\n",
      "Epoch:  0056 D loss:-0.6982 G loss:-2.127\n",
      "Epoch:  0056 D loss:-0.7019 G loss:-1.888\n",
      "Epoch:  0056 D loss:-0.8195 G loss:-1.741\n",
      "Epoch:  0056 D loss:-0.8808 G loss:-1.797\n",
      "Epoch:  0056 D loss:-0.566 G loss:-2.073\n",
      "Epoch:  0056 D loss:-0.616 G loss:-1.966\n",
      "Epoch:  0056 D loss:-0.5782 G loss:-2.143\n",
      "Epoch:  0056 D loss:-0.6939 G loss:-1.943\n",
      "Epoch:  0056 D loss:-0.6209 G loss:-2.182\n",
      "Epoch:  0056 D loss:-0.6766 G loss:-2.362\n",
      "Epoch:  0056 D loss:-0.8095 G loss:-2.133\n",
      "Epoch:  0056 D loss:-0.596 G loss:-2.252\n",
      "Epoch:  0056 D loss:-0.4854 G loss:-2.353\n",
      "Epoch:  0056 D loss:-0.778 G loss:-2.149\n",
      "Epoch:  0056 D loss:-0.6979 G loss:-1.928\n",
      "Epoch:  0056 D loss:-0.6558 G loss:-1.977\n",
      "Epoch:  0056 D loss:-0.7486 G loss:-2.003\n",
      "Epoch:  0056 D loss:-0.594 G loss:-1.859\n",
      "Epoch:  0056 D loss:-0.7667 G loss:-1.953\n",
      "Epoch:  0056 D loss:-0.5762 G loss:-2.226\n",
      "Epoch:  0056 D loss:-0.6299 G loss:-2.164\n",
      "Epoch:  0056 D loss:-0.7811 G loss:-2.012\n",
      "Epoch:  0056 D loss:-0.7961 G loss:-1.978\n",
      "Epoch:  0056 D loss:-0.6097 G loss:-2.144\n",
      "Epoch:  0056 D loss:-0.6921 G loss:-2.198\n",
      "Epoch:  0056 D loss:-0.7908 G loss:-2.137\n",
      "Epoch:  0056 D loss:-0.6206 G loss:-2.355\n",
      "Epoch:  0056 D loss:-0.6699 G loss:-2.296\n",
      "Epoch:  0056 D loss:-0.4903 G loss:-2.163\n",
      "Epoch:  0056 D loss:-0.6686 G loss:-2.149\n",
      "Epoch:  0056 D loss:-0.5772 G loss:-2.327\n",
      "Epoch:  0056 D loss:-0.7004 G loss:-1.963\n",
      "Epoch:  0056 D loss:-0.6572 G loss:-1.985\n",
      "Epoch:  0056 D loss:-0.5815 G loss:-2.073\n",
      "Epoch:  0056 D loss:-0.7188 G loss:-2.088\n",
      "Epoch:  0056 D loss:-0.6846 G loss:-2.086\n",
      "Epoch:  0056 D loss:-0.7315 G loss:-2.12\n",
      "Epoch:  0056 D loss:-0.6751 G loss:-2.083\n",
      "Epoch:  0056 D loss:-0.5985 G loss:-2.03\n",
      "Epoch:  0056 D loss:-0.5697 G loss:-2.279\n",
      "Epoch:  0056 D loss:-0.5672 G loss:-2.096\n",
      "Epoch:  0056 D loss:-0.6351 G loss:-2.305\n",
      "Epoch:  0056 D loss:-0.5214 G loss:-2.277\n",
      "Epoch:  0056 D loss:-0.6445 G loss:-2.019\n",
      "Epoch:  0056 D loss:-0.524 G loss:-2.291\n",
      "Epoch:  0056 D loss:-0.5972 G loss:-2.168\n",
      "Epoch:  0056 D loss:-0.4798 G loss:-2.414\n",
      "Epoch:  0056 D loss:-0.527 G loss:-2.233\n",
      "Epoch:  0056 D loss:-0.6472 G loss:-2.08\n",
      "Epoch:  0056 D loss:-0.6172 G loss:-2.094\n",
      "Epoch:  0056 D loss:-0.719 G loss:-2.22\n",
      "Epoch:  0056 D loss:-0.7685 G loss:-2.277\n",
      "Epoch:  0056 D loss:-0.5879 G loss:-2.308\n",
      "Epoch:  0056 D loss:-0.5135 G loss:-2.254\n",
      "Epoch:  0056 D loss:-0.7063 G loss:-2.331\n",
      "Epoch:  0056 D loss:-0.7016 G loss:-2.009\n",
      "Epoch:  0056 D loss:-0.6275 G loss:-2.123\n",
      "Epoch:  0056 D loss:-0.6548 G loss:-2.002\n",
      "Epoch:  0056 D loss:-0.6503 G loss:-2.05\n",
      "Epoch:  0056 D loss:-0.6661 G loss:-2.186\n",
      "Epoch:  0056 D loss:-0.6283 G loss:-2.027\n",
      "Epoch:  0056 D loss:-0.6007 G loss:-2.167\n",
      "Epoch:  0056 D loss:-0.6479 G loss:-1.911\n",
      "Epoch:  0056 D loss:-0.7265 G loss:-1.95\n",
      "Epoch:  0056 D loss:-0.4899 G loss:-2.385\n",
      "Epoch:  0056 D loss:-0.5048 G loss:-2.448\n",
      "Epoch:  0056 D loss:-0.553 G loss:-2.14\n",
      "Epoch:  0056 D loss:-0.4918 G loss:-2.229\n",
      "Epoch:  0056 D loss:-0.4946 G loss:-2.325\n",
      "Epoch:  0056 D loss:-0.7005 G loss:-2.18\n",
      "Epoch:  0056 D loss:-0.5738 G loss:-2.39\n",
      "Epoch:  0056 D loss:-0.6078 G loss:-2.209\n",
      "Epoch:  0056 D loss:-0.5401 G loss:-2.247\n",
      "Epoch:  0056 D loss:-0.6219 G loss:-2.176\n",
      "Epoch:  0056 D loss:-0.5227 G loss:-2.461\n",
      "Epoch:  0056 D loss:-0.632 G loss:-2.113\n",
      "Epoch:  0056 D loss:-0.6106 G loss:-2.025\n",
      "Epoch:  0056 D loss:-0.5539 G loss:-2.032\n",
      "Epoch:  0056 D loss:-0.6532 G loss:-2.419\n",
      "Epoch:  0056 D loss:-0.6813 G loss:-2.079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0056 D loss:-0.4155 G loss:-2.438\n",
      "Epoch:  0056 D loss:-0.5808 G loss:-2.213\n",
      "Epoch:  0056 D loss:-0.5739 G loss:-2.218\n",
      "Epoch:  0056 D loss:-0.5654 G loss:-2.314\n",
      "Epoch:  0056 D loss:-0.5411 G loss:-2.337\n",
      "Epoch:  0056 D loss:-0.5737 G loss:-2.204\n",
      "Epoch:  0056 D loss:-0.4882 G loss:-2.404\n",
      "Epoch:  0056 D loss:-0.475 G loss:-2.38\n",
      "Epoch:  0056 D loss:-0.4591 G loss:-2.498\n",
      "Epoch:  0056 D loss:-0.5335 G loss:-2.151\n",
      "Epoch:  0056 D loss:-0.5243 G loss:-2.423\n",
      "Epoch:  0056 D loss:-0.5355 G loss:-2.14\n",
      "Epoch:  0056 D loss:-0.5116 G loss:-2.453\n",
      "Epoch:  0056 D loss:-0.5845 G loss:-2.192\n",
      "Epoch:  0056 D loss:-0.5126 G loss:-2.421\n",
      "Epoch:  0056 D loss:-0.514 G loss:-2.369\n",
      "Epoch:  0056 D loss:-0.5369 G loss:-2.497\n",
      "Epoch:  0056 D loss:-0.7231 G loss:-1.871\n",
      "Epoch:  0056 D loss:-0.6849 G loss:-2.234\n",
      "Epoch:  0056 D loss:-0.6178 G loss:-2.144\n",
      "Epoch:  0056 D loss:-0.4524 G loss:-2.088\n",
      "Epoch:  0056 D loss:-0.4146 G loss:-2.36\n",
      "Epoch:  0056 D loss:-0.5761 G loss:-2.376\n",
      "Epoch:  0056 D loss:-0.6072 G loss:-2.376\n",
      "Epoch:  0056 D loss:-0.6706 G loss:-2.173\n",
      "Epoch:  0056 D loss:-0.486 G loss:-2.341\n",
      "Epoch:  0056 D loss:-0.6409 G loss:-2.128\n",
      "Epoch:  0056 D loss:-0.5668 G loss:-2.24\n",
      "Epoch:  0056 D loss:-0.4525 G loss:-2.263\n",
      "Epoch:  0056 D loss:-0.6461 G loss:-2.169\n",
      "Epoch:  0056 D loss:-0.5137 G loss:-2.15\n",
      "Epoch:  0056 D loss:-0.5443 G loss:-2.114\n",
      "Epoch:  0056 D loss:-0.582 G loss:-1.864\n",
      "Epoch:  0056 D loss:-0.6027 G loss:-1.975\n",
      "Epoch:  0056 D loss:-0.4936 G loss:-2.133\n",
      "Epoch:  0056 D loss:-0.6341 G loss:-2.079\n",
      "Epoch:  0056 D loss:-0.6334 G loss:-2.184\n",
      "Epoch:  0056 D loss:-0.6363 G loss:-2.265\n",
      "Epoch:  0056 D loss:-0.6027 G loss:-2.374\n",
      "Epoch:  0056 D loss:-0.6169 G loss:-2.229\n",
      "Epoch:  0056 D loss:-0.6055 G loss:-2.349\n",
      "Epoch:  0056 D loss:-0.623 G loss:-2.387\n",
      "Epoch:  0056 D loss:-0.6631 G loss:-2.187\n",
      "Epoch:  0056 D loss:-0.4677 G loss:-2.308\n",
      "Epoch:  0056 D loss:-0.6111 G loss:-2.089\n",
      "Epoch:  0056 D loss:-0.6677 G loss:-2.044\n",
      "Epoch:  0056 D loss:-0.547 G loss:-2.141\n",
      "Epoch:  0056 D loss:-0.4473 G loss:-2.297\n",
      "Epoch:  0056 D loss:-0.5102 G loss:-2.118\n",
      "Epoch:  0056 D loss:-0.6849 G loss:-2.02\n",
      "Epoch:  0056 D loss:-0.6686 G loss:-2.19\n",
      "Epoch:  0056 D loss:-0.6005 G loss:-2.092\n",
      "Epoch:  0056 D loss:-0.6572 G loss:-2.042\n",
      "Epoch:  0056 D loss:-0.579 G loss:-2.307\n",
      "Epoch:  0056 D loss:-0.6205 G loss:-2.246\n",
      "Epoch:  0056 D loss:-0.686 G loss:-2.117\n",
      "Epoch:  0056 D loss:-0.5717 G loss:-2.146\n",
      "Epoch:  0056 D loss:-0.6653 G loss:-2.432\n",
      "Epoch:  0056 D loss:-0.5658 G loss:-2.184\n",
      "Epoch:  0056 D loss:-0.544 G loss:-2.182\n",
      "Epoch:  0056 D loss:-0.6003 G loss:-2.066\n",
      "Epoch:  0056 D loss:-0.7257 G loss:-2.223\n",
      "Epoch:  0056 D loss:-0.5713 G loss:-2.318\n",
      "Epoch:  0056 D loss:-0.5762 G loss:-2.378\n",
      "Epoch:  0056 D loss:-0.5951 G loss:-1.953\n",
      "Epoch:  0056 D loss:-0.732 G loss:-2.0\n",
      "Epoch:  0056 D loss:-0.7595 G loss:-2.073\n",
      "Epoch:  0056 D loss:-0.6642 G loss:-1.792\n",
      "Epoch:  0056 D loss:-0.5517 G loss:-2.079\n",
      "Epoch:  0056 D loss:-0.5241 G loss:-1.885\n",
      "Epoch:  0056 D loss:-0.6208 G loss:-2.013\n",
      "Epoch:  0056 D loss:-0.6599 G loss:-1.987\n",
      "Epoch:  0056 D loss:-0.5699 G loss:-2.13\n",
      "Epoch:  0056 D loss:-0.5469 G loss:-2.155\n",
      "Epoch:  0056 D loss:-0.7243 G loss:-2.364\n",
      "Epoch:  0056 D loss:-0.7367 G loss:-1.941\n",
      "Epoch:  0056 D loss:-0.7339 G loss:-1.979\n",
      "Epoch:  0056 D loss:-0.8371 G loss:-2.053\n",
      "Epoch:  0056 D loss:-0.5553 G loss:-1.949\n",
      "Epoch:  0056 D loss:-0.6986 G loss:-1.957\n",
      "Epoch:  0056 D loss:-0.639 G loss:-2.059\n",
      "Epoch:  0056 D loss:-0.607 G loss:-2.359\n",
      "Epoch:  0056 D loss:-0.6097 G loss:-2.087\n",
      "Epoch:  0056 D loss:-0.5669 G loss:-2.289\n",
      "Epoch:  0056 D loss:-0.5331 G loss:-2.149\n",
      "Epoch:  0056 D loss:-0.5342 G loss:-2.153\n",
      "Epoch:  0056 D loss:-0.7861 G loss:-2.119\n",
      "Epoch:  0056 D loss:-0.6427 G loss:-2.199\n",
      "Epoch:  0056 D loss:-0.5797 G loss:-2.234\n",
      "Epoch:  0056 D loss:-0.6722 G loss:-2.202\n",
      "Epoch:  0056 D loss:-0.5829 G loss:-2.154\n",
      "Epoch:  0056 D loss:-0.6284 G loss:-2.175\n",
      "Epoch:  0056 D loss:-0.6193 G loss:-2.041\n",
      "Epoch:  0056 D loss:-0.6305 G loss:-2.183\n",
      "Epoch:  0056 D loss:-0.5904 G loss:-1.968\n",
      "Epoch:  0056 D loss:-0.6458 G loss:-2.245\n",
      "Epoch:  0056 D loss:-0.6307 G loss:-2.147\n",
      "Epoch:  0056 D loss:-0.5612 G loss:-2.114\n",
      "Epoch:  0056 D loss:-0.7546 G loss:-2.051\n",
      "Epoch:  0056 D loss:-0.656 G loss:-2.23\n",
      "Epoch:  0056 D loss:-0.6061 G loss:-2.135\n",
      "Epoch:  0056 D loss:-0.6285 G loss:-2.04\n",
      "Epoch:  0056 D loss:-0.659 G loss:-2.07\n",
      "Epoch:  0056 D loss:-0.5473 G loss:-1.956\n",
      "Epoch:  0056 D loss:-0.7261 G loss:-2.339\n",
      "Epoch:  0056 D loss:-0.5904 G loss:-2.446\n",
      "Epoch:  0056 D loss:-0.6945 G loss:-2.274\n",
      "Epoch:  0056 D loss:-0.6011 G loss:-2.328\n",
      "Epoch:  0056 D loss:-0.6388 G loss:-2.146\n",
      "Epoch:  0056 D loss:-0.4982 G loss:-2.435\n",
      "Epoch:  0056 D loss:-0.6282 G loss:-2.055\n",
      "Epoch:  0056 D loss:-0.4658 G loss:-2.186\n",
      "Epoch:  0056 D loss:-0.5441 G loss:-2.116\n",
      "Epoch:  0056 D loss:-0.7195 G loss:-2.043\n",
      "Epoch:  0056 D loss:-0.5327 G loss:-2.153\n",
      "Epoch:  0056 D loss:-0.5226 G loss:-2.212\n",
      "Epoch:  0056 D loss:-0.5341 G loss:-2.316\n",
      "Epoch:  0056 D loss:-0.6577 G loss:-2.025\n",
      "Epoch:  0056 D loss:-0.5768 G loss:-2.136\n",
      "Epoch:  0056 D loss:-0.6633 G loss:-2.136\n",
      "Epoch:  0056 D loss:-0.5964 G loss:-2.113\n",
      "Epoch:  0056 D loss:-0.5923 G loss:-2.159\n",
      "Epoch:  0056 D loss:-0.7266 G loss:-2.128\n",
      "Epoch:  0056 D loss:-0.5557 G loss:-1.948\n",
      "Epoch:  0056 D loss:-0.5298 G loss:-2.265\n",
      "Epoch:  0056 D loss:-0.4414 G loss:-2.369\n",
      "Epoch:  0056 D loss:-0.6676 G loss:-2.171\n",
      "Epoch:  0056 D loss:-0.5151 G loss:-2.497\n",
      "Epoch:  0056 D loss:-0.6402 G loss:-2.323\n",
      "Epoch:  0056 D loss:-0.5264 G loss:-2.267\n",
      "Epoch:  0056 D loss:-0.523 G loss:-2.046\n",
      "Epoch:  0056 D loss:-0.6572 G loss:-2.146\n",
      "Epoch:  0056 D loss:-0.5002 G loss:-2.22\n",
      "Epoch:  0056 D loss:-0.4724 G loss:-2.359\n",
      "Epoch:  0056 D loss:-0.6456 G loss:-2.277\n",
      "Epoch:  0056 D loss:-0.5125 G loss:-2.179\n",
      "Epoch:  0056 D loss:-0.497 G loss:-2.364\n",
      "Epoch:  0056 D loss:-0.6059 G loss:-2.322\n",
      "Epoch:  0056 D loss:-0.6606 G loss:-2.314\n",
      "Epoch:  0056 D loss:-0.6155 G loss:-2.192\n",
      "Epoch:  0056 D loss:-0.6346 G loss:-2.218\n",
      "Epoch:  0056 D loss:-0.5106 G loss:-2.078\n",
      "Epoch:  0056 D loss:-0.6838 G loss:-1.822\n",
      "Epoch:  0056 D loss:-0.4744 G loss:-2.349\n",
      "Epoch:  0056 D loss:-0.5826 G loss:-2.129\n",
      "Epoch:  0056 D loss:-0.5752 G loss:-2.35\n",
      "Epoch:  0056 D loss:-0.6833 G loss:-2.19\n",
      "Epoch:  0056 D loss:-0.5203 G loss:-2.209\n",
      "Epoch:  0056 D loss:-0.4792 G loss:-2.366\n",
      "Epoch:  0056 D loss:-0.7152 G loss:-2.125\n",
      "Epoch:  0056 D loss:-0.7189 G loss:-2.15\n",
      "Epoch:  0056 D loss:-0.5575 G loss:-2.109\n",
      "Epoch:  0056 D loss:-0.6182 G loss:-2.136\n",
      "Epoch:  0056 D loss:-0.8314 G loss:-2.205\n",
      "Epoch:  0056 D loss:-0.502 G loss:-2.151\n",
      "Epoch:  0056 D loss:-0.6738 G loss:-2.211\n",
      "Epoch:  0056 D loss:-0.589 G loss:-2.194\n",
      "Epoch:  0056 D loss:-0.6277 G loss:-2.042\n",
      "Epoch:  0056 D loss:-0.6336 G loss:-1.909\n",
      "Epoch:  0056 D loss:-0.627 G loss:-2.177\n",
      "Epoch:  0056 D loss:-0.5448 G loss:-2.252\n",
      "Epoch:  0056 D loss:-0.6704 G loss:-2.282\n",
      "Epoch:  0056 D loss:-0.5502 G loss:-2.481\n",
      "Epoch:  0056 D loss:-0.5855 G loss:-2.409\n",
      "Epoch:  0056 D loss:-0.4876 G loss:-2.167\n",
      "Epoch:  0056 D loss:-0.6341 G loss:-2.072\n",
      "Epoch:  0056 D loss:-0.6012 G loss:-2.111\n",
      "Epoch:  0056 D loss:-0.5281 G loss:-2.116\n",
      "Epoch:  0056 D loss:-0.5196 G loss:-2.231\n",
      "Epoch:  0056 D loss:-0.6055 G loss:-2.196\n",
      "Epoch:  0056 D loss:-0.6626 G loss:-2.083\n",
      "Epoch:  0056 D loss:-0.5653 G loss:-2.254\n",
      "Epoch:  0056 D loss:-0.6387 G loss:-2.348\n",
      "Epoch:  0056 D loss:-0.6473 G loss:-2.297\n",
      "Epoch:  0056 D loss:-0.559 G loss:-2.278\n",
      "Epoch:  0056 D loss:-0.5913 G loss:-2.193\n",
      "Epoch:  0056 D loss:-0.5383 G loss:-2.218\n",
      "Epoch:  0056 D loss:-0.6234 G loss:-2.182\n",
      "Epoch:  0056 D loss:-0.5927 G loss:-2.219\n",
      "Epoch:  0056 D loss:-0.7001 G loss:-2.124\n",
      "Epoch:  0056 D loss:-0.5951 G loss:-2.293\n",
      "Epoch:  0056 D loss:-0.752 G loss:-2.041\n",
      "Epoch:  0056 D loss:-0.7467 G loss:-2.016\n",
      "Epoch:  0056 D loss:-0.6483 G loss:-2.047\n",
      "Epoch:  0056 D loss:-0.6642 G loss:-2.347\n",
      "Epoch:  0056 D loss:-0.6165 G loss:-2.069\n",
      "Epoch:  0056 D loss:-0.5804 G loss:-2.059\n",
      "Epoch:  0056 D loss:-0.5111 G loss:-2.172\n",
      "Epoch:  0056 D loss:-0.604 G loss:-2.089\n",
      "Epoch:  0056 D loss:-0.6226 G loss:-2.273\n",
      "Epoch:  0056 D loss:-0.5057 G loss:-2.203\n",
      "Epoch:  0056 D loss:-0.5879 G loss:-2.266\n",
      "Epoch:  0056 D loss:-0.6587 G loss:-2.283\n",
      "Epoch:  0056 D loss:-0.5703 G loss:-2.372\n",
      "Epoch:  0056 D loss:-0.7555 G loss:-2.248\n",
      "Epoch:  0056 D loss:-0.6388 G loss:-2.285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0056 D loss:-0.6832 G loss:-2.188\n",
      "Epoch:  0056 D loss:-0.6535 G loss:-2.386\n",
      "Epoch:  0056 D loss:-0.6697 G loss:-2.241\n",
      "Epoch:  0056 D loss:-0.6948 G loss:-2.381\n",
      "Epoch:  0056 D loss:-0.5991 G loss:-2.154\n",
      "Epoch:  0056 D loss:-0.6403 G loss:-1.959\n",
      "Epoch:  0056 D loss:-0.7486 G loss:-1.946\n",
      "Epoch:  0056 D loss:-0.589 G loss:-1.935\n",
      "Epoch:  0056 D loss:-0.5664 G loss:-2.032\n",
      "Epoch:  0056 D loss:-0.5567 G loss:-1.937\n",
      "Epoch:  0056 D loss:-0.6066 G loss:-2.182\n",
      "Epoch:  0056 D loss:-0.6049 G loss:-2.147\n",
      "Epoch:  0056 D loss:-0.5341 G loss:-2.494\n",
      "Epoch:  0056 D loss:-0.6045 G loss:-2.192\n",
      "Epoch:  0056 D loss:-0.6063 G loss:-2.292\n",
      "Epoch:  0056 D loss:-0.6339 G loss:-2.329\n",
      "Epoch:  0056 D loss:-0.472 G loss:-2.252\n",
      "Epoch:  0056 D loss:-0.6106 G loss:-2.268\n",
      "Epoch:  0056 D loss:-0.748 G loss:-2.153\n",
      "Epoch:  0056 D loss:-0.6622 G loss:-2.087\n",
      "Epoch:  0056 D loss:-0.7513 G loss:-2.061\n",
      "Epoch:  0056 D loss:-0.6818 G loss:-2.063\n",
      "Epoch:  0056 D loss:-0.5959 G loss:-2.12\n",
      "Epoch:  0056 D loss:-0.688 G loss:-1.9\n",
      "Epoch:  0056 D loss:-0.7354 G loss:-2.072\n",
      "Epoch:  0056 D loss:-0.6546 G loss:-2.1\n",
      "Epoch:  0056 D loss:-0.5431 G loss:-2.124\n",
      "Epoch:  0056 D loss:-0.6593 G loss:-2.258\n",
      "Epoch:  0056 D loss:-0.7767 G loss:-2.357\n",
      "Epoch:  0056 D loss:-0.8279 G loss:-2.371\n",
      "Epoch:  0056 D loss:-0.5366 G loss:-2.421\n",
      "Epoch:  0056 D loss:-0.6115 G loss:-2.251\n",
      "Epoch:  0056 D loss:-0.5675 G loss:-2.405\n",
      "Epoch:  0056 D loss:-0.7963 G loss:-2.109\n",
      "Epoch:  0056 D loss:-0.7006 G loss:-2.118\n",
      "Epoch:  0056 D loss:-0.6028 G loss:-2.17\n",
      "Epoch:  0056 D loss:-0.6075 G loss:-1.966\n",
      "Epoch:  0056 D loss:-0.6705 G loss:-2.134\n",
      "Epoch:  0056 D loss:-0.6015 G loss:-2.003\n",
      "Epoch:  0056 D loss:-0.5369 G loss:-1.931\n",
      "Epoch:  0056 D loss:-0.6346 G loss:-1.98\n",
      "Epoch:  0056 D loss:-0.4602 G loss:-2.25\n",
      "Epoch:  0056 D loss:-0.5993 G loss:-2.233\n",
      "Epoch:  0056 D loss:-0.693 G loss:-2.376\n",
      "Epoch:  0056 D loss:-0.5265 G loss:-2.42\n",
      "Epoch:  0056 D loss:-0.5168 G loss:-2.382\n",
      "Epoch:  0056 D loss:-0.5431 G loss:-2.356\n",
      "Epoch:  0056 D loss:-0.5902 G loss:-2.473\n",
      "Epoch:  0056 D loss:-0.6637 G loss:-2.241\n",
      "Epoch:  0056 D loss:-0.8279 G loss:-2.377\n",
      "Epoch:  0056 D loss:-0.628 G loss:-2.26\n",
      "Epoch:  0056 D loss:-0.5623 G loss:-2.031\n",
      "Epoch:  0056 D loss:-0.6069 G loss:-2.048\n",
      "Epoch:  0056 D loss:-0.6558 G loss:-2.103\n",
      "Epoch:  0056 D loss:-0.6017 G loss:-1.925\n",
      "Epoch:  0056 D loss:-0.6062 G loss:-2.109\n",
      "Epoch:  0056 D loss:-0.6117 G loss:-2.05\n",
      "Epoch:  0056 D loss:-0.5606 G loss:-2.066\n",
      "Epoch:  0056 D loss:-0.7324 G loss:-1.939\n",
      "Epoch:  0056 D loss:-0.5702 G loss:-2.236\n",
      "Epoch:  0056 D loss:-0.5719 G loss:-2.324\n",
      "Epoch:  0056 D loss:-0.5888 G loss:-2.153\n",
      "Epoch:  0056 D loss:-0.5517 G loss:-2.343\n",
      "Epoch:  0056 D loss:-0.5701 G loss:-2.235\n",
      "Epoch:  0056 D loss:-0.673 G loss:-2.325\n",
      "Epoch:  0056 D loss:-0.5292 G loss:-2.247\n",
      "Epoch:  0056 D loss:-0.6861 G loss:-2.234\n",
      "Epoch:  0056 D loss:-0.6044 G loss:-2.47\n",
      "Epoch:  0056 D loss:-0.5532 G loss:-2.4\n",
      "Epoch:  0056 D loss:-0.509 G loss:-2.456\n",
      "Epoch:  0056 D loss:-0.5082 G loss:-2.224\n",
      "Epoch:  0056 D loss:-0.5561 G loss:-2.175\n",
      "Epoch:  0056 D loss:-0.5074 G loss:-2.252\n",
      "Epoch:  0056 D loss:-0.5308 G loss:-2.147\n",
      "Epoch:  0056 D loss:-0.6265 G loss:-2.178\n",
      "Epoch:  0056 D loss:-0.6831 G loss:-2.167\n",
      "Epoch:  0056 D loss:-0.5059 G loss:-2.222\n",
      "Epoch:  0056 D loss:-0.4557 G loss:-2.28\n",
      "Epoch:  0056 D loss:-0.5089 G loss:-2.518\n",
      "Epoch:  0056 D loss:-0.5504 G loss:-2.21\n",
      "Epoch:  0056 D loss:-0.6832 G loss:-2.26\n",
      "Epoch:  0056 D loss:-0.5225 G loss:-2.242\n",
      "Epoch:  0056 D loss:-0.6989 G loss:-2.006\n",
      "Epoch:  0056 D loss:-0.7275 G loss:-2.171\n",
      "Epoch:  0056 D loss:-0.5548 G loss:-2.335\n",
      "Epoch:  0056 D loss:-0.404 G loss:-2.298\n",
      "Epoch:  0056 D loss:-0.4968 G loss:-2.33\n",
      "Epoch:  0056 D loss:-0.5446 G loss:-2.318\n",
      "Epoch:  0056 D loss:-0.5772 G loss:-2.119\n",
      "Epoch:  0056 D loss:-0.5757 G loss:-2.145\n",
      "Epoch:  0056 D loss:-0.5734 G loss:-2.207\n",
      "Epoch:  0056 D loss:-0.5903 G loss:-2.278\n",
      "Epoch:  0056 D loss:-0.5503 G loss:-2.427\n",
      "Epoch:  0056 D loss:-0.5735 G loss:-2.471\n",
      "Epoch:  0056 D loss:-0.6319 G loss:-2.406\n",
      "Epoch:  0056 D loss:-0.6208 G loss:-2.379\n",
      "Epoch:  0056 D loss:-0.5141 G loss:-2.316\n",
      "Epoch:  0056 D loss:-0.4901 G loss:-2.475\n",
      "Epoch:  0056 D loss:-0.4633 G loss:-2.668\n",
      "Epoch:  0056 D loss:-0.5033 G loss:-2.462\n",
      "Epoch:  0056 D loss:-0.4944 G loss:-2.348\n",
      "Epoch:  0056 D loss:-0.5754 G loss:-2.285\n",
      "Epoch:  0056 D loss:-0.5453 G loss:-2.47\n",
      "Epoch:  0056 D loss:-0.6557 G loss:-2.446\n",
      "Epoch:  0056 D loss:-0.6512 G loss:-2.29\n",
      "Epoch:  0056 D loss:-0.5649 G loss:-2.163\n",
      "Epoch:  0056 D loss:-0.6301 G loss:-2.205\n",
      "Epoch:  0056 D loss:-0.5601 G loss:-2.042\n",
      "Epoch:  0056 D loss:-0.644 G loss:-1.828\n",
      "Epoch:  0056 D loss:-0.6499 G loss:-2.042\n",
      "Epoch:  0056 D loss:-0.629 G loss:-2.115\n",
      "Epoch:  0056 D loss:-0.5439 G loss:-2.312\n",
      "Epoch:  0056 D loss:-0.5354 G loss:-2.304\n",
      "Epoch:  0056 D loss:-0.6253 G loss:-2.257\n",
      "Epoch:  0056 D loss:-0.5381 G loss:-2.566\n",
      "Epoch:  0056 D loss:-0.4935 G loss:-2.329\n",
      "Epoch:  0056 D loss:-0.4249 G loss:-2.523\n",
      "Epoch:  0056 D loss:-0.7356 G loss:-2.496\n",
      "Epoch:  0056 D loss:-0.5529 G loss:-2.493\n",
      "Epoch:  0056 D loss:-0.5622 G loss:-2.397\n",
      "Epoch:  0056 D loss:-0.5873 G loss:-2.151\n",
      "Epoch:  0056 D loss:-0.4899 G loss:-2.389\n",
      "Epoch:  0056 D loss:-0.6094 G loss:-2.015\n",
      "Epoch:  0056 D loss:-0.6748 G loss:-1.838\n",
      "Epoch:  0056 D loss:-0.6702 G loss:-1.977\n",
      "Epoch:  0056 D loss:-0.6263 G loss:-1.88\n",
      "Epoch:  0056 D loss:-0.6365 G loss:-2.065\n",
      "Epoch:  0056 D loss:-0.6693 G loss:-1.973\n",
      "Epoch:  0056 D loss:-0.7604 G loss:-2.085\n",
      "Epoch:  0056 D loss:-0.604 G loss:-2.358\n",
      "Epoch:  0056 D loss:-0.5736 G loss:-2.265\n",
      "Epoch:  0056 D loss:-0.6404 G loss:-2.131\n",
      "Epoch:  0056 D loss:-0.5419 G loss:-2.225\n",
      "Epoch:  0056 D loss:-0.643 G loss:-2.415\n",
      "Epoch:  0056 D loss:-0.6862 G loss:-2.426\n",
      "Epoch:  0056 D loss:-0.6819 G loss:-2.161\n",
      "Epoch:  0056 D loss:-0.6088 G loss:-2.347\n",
      "Epoch:  0056 D loss:-0.6251 G loss:-2.266\n",
      "Epoch:  0056 D loss:-0.5753 G loss:-2.155\n",
      "Epoch:  0056 D loss:-0.6539 G loss:-2.075\n",
      "Epoch:  0056 D loss:-0.6189 G loss:-2.111\n",
      "Epoch:  0056 D loss:-0.6204 G loss:-2.16\n",
      "Epoch:  0056 D loss:-0.5956 G loss:-2.015\n",
      "Epoch:  0056 D loss:-0.5474 G loss:-2.161\n",
      "Epoch:  0056 D loss:-0.5889 G loss:-2.155\n",
      "Epoch:  0056 D loss:-0.6878 G loss:-2.117\n",
      "Epoch:  0056 D loss:-0.6975 G loss:-2.407\n",
      "Epoch:  0056 D loss:-0.6563 G loss:-2.351\n",
      "Epoch:  0056 D loss:-0.6301 G loss:-2.108\n",
      "Epoch:  0056 D loss:-0.6729 G loss:-2.251\n",
      "Epoch:  0056 D loss:-0.674 G loss:-2.076\n",
      "Epoch:  0056 D loss:-0.5585 G loss:-2.175\n",
      "Epoch:  0056 D loss:-0.6247 G loss:-2.342\n",
      "Epoch:  0056 D loss:-0.5971 G loss:-2.436\n",
      "Epoch:  0056 D loss:-0.6758 G loss:-2.299\n",
      "Epoch:  0056 D loss:-0.6817 G loss:-2.253\n",
      "Epoch:  0056 D loss:-0.6791 G loss:-2.107\n",
      "Epoch:  0056 D loss:-0.5816 G loss:-2.188\n",
      "Epoch:  0056 D loss:-0.5786 G loss:-2.223\n",
      "Epoch:  0056 D loss:-0.6344 G loss:-2.022\n",
      "Epoch:  0056 D loss:-0.6628 G loss:-2.04\n",
      "Epoch:  0056 D loss:-0.6866 G loss:-2.053\n",
      "Epoch:  0056 D loss:-0.7456 G loss:-1.961\n",
      "Epoch:  0056 D loss:-0.7546 G loss:-2.062\n",
      "Epoch:  0056 D loss:-0.6643 G loss:-2.206\n",
      "Epoch:  0056 D loss:-0.7674 G loss:-2.099\n",
      "Epoch:  0056 D loss:-0.7058 G loss:-2.263\n",
      "Epoch:  0056 D loss:-0.6846 G loss:-1.995\n",
      "Epoch:  0056 D loss:-0.6181 G loss:-2.011\n",
      "Epoch:  0056 D loss:-0.6264 G loss:-1.96\n",
      "Epoch:  0056 D loss:-0.6487 G loss:-2.212\n",
      "Epoch:  0056 D loss:-0.6466 G loss:-2.225\n",
      "Epoch:  0056 D loss:-0.6883 G loss:-2.089\n",
      "Epoch:  0056 D loss:-0.634 G loss:-2.066\n",
      "Epoch:  0056 D loss:-0.6392 G loss:-2.3\n",
      "Epoch:  0056 D loss:-0.5726 G loss:-2.236\n",
      "Epoch:  0056 D loss:-0.7225 G loss:-2.053\n",
      "Epoch:  0056 D loss:-0.5831 G loss:-2.301\n",
      "Epoch:  0056 D loss:-0.7274 G loss:-2.179\n",
      "Epoch:  0056 D loss:-0.5874 G loss:-2.062\n",
      "Epoch:  0056 D loss:-0.6717 G loss:-2.164\n",
      "Epoch:  0056 D loss:-0.7214 G loss:-2.039\n",
      "Epoch:  0056 D loss:-0.8014 G loss:-1.93\n",
      "Epoch:  0056 D loss:-0.7159 G loss:-2.06\n",
      "Epoch:  0056 D loss:-0.6318 G loss:-2.019\n",
      "Epoch:  0056 D loss:-0.6806 G loss:-2.026\n",
      "Epoch:  0056 D loss:-0.669 G loss:-2.032\n",
      "Epoch:  0056 D loss:-0.6023 G loss:-2.144\n",
      "Epoch:  0056 D loss:-0.6606 G loss:-1.824\n",
      "Epoch:  0056 D loss:-0.7091 G loss:-1.966\n",
      "Epoch:  0056 D loss:-0.7992 G loss:-1.885\n",
      "Epoch:  0056 D loss:-0.6793 G loss:-1.793\n",
      "Epoch:  0056 D loss:-0.7288 G loss:-1.855\n",
      "Epoch:  0056 D loss:-0.5914 G loss:-2.288\n",
      "Epoch:  0056 D loss:-0.5829 G loss:-2.253\n",
      "Epoch:  0056 D loss:-0.7563 G loss:-2.114\n",
      "Epoch:  0056 D loss:-0.6047 G loss:-2.356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0056 D loss:-0.7171 G loss:-2.396\n",
      "Epoch:  0056 D loss:-0.6622 G loss:-2.183\n",
      "Epoch:  0056 D loss:-0.6721 G loss:-1.926\n",
      "Epoch:  0056 D loss:-0.7694 G loss:-1.846\n",
      "Epoch:  0056 D loss:-0.5949 G loss:-1.902\n",
      "Epoch:  0056 D loss:-0.5402 G loss:-2.182\n",
      "Epoch:  0056 D loss:-0.6962 G loss:-2.037\n",
      "Epoch:  0056 D loss:-0.6623 G loss:-2.012\n",
      "Epoch:  0056 D loss:-0.6085 G loss:-2.316\n",
      "Epoch:  0056 D loss:-0.7314 G loss:-2.272\n",
      "Epoch:  0056 D loss:-0.6479 G loss:-2.16\n",
      "Epoch:  0056 D loss:-0.6662 G loss:-2.371\n",
      "Epoch:  0056 D loss:-0.64 G loss:-2.29\n",
      "Epoch:  0056 D loss:-0.6789 G loss:-2.237\n",
      "Epoch:  0056 D loss:-0.7295 G loss:-2.186\n",
      "Epoch:  0056 D loss:-0.5077 G loss:-2.422\n",
      "Epoch:  0056 D loss:-0.5866 G loss:-2.214\n",
      "Epoch:  0056 D loss:-0.6606 G loss:-2.173\n",
      "Epoch:  0056 D loss:-0.8122 G loss:-2.104\n",
      "Epoch:  0056 D loss:-0.7061 G loss:-2.158\n",
      "Epoch:  0056 D loss:-0.5664 G loss:-2.057\n",
      "Epoch:  0056 D loss:-0.8019 G loss:-1.809\n",
      "Epoch:  0056 D loss:-0.7309 G loss:-1.779\n",
      "Epoch:  0056 D loss:-0.8006 G loss:-1.761\n",
      "Epoch:  0056 D loss:-0.6851 G loss:-1.935\n",
      "Epoch:  0056 D loss:-0.651 G loss:-1.892\n",
      "Epoch:  0056 D loss:-0.5639 G loss:-2.09\n",
      "Epoch:  0056 D loss:-0.7368 G loss:-1.974\n",
      "Epoch:  0056 D loss:-0.7328 G loss:-2.07\n",
      "Epoch:  0056 D loss:-0.7254 G loss:-1.984\n",
      "Epoch:  0057 D loss:-0.7058 G loss:-2.121\n",
      "Epoch:  0057 D loss:-0.5759 G loss:-2.422\n",
      "Epoch:  0057 D loss:-0.639 G loss:-2.629\n",
      "Epoch:  0057 D loss:-0.6222 G loss:-2.162\n",
      "Epoch:  0057 D loss:-0.5854 G loss:-2.423\n",
      "Epoch:  0057 D loss:-0.5994 G loss:-2.372\n",
      "Epoch:  0057 D loss:-0.6095 G loss:-2.314\n",
      "Epoch:  0057 D loss:-0.5659 G loss:-2.425\n",
      "Epoch:  0057 D loss:-0.5545 G loss:-2.249\n",
      "Epoch:  0057 D loss:-0.5742 G loss:-2.285\n",
      "Epoch:  0057 D loss:-0.5511 G loss:-2.042\n",
      "Epoch:  0057 D loss:-0.4709 G loss:-2.229\n",
      "Epoch:  0057 D loss:-0.6158 G loss:-2.037\n",
      "Epoch:  0057 D loss:-0.5043 G loss:-1.995\n",
      "Epoch:  0057 D loss:-0.6224 G loss:-2.012\n",
      "Epoch:  0057 D loss:-0.6033 G loss:-1.991\n",
      "Epoch:  0057 D loss:-0.6194 G loss:-2.163\n",
      "Epoch:  0057 D loss:-0.5426 G loss:-2.144\n",
      "Epoch:  0057 D loss:-0.6107 G loss:-2.179\n",
      "Epoch:  0057 D loss:-0.5551 G loss:-2.369\n",
      "Epoch:  0057 D loss:-0.7681 G loss:-2.389\n",
      "Epoch:  0057 D loss:-0.7909 G loss:-2.481\n",
      "Epoch:  0057 D loss:-0.5789 G loss:-2.571\n",
      "Epoch:  0057 D loss:-0.6392 G loss:-2.14\n",
      "Epoch:  0057 D loss:-0.6702 G loss:-2.085\n",
      "Epoch:  0057 D loss:-0.5905 G loss:-2.337\n",
      "Epoch:  0057 D loss:-0.7611 G loss:-1.975\n",
      "Epoch:  0057 D loss:-0.534 G loss:-2.083\n",
      "Epoch:  0057 D loss:-0.6043 G loss:-2.075\n",
      "Epoch:  0057 D loss:-0.6686 G loss:-1.94\n",
      "Epoch:  0057 D loss:-0.6554 G loss:-2.092\n",
      "Epoch:  0057 D loss:-0.6243 G loss:-2.072\n",
      "Epoch:  0057 D loss:-0.5459 G loss:-2.016\n",
      "Epoch:  0057 D loss:-0.5838 G loss:-2.046\n",
      "Epoch:  0057 D loss:-0.5362 G loss:-2.093\n",
      "Epoch:  0057 D loss:-0.714 G loss:-2.014\n",
      "Epoch:  0057 D loss:-0.6232 G loss:-2.36\n",
      "Epoch:  0057 D loss:-0.6192 G loss:-2.212\n",
      "Epoch:  0057 D loss:-0.5472 G loss:-2.365\n",
      "Epoch:  0057 D loss:-0.5029 G loss:-2.393\n",
      "Epoch:  0057 D loss:-0.5891 G loss:-2.319\n",
      "Epoch:  0057 D loss:-0.6042 G loss:-2.488\n",
      "Epoch:  0057 D loss:-0.5216 G loss:-2.326\n",
      "Epoch:  0057 D loss:-0.6621 G loss:-2.135\n",
      "Epoch:  0057 D loss:-0.5805 G loss:-2.325\n",
      "Epoch:  0057 D loss:-0.7365 G loss:-2.017\n",
      "Epoch:  0057 D loss:-0.587 G loss:-2.212\n",
      "Epoch:  0057 D loss:-0.6173 G loss:-2.201\n",
      "Epoch:  0057 D loss:-0.4796 G loss:-2.294\n",
      "Epoch:  0057 D loss:-0.5712 G loss:-2.128\n",
      "Epoch:  0057 D loss:-0.5814 G loss:-2.268\n",
      "Epoch:  0057 D loss:-0.6837 G loss:-2.203\n",
      "Epoch:  0057 D loss:-0.6227 G loss:-2.01\n",
      "Epoch:  0057 D loss:-0.5967 G loss:-2.243\n",
      "Epoch:  0057 D loss:-0.6292 G loss:-2.224\n",
      "Epoch:  0057 D loss:-0.5968 G loss:-2.378\n",
      "Epoch:  0057 D loss:-0.7223 G loss:-2.122\n",
      "Epoch:  0057 D loss:-0.6577 G loss:-2.323\n",
      "Epoch:  0057 D loss:-0.612 G loss:-2.389\n",
      "Epoch:  0057 D loss:-0.5784 G loss:-2.265\n",
      "Epoch:  0057 D loss:-0.6738 G loss:-2.277\n",
      "Epoch:  0057 D loss:-0.6673 G loss:-2.266\n",
      "Epoch:  0057 D loss:-0.576 G loss:-2.055\n",
      "Epoch:  0057 D loss:-0.4787 G loss:-2.606\n",
      "Epoch:  0057 D loss:-0.6443 G loss:-2.196\n",
      "Epoch:  0057 D loss:-0.7235 G loss:-2.003\n",
      "Epoch:  0057 D loss:-0.5245 G loss:-2.179\n",
      "Epoch:  0057 D loss:-0.5495 G loss:-2.156\n",
      "Epoch:  0057 D loss:-0.615 G loss:-2.26\n",
      "Epoch:  0057 D loss:-0.6069 G loss:-2.236\n",
      "Epoch:  0057 D loss:-0.6807 G loss:-2.169\n",
      "Epoch:  0057 D loss:-0.6836 G loss:-2.191\n",
      "Epoch:  0057 D loss:-0.6496 G loss:-2.248\n",
      "Epoch:  0057 D loss:-0.651 G loss:-2.047\n",
      "Epoch:  0057 D loss:-0.7038 G loss:-2.053\n",
      "Epoch:  0057 D loss:-0.6438 G loss:-2.033\n",
      "Epoch:  0057 D loss:-0.7207 G loss:-1.92\n",
      "Epoch:  0057 D loss:-0.707 G loss:-2.049\n",
      "Epoch:  0057 D loss:-0.6551 G loss:-1.792\n",
      "Epoch:  0057 D loss:-0.6046 G loss:-2.078\n",
      "Epoch:  0057 D loss:-0.6352 G loss:-2.121\n",
      "Epoch:  0057 D loss:-0.6919 G loss:-2.322\n",
      "Epoch:  0057 D loss:-0.6266 G loss:-2.06\n",
      "Epoch:  0057 D loss:-0.6115 G loss:-2.206\n",
      "Epoch:  0057 D loss:-0.7263 G loss:-2.076\n",
      "Epoch:  0057 D loss:-0.6227 G loss:-2.216\n",
      "Epoch:  0057 D loss:-0.7244 G loss:-2.04\n",
      "Epoch:  0057 D loss:-0.5959 G loss:-2.361\n",
      "Epoch:  0057 D loss:-0.6372 G loss:-2.531\n",
      "Epoch:  0057 D loss:-0.6949 G loss:-2.19\n",
      "Epoch:  0057 D loss:-0.5584 G loss:-2.162\n",
      "Epoch:  0057 D loss:-0.5723 G loss:-2.065\n",
      "Epoch:  0057 D loss:-0.5998 G loss:-2.05\n",
      "Epoch:  0057 D loss:-0.6385 G loss:-2.053\n",
      "Epoch:  0057 D loss:-0.5565 G loss:-2.27\n",
      "Epoch:  0057 D loss:-0.7424 G loss:-1.907\n",
      "Epoch:  0057 D loss:-0.7452 G loss:-2.05\n",
      "Epoch:  0057 D loss:-0.5506 G loss:-1.986\n",
      "Epoch:  0057 D loss:-0.5126 G loss:-2.348\n",
      "Epoch:  0057 D loss:-0.7798 G loss:-2.042\n",
      "Epoch:  0057 D loss:-0.6594 G loss:-2.258\n",
      "Epoch:  0057 D loss:-0.6812 G loss:-2.471\n",
      "Epoch:  0057 D loss:-0.7289 G loss:-2.451\n",
      "Epoch:  0057 D loss:-0.7088 G loss:-2.014\n",
      "Epoch:  0057 D loss:-0.7212 G loss:-1.915\n",
      "Epoch:  0057 D loss:-0.5861 G loss:-2.08\n",
      "Epoch:  0057 D loss:-0.6678 G loss:-2.11\n",
      "Epoch:  0057 D loss:-0.8355 G loss:-1.887\n",
      "Epoch:  0057 D loss:-0.4739 G loss:-1.949\n",
      "Epoch:  0057 D loss:-0.8918 G loss:-2.069\n",
      "Epoch:  0057 D loss:-0.6886 G loss:-2.133\n",
      "Epoch:  0057 D loss:-0.7728 G loss:-2.232\n",
      "Epoch:  0057 D loss:-0.6248 G loss:-1.998\n",
      "Epoch:  0057 D loss:-0.5603 G loss:-2.385\n",
      "Epoch:  0057 D loss:-0.7187 G loss:-2.156\n",
      "Epoch:  0057 D loss:-0.5955 G loss:-2.321\n",
      "Epoch:  0057 D loss:-0.6661 G loss:-2.47\n",
      "Epoch:  0057 D loss:-0.7247 G loss:-2.119\n",
      "Epoch:  0057 D loss:-0.5963 G loss:-2.105\n",
      "Epoch:  0057 D loss:-0.7378 G loss:-2.028\n",
      "Epoch:  0057 D loss:-0.7126 G loss:-2.074\n",
      "Epoch:  0057 D loss:-0.608 G loss:-2.263\n",
      "Epoch:  0057 D loss:-0.6501 G loss:-2.204\n",
      "Epoch:  0057 D loss:-0.6886 G loss:-2.118\n",
      "Epoch:  0057 D loss:-0.553 G loss:-2.221\n",
      "Epoch:  0057 D loss:-0.7419 G loss:-1.961\n",
      "Epoch:  0057 D loss:-0.58 G loss:-2.186\n",
      "Epoch:  0057 D loss:-0.6461 G loss:-2.322\n",
      "Epoch:  0057 D loss:-0.6587 G loss:-2.292\n",
      "Epoch:  0057 D loss:-0.7196 G loss:-2.611\n",
      "Epoch:  0057 D loss:-0.5789 G loss:-2.204\n",
      "Epoch:  0057 D loss:-0.6155 G loss:-2.073\n",
      "Epoch:  0057 D loss:-0.6816 G loss:-2.076\n",
      "Epoch:  0057 D loss:-0.6008 G loss:-2.21\n",
      "Epoch:  0057 D loss:-0.5588 G loss:-2.16\n",
      "Epoch:  0057 D loss:-0.7119 G loss:-2.155\n",
      "Epoch:  0057 D loss:-0.7045 G loss:-2.135\n",
      "Epoch:  0057 D loss:-0.6885 G loss:-1.977\n",
      "Epoch:  0057 D loss:-0.6288 G loss:-2.129\n",
      "Epoch:  0057 D loss:-0.6295 G loss:-2.21\n",
      "Epoch:  0057 D loss:-0.623 G loss:-1.811\n",
      "Epoch:  0057 D loss:-0.671 G loss:-2.005\n",
      "Epoch:  0057 D loss:-0.7091 G loss:-1.915\n",
      "Epoch:  0057 D loss:-0.6604 G loss:-2.152\n",
      "Epoch:  0057 D loss:-0.6195 G loss:-2.199\n",
      "Epoch:  0057 D loss:-0.6415 G loss:-2.262\n",
      "Epoch:  0057 D loss:-0.7397 G loss:-2.348\n",
      "Epoch:  0057 D loss:-0.5857 G loss:-2.161\n",
      "Epoch:  0057 D loss:-0.6561 G loss:-2.459\n",
      "Epoch:  0057 D loss:-0.5993 G loss:-2.304\n",
      "Epoch:  0057 D loss:-0.6698 G loss:-2.349\n",
      "Epoch:  0057 D loss:-0.6083 G loss:-2.243\n",
      "Epoch:  0057 D loss:-0.5652 G loss:-2.262\n",
      "Epoch:  0057 D loss:-0.6133 G loss:-2.092\n",
      "Epoch:  0057 D loss:-0.6811 G loss:-2.058\n",
      "Epoch:  0057 D loss:-0.7942 G loss:-1.938\n",
      "Epoch:  0057 D loss:-0.6809 G loss:-2.032\n",
      "Epoch:  0057 D loss:-0.7281 G loss:-1.989\n",
      "Epoch:  0057 D loss:-0.7999 G loss:-2.015\n",
      "Epoch:  0057 D loss:-0.7911 G loss:-2.195\n",
      "Epoch:  0057 D loss:-0.6625 G loss:-2.252\n",
      "Epoch:  0057 D loss:-0.6438 G loss:-2.124\n",
      "Epoch:  0057 D loss:-0.7158 G loss:-2.108\n",
      "Epoch:  0057 D loss:-0.5946 G loss:-2.024\n",
      "Epoch:  0057 D loss:-0.6747 G loss:-2.01\n",
      "Epoch:  0057 D loss:-0.6608 G loss:-2.021\n",
      "Epoch:  0057 D loss:-0.7109 G loss:-1.999\n",
      "Epoch:  0057 D loss:-0.7101 G loss:-2.101\n",
      "Epoch:  0057 D loss:-0.586 G loss:-2.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0057 D loss:-0.6455 G loss:-2.017\n",
      "Epoch:  0057 D loss:-0.7064 G loss:-2.031\n",
      "Epoch:  0057 D loss:-0.7551 G loss:-2.034\n",
      "Epoch:  0057 D loss:-0.7489 G loss:-2.201\n",
      "Epoch:  0057 D loss:-0.7416 G loss:-2.075\n",
      "Epoch:  0057 D loss:-0.7598 G loss:-2.105\n",
      "Epoch:  0057 D loss:-0.6873 G loss:-2.004\n",
      "Epoch:  0057 D loss:-0.5889 G loss:-2.182\n",
      "Epoch:  0057 D loss:-0.603 G loss:-2.177\n",
      "Epoch:  0057 D loss:-0.7154 G loss:-2.147\n",
      "Epoch:  0057 D loss:-0.7218 G loss:-2.237\n",
      "Epoch:  0057 D loss:-0.7338 G loss:-2.063\n",
      "Epoch:  0057 D loss:-0.7095 G loss:-2.143\n",
      "Epoch:  0057 D loss:-0.7363 G loss:-2.128\n",
      "Epoch:  0057 D loss:-0.8462 G loss:-2.117\n",
      "Epoch:  0057 D loss:-0.6083 G loss:-2.019\n",
      "Epoch:  0057 D loss:-0.6979 G loss:-2.019\n",
      "Epoch:  0057 D loss:-0.673 G loss:-1.878\n",
      "Epoch:  0057 D loss:-0.7032 G loss:-1.915\n",
      "Epoch:  0057 D loss:-0.7533 G loss:-1.957\n",
      "Epoch:  0057 D loss:-0.7368 G loss:-1.972\n",
      "Epoch:  0057 D loss:-0.7427 G loss:-1.993\n",
      "Epoch:  0057 D loss:-0.8131 G loss:-1.944\n",
      "Epoch:  0057 D loss:-0.7519 G loss:-1.743\n",
      "Epoch:  0057 D loss:-0.6319 G loss:-1.996\n",
      "Epoch:  0057 D loss:-0.5327 G loss:-2.06\n",
      "Epoch:  0057 D loss:-0.5254 G loss:-2.05\n",
      "Epoch:  0057 D loss:-0.7103 G loss:-2.195\n",
      "Epoch:  0057 D loss:-0.4992 G loss:-2.201\n",
      "Epoch:  0057 D loss:-0.7946 G loss:-2.228\n",
      "Epoch:  0057 D loss:-0.8234 G loss:-1.942\n",
      "Epoch:  0057 D loss:-0.6805 G loss:-2.096\n",
      "Epoch:  0057 D loss:-0.7858 G loss:-2.087\n",
      "Epoch:  0057 D loss:-0.4982 G loss:-2.205\n",
      "Epoch:  0057 D loss:-0.8027 G loss:-2.059\n",
      "Epoch:  0057 D loss:-0.6385 G loss:-2.147\n",
      "Epoch:  0057 D loss:-0.7201 G loss:-1.897\n",
      "Epoch:  0057 D loss:-0.7531 G loss:-2.06\n",
      "Epoch:  0057 D loss:-0.5626 G loss:-1.98\n",
      "Epoch:  0057 D loss:-0.6333 G loss:-2.071\n",
      "Epoch:  0057 D loss:-0.7343 G loss:-2.086\n",
      "Epoch:  0057 D loss:-0.5158 G loss:-2.103\n",
      "Epoch:  0057 D loss:-0.5065 G loss:-2.155\n",
      "Epoch:  0057 D loss:-0.6727 G loss:-2.054\n",
      "Epoch:  0057 D loss:-0.7019 G loss:-2.164\n",
      "Epoch:  0057 D loss:-0.5809 G loss:-2.116\n",
      "Epoch:  0057 D loss:-0.6238 G loss:-2.129\n",
      "Epoch:  0057 D loss:-0.5561 G loss:-2.108\n",
      "Epoch:  0057 D loss:-0.6085 G loss:-2.315\n",
      "Epoch:  0057 D loss:-0.5436 G loss:-2.289\n",
      "Epoch:  0057 D loss:-0.7072 G loss:-2.505\n",
      "Epoch:  0057 D loss:-0.5577 G loss:-2.601\n",
      "Epoch:  0057 D loss:-0.654 G loss:-2.379\n",
      "Epoch:  0057 D loss:-0.5316 G loss:-2.244\n",
      "Epoch:  0057 D loss:-0.6491 G loss:-2.288\n",
      "Epoch:  0057 D loss:-0.5269 G loss:-2.149\n",
      "Epoch:  0057 D loss:-0.629 G loss:-1.997\n",
      "Epoch:  0057 D loss:-0.6913 G loss:-1.936\n",
      "Epoch:  0057 D loss:-0.5556 G loss:-2.228\n",
      "Epoch:  0057 D loss:-0.6022 G loss:-2.071\n",
      "Epoch:  0057 D loss:-0.7055 G loss:-2.083\n",
      "Epoch:  0057 D loss:-0.5267 G loss:-1.974\n",
      "Epoch:  0057 D loss:-0.5095 G loss:-2.239\n",
      "Epoch:  0057 D loss:-0.5478 G loss:-2.205\n",
      "Epoch:  0057 D loss:-0.4917 G loss:-2.233\n",
      "Epoch:  0057 D loss:-0.6728 G loss:-2.213\n",
      "Epoch:  0057 D loss:-0.642 G loss:-2.175\n",
      "Epoch:  0057 D loss:-0.7654 G loss:-2.276\n",
      "Epoch:  0057 D loss:-0.6661 G loss:-2.254\n",
      "Epoch:  0057 D loss:-0.6536 G loss:-2.106\n",
      "Epoch:  0057 D loss:-0.5469 G loss:-2.617\n",
      "Epoch:  0057 D loss:-0.6154 G loss:-2.541\n",
      "Epoch:  0057 D loss:-0.5867 G loss:-2.438\n",
      "Epoch:  0057 D loss:-0.7516 G loss:-2.172\n",
      "Epoch:  0057 D loss:-0.5185 G loss:-2.399\n",
      "Epoch:  0057 D loss:-0.6847 G loss:-2.034\n",
      "Epoch:  0057 D loss:-0.7317 G loss:-1.955\n",
      "Epoch:  0057 D loss:-0.6989 G loss:-2.13\n",
      "Epoch:  0057 D loss:-0.7741 G loss:-2.043\n",
      "Epoch:  0057 D loss:-0.7039 G loss:-1.938\n",
      "Epoch:  0057 D loss:-0.7038 G loss:-2.007\n",
      "Epoch:  0057 D loss:-0.7064 G loss:-1.836\n",
      "Epoch:  0057 D loss:-0.6527 G loss:-1.884\n",
      "Epoch:  0057 D loss:-0.6666 G loss:-2.013\n",
      "Epoch:  0057 D loss:-0.7077 G loss:-1.982\n",
      "Epoch:  0057 D loss:-0.5396 G loss:-2.111\n",
      "Epoch:  0057 D loss:-0.6539 G loss:-2.169\n",
      "Epoch:  0057 D loss:-0.7459 G loss:-2.314\n",
      "Epoch:  0057 D loss:-0.6537 G loss:-2.189\n",
      "Epoch:  0057 D loss:-0.6258 G loss:-2.162\n",
      "Epoch:  0057 D loss:-0.6127 G loss:-2.308\n",
      "Epoch:  0057 D loss:-0.5862 G loss:-2.267\n",
      "Epoch:  0057 D loss:-0.5683 G loss:-2.071\n",
      "Epoch:  0057 D loss:-0.553 G loss:-2.068\n",
      "Epoch:  0057 D loss:-0.5164 G loss:-2.315\n",
      "Epoch:  0057 D loss:-0.5757 G loss:-2.172\n",
      "Epoch:  0057 D loss:-0.673 G loss:-1.956\n",
      "Epoch:  0057 D loss:-0.6342 G loss:-2.314\n",
      "Epoch:  0057 D loss:-0.5906 G loss:-2.142\n",
      "Epoch:  0057 D loss:-0.6054 G loss:-1.974\n",
      "Epoch:  0057 D loss:-0.7083 G loss:-2.129\n",
      "Epoch:  0057 D loss:-0.5645 G loss:-2.145\n",
      "Epoch:  0057 D loss:-0.6385 G loss:-1.878\n",
      "Epoch:  0057 D loss:-0.649 G loss:-1.92\n",
      "Epoch:  0057 D loss:-0.635 G loss:-1.94\n",
      "Epoch:  0057 D loss:-0.6847 G loss:-2.243\n",
      "Epoch:  0057 D loss:-0.5786 G loss:-2.044\n",
      "Epoch:  0057 D loss:-0.631 G loss:-2.061\n",
      "Epoch:  0057 D loss:-0.7783 G loss:-2.105\n",
      "Epoch:  0057 D loss:-0.6812 G loss:-1.911\n",
      "Epoch:  0057 D loss:-0.5403 G loss:-2.396\n",
      "Epoch:  0057 D loss:-0.5782 G loss:-2.167\n",
      "Epoch:  0057 D loss:-0.7557 G loss:-1.978\n",
      "Epoch:  0057 D loss:-0.6147 G loss:-2.016\n",
      "Epoch:  0057 D loss:-0.5285 G loss:-2.416\n",
      "Epoch:  0057 D loss:-0.5917 G loss:-2.241\n",
      "Epoch:  0057 D loss:-0.504 G loss:-2.245\n",
      "Epoch:  0057 D loss:-0.5624 G loss:-2.261\n",
      "Epoch:  0057 D loss:-0.6447 G loss:-2.248\n",
      "Epoch:  0057 D loss:-0.623 G loss:-2.319\n",
      "Epoch:  0057 D loss:-0.7309 G loss:-2.311\n",
      "Epoch:  0057 D loss:-0.6201 G loss:-2.2\n",
      "Epoch:  0057 D loss:-0.5382 G loss:-2.153\n",
      "Epoch:  0057 D loss:-0.7519 G loss:-2.069\n",
      "Epoch:  0057 D loss:-0.6688 G loss:-2.004\n",
      "Epoch:  0057 D loss:-0.6716 G loss:-2.125\n",
      "Epoch:  0057 D loss:-0.5342 G loss:-2.146\n",
      "Epoch:  0057 D loss:-0.5797 G loss:-1.958\n",
      "Epoch:  0057 D loss:-0.6323 G loss:-2.118\n",
      "Epoch:  0057 D loss:-0.6206 G loss:-2.282\n",
      "Epoch:  0057 D loss:-0.512 G loss:-2.259\n",
      "Epoch:  0057 D loss:-0.5907 G loss:-2.155\n",
      "Epoch:  0057 D loss:-0.7812 G loss:-2.277\n",
      "Epoch:  0057 D loss:-0.7265 G loss:-2.093\n",
      "Epoch:  0057 D loss:-0.5046 G loss:-2.09\n",
      "Epoch:  0057 D loss:-0.8232 G loss:-1.902\n",
      "Epoch:  0057 D loss:-0.7991 G loss:-2.003\n",
      "Epoch:  0057 D loss:-0.6321 G loss:-1.99\n",
      "Epoch:  0057 D loss:-0.8008 G loss:-2.106\n",
      "Epoch:  0057 D loss:-0.6914 G loss:-1.963\n",
      "Epoch:  0057 D loss:-0.7228 G loss:-2.025\n",
      "Epoch:  0057 D loss:-0.6418 G loss:-2.262\n",
      "Epoch:  0057 D loss:-0.5675 G loss:-2.192\n",
      "Epoch:  0057 D loss:-0.713 G loss:-2.031\n",
      "Epoch:  0057 D loss:-0.6566 G loss:-2.238\n",
      "Epoch:  0057 D loss:-0.8138 G loss:-2.092\n",
      "Epoch:  0057 D loss:-0.6634 G loss:-1.976\n",
      "Epoch:  0057 D loss:-0.7115 G loss:-1.817\n",
      "Epoch:  0057 D loss:-0.7831 G loss:-2.016\n",
      "Epoch:  0057 D loss:-0.6816 G loss:-1.946\n",
      "Epoch:  0057 D loss:-0.6823 G loss:-1.941\n",
      "Epoch:  0057 D loss:-0.7775 G loss:-1.99\n",
      "Epoch:  0057 D loss:-0.7082 G loss:-2.019\n",
      "Epoch:  0057 D loss:-0.6231 G loss:-2.173\n",
      "Epoch:  0057 D loss:-0.6037 G loss:-2.242\n",
      "Epoch:  0057 D loss:-0.6096 G loss:-2.157\n",
      "Epoch:  0057 D loss:-0.7471 G loss:-2.045\n",
      "Epoch:  0057 D loss:-0.7393 G loss:-2.133\n",
      "Epoch:  0057 D loss:-0.7388 G loss:-1.993\n",
      "Epoch:  0057 D loss:-0.7084 G loss:-1.894\n",
      "Epoch:  0057 D loss:-0.6607 G loss:-2.167\n",
      "Epoch:  0057 D loss:-0.7029 G loss:-1.923\n",
      "Epoch:  0057 D loss:-0.6188 G loss:-2.252\n",
      "Epoch:  0057 D loss:-0.5555 G loss:-2.022\n",
      "Epoch:  0057 D loss:-0.7417 G loss:-1.956\n",
      "Epoch:  0057 D loss:-0.6749 G loss:-2.081\n",
      "Epoch:  0057 D loss:-0.6515 G loss:-1.936\n",
      "Epoch:  0057 D loss:-0.5869 G loss:-2.229\n",
      "Epoch:  0057 D loss:-0.6159 G loss:-2.141\n",
      "Epoch:  0057 D loss:-0.7705 G loss:-2.154\n",
      "Epoch:  0057 D loss:-0.5707 G loss:-2.116\n",
      "Epoch:  0057 D loss:-0.5217 G loss:-2.13\n",
      "Epoch:  0057 D loss:-0.7918 G loss:-2.145\n",
      "Epoch:  0057 D loss:-0.5948 G loss:-2.336\n",
      "Epoch:  0057 D loss:-0.5181 G loss:-2.192\n",
      "Epoch:  0057 D loss:-0.6563 G loss:-2.388\n",
      "Epoch:  0057 D loss:-0.6297 G loss:-2.448\n",
      "Epoch:  0057 D loss:-0.6272 G loss:-2.166\n",
      "Epoch:  0057 D loss:-0.6309 G loss:-2.081\n",
      "Epoch:  0057 D loss:-0.7048 G loss:-1.864\n",
      "Epoch:  0057 D loss:-0.7988 G loss:-1.829\n",
      "Epoch:  0057 D loss:-0.6522 G loss:-2.106\n",
      "Epoch:  0057 D loss:-0.5942 G loss:-2.135\n",
      "Epoch:  0057 D loss:-0.6802 G loss:-2.038\n",
      "Epoch:  0057 D loss:-0.7161 G loss:-2.076\n",
      "Epoch:  0057 D loss:-0.639 G loss:-2.192\n",
      "Epoch:  0057 D loss:-0.585 G loss:-2.201\n",
      "Epoch:  0057 D loss:-0.716 G loss:-2.342\n",
      "Epoch:  0057 D loss:-0.7777 G loss:-2.047\n",
      "Epoch:  0057 D loss:-0.6886 G loss:-2.408\n",
      "Epoch:  0057 D loss:-0.6705 G loss:-2.088\n",
      "Epoch:  0057 D loss:-0.5288 G loss:-2.088\n",
      "Epoch:  0057 D loss:-0.8001 G loss:-2.078\n",
      "Epoch:  0057 D loss:-0.7318 G loss:-2.143\n",
      "Epoch:  0057 D loss:-0.7407 G loss:-2.064\n",
      "Epoch:  0057 D loss:-0.7483 G loss:-2.178\n",
      "Epoch:  0057 D loss:-0.5158 G loss:-2.16\n",
      "Epoch:  0057 D loss:-0.7004 G loss:-2.072\n",
      "Epoch:  0057 D loss:-0.6435 G loss:-2.193\n",
      "Epoch:  0057 D loss:-0.7248 G loss:-1.992\n",
      "Epoch:  0057 D loss:-0.7452 G loss:-2.052\n",
      "Epoch:  0057 D loss:-0.6174 G loss:-2.242\n",
      "Epoch:  0057 D loss:-0.6477 G loss:-2.224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0057 D loss:-0.6224 G loss:-2.133\n",
      "Epoch:  0057 D loss:-0.6666 G loss:-2.416\n",
      "Epoch:  0057 D loss:-0.6664 G loss:-2.281\n",
      "Epoch:  0057 D loss:-0.7176 G loss:-2.163\n",
      "Epoch:  0057 D loss:-0.5235 G loss:-2.145\n",
      "Epoch:  0057 D loss:-0.7615 G loss:-2.018\n",
      "Epoch:  0057 D loss:-0.6512 G loss:-2.203\n",
      "Epoch:  0057 D loss:-0.6503 G loss:-1.998\n",
      "Epoch:  0057 D loss:-0.5931 G loss:-2.003\n",
      "Epoch:  0057 D loss:-0.5963 G loss:-2.223\n",
      "Epoch:  0057 D loss:-0.6275 G loss:-2.021\n",
      "Epoch:  0057 D loss:-0.6101 G loss:-2.131\n",
      "Epoch:  0057 D loss:-0.8022 G loss:-2.01\n",
      "Epoch:  0057 D loss:-0.5807 G loss:-2.17\n",
      "Epoch:  0057 D loss:-0.6045 G loss:-2.454\n",
      "Epoch:  0057 D loss:-0.6178 G loss:-2.248\n",
      "Epoch:  0057 D loss:-0.6462 G loss:-2.175\n",
      "Epoch:  0057 D loss:-0.6444 G loss:-2.285\n",
      "Epoch:  0057 D loss:-0.6088 G loss:-2.414\n",
      "Epoch:  0057 D loss:-0.6179 G loss:-2.394\n",
      "Epoch:  0057 D loss:-0.6844 G loss:-2.028\n",
      "Epoch:  0057 D loss:-0.6386 G loss:-2.256\n",
      "Epoch:  0057 D loss:-0.6408 G loss:-2.325\n",
      "Epoch:  0057 D loss:-0.6435 G loss:-2.074\n",
      "Epoch:  0057 D loss:-0.5638 G loss:-2.19\n",
      "Epoch:  0057 D loss:-0.5661 G loss:-2.048\n",
      "Epoch:  0057 D loss:-0.7391 G loss:-2.018\n",
      "Epoch:  0057 D loss:-0.7151 G loss:-2.115\n",
      "Epoch:  0057 D loss:-0.5881 G loss:-2.206\n",
      "Epoch:  0057 D loss:-0.669 G loss:-2.404\n",
      "Epoch:  0057 D loss:-0.7336 G loss:-2.103\n",
      "Epoch:  0057 D loss:-0.5884 G loss:-2.32\n",
      "Epoch:  0057 D loss:-0.5491 G loss:-2.203\n",
      "Epoch:  0057 D loss:-0.6335 G loss:-2.076\n",
      "Epoch:  0057 D loss:-0.6619 G loss:-2.147\n",
      "Epoch:  0057 D loss:-0.6684 G loss:-2.107\n",
      "Epoch:  0057 D loss:-0.6237 G loss:-2.058\n",
      "Epoch:  0057 D loss:-0.5922 G loss:-2.024\n",
      "Epoch:  0057 D loss:-0.7274 G loss:-2.17\n",
      "Epoch:  0057 D loss:-0.6237 G loss:-2.069\n",
      "Epoch:  0057 D loss:-0.6668 G loss:-2.202\n",
      "Epoch:  0057 D loss:-0.6586 G loss:-2.228\n",
      "Epoch:  0057 D loss:-0.7295 G loss:-2.094\n",
      "Epoch:  0057 D loss:-0.672 G loss:-2.214\n",
      "Epoch:  0057 D loss:-0.6287 G loss:-1.973\n",
      "Epoch:  0057 D loss:-0.5943 G loss:-2.389\n",
      "Epoch:  0057 D loss:-0.603 G loss:-2.455\n",
      "Epoch:  0057 D loss:-0.6314 G loss:-2.117\n",
      "Epoch:  0057 D loss:-0.6047 G loss:-2.312\n",
      "Epoch:  0057 D loss:-0.7265 G loss:-2.23\n",
      "Epoch:  0057 D loss:-0.6029 G loss:-1.991\n",
      "Epoch:  0057 D loss:-0.6869 G loss:-1.985\n",
      "Epoch:  0057 D loss:-0.7577 G loss:-1.881\n",
      "Epoch:  0057 D loss:-0.6477 G loss:-1.987\n",
      "Epoch:  0057 D loss:-0.8049 G loss:-1.882\n",
      "Epoch:  0057 D loss:-0.6268 G loss:-1.937\n",
      "Epoch:  0057 D loss:-0.6272 G loss:-2.113\n",
      "Epoch:  0057 D loss:-0.7311 G loss:-1.971\n",
      "Epoch:  0057 D loss:-0.763 G loss:-1.839\n",
      "Epoch:  0057 D loss:-0.6943 G loss:-2.038\n",
      "Epoch:  0057 D loss:-0.8164 G loss:-1.93\n",
      "Epoch:  0057 D loss:-0.6933 G loss:-2.165\n",
      "Epoch:  0057 D loss:-0.7591 G loss:-2.008\n",
      "Epoch:  0057 D loss:-0.6348 G loss:-2.297\n",
      "Epoch:  0057 D loss:-0.735 G loss:-2.112\n",
      "Epoch:  0057 D loss:-0.8459 G loss:-1.978\n",
      "Epoch:  0057 D loss:-0.701 G loss:-2.053\n",
      "Epoch:  0057 D loss:-0.7275 G loss:-2.084\n",
      "Epoch:  0057 D loss:-0.7847 G loss:-1.927\n",
      "Epoch:  0057 D loss:-0.6526 G loss:-2.168\n",
      "Epoch:  0057 D loss:-0.6865 G loss:-1.912\n",
      "Epoch:  0057 D loss:-0.755 G loss:-2.053\n",
      "Epoch:  0057 D loss:-0.8049 G loss:-1.975\n",
      "Epoch:  0057 D loss:-0.844 G loss:-1.788\n",
      "Epoch:  0057 D loss:-0.9027 G loss:-1.957\n",
      "Epoch:  0057 D loss:-0.7345 G loss:-2.037\n",
      "Epoch:  0057 D loss:-0.683 G loss:-1.779\n",
      "Epoch:  0057 D loss:-0.576 G loss:-2.09\n",
      "Epoch:  0057 D loss:-0.7522 G loss:-1.937\n",
      "Epoch:  0057 D loss:-0.6901 G loss:-2.039\n",
      "Epoch:  0057 D loss:-0.6183 G loss:-2.054\n",
      "Epoch:  0057 D loss:-0.7562 G loss:-1.957\n",
      "Epoch:  0057 D loss:-0.742 G loss:-2.178\n",
      "Epoch:  0057 D loss:-0.6731 G loss:-2.077\n",
      "Epoch:  0057 D loss:-0.8804 G loss:-2.114\n",
      "Epoch:  0057 D loss:-0.7247 G loss:-1.961\n",
      "Epoch:  0057 D loss:-0.6101 G loss:-2.116\n",
      "Epoch:  0057 D loss:-0.6797 G loss:-2.097\n",
      "Epoch:  0057 D loss:-0.6806 G loss:-2.225\n",
      "Epoch:  0057 D loss:-0.6304 G loss:-2.02\n",
      "Epoch:  0057 D loss:-0.6621 G loss:-2.121\n",
      "Epoch:  0057 D loss:-0.8142 G loss:-1.957\n",
      "Epoch:  0057 D loss:-0.7399 G loss:-2.034\n",
      "Epoch:  0057 D loss:-0.5893 G loss:-1.989\n",
      "Epoch:  0057 D loss:-0.7055 G loss:-1.971\n",
      "Epoch:  0057 D loss:-0.8442 G loss:-1.944\n",
      "Epoch:  0057 D loss:-0.6703 G loss:-2.097\n",
      "Epoch:  0057 D loss:-0.7119 G loss:-2.146\n",
      "Epoch:  0057 D loss:-0.6543 G loss:-1.92\n",
      "Epoch:  0057 D loss:-0.812 G loss:-2.105\n",
      "Epoch:  0057 D loss:-0.6268 G loss:-2.234\n",
      "Epoch:  0057 D loss:-0.8439 G loss:-1.898\n",
      "Epoch:  0057 D loss:-0.7942 G loss:-2.069\n",
      "Epoch:  0057 D loss:-0.6881 G loss:-1.843\n",
      "Epoch:  0057 D loss:-0.7693 G loss:-1.991\n",
      "Epoch:  0057 D loss:-0.7141 G loss:-2.168\n",
      "Epoch:  0057 D loss:-0.7299 G loss:-1.802\n",
      "Epoch:  0057 D loss:-0.788 G loss:-1.849\n",
      "Epoch:  0057 D loss:-0.7236 G loss:-1.968\n",
      "Epoch:  0057 D loss:-0.4989 G loss:-2.271\n",
      "Epoch:  0057 D loss:-0.7539 G loss:-2.046\n",
      "Epoch:  0057 D loss:-0.7679 G loss:-2.099\n",
      "Epoch:  0057 D loss:-0.6206 G loss:-2.263\n",
      "Epoch:  0057 D loss:-0.8016 G loss:-2.553\n",
      "Epoch:  0057 D loss:-0.6149 G loss:-2.135\n",
      "Epoch:  0057 D loss:-0.5676 G loss:-2.22\n",
      "Epoch:  0057 D loss:-0.682 G loss:-2.261\n",
      "Epoch:  0057 D loss:-0.6836 G loss:-2.2\n",
      "Epoch:  0057 D loss:-0.5146 G loss:-2.134\n",
      "Epoch:  0057 D loss:-0.5605 G loss:-2.256\n",
      "Epoch:  0057 D loss:-0.6969 G loss:-2.15\n",
      "Epoch:  0057 D loss:-0.6313 G loss:-2.048\n",
      "Epoch:  0057 D loss:-0.6179 G loss:-2.291\n",
      "Epoch:  0057 D loss:-0.5866 G loss:-2.175\n",
      "Epoch:  0057 D loss:-0.6415 G loss:-2.12\n",
      "Epoch:  0057 D loss:-0.7141 G loss:-2.026\n",
      "Epoch:  0057 D loss:-0.5618 G loss:-2.057\n",
      "Epoch:  0057 D loss:-0.6267 G loss:-2.26\n",
      "Epoch:  0057 D loss:-0.667 G loss:-2.318\n",
      "Epoch:  0057 D loss:-0.541 G loss:-2.366\n",
      "Epoch:  0057 D loss:-0.59 G loss:-2.269\n",
      "Epoch:  0057 D loss:-0.512 G loss:-2.599\n",
      "Epoch:  0057 D loss:-0.6403 G loss:-2.355\n",
      "Epoch:  0057 D loss:-0.7887 G loss:-1.986\n",
      "Epoch:  0057 D loss:-0.5197 G loss:-2.288\n",
      "Epoch:  0057 D loss:-0.7509 G loss:-1.993\n",
      "Epoch:  0057 D loss:-0.6368 G loss:-2.277\n",
      "Epoch:  0057 D loss:-0.5911 G loss:-2.332\n",
      "Epoch:  0057 D loss:-0.5875 G loss:-1.965\n",
      "Epoch:  0057 D loss:-0.7067 G loss:-1.93\n",
      "Epoch:  0057 D loss:-0.5675 G loss:-2.083\n",
      "Epoch:  0057 D loss:-0.5724 G loss:-1.921\n",
      "Epoch:  0057 D loss:-0.6926 G loss:-2.004\n",
      "Epoch:  0057 D loss:-0.5883 G loss:-2.072\n",
      "Epoch:  0057 D loss:-0.6122 G loss:-2.142\n",
      "Epoch:  0057 D loss:-0.6625 G loss:-2.257\n",
      "Epoch:  0057 D loss:-0.7675 G loss:-2.132\n",
      "Epoch:  0057 D loss:-0.5788 G loss:-2.185\n",
      "Epoch:  0057 D loss:-0.6245 G loss:-2.312\n",
      "Epoch:  0057 D loss:-0.6779 G loss:-2.398\n",
      "Epoch:  0057 D loss:-0.7376 G loss:-2.092\n",
      "Epoch:  0057 D loss:-0.6674 G loss:-2.18\n",
      "Epoch:  0057 D loss:-0.5958 G loss:-1.985\n",
      "Epoch:  0057 D loss:-0.6605 G loss:-1.884\n",
      "Epoch:  0057 D loss:-0.6485 G loss:-2.017\n",
      "Epoch:  0057 D loss:-0.5827 G loss:-1.958\n",
      "Epoch:  0057 D loss:-0.5734 G loss:-1.889\n",
      "Epoch:  0057 D loss:-0.6667 G loss:-2.158\n",
      "Epoch:  0057 D loss:-0.5565 G loss:-2.253\n",
      "Epoch:  0057 D loss:-0.6908 G loss:-1.987\n",
      "Epoch:  0057 D loss:-0.6262 G loss:-2.189\n",
      "Epoch:  0057 D loss:-0.5523 G loss:-2.059\n",
      "Epoch:  0057 D loss:-0.6447 G loss:-2.134\n",
      "Epoch:  0057 D loss:-0.5986 G loss:-2.336\n",
      "Epoch:  0057 D loss:-0.6268 G loss:-2.196\n",
      "Epoch:  0057 D loss:-0.7523 G loss:-2.081\n",
      "Epoch:  0057 D loss:-0.6952 G loss:-2.1\n",
      "Epoch:  0057 D loss:-0.7218 G loss:-2.077\n",
      "Epoch:  0057 D loss:-0.5239 G loss:-2.231\n",
      "Epoch:  0057 D loss:-0.6744 G loss:-2.056\n",
      "Epoch:  0057 D loss:-0.6776 G loss:-1.963\n",
      "Epoch:  0057 D loss:-0.5611 G loss:-2.164\n",
      "Epoch:  0057 D loss:-0.6923 G loss:-2.106\n",
      "Epoch:  0057 D loss:-0.6056 G loss:-1.936\n",
      "Epoch:  0057 D loss:-0.6852 G loss:-2.108\n",
      "Epoch:  0057 D loss:-0.8164 G loss:-1.971\n",
      "Epoch:  0057 D loss:-0.7291 G loss:-2.03\n",
      "Epoch:  0057 D loss:-0.6735 G loss:-1.952\n",
      "Epoch:  0058 D loss:-0.6906 G loss:-1.924\n",
      "Epoch:  0058 D loss:-0.6785 G loss:-2.011\n",
      "Epoch:  0058 D loss:-0.5887 G loss:-2.122\n",
      "Epoch:  0058 D loss:-0.5395 G loss:-2.215\n",
      "Epoch:  0058 D loss:-0.5989 G loss:-2.093\n",
      "Epoch:  0058 D loss:-0.6422 G loss:-2.309\n",
      "Epoch:  0058 D loss:-0.6902 G loss:-2.21\n",
      "Epoch:  0058 D loss:-0.6495 G loss:-2.083\n",
      "Epoch:  0058 D loss:-0.6397 G loss:-2.265\n",
      "Epoch:  0058 D loss:-0.7507 G loss:-2.222\n",
      "Epoch:  0058 D loss:-0.6592 G loss:-2.088\n",
      "Epoch:  0058 D loss:-0.6624 G loss:-2.036\n",
      "Epoch:  0058 D loss:-0.695 G loss:-1.901\n",
      "Epoch:  0058 D loss:-0.6402 G loss:-2.104\n",
      "Epoch:  0058 D loss:-0.8761 G loss:-1.862\n",
      "Epoch:  0058 D loss:-0.6222 G loss:-2.149\n",
      "Epoch:  0058 D loss:-0.7398 G loss:-2.008\n",
      "Epoch:  0058 D loss:-0.6001 G loss:-1.933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0058 D loss:-0.6675 G loss:-2.114\n",
      "Epoch:  0058 D loss:-0.6061 G loss:-2.222\n",
      "Epoch:  0058 D loss:-0.7418 G loss:-2.188\n",
      "Epoch:  0058 D loss:-0.7379 G loss:-2.112\n",
      "Epoch:  0058 D loss:-0.6413 G loss:-2.022\n",
      "Epoch:  0058 D loss:-0.6508 G loss:-1.89\n",
      "Epoch:  0058 D loss:-0.6856 G loss:-1.999\n",
      "Epoch:  0058 D loss:-0.7231 G loss:-1.934\n",
      "Epoch:  0058 D loss:-0.6661 G loss:-2.056\n",
      "Epoch:  0058 D loss:-0.6516 G loss:-2.121\n",
      "Epoch:  0058 D loss:-0.7937 G loss:-2.299\n",
      "Epoch:  0058 D loss:-0.817 G loss:-2.039\n",
      "Epoch:  0058 D loss:-0.7413 G loss:-1.975\n",
      "Epoch:  0058 D loss:-0.6634 G loss:-2.2\n",
      "Epoch:  0058 D loss:-0.7686 G loss:-1.953\n",
      "Epoch:  0058 D loss:-0.5726 G loss:-2.013\n",
      "Epoch:  0058 D loss:-0.778 G loss:-1.941\n",
      "Epoch:  0058 D loss:-0.7162 G loss:-1.917\n",
      "Epoch:  0058 D loss:-0.6002 G loss:-1.838\n",
      "Epoch:  0058 D loss:-0.642 G loss:-1.947\n",
      "Epoch:  0058 D loss:-0.6238 G loss:-2.128\n",
      "Epoch:  0058 D loss:-0.6526 G loss:-2.23\n",
      "Epoch:  0058 D loss:-0.6812 G loss:-2.21\n",
      "Epoch:  0058 D loss:-0.6506 G loss:-2.115\n",
      "Epoch:  0058 D loss:-0.7284 G loss:-2.135\n",
      "Epoch:  0058 D loss:-0.5703 G loss:-1.991\n",
      "Epoch:  0058 D loss:-0.5335 G loss:-2.167\n",
      "Epoch:  0058 D loss:-0.6377 G loss:-2.168\n",
      "Epoch:  0058 D loss:-0.5984 G loss:-2.324\n",
      "Epoch:  0058 D loss:-0.7115 G loss:-1.935\n",
      "Epoch:  0058 D loss:-0.6029 G loss:-2.335\n",
      "Epoch:  0058 D loss:-0.6332 G loss:-2.033\n",
      "Epoch:  0058 D loss:-0.649 G loss:-1.955\n",
      "Epoch:  0058 D loss:-0.6661 G loss:-2.071\n",
      "Epoch:  0058 D loss:-0.6375 G loss:-2.02\n",
      "Epoch:  0058 D loss:-0.7695 G loss:-1.903\n",
      "Epoch:  0058 D loss:-0.6306 G loss:-2.21\n",
      "Epoch:  0058 D loss:-0.708 G loss:-2.065\n",
      "Epoch:  0058 D loss:-0.8014 G loss:-2.1\n",
      "Epoch:  0058 D loss:-0.7058 G loss:-2.179\n",
      "Epoch:  0058 D loss:-0.6888 G loss:-2.008\n",
      "Epoch:  0058 D loss:-0.6804 G loss:-2.063\n",
      "Epoch:  0058 D loss:-0.722 G loss:-2.299\n",
      "Epoch:  0058 D loss:-0.7228 G loss:-2.094\n",
      "Epoch:  0058 D loss:-0.7028 G loss:-1.924\n",
      "Epoch:  0058 D loss:-0.6318 G loss:-2.176\n",
      "Epoch:  0058 D loss:-0.5861 G loss:-2.18\n",
      "Epoch:  0058 D loss:-0.7331 G loss:-2.329\n",
      "Epoch:  0058 D loss:-0.6346 G loss:-2.096\n",
      "Epoch:  0058 D loss:-0.7501 G loss:-1.954\n",
      "Epoch:  0058 D loss:-0.6739 G loss:-2.077\n",
      "Epoch:  0058 D loss:-0.5543 G loss:-2.219\n",
      "Epoch:  0058 D loss:-0.6006 G loss:-1.997\n",
      "Epoch:  0058 D loss:-0.6268 G loss:-1.983\n",
      "Epoch:  0058 D loss:-0.5992 G loss:-2.041\n",
      "Epoch:  0058 D loss:-0.6008 G loss:-2.114\n",
      "Epoch:  0058 D loss:-0.6559 G loss:-2.084\n",
      "Epoch:  0058 D loss:-0.5864 G loss:-2.232\n",
      "Epoch:  0058 D loss:-0.6149 G loss:-2.175\n",
      "Epoch:  0058 D loss:-0.5298 G loss:-2.216\n",
      "Epoch:  0058 D loss:-0.6061 G loss:-2.181\n",
      "Epoch:  0058 D loss:-0.5435 G loss:-2.154\n",
      "Epoch:  0058 D loss:-0.74 G loss:-2.104\n",
      "Epoch:  0058 D loss:-0.6844 G loss:-2.151\n",
      "Epoch:  0058 D loss:-0.6462 G loss:-1.887\n",
      "Epoch:  0058 D loss:-0.7135 G loss:-2.245\n",
      "Epoch:  0058 D loss:-0.6858 G loss:-1.9\n",
      "Epoch:  0058 D loss:-0.753 G loss:-2.222\n",
      "Epoch:  0058 D loss:-0.5407 G loss:-2.222\n",
      "Epoch:  0058 D loss:-0.6344 G loss:-1.855\n",
      "Epoch:  0058 D loss:-0.6249 G loss:-2.108\n",
      "Epoch:  0058 D loss:-0.7581 G loss:-2.081\n",
      "Epoch:  0058 D loss:-0.5645 G loss:-2.154\n",
      "Epoch:  0058 D loss:-0.5945 G loss:-2.122\n",
      "Epoch:  0058 D loss:-0.567 G loss:-2.423\n",
      "Epoch:  0058 D loss:-0.754 G loss:-2.231\n",
      "Epoch:  0058 D loss:-0.8111 G loss:-2.136\n",
      "Epoch:  0058 D loss:-0.7497 G loss:-2.153\n",
      "Epoch:  0058 D loss:-0.5671 G loss:-2.298\n",
      "Epoch:  0058 D loss:-0.5759 G loss:-2.205\n",
      "Epoch:  0058 D loss:-0.5881 G loss:-2.116\n",
      "Epoch:  0058 D loss:-0.7217 G loss:-1.979\n",
      "Epoch:  0058 D loss:-0.5269 G loss:-2.048\n",
      "Epoch:  0058 D loss:-0.6641 G loss:-2.009\n",
      "Epoch:  0058 D loss:-0.7534 G loss:-1.866\n",
      "Epoch:  0058 D loss:-0.588 G loss:-2.188\n",
      "Epoch:  0058 D loss:-0.6591 G loss:-2.163\n",
      "Epoch:  0058 D loss:-0.5239 G loss:-2.422\n",
      "Epoch:  0058 D loss:-0.6707 G loss:-2.082\n",
      "Epoch:  0058 D loss:-0.6695 G loss:-2.164\n",
      "Epoch:  0058 D loss:-0.7019 G loss:-2.102\n",
      "Epoch:  0058 D loss:-0.6266 G loss:-2.291\n",
      "Epoch:  0058 D loss:-0.5891 G loss:-2.303\n",
      "Epoch:  0058 D loss:-0.5692 G loss:-2.358\n",
      "Epoch:  0058 D loss:-0.6574 G loss:-2.26\n",
      "Epoch:  0058 D loss:-0.6767 G loss:-2.13\n",
      "Epoch:  0058 D loss:-0.6393 G loss:-2.007\n",
      "Epoch:  0058 D loss:-0.6475 G loss:-2.114\n",
      "Epoch:  0058 D loss:-0.6805 G loss:-1.869\n",
      "Epoch:  0058 D loss:-0.5954 G loss:-1.9\n",
      "Epoch:  0058 D loss:-0.6686 G loss:-2.079\n",
      "Epoch:  0058 D loss:-0.6067 G loss:-2.064\n",
      "Epoch:  0058 D loss:-0.6056 G loss:-1.958\n",
      "Epoch:  0058 D loss:-0.6158 G loss:-2.015\n",
      "Epoch:  0058 D loss:-0.6042 G loss:-2.165\n",
      "Epoch:  0058 D loss:-0.6678 G loss:-2.289\n",
      "Epoch:  0058 D loss:-0.6022 G loss:-2.268\n",
      "Epoch:  0058 D loss:-0.7714 G loss:-2.153\n",
      "Epoch:  0058 D loss:-0.6802 G loss:-2.241\n",
      "Epoch:  0058 D loss:-0.5569 G loss:-2.481\n",
      "Epoch:  0058 D loss:-0.6995 G loss:-2.292\n",
      "Epoch:  0058 D loss:-0.6893 G loss:-2.237\n",
      "Epoch:  0058 D loss:-0.6591 G loss:-2.121\n",
      "Epoch:  0058 D loss:-0.6584 G loss:-2.103\n",
      "Epoch:  0058 D loss:-0.7001 G loss:-2.104\n",
      "Epoch:  0058 D loss:-0.5853 G loss:-2.054\n",
      "Epoch:  0058 D loss:-0.7014 G loss:-2.211\n",
      "Epoch:  0058 D loss:-0.6217 G loss:-1.986\n",
      "Epoch:  0058 D loss:-0.7815 G loss:-1.976\n",
      "Epoch:  0058 D loss:-0.6936 G loss:-2.068\n",
      "Epoch:  0058 D loss:-0.6455 G loss:-2.143\n",
      "Epoch:  0058 D loss:-0.4733 G loss:-2.269\n",
      "Epoch:  0058 D loss:-0.5943 G loss:-2.322\n",
      "Epoch:  0058 D loss:-0.6534 G loss:-2.391\n",
      "Epoch:  0058 D loss:-0.7204 G loss:-2.112\n",
      "Epoch:  0058 D loss:-0.5819 G loss:-2.123\n",
      "Epoch:  0058 D loss:-0.6407 G loss:-2.212\n",
      "Epoch:  0058 D loss:-0.6629 G loss:-2.07\n",
      "Epoch:  0058 D loss:-0.7932 G loss:-1.803\n",
      "Epoch:  0058 D loss:-0.651 G loss:-2.122\n",
      "Epoch:  0058 D loss:-0.6401 G loss:-2.201\n",
      "Epoch:  0058 D loss:-0.6732 G loss:-2.005\n",
      "Epoch:  0058 D loss:-0.7924 G loss:-1.892\n",
      "Epoch:  0058 D loss:-0.7512 G loss:-1.809\n",
      "Epoch:  0058 D loss:-0.6403 G loss:-1.952\n",
      "Epoch:  0058 D loss:-0.7987 G loss:-1.916\n",
      "Epoch:  0058 D loss:-0.6416 G loss:-2.038\n",
      "Epoch:  0058 D loss:-0.7458 G loss:-2.047\n",
      "Epoch:  0058 D loss:-0.7122 G loss:-2.298\n",
      "Epoch:  0058 D loss:-0.6816 G loss:-1.958\n",
      "Epoch:  0058 D loss:-0.7468 G loss:-2.011\n",
      "Epoch:  0058 D loss:-0.7348 G loss:-1.974\n",
      "Epoch:  0058 D loss:-0.6903 G loss:-2.122\n",
      "Epoch:  0058 D loss:-0.6694 G loss:-2.033\n",
      "Epoch:  0058 D loss:-0.7937 G loss:-1.978\n",
      "Epoch:  0058 D loss:-0.6707 G loss:-2.274\n",
      "Epoch:  0058 D loss:-0.7287 G loss:-2.045\n",
      "Epoch:  0058 D loss:-0.6652 G loss:-2.085\n",
      "Epoch:  0058 D loss:-0.7632 G loss:-1.919\n",
      "Epoch:  0058 D loss:-0.7853 G loss:-1.814\n",
      "Epoch:  0058 D loss:-0.5953 G loss:-2.11\n",
      "Epoch:  0058 D loss:-0.8098 G loss:-1.905\n",
      "Epoch:  0058 D loss:-0.6773 G loss:-2.023\n",
      "Epoch:  0058 D loss:-0.6845 G loss:-2.224\n",
      "Epoch:  0058 D loss:-0.5146 G loss:-2.125\n",
      "Epoch:  0058 D loss:-0.7185 G loss:-1.981\n",
      "Epoch:  0058 D loss:-0.68 G loss:-2.171\n",
      "Epoch:  0058 D loss:-0.7646 G loss:-2.11\n",
      "Epoch:  0058 D loss:-0.558 G loss:-2.25\n",
      "Epoch:  0058 D loss:-0.7216 G loss:-2.17\n",
      "Epoch:  0058 D loss:-0.6964 G loss:-1.811\n",
      "Epoch:  0058 D loss:-0.556 G loss:-2.133\n",
      "Epoch:  0058 D loss:-0.7186 G loss:-2.086\n",
      "Epoch:  0058 D loss:-0.5781 G loss:-2.052\n",
      "Epoch:  0058 D loss:-0.7486 G loss:-1.859\n",
      "Epoch:  0058 D loss:-0.6107 G loss:-2.381\n",
      "Epoch:  0058 D loss:-0.7551 G loss:-2.116\n",
      "Epoch:  0058 D loss:-0.713 G loss:-2.0\n",
      "Epoch:  0058 D loss:-0.6281 G loss:-2.083\n",
      "Epoch:  0058 D loss:-0.6555 G loss:-1.965\n",
      "Epoch:  0058 D loss:-0.4934 G loss:-1.978\n",
      "Epoch:  0058 D loss:-0.7147 G loss:-1.795\n",
      "Epoch:  0058 D loss:-0.6551 G loss:-2.075\n",
      "Epoch:  0058 D loss:-0.8283 G loss:-1.786\n",
      "Epoch:  0058 D loss:-0.8776 G loss:-1.918\n",
      "Epoch:  0058 D loss:-0.6183 G loss:-2.162\n",
      "Epoch:  0058 D loss:-0.794 G loss:-2.209\n",
      "Epoch:  0058 D loss:-0.6194 G loss:-2.326\n",
      "Epoch:  0058 D loss:-0.7313 G loss:-2.269\n",
      "Epoch:  0058 D loss:-0.7438 G loss:-2.238\n",
      "Epoch:  0058 D loss:-0.6946 G loss:-2.43\n",
      "Epoch:  0058 D loss:-0.6864 G loss:-2.039\n",
      "Epoch:  0058 D loss:-0.681 G loss:-2.149\n",
      "Epoch:  0058 D loss:-0.6055 G loss:-2.081\n",
      "Epoch:  0058 D loss:-0.8699 G loss:-1.889\n",
      "Epoch:  0058 D loss:-0.5658 G loss:-2.078\n",
      "Epoch:  0058 D loss:-0.7979 G loss:-1.947\n",
      "Epoch:  0058 D loss:-0.5746 G loss:-1.907\n",
      "Epoch:  0058 D loss:-0.7968 G loss:-1.895\n",
      "Epoch:  0058 D loss:-0.6517 G loss:-1.957\n",
      "Epoch:  0058 D loss:-0.7869 G loss:-1.873\n",
      "Epoch:  0058 D loss:-0.7734 G loss:-2.077\n",
      "Epoch:  0058 D loss:-0.6311 G loss:-1.974\n",
      "Epoch:  0058 D loss:-0.6576 G loss:-2.14\n",
      "Epoch:  0058 D loss:-0.7811 G loss:-2.141\n",
      "Epoch:  0058 D loss:-0.6296 G loss:-2.099\n",
      "Epoch:  0058 D loss:-0.71 G loss:-2.224\n",
      "Epoch:  0058 D loss:-0.6724 G loss:-2.299\n",
      "Epoch:  0058 D loss:-0.5479 G loss:-2.373\n",
      "Epoch:  0058 D loss:-0.466 G loss:-2.339\n",
      "Epoch:  0058 D loss:-0.7095 G loss:-2.258\n",
      "Epoch:  0058 D loss:-0.6672 G loss:-2.289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0058 D loss:-0.4263 G loss:-2.21\n",
      "Epoch:  0058 D loss:-0.6054 G loss:-2.189\n",
      "Epoch:  0058 D loss:-0.8271 G loss:-2.069\n",
      "Epoch:  0058 D loss:-0.6286 G loss:-2.169\n",
      "Epoch:  0058 D loss:-0.5893 G loss:-2.022\n",
      "Epoch:  0058 D loss:-0.5626 G loss:-2.156\n",
      "Epoch:  0058 D loss:-0.6143 G loss:-2.177\n",
      "Epoch:  0058 D loss:-0.5796 G loss:-2.248\n",
      "Epoch:  0058 D loss:-0.7218 G loss:-2.031\n",
      "Epoch:  0058 D loss:-0.6675 G loss:-2.129\n",
      "Epoch:  0058 D loss:-0.6842 G loss:-2.251\n",
      "Epoch:  0058 D loss:-0.5132 G loss:-2.037\n",
      "Epoch:  0058 D loss:-0.5326 G loss:-2.145\n",
      "Epoch:  0058 D loss:-0.5418 G loss:-2.143\n",
      "Epoch:  0058 D loss:-0.6208 G loss:-2.189\n",
      "Epoch:  0058 D loss:-0.6542 G loss:-2.066\n",
      "Epoch:  0058 D loss:-0.7697 G loss:-2.299\n",
      "Epoch:  0058 D loss:-0.6091 G loss:-2.228\n",
      "Epoch:  0058 D loss:-0.5926 G loss:-2.195\n",
      "Epoch:  0058 D loss:-0.5686 G loss:-2.195\n",
      "Epoch:  0058 D loss:-0.5734 G loss:-2.041\n",
      "Epoch:  0058 D loss:-0.5385 G loss:-2.048\n",
      "Epoch:  0058 D loss:-0.5543 G loss:-2.205\n",
      "Epoch:  0058 D loss:-0.7099 G loss:-2.159\n",
      "Epoch:  0058 D loss:-0.6123 G loss:-2.245\n",
      "Epoch:  0058 D loss:-0.8329 G loss:-2.035\n",
      "Epoch:  0058 D loss:-0.5901 G loss:-2.063\n",
      "Epoch:  0058 D loss:-0.6547 G loss:-2.143\n",
      "Epoch:  0058 D loss:-0.5913 G loss:-2.053\n",
      "Epoch:  0058 D loss:-0.5907 G loss:-2.226\n",
      "Epoch:  0058 D loss:-0.6552 G loss:-2.232\n",
      "Epoch:  0058 D loss:-0.5923 G loss:-2.07\n",
      "Epoch:  0058 D loss:-0.6913 G loss:-2.091\n",
      "Epoch:  0058 D loss:-0.5839 G loss:-2.177\n",
      "Epoch:  0058 D loss:-0.5969 G loss:-2.032\n",
      "Epoch:  0058 D loss:-0.7055 G loss:-2.006\n",
      "Epoch:  0058 D loss:-0.783 G loss:-1.886\n",
      "Epoch:  0058 D loss:-0.6135 G loss:-1.927\n",
      "Epoch:  0058 D loss:-0.6654 G loss:-2.17\n",
      "Epoch:  0058 D loss:-0.725 G loss:-2.077\n",
      "Epoch:  0058 D loss:-0.675 G loss:-2.026\n",
      "Epoch:  0058 D loss:-0.576 G loss:-2.339\n",
      "Epoch:  0058 D loss:-0.6077 G loss:-2.117\n",
      "Epoch:  0058 D loss:-0.6153 G loss:-2.038\n",
      "Epoch:  0058 D loss:-0.607 G loss:-2.041\n",
      "Epoch:  0058 D loss:-0.6046 G loss:-2.17\n",
      "Epoch:  0058 D loss:-0.6601 G loss:-2.026\n",
      "Epoch:  0058 D loss:-0.63 G loss:-2.143\n",
      "Epoch:  0058 D loss:-0.6075 G loss:-2.202\n",
      "Epoch:  0058 D loss:-0.6311 G loss:-2.13\n",
      "Epoch:  0058 D loss:-0.6275 G loss:-2.035\n",
      "Epoch:  0058 D loss:-0.5758 G loss:-2.186\n",
      "Epoch:  0058 D loss:-0.6162 G loss:-2.167\n",
      "Epoch:  0058 D loss:-0.6453 G loss:-2.179\n",
      "Epoch:  0058 D loss:-0.5185 G loss:-2.317\n",
      "Epoch:  0058 D loss:-0.7123 G loss:-2.233\n",
      "Epoch:  0058 D loss:-0.6184 G loss:-2.175\n",
      "Epoch:  0058 D loss:-0.6102 G loss:-2.188\n",
      "Epoch:  0058 D loss:-0.6172 G loss:-2.068\n",
      "Epoch:  0058 D loss:-0.6331 G loss:-1.997\n",
      "Epoch:  0058 D loss:-0.7476 G loss:-2.044\n",
      "Epoch:  0058 D loss:-0.8191 G loss:-2.201\n",
      "Epoch:  0058 D loss:-0.7128 G loss:-2.025\n",
      "Epoch:  0058 D loss:-0.7609 G loss:-1.954\n",
      "Epoch:  0058 D loss:-0.6272 G loss:-2.156\n",
      "Epoch:  0058 D loss:-0.7428 G loss:-1.84\n",
      "Epoch:  0058 D loss:-0.6087 G loss:-2.25\n",
      "Epoch:  0058 D loss:-0.5437 G loss:-2.233\n",
      "Epoch:  0058 D loss:-0.6897 G loss:-2.263\n",
      "Epoch:  0058 D loss:-0.7625 G loss:-1.918\n",
      "Epoch:  0058 D loss:-0.7462 G loss:-1.91\n",
      "Epoch:  0058 D loss:-0.6853 G loss:-1.995\n",
      "Epoch:  0058 D loss:-0.6082 G loss:-2.154\n",
      "Epoch:  0058 D loss:-0.7825 G loss:-1.965\n",
      "Epoch:  0058 D loss:-0.7368 G loss:-1.998\n",
      "Epoch:  0058 D loss:-0.6195 G loss:-2.146\n",
      "Epoch:  0058 D loss:-0.6484 G loss:-2.169\n",
      "Epoch:  0058 D loss:-0.6794 G loss:-2.248\n",
      "Epoch:  0058 D loss:-0.5983 G loss:-2.146\n",
      "Epoch:  0058 D loss:-0.6195 G loss:-2.136\n",
      "Epoch:  0058 D loss:-0.6041 G loss:-2.203\n",
      "Epoch:  0058 D loss:-0.5316 G loss:-2.088\n",
      "Epoch:  0058 D loss:-0.7457 G loss:-2.302\n",
      "Epoch:  0058 D loss:-0.7914 G loss:-2.12\n",
      "Epoch:  0058 D loss:-0.6693 G loss:-2.002\n",
      "Epoch:  0058 D loss:-0.6625 G loss:-1.984\n",
      "Epoch:  0058 D loss:-0.721 G loss:-2.094\n",
      "Epoch:  0058 D loss:-0.6691 G loss:-1.842\n",
      "Epoch:  0058 D loss:-0.7326 G loss:-2.002\n",
      "Epoch:  0058 D loss:-0.6402 G loss:-2.132\n",
      "Epoch:  0058 D loss:-0.8067 G loss:-1.867\n",
      "Epoch:  0058 D loss:-0.6528 G loss:-2.127\n",
      "Epoch:  0058 D loss:-0.738 G loss:-2.092\n",
      "Epoch:  0058 D loss:-0.6813 G loss:-2.384\n",
      "Epoch:  0058 D loss:-0.5647 G loss:-2.363\n",
      "Epoch:  0058 D loss:-0.7493 G loss:-1.864\n",
      "Epoch:  0058 D loss:-0.5112 G loss:-2.409\n",
      "Epoch:  0058 D loss:-0.6586 G loss:-2.074\n",
      "Epoch:  0058 D loss:-0.5356 G loss:-2.094\n",
      "Epoch:  0058 D loss:-0.6479 G loss:-2.083\n",
      "Epoch:  0058 D loss:-0.5512 G loss:-2.011\n",
      "Epoch:  0058 D loss:-0.6238 G loss:-2.013\n",
      "Epoch:  0058 D loss:-0.6015 G loss:-2.175\n",
      "Epoch:  0058 D loss:-0.6236 G loss:-2.144\n",
      "Epoch:  0058 D loss:-0.6095 G loss:-2.303\n",
      "Epoch:  0058 D loss:-0.6791 G loss:-2.265\n",
      "Epoch:  0058 D loss:-0.6964 G loss:-2.245\n",
      "Epoch:  0058 D loss:-0.5249 G loss:-2.448\n",
      "Epoch:  0058 D loss:-0.5258 G loss:-2.24\n",
      "Epoch:  0058 D loss:-0.7623 G loss:-2.059\n",
      "Epoch:  0058 D loss:-0.5507 G loss:-2.283\n",
      "Epoch:  0058 D loss:-0.6582 G loss:-1.981\n",
      "Epoch:  0058 D loss:-0.6812 G loss:-1.917\n",
      "Epoch:  0058 D loss:-0.5955 G loss:-1.918\n",
      "Epoch:  0058 D loss:-0.6897 G loss:-1.944\n",
      "Epoch:  0058 D loss:-0.664 G loss:-1.917\n",
      "Epoch:  0058 D loss:-0.6405 G loss:-2.169\n",
      "Epoch:  0058 D loss:-0.6294 G loss:-1.895\n",
      "Epoch:  0058 D loss:-0.6457 G loss:-2.038\n",
      "Epoch:  0058 D loss:-0.6565 G loss:-2.149\n",
      "Epoch:  0058 D loss:-0.729 G loss:-2.047\n",
      "Epoch:  0058 D loss:-0.626 G loss:-2.295\n",
      "Epoch:  0058 D loss:-0.8548 G loss:-2.126\n",
      "Epoch:  0058 D loss:-0.5869 G loss:-2.324\n",
      "Epoch:  0058 D loss:-0.4981 G loss:-2.536\n",
      "Epoch:  0058 D loss:-0.6496 G loss:-2.226\n",
      "Epoch:  0058 D loss:-0.5113 G loss:-2.232\n",
      "Epoch:  0058 D loss:-0.7164 G loss:-2.113\n",
      "Epoch:  0058 D loss:-0.5775 G loss:-2.357\n",
      "Epoch:  0058 D loss:-0.7396 G loss:-2.081\n",
      "Epoch:  0058 D loss:-0.5689 G loss:-2.202\n",
      "Epoch:  0058 D loss:-0.5799 G loss:-2.258\n",
      "Epoch:  0058 D loss:-0.659 G loss:-2.184\n",
      "Epoch:  0058 D loss:-0.7271 G loss:-1.825\n",
      "Epoch:  0058 D loss:-0.7091 G loss:-1.986\n",
      "Epoch:  0058 D loss:-0.7692 G loss:-2.041\n",
      "Epoch:  0058 D loss:-0.7501 G loss:-2.038\n",
      "Epoch:  0058 D loss:-0.6301 G loss:-2.213\n",
      "Epoch:  0058 D loss:-0.7632 G loss:-1.97\n",
      "Epoch:  0058 D loss:-0.6559 G loss:-2.021\n",
      "Epoch:  0058 D loss:-0.7949 G loss:-1.974\n",
      "Epoch:  0058 D loss:-0.4919 G loss:-2.221\n",
      "Epoch:  0058 D loss:-0.6561 G loss:-2.089\n",
      "Epoch:  0058 D loss:-0.6527 G loss:-2.125\n",
      "Epoch:  0058 D loss:-0.7327 G loss:-2.108\n",
      "Epoch:  0058 D loss:-0.7202 G loss:-2.011\n",
      "Epoch:  0058 D loss:-0.7733 G loss:-2.067\n",
      "Epoch:  0058 D loss:-0.7247 G loss:-2.134\n",
      "Epoch:  0058 D loss:-0.6372 G loss:-2.148\n",
      "Epoch:  0058 D loss:-0.6527 G loss:-2.218\n",
      "Epoch:  0058 D loss:-0.5992 G loss:-2.13\n",
      "Epoch:  0058 D loss:-0.5701 G loss:-2.001\n",
      "Epoch:  0058 D loss:-0.7424 G loss:-2.062\n",
      "Epoch:  0058 D loss:-0.7096 G loss:-1.992\n",
      "Epoch:  0058 D loss:-0.6894 G loss:-2.214\n",
      "Epoch:  0058 D loss:-0.5506 G loss:-2.049\n",
      "Epoch:  0058 D loss:-0.5304 G loss:-2.127\n",
      "Epoch:  0058 D loss:-0.6683 G loss:-2.001\n",
      "Epoch:  0058 D loss:-0.6998 G loss:-1.862\n",
      "Epoch:  0058 D loss:-0.6104 G loss:-2.068\n",
      "Epoch:  0058 D loss:-0.5876 G loss:-2.012\n",
      "Epoch:  0058 D loss:-0.6913 G loss:-2.253\n",
      "Epoch:  0058 D loss:-0.6926 G loss:-2.39\n",
      "Epoch:  0058 D loss:-0.62 G loss:-2.299\n",
      "Epoch:  0058 D loss:-0.5585 G loss:-2.185\n",
      "Epoch:  0058 D loss:-0.6024 G loss:-2.093\n",
      "Epoch:  0058 D loss:-0.666 G loss:-2.253\n",
      "Epoch:  0058 D loss:-0.5352 G loss:-2.447\n",
      "Epoch:  0058 D loss:-0.5895 G loss:-2.365\n",
      "Epoch:  0058 D loss:-0.6523 G loss:-2.262\n",
      "Epoch:  0058 D loss:-0.7795 G loss:-2.095\n",
      "Epoch:  0058 D loss:-0.6413 G loss:-2.104\n",
      "Epoch:  0058 D loss:-0.6339 G loss:-2.105\n",
      "Epoch:  0058 D loss:-0.7966 G loss:-1.925\n",
      "Epoch:  0058 D loss:-0.4707 G loss:-2.032\n",
      "Epoch:  0058 D loss:-0.6074 G loss:-1.835\n",
      "Epoch:  0058 D loss:-0.5772 G loss:-2.017\n",
      "Epoch:  0058 D loss:-0.6111 G loss:-1.879\n",
      "Epoch:  0058 D loss:-0.6715 G loss:-1.951\n",
      "Epoch:  0058 D loss:-0.6075 G loss:-2.198\n",
      "Epoch:  0058 D loss:-0.642 G loss:-2.3\n",
      "Epoch:  0058 D loss:-0.6284 G loss:-2.388\n",
      "Epoch:  0058 D loss:-0.5217 G loss:-2.425\n",
      "Epoch:  0058 D loss:-0.6951 G loss:-2.424\n",
      "Epoch:  0058 D loss:-0.7366 G loss:-2.338\n",
      "Epoch:  0058 D loss:-0.6059 G loss:-2.327\n",
      "Epoch:  0058 D loss:-0.7337 G loss:-2.142\n",
      "Epoch:  0058 D loss:-0.6742 G loss:-1.987\n",
      "Epoch:  0058 D loss:-0.8762 G loss:-1.919\n",
      "Epoch:  0058 D loss:-0.7804 G loss:-1.802\n",
      "Epoch:  0058 D loss:-0.5903 G loss:-1.865\n",
      "Epoch:  0058 D loss:-0.6026 G loss:-1.789\n",
      "Epoch:  0058 D loss:-0.8021 G loss:-1.777\n",
      "Epoch:  0058 D loss:-0.5697 G loss:-1.835\n",
      "Epoch:  0058 D loss:-0.6726 G loss:-2.067\n",
      "Epoch:  0058 D loss:-0.78 G loss:-1.948\n",
      "Epoch:  0058 D loss:-0.6289 G loss:-2.091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0058 D loss:-0.6718 G loss:-2.111\n",
      "Epoch:  0058 D loss:-0.7088 G loss:-2.182\n",
      "Epoch:  0058 D loss:-0.6417 G loss:-2.119\n",
      "Epoch:  0058 D loss:-0.5831 G loss:-2.293\n",
      "Epoch:  0058 D loss:-0.6647 G loss:-2.174\n",
      "Epoch:  0058 D loss:-0.7305 G loss:-2.115\n",
      "Epoch:  0058 D loss:-0.6934 G loss:-2.194\n",
      "Epoch:  0058 D loss:-0.6577 G loss:-2.195\n",
      "Epoch:  0058 D loss:-0.5241 G loss:-2.224\n",
      "Epoch:  0058 D loss:-0.5616 G loss:-2.117\n",
      "Epoch:  0058 D loss:-0.6281 G loss:-2.097\n",
      "Epoch:  0058 D loss:-0.5844 G loss:-2.108\n",
      "Epoch:  0058 D loss:-0.7112 G loss:-1.996\n",
      "Epoch:  0058 D loss:-0.688 G loss:-2.121\n",
      "Epoch:  0058 D loss:-0.5296 G loss:-2.104\n",
      "Epoch:  0058 D loss:-0.5998 G loss:-2.135\n",
      "Epoch:  0058 D loss:-0.766 G loss:-2.0\n",
      "Epoch:  0058 D loss:-0.4679 G loss:-2.226\n",
      "Epoch:  0058 D loss:-0.6575 G loss:-2.144\n",
      "Epoch:  0058 D loss:-0.6057 G loss:-1.988\n",
      "Epoch:  0058 D loss:-0.682 G loss:-2.307\n",
      "Epoch:  0058 D loss:-0.8437 G loss:-2.173\n",
      "Epoch:  0058 D loss:-0.7021 G loss:-2.057\n",
      "Epoch:  0058 D loss:-0.6511 G loss:-2.122\n",
      "Epoch:  0058 D loss:-0.5042 G loss:-2.189\n",
      "Epoch:  0058 D loss:-0.8032 G loss:-1.983\n",
      "Epoch:  0058 D loss:-0.598 G loss:-2.059\n",
      "Epoch:  0058 D loss:-0.5483 G loss:-2.111\n",
      "Epoch:  0058 D loss:-0.5649 G loss:-2.057\n",
      "Epoch:  0058 D loss:-0.7703 G loss:-1.902\n",
      "Epoch:  0058 D loss:-0.5803 G loss:-2.319\n",
      "Epoch:  0058 D loss:-0.6172 G loss:-2.137\n",
      "Epoch:  0058 D loss:-0.6128 G loss:-2.034\n",
      "Epoch:  0058 D loss:-0.6462 G loss:-1.883\n",
      "Epoch:  0058 D loss:-0.642 G loss:-2.068\n",
      "Epoch:  0058 D loss:-0.7222 G loss:-2.325\n",
      "Epoch:  0058 D loss:-0.7275 G loss:-2.023\n",
      "Epoch:  0058 D loss:-0.7395 G loss:-2.244\n",
      "Epoch:  0058 D loss:-0.7956 G loss:-2.09\n",
      "Epoch:  0058 D loss:-0.5167 G loss:-2.182\n",
      "Epoch:  0058 D loss:-0.7022 G loss:-2.087\n",
      "Epoch:  0058 D loss:-0.6952 G loss:-2.075\n",
      "Epoch:  0058 D loss:-0.6712 G loss:-2.118\n",
      "Epoch:  0058 D loss:-0.6698 G loss:-1.796\n",
      "Epoch:  0058 D loss:-0.6926 G loss:-1.914\n",
      "Epoch:  0058 D loss:-0.7346 G loss:-2.009\n",
      "Epoch:  0058 D loss:-0.5929 G loss:-1.99\n",
      "Epoch:  0058 D loss:-0.5716 G loss:-2.189\n",
      "Epoch:  0058 D loss:-0.7016 G loss:-2.099\n",
      "Epoch:  0058 D loss:-0.6229 G loss:-2.172\n",
      "Epoch:  0058 D loss:-0.6276 G loss:-2.334\n",
      "Epoch:  0058 D loss:-0.6624 G loss:-2.386\n",
      "Epoch:  0058 D loss:-0.4984 G loss:-2.382\n",
      "Epoch:  0058 D loss:-0.6626 G loss:-2.367\n",
      "Epoch:  0058 D loss:-0.61 G loss:-2.35\n",
      "Epoch:  0058 D loss:-0.6248 G loss:-2.34\n",
      "Epoch:  0058 D loss:-0.6099 G loss:-2.284\n",
      "Epoch:  0058 D loss:-0.7413 G loss:-2.138\n",
      "Epoch:  0058 D loss:-0.8012 G loss:-1.887\n",
      "Epoch:  0058 D loss:-0.7034 G loss:-1.954\n",
      "Epoch:  0058 D loss:-0.7485 G loss:-1.866\n",
      "Epoch:  0058 D loss:-0.585 G loss:-2.069\n",
      "Epoch:  0058 D loss:-0.5097 G loss:-2.098\n",
      "Epoch:  0058 D loss:-0.74 G loss:-1.847\n",
      "Epoch:  0058 D loss:-0.5876 G loss:-2.049\n",
      "Epoch:  0058 D loss:-0.6149 G loss:-2.226\n",
      "Epoch:  0058 D loss:-0.6589 G loss:-1.967\n",
      "Epoch:  0058 D loss:-0.6662 G loss:-2.313\n",
      "Epoch:  0058 D loss:-0.6745 G loss:-2.151\n",
      "Epoch:  0058 D loss:-0.6698 G loss:-2.201\n",
      "Epoch:  0058 D loss:-0.5987 G loss:-2.201\n",
      "Epoch:  0058 D loss:-0.5716 G loss:-2.195\n",
      "Epoch:  0058 D loss:-0.6393 G loss:-2.199\n",
      "Epoch:  0058 D loss:-0.6505 G loss:-2.064\n",
      "Epoch:  0058 D loss:-0.5889 G loss:-2.209\n",
      "Epoch:  0058 D loss:-0.681 G loss:-2.162\n",
      "Epoch:  0058 D loss:-0.6772 G loss:-1.792\n",
      "Epoch:  0058 D loss:-0.6803 G loss:-2.003\n",
      "Epoch:  0058 D loss:-0.5727 G loss:-1.981\n",
      "Epoch:  0058 D loss:-0.6067 G loss:-2.138\n",
      "Epoch:  0058 D loss:-0.594 G loss:-2.141\n",
      "Epoch:  0058 D loss:-0.5649 G loss:-2.215\n",
      "Epoch:  0058 D loss:-0.6188 G loss:-2.261\n",
      "Epoch:  0058 D loss:-0.715 G loss:-1.942\n",
      "Epoch:  0058 D loss:-0.6733 G loss:-1.947\n",
      "Epoch:  0058 D loss:-0.5766 G loss:-2.2\n",
      "Epoch:  0058 D loss:-0.7262 G loss:-2.017\n",
      "Epoch:  0058 D loss:-0.6177 G loss:-2.194\n",
      "Epoch:  0058 D loss:-0.6507 G loss:-2.146\n",
      "Epoch:  0058 D loss:-0.6857 G loss:-2.208\n",
      "Epoch:  0058 D loss:-0.7182 G loss:-1.87\n",
      "Epoch:  0058 D loss:-0.6123 G loss:-1.988\n",
      "Epoch:  0058 D loss:-0.7454 G loss:-2.044\n",
      "Epoch:  0058 D loss:-0.6687 G loss:-2.142\n",
      "Epoch:  0058 D loss:-0.682 G loss:-2.075\n",
      "Epoch:  0058 D loss:-0.6543 G loss:-1.995\n",
      "Epoch:  0058 D loss:-0.5933 G loss:-2.234\n",
      "Epoch:  0058 D loss:-0.7064 G loss:-1.887\n",
      "Epoch:  0058 D loss:-0.7272 G loss:-2.16\n",
      "Epoch:  0058 D loss:-0.696 G loss:-1.896\n",
      "Epoch:  0058 D loss:-0.5924 G loss:-2.095\n",
      "Epoch:  0058 D loss:-0.7819 G loss:-2.035\n",
      "Epoch:  0058 D loss:-0.6785 G loss:-2.149\n",
      "Epoch:  0058 D loss:-0.6738 G loss:-2.196\n",
      "Epoch:  0058 D loss:-0.5384 G loss:-2.116\n",
      "Epoch:  0058 D loss:-0.623 G loss:-2.297\n",
      "Epoch:  0058 D loss:-0.6772 G loss:-2.291\n",
      "Epoch:  0058 D loss:-0.7264 G loss:-2.328\n",
      "Epoch:  0058 D loss:-0.6961 G loss:-2.194\n",
      "Epoch:  0058 D loss:-0.6636 G loss:-2.218\n",
      "Epoch:  0058 D loss:-0.6645 G loss:-2.124\n",
      "Epoch:  0058 D loss:-0.6333 G loss:-2.057\n",
      "Epoch:  0058 D loss:-0.7068 G loss:-1.982\n",
      "Epoch:  0058 D loss:-0.6865 G loss:-1.986\n",
      "Epoch:  0058 D loss:-0.7007 G loss:-1.857\n",
      "Epoch:  0058 D loss:-0.7262 G loss:-2.01\n",
      "Epoch:  0058 D loss:-0.7095 G loss:-1.984\n",
      "Epoch:  0058 D loss:-0.5497 G loss:-2.05\n",
      "Epoch:  0058 D loss:-0.7745 G loss:-2.172\n",
      "Epoch:  0058 D loss:-0.661 G loss:-2.14\n",
      "Epoch:  0058 D loss:-0.5435 G loss:-2.465\n",
      "Epoch:  0058 D loss:-0.5429 G loss:-2.353\n",
      "Epoch:  0058 D loss:-0.7372 G loss:-2.147\n",
      "Epoch:  0058 D loss:-0.7264 G loss:-2.144\n",
      "Epoch:  0058 D loss:-0.7139 G loss:-1.906\n",
      "Epoch:  0058 D loss:-0.6683 G loss:-1.949\n",
      "Epoch:  0058 D loss:-0.6544 G loss:-2.054\n",
      "Epoch:  0058 D loss:-0.5701 G loss:-2.249\n",
      "Epoch:  0058 D loss:-0.6629 G loss:-2.086\n",
      "Epoch:  0058 D loss:-0.6904 G loss:-1.98\n",
      "Epoch:  0058 D loss:-0.7228 G loss:-2.042\n",
      "Epoch:  0058 D loss:-0.6262 G loss:-2.11\n",
      "Epoch:  0058 D loss:-0.6094 G loss:-2.197\n",
      "Epoch:  0059 D loss:-0.7652 G loss:-2.075\n",
      "Epoch:  0059 D loss:-0.6307 G loss:-2.226\n",
      "Epoch:  0059 D loss:-0.5924 G loss:-2.164\n",
      "Epoch:  0059 D loss:-0.5422 G loss:-2.274\n",
      "Epoch:  0059 D loss:-0.5906 G loss:-2.135\n",
      "Epoch:  0059 D loss:-0.6747 G loss:-2.044\n",
      "Epoch:  0059 D loss:-0.5687 G loss:-2.259\n",
      "Epoch:  0059 D loss:-0.5924 G loss:-2.141\n",
      "Epoch:  0059 D loss:-0.7657 G loss:-2.077\n",
      "Epoch:  0059 D loss:-0.5666 G loss:-2.2\n",
      "Epoch:  0059 D loss:-0.5744 G loss:-2.043\n",
      "Epoch:  0059 D loss:-0.6977 G loss:-2.18\n",
      "Epoch:  0059 D loss:-0.6777 G loss:-2.198\n",
      "Epoch:  0059 D loss:-0.6108 G loss:-2.232\n",
      "Epoch:  0059 D loss:-0.576 G loss:-2.401\n",
      "Epoch:  0059 D loss:-0.6041 G loss:-2.254\n",
      "Epoch:  0059 D loss:-0.6398 G loss:-2.28\n",
      "Epoch:  0059 D loss:-0.7309 G loss:-2.377\n",
      "Epoch:  0059 D loss:-0.6473 G loss:-2.081\n",
      "Epoch:  0059 D loss:-0.6248 G loss:-2.196\n",
      "Epoch:  0059 D loss:-0.5763 G loss:-1.973\n",
      "Epoch:  0059 D loss:-0.6451 G loss:-2.117\n",
      "Epoch:  0059 D loss:-0.5464 G loss:-2.114\n",
      "Epoch:  0059 D loss:-0.7121 G loss:-2.107\n",
      "Epoch:  0059 D loss:-0.5728 G loss:-2.174\n",
      "Epoch:  0059 D loss:-0.5907 G loss:-2.04\n",
      "Epoch:  0059 D loss:-0.6399 G loss:-2.12\n",
      "Epoch:  0059 D loss:-0.5917 G loss:-2.263\n",
      "Epoch:  0059 D loss:-0.6649 G loss:-2.083\n",
      "Epoch:  0059 D loss:-0.6549 G loss:-2.165\n",
      "Epoch:  0059 D loss:-0.5191 G loss:-2.11\n",
      "Epoch:  0059 D loss:-0.729 G loss:-2.097\n",
      "Epoch:  0059 D loss:-0.6021 G loss:-2.157\n",
      "Epoch:  0059 D loss:-0.5028 G loss:-2.407\n",
      "Epoch:  0059 D loss:-0.5059 G loss:-2.281\n",
      "Epoch:  0059 D loss:-0.6133 G loss:-2.202\n",
      "Epoch:  0059 D loss:-0.5517 G loss:-2.283\n",
      "Epoch:  0059 D loss:-0.6024 G loss:-2.269\n",
      "Epoch:  0059 D loss:-0.6703 G loss:-2.364\n",
      "Epoch:  0059 D loss:-0.6144 G loss:-2.331\n",
      "Epoch:  0059 D loss:-0.5235 G loss:-2.229\n",
      "Epoch:  0059 D loss:-0.656 G loss:-2.382\n",
      "Epoch:  0059 D loss:-0.6094 G loss:-2.193\n",
      "Epoch:  0059 D loss:-0.5018 G loss:-2.347\n",
      "Epoch:  0059 D loss:-0.6834 G loss:-2.054\n",
      "Epoch:  0059 D loss:-0.5672 G loss:-2.074\n",
      "Epoch:  0059 D loss:-0.6387 G loss:-2.041\n",
      "Epoch:  0059 D loss:-0.7046 G loss:-1.985\n",
      "Epoch:  0059 D loss:-0.5355 G loss:-2.211\n",
      "Epoch:  0059 D loss:-0.5809 G loss:-2.094\n",
      "Epoch:  0059 D loss:-0.4908 G loss:-2.289\n",
      "Epoch:  0059 D loss:-0.59 G loss:-2.262\n",
      "Epoch:  0059 D loss:-0.6287 G loss:-2.169\n",
      "Epoch:  0059 D loss:-0.6202 G loss:-2.475\n",
      "Epoch:  0059 D loss:-0.5537 G loss:-2.329\n",
      "Epoch:  0059 D loss:-0.4612 G loss:-2.371\n",
      "Epoch:  0059 D loss:-0.6327 G loss:-2.246\n",
      "Epoch:  0059 D loss:-0.511 G loss:-2.274\n",
      "Epoch:  0059 D loss:-0.5366 G loss:-2.333\n",
      "Epoch:  0059 D loss:-0.678 G loss:-2.037\n",
      "Epoch:  0059 D loss:-0.5148 G loss:-2.408\n",
      "Epoch:  0059 D loss:-0.5903 G loss:-2.279\n",
      "Epoch:  0059 D loss:-0.5112 G loss:-2.117\n",
      "Epoch:  0059 D loss:-0.759 G loss:-1.989\n",
      "Epoch:  0059 D loss:-0.6305 G loss:-2.045\n",
      "Epoch:  0059 D loss:-0.6094 G loss:-2.021\n",
      "Epoch:  0059 D loss:-0.5735 G loss:-2.249\n",
      "Epoch:  0059 D loss:-0.5862 G loss:-2.107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0059 D loss:-0.6357 G loss:-2.15\n",
      "Epoch:  0059 D loss:-0.6102 G loss:-2.2\n",
      "Epoch:  0059 D loss:-0.6118 G loss:-2.071\n",
      "Epoch:  0059 D loss:-0.7082 G loss:-2.337\n",
      "Epoch:  0059 D loss:-0.643 G loss:-2.16\n",
      "Epoch:  0059 D loss:-0.6064 G loss:-2.706\n",
      "Epoch:  0059 D loss:-0.5816 G loss:-2.198\n",
      "Epoch:  0059 D loss:-0.5985 G loss:-2.482\n",
      "Epoch:  0059 D loss:-0.6981 G loss:-2.379\n",
      "Epoch:  0059 D loss:-0.6461 G loss:-2.242\n",
      "Epoch:  0059 D loss:-0.5601 G loss:-2.296\n",
      "Epoch:  0059 D loss:-0.711 G loss:-2.08\n",
      "Epoch:  0059 D loss:-0.6322 G loss:-2.041\n",
      "Epoch:  0059 D loss:-0.6148 G loss:-1.932\n",
      "Epoch:  0059 D loss:-0.6073 G loss:-2.058\n",
      "Epoch:  0059 D loss:-0.689 G loss:-1.673\n",
      "Epoch:  0059 D loss:-0.6662 G loss:-1.846\n",
      "Epoch:  0059 D loss:-0.5632 G loss:-2.326\n",
      "Epoch:  0059 D loss:-0.6662 G loss:-2.145\n",
      "Epoch:  0059 D loss:-0.6745 G loss:-2.289\n",
      "Epoch:  0059 D loss:-0.6143 G loss:-2.162\n",
      "Epoch:  0059 D loss:-0.5292 G loss:-2.25\n",
      "Epoch:  0059 D loss:-0.6481 G loss:-2.422\n",
      "Epoch:  0059 D loss:-0.7097 G loss:-2.142\n",
      "Epoch:  0059 D loss:-0.5333 G loss:-2.282\n",
      "Epoch:  0059 D loss:-0.6434 G loss:-2.222\n",
      "Epoch:  0059 D loss:-0.7083 G loss:-2.222\n",
      "Epoch:  0059 D loss:-0.6285 G loss:-2.318\n",
      "Epoch:  0059 D loss:-0.754 G loss:-1.955\n",
      "Epoch:  0059 D loss:-0.7836 G loss:-2.05\n",
      "Epoch:  0059 D loss:-0.5953 G loss:-1.978\n",
      "Epoch:  0059 D loss:-0.6854 G loss:-1.868\n",
      "Epoch:  0059 D loss:-0.6401 G loss:-2.012\n",
      "Epoch:  0059 D loss:-0.572 G loss:-2.017\n",
      "Epoch:  0059 D loss:-0.7094 G loss:-2.041\n",
      "Epoch:  0059 D loss:-0.733 G loss:-2.236\n",
      "Epoch:  0059 D loss:-0.64 G loss:-2.094\n",
      "Epoch:  0059 D loss:-0.5917 G loss:-2.175\n",
      "Epoch:  0059 D loss:-0.6288 G loss:-2.024\n",
      "Epoch:  0059 D loss:-0.5317 G loss:-2.466\n",
      "Epoch:  0059 D loss:-0.6383 G loss:-2.254\n",
      "Epoch:  0059 D loss:-0.6412 G loss:-2.536\n",
      "Epoch:  0059 D loss:-0.6349 G loss:-2.264\n",
      "Epoch:  0059 D loss:-0.6841 G loss:-2.325\n",
      "Epoch:  0059 D loss:-0.7831 G loss:-2.063\n",
      "Epoch:  0059 D loss:-0.625 G loss:-2.274\n",
      "Epoch:  0059 D loss:-0.7564 G loss:-2.46\n",
      "Epoch:  0059 D loss:-0.5988 G loss:-2.258\n",
      "Epoch:  0059 D loss:-0.6046 G loss:-2.173\n",
      "Epoch:  0059 D loss:-0.6693 G loss:-2.218\n",
      "Epoch:  0059 D loss:-0.6809 G loss:-2.143\n",
      "Epoch:  0059 D loss:-0.6131 G loss:-2.242\n",
      "Epoch:  0059 D loss:-0.7329 G loss:-2.041\n",
      "Epoch:  0059 D loss:-0.8274 G loss:-1.823\n",
      "Epoch:  0059 D loss:-0.6962 G loss:-2.298\n",
      "Epoch:  0059 D loss:-0.7477 G loss:-1.989\n",
      "Epoch:  0059 D loss:-0.6621 G loss:-2.321\n",
      "Epoch:  0059 D loss:-0.5871 G loss:-2.212\n",
      "Epoch:  0059 D loss:-0.6332 G loss:-2.083\n",
      "Epoch:  0059 D loss:-0.5786 G loss:-2.468\n",
      "Epoch:  0059 D loss:-0.6047 G loss:-2.306\n",
      "Epoch:  0059 D loss:-0.7122 G loss:-2.073\n",
      "Epoch:  0059 D loss:-0.6881 G loss:-2.012\n",
      "Epoch:  0059 D loss:-0.6878 G loss:-1.847\n",
      "Epoch:  0059 D loss:-0.7884 G loss:-1.978\n",
      "Epoch:  0059 D loss:-0.5965 G loss:-2.062\n",
      "Epoch:  0059 D loss:-0.6176 G loss:-2.124\n",
      "Epoch:  0059 D loss:-0.7821 G loss:-1.907\n",
      "Epoch:  0059 D loss:-0.6038 G loss:-2.085\n",
      "Epoch:  0059 D loss:-0.6391 G loss:-2.324\n",
      "Epoch:  0059 D loss:-0.6627 G loss:-2.141\n",
      "Epoch:  0059 D loss:-0.7389 G loss:-2.138\n",
      "Epoch:  0059 D loss:-0.6341 G loss:-2.148\n",
      "Epoch:  0059 D loss:-0.7498 G loss:-2.003\n",
      "Epoch:  0059 D loss:-0.6981 G loss:-2.073\n",
      "Epoch:  0059 D loss:-0.6797 G loss:-2.11\n",
      "Epoch:  0059 D loss:-0.6137 G loss:-2.077\n",
      "Epoch:  0059 D loss:-0.6413 G loss:-2.098\n",
      "Epoch:  0059 D loss:-0.6166 G loss:-2.166\n",
      "Epoch:  0059 D loss:-0.5537 G loss:-2.214\n",
      "Epoch:  0059 D loss:-0.6118 G loss:-1.979\n",
      "Epoch:  0059 D loss:-0.529 G loss:-2.18\n",
      "Epoch:  0059 D loss:-0.5834 G loss:-1.971\n",
      "Epoch:  0059 D loss:-0.6556 G loss:-1.937\n",
      "Epoch:  0059 D loss:-0.5639 G loss:-2.424\n",
      "Epoch:  0059 D loss:-0.681 G loss:-1.951\n",
      "Epoch:  0059 D loss:-0.5809 G loss:-2.142\n",
      "Epoch:  0059 D loss:-0.5478 G loss:-2.447\n",
      "Epoch:  0059 D loss:-0.7785 G loss:-1.975\n",
      "Epoch:  0059 D loss:-0.6029 G loss:-2.377\n",
      "Epoch:  0059 D loss:-0.5019 G loss:-2.343\n",
      "Epoch:  0059 D loss:-0.6787 G loss:-2.249\n",
      "Epoch:  0059 D loss:-0.5712 G loss:-2.231\n",
      "Epoch:  0059 D loss:-0.5489 G loss:-2.305\n",
      "Epoch:  0059 D loss:-0.622 G loss:-2.073\n",
      "Epoch:  0059 D loss:-0.6784 G loss:-2.238\n",
      "Epoch:  0059 D loss:-0.5958 G loss:-2.161\n",
      "Epoch:  0059 D loss:-0.6057 G loss:-2.171\n",
      "Epoch:  0059 D loss:-0.4245 G loss:-2.209\n",
      "Epoch:  0059 D loss:-0.5752 G loss:-2.072\n",
      "Epoch:  0059 D loss:-0.6425 G loss:-2.195\n",
      "Epoch:  0059 D loss:-0.647 G loss:-2.099\n",
      "Epoch:  0059 D loss:-0.6499 G loss:-2.417\n",
      "Epoch:  0059 D loss:-0.6004 G loss:-2.29\n",
      "Epoch:  0059 D loss:-0.6505 G loss:-2.009\n",
      "Epoch:  0059 D loss:-0.6689 G loss:-2.148\n",
      "Epoch:  0059 D loss:-0.6401 G loss:-2.215\n",
      "Epoch:  0059 D loss:-0.6849 G loss:-2.179\n",
      "Epoch:  0059 D loss:-0.5751 G loss:-2.17\n",
      "Epoch:  0059 D loss:-0.6092 G loss:-2.043\n",
      "Epoch:  0059 D loss:-0.604 G loss:-2.112\n",
      "Epoch:  0059 D loss:-0.6524 G loss:-1.78\n",
      "Epoch:  0059 D loss:-0.6627 G loss:-1.896\n",
      "Epoch:  0059 D loss:-0.7452 G loss:-1.886\n",
      "Epoch:  0059 D loss:-0.6426 G loss:-1.947\n",
      "Epoch:  0059 D loss:-0.6404 G loss:-2.344\n",
      "Epoch:  0059 D loss:-0.5763 G loss:-2.157\n",
      "Epoch:  0059 D loss:-0.5693 G loss:-2.215\n",
      "Epoch:  0059 D loss:-0.5483 G loss:-2.384\n",
      "Epoch:  0059 D loss:-0.5796 G loss:-2.306\n",
      "Epoch:  0059 D loss:-0.5437 G loss:-2.428\n",
      "Epoch:  0059 D loss:-0.5377 G loss:-2.377\n",
      "Epoch:  0059 D loss:-0.66 G loss:-2.367\n",
      "Epoch:  0059 D loss:-0.6502 G loss:-2.537\n",
      "Epoch:  0059 D loss:-0.565 G loss:-2.408\n",
      "Epoch:  0059 D loss:-0.6946 G loss:-2.159\n",
      "Epoch:  0059 D loss:-0.642 G loss:-2.113\n",
      "Epoch:  0059 D loss:-0.6489 G loss:-2.118\n",
      "Epoch:  0059 D loss:-0.6656 G loss:-1.92\n",
      "Epoch:  0059 D loss:-0.7448 G loss:-1.831\n",
      "Epoch:  0059 D loss:-0.4897 G loss:-2.198\n",
      "Epoch:  0059 D loss:-0.6116 G loss:-2.165\n",
      "Epoch:  0059 D loss:-0.5742 G loss:-2.246\n",
      "Epoch:  0059 D loss:-0.5086 G loss:-2.173\n",
      "Epoch:  0059 D loss:-0.7481 G loss:-2.3\n",
      "Epoch:  0059 D loss:-0.7294 G loss:-2.298\n",
      "Epoch:  0059 D loss:-0.6395 G loss:-2.375\n",
      "Epoch:  0059 D loss:-0.6193 G loss:-2.747\n",
      "Epoch:  0059 D loss:-0.7226 G loss:-2.258\n",
      "Epoch:  0059 D loss:-0.6702 G loss:-2.144\n",
      "Epoch:  0059 D loss:-0.6299 G loss:-2.326\n",
      "Epoch:  0059 D loss:-0.8279 G loss:-1.831\n",
      "Epoch:  0059 D loss:-0.648 G loss:-1.902\n",
      "Epoch:  0059 D loss:-0.6382 G loss:-2.199\n",
      "Epoch:  0059 D loss:-0.6377 G loss:-2.281\n",
      "Epoch:  0059 D loss:-0.6525 G loss:-2.031\n",
      "Epoch:  0059 D loss:-0.5391 G loss:-2.243\n",
      "Epoch:  0059 D loss:-0.5824 G loss:-2.208\n",
      "Epoch:  0059 D loss:-0.6193 G loss:-2.086\n",
      "Epoch:  0059 D loss:-0.6543 G loss:-2.32\n",
      "Epoch:  0059 D loss:-0.7563 G loss:-2.343\n",
      "Epoch:  0059 D loss:-0.607 G loss:-2.314\n",
      "Epoch:  0059 D loss:-0.6316 G loss:-2.114\n",
      "Epoch:  0059 D loss:-0.7689 G loss:-2.028\n",
      "Epoch:  0059 D loss:-0.6837 G loss:-2.087\n",
      "Epoch:  0059 D loss:-0.7113 G loss:-2.115\n",
      "Epoch:  0059 D loss:-0.6628 G loss:-2.256\n",
      "Epoch:  0059 D loss:-0.6457 G loss:-2.189\n",
      "Epoch:  0059 D loss:-0.7156 G loss:-2.095\n",
      "Epoch:  0059 D loss:-0.6693 G loss:-2.071\n",
      "Epoch:  0059 D loss:-0.8045 G loss:-2.182\n",
      "Epoch:  0059 D loss:-0.6808 G loss:-2.22\n",
      "Epoch:  0059 D loss:-0.6573 G loss:-2.074\n",
      "Epoch:  0059 D loss:-0.7174 G loss:-2.011\n",
      "Epoch:  0059 D loss:-0.5553 G loss:-2.194\n",
      "Epoch:  0059 D loss:-0.7348 G loss:-2.045\n",
      "Epoch:  0059 D loss:-0.466 G loss:-2.405\n",
      "Epoch:  0059 D loss:-0.5499 G loss:-2.11\n",
      "Epoch:  0059 D loss:-0.6922 G loss:-1.965\n",
      "Epoch:  0059 D loss:-0.7951 G loss:-1.938\n",
      "Epoch:  0059 D loss:-0.7066 G loss:-2.287\n",
      "Epoch:  0059 D loss:-0.7032 G loss:-2.167\n",
      "Epoch:  0059 D loss:-0.7587 G loss:-2.385\n",
      "Epoch:  0059 D loss:-0.7014 G loss:-2.197\n",
      "Epoch:  0059 D loss:-0.6972 G loss:-2.35\n",
      "Epoch:  0059 D loss:-0.7208 G loss:-2.111\n",
      "Epoch:  0059 D loss:-0.7275 G loss:-2.205\n",
      "Epoch:  0059 D loss:-0.7137 G loss:-2.03\n",
      "Epoch:  0059 D loss:-0.6166 G loss:-2.093\n",
      "Epoch:  0059 D loss:-0.7466 G loss:-1.749\n",
      "Epoch:  0059 D loss:-0.7029 G loss:-2.013\n",
      "Epoch:  0059 D loss:-0.6708 G loss:-1.962\n",
      "Epoch:  0059 D loss:-0.7111 G loss:-2.069\n",
      "Epoch:  0059 D loss:-0.7995 G loss:-2.173\n",
      "Epoch:  0059 D loss:-0.614 G loss:-2.226\n",
      "Epoch:  0059 D loss:-0.5636 G loss:-2.347\n",
      "Epoch:  0059 D loss:-0.6531 G loss:-2.279\n",
      "Epoch:  0059 D loss:-0.6657 G loss:-2.316\n",
      "Epoch:  0059 D loss:-0.5831 G loss:-2.271\n",
      "Epoch:  0059 D loss:-0.7129 G loss:-2.254\n",
      "Epoch:  0059 D loss:-0.6492 G loss:-2.054\n",
      "Epoch:  0059 D loss:-0.6183 G loss:-2.013\n",
      "Epoch:  0059 D loss:-0.6989 G loss:-1.922\n",
      "Epoch:  0059 D loss:-0.5631 G loss:-2.391\n",
      "Epoch:  0059 D loss:-0.6322 G loss:-2.133\n",
      "Epoch:  0059 D loss:-0.5904 G loss:-2.199\n",
      "Epoch:  0059 D loss:-0.5797 G loss:-2.208\n",
      "Epoch:  0059 D loss:-0.53 G loss:-2.475\n",
      "Epoch:  0059 D loss:-0.7101 G loss:-2.215\n",
      "Epoch:  0059 D loss:-0.6315 G loss:-2.228\n",
      "Epoch:  0059 D loss:-0.6959 G loss:-2.149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0059 D loss:-0.6892 G loss:-2.095\n",
      "Epoch:  0059 D loss:-0.5573 G loss:-2.327\n",
      "Epoch:  0059 D loss:-0.8455 G loss:-2.177\n",
      "Epoch:  0059 D loss:-0.6368 G loss:-2.093\n",
      "Epoch:  0059 D loss:-0.7129 G loss:-2.048\n",
      "Epoch:  0059 D loss:-0.6937 G loss:-1.903\n",
      "Epoch:  0059 D loss:-0.6804 G loss:-2.0\n",
      "Epoch:  0059 D loss:-0.7131 G loss:-1.989\n",
      "Epoch:  0059 D loss:-0.673 G loss:-2.453\n",
      "Epoch:  0059 D loss:-0.5941 G loss:-2.17\n",
      "Epoch:  0059 D loss:-0.6552 G loss:-2.244\n",
      "Epoch:  0059 D loss:-0.6709 G loss:-2.346\n",
      "Epoch:  0059 D loss:-0.5997 G loss:-2.379\n",
      "Epoch:  0059 D loss:-0.5505 G loss:-2.502\n",
      "Epoch:  0059 D loss:-0.6688 G loss:-2.499\n",
      "Epoch:  0059 D loss:-0.8102 G loss:-2.296\n",
      "Epoch:  0059 D loss:-0.6895 G loss:-2.334\n",
      "Epoch:  0059 D loss:-0.729 G loss:-2.213\n",
      "Epoch:  0059 D loss:-0.6132 G loss:-2.143\n",
      "Epoch:  0059 D loss:-0.8017 G loss:-1.802\n",
      "Epoch:  0059 D loss:-0.6892 G loss:-1.788\n",
      "Epoch:  0059 D loss:-0.8978 G loss:-1.8\n",
      "Epoch:  0059 D loss:-0.701 G loss:-1.976\n",
      "Epoch:  0059 D loss:-0.6843 G loss:-2.058\n",
      "Epoch:  0059 D loss:-0.7449 G loss:-2.044\n",
      "Epoch:  0059 D loss:-0.696 G loss:-2.09\n",
      "Epoch:  0059 D loss:-0.6826 G loss:-2.156\n",
      "Epoch:  0059 D loss:-0.6951 G loss:-2.033\n",
      "Epoch:  0059 D loss:-0.6203 G loss:-2.151\n",
      "Epoch:  0059 D loss:-0.7383 G loss:-2.006\n",
      "Epoch:  0059 D loss:-0.7212 G loss:-2.104\n",
      "Epoch:  0059 D loss:-0.6476 G loss:-2.308\n",
      "Epoch:  0059 D loss:-0.8003 G loss:-1.951\n",
      "Epoch:  0059 D loss:-0.61 G loss:-2.229\n",
      "Epoch:  0059 D loss:-0.5972 G loss:-2.034\n",
      "Epoch:  0059 D loss:-0.6289 G loss:-2.177\n",
      "Epoch:  0059 D loss:-0.581 G loss:-2.43\n",
      "Epoch:  0059 D loss:-0.7274 G loss:-2.371\n",
      "Epoch:  0059 D loss:-0.6984 G loss:-2.311\n",
      "Epoch:  0059 D loss:-0.6586 G loss:-2.166\n",
      "Epoch:  0059 D loss:-0.8028 G loss:-2.101\n",
      "Epoch:  0059 D loss:-0.479 G loss:-2.258\n",
      "Epoch:  0059 D loss:-0.5568 G loss:-2.267\n",
      "Epoch:  0059 D loss:-0.7055 G loss:-2.107\n",
      "Epoch:  0059 D loss:-0.7138 G loss:-2.042\n",
      "Epoch:  0059 D loss:-0.5676 G loss:-2.181\n",
      "Epoch:  0059 D loss:-0.6119 G loss:-2.342\n",
      "Epoch:  0059 D loss:-0.5999 G loss:-2.2\n",
      "Epoch:  0059 D loss:-0.5827 G loss:-2.253\n",
      "Epoch:  0059 D loss:-0.6307 G loss:-2.226\n",
      "Epoch:  0059 D loss:-0.6085 G loss:-1.983\n",
      "Epoch:  0059 D loss:-0.605 G loss:-2.22\n",
      "Epoch:  0059 D loss:-0.6504 G loss:-1.981\n",
      "Epoch:  0059 D loss:-0.7115 G loss:-2.076\n",
      "Epoch:  0059 D loss:-0.5661 G loss:-2.046\n",
      "Epoch:  0059 D loss:-0.5888 G loss:-2.147\n",
      "Epoch:  0059 D loss:-0.5109 G loss:-2.363\n",
      "Epoch:  0059 D loss:-0.6965 G loss:-2.272\n",
      "Epoch:  0059 D loss:-0.6875 G loss:-2.117\n",
      "Epoch:  0059 D loss:-0.7513 G loss:-2.037\n",
      "Epoch:  0059 D loss:-0.7127 G loss:-2.325\n",
      "Epoch:  0059 D loss:-0.6359 G loss:-2.158\n",
      "Epoch:  0059 D loss:-0.6736 G loss:-1.938\n",
      "Epoch:  0059 D loss:-0.6343 G loss:-1.991\n",
      "Epoch:  0059 D loss:-0.4917 G loss:-2.394\n",
      "Epoch:  0059 D loss:-0.6802 G loss:-1.902\n",
      "Epoch:  0059 D loss:-0.5675 G loss:-2.278\n",
      "Epoch:  0059 D loss:-0.663 G loss:-2.125\n",
      "Epoch:  0059 D loss:-0.5766 G loss:-2.19\n",
      "Epoch:  0059 D loss:-0.6831 G loss:-2.149\n",
      "Epoch:  0059 D loss:-0.5959 G loss:-2.325\n",
      "Epoch:  0059 D loss:-0.5226 G loss:-2.154\n",
      "Epoch:  0059 D loss:-0.5978 G loss:-2.333\n",
      "Epoch:  0059 D loss:-0.646 G loss:-2.285\n",
      "Epoch:  0059 D loss:-0.5979 G loss:-2.089\n",
      "Epoch:  0059 D loss:-0.5367 G loss:-2.26\n",
      "Epoch:  0059 D loss:-0.716 G loss:-2.224\n",
      "Epoch:  0059 D loss:-0.6455 G loss:-2.26\n",
      "Epoch:  0059 D loss:-0.5976 G loss:-2.121\n",
      "Epoch:  0059 D loss:-0.6884 G loss:-2.028\n",
      "Epoch:  0059 D loss:-0.5649 G loss:-2.187\n",
      "Epoch:  0059 D loss:-0.6918 G loss:-2.132\n",
      "Epoch:  0059 D loss:-0.5992 G loss:-2.177\n",
      "Epoch:  0059 D loss:-0.6116 G loss:-2.063\n",
      "Epoch:  0059 D loss:-0.6433 G loss:-1.999\n",
      "Epoch:  0059 D loss:-0.7514 G loss:-1.86\n",
      "Epoch:  0059 D loss:-0.6802 G loss:-1.899\n",
      "Epoch:  0059 D loss:-0.5668 G loss:-2.146\n",
      "Epoch:  0059 D loss:-0.638 G loss:-2.101\n",
      "Epoch:  0059 D loss:-0.5446 G loss:-2.033\n",
      "Epoch:  0059 D loss:-0.6252 G loss:-1.822\n",
      "Epoch:  0059 D loss:-0.7739 G loss:-1.998\n",
      "Epoch:  0059 D loss:-0.7013 G loss:-2.234\n",
      "Epoch:  0059 D loss:-0.4633 G loss:-2.448\n",
      "Epoch:  0059 D loss:-0.5987 G loss:-2.368\n",
      "Epoch:  0059 D loss:-0.7268 G loss:-2.073\n",
      "Epoch:  0059 D loss:-0.7246 G loss:-2.206\n",
      "Epoch:  0059 D loss:-0.6709 G loss:-2.355\n",
      "Epoch:  0059 D loss:-0.5836 G loss:-2.291\n",
      "Epoch:  0059 D loss:-0.6586 G loss:-2.323\n",
      "Epoch:  0059 D loss:-0.6125 G loss:-2.268\n",
      "Epoch:  0059 D loss:-0.5713 G loss:-2.191\n",
      "Epoch:  0059 D loss:-0.5945 G loss:-2.249\n",
      "Epoch:  0059 D loss:-0.6161 G loss:-2.186\n",
      "Epoch:  0059 D loss:-0.6908 G loss:-1.978\n",
      "Epoch:  0059 D loss:-0.6119 G loss:-1.992\n",
      "Epoch:  0059 D loss:-0.5701 G loss:-2.082\n",
      "Epoch:  0059 D loss:-0.6713 G loss:-2.058\n",
      "Epoch:  0059 D loss:-0.6878 G loss:-2.075\n",
      "Epoch:  0059 D loss:-0.6372 G loss:-2.156\n",
      "Epoch:  0059 D loss:-0.7023 G loss:-2.037\n",
      "Epoch:  0059 D loss:-0.6389 G loss:-1.936\n",
      "Epoch:  0059 D loss:-0.5487 G loss:-2.171\n",
      "Epoch:  0059 D loss:-0.65 G loss:-2.099\n",
      "Epoch:  0059 D loss:-0.7332 G loss:-2.194\n",
      "Epoch:  0059 D loss:-0.7755 G loss:-2.144\n",
      "Epoch:  0059 D loss:-0.4802 G loss:-2.348\n",
      "Epoch:  0059 D loss:-0.7807 G loss:-2.424\n",
      "Epoch:  0059 D loss:-0.522 G loss:-2.366\n",
      "Epoch:  0059 D loss:-0.5568 G loss:-2.109\n",
      "Epoch:  0059 D loss:-0.6519 G loss:-2.432\n",
      "Epoch:  0059 D loss:-0.5742 G loss:-2.574\n",
      "Epoch:  0059 D loss:-0.6294 G loss:-2.184\n",
      "Epoch:  0059 D loss:-0.6868 G loss:-2.393\n",
      "Epoch:  0059 D loss:-0.689 G loss:-2.061\n",
      "Epoch:  0059 D loss:-0.5311 G loss:-2.329\n",
      "Epoch:  0059 D loss:-0.6729 G loss:-2.002\n",
      "Epoch:  0059 D loss:-0.7353 G loss:-2.08\n",
      "Epoch:  0059 D loss:-0.6161 G loss:-2.15\n",
      "Epoch:  0059 D loss:-0.6993 G loss:-2.089\n",
      "Epoch:  0059 D loss:-0.6166 G loss:-2.2\n",
      "Epoch:  0059 D loss:-0.737 G loss:-2.248\n",
      "Epoch:  0059 D loss:-0.6267 G loss:-2.12\n",
      "Epoch:  0059 D loss:-0.6529 G loss:-2.194\n",
      "Epoch:  0059 D loss:-0.6796 G loss:-2.355\n",
      "Epoch:  0059 D loss:-0.6439 G loss:-2.21\n",
      "Epoch:  0059 D loss:-0.5829 G loss:-2.199\n",
      "Epoch:  0059 D loss:-0.7557 G loss:-2.146\n",
      "Epoch:  0059 D loss:-0.6675 G loss:-2.129\n",
      "Epoch:  0059 D loss:-0.6274 G loss:-2.422\n",
      "Epoch:  0059 D loss:-0.6462 G loss:-2.137\n",
      "Epoch:  0059 D loss:-0.6355 G loss:-2.094\n",
      "Epoch:  0059 D loss:-0.7657 G loss:-2.007\n",
      "Epoch:  0059 D loss:-0.4967 G loss:-2.215\n",
      "Epoch:  0059 D loss:-0.6693 G loss:-2.012\n",
      "Epoch:  0059 D loss:-0.7649 G loss:-2.015\n",
      "Epoch:  0059 D loss:-0.7563 G loss:-2.037\n",
      "Epoch:  0059 D loss:-0.6322 G loss:-2.408\n",
      "Epoch:  0059 D loss:-0.7251 G loss:-2.106\n",
      "Epoch:  0059 D loss:-0.8051 G loss:-2.092\n",
      "Epoch:  0059 D loss:-0.5959 G loss:-2.119\n",
      "Epoch:  0059 D loss:-0.7257 G loss:-2.084\n",
      "Epoch:  0059 D loss:-0.728 G loss:-2.148\n",
      "Epoch:  0059 D loss:-0.7634 G loss:-2.122\n",
      "Epoch:  0059 D loss:-0.7328 G loss:-2.26\n",
      "Epoch:  0059 D loss:-0.8932 G loss:-2.165\n",
      "Epoch:  0059 D loss:-0.7112 G loss:-2.073\n",
      "Epoch:  0059 D loss:-0.654 G loss:-2.22\n",
      "Epoch:  0059 D loss:-0.7451 G loss:-1.949\n",
      "Epoch:  0059 D loss:-0.6581 G loss:-2.013\n",
      "Epoch:  0059 D loss:-0.7298 G loss:-2.108\n",
      "Epoch:  0059 D loss:-0.7343 G loss:-1.972\n",
      "Epoch:  0059 D loss:-0.6855 G loss:-2.11\n",
      "Epoch:  0059 D loss:-0.6672 G loss:-2.307\n",
      "Epoch:  0059 D loss:-0.5601 G loss:-2.316\n",
      "Epoch:  0059 D loss:-0.7774 G loss:-2.235\n",
      "Epoch:  0059 D loss:-0.7796 G loss:-2.239\n",
      "Epoch:  0059 D loss:-0.7259 G loss:-2.245\n",
      "Epoch:  0059 D loss:-0.6861 G loss:-2.201\n",
      "Epoch:  0059 D loss:-0.7672 G loss:-1.922\n",
      "Epoch:  0059 D loss:-0.5932 G loss:-2.079\n",
      "Epoch:  0059 D loss:-0.7639 G loss:-1.832\n",
      "Epoch:  0059 D loss:-0.6013 G loss:-2.069\n",
      "Epoch:  0059 D loss:-0.6927 G loss:-2.039\n",
      "Epoch:  0059 D loss:-0.7327 G loss:-1.977\n",
      "Epoch:  0059 D loss:-0.6716 G loss:-1.931\n",
      "Epoch:  0059 D loss:-0.6698 G loss:-2.212\n",
      "Epoch:  0059 D loss:-0.6461 G loss:-2.167\n",
      "Epoch:  0059 D loss:-0.7579 G loss:-1.967\n",
      "Epoch:  0059 D loss:-0.6592 G loss:-2.019\n",
      "Epoch:  0059 D loss:-0.7182 G loss:-2.012\n",
      "Epoch:  0059 D loss:-0.7254 G loss:-1.867\n",
      "Epoch:  0059 D loss:-0.6939 G loss:-2.142\n",
      "Epoch:  0059 D loss:-0.7091 G loss:-2.172\n",
      "Epoch:  0059 D loss:-0.6578 G loss:-1.995\n",
      "Epoch:  0059 D loss:-0.5844 G loss:-1.966\n",
      "Epoch:  0059 D loss:-0.6284 G loss:-2.377\n",
      "Epoch:  0059 D loss:-0.6362 G loss:-2.302\n",
      "Epoch:  0059 D loss:-0.6709 G loss:-2.374\n",
      "Epoch:  0059 D loss:-0.6684 G loss:-2.402\n",
      "Epoch:  0059 D loss:-0.6078 G loss:-1.942\n",
      "Epoch:  0059 D loss:-0.6729 G loss:-2.119\n",
      "Epoch:  0059 D loss:-0.7393 G loss:-1.984\n",
      "Epoch:  0059 D loss:-0.7321 G loss:-2.048\n",
      "Epoch:  0059 D loss:-0.6035 G loss:-2.14\n",
      "Epoch:  0059 D loss:-0.6988 G loss:-2.121\n",
      "Epoch:  0059 D loss:-0.7648 G loss:-1.995\n",
      "Epoch:  0059 D loss:-0.5457 G loss:-2.276\n",
      "Epoch:  0059 D loss:-0.7326 G loss:-1.88\n",
      "Epoch:  0059 D loss:-0.5804 G loss:-2.135\n",
      "Epoch:  0059 D loss:-0.5413 G loss:-2.101\n",
      "Epoch:  0059 D loss:-0.7106 G loss:-2.147\n",
      "Epoch:  0059 D loss:-0.6229 G loss:-1.968\n",
      "Epoch:  0059 D loss:-0.5496 G loss:-2.339\n",
      "Epoch:  0059 D loss:-0.6773 G loss:-2.322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0059 D loss:-0.6447 G loss:-2.259\n",
      "Epoch:  0059 D loss:-0.5933 G loss:-2.33\n",
      "Epoch:  0059 D loss:-0.5562 G loss:-2.012\n",
      "Epoch:  0059 D loss:-0.632 G loss:-2.168\n",
      "Epoch:  0059 D loss:-0.6637 G loss:-2.128\n",
      "Epoch:  0059 D loss:-0.7096 G loss:-2.065\n",
      "Epoch:  0059 D loss:-0.5905 G loss:-2.215\n",
      "Epoch:  0059 D loss:-0.7491 G loss:-1.989\n",
      "Epoch:  0059 D loss:-0.6144 G loss:-2.275\n",
      "Epoch:  0059 D loss:-0.54 G loss:-2.259\n",
      "Epoch:  0059 D loss:-0.6566 G loss:-2.162\n",
      "Epoch:  0059 D loss:-0.6931 G loss:-2.438\n",
      "Epoch:  0059 D loss:-0.6518 G loss:-2.154\n",
      "Epoch:  0059 D loss:-0.6473 G loss:-2.229\n",
      "Epoch:  0059 D loss:-0.5735 G loss:-2.327\n",
      "Epoch:  0059 D loss:-0.593 G loss:-2.378\n",
      "Epoch:  0059 D loss:-0.6009 G loss:-2.177\n",
      "Epoch:  0059 D loss:-0.6774 G loss:-2.192\n",
      "Epoch:  0059 D loss:-0.7405 G loss:-2.191\n",
      "Epoch:  0059 D loss:-0.666 G loss:-2.327\n",
      "Epoch:  0059 D loss:-0.7392 G loss:-1.949\n",
      "Epoch:  0059 D loss:-0.8279 G loss:-2.041\n",
      "Epoch:  0059 D loss:-0.653 G loss:-2.133\n",
      "Epoch:  0059 D loss:-0.65 G loss:-2.056\n",
      "Epoch:  0059 D loss:-0.6075 G loss:-2.03\n",
      "Epoch:  0059 D loss:-0.7721 G loss:-2.05\n",
      "Epoch:  0059 D loss:-0.718 G loss:-2.157\n",
      "Epoch:  0059 D loss:-0.6482 G loss:-2.127\n",
      "Epoch:  0059 D loss:-0.6637 G loss:-2.046\n",
      "Epoch:  0059 D loss:-0.6423 G loss:-2.153\n",
      "Epoch:  0059 D loss:-0.7239 G loss:-2.026\n",
      "Epoch:  0059 D loss:-0.7296 G loss:-1.77\n",
      "Epoch:  0059 D loss:-0.6041 G loss:-2.155\n",
      "Epoch:  0059 D loss:-0.713 G loss:-2.063\n",
      "Epoch:  0059 D loss:-0.7719 G loss:-2.031\n",
      "Epoch:  0059 D loss:-0.7921 G loss:-1.702\n",
      "Epoch:  0059 D loss:-0.7207 G loss:-1.96\n",
      "Epoch:  0059 D loss:-0.5758 G loss:-2.217\n",
      "Epoch:  0059 D loss:-0.7487 G loss:-1.935\n",
      "Epoch:  0059 D loss:-0.6607 G loss:-1.993\n",
      "Epoch:  0059 D loss:-0.6892 G loss:-2.131\n",
      "Epoch:  0059 D loss:-0.7364 G loss:-1.97\n",
      "Epoch:  0059 D loss:-0.5904 G loss:-2.05\n",
      "Epoch:  0059 D loss:-0.7378 G loss:-2.237\n",
      "Epoch:  0059 D loss:-0.7642 G loss:-2.227\n",
      "Epoch:  0059 D loss:-0.614 G loss:-2.235\n",
      "Epoch:  0059 D loss:-0.6349 G loss:-2.334\n",
      "Epoch:  0059 D loss:-0.5493 G loss:-2.271\n",
      "Epoch:  0059 D loss:-0.5414 G loss:-2.199\n",
      "Epoch:  0059 D loss:-0.6374 G loss:-2.205\n",
      "Epoch:  0059 D loss:-0.621 G loss:-2.313\n",
      "Epoch:  0059 D loss:-0.495 G loss:-2.318\n",
      "Epoch:  0059 D loss:-0.7123 G loss:-2.188\n",
      "Epoch:  0059 D loss:-0.6808 G loss:-2.099\n",
      "Epoch:  0059 D loss:-0.7209 G loss:-2.052\n",
      "Epoch:  0059 D loss:-0.7328 G loss:-2.076\n",
      "Epoch:  0059 D loss:-0.6097 G loss:-2.237\n",
      "Epoch:  0059 D loss:-0.765 G loss:-2.073\n",
      "Epoch:  0059 D loss:-0.7752 G loss:-2.244\n",
      "Epoch:  0059 D loss:-0.6013 G loss:-2.358\n",
      "Epoch:  0059 D loss:-0.6977 G loss:-2.103\n",
      "Epoch:  0059 D loss:-0.6417 G loss:-2.032\n",
      "Epoch:  0059 D loss:-0.5987 G loss:-2.086\n",
      "Epoch:  0059 D loss:-0.5573 G loss:-2.185\n",
      "Epoch:  0059 D loss:-0.7541 G loss:-1.994\n",
      "Epoch:  0059 D loss:-0.692 G loss:-1.9\n",
      "Epoch:  0059 D loss:-0.6227 G loss:-2.119\n",
      "Epoch:  0059 D loss:-0.6654 G loss:-1.838\n",
      "Epoch:  0059 D loss:-0.5989 G loss:-2.2\n",
      "Epoch:  0059 D loss:-0.6858 G loss:-1.966\n",
      "Epoch:  0059 D loss:-0.6923 G loss:-2.016\n",
      "Epoch:  0059 D loss:-0.7345 G loss:-1.871\n",
      "Epoch:  0059 D loss:-0.7255 G loss:-2.03\n",
      "Epoch:  0059 D loss:-0.7533 G loss:-2.041\n",
      "Epoch:  0059 D loss:-0.8274 G loss:-2.097\n",
      "Epoch:  0059 D loss:-0.5918 G loss:-2.297\n",
      "Epoch:  0060 D loss:-0.6862 G loss:-2.29\n",
      "Epoch:  0060 D loss:-0.6915 G loss:-2.443\n",
      "Epoch:  0060 D loss:-0.7399 G loss:-2.19\n",
      "Epoch:  0060 D loss:-0.6844 G loss:-2.056\n",
      "Epoch:  0060 D loss:-0.5672 G loss:-2.25\n",
      "Epoch:  0060 D loss:-0.6351 G loss:-2.047\n",
      "Epoch:  0060 D loss:-0.6657 G loss:-1.959\n",
      "Epoch:  0060 D loss:-0.6296 G loss:-2.205\n",
      "Epoch:  0060 D loss:-0.5634 G loss:-2.272\n",
      "Epoch:  0060 D loss:-0.6493 G loss:-1.932\n",
      "Epoch:  0060 D loss:-0.6073 G loss:-2.005\n",
      "Epoch:  0060 D loss:-0.6344 G loss:-2.038\n",
      "Epoch:  0060 D loss:-0.6182 G loss:-1.883\n",
      "Epoch:  0060 D loss:-0.6856 G loss:-2.283\n",
      "Epoch:  0060 D loss:-0.758 G loss:-2.067\n",
      "Epoch:  0060 D loss:-0.6285 G loss:-2.52\n",
      "Epoch:  0060 D loss:-0.5205 G loss:-2.383\n",
      "Epoch:  0060 D loss:-0.8332 G loss:-1.936\n",
      "Epoch:  0060 D loss:-0.7512 G loss:-1.967\n",
      "Epoch:  0060 D loss:-0.8164 G loss:-2.18\n",
      "Epoch:  0060 D loss:-0.7739 G loss:-2.205\n",
      "Epoch:  0060 D loss:-0.743 G loss:-2.139\n",
      "Epoch:  0060 D loss:-0.8011 G loss:-1.952\n",
      "Epoch:  0060 D loss:-0.708 G loss:-2.048\n",
      "Epoch:  0060 D loss:-0.7785 G loss:-1.755\n",
      "Epoch:  0060 D loss:-0.792 G loss:-1.977\n",
      "Epoch:  0060 D loss:-0.6009 G loss:-1.88\n",
      "Epoch:  0060 D loss:-0.8286 G loss:-1.863\n",
      "Epoch:  0060 D loss:-0.7199 G loss:-2.031\n",
      "Epoch:  0060 D loss:-0.683 G loss:-2.091\n",
      "Epoch:  0060 D loss:-0.6932 G loss:-1.971\n",
      "Epoch:  0060 D loss:-0.6967 G loss:-2.204\n",
      "Epoch:  0060 D loss:-0.5355 G loss:-2.32\n",
      "Epoch:  0060 D loss:-0.6663 G loss:-2.263\n",
      "Epoch:  0060 D loss:-0.6468 G loss:-2.18\n",
      "Epoch:  0060 D loss:-0.653 G loss:-2.122\n",
      "Epoch:  0060 D loss:-0.8172 G loss:-1.986\n",
      "Epoch:  0060 D loss:-0.6941 G loss:-2.271\n",
      "Epoch:  0060 D loss:-0.7457 G loss:-2.086\n",
      "Epoch:  0060 D loss:-0.7517 G loss:-1.837\n",
      "Epoch:  0060 D loss:-0.5886 G loss:-2.175\n",
      "Epoch:  0060 D loss:-0.7019 G loss:-2.171\n",
      "Epoch:  0060 D loss:-0.7417 G loss:-1.928\n",
      "Epoch:  0060 D loss:-0.6786 G loss:-2.269\n",
      "Epoch:  0060 D loss:-0.6886 G loss:-2.082\n",
      "Epoch:  0060 D loss:-0.6178 G loss:-2.125\n",
      "Epoch:  0060 D loss:-0.6142 G loss:-2.011\n",
      "Epoch:  0060 D loss:-0.7255 G loss:-1.951\n",
      "Epoch:  0060 D loss:-0.7966 G loss:-1.978\n",
      "Epoch:  0060 D loss:-0.6337 G loss:-1.857\n",
      "Epoch:  0060 D loss:-0.7255 G loss:-1.887\n",
      "Epoch:  0060 D loss:-0.7263 G loss:-2.018\n",
      "Epoch:  0060 D loss:-0.646 G loss:-2.063\n",
      "Epoch:  0060 D loss:-0.5775 G loss:-2.165\n",
      "Epoch:  0060 D loss:-0.6837 G loss:-2.292\n",
      "Epoch:  0060 D loss:-0.6131 G loss:-2.317\n",
      "Epoch:  0060 D loss:-0.5987 G loss:-2.333\n",
      "Epoch:  0060 D loss:-0.7048 G loss:-2.387\n",
      "Epoch:  0060 D loss:-0.7481 G loss:-2.368\n",
      "Epoch:  0060 D loss:-0.5593 G loss:-2.455\n",
      "Epoch:  0060 D loss:-0.6088 G loss:-2.296\n",
      "Epoch:  0060 D loss:-0.7003 G loss:-2.167\n",
      "Epoch:  0060 D loss:-0.6063 G loss:-2.009\n",
      "Epoch:  0060 D loss:-0.7276 G loss:-1.984\n",
      "Epoch:  0060 D loss:-0.6375 G loss:-2.051\n",
      "Epoch:  0060 D loss:-0.5541 G loss:-2.013\n",
      "Epoch:  0060 D loss:-0.6238 G loss:-1.984\n",
      "Epoch:  0060 D loss:-0.5758 G loss:-2.026\n",
      "Epoch:  0060 D loss:-0.5356 G loss:-2.444\n",
      "Epoch:  0060 D loss:-0.5804 G loss:-2.251\n",
      "Epoch:  0060 D loss:-0.6749 G loss:-2.298\n",
      "Epoch:  0060 D loss:-0.6626 G loss:-2.358\n",
      "Epoch:  0060 D loss:-0.6867 G loss:-2.391\n",
      "Epoch:  0060 D loss:-0.6452 G loss:-2.209\n",
      "Epoch:  0060 D loss:-0.6447 G loss:-2.398\n",
      "Epoch:  0060 D loss:-0.6133 G loss:-2.28\n",
      "Epoch:  0060 D loss:-0.5801 G loss:-2.253\n",
      "Epoch:  0060 D loss:-0.662 G loss:-2.137\n",
      "Epoch:  0060 D loss:-0.6386 G loss:-2.239\n",
      "Epoch:  0060 D loss:-0.5312 G loss:-2.203\n",
      "Epoch:  0060 D loss:-0.5931 G loss:-2.235\n",
      "Epoch:  0060 D loss:-0.6258 G loss:-2.006\n",
      "Epoch:  0060 D loss:-0.5096 G loss:-2.219\n",
      "Epoch:  0060 D loss:-0.5266 G loss:-2.099\n",
      "Epoch:  0060 D loss:-0.591 G loss:-2.286\n",
      "Epoch:  0060 D loss:-0.6629 G loss:-2.0\n",
      "Epoch:  0060 D loss:-0.6295 G loss:-2.225\n",
      "Epoch:  0060 D loss:-0.5977 G loss:-2.107\n",
      "Epoch:  0060 D loss:-0.647 G loss:-2.17\n",
      "Epoch:  0060 D loss:-0.5832 G loss:-2.138\n",
      "Epoch:  0060 D loss:-0.6835 G loss:-1.991\n",
      "Epoch:  0060 D loss:-0.6365 G loss:-2.245\n",
      "Epoch:  0060 D loss:-0.7035 G loss:-2.301\n",
      "Epoch:  0060 D loss:-0.6615 G loss:-2.291\n",
      "Epoch:  0060 D loss:-0.5926 G loss:-2.202\n",
      "Epoch:  0060 D loss:-0.7035 G loss:-2.201\n",
      "Epoch:  0060 D loss:-0.7464 G loss:-2.218\n",
      "Epoch:  0060 D loss:-0.6547 G loss:-2.16\n",
      "Epoch:  0060 D loss:-0.7778 G loss:-2.161\n",
      "Epoch:  0060 D loss:-0.7056 G loss:-2.16\n",
      "Epoch:  0060 D loss:-0.5956 G loss:-2.113\n",
      "Epoch:  0060 D loss:-0.6636 G loss:-2.087\n",
      "Epoch:  0060 D loss:-0.593 G loss:-2.391\n",
      "Epoch:  0060 D loss:-0.6462 G loss:-2.429\n",
      "Epoch:  0060 D loss:-0.5922 G loss:-2.474\n",
      "Epoch:  0060 D loss:-0.6184 G loss:-2.384\n",
      "Epoch:  0060 D loss:-0.6678 G loss:-2.248\n",
      "Epoch:  0060 D loss:-0.6034 G loss:-2.382\n",
      "Epoch:  0060 D loss:-0.5886 G loss:-2.228\n",
      "Epoch:  0060 D loss:-0.7175 G loss:-2.051\n",
      "Epoch:  0060 D loss:-0.6538 G loss:-1.828\n",
      "Epoch:  0060 D loss:-0.6162 G loss:-2.041\n",
      "Epoch:  0060 D loss:-0.5298 G loss:-2.045\n",
      "Epoch:  0060 D loss:-0.6413 G loss:-2.052\n",
      "Epoch:  0060 D loss:-0.5509 G loss:-2.051\n",
      "Epoch:  0060 D loss:-0.661 G loss:-1.995\n",
      "Epoch:  0060 D loss:-0.6534 G loss:-2.225\n",
      "Epoch:  0060 D loss:-0.714 G loss:-2.331\n",
      "Epoch:  0060 D loss:-0.738 G loss:-2.16\n",
      "Epoch:  0060 D loss:-0.7144 G loss:-2.437\n",
      "Epoch:  0060 D loss:-0.6534 G loss:-2.463\n",
      "Epoch:  0060 D loss:-0.4871 G loss:-2.252\n",
      "Epoch:  0060 D loss:-0.729 G loss:-2.258\n",
      "Epoch:  0060 D loss:-0.5702 G loss:-2.216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0060 D loss:-0.5701 G loss:-2.013\n",
      "Epoch:  0060 D loss:-0.6276 G loss:-1.884\n",
      "Epoch:  0060 D loss:-0.6316 G loss:-1.944\n",
      "Epoch:  0060 D loss:-0.6664 G loss:-1.768\n",
      "Epoch:  0060 D loss:-0.8497 G loss:-1.714\n",
      "Epoch:  0060 D loss:-0.7323 G loss:-1.772\n",
      "Epoch:  0060 D loss:-0.7367 G loss:-2.023\n",
      "Epoch:  0060 D loss:-0.7222 G loss:-1.964\n",
      "Epoch:  0060 D loss:-0.7667 G loss:-2.021\n",
      "Epoch:  0060 D loss:-0.5654 G loss:-2.291\n",
      "Epoch:  0060 D loss:-0.6578 G loss:-2.194\n",
      "Epoch:  0060 D loss:-0.5765 G loss:-2.499\n",
      "Epoch:  0060 D loss:-0.6354 G loss:-2.325\n",
      "Epoch:  0060 D loss:-0.7213 G loss:-2.155\n",
      "Epoch:  0060 D loss:-0.6987 G loss:-2.277\n",
      "Epoch:  0060 D loss:-0.6555 G loss:-2.23\n",
      "Epoch:  0060 D loss:-0.7654 G loss:-2.15\n",
      "Epoch:  0060 D loss:-0.7 G loss:-2.169\n",
      "Epoch:  0060 D loss:-0.6479 G loss:-2.066\n",
      "Epoch:  0060 D loss:-0.6566 G loss:-1.941\n",
      "Epoch:  0060 D loss:-0.5334 G loss:-1.89\n",
      "Epoch:  0060 D loss:-0.5366 G loss:-2.103\n",
      "Epoch:  0060 D loss:-0.683 G loss:-1.836\n",
      "Epoch:  0060 D loss:-0.6562 G loss:-2.21\n",
      "Epoch:  0060 D loss:-0.645 G loss:-2.296\n",
      "Epoch:  0060 D loss:-0.6929 G loss:-2.108\n",
      "Epoch:  0060 D loss:-0.7215 G loss:-2.211\n",
      "Epoch:  0060 D loss:-0.7333 G loss:-2.193\n",
      "Epoch:  0060 D loss:-0.6355 G loss:-2.156\n",
      "Epoch:  0060 D loss:-0.7348 G loss:-2.062\n",
      "Epoch:  0060 D loss:-0.6336 G loss:-2.235\n",
      "Epoch:  0060 D loss:-0.5713 G loss:-2.341\n",
      "Epoch:  0060 D loss:-0.6751 G loss:-2.207\n",
      "Epoch:  0060 D loss:-0.7085 G loss:-2.297\n",
      "Epoch:  0060 D loss:-0.6872 G loss:-2.097\n",
      "Epoch:  0060 D loss:-0.6939 G loss:-2.283\n",
      "Epoch:  0060 D loss:-0.7449 G loss:-2.078\n",
      "Epoch:  0060 D loss:-0.6786 G loss:-2.068\n",
      "Epoch:  0060 D loss:-0.5699 G loss:-2.378\n",
      "Epoch:  0060 D loss:-0.7671 G loss:-2.204\n",
      "Epoch:  0060 D loss:-0.7483 G loss:-2.336\n",
      "Epoch:  0060 D loss:-0.5854 G loss:-2.222\n",
      "Epoch:  0060 D loss:-0.7224 G loss:-2.224\n",
      "Epoch:  0060 D loss:-0.6663 G loss:-2.096\n",
      "Epoch:  0060 D loss:-0.7322 G loss:-2.089\n",
      "Epoch:  0060 D loss:-0.6252 G loss:-2.119\n",
      "Epoch:  0060 D loss:-0.7152 G loss:-2.055\n",
      "Epoch:  0060 D loss:-0.5676 G loss:-2.122\n",
      "Epoch:  0060 D loss:-0.6867 G loss:-1.972\n",
      "Epoch:  0060 D loss:-0.5755 G loss:-2.262\n",
      "Epoch:  0060 D loss:-0.6588 G loss:-2.245\n",
      "Epoch:  0060 D loss:-0.5931 G loss:-2.13\n",
      "Epoch:  0060 D loss:-0.7014 G loss:-2.246\n",
      "Epoch:  0060 D loss:-0.6414 G loss:-2.355\n",
      "Epoch:  0060 D loss:-0.5488 G loss:-2.261\n",
      "Epoch:  0060 D loss:-0.4488 G loss:-2.648\n",
      "Epoch:  0060 D loss:-0.7938 G loss:-2.227\n",
      "Epoch:  0060 D loss:-0.5679 G loss:-2.355\n",
      "Epoch:  0060 D loss:-0.5961 G loss:-2.49\n",
      "Epoch:  0060 D loss:-0.5061 G loss:-2.425\n",
      "Epoch:  0060 D loss:-0.7382 G loss:-2.251\n",
      "Epoch:  0060 D loss:-0.633 G loss:-2.233\n",
      "Epoch:  0060 D loss:-0.687 G loss:-2.505\n",
      "Epoch:  0060 D loss:-0.6546 G loss:-2.21\n",
      "Epoch:  0060 D loss:-0.6384 G loss:-1.92\n",
      "Epoch:  0060 D loss:-0.7698 G loss:-1.967\n",
      "Epoch:  0060 D loss:-0.6305 G loss:-2.228\n",
      "Epoch:  0060 D loss:-0.6664 G loss:-2.007\n",
      "Epoch:  0060 D loss:-0.6521 G loss:-2.06\n",
      "Epoch:  0060 D loss:-0.6633 G loss:-1.932\n",
      "Epoch:  0060 D loss:-0.7505 G loss:-2.112\n",
      "Epoch:  0060 D loss:-0.7238 G loss:-2.001\n",
      "Epoch:  0060 D loss:-0.6031 G loss:-2.416\n",
      "Epoch:  0060 D loss:-0.6296 G loss:-2.21\n",
      "Epoch:  0060 D loss:-0.6817 G loss:-2.168\n",
      "Epoch:  0060 D loss:-0.6575 G loss:-2.254\n",
      "Epoch:  0060 D loss:-0.6048 G loss:-2.348\n",
      "Epoch:  0060 D loss:-0.6965 G loss:-2.196\n",
      "Epoch:  0060 D loss:-0.6933 G loss:-2.158\n",
      "Epoch:  0060 D loss:-0.7223 G loss:-2.042\n",
      "Epoch:  0060 D loss:-0.4952 G loss:-2.203\n",
      "Epoch:  0060 D loss:-0.8034 G loss:-2.075\n",
      "Epoch:  0060 D loss:-0.6737 G loss:-2.145\n",
      "Epoch:  0060 D loss:-0.6271 G loss:-2.093\n",
      "Epoch:  0060 D loss:-0.6544 G loss:-1.966\n",
      "Epoch:  0060 D loss:-0.7191 G loss:-1.972\n",
      "Epoch:  0060 D loss:-0.6737 G loss:-2.054\n",
      "Epoch:  0060 D loss:-0.6635 G loss:-1.954\n",
      "Epoch:  0060 D loss:-0.7779 G loss:-2.032\n",
      "Epoch:  0060 D loss:-0.7527 G loss:-2.122\n",
      "Epoch:  0060 D loss:-0.7184 G loss:-2.056\n",
      "Epoch:  0060 D loss:-0.575 G loss:-2.309\n",
      "Epoch:  0060 D loss:-0.6668 G loss:-2.249\n",
      "Epoch:  0060 D loss:-0.7379 G loss:-2.215\n",
      "Epoch:  0060 D loss:-0.5972 G loss:-2.383\n",
      "Epoch:  0060 D loss:-0.5777 G loss:-2.354\n",
      "Epoch:  0060 D loss:-0.6623 G loss:-2.458\n",
      "Epoch:  0060 D loss:-0.746 G loss:-2.14\n",
      "Epoch:  0060 D loss:-0.6171 G loss:-2.273\n",
      "Epoch:  0060 D loss:-0.6958 G loss:-2.018\n",
      "Epoch:  0060 D loss:-0.7725 G loss:-2.106\n",
      "Epoch:  0060 D loss:-0.7521 G loss:-2.167\n",
      "Epoch:  0060 D loss:-0.6457 G loss:-1.947\n",
      "Epoch:  0060 D loss:-0.7623 G loss:-1.909\n",
      "Epoch:  0060 D loss:-0.6495 G loss:-2.038\n",
      "Epoch:  0060 D loss:-0.6987 G loss:-2.14\n",
      "Epoch:  0060 D loss:-0.7497 G loss:-2.028\n",
      "Epoch:  0060 D loss:-0.7679 G loss:-1.994\n",
      "Epoch:  0060 D loss:-0.6883 G loss:-1.988\n",
      "Epoch:  0060 D loss:-0.7424 G loss:-2.197\n",
      "Epoch:  0060 D loss:-0.5668 G loss:-2.246\n",
      "Epoch:  0060 D loss:-0.6047 G loss:-2.184\n",
      "Epoch:  0060 D loss:-0.6902 G loss:-1.883\n",
      "Epoch:  0060 D loss:-0.6459 G loss:-2.101\n",
      "Epoch:  0060 D loss:-0.5236 G loss:-2.256\n",
      "Epoch:  0060 D loss:-0.6613 G loss:-1.952\n",
      "Epoch:  0060 D loss:-0.6859 G loss:-2.322\n",
      "Epoch:  0060 D loss:-0.8023 G loss:-2.213\n",
      "Epoch:  0060 D loss:-0.6429 G loss:-2.302\n",
      "Epoch:  0060 D loss:-0.5015 G loss:-2.38\n",
      "Epoch:  0060 D loss:-0.7067 G loss:-2.057\n",
      "Epoch:  0060 D loss:-0.6941 G loss:-2.08\n",
      "Epoch:  0060 D loss:-0.5682 G loss:-2.38\n",
      "Epoch:  0060 D loss:-0.6649 G loss:-1.834\n",
      "Epoch:  0060 D loss:-0.5913 G loss:-1.85\n",
      "Epoch:  0060 D loss:-0.7223 G loss:-1.822\n",
      "Epoch:  0060 D loss:-0.7229 G loss:-1.881\n",
      "Epoch:  0060 D loss:-0.7978 G loss:-1.788\n",
      "Epoch:  0060 D loss:-0.6084 G loss:-1.852\n",
      "Epoch:  0060 D loss:-0.7239 G loss:-2.21\n",
      "Epoch:  0060 D loss:-0.6014 G loss:-2.095\n",
      "Epoch:  0060 D loss:-0.6098 G loss:-2.238\n",
      "Epoch:  0060 D loss:-0.5515 G loss:-2.406\n",
      "Epoch:  0060 D loss:-0.626 G loss:-2.548\n",
      "Epoch:  0060 D loss:-0.6068 G loss:-2.573\n",
      "Epoch:  0060 D loss:-0.7416 G loss:-2.416\n",
      "Epoch:  0060 D loss:-0.5954 G loss:-2.381\n",
      "Epoch:  0060 D loss:-0.7416 G loss:-2.282\n",
      "Epoch:  0060 D loss:-0.4453 G loss:-2.368\n",
      "Epoch:  0060 D loss:-0.6671 G loss:-2.216\n",
      "Epoch:  0060 D loss:-0.5039 G loss:-2.452\n",
      "Epoch:  0060 D loss:-0.5999 G loss:-2.286\n",
      "Epoch:  0060 D loss:-0.6162 G loss:-2.183\n",
      "Epoch:  0060 D loss:-0.6214 G loss:-1.969\n",
      "Epoch:  0060 D loss:-0.7614 G loss:-1.966\n",
      "Epoch:  0060 D loss:-0.6121 G loss:-2.31\n",
      "Epoch:  0060 D loss:-0.746 G loss:-2.277\n",
      "Epoch:  0060 D loss:-0.5951 G loss:-2.083\n",
      "Epoch:  0060 D loss:-0.7256 G loss:-2.117\n",
      "Epoch:  0060 D loss:-0.656 G loss:-2.118\n",
      "Epoch:  0060 D loss:-0.6468 G loss:-2.097\n",
      "Epoch:  0060 D loss:-0.6566 G loss:-2.006\n",
      "Epoch:  0060 D loss:-0.6275 G loss:-2.35\n",
      "Epoch:  0060 D loss:-0.578 G loss:-2.062\n",
      "Epoch:  0060 D loss:-0.6158 G loss:-1.98\n",
      "Epoch:  0060 D loss:-0.6585 G loss:-2.214\n",
      "Epoch:  0060 D loss:-0.5599 G loss:-2.365\n",
      "Epoch:  0060 D loss:-0.5632 G loss:-2.501\n",
      "Epoch:  0060 D loss:-0.6412 G loss:-2.265\n",
      "Epoch:  0060 D loss:-0.6673 G loss:-2.141\n",
      "Epoch:  0060 D loss:-0.6442 G loss:-2.176\n",
      "Epoch:  0060 D loss:-0.7334 G loss:-2.258\n",
      "Epoch:  0060 D loss:-0.5514 G loss:-2.05\n",
      "Epoch:  0060 D loss:-0.5503 G loss:-2.2\n",
      "Epoch:  0060 D loss:-0.556 G loss:-1.923\n",
      "Epoch:  0060 D loss:-0.5576 G loss:-2.24\n",
      "Epoch:  0060 D loss:-0.7034 G loss:-2.058\n",
      "Epoch:  0060 D loss:-0.6799 G loss:-2.033\n",
      "Epoch:  0060 D loss:-0.6262 G loss:-2.129\n",
      "Epoch:  0060 D loss:-0.7827 G loss:-1.912\n",
      "Epoch:  0060 D loss:-0.8151 G loss:-2.066\n",
      "Epoch:  0060 D loss:-0.6171 G loss:-2.241\n",
      "Epoch:  0060 D loss:-0.7534 G loss:-1.951\n",
      "Epoch:  0060 D loss:-0.6696 G loss:-2.124\n",
      "Epoch:  0060 D loss:-0.6397 G loss:-2.119\n",
      "Epoch:  0060 D loss:-0.6543 G loss:-2.066\n",
      "Epoch:  0060 D loss:-0.7568 G loss:-2.025\n",
      "Epoch:  0060 D loss:-0.6583 G loss:-1.999\n",
      "Epoch:  0060 D loss:-0.6927 G loss:-2.15\n",
      "Epoch:  0060 D loss:-0.6769 G loss:-1.862\n",
      "Epoch:  0060 D loss:-0.6145 G loss:-2.206\n",
      "Epoch:  0060 D loss:-0.5596 G loss:-2.207\n",
      "Epoch:  0060 D loss:-0.5631 G loss:-2.101\n",
      "Epoch:  0060 D loss:-0.6469 G loss:-2.134\n",
      "Epoch:  0060 D loss:-0.6454 G loss:-2.085\n",
      "Epoch:  0060 D loss:-0.6027 G loss:-2.201\n",
      "Epoch:  0060 D loss:-0.5838 G loss:-2.175\n",
      "Epoch:  0060 D loss:-0.7332 G loss:-2.236\n",
      "Epoch:  0060 D loss:-0.5956 G loss:-2.194\n",
      "Epoch:  0060 D loss:-0.5736 G loss:-2.094\n",
      "Epoch:  0060 D loss:-0.6823 G loss:-2.341\n",
      "Epoch:  0060 D loss:-0.5155 G loss:-2.364\n",
      "Epoch:  0060 D loss:-0.5258 G loss:-2.364\n",
      "Epoch:  0060 D loss:-0.5542 G loss:-2.256\n",
      "Epoch:  0060 D loss:-0.6643 G loss:-2.33\n",
      "Epoch:  0060 D loss:-0.7706 G loss:-1.999\n",
      "Epoch:  0060 D loss:-0.5397 G loss:-2.287\n",
      "Epoch:  0060 D loss:-0.6039 G loss:-2.035\n",
      "Epoch:  0060 D loss:-0.6627 G loss:-2.033\n",
      "Epoch:  0060 D loss:-0.6823 G loss:-2.017\n",
      "Epoch:  0060 D loss:-0.6633 G loss:-2.118\n",
      "Epoch:  0060 D loss:-0.7142 G loss:-1.997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0060 D loss:-0.5673 G loss:-2.13\n",
      "Epoch:  0060 D loss:-0.7074 G loss:-2.123\n",
      "Epoch:  0060 D loss:-0.6864 G loss:-2.096\n",
      "Epoch:  0060 D loss:-0.642 G loss:-2.04\n",
      "Epoch:  0060 D loss:-0.7513 G loss:-1.877\n",
      "Epoch:  0060 D loss:-0.5445 G loss:-2.149\n",
      "Epoch:  0060 D loss:-0.7215 G loss:-2.156\n",
      "Epoch:  0060 D loss:-0.6303 G loss:-2.202\n",
      "Epoch:  0060 D loss:-0.5783 G loss:-2.345\n",
      "Epoch:  0060 D loss:-0.6817 G loss:-2.241\n",
      "Epoch:  0060 D loss:-0.6919 G loss:-2.387\n",
      "Epoch:  0060 D loss:-0.4664 G loss:-2.321\n",
      "Epoch:  0060 D loss:-0.6265 G loss:-2.244\n",
      "Epoch:  0060 D loss:-0.6316 G loss:-2.166\n",
      "Epoch:  0060 D loss:-0.636 G loss:-2.211\n",
      "Epoch:  0060 D loss:-0.6341 G loss:-2.192\n",
      "Epoch:  0060 D loss:-0.6572 G loss:-2.084\n",
      "Epoch:  0060 D loss:-0.5863 G loss:-2.197\n",
      "Epoch:  0060 D loss:-0.6981 G loss:-2.105\n",
      "Epoch:  0060 D loss:-0.684 G loss:-2.214\n",
      "Epoch:  0060 D loss:-0.6315 G loss:-2.156\n",
      "Epoch:  0060 D loss:-0.5901 G loss:-2.132\n",
      "Epoch:  0060 D loss:-0.7598 G loss:-1.951\n",
      "Epoch:  0060 D loss:-0.564 G loss:-1.997\n",
      "Epoch:  0060 D loss:-0.5627 G loss:-2.073\n",
      "Epoch:  0060 D loss:-0.6687 G loss:-2.03\n",
      "Epoch:  0060 D loss:-0.7294 G loss:-2.166\n",
      "Epoch:  0060 D loss:-0.6224 G loss:-2.126\n",
      "Epoch:  0060 D loss:-0.628 G loss:-2.073\n",
      "Epoch:  0060 D loss:-0.7389 G loss:-1.985\n",
      "Epoch:  0060 D loss:-0.6565 G loss:-2.17\n",
      "Epoch:  0060 D loss:-0.831 G loss:-2.125\n",
      "Epoch:  0060 D loss:-0.7303 G loss:-2.023\n",
      "Epoch:  0060 D loss:-0.6864 G loss:-2.002\n",
      "Epoch:  0060 D loss:-0.695 G loss:-2.007\n",
      "Epoch:  0060 D loss:-0.6628 G loss:-1.967\n",
      "Epoch:  0060 D loss:-0.5899 G loss:-2.088\n",
      "Epoch:  0060 D loss:-0.6819 G loss:-1.875\n",
      "Epoch:  0060 D loss:-0.6409 G loss:-2.099\n",
      "Epoch:  0060 D loss:-0.6907 G loss:-2.029\n",
      "Epoch:  0060 D loss:-0.6232 G loss:-2.029\n",
      "Epoch:  0060 D loss:-0.7684 G loss:-2.058\n",
      "Epoch:  0060 D loss:-0.6348 G loss:-2.195\n",
      "Epoch:  0060 D loss:-0.6004 G loss:-2.075\n",
      "Epoch:  0060 D loss:-0.5523 G loss:-2.1\n",
      "Epoch:  0060 D loss:-0.6559 G loss:-2.222\n",
      "Epoch:  0060 D loss:-0.9328 G loss:-2.095\n",
      "Epoch:  0060 D loss:-0.6432 G loss:-2.139\n",
      "Epoch:  0060 D loss:-0.6083 G loss:-2.058\n",
      "Epoch:  0060 D loss:-0.8792 G loss:-1.846\n",
      "Epoch:  0060 D loss:-0.6603 G loss:-2.136\n",
      "Epoch:  0060 D loss:-0.6869 G loss:-1.843\n",
      "Epoch:  0060 D loss:-0.6215 G loss:-1.993\n",
      "Epoch:  0060 D loss:-0.7547 G loss:-2.085\n",
      "Epoch:  0060 D loss:-0.6082 G loss:-2.027\n",
      "Epoch:  0060 D loss:-0.6956 G loss:-2.117\n",
      "Epoch:  0060 D loss:-0.683 G loss:-2.362\n",
      "Epoch:  0060 D loss:-0.4682 G loss:-2.228\n",
      "Epoch:  0060 D loss:-0.653 G loss:-2.146\n",
      "Epoch:  0060 D loss:-0.5818 G loss:-2.371\n",
      "Epoch:  0060 D loss:-0.6308 G loss:-2.242\n",
      "Epoch:  0060 D loss:-0.6823 G loss:-2.251\n",
      "Epoch:  0060 D loss:-0.7042 G loss:-2.181\n",
      "Epoch:  0060 D loss:-0.5338 G loss:-2.39\n",
      "Epoch:  0060 D loss:-0.5693 G loss:-2.128\n",
      "Epoch:  0060 D loss:-0.6385 G loss:-2.182\n",
      "Epoch:  0060 D loss:-0.7796 G loss:-1.868\n",
      "Epoch:  0060 D loss:-0.736 G loss:-2.02\n",
      "Epoch:  0060 D loss:-0.5842 G loss:-2.208\n",
      "Epoch:  0060 D loss:-0.4759 G loss:-2.121\n",
      "Epoch:  0060 D loss:-0.6545 G loss:-2.271\n",
      "Epoch:  0060 D loss:-0.6288 G loss:-2.136\n",
      "Epoch:  0060 D loss:-0.604 G loss:-2.273\n",
      "Epoch:  0060 D loss:-0.5776 G loss:-2.044\n",
      "Epoch:  0060 D loss:-0.6012 G loss:-2.171\n",
      "Epoch:  0060 D loss:-0.7772 G loss:-2.149\n",
      "Epoch:  0060 D loss:-0.8355 G loss:-2.177\n",
      "Epoch:  0060 D loss:-0.6045 G loss:-2.038\n",
      "Epoch:  0060 D loss:-0.587 G loss:-2.254\n",
      "Epoch:  0060 D loss:-0.6089 G loss:-2.061\n",
      "Epoch:  0060 D loss:-0.5653 G loss:-2.066\n",
      "Epoch:  0060 D loss:-0.8983 G loss:-2.154\n",
      "Epoch:  0060 D loss:-0.6089 G loss:-2.241\n",
      "Epoch:  0060 D loss:-0.7142 G loss:-2.091\n",
      "Epoch:  0060 D loss:-0.549 G loss:-2.316\n",
      "Epoch:  0060 D loss:-0.7619 G loss:-2.055\n",
      "Epoch:  0060 D loss:-0.7291 G loss:-2.152\n",
      "Epoch:  0060 D loss:-0.6292 G loss:-2.14\n",
      "Epoch:  0060 D loss:-0.7212 G loss:-2.033\n",
      "Epoch:  0060 D loss:-0.64 G loss:-2.248\n",
      "Epoch:  0060 D loss:-0.5312 G loss:-2.074\n",
      "Epoch:  0060 D loss:-0.6974 G loss:-1.902\n",
      "Epoch:  0060 D loss:-0.713 G loss:-1.98\n",
      "Epoch:  0060 D loss:-0.6213 G loss:-2.04\n",
      "Epoch:  0060 D loss:-0.5831 G loss:-2.0\n",
      "Epoch:  0060 D loss:-0.701 G loss:-2.017\n",
      "Epoch:  0060 D loss:-0.5964 G loss:-2.152\n",
      "Epoch:  0060 D loss:-0.6502 G loss:-2.218\n",
      "Epoch:  0060 D loss:-0.5761 G loss:-2.01\n",
      "Epoch:  0060 D loss:-0.5976 G loss:-2.262\n",
      "Epoch:  0060 D loss:-0.5738 G loss:-2.127\n",
      "Epoch:  0060 D loss:-0.5738 G loss:-2.114\n",
      "Epoch:  0060 D loss:-0.668 G loss:-2.334\n",
      "Epoch:  0060 D loss:-0.6539 G loss:-2.269\n",
      "Epoch:  0060 D loss:-0.6315 G loss:-2.347\n",
      "Epoch:  0060 D loss:-0.5867 G loss:-2.37\n",
      "Epoch:  0060 D loss:-0.5397 G loss:-2.315\n",
      "Epoch:  0060 D loss:-0.5528 G loss:-2.038\n",
      "Epoch:  0060 D loss:-0.7245 G loss:-1.924\n",
      "Epoch:  0060 D loss:-0.6481 G loss:-1.98\n",
      "Epoch:  0060 D loss:-0.555 G loss:-1.875\n",
      "Epoch:  0060 D loss:-0.6827 G loss:-2.217\n",
      "Epoch:  0060 D loss:-0.574 G loss:-2.322\n",
      "Epoch:  0060 D loss:-0.588 G loss:-2.363\n",
      "Epoch:  0060 D loss:-0.6779 G loss:-2.082\n",
      "Epoch:  0060 D loss:-0.5925 G loss:-2.274\n",
      "Epoch:  0060 D loss:-0.6415 G loss:-2.384\n",
      "Epoch:  0060 D loss:-0.6183 G loss:-2.35\n",
      "Epoch:  0060 D loss:-0.4611 G loss:-2.268\n",
      "Epoch:  0060 D loss:-0.6716 G loss:-2.213\n",
      "Epoch:  0060 D loss:-0.6507 G loss:-2.26\n",
      "Epoch:  0060 D loss:-0.6064 G loss:-2.344\n",
      "Epoch:  0060 D loss:-0.5364 G loss:-2.401\n",
      "Epoch:  0060 D loss:-0.5627 G loss:-2.422\n",
      "Epoch:  0060 D loss:-0.6426 G loss:-2.21\n",
      "Epoch:  0060 D loss:-0.5384 G loss:-2.081\n",
      "Epoch:  0060 D loss:-0.6687 G loss:-2.011\n",
      "Epoch:  0060 D loss:-0.7737 G loss:-1.883\n",
      "Epoch:  0060 D loss:-0.6306 G loss:-2.149\n",
      "Epoch:  0060 D loss:-0.6346 G loss:-2.091\n",
      "Epoch:  0060 D loss:-0.6166 G loss:-2.277\n",
      "Epoch:  0060 D loss:-0.6475 G loss:-2.278\n",
      "Epoch:  0060 D loss:-0.6617 G loss:-1.971\n",
      "Epoch:  0060 D loss:-0.5662 G loss:-2.158\n",
      "Epoch:  0060 D loss:-0.7008 G loss:-2.322\n",
      "Epoch:  0060 D loss:-0.6625 G loss:-2.013\n",
      "Epoch:  0060 D loss:-0.6567 G loss:-2.269\n",
      "Epoch:  0060 D loss:-0.5564 G loss:-2.172\n",
      "Epoch:  0060 D loss:-0.7996 G loss:-2.101\n",
      "Epoch:  0060 D loss:-0.5471 G loss:-2.127\n",
      "Epoch:  0060 D loss:-0.6789 G loss:-2.014\n",
      "Epoch:  0060 D loss:-0.5251 G loss:-2.131\n",
      "Epoch:  0060 D loss:-0.7626 G loss:-1.835\n",
      "Epoch:  0060 D loss:-0.6133 G loss:-2.211\n",
      "Epoch:  0060 D loss:-0.6519 G loss:-1.962\n",
      "Epoch:  0060 D loss:-0.7426 G loss:-1.878\n",
      "Epoch:  0060 D loss:-0.6121 G loss:-2.126\n",
      "Epoch:  0060 D loss:-0.6073 G loss:-2.281\n",
      "Epoch:  0060 D loss:-0.7632 G loss:-2.166\n",
      "Epoch:  0060 D loss:-0.6334 G loss:-2.232\n",
      "Epoch:  0060 D loss:-0.6242 G loss:-2.139\n",
      "Epoch:  0060 D loss:-0.5468 G loss:-2.065\n",
      "Epoch:  0060 D loss:-0.6254 G loss:-2.32\n",
      "Epoch:  0060 D loss:-0.8332 G loss:-1.959\n",
      "Epoch:  0060 D loss:-0.7177 G loss:-1.892\n",
      "Epoch:  0060 D loss:-0.6899 G loss:-2.025\n",
      "Epoch:  0060 D loss:-0.6546 G loss:-2.154\n",
      "Epoch:  0060 D loss:-0.6733 G loss:-2.245\n",
      "Epoch:  0060 D loss:-0.7314 G loss:-1.926\n",
      "Epoch:  0060 D loss:-0.4888 G loss:-2.288\n",
      "Epoch:  0060 D loss:-0.5936 G loss:-2.318\n",
      "Epoch:  0060 D loss:-0.5661 G loss:-2.287\n",
      "Epoch:  0060 D loss:-0.6875 G loss:-2.337\n",
      "Epoch:  0060 D loss:-0.7175 G loss:-2.088\n",
      "Epoch:  0060 D loss:-0.5785 G loss:-2.293\n",
      "Epoch:  0060 D loss:-0.677 G loss:-2.021\n",
      "Epoch:  0060 D loss:-0.6908 G loss:-2.145\n",
      "Epoch:  0060 D loss:-0.6801 G loss:-1.972\n",
      "Epoch:  0060 D loss:-0.7992 G loss:-1.941\n",
      "Epoch:  0060 D loss:-0.6898 G loss:-2.016\n",
      "Epoch:  0060 D loss:-0.6045 G loss:-1.958\n",
      "Epoch:  0060 D loss:-0.6596 G loss:-2.068\n",
      "Epoch:  0060 D loss:-0.5328 G loss:-2.187\n",
      "Epoch:  0060 D loss:-0.6268 G loss:-2.169\n",
      "Epoch:  0060 D loss:-0.7501 G loss:-2.386\n",
      "Epoch:  0060 D loss:-0.5633 G loss:-2.451\n",
      "Epoch:  0060 D loss:-0.6443 G loss:-2.46\n",
      "Epoch:  0060 D loss:-0.5951 G loss:-2.448\n",
      "Epoch:  0060 D loss:-0.594 G loss:-2.488\n",
      "Epoch:  0060 D loss:-0.6521 G loss:-2.434\n",
      "Epoch:  0060 D loss:-0.7381 G loss:-2.122\n",
      "Epoch:  0060 D loss:-0.6414 G loss:-2.365\n",
      "Epoch:  0060 D loss:-0.7025 G loss:-2.29\n",
      "Epoch:  0060 D loss:-0.6629 G loss:-2.31\n",
      "Epoch:  0060 D loss:-0.6767 G loss:-1.922\n",
      "Epoch:  0060 D loss:-0.7863 G loss:-1.783\n",
      "Epoch:  0060 D loss:-0.5935 G loss:-2.171\n",
      "Epoch:  0060 D loss:-0.609 G loss:-1.998\n",
      "Epoch:  0060 D loss:-0.6996 G loss:-1.691\n",
      "Epoch:  0060 D loss:-0.6439 G loss:-2.187\n",
      "Epoch:  0060 D loss:-0.6799 G loss:-1.932\n",
      "Epoch:  0060 D loss:-0.5337 G loss:-2.083\n",
      "Epoch:  0060 D loss:-0.5487 G loss:-2.046\n",
      "Epoch:  0060 D loss:-0.6917 G loss:-2.098\n",
      "Epoch:  0060 D loss:-0.5784 G loss:-2.291\n",
      "Epoch:  0060 D loss:-0.6444 G loss:-2.045\n",
      "Epoch:  0060 D loss:-0.7241 G loss:-2.168\n",
      "Epoch:  0060 D loss:-0.7025 G loss:-2.386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0060 D loss:-0.6201 G loss:-2.295\n",
      "Epoch:  0060 D loss:-0.6853 G loss:-2.178\n",
      "Epoch:  0060 D loss:-0.5948 G loss:-2.302\n",
      "Epoch:  0060 D loss:-0.7026 G loss:-2.118\n",
      "Epoch:  0060 D loss:-0.6799 G loss:-1.923\n",
      "Epoch:  0060 D loss:-0.5557 G loss:-2.13\n",
      "Epoch:  0060 D loss:-0.7322 G loss:-2.153\n",
      "Epoch:  0060 D loss:-0.5898 G loss:-2.16\n",
      "Epoch:  0060 D loss:-0.5318 G loss:-2.038\n",
      "Epoch:  0060 D loss:-0.7914 G loss:-2.056\n",
      "Epoch:  0060 D loss:-0.7124 G loss:-2.113\n",
      "Epoch:  0060 D loss:-0.7073 G loss:-1.969\n",
      "Epoch:  0060 D loss:-0.7565 G loss:-2.129\n",
      "Epoch:  0060 D loss:-0.8074 G loss:-2.137\n",
      "Epoch:  0060 D loss:-0.5496 G loss:-2.27\n",
      "Epoch:  0060 D loss:-0.7875 G loss:-2.236\n",
      "Epoch:  0060 D loss:-0.6859 G loss:-2.019\n",
      "Epoch:  0060 D loss:-0.5854 G loss:-2.06\n",
      "Epoch:  0060 D loss:-0.7265 G loss:-2.1\n",
      "Epoch:  0060 D loss:-0.6389 G loss:-2.092\n",
      "Epoch:  0060 D loss:-0.7771 G loss:-2.023\n",
      "Epoch:  0060 D loss:-0.711 G loss:-2.092\n",
      "Epoch:  0060 D loss:-0.6782 G loss:-2.247\n",
      "Epoch:  0060 D loss:-0.6693 G loss:-2.13\n",
      "Epoch:  0060 D loss:-0.6145 G loss:-2.245\n",
      "Epoch:  0060 D loss:-0.6383 G loss:-2.358\n",
      "Epoch:  0061 D loss:-0.8098 G loss:-2.103\n",
      "Epoch:  0061 D loss:-0.6269 G loss:-2.089\n",
      "Epoch:  0061 D loss:-0.6014 G loss:-2.255\n",
      "Epoch:  0061 D loss:-0.5859 G loss:-2.058\n",
      "Epoch:  0061 D loss:-0.8375 G loss:-1.84\n",
      "Epoch:  0061 D loss:-0.7101 G loss:-1.914\n",
      "Epoch:  0061 D loss:-0.4954 G loss:-2.176\n",
      "Epoch:  0061 D loss:-0.6359 G loss:-2.024\n",
      "Epoch:  0061 D loss:-0.6502 G loss:-2.275\n",
      "Epoch:  0061 D loss:-0.565 G loss:-2.286\n",
      "Epoch:  0061 D loss:-0.7434 G loss:-2.381\n",
      "Epoch:  0061 D loss:-0.8601 G loss:-2.194\n",
      "Epoch:  0061 D loss:-0.6675 G loss:-2.15\n",
      "Epoch:  0061 D loss:-0.7863 G loss:-2.364\n",
      "Epoch:  0061 D loss:-0.7389 G loss:-1.961\n",
      "Epoch:  0061 D loss:-0.6248 G loss:-1.914\n",
      "Epoch:  0061 D loss:-0.6484 G loss:-1.988\n",
      "Epoch:  0061 D loss:-0.6519 G loss:-1.714\n",
      "Epoch:  0061 D loss:-0.5189 G loss:-2.188\n",
      "Epoch:  0061 D loss:-0.601 G loss:-2.09\n",
      "Epoch:  0061 D loss:-0.6308 G loss:-2.099\n",
      "Epoch:  0061 D loss:-0.7062 G loss:-2.098\n",
      "Epoch:  0061 D loss:-0.532 G loss:-2.256\n",
      "Epoch:  0061 D loss:-0.6664 G loss:-2.172\n",
      "Epoch:  0061 D loss:-0.6115 G loss:-2.207\n",
      "Epoch:  0061 D loss:-0.5695 G loss:-2.289\n",
      "Epoch:  0061 D loss:-0.579 G loss:-2.149\n",
      "Epoch:  0061 D loss:-0.5202 G loss:-2.318\n",
      "Epoch:  0061 D loss:-0.7745 G loss:-2.018\n",
      "Epoch:  0061 D loss:-0.7141 G loss:-2.155\n",
      "Epoch:  0061 D loss:-0.6576 G loss:-2.034\n",
      "Epoch:  0061 D loss:-0.7185 G loss:-2.128\n",
      "Epoch:  0061 D loss:-0.5728 G loss:-2.021\n",
      "Epoch:  0061 D loss:-0.7012 G loss:-1.923\n",
      "Epoch:  0061 D loss:-0.6476 G loss:-2.079\n",
      "Epoch:  0061 D loss:-0.5526 G loss:-2.128\n",
      "Epoch:  0061 D loss:-0.5831 G loss:-1.946\n",
      "Epoch:  0061 D loss:-0.6988 G loss:-1.948\n",
      "Epoch:  0061 D loss:-0.6698 G loss:-1.927\n",
      "Epoch:  0061 D loss:-0.6771 G loss:-2.084\n",
      "Epoch:  0061 D loss:-0.5916 G loss:-2.05\n",
      "Epoch:  0061 D loss:-0.6081 G loss:-2.081\n",
      "Epoch:  0061 D loss:-0.7015 G loss:-1.945\n",
      "Epoch:  0061 D loss:-0.6017 G loss:-2.341\n",
      "Epoch:  0061 D loss:-0.5403 G loss:-2.19\n",
      "Epoch:  0061 D loss:-0.5741 G loss:-2.091\n",
      "Epoch:  0061 D loss:-0.5774 G loss:-2.053\n",
      "Epoch:  0061 D loss:-0.6751 G loss:-1.922\n",
      "Epoch:  0061 D loss:-0.6913 G loss:-2.101\n",
      "Epoch:  0061 D loss:-0.6288 G loss:-2.399\n",
      "Epoch:  0061 D loss:-0.6254 G loss:-2.199\n",
      "Epoch:  0061 D loss:-0.718 G loss:-2.11\n",
      "Epoch:  0061 D loss:-0.6787 G loss:-2.177\n",
      "Epoch:  0061 D loss:-0.6847 G loss:-2.108\n",
      "Epoch:  0061 D loss:-0.434 G loss:-2.376\n",
      "Epoch:  0061 D loss:-0.7351 G loss:-2.305\n",
      "Epoch:  0061 D loss:-0.5863 G loss:-2.327\n",
      "Epoch:  0061 D loss:-0.7274 G loss:-2.093\n",
      "Epoch:  0061 D loss:-0.6987 G loss:-2.269\n",
      "Epoch:  0061 D loss:-0.5944 G loss:-2.319\n",
      "Epoch:  0061 D loss:-0.621 G loss:-2.26\n",
      "Epoch:  0061 D loss:-0.6865 G loss:-2.094\n",
      "Epoch:  0061 D loss:-0.6942 G loss:-2.051\n",
      "Epoch:  0061 D loss:-0.7784 G loss:-1.883\n",
      "Epoch:  0061 D loss:-0.5974 G loss:-2.033\n",
      "Epoch:  0061 D loss:-0.6481 G loss:-1.951\n",
      "Epoch:  0061 D loss:-0.6312 G loss:-2.004\n",
      "Epoch:  0061 D loss:-0.6148 G loss:-1.946\n",
      "Epoch:  0061 D loss:-0.7215 G loss:-1.98\n",
      "Epoch:  0061 D loss:-0.6255 G loss:-2.326\n",
      "Epoch:  0061 D loss:-0.6124 G loss:-2.152\n",
      "Epoch:  0061 D loss:-0.5463 G loss:-2.292\n",
      "Epoch:  0061 D loss:-0.4868 G loss:-2.291\n",
      "Epoch:  0061 D loss:-0.643 G loss:-2.351\n",
      "Epoch:  0061 D loss:-0.6463 G loss:-2.13\n",
      "Epoch:  0061 D loss:-0.696 G loss:-2.425\n",
      "Epoch:  0061 D loss:-0.7241 G loss:-2.16\n",
      "Epoch:  0061 D loss:-0.5598 G loss:-2.077\n",
      "Epoch:  0061 D loss:-0.6401 G loss:-2.267\n",
      "Epoch:  0061 D loss:-0.608 G loss:-2.002\n",
      "Epoch:  0061 D loss:-0.6455 G loss:-1.975\n",
      "Epoch:  0061 D loss:-0.7492 G loss:-2.01\n",
      "Epoch:  0061 D loss:-0.6199 G loss:-1.996\n",
      "Epoch:  0061 D loss:-0.622 G loss:-2.065\n",
      "Epoch:  0061 D loss:-0.7403 G loss:-1.918\n",
      "Epoch:  0061 D loss:-0.6383 G loss:-1.909\n",
      "Epoch:  0061 D loss:-0.6102 G loss:-2.144\n",
      "Epoch:  0061 D loss:-0.6564 G loss:-2.028\n",
      "Epoch:  0061 D loss:-0.6329 G loss:-2.379\n",
      "Epoch:  0061 D loss:-0.5543 G loss:-2.413\n",
      "Epoch:  0061 D loss:-0.6901 G loss:-2.052\n",
      "Epoch:  0061 D loss:-0.6048 G loss:-2.242\n",
      "Epoch:  0061 D loss:-0.7039 G loss:-2.273\n",
      "Epoch:  0061 D loss:-0.5949 G loss:-2.336\n",
      "Epoch:  0061 D loss:-0.7135 G loss:-2.141\n",
      "Epoch:  0061 D loss:-0.7354 G loss:-2.012\n",
      "Epoch:  0061 D loss:-0.4808 G loss:-2.218\n",
      "Epoch:  0061 D loss:-0.7085 G loss:-1.973\n",
      "Epoch:  0061 D loss:-0.5907 G loss:-2.082\n",
      "Epoch:  0061 D loss:-0.57 G loss:-2.189\n",
      "Epoch:  0061 D loss:-0.5455 G loss:-2.134\n",
      "Epoch:  0061 D loss:-0.618 G loss:-2.072\n",
      "Epoch:  0061 D loss:-0.6904 G loss:-2.021\n",
      "Epoch:  0061 D loss:-0.6141 G loss:-2.102\n",
      "Epoch:  0061 D loss:-0.5771 G loss:-2.25\n",
      "Epoch:  0061 D loss:-0.5894 G loss:-2.413\n",
      "Epoch:  0061 D loss:-0.669 G loss:-2.371\n",
      "Epoch:  0061 D loss:-0.578 G loss:-2.413\n",
      "Epoch:  0061 D loss:-0.6775 G loss:-2.487\n",
      "Epoch:  0061 D loss:-0.6038 G loss:-2.44\n",
      "Epoch:  0061 D loss:-0.6118 G loss:-2.332\n",
      "Epoch:  0061 D loss:-0.6286 G loss:-2.081\n",
      "Epoch:  0061 D loss:-0.7346 G loss:-2.059\n",
      "Epoch:  0061 D loss:-0.612 G loss:-1.939\n",
      "Epoch:  0061 D loss:-0.7119 G loss:-1.89\n",
      "Epoch:  0061 D loss:-0.7182 G loss:-1.973\n",
      "Epoch:  0061 D loss:-0.5882 G loss:-2.068\n",
      "Epoch:  0061 D loss:-0.7675 G loss:-1.889\n",
      "Epoch:  0061 D loss:-0.5807 G loss:-2.307\n",
      "Epoch:  0061 D loss:-0.7616 G loss:-2.016\n",
      "Epoch:  0061 D loss:-0.6822 G loss:-2.042\n",
      "Epoch:  0061 D loss:-0.6688 G loss:-2.302\n",
      "Epoch:  0061 D loss:-0.6945 G loss:-1.975\n",
      "Epoch:  0061 D loss:-0.6763 G loss:-2.074\n",
      "Epoch:  0061 D loss:-0.8014 G loss:-1.934\n",
      "Epoch:  0061 D loss:-0.6483 G loss:-2.08\n",
      "Epoch:  0061 D loss:-0.5935 G loss:-2.123\n",
      "Epoch:  0061 D loss:-0.7736 G loss:-2.102\n",
      "Epoch:  0061 D loss:-0.6454 G loss:-2.253\n",
      "Epoch:  0061 D loss:-0.6531 G loss:-2.102\n",
      "Epoch:  0061 D loss:-0.5914 G loss:-2.265\n",
      "Epoch:  0061 D loss:-0.6318 G loss:-2.261\n",
      "Epoch:  0061 D loss:-0.7361 G loss:-2.273\n",
      "Epoch:  0061 D loss:-0.7223 G loss:-2.362\n",
      "Epoch:  0061 D loss:-0.7808 G loss:-2.081\n",
      "Epoch:  0061 D loss:-0.728 G loss:-2.124\n",
      "Epoch:  0061 D loss:-0.6268 G loss:-2.083\n",
      "Epoch:  0061 D loss:-0.805 G loss:-1.816\n",
      "Epoch:  0061 D loss:-0.7506 G loss:-2.173\n",
      "Epoch:  0061 D loss:-0.614 G loss:-1.894\n",
      "Epoch:  0061 D loss:-0.672 G loss:-2.006\n",
      "Epoch:  0061 D loss:-0.6571 G loss:-2.055\n",
      "Epoch:  0061 D loss:-0.5873 G loss:-2.072\n",
      "Epoch:  0061 D loss:-0.6932 G loss:-2.102\n",
      "Epoch:  0061 D loss:-0.7442 G loss:-2.033\n",
      "Epoch:  0061 D loss:-0.6122 G loss:-2.186\n",
      "Epoch:  0061 D loss:-0.6404 G loss:-2.156\n",
      "Epoch:  0061 D loss:-0.7321 G loss:-2.069\n",
      "Epoch:  0061 D loss:-0.6787 G loss:-2.027\n",
      "Epoch:  0061 D loss:-0.8208 G loss:-1.98\n",
      "Epoch:  0061 D loss:-0.7096 G loss:-2.428\n",
      "Epoch:  0061 D loss:-0.6321 G loss:-2.371\n",
      "Epoch:  0061 D loss:-0.6235 G loss:-2.278\n",
      "Epoch:  0061 D loss:-0.6306 G loss:-2.253\n",
      "Epoch:  0061 D loss:-0.5334 G loss:-2.166\n",
      "Epoch:  0061 D loss:-0.6792 G loss:-1.881\n",
      "Epoch:  0061 D loss:-0.7828 G loss:-1.957\n",
      "Epoch:  0061 D loss:-0.5602 G loss:-1.793\n",
      "Epoch:  0061 D loss:-0.609 G loss:-1.952\n",
      "Epoch:  0061 D loss:-0.773 G loss:-1.814\n",
      "Epoch:  0061 D loss:-0.6269 G loss:-2.06\n",
      "Epoch:  0061 D loss:-0.7704 G loss:-1.981\n",
      "Epoch:  0061 D loss:-0.663 G loss:-2.174\n",
      "Epoch:  0061 D loss:-0.5435 G loss:-2.292\n",
      "Epoch:  0061 D loss:-0.6893 G loss:-2.058\n",
      "Epoch:  0061 D loss:-0.6879 G loss:-2.081\n",
      "Epoch:  0061 D loss:-0.6471 G loss:-2.181\n",
      "Epoch:  0061 D loss:-0.7087 G loss:-2.071\n",
      "Epoch:  0061 D loss:-0.8361 G loss:-2.095\n",
      "Epoch:  0061 D loss:-0.5702 G loss:-2.082\n",
      "Epoch:  0061 D loss:-0.6898 G loss:-2.013\n",
      "Epoch:  0061 D loss:-0.6768 G loss:-2.047\n",
      "Epoch:  0061 D loss:-0.5825 G loss:-1.969\n",
      "Epoch:  0061 D loss:-0.6515 G loss:-1.943\n",
      "Epoch:  0061 D loss:-0.7894 G loss:-1.732\n",
      "Epoch:  0061 D loss:-0.6168 G loss:-1.891\n",
      "Epoch:  0061 D loss:-0.7292 G loss:-1.968\n",
      "Epoch:  0061 D loss:-0.7687 G loss:-2.037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0061 D loss:-0.6598 G loss:-2.036\n",
      "Epoch:  0061 D loss:-0.6899 G loss:-2.017\n",
      "Epoch:  0061 D loss:-0.7749 G loss:-2.069\n",
      "Epoch:  0061 D loss:-0.6224 G loss:-2.043\n",
      "Epoch:  0061 D loss:-0.7131 G loss:-2.084\n",
      "Epoch:  0061 D loss:-0.6366 G loss:-2.394\n",
      "Epoch:  0061 D loss:-0.7453 G loss:-2.132\n",
      "Epoch:  0061 D loss:-0.5891 G loss:-2.094\n",
      "Epoch:  0061 D loss:-0.8298 G loss:-1.944\n",
      "Epoch:  0061 D loss:-0.558 G loss:-2.032\n",
      "Epoch:  0061 D loss:-0.7216 G loss:-1.958\n",
      "Epoch:  0061 D loss:-0.7352 G loss:-2.08\n",
      "Epoch:  0061 D loss:-0.5565 G loss:-1.993\n",
      "Epoch:  0061 D loss:-0.5858 G loss:-2.06\n",
      "Epoch:  0061 D loss:-0.687 G loss:-2.155\n",
      "Epoch:  0061 D loss:-0.6148 G loss:-1.914\n",
      "Epoch:  0061 D loss:-0.681 G loss:-1.969\n",
      "Epoch:  0061 D loss:-0.6487 G loss:-2.098\n",
      "Epoch:  0061 D loss:-0.6008 G loss:-2.104\n",
      "Epoch:  0061 D loss:-0.6741 G loss:-1.914\n",
      "Epoch:  0061 D loss:-0.7882 G loss:-2.135\n",
      "Epoch:  0061 D loss:-0.8531 G loss:-2.266\n",
      "Epoch:  0061 D loss:-0.7897 G loss:-2.223\n",
      "Epoch:  0061 D loss:-0.5926 G loss:-2.26\n",
      "Epoch:  0061 D loss:-0.7047 G loss:-1.955\n",
      "Epoch:  0061 D loss:-0.616 G loss:-2.144\n",
      "Epoch:  0061 D loss:-0.6863 G loss:-2.027\n",
      "Epoch:  0061 D loss:-0.5982 G loss:-2.141\n",
      "Epoch:  0061 D loss:-0.5301 G loss:-2.135\n",
      "Epoch:  0061 D loss:-0.7124 G loss:-1.966\n",
      "Epoch:  0061 D loss:-0.6974 G loss:-1.993\n",
      "Epoch:  0061 D loss:-0.5363 G loss:-2.272\n",
      "Epoch:  0061 D loss:-0.5638 G loss:-2.253\n",
      "Epoch:  0061 D loss:-0.7791 G loss:-2.076\n",
      "Epoch:  0061 D loss:-0.6865 G loss:-2.232\n",
      "Epoch:  0061 D loss:-0.7887 G loss:-1.871\n",
      "Epoch:  0061 D loss:-0.6545 G loss:-1.908\n",
      "Epoch:  0061 D loss:-0.622 G loss:-2.003\n",
      "Epoch:  0061 D loss:-0.7108 G loss:-1.874\n",
      "Epoch:  0061 D loss:-0.795 G loss:-2.159\n",
      "Epoch:  0061 D loss:-0.7584 G loss:-1.98\n",
      "Epoch:  0061 D loss:-0.6395 G loss:-2.138\n",
      "Epoch:  0061 D loss:-0.6857 G loss:-2.113\n",
      "Epoch:  0061 D loss:-0.5258 G loss:-2.152\n",
      "Epoch:  0061 D loss:-0.662 G loss:-2.101\n",
      "Epoch:  0061 D loss:-0.8004 G loss:-1.989\n",
      "Epoch:  0061 D loss:-0.8047 G loss:-2.142\n",
      "Epoch:  0061 D loss:-0.6604 G loss:-2.435\n",
      "Epoch:  0061 D loss:-0.5645 G loss:-2.307\n",
      "Epoch:  0061 D loss:-0.6355 G loss:-2.086\n",
      "Epoch:  0061 D loss:-0.6752 G loss:-2.283\n",
      "Epoch:  0061 D loss:-0.6332 G loss:-2.134\n",
      "Epoch:  0061 D loss:-0.6579 G loss:-2.23\n",
      "Epoch:  0061 D loss:-0.7004 G loss:-1.957\n",
      "Epoch:  0061 D loss:-0.6558 G loss:-2.176\n",
      "Epoch:  0061 D loss:-0.6773 G loss:-2.053\n",
      "Epoch:  0061 D loss:-0.6776 G loss:-1.967\n",
      "Epoch:  0061 D loss:-0.6401 G loss:-2.097\n",
      "Epoch:  0061 D loss:-0.7639 G loss:-1.881\n",
      "Epoch:  0061 D loss:-0.6095 G loss:-2.08\n",
      "Epoch:  0061 D loss:-0.6285 G loss:-2.091\n",
      "Epoch:  0061 D loss:-0.7901 G loss:-1.829\n",
      "Epoch:  0061 D loss:-0.7662 G loss:-1.936\n",
      "Epoch:  0061 D loss:-0.7823 G loss:-1.959\n",
      "Epoch:  0061 D loss:-0.563 G loss:-2.12\n",
      "Epoch:  0061 D loss:-0.5388 G loss:-2.282\n",
      "Epoch:  0061 D loss:-0.6237 G loss:-2.311\n",
      "Epoch:  0061 D loss:-0.7042 G loss:-2.383\n",
      "Epoch:  0061 D loss:-0.6338 G loss:-2.404\n",
      "Epoch:  0061 D loss:-0.593 G loss:-2.366\n",
      "Epoch:  0061 D loss:-0.6933 G loss:-2.3\n",
      "Epoch:  0061 D loss:-0.5601 G loss:-2.311\n",
      "Epoch:  0061 D loss:-0.7358 G loss:-1.954\n",
      "Epoch:  0061 D loss:-0.7143 G loss:-2.131\n",
      "Epoch:  0061 D loss:-0.6107 G loss:-2.05\n",
      "Epoch:  0061 D loss:-0.6968 G loss:-1.834\n",
      "Epoch:  0061 D loss:-0.4975 G loss:-2.06\n",
      "Epoch:  0061 D loss:-0.6061 G loss:-1.784\n",
      "Epoch:  0061 D loss:-0.7552 G loss:-2.008\n",
      "Epoch:  0061 D loss:-0.5599 G loss:-2.123\n",
      "Epoch:  0061 D loss:-0.5852 G loss:-2.158\n",
      "Epoch:  0061 D loss:-0.7553 G loss:-2.001\n",
      "Epoch:  0061 D loss:-0.5275 G loss:-2.266\n",
      "Epoch:  0061 D loss:-0.63 G loss:-2.353\n",
      "Epoch:  0061 D loss:-0.7415 G loss:-1.953\n",
      "Epoch:  0061 D loss:-0.7337 G loss:-2.048\n",
      "Epoch:  0061 D loss:-0.6995 G loss:-2.034\n",
      "Epoch:  0061 D loss:-0.5422 G loss:-2.18\n",
      "Epoch:  0061 D loss:-0.6176 G loss:-1.987\n",
      "Epoch:  0061 D loss:-0.54 G loss:-1.985\n",
      "Epoch:  0061 D loss:-0.6206 G loss:-2.053\n",
      "Epoch:  0061 D loss:-0.5444 G loss:-2.158\n",
      "Epoch:  0061 D loss:-0.5549 G loss:-2.206\n",
      "Epoch:  0061 D loss:-0.6526 G loss:-2.236\n",
      "Epoch:  0061 D loss:-0.7819 G loss:-1.926\n",
      "Epoch:  0061 D loss:-0.5801 G loss:-2.33\n",
      "Epoch:  0061 D loss:-0.6928 G loss:-2.428\n",
      "Epoch:  0061 D loss:-0.5864 G loss:-2.409\n",
      "Epoch:  0061 D loss:-0.894 G loss:-2.35\n",
      "Epoch:  0061 D loss:-0.5547 G loss:-2.191\n",
      "Epoch:  0061 D loss:-0.6401 G loss:-2.221\n",
      "Epoch:  0061 D loss:-0.5255 G loss:-2.387\n",
      "Epoch:  0061 D loss:-0.7162 G loss:-2.099\n",
      "Epoch:  0061 D loss:-0.5824 G loss:-2.355\n",
      "Epoch:  0061 D loss:-0.6502 G loss:-2.031\n",
      "Epoch:  0061 D loss:-0.8102 G loss:-1.837\n",
      "Epoch:  0061 D loss:-0.5425 G loss:-2.176\n",
      "Epoch:  0061 D loss:-0.4927 G loss:-2.228\n",
      "Epoch:  0061 D loss:-0.611 G loss:-1.965\n",
      "Epoch:  0061 D loss:-0.6288 G loss:-2.044\n",
      "Epoch:  0061 D loss:-0.7399 G loss:-1.997\n",
      "Epoch:  0061 D loss:-0.6645 G loss:-1.989\n",
      "Epoch:  0061 D loss:-0.5663 G loss:-2.354\n",
      "Epoch:  0061 D loss:-0.6379 G loss:-2.217\n",
      "Epoch:  0061 D loss:-0.6104 G loss:-2.268\n",
      "Epoch:  0061 D loss:-0.751 G loss:-1.977\n",
      "Epoch:  0061 D loss:-0.813 G loss:-1.988\n",
      "Epoch:  0061 D loss:-0.6718 G loss:-2.206\n",
      "Epoch:  0061 D loss:-0.6174 G loss:-2.144\n",
      "Epoch:  0061 D loss:-0.6636 G loss:-2.036\n",
      "Epoch:  0061 D loss:-0.614 G loss:-2.197\n",
      "Epoch:  0061 D loss:-0.6444 G loss:-2.182\n",
      "Epoch:  0061 D loss:-0.5387 G loss:-2.296\n",
      "Epoch:  0061 D loss:-0.4874 G loss:-2.285\n",
      "Epoch:  0061 D loss:-0.7815 G loss:-2.125\n",
      "Epoch:  0061 D loss:-0.7217 G loss:-2.183\n",
      "Epoch:  0061 D loss:-0.7428 G loss:-2.06\n",
      "Epoch:  0061 D loss:-0.5589 G loss:-2.341\n",
      "Epoch:  0061 D loss:-0.6248 G loss:-2.138\n",
      "Epoch:  0061 D loss:-0.6269 G loss:-2.18\n",
      "Epoch:  0061 D loss:-0.6371 G loss:-2.047\n",
      "Epoch:  0061 D loss:-0.6848 G loss:-1.93\n",
      "Epoch:  0061 D loss:-0.6641 G loss:-1.987\n",
      "Epoch:  0061 D loss:-0.7073 G loss:-2.082\n",
      "Epoch:  0061 D loss:-0.7471 G loss:-2.011\n",
      "Epoch:  0061 D loss:-0.6404 G loss:-1.919\n",
      "Epoch:  0061 D loss:-0.6758 G loss:-2.082\n",
      "Epoch:  0061 D loss:-0.6057 G loss:-2.174\n",
      "Epoch:  0061 D loss:-0.7196 G loss:-1.937\n",
      "Epoch:  0061 D loss:-0.6818 G loss:-1.956\n",
      "Epoch:  0061 D loss:-0.7285 G loss:-1.966\n",
      "Epoch:  0061 D loss:-0.714 G loss:-1.972\n",
      "Epoch:  0061 D loss:-0.5706 G loss:-2.327\n",
      "Epoch:  0061 D loss:-0.6059 G loss:-2.114\n",
      "Epoch:  0061 D loss:-0.5491 G loss:-2.358\n",
      "Epoch:  0061 D loss:-0.7244 G loss:-2.322\n",
      "Epoch:  0061 D loss:-0.6986 G loss:-2.213\n",
      "Epoch:  0061 D loss:-0.7013 G loss:-2.317\n",
      "Epoch:  0061 D loss:-0.6542 G loss:-2.28\n",
      "Epoch:  0061 D loss:-0.5969 G loss:-2.425\n",
      "Epoch:  0061 D loss:-0.7362 G loss:-2.19\n",
      "Epoch:  0061 D loss:-0.6435 G loss:-2.038\n",
      "Epoch:  0061 D loss:-0.6195 G loss:-2.139\n",
      "Epoch:  0061 D loss:-0.6927 G loss:-1.961\n",
      "Epoch:  0061 D loss:-0.6586 G loss:-2.061\n",
      "Epoch:  0061 D loss:-0.7399 G loss:-2.018\n",
      "Epoch:  0061 D loss:-0.8969 G loss:-1.72\n",
      "Epoch:  0061 D loss:-0.8406 G loss:-1.768\n",
      "Epoch:  0061 D loss:-0.6874 G loss:-2.055\n",
      "Epoch:  0061 D loss:-0.6235 G loss:-1.933\n",
      "Epoch:  0061 D loss:-0.729 G loss:-2.063\n",
      "Epoch:  0061 D loss:-0.5612 G loss:-2.185\n",
      "Epoch:  0061 D loss:-0.6744 G loss:-2.264\n",
      "Epoch:  0061 D loss:-0.6151 G loss:-2.052\n",
      "Epoch:  0061 D loss:-0.6636 G loss:-2.034\n",
      "Epoch:  0061 D loss:-0.6865 G loss:-2.027\n",
      "Epoch:  0061 D loss:-0.7161 G loss:-1.843\n",
      "Epoch:  0061 D loss:-0.6323 G loss:-2.209\n",
      "Epoch:  0061 D loss:-0.8314 G loss:-2.123\n",
      "Epoch:  0061 D loss:-0.6662 G loss:-2.155\n",
      "Epoch:  0061 D loss:-0.5903 G loss:-2.483\n",
      "Epoch:  0061 D loss:-0.695 G loss:-2.115\n",
      "Epoch:  0061 D loss:-0.619 G loss:-2.342\n",
      "Epoch:  0061 D loss:-0.6406 G loss:-2.098\n",
      "Epoch:  0061 D loss:-0.6565 G loss:-1.969\n",
      "Epoch:  0061 D loss:-0.6959 G loss:-2.184\n",
      "Epoch:  0061 D loss:-0.8105 G loss:-2.007\n",
      "Epoch:  0061 D loss:-0.909 G loss:-2.216\n",
      "Epoch:  0061 D loss:-0.6174 G loss:-2.049\n",
      "Epoch:  0061 D loss:-0.7145 G loss:-1.912\n",
      "Epoch:  0061 D loss:-0.7815 G loss:-1.997\n",
      "Epoch:  0061 D loss:-0.7073 G loss:-1.925\n",
      "Epoch:  0061 D loss:-0.6905 G loss:-1.844\n",
      "Epoch:  0061 D loss:-0.7241 G loss:-2.044\n",
      "Epoch:  0061 D loss:-0.645 G loss:-1.98\n",
      "Epoch:  0061 D loss:-0.5787 G loss:-2.12\n",
      "Epoch:  0061 D loss:-0.5955 G loss:-1.916\n",
      "Epoch:  0061 D loss:-0.6845 G loss:-1.989\n",
      "Epoch:  0061 D loss:-0.738 G loss:-1.944\n",
      "Epoch:  0061 D loss:-0.631 G loss:-2.134\n",
      "Epoch:  0061 D loss:-0.7083 G loss:-2.286\n",
      "Epoch:  0061 D loss:-0.6952 G loss:-2.234\n",
      "Epoch:  0061 D loss:-0.753 G loss:-1.936\n",
      "Epoch:  0061 D loss:-0.8337 G loss:-1.961\n",
      "Epoch:  0061 D loss:-0.5713 G loss:-2.119\n",
      "Epoch:  0061 D loss:-0.6579 G loss:-2.097\n",
      "Epoch:  0061 D loss:-0.6971 G loss:-2.021\n",
      "Epoch:  0061 D loss:-0.7258 G loss:-1.998\n",
      "Epoch:  0061 D loss:-0.729 G loss:-2.006\n",
      "Epoch:  0061 D loss:-0.6274 G loss:-2.081\n",
      "Epoch:  0061 D loss:-0.6222 G loss:-2.546\n",
      "Epoch:  0061 D loss:-0.7017 G loss:-2.25\n",
      "Epoch:  0061 D loss:-0.7764 G loss:-2.105\n",
      "Epoch:  0061 D loss:-0.7208 G loss:-2.124\n",
      "Epoch:  0061 D loss:-0.7591 G loss:-1.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0061 D loss:-0.6829 G loss:-1.858\n",
      "Epoch:  0061 D loss:-0.7172 G loss:-2.017\n",
      "Epoch:  0061 D loss:-0.7887 G loss:-1.809\n",
      "Epoch:  0061 D loss:-0.5234 G loss:-2.108\n",
      "Epoch:  0061 D loss:-0.7609 G loss:-1.847\n",
      "Epoch:  0061 D loss:-0.7338 G loss:-2.06\n",
      "Epoch:  0061 D loss:-0.7306 G loss:-2.347\n",
      "Epoch:  0061 D loss:-0.6316 G loss:-2.061\n",
      "Epoch:  0061 D loss:-0.5148 G loss:-2.33\n",
      "Epoch:  0061 D loss:-0.6735 G loss:-2.278\n",
      "Epoch:  0061 D loss:-0.6903 G loss:-2.108\n",
      "Epoch:  0061 D loss:-0.6069 G loss:-2.387\n",
      "Epoch:  0061 D loss:-0.6956 G loss:-2.19\n",
      "Epoch:  0061 D loss:-0.768 G loss:-1.981\n",
      "Epoch:  0061 D loss:-0.6657 G loss:-2.05\n",
      "Epoch:  0061 D loss:-0.661 G loss:-2.148\n",
      "Epoch:  0061 D loss:-0.8038 G loss:-1.873\n",
      "Epoch:  0061 D loss:-0.6335 G loss:-2.003\n",
      "Epoch:  0061 D loss:-0.5469 G loss:-2.13\n",
      "Epoch:  0061 D loss:-0.7304 G loss:-1.907\n",
      "Epoch:  0061 D loss:-0.5842 G loss:-2.153\n",
      "Epoch:  0061 D loss:-0.6065 G loss:-2.185\n",
      "Epoch:  0061 D loss:-0.6286 G loss:-2.058\n",
      "Epoch:  0061 D loss:-0.6027 G loss:-2.206\n",
      "Epoch:  0061 D loss:-0.6583 G loss:-2.215\n",
      "Epoch:  0061 D loss:-0.6342 G loss:-2.225\n",
      "Epoch:  0061 D loss:-0.6909 G loss:-2.216\n",
      "Epoch:  0061 D loss:-0.6356 G loss:-2.27\n",
      "Epoch:  0061 D loss:-0.75 G loss:-2.341\n",
      "Epoch:  0061 D loss:-0.6802 G loss:-2.084\n",
      "Epoch:  0061 D loss:-0.647 G loss:-2.03\n",
      "Epoch:  0061 D loss:-0.8038 G loss:-2.091\n",
      "Epoch:  0061 D loss:-0.7346 G loss:-2.04\n",
      "Epoch:  0061 D loss:-0.7545 G loss:-1.986\n",
      "Epoch:  0061 D loss:-0.7605 G loss:-1.922\n",
      "Epoch:  0061 D loss:-0.6859 G loss:-1.969\n",
      "Epoch:  0061 D loss:-0.6286 G loss:-1.789\n",
      "Epoch:  0061 D loss:-0.6889 G loss:-2.061\n",
      "Epoch:  0061 D loss:-0.6746 G loss:-2.236\n",
      "Epoch:  0061 D loss:-0.6363 G loss:-2.212\n",
      "Epoch:  0061 D loss:-0.6332 G loss:-2.341\n",
      "Epoch:  0061 D loss:-0.6371 G loss:-2.321\n",
      "Epoch:  0061 D loss:-0.6368 G loss:-2.379\n",
      "Epoch:  0061 D loss:-0.7593 G loss:-2.304\n",
      "Epoch:  0061 D loss:-0.6274 G loss:-1.915\n",
      "Epoch:  0061 D loss:-0.7734 G loss:-2.105\n",
      "Epoch:  0061 D loss:-0.7297 G loss:-2.164\n",
      "Epoch:  0061 D loss:-0.7856 G loss:-1.987\n",
      "Epoch:  0061 D loss:-0.6695 G loss:-2.256\n",
      "Epoch:  0061 D loss:-0.7416 G loss:-1.89\n",
      "Epoch:  0061 D loss:-0.7665 G loss:-1.794\n",
      "Epoch:  0061 D loss:-0.5606 G loss:-2.163\n",
      "Epoch:  0061 D loss:-0.6658 G loss:-1.813\n",
      "Epoch:  0061 D loss:-0.7144 G loss:-1.927\n",
      "Epoch:  0061 D loss:-0.8394 G loss:-1.93\n",
      "Epoch:  0061 D loss:-0.7016 G loss:-1.892\n",
      "Epoch:  0061 D loss:-0.738 G loss:-2.098\n",
      "Epoch:  0061 D loss:-0.7209 G loss:-2.24\n",
      "Epoch:  0061 D loss:-0.7747 G loss:-1.931\n",
      "Epoch:  0061 D loss:-0.6752 G loss:-2.258\n",
      "Epoch:  0061 D loss:-0.6913 G loss:-2.167\n",
      "Epoch:  0061 D loss:-0.7877 G loss:-1.997\n",
      "Epoch:  0061 D loss:-0.6007 G loss:-2.121\n",
      "Epoch:  0061 D loss:-0.7454 G loss:-2.01\n",
      "Epoch:  0061 D loss:-0.5944 G loss:-2.114\n",
      "Epoch:  0061 D loss:-0.7711 G loss:-2.053\n",
      "Epoch:  0061 D loss:-0.7391 G loss:-1.835\n",
      "Epoch:  0061 D loss:-0.676 G loss:-1.975\n",
      "Epoch:  0061 D loss:-0.7247 G loss:-1.96\n",
      "Epoch:  0061 D loss:-0.6229 G loss:-2.076\n",
      "Epoch:  0061 D loss:-0.6856 G loss:-2.124\n",
      "Epoch:  0061 D loss:-0.684 G loss:-1.908\n",
      "Epoch:  0061 D loss:-0.6849 G loss:-2.033\n",
      "Epoch:  0061 D loss:-0.7822 G loss:-1.949\n",
      "Epoch:  0061 D loss:-0.7446 G loss:-2.042\n",
      "Epoch:  0061 D loss:-0.8624 G loss:-1.993\n",
      "Epoch:  0061 D loss:-0.6929 G loss:-1.984\n",
      "Epoch:  0061 D loss:-0.6455 G loss:-2.113\n",
      "Epoch:  0061 D loss:-0.8094 G loss:-2.282\n",
      "Epoch:  0061 D loss:-0.616 G loss:-2.145\n",
      "Epoch:  0061 D loss:-0.7555 G loss:-2.221\n",
      "Epoch:  0061 D loss:-0.619 G loss:-2.341\n",
      "Epoch:  0061 D loss:-0.7112 G loss:-2.139\n",
      "Epoch:  0061 D loss:-0.6971 G loss:-2.273\n",
      "Epoch:  0061 D loss:-0.6068 G loss:-1.976\n",
      "Epoch:  0061 D loss:-0.7823 G loss:-1.974\n",
      "Epoch:  0061 D loss:-0.6345 G loss:-2.068\n",
      "Epoch:  0061 D loss:-0.7059 G loss:-1.874\n",
      "Epoch:  0061 D loss:-0.5867 G loss:-2.196\n",
      "Epoch:  0061 D loss:-0.7407 G loss:-2.014\n",
      "Epoch:  0061 D loss:-0.6947 G loss:-2.019\n",
      "Epoch:  0061 D loss:-0.6325 G loss:-2.121\n",
      "Epoch:  0061 D loss:-0.7762 G loss:-1.952\n",
      "Epoch:  0061 D loss:-0.7305 G loss:-1.986\n",
      "Epoch:  0061 D loss:-0.6757 G loss:-1.988\n",
      "Epoch:  0061 D loss:-0.6351 G loss:-2.174\n",
      "Epoch:  0061 D loss:-0.6275 G loss:-2.055\n",
      "Epoch:  0061 D loss:-0.7018 G loss:-1.969\n",
      "Epoch:  0061 D loss:-0.623 G loss:-2.093\n",
      "Epoch:  0061 D loss:-0.6229 G loss:-2.032\n",
      "Epoch:  0061 D loss:-0.5911 G loss:-2.051\n",
      "Epoch:  0061 D loss:-0.6499 G loss:-2.053\n",
      "Epoch:  0061 D loss:-0.7845 G loss:-1.91\n",
      "Epoch:  0061 D loss:-0.6906 G loss:-2.058\n",
      "Epoch:  0061 D loss:-0.6759 G loss:-2.248\n",
      "Epoch:  0061 D loss:-0.7438 G loss:-2.036\n",
      "Epoch:  0061 D loss:-0.6055 G loss:-2.016\n",
      "Epoch:  0061 D loss:-0.5723 G loss:-2.155\n",
      "Epoch:  0061 D loss:-0.5883 G loss:-2.196\n",
      "Epoch:  0061 D loss:-0.6182 G loss:-2.229\n",
      "Epoch:  0061 D loss:-0.8251 G loss:-1.99\n",
      "Epoch:  0061 D loss:-0.7098 G loss:-1.811\n",
      "Epoch:  0061 D loss:-0.6763 G loss:-2.062\n",
      "Epoch:  0061 D loss:-0.7265 G loss:-2.217\n",
      "Epoch:  0061 D loss:-0.7411 G loss:-2.055\n",
      "Epoch:  0061 D loss:-0.6125 G loss:-2.067\n",
      "Epoch:  0061 D loss:-0.4848 G loss:-2.307\n",
      "Epoch:  0061 D loss:-0.593 G loss:-2.282\n",
      "Epoch:  0061 D loss:-0.634 G loss:-2.337\n",
      "Epoch:  0061 D loss:-0.5732 G loss:-2.202\n",
      "Epoch:  0061 D loss:-0.604 G loss:-2.11\n",
      "Epoch:  0061 D loss:-0.6585 G loss:-1.992\n",
      "Epoch:  0061 D loss:-0.6419 G loss:-2.174\n",
      "Epoch:  0061 D loss:-0.6449 G loss:-2.079\n",
      "Epoch:  0061 D loss:-0.572 G loss:-2.054\n",
      "Epoch:  0061 D loss:-0.792 G loss:-2.074\n",
      "Epoch:  0061 D loss:-0.6939 G loss:-1.801\n",
      "Epoch:  0061 D loss:-0.5822 G loss:-1.949\n",
      "Epoch:  0061 D loss:-0.507 G loss:-2.196\n",
      "Epoch:  0061 D loss:-0.5027 G loss:-2.273\n",
      "Epoch:  0061 D loss:-0.6028 G loss:-2.316\n",
      "Epoch:  0061 D loss:-0.6479 G loss:-2.01\n",
      "Epoch:  0061 D loss:-0.7069 G loss:-2.197\n",
      "Epoch:  0061 D loss:-0.4962 G loss:-2.319\n",
      "Epoch:  0061 D loss:-0.6593 G loss:-2.229\n",
      "Epoch:  0061 D loss:-0.6276 G loss:-2.181\n",
      "Epoch:  0061 D loss:-0.8495 G loss:-2.264\n",
      "Epoch:  0061 D loss:-0.62 G loss:-2.391\n",
      "Epoch:  0061 D loss:-0.5197 G loss:-2.08\n",
      "Epoch:  0061 D loss:-0.5934 G loss:-2.12\n",
      "Epoch:  0061 D loss:-0.5824 G loss:-2.172\n",
      "Epoch:  0061 D loss:-0.5989 G loss:-2.055\n",
      "Epoch:  0061 D loss:-0.674 G loss:-2.121\n",
      "Epoch:  0061 D loss:-0.6169 G loss:-1.884\n",
      "Epoch:  0061 D loss:-0.7672 G loss:-1.827\n",
      "Epoch:  0061 D loss:-0.7955 G loss:-1.895\n",
      "Epoch:  0061 D loss:-0.5202 G loss:-2.43\n",
      "Epoch:  0061 D loss:-0.5743 G loss:-2.062\n",
      "Epoch:  0061 D loss:-0.7472 G loss:-2.098\n",
      "Epoch:  0061 D loss:-0.7121 G loss:-2.075\n",
      "Epoch:  0061 D loss:-0.737 G loss:-2.089\n",
      "Epoch:  0061 D loss:-0.7919 G loss:-1.912\n",
      "Epoch:  0061 D loss:-0.7067 G loss:-2.16\n",
      "Epoch:  0061 D loss:-0.6891 G loss:-2.389\n",
      "Epoch:  0061 D loss:-0.6024 G loss:-2.219\n",
      "Epoch:  0061 D loss:-0.7081 G loss:-2.347\n",
      "Epoch:  0061 D loss:-0.5193 G loss:-2.089\n",
      "Epoch:  0061 D loss:-0.6832 G loss:-2.086\n",
      "Epoch:  0061 D loss:-0.7225 G loss:-2.034\n",
      "Epoch:  0061 D loss:-0.6157 G loss:-2.141\n",
      "Epoch:  0061 D loss:-0.793 G loss:-1.894\n",
      "Epoch:  0061 D loss:-0.7292 G loss:-1.838\n",
      "Epoch:  0061 D loss:-0.681 G loss:-1.956\n",
      "Epoch:  0061 D loss:-0.6461 G loss:-1.966\n",
      "Epoch:  0061 D loss:-0.6242 G loss:-1.954\n",
      "Epoch:  0061 D loss:-0.7107 G loss:-2.101\n",
      "Epoch:  0061 D loss:-0.5966 G loss:-2.067\n",
      "Epoch:  0062 D loss:-0.6153 G loss:-2.158\n",
      "Epoch:  0062 D loss:-0.7791 G loss:-2.047\n",
      "Epoch:  0062 D loss:-0.5686 G loss:-2.32\n",
      "Epoch:  0062 D loss:-0.53 G loss:-2.215\n",
      "Epoch:  0062 D loss:-0.639 G loss:-2.201\n",
      "Epoch:  0062 D loss:-0.6946 G loss:-2.22\n",
      "Epoch:  0062 D loss:-0.5876 G loss:-1.934\n",
      "Epoch:  0062 D loss:-0.7059 G loss:-2.208\n",
      "Epoch:  0062 D loss:-0.6655 G loss:-2.056\n",
      "Epoch:  0062 D loss:-0.5847 G loss:-2.286\n",
      "Epoch:  0062 D loss:-0.664 G loss:-2.065\n",
      "Epoch:  0062 D loss:-0.8368 G loss:-2.099\n",
      "Epoch:  0062 D loss:-0.6841 G loss:-1.947\n",
      "Epoch:  0062 D loss:-0.6147 G loss:-2.22\n",
      "Epoch:  0062 D loss:-0.7351 G loss:-1.9\n",
      "Epoch:  0062 D loss:-0.6612 G loss:-1.816\n",
      "Epoch:  0062 D loss:-0.6566 G loss:-2.021\n",
      "Epoch:  0062 D loss:-0.7129 G loss:-1.915\n",
      "Epoch:  0062 D loss:-0.7555 G loss:-2.065\n",
      "Epoch:  0062 D loss:-0.5837 G loss:-2.177\n",
      "Epoch:  0062 D loss:-0.6087 G loss:-2.102\n",
      "Epoch:  0062 D loss:-0.603 G loss:-2.44\n",
      "Epoch:  0062 D loss:-0.6173 G loss:-2.468\n",
      "Epoch:  0062 D loss:-0.6956 G loss:-2.331\n",
      "Epoch:  0062 D loss:-0.6619 G loss:-2.398\n",
      "Epoch:  0062 D loss:-0.6966 G loss:-2.385\n",
      "Epoch:  0062 D loss:-0.6879 G loss:-2.055\n",
      "Epoch:  0062 D loss:-0.6459 G loss:-2.148\n",
      "Epoch:  0062 D loss:-0.6242 G loss:-2.142\n",
      "Epoch:  0062 D loss:-0.6615 G loss:-2.144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0062 D loss:-0.7204 G loss:-2.036\n",
      "Epoch:  0062 D loss:-0.6473 G loss:-1.891\n",
      "Epoch:  0062 D loss:-0.6232 G loss:-1.927\n",
      "Epoch:  0062 D loss:-0.6135 G loss:-1.993\n",
      "Epoch:  0062 D loss:-0.7146 G loss:-1.833\n",
      "Epoch:  0062 D loss:-0.6072 G loss:-1.901\n",
      "Epoch:  0062 D loss:-0.7061 G loss:-1.853\n",
      "Epoch:  0062 D loss:-0.7161 G loss:-1.794\n",
      "Epoch:  0062 D loss:-0.7019 G loss:-2.034\n",
      "Epoch:  0062 D loss:-0.7229 G loss:-2.14\n",
      "Epoch:  0062 D loss:-0.5853 G loss:-2.174\n",
      "Epoch:  0062 D loss:-0.6553 G loss:-2.265\n",
      "Epoch:  0062 D loss:-0.6696 G loss:-2.063\n",
      "Epoch:  0062 D loss:-0.5794 G loss:-2.308\n",
      "Epoch:  0062 D loss:-0.6233 G loss:-2.68\n",
      "Epoch:  0062 D loss:-0.6503 G loss:-2.295\n",
      "Epoch:  0062 D loss:-0.701 G loss:-1.943\n",
      "Epoch:  0062 D loss:-0.5893 G loss:-2.282\n",
      "Epoch:  0062 D loss:-0.5905 G loss:-2.223\n",
      "Epoch:  0062 D loss:-0.6516 G loss:-2.083\n",
      "Epoch:  0062 D loss:-0.5454 G loss:-2.186\n",
      "Epoch:  0062 D loss:-0.6298 G loss:-2.035\n",
      "Epoch:  0062 D loss:-0.5954 G loss:-2.08\n",
      "Epoch:  0062 D loss:-0.6555 G loss:-2.047\n",
      "Epoch:  0062 D loss:-0.6638 G loss:-2.012\n",
      "Epoch:  0062 D loss:-0.5914 G loss:-1.989\n",
      "Epoch:  0062 D loss:-0.5849 G loss:-2.12\n",
      "Epoch:  0062 D loss:-0.6401 G loss:-2.226\n",
      "Epoch:  0062 D loss:-0.6692 G loss:-2.105\n",
      "Epoch:  0062 D loss:-0.5961 G loss:-2.031\n",
      "Epoch:  0062 D loss:-0.7082 G loss:-1.998\n",
      "Epoch:  0062 D loss:-0.6334 G loss:-2.198\n",
      "Epoch:  0062 D loss:-0.7665 G loss:-2.099\n",
      "Epoch:  0062 D loss:-0.5757 G loss:-2.181\n",
      "Epoch:  0062 D loss:-0.6825 G loss:-1.983\n",
      "Epoch:  0062 D loss:-0.7214 G loss:-2.078\n",
      "Epoch:  0062 D loss:-0.5712 G loss:-2.208\n",
      "Epoch:  0062 D loss:-0.6153 G loss:-2.265\n",
      "Epoch:  0062 D loss:-0.5996 G loss:-2.113\n",
      "Epoch:  0062 D loss:-0.7259 G loss:-2.208\n",
      "Epoch:  0062 D loss:-0.8155 G loss:-2.032\n",
      "Epoch:  0062 D loss:-0.7609 G loss:-2.007\n",
      "Epoch:  0062 D loss:-0.615 G loss:-2.227\n",
      "Epoch:  0062 D loss:-0.6867 G loss:-2.18\n",
      "Epoch:  0062 D loss:-0.8639 G loss:-2.031\n",
      "Epoch:  0062 D loss:-0.7652 G loss:-1.832\n",
      "Epoch:  0062 D loss:-0.634 G loss:-2.039\n",
      "Epoch:  0062 D loss:-0.6864 G loss:-1.883\n",
      "Epoch:  0062 D loss:-0.736 G loss:-1.979\n",
      "Epoch:  0062 D loss:-0.6242 G loss:-2.114\n",
      "Epoch:  0062 D loss:-0.7083 G loss:-1.99\n",
      "Epoch:  0062 D loss:-0.6271 G loss:-2.017\n",
      "Epoch:  0062 D loss:-0.685 G loss:-2.058\n",
      "Epoch:  0062 D loss:-0.6888 G loss:-2.146\n",
      "Epoch:  0062 D loss:-0.6876 G loss:-2.137\n",
      "Epoch:  0062 D loss:-0.6419 G loss:-2.043\n",
      "Epoch:  0062 D loss:-0.6627 G loss:-2.148\n",
      "Epoch:  0062 D loss:-0.7578 G loss:-1.985\n",
      "Epoch:  0062 D loss:-0.666 G loss:-2.154\n",
      "Epoch:  0062 D loss:-0.6181 G loss:-2.154\n",
      "Epoch:  0062 D loss:-0.7424 G loss:-1.922\n",
      "Epoch:  0062 D loss:-0.5569 G loss:-2.047\n",
      "Epoch:  0062 D loss:-0.7022 G loss:-2.1\n",
      "Epoch:  0062 D loss:-0.5681 G loss:-2.044\n",
      "Epoch:  0062 D loss:-0.6033 G loss:-2.088\n",
      "Epoch:  0062 D loss:-0.6773 G loss:-2.071\n",
      "Epoch:  0062 D loss:-0.5834 G loss:-2.201\n",
      "Epoch:  0062 D loss:-0.7144 G loss:-2.074\n",
      "Epoch:  0062 D loss:-0.7558 G loss:-1.99\n",
      "Epoch:  0062 D loss:-0.6373 G loss:-2.058\n",
      "Epoch:  0062 D loss:-0.6187 G loss:-1.94\n",
      "Epoch:  0062 D loss:-0.6667 G loss:-2.122\n",
      "Epoch:  0062 D loss:-0.4752 G loss:-2.144\n",
      "Epoch:  0062 D loss:-0.5934 G loss:-2.103\n",
      "Epoch:  0062 D loss:-0.7179 G loss:-1.983\n",
      "Epoch:  0062 D loss:-0.7273 G loss:-2.267\n",
      "Epoch:  0062 D loss:-0.6165 G loss:-2.212\n",
      "Epoch:  0062 D loss:-0.7309 G loss:-2.208\n",
      "Epoch:  0062 D loss:-0.7082 G loss:-2.233\n",
      "Epoch:  0062 D loss:-0.5446 G loss:-2.364\n",
      "Epoch:  0062 D loss:-0.6078 G loss:-2.193\n",
      "Epoch:  0062 D loss:-0.538 G loss:-2.01\n",
      "Epoch:  0062 D loss:-0.6412 G loss:-2.202\n",
      "Epoch:  0062 D loss:-0.7409 G loss:-2.006\n",
      "Epoch:  0062 D loss:-0.6289 G loss:-2.311\n",
      "Epoch:  0062 D loss:-0.6831 G loss:-2.218\n",
      "Epoch:  0062 D loss:-0.7053 G loss:-1.974\n",
      "Epoch:  0062 D loss:-0.6148 G loss:-2.024\n",
      "Epoch:  0062 D loss:-0.4855 G loss:-2.075\n",
      "Epoch:  0062 D loss:-0.7314 G loss:-2.094\n",
      "Epoch:  0062 D loss:-0.7198 G loss:-2.006\n",
      "Epoch:  0062 D loss:-0.4944 G loss:-2.189\n",
      "Epoch:  0062 D loss:-0.6102 G loss:-2.124\n",
      "Epoch:  0062 D loss:-0.6935 G loss:-2.287\n",
      "Epoch:  0062 D loss:-0.633 G loss:-2.361\n",
      "Epoch:  0062 D loss:-0.6851 G loss:-2.185\n",
      "Epoch:  0062 D loss:-0.568 G loss:-2.367\n",
      "Epoch:  0062 D loss:-0.7607 G loss:-2.144\n",
      "Epoch:  0062 D loss:-0.7145 G loss:-2.069\n",
      "Epoch:  0062 D loss:-0.692 G loss:-2.187\n",
      "Epoch:  0062 D loss:-0.7972 G loss:-1.917\n",
      "Epoch:  0062 D loss:-0.739 G loss:-1.943\n",
      "Epoch:  0062 D loss:-0.6391 G loss:-2.102\n",
      "Epoch:  0062 D loss:-0.5985 G loss:-2.188\n",
      "Epoch:  0062 D loss:-0.6443 G loss:-2.096\n",
      "Epoch:  0062 D loss:-0.7046 G loss:-1.9\n",
      "Epoch:  0062 D loss:-0.7806 G loss:-1.924\n",
      "Epoch:  0062 D loss:-0.5712 G loss:-2.153\n",
      "Epoch:  0062 D loss:-0.7024 G loss:-1.928\n",
      "Epoch:  0062 D loss:-0.617 G loss:-2.352\n",
      "Epoch:  0062 D loss:-0.6475 G loss:-2.178\n",
      "Epoch:  0062 D loss:-0.7305 G loss:-1.962\n",
      "Epoch:  0062 D loss:-0.7357 G loss:-1.961\n",
      "Epoch:  0062 D loss:-0.6979 G loss:-2.027\n",
      "Epoch:  0062 D loss:-0.5569 G loss:-2.32\n",
      "Epoch:  0062 D loss:-0.7645 G loss:-2.03\n",
      "Epoch:  0062 D loss:-0.7026 G loss:-2.055\n",
      "Epoch:  0062 D loss:-0.7646 G loss:-1.966\n",
      "Epoch:  0062 D loss:-0.7933 G loss:-1.878\n",
      "Epoch:  0062 D loss:-0.662 G loss:-2.179\n",
      "Epoch:  0062 D loss:-0.561 G loss:-2.103\n",
      "Epoch:  0062 D loss:-0.6535 G loss:-1.986\n",
      "Epoch:  0062 D loss:-0.5467 G loss:-2.335\n",
      "Epoch:  0062 D loss:-0.7506 G loss:-2.218\n",
      "Epoch:  0062 D loss:-0.662 G loss:-2.209\n",
      "Epoch:  0062 D loss:-0.6248 G loss:-2.125\n",
      "Epoch:  0062 D loss:-0.6331 G loss:-2.202\n",
      "Epoch:  0062 D loss:-0.7557 G loss:-1.956\n",
      "Epoch:  0062 D loss:-0.7583 G loss:-1.854\n",
      "Epoch:  0062 D loss:-0.5567 G loss:-2.188\n",
      "Epoch:  0062 D loss:-0.6393 G loss:-2.061\n",
      "Epoch:  0062 D loss:-0.636 G loss:-2.274\n",
      "Epoch:  0062 D loss:-0.6731 G loss:-2.198\n",
      "Epoch:  0062 D loss:-0.6233 G loss:-2.199\n",
      "Epoch:  0062 D loss:-0.5941 G loss:-2.168\n",
      "Epoch:  0062 D loss:-0.689 G loss:-2.266\n",
      "Epoch:  0062 D loss:-0.7006 G loss:-2.134\n",
      "Epoch:  0062 D loss:-0.5612 G loss:-2.27\n",
      "Epoch:  0062 D loss:-0.6843 G loss:-2.344\n",
      "Epoch:  0062 D loss:-0.6398 G loss:-2.167\n",
      "Epoch:  0062 D loss:-0.6843 G loss:-2.036\n",
      "Epoch:  0062 D loss:-0.6639 G loss:-2.081\n",
      "Epoch:  0062 D loss:-0.5699 G loss:-2.121\n",
      "Epoch:  0062 D loss:-0.6505 G loss:-2.041\n",
      "Epoch:  0062 D loss:-0.5457 G loss:-2.0\n",
      "Epoch:  0062 D loss:-0.6641 G loss:-2.039\n",
      "Epoch:  0062 D loss:-0.6001 G loss:-2.126\n",
      "Epoch:  0062 D loss:-0.5809 G loss:-2.165\n",
      "Epoch:  0062 D loss:-0.6173 G loss:-2.135\n",
      "Epoch:  0062 D loss:-0.532 G loss:-2.379\n",
      "Epoch:  0062 D loss:-0.6067 G loss:-2.249\n",
      "Epoch:  0062 D loss:-0.6655 G loss:-2.289\n",
      "Epoch:  0062 D loss:-0.5291 G loss:-2.397\n",
      "Epoch:  0062 D loss:-0.5849 G loss:-2.284\n",
      "Epoch:  0062 D loss:-0.613 G loss:-2.212\n",
      "Epoch:  0062 D loss:-0.6433 G loss:-2.216\n",
      "Epoch:  0062 D loss:-0.6567 G loss:-2.132\n",
      "Epoch:  0062 D loss:-0.6111 G loss:-2.354\n",
      "Epoch:  0062 D loss:-0.4501 G loss:-2.311\n",
      "Epoch:  0062 D loss:-0.6233 G loss:-2.307\n",
      "Epoch:  0062 D loss:-0.5592 G loss:-2.177\n",
      "Epoch:  0062 D loss:-0.5905 G loss:-2.127\n",
      "Epoch:  0062 D loss:-0.5511 G loss:-2.103\n",
      "Epoch:  0062 D loss:-0.6206 G loss:-2.079\n",
      "Epoch:  0062 D loss:-0.613 G loss:-2.118\n",
      "Epoch:  0062 D loss:-0.4869 G loss:-2.283\n",
      "Epoch:  0062 D loss:-0.5426 G loss:-2.292\n",
      "Epoch:  0062 D loss:-0.5302 G loss:-2.373\n",
      "Epoch:  0062 D loss:-0.5976 G loss:-2.276\n",
      "Epoch:  0062 D loss:-0.6106 G loss:-2.246\n",
      "Epoch:  0062 D loss:-0.4718 G loss:-2.405\n",
      "Epoch:  0062 D loss:-0.7328 G loss:-2.086\n",
      "Epoch:  0062 D loss:-0.656 G loss:-2.097\n",
      "Epoch:  0062 D loss:-0.5329 G loss:-2.103\n",
      "Epoch:  0062 D loss:-0.701 G loss:-1.902\n",
      "Epoch:  0062 D loss:-0.6515 G loss:-2.114\n",
      "Epoch:  0062 D loss:-0.6607 G loss:-2.031\n",
      "Epoch:  0062 D loss:-0.4026 G loss:-2.34\n",
      "Epoch:  0062 D loss:-0.6432 G loss:-2.21\n",
      "Epoch:  0062 D loss:-0.6033 G loss:-2.266\n",
      "Epoch:  0062 D loss:-0.6361 G loss:-2.366\n",
      "Epoch:  0062 D loss:-0.5065 G loss:-2.304\n",
      "Epoch:  0062 D loss:-0.6552 G loss:-2.289\n",
      "Epoch:  0062 D loss:-0.627 G loss:-2.187\n",
      "Epoch:  0062 D loss:-0.7185 G loss:-2.017\n",
      "Epoch:  0062 D loss:-0.7039 G loss:-2.078\n",
      "Epoch:  0062 D loss:-0.5415 G loss:-2.132\n",
      "Epoch:  0062 D loss:-0.5515 G loss:-2.106\n",
      "Epoch:  0062 D loss:-0.7911 G loss:-2.082\n",
      "Epoch:  0062 D loss:-0.7508 G loss:-2.159\n",
      "Epoch:  0062 D loss:-0.4305 G loss:-2.292\n",
      "Epoch:  0062 D loss:-0.575 G loss:-2.135\n",
      "Epoch:  0062 D loss:-0.6502 G loss:-2.12\n",
      "Epoch:  0062 D loss:-0.6302 G loss:-2.085\n",
      "Epoch:  0062 D loss:-0.6679 G loss:-2.148\n",
      "Epoch:  0062 D loss:-0.7506 G loss:-1.98\n",
      "Epoch:  0062 D loss:-0.6291 G loss:-2.014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0062 D loss:-0.6871 G loss:-1.996\n",
      "Epoch:  0062 D loss:-0.5711 G loss:-2.054\n",
      "Epoch:  0062 D loss:-0.5434 G loss:-2.171\n",
      "Epoch:  0062 D loss:-0.8042 G loss:-2.179\n",
      "Epoch:  0062 D loss:-0.58 G loss:-2.267\n",
      "Epoch:  0062 D loss:-0.6655 G loss:-2.183\n",
      "Epoch:  0062 D loss:-0.6112 G loss:-2.276\n",
      "Epoch:  0062 D loss:-0.7703 G loss:-2.266\n",
      "Epoch:  0062 D loss:-0.7449 G loss:-2.158\n",
      "Epoch:  0062 D loss:-0.6291 G loss:-2.028\n",
      "Epoch:  0062 D loss:-0.5876 G loss:-2.146\n",
      "Epoch:  0062 D loss:-0.7087 G loss:-2.155\n",
      "Epoch:  0062 D loss:-0.734 G loss:-2.088\n",
      "Epoch:  0062 D loss:-0.7239 G loss:-1.847\n",
      "Epoch:  0062 D loss:-0.7096 G loss:-1.835\n",
      "Epoch:  0062 D loss:-0.6543 G loss:-2.224\n",
      "Epoch:  0062 D loss:-0.597 G loss:-2.348\n",
      "Epoch:  0062 D loss:-0.6973 G loss:-2.092\n",
      "Epoch:  0062 D loss:-0.5153 G loss:-2.056\n",
      "Epoch:  0062 D loss:-0.615 G loss:-2.108\n",
      "Epoch:  0062 D loss:-0.7632 G loss:-1.895\n",
      "Epoch:  0062 D loss:-0.6582 G loss:-2.101\n",
      "Epoch:  0062 D loss:-0.6622 G loss:-2.086\n",
      "Epoch:  0062 D loss:-0.9143 G loss:-1.932\n",
      "Epoch:  0062 D loss:-0.7212 G loss:-1.989\n",
      "Epoch:  0062 D loss:-0.7012 G loss:-2.209\n",
      "Epoch:  0062 D loss:-0.7953 G loss:-1.83\n",
      "Epoch:  0062 D loss:-0.8019 G loss:-1.908\n",
      "Epoch:  0062 D loss:-0.6594 G loss:-1.988\n",
      "Epoch:  0062 D loss:-0.7368 G loss:-2.178\n",
      "Epoch:  0062 D loss:-0.7169 G loss:-1.913\n",
      "Epoch:  0062 D loss:-0.7167 G loss:-1.875\n",
      "Epoch:  0062 D loss:-0.628 G loss:-2.179\n",
      "Epoch:  0062 D loss:-0.6978 G loss:-2.282\n",
      "Epoch:  0062 D loss:-0.6872 G loss:-1.748\n",
      "Epoch:  0062 D loss:-0.7628 G loss:-2.217\n",
      "Epoch:  0062 D loss:-0.6174 G loss:-2.172\n",
      "Epoch:  0062 D loss:-0.7173 G loss:-1.977\n",
      "Epoch:  0062 D loss:-0.7515 G loss:-1.811\n",
      "Epoch:  0062 D loss:-0.7196 G loss:-2.16\n",
      "Epoch:  0062 D loss:-0.6299 G loss:-2.113\n",
      "Epoch:  0062 D loss:-0.7157 G loss:-2.067\n",
      "Epoch:  0062 D loss:-0.6956 G loss:-2.03\n",
      "Epoch:  0062 D loss:-0.6668 G loss:-2.223\n",
      "Epoch:  0062 D loss:-0.7042 G loss:-2.12\n",
      "Epoch:  0062 D loss:-0.7014 G loss:-2.069\n",
      "Epoch:  0062 D loss:-0.7245 G loss:-2.014\n",
      "Epoch:  0062 D loss:-0.6783 G loss:-1.993\n",
      "Epoch:  0062 D loss:-0.7763 G loss:-1.893\n",
      "Epoch:  0062 D loss:-0.5642 G loss:-2.008\n",
      "Epoch:  0062 D loss:-0.606 G loss:-2.059\n",
      "Epoch:  0062 D loss:-0.5016 G loss:-2.05\n",
      "Epoch:  0062 D loss:-0.639 G loss:-1.908\n",
      "Epoch:  0062 D loss:-0.6062 G loss:-1.994\n",
      "Epoch:  0062 D loss:-0.7188 G loss:-2.007\n",
      "Epoch:  0062 D loss:-0.7399 G loss:-1.883\n",
      "Epoch:  0062 D loss:-0.7086 G loss:-1.901\n",
      "Epoch:  0062 D loss:-0.6154 G loss:-2.252\n",
      "Epoch:  0062 D loss:-0.6895 G loss:-2.531\n",
      "Epoch:  0062 D loss:-0.71 G loss:-2.259\n",
      "Epoch:  0062 D loss:-0.7462 G loss:-2.347\n",
      "Epoch:  0062 D loss:-0.8054 G loss:-2.368\n",
      "Epoch:  0062 D loss:-0.9147 G loss:-2.037\n",
      "Epoch:  0062 D loss:-0.6127 G loss:-2.11\n",
      "Epoch:  0062 D loss:-0.6739 G loss:-2.139\n",
      "Epoch:  0062 D loss:-0.7174 G loss:-2.06\n",
      "Epoch:  0062 D loss:-0.7295 G loss:-2.078\n",
      "Epoch:  0062 D loss:-0.7205 G loss:-1.959\n",
      "Epoch:  0062 D loss:-0.6386 G loss:-2.021\n",
      "Epoch:  0062 D loss:-0.5373 G loss:-2.098\n",
      "Epoch:  0062 D loss:-0.7667 G loss:-1.872\n",
      "Epoch:  0062 D loss:-0.6439 G loss:-2.254\n",
      "Epoch:  0062 D loss:-0.6838 G loss:-2.206\n",
      "Epoch:  0062 D loss:-0.638 G loss:-2.066\n",
      "Epoch:  0062 D loss:-0.5497 G loss:-2.263\n",
      "Epoch:  0062 D loss:-0.7151 G loss:-2.069\n",
      "Epoch:  0062 D loss:-0.678 G loss:-1.954\n",
      "Epoch:  0062 D loss:-0.5908 G loss:-1.951\n",
      "Epoch:  0062 D loss:-0.5966 G loss:-2.066\n",
      "Epoch:  0062 D loss:-0.7828 G loss:-1.828\n",
      "Epoch:  0062 D loss:-0.7013 G loss:-2.122\n",
      "Epoch:  0062 D loss:-0.5385 G loss:-2.145\n",
      "Epoch:  0062 D loss:-0.5973 G loss:-2.183\n",
      "Epoch:  0062 D loss:-0.6882 G loss:-2.049\n",
      "Epoch:  0062 D loss:-0.5993 G loss:-2.107\n",
      "Epoch:  0062 D loss:-0.6408 G loss:-2.065\n",
      "Epoch:  0062 D loss:-0.6099 G loss:-2.175\n",
      "Epoch:  0062 D loss:-0.6764 G loss:-2.082\n",
      "Epoch:  0062 D loss:-0.814 G loss:-2.181\n",
      "Epoch:  0062 D loss:-0.6628 G loss:-2.16\n",
      "Epoch:  0062 D loss:-0.6793 G loss:-2.261\n",
      "Epoch:  0062 D loss:-0.5275 G loss:-2.309\n",
      "Epoch:  0062 D loss:-0.7223 G loss:-1.847\n",
      "Epoch:  0062 D loss:-0.5372 G loss:-2.17\n",
      "Epoch:  0062 D loss:-0.6719 G loss:-2.085\n",
      "Epoch:  0062 D loss:-0.615 G loss:-2.114\n",
      "Epoch:  0062 D loss:-0.5542 G loss:-2.317\n",
      "Epoch:  0062 D loss:-0.673 G loss:-2.073\n",
      "Epoch:  0062 D loss:-0.5349 G loss:-2.113\n",
      "Epoch:  0062 D loss:-0.6357 G loss:-2.056\n",
      "Epoch:  0062 D loss:-0.6829 G loss:-2.112\n",
      "Epoch:  0062 D loss:-0.5721 G loss:-2.352\n",
      "Epoch:  0062 D loss:-0.593 G loss:-2.219\n",
      "Epoch:  0062 D loss:-0.5302 G loss:-2.4\n",
      "Epoch:  0062 D loss:-0.5193 G loss:-2.753\n",
      "Epoch:  0062 D loss:-0.6353 G loss:-2.473\n",
      "Epoch:  0062 D loss:-0.4208 G loss:-2.475\n",
      "Epoch:  0062 D loss:-0.5884 G loss:-2.424\n",
      "Epoch:  0062 D loss:-0.6366 G loss:-2.047\n",
      "Epoch:  0062 D loss:-0.5896 G loss:-2.233\n",
      "Epoch:  0062 D loss:-0.6834 G loss:-2.049\n",
      "Epoch:  0062 D loss:-0.612 G loss:-2.211\n",
      "Epoch:  0062 D loss:-0.6853 G loss:-2.086\n",
      "Epoch:  0062 D loss:-0.7259 G loss:-2.199\n",
      "Epoch:  0062 D loss:-0.5246 G loss:-2.097\n",
      "Epoch:  0062 D loss:-0.576 G loss:-2.11\n",
      "Epoch:  0062 D loss:-0.6635 G loss:-1.835\n",
      "Epoch:  0062 D loss:-0.7182 G loss:-1.769\n",
      "Epoch:  0062 D loss:-0.6683 G loss:-2.073\n",
      "Epoch:  0062 D loss:-0.5357 G loss:-2.3\n",
      "Epoch:  0062 D loss:-0.6136 G loss:-2.197\n",
      "Epoch:  0062 D loss:-0.6284 G loss:-2.382\n",
      "Epoch:  0062 D loss:-0.6057 G loss:-2.495\n",
      "Epoch:  0062 D loss:-0.7323 G loss:-2.135\n",
      "Epoch:  0062 D loss:-0.5173 G loss:-2.307\n",
      "Epoch:  0062 D loss:-0.6056 G loss:-2.178\n",
      "Epoch:  0062 D loss:-0.4899 G loss:-2.341\n",
      "Epoch:  0062 D loss:-0.7088 G loss:-1.914\n",
      "Epoch:  0062 D loss:-0.6663 G loss:-1.918\n",
      "Epoch:  0062 D loss:-0.6682 G loss:-1.934\n",
      "Epoch:  0062 D loss:-0.6221 G loss:-2.111\n",
      "Epoch:  0062 D loss:-0.6636 G loss:-1.941\n",
      "Epoch:  0062 D loss:-0.586 G loss:-2.391\n",
      "Epoch:  0062 D loss:-0.6484 G loss:-2.246\n",
      "Epoch:  0062 D loss:-0.7311 G loss:-2.091\n",
      "Epoch:  0062 D loss:-0.6612 G loss:-2.245\n",
      "Epoch:  0062 D loss:-0.5923 G loss:-2.324\n",
      "Epoch:  0062 D loss:-0.7605 G loss:-2.11\n",
      "Epoch:  0062 D loss:-0.7581 G loss:-2.044\n",
      "Epoch:  0062 D loss:-0.6532 G loss:-2.23\n",
      "Epoch:  0062 D loss:-0.6281 G loss:-2.122\n",
      "Epoch:  0062 D loss:-0.6942 G loss:-1.854\n",
      "Epoch:  0062 D loss:-0.6549 G loss:-2.162\n",
      "Epoch:  0062 D loss:-0.7364 G loss:-2.049\n",
      "Epoch:  0062 D loss:-0.6 G loss:-2.065\n",
      "Epoch:  0062 D loss:-0.4947 G loss:-2.317\n",
      "Epoch:  0062 D loss:-0.6563 G loss:-2.341\n",
      "Epoch:  0062 D loss:-0.6091 G loss:-2.176\n",
      "Epoch:  0062 D loss:-0.6952 G loss:-1.991\n",
      "Epoch:  0062 D loss:-0.7281 G loss:-2.096\n",
      "Epoch:  0062 D loss:-0.577 G loss:-2.175\n",
      "Epoch:  0062 D loss:-0.629 G loss:-2.202\n",
      "Epoch:  0062 D loss:-0.7134 G loss:-2.181\n",
      "Epoch:  0062 D loss:-0.6339 G loss:-2.283\n",
      "Epoch:  0062 D loss:-0.6143 G loss:-2.382\n",
      "Epoch:  0062 D loss:-0.6293 G loss:-2.177\n",
      "Epoch:  0062 D loss:-0.6685 G loss:-2.117\n",
      "Epoch:  0062 D loss:-0.6566 G loss:-2.069\n",
      "Epoch:  0062 D loss:-0.5808 G loss:-2.123\n",
      "Epoch:  0062 D loss:-0.6583 G loss:-2.123\n",
      "Epoch:  0062 D loss:-0.7469 G loss:-2.208\n",
      "Epoch:  0062 D loss:-0.7473 G loss:-2.083\n",
      "Epoch:  0062 D loss:-0.6721 G loss:-1.859\n",
      "Epoch:  0062 D loss:-0.7859 G loss:-1.912\n",
      "Epoch:  0062 D loss:-0.7255 G loss:-1.945\n",
      "Epoch:  0062 D loss:-0.5361 G loss:-2.049\n",
      "Epoch:  0062 D loss:-0.6895 G loss:-2.128\n",
      "Epoch:  0062 D loss:-0.7503 G loss:-2.037\n",
      "Epoch:  0062 D loss:-0.7786 G loss:-2.006\n",
      "Epoch:  0062 D loss:-0.5768 G loss:-2.092\n",
      "Epoch:  0062 D loss:-0.6332 G loss:-2.024\n",
      "Epoch:  0062 D loss:-0.6907 G loss:-2.169\n",
      "Epoch:  0062 D loss:-0.6881 G loss:-2.353\n",
      "Epoch:  0062 D loss:-0.5601 G loss:-2.188\n",
      "Epoch:  0062 D loss:-0.5914 G loss:-2.449\n",
      "Epoch:  0062 D loss:-0.7468 G loss:-2.431\n",
      "Epoch:  0062 D loss:-0.7002 G loss:-2.294\n",
      "Epoch:  0062 D loss:-0.7449 G loss:-2.247\n",
      "Epoch:  0062 D loss:-0.6495 G loss:-2.122\n",
      "Epoch:  0062 D loss:-0.6375 G loss:-2.318\n",
      "Epoch:  0062 D loss:-0.7444 G loss:-1.914\n",
      "Epoch:  0062 D loss:-0.756 G loss:-1.924\n",
      "Epoch:  0062 D loss:-0.6891 G loss:-1.851\n",
      "Epoch:  0062 D loss:-0.702 G loss:-1.944\n",
      "Epoch:  0062 D loss:-0.5625 G loss:-2.02\n",
      "Epoch:  0062 D loss:-0.6968 G loss:-1.936\n",
      "Epoch:  0062 D loss:-0.584 G loss:-1.967\n",
      "Epoch:  0062 D loss:-0.7756 G loss:-1.804\n",
      "Epoch:  0062 D loss:-0.5897 G loss:-2.062\n",
      "Epoch:  0062 D loss:-0.7598 G loss:-2.074\n",
      "Epoch:  0062 D loss:-0.7098 G loss:-2.064\n",
      "Epoch:  0062 D loss:-0.6864 G loss:-2.291\n",
      "Epoch:  0062 D loss:-0.7164 G loss:-2.087\n",
      "Epoch:  0062 D loss:-0.7386 G loss:-2.218\n",
      "Epoch:  0062 D loss:-0.7321 G loss:-2.258\n",
      "Epoch:  0062 D loss:-0.6185 G loss:-2.238\n",
      "Epoch:  0062 D loss:-0.7909 G loss:-2.108\n",
      "Epoch:  0062 D loss:-0.6531 G loss:-2.287\n",
      "Epoch:  0062 D loss:-0.7424 G loss:-1.996\n",
      "Epoch:  0062 D loss:-0.6813 G loss:-1.861\n",
      "Epoch:  0062 D loss:-0.6173 G loss:-2.054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0062 D loss:-0.6208 G loss:-2.205\n",
      "Epoch:  0062 D loss:-0.7764 G loss:-1.96\n",
      "Epoch:  0062 D loss:-0.5521 G loss:-2.225\n",
      "Epoch:  0062 D loss:-0.6574 G loss:-2.015\n",
      "Epoch:  0062 D loss:-0.7075 G loss:-2.151\n",
      "Epoch:  0062 D loss:-0.5912 G loss:-2.163\n",
      "Epoch:  0062 D loss:-0.7405 G loss:-1.737\n",
      "Epoch:  0062 D loss:-0.6286 G loss:-2.063\n",
      "Epoch:  0062 D loss:-0.5959 G loss:-1.985\n",
      "Epoch:  0062 D loss:-0.7653 G loss:-2.123\n",
      "Epoch:  0062 D loss:-0.7984 G loss:-1.997\n",
      "Epoch:  0062 D loss:-0.587 G loss:-2.097\n",
      "Epoch:  0062 D loss:-0.8708 G loss:-1.834\n",
      "Epoch:  0062 D loss:-0.8541 G loss:-1.828\n",
      "Epoch:  0062 D loss:-0.7384 G loss:-2.247\n",
      "Epoch:  0062 D loss:-0.8722 G loss:-2.009\n",
      "Epoch:  0062 D loss:-0.5464 G loss:-2.099\n",
      "Epoch:  0062 D loss:-0.6283 G loss:-1.993\n",
      "Epoch:  0062 D loss:-0.5725 G loss:-2.429\n",
      "Epoch:  0062 D loss:-0.6532 G loss:-2.381\n",
      "Epoch:  0062 D loss:-0.6232 G loss:-2.179\n",
      "Epoch:  0062 D loss:-0.6209 G loss:-2.158\n",
      "Epoch:  0062 D loss:-0.7094 G loss:-2.169\n",
      "Epoch:  0062 D loss:-0.6264 G loss:-2.194\n",
      "Epoch:  0062 D loss:-0.6702 G loss:-2.192\n",
      "Epoch:  0062 D loss:-0.7152 G loss:-2.071\n",
      "Epoch:  0062 D loss:-0.5424 G loss:-2.14\n",
      "Epoch:  0062 D loss:-0.6943 G loss:-2.126\n",
      "Epoch:  0062 D loss:-0.6592 G loss:-2.002\n",
      "Epoch:  0062 D loss:-0.7172 G loss:-1.956\n",
      "Epoch:  0062 D loss:-0.7574 G loss:-2.101\n",
      "Epoch:  0062 D loss:-0.6878 G loss:-1.977\n",
      "Epoch:  0062 D loss:-0.6549 G loss:-2.061\n",
      "Epoch:  0062 D loss:-0.6087 G loss:-2.274\n",
      "Epoch:  0062 D loss:-0.7402 G loss:-2.228\n",
      "Epoch:  0062 D loss:-0.545 G loss:-2.033\n",
      "Epoch:  0062 D loss:-0.7641 G loss:-2.328\n",
      "Epoch:  0062 D loss:-0.6509 G loss:-2.131\n",
      "Epoch:  0062 D loss:-0.5323 G loss:-2.237\n",
      "Epoch:  0062 D loss:-0.653 G loss:-2.164\n",
      "Epoch:  0062 D loss:-0.657 G loss:-2.109\n",
      "Epoch:  0062 D loss:-0.6026 G loss:-2.085\n",
      "Epoch:  0062 D loss:-0.5981 G loss:-2.149\n",
      "Epoch:  0062 D loss:-0.6968 G loss:-1.944\n",
      "Epoch:  0062 D loss:-0.7914 G loss:-2.008\n",
      "Epoch:  0062 D loss:-0.6242 G loss:-1.926\n",
      "Epoch:  0062 D loss:-0.554 G loss:-2.083\n",
      "Epoch:  0062 D loss:-0.5355 G loss:-2.217\n",
      "Epoch:  0062 D loss:-0.6236 G loss:-2.211\n",
      "Epoch:  0062 D loss:-0.6996 G loss:-2.282\n",
      "Epoch:  0062 D loss:-0.6213 G loss:-2.203\n",
      "Epoch:  0062 D loss:-0.7298 G loss:-2.106\n",
      "Epoch:  0062 D loss:-0.629 G loss:-2.227\n",
      "Epoch:  0062 D loss:-0.6171 G loss:-2.027\n",
      "Epoch:  0062 D loss:-0.7513 G loss:-2.11\n",
      "Epoch:  0062 D loss:-0.57 G loss:-1.985\n",
      "Epoch:  0062 D loss:-0.6688 G loss:-2.04\n",
      "Epoch:  0062 D loss:-0.6567 G loss:-2.211\n",
      "Epoch:  0062 D loss:-0.558 G loss:-2.217\n",
      "Epoch:  0062 D loss:-0.7845 G loss:-2.208\n",
      "Epoch:  0062 D loss:-0.5787 G loss:-2.332\n",
      "Epoch:  0062 D loss:-0.6057 G loss:-2.177\n",
      "Epoch:  0062 D loss:-0.6645 G loss:-2.105\n",
      "Epoch:  0062 D loss:-0.6732 G loss:-2.189\n",
      "Epoch:  0062 D loss:-0.7808 G loss:-2.115\n",
      "Epoch:  0062 D loss:-0.6115 G loss:-2.173\n",
      "Epoch:  0062 D loss:-0.6113 G loss:-2.004\n",
      "Epoch:  0062 D loss:-0.6563 G loss:-2.068\n",
      "Epoch:  0062 D loss:-0.6394 G loss:-1.985\n",
      "Epoch:  0062 D loss:-0.59 G loss:-2.088\n",
      "Epoch:  0062 D loss:-0.6472 G loss:-2.076\n",
      "Epoch:  0062 D loss:-0.7504 G loss:-1.92\n",
      "Epoch:  0062 D loss:-0.6631 G loss:-1.818\n",
      "Epoch:  0062 D loss:-0.5526 G loss:-2.183\n",
      "Epoch:  0062 D loss:-0.5267 G loss:-2.183\n",
      "Epoch:  0062 D loss:-0.6117 G loss:-2.188\n",
      "Epoch:  0062 D loss:-0.7157 G loss:-2.246\n",
      "Epoch:  0062 D loss:-0.5374 G loss:-2.338\n",
      "Epoch:  0062 D loss:-0.7184 G loss:-2.25\n",
      "Epoch:  0062 D loss:-0.751 G loss:-2.307\n",
      "Epoch:  0062 D loss:-0.6046 G loss:-2.183\n",
      "Epoch:  0062 D loss:-0.5416 G loss:-2.306\n",
      "Epoch:  0062 D loss:-0.6451 G loss:-2.097\n",
      "Epoch:  0062 D loss:-0.6985 G loss:-1.92\n",
      "Epoch:  0062 D loss:-0.6344 G loss:-2.145\n",
      "Epoch:  0062 D loss:-0.6538 G loss:-2.129\n",
      "Epoch:  0062 D loss:-0.7163 G loss:-1.829\n",
      "Epoch:  0062 D loss:-0.6413 G loss:-2.027\n",
      "Epoch:  0062 D loss:-0.6841 G loss:-2.013\n",
      "Epoch:  0062 D loss:-0.6371 G loss:-2.057\n",
      "Epoch:  0062 D loss:-0.7255 G loss:-2.099\n",
      "Epoch:  0062 D loss:-0.6674 G loss:-2.228\n",
      "Epoch:  0062 D loss:-0.6198 G loss:-2.152\n",
      "Epoch:  0062 D loss:-0.8495 G loss:-2.126\n",
      "Epoch:  0062 D loss:-0.5946 G loss:-2.185\n",
      "Epoch:  0062 D loss:-0.5885 G loss:-2.421\n",
      "Epoch:  0062 D loss:-0.5354 G loss:-2.446\n",
      "Epoch:  0062 D loss:-0.6911 G loss:-2.41\n",
      "Epoch:  0062 D loss:-0.4603 G loss:-2.234\n",
      "Epoch:  0062 D loss:-0.745 G loss:-2.135\n",
      "Epoch:  0062 D loss:-0.4557 G loss:-2.321\n",
      "Epoch:  0062 D loss:-0.5732 G loss:-2.393\n",
      "Epoch:  0062 D loss:-0.5067 G loss:-2.14\n",
      "Epoch:  0062 D loss:-0.6531 G loss:-2.074\n",
      "Epoch:  0062 D loss:-0.7163 G loss:-1.997\n",
      "Epoch:  0062 D loss:-0.6662 G loss:-2.049\n",
      "Epoch:  0062 D loss:-0.5632 G loss:-2.029\n",
      "Epoch:  0062 D loss:-0.6734 G loss:-2.16\n",
      "Epoch:  0062 D loss:-0.6307 G loss:-2.192\n",
      "Epoch:  0062 D loss:-0.5388 G loss:-2.188\n",
      "Epoch:  0062 D loss:-0.5979 G loss:-2.342\n",
      "Epoch:  0062 D loss:-0.4732 G loss:-2.506\n",
      "Epoch:  0062 D loss:-0.5584 G loss:-2.123\n",
      "Epoch:  0062 D loss:-0.6642 G loss:-2.102\n",
      "Epoch:  0062 D loss:-0.4721 G loss:-2.152\n",
      "Epoch:  0062 D loss:-0.5975 G loss:-2.148\n",
      "Epoch:  0062 D loss:-0.5501 G loss:-2.064\n",
      "Epoch:  0062 D loss:-0.6034 G loss:-1.991\n",
      "Epoch:  0062 D loss:-0.5412 G loss:-1.967\n",
      "Epoch:  0062 D loss:-0.5023 G loss:-2.201\n",
      "Epoch:  0062 D loss:-0.7862 G loss:-2.066\n",
      "Epoch:  0062 D loss:-0.5952 G loss:-2.126\n",
      "Epoch:  0063 D loss:-0.7208 G loss:-2.115\n",
      "Epoch:  0063 D loss:-0.6579 G loss:-2.171\n",
      "Epoch:  0063 D loss:-0.7021 G loss:-1.937\n",
      "Epoch:  0063 D loss:-0.7623 G loss:-2.131\n",
      "Epoch:  0063 D loss:-0.6826 G loss:-2.037\n",
      "Epoch:  0063 D loss:-0.6738 G loss:-1.987\n",
      "Epoch:  0063 D loss:-0.5854 G loss:-2.027\n",
      "Epoch:  0063 D loss:-0.4461 G loss:-2.274\n",
      "Epoch:  0063 D loss:-0.619 G loss:-2.147\n",
      "Epoch:  0063 D loss:-0.5575 G loss:-2.474\n",
      "Epoch:  0063 D loss:-0.6982 G loss:-2.25\n",
      "Epoch:  0063 D loss:-0.521 G loss:-2.324\n",
      "Epoch:  0063 D loss:-0.7669 G loss:-2.264\n",
      "Epoch:  0063 D loss:-0.721 G loss:-2.085\n",
      "Epoch:  0063 D loss:-0.6014 G loss:-2.217\n",
      "Epoch:  0063 D loss:-0.6335 G loss:-2.179\n",
      "Epoch:  0063 D loss:-0.7162 G loss:-2.037\n",
      "Epoch:  0063 D loss:-0.5709 G loss:-2.029\n",
      "Epoch:  0063 D loss:-0.6109 G loss:-1.947\n",
      "Epoch:  0063 D loss:-0.7652 G loss:-1.963\n",
      "Epoch:  0063 D loss:-0.6684 G loss:-1.831\n",
      "Epoch:  0063 D loss:-0.6291 G loss:-2.047\n",
      "Epoch:  0063 D loss:-0.6151 G loss:-2.057\n",
      "Epoch:  0063 D loss:-0.5786 G loss:-2.18\n",
      "Epoch:  0063 D loss:-0.4906 G loss:-2.357\n",
      "Epoch:  0063 D loss:-0.6841 G loss:-2.174\n",
      "Epoch:  0063 D loss:-0.7426 G loss:-2.203\n",
      "Epoch:  0063 D loss:-0.6958 G loss:-1.996\n",
      "Epoch:  0063 D loss:-0.6817 G loss:-2.154\n",
      "Epoch:  0063 D loss:-0.7318 G loss:-2.254\n",
      "Epoch:  0063 D loss:-0.8006 G loss:-2.087\n",
      "Epoch:  0063 D loss:-0.6442 G loss:-2.013\n",
      "Epoch:  0063 D loss:-0.6166 G loss:-2.204\n",
      "Epoch:  0063 D loss:-0.6196 G loss:-2.017\n",
      "Epoch:  0063 D loss:-0.6259 G loss:-2.06\n",
      "Epoch:  0063 D loss:-0.5429 G loss:-2.201\n",
      "Epoch:  0063 D loss:-0.813 G loss:-1.917\n",
      "Epoch:  0063 D loss:-0.7234 G loss:-2.058\n",
      "Epoch:  0063 D loss:-0.687 G loss:-2.001\n",
      "Epoch:  0063 D loss:-0.6853 G loss:-1.78\n",
      "Epoch:  0063 D loss:-0.7047 G loss:-1.969\n",
      "Epoch:  0063 D loss:-0.6137 G loss:-1.866\n",
      "Epoch:  0063 D loss:-0.6708 G loss:-2.018\n",
      "Epoch:  0063 D loss:-0.7365 G loss:-2.172\n",
      "Epoch:  0063 D loss:-0.8468 G loss:-2.052\n",
      "Epoch:  0063 D loss:-0.6922 G loss:-2.084\n",
      "Epoch:  0063 D loss:-0.885 G loss:-2.084\n",
      "Epoch:  0063 D loss:-0.7126 G loss:-1.909\n",
      "Epoch:  0063 D loss:-0.8825 G loss:-1.841\n",
      "Epoch:  0063 D loss:-0.712 G loss:-2.024\n",
      "Epoch:  0063 D loss:-0.6957 G loss:-1.9\n",
      "Epoch:  0063 D loss:-0.7988 G loss:-1.9\n",
      "Epoch:  0063 D loss:-0.8085 G loss:-1.801\n",
      "Epoch:  0063 D loss:-0.715 G loss:-1.848\n",
      "Epoch:  0063 D loss:-0.5312 G loss:-2.237\n",
      "Epoch:  0063 D loss:-0.7335 G loss:-2.138\n",
      "Epoch:  0063 D loss:-0.6647 G loss:-1.887\n",
      "Epoch:  0063 D loss:-0.767 G loss:-1.877\n",
      "Epoch:  0063 D loss:-0.7592 G loss:-1.927\n",
      "Epoch:  0063 D loss:-0.6448 G loss:-2.08\n",
      "Epoch:  0063 D loss:-0.7055 G loss:-2.227\n",
      "Epoch:  0063 D loss:-0.7384 G loss:-2.244\n",
      "Epoch:  0063 D loss:-0.7133 G loss:-1.976\n",
      "Epoch:  0063 D loss:-0.7042 G loss:-1.904\n",
      "Epoch:  0063 D loss:-0.5826 G loss:-2.143\n",
      "Epoch:  0063 D loss:-0.6817 G loss:-1.849\n",
      "Epoch:  0063 D loss:-0.6454 G loss:-1.932\n",
      "Epoch:  0063 D loss:-0.6527 G loss:-2.157\n",
      "Epoch:  0063 D loss:-0.7313 G loss:-2.183\n",
      "Epoch:  0063 D loss:-0.7106 G loss:-2.238\n",
      "Epoch:  0063 D loss:-0.5837 G loss:-2.174\n",
      "Epoch:  0063 D loss:-0.6033 G loss:-2.091\n",
      "Epoch:  0063 D loss:-0.7066 G loss:-2.235\n",
      "Epoch:  0063 D loss:-0.6477 G loss:-2.212\n",
      "Epoch:  0063 D loss:-0.7149 G loss:-2.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0063 D loss:-0.5363 G loss:-2.09\n",
      "Epoch:  0063 D loss:-0.6355 G loss:-1.854\n",
      "Epoch:  0063 D loss:-0.7785 G loss:-1.891\n",
      "Epoch:  0063 D loss:-0.6139 G loss:-2.009\n",
      "Epoch:  0063 D loss:-0.6422 G loss:-2.132\n",
      "Epoch:  0063 D loss:-0.5729 G loss:-2.233\n",
      "Epoch:  0063 D loss:-0.5554 G loss:-2.187\n",
      "Epoch:  0063 D loss:-0.6478 G loss:-2.187\n",
      "Epoch:  0063 D loss:-0.6327 G loss:-2.251\n",
      "Epoch:  0063 D loss:-0.7307 G loss:-1.988\n",
      "Epoch:  0063 D loss:-0.607 G loss:-2.21\n",
      "Epoch:  0063 D loss:-0.6973 G loss:-2.076\n",
      "Epoch:  0063 D loss:-0.6641 G loss:-1.972\n",
      "Epoch:  0063 D loss:-0.6308 G loss:-2.104\n",
      "Epoch:  0063 D loss:-0.6003 G loss:-2.143\n",
      "Epoch:  0063 D loss:-0.6509 G loss:-2.0\n",
      "Epoch:  0063 D loss:-0.5541 G loss:-2.123\n",
      "Epoch:  0063 D loss:-0.4973 G loss:-2.328\n",
      "Epoch:  0063 D loss:-0.6051 G loss:-2.252\n",
      "Epoch:  0063 D loss:-0.5541 G loss:-2.309\n",
      "Epoch:  0063 D loss:-0.5714 G loss:-2.119\n",
      "Epoch:  0063 D loss:-0.583 G loss:-2.062\n",
      "Epoch:  0063 D loss:-0.6732 G loss:-2.032\n",
      "Epoch:  0063 D loss:-0.5694 G loss:-2.093\n",
      "Epoch:  0063 D loss:-0.6122 G loss:-2.185\n",
      "Epoch:  0063 D loss:-0.5624 G loss:-1.901\n",
      "Epoch:  0063 D loss:-0.6419 G loss:-1.988\n",
      "Epoch:  0063 D loss:-0.6444 G loss:-2.04\n",
      "Epoch:  0063 D loss:-0.7688 G loss:-2.118\n",
      "Epoch:  0063 D loss:-0.5649 G loss:-1.98\n",
      "Epoch:  0063 D loss:-0.6263 G loss:-2.28\n",
      "Epoch:  0063 D loss:-0.6969 G loss:-2.121\n",
      "Epoch:  0063 D loss:-0.5862 G loss:-2.181\n",
      "Epoch:  0063 D loss:-0.6174 G loss:-2.181\n",
      "Epoch:  0063 D loss:-0.6229 G loss:-2.196\n",
      "Epoch:  0063 D loss:-0.6355 G loss:-1.932\n",
      "Epoch:  0063 D loss:-0.6308 G loss:-2.227\n",
      "Epoch:  0063 D loss:-0.6406 G loss:-2.2\n",
      "Epoch:  0063 D loss:-0.636 G loss:-2.203\n",
      "Epoch:  0063 D loss:-0.6247 G loss:-2.023\n",
      "Epoch:  0063 D loss:-0.6205 G loss:-2.078\n",
      "Epoch:  0063 D loss:-0.6523 G loss:-2.102\n",
      "Epoch:  0063 D loss:-0.6322 G loss:-2.12\n",
      "Epoch:  0063 D loss:-0.5626 G loss:-2.093\n",
      "Epoch:  0063 D loss:-0.5619 G loss:-2.141\n",
      "Epoch:  0063 D loss:-0.5466 G loss:-2.581\n",
      "Epoch:  0063 D loss:-0.5725 G loss:-2.427\n",
      "Epoch:  0063 D loss:-0.6522 G loss:-2.125\n",
      "Epoch:  0063 D loss:-0.5672 G loss:-2.21\n",
      "Epoch:  0063 D loss:-0.6635 G loss:-2.398\n",
      "Epoch:  0063 D loss:-0.6192 G loss:-2.321\n",
      "Epoch:  0063 D loss:-0.6132 G loss:-2.284\n",
      "Epoch:  0063 D loss:-0.6125 G loss:-2.175\n",
      "Epoch:  0063 D loss:-0.6542 G loss:-1.991\n",
      "Epoch:  0063 D loss:-0.5801 G loss:-2.203\n",
      "Epoch:  0063 D loss:-0.5985 G loss:-2.026\n",
      "Epoch:  0063 D loss:-0.5031 G loss:-2.17\n",
      "Epoch:  0063 D loss:-0.6294 G loss:-2.252\n",
      "Epoch:  0063 D loss:-0.6249 G loss:-2.125\n",
      "Epoch:  0063 D loss:-0.6897 G loss:-2.098\n",
      "Epoch:  0063 D loss:-0.6733 G loss:-2.258\n",
      "Epoch:  0063 D loss:-0.6341 G loss:-2.347\n",
      "Epoch:  0063 D loss:-0.5534 G loss:-2.422\n",
      "Epoch:  0063 D loss:-0.6342 G loss:-2.519\n",
      "Epoch:  0063 D loss:-0.5792 G loss:-2.308\n",
      "Epoch:  0063 D loss:-0.6071 G loss:-1.989\n",
      "Epoch:  0063 D loss:-0.5787 G loss:-2.176\n",
      "Epoch:  0063 D loss:-0.6477 G loss:-2.096\n",
      "Epoch:  0063 D loss:-0.7251 G loss:-2.163\n",
      "Epoch:  0063 D loss:-0.5731 G loss:-2.26\n",
      "Epoch:  0063 D loss:-0.6423 G loss:-2.114\n",
      "Epoch:  0063 D loss:-0.6449 G loss:-2.055\n",
      "Epoch:  0063 D loss:-0.6377 G loss:-2.306\n",
      "Epoch:  0063 D loss:-0.6621 G loss:-2.17\n",
      "Epoch:  0063 D loss:-0.6341 G loss:-2.369\n",
      "Epoch:  0063 D loss:-0.605 G loss:-2.321\n",
      "Epoch:  0063 D loss:-0.5651 G loss:-2.368\n",
      "Epoch:  0063 D loss:-0.6421 G loss:-2.124\n",
      "Epoch:  0063 D loss:-0.7872 G loss:-2.244\n",
      "Epoch:  0063 D loss:-0.5586 G loss:-2.285\n",
      "Epoch:  0063 D loss:-0.6167 G loss:-2.032\n",
      "Epoch:  0063 D loss:-0.5981 G loss:-1.922\n",
      "Epoch:  0063 D loss:-0.7565 G loss:-1.997\n",
      "Epoch:  0063 D loss:-0.715 G loss:-2.15\n",
      "Epoch:  0063 D loss:-0.7305 G loss:-2.031\n",
      "Epoch:  0063 D loss:-0.6796 G loss:-2.139\n",
      "Epoch:  0063 D loss:-0.5981 G loss:-2.08\n",
      "Epoch:  0063 D loss:-0.5781 G loss:-2.028\n",
      "Epoch:  0063 D loss:-0.5424 G loss:-2.255\n",
      "Epoch:  0063 D loss:-0.8456 G loss:-1.9\n",
      "Epoch:  0063 D loss:-0.6563 G loss:-2.201\n",
      "Epoch:  0063 D loss:-0.56 G loss:-2.208\n",
      "Epoch:  0063 D loss:-0.5994 G loss:-2.275\n",
      "Epoch:  0063 D loss:-0.6035 G loss:-2.101\n",
      "Epoch:  0063 D loss:-0.519 G loss:-2.131\n",
      "Epoch:  0063 D loss:-0.6472 G loss:-2.272\n",
      "Epoch:  0063 D loss:-0.6616 G loss:-2.404\n",
      "Epoch:  0063 D loss:-0.5917 G loss:-2.449\n",
      "Epoch:  0063 D loss:-0.7081 G loss:-2.269\n",
      "Epoch:  0063 D loss:-0.5509 G loss:-2.345\n",
      "Epoch:  0063 D loss:-0.6576 G loss:-2.114\n",
      "Epoch:  0063 D loss:-0.6531 G loss:-2.079\n",
      "Epoch:  0063 D loss:-0.6404 G loss:-2.138\n",
      "Epoch:  0063 D loss:-0.5874 G loss:-2.181\n",
      "Epoch:  0063 D loss:-0.6341 G loss:-2.251\n",
      "Epoch:  0063 D loss:-0.5492 G loss:-2.042\n",
      "Epoch:  0063 D loss:-0.6606 G loss:-2.191\n",
      "Epoch:  0063 D loss:-0.5853 G loss:-2.326\n",
      "Epoch:  0063 D loss:-0.7115 G loss:-2.167\n",
      "Epoch:  0063 D loss:-0.59 G loss:-1.932\n",
      "Epoch:  0063 D loss:-0.7176 G loss:-1.893\n",
      "Epoch:  0063 D loss:-0.685 G loss:-2.372\n",
      "Epoch:  0063 D loss:-0.7099 G loss:-2.303\n",
      "Epoch:  0063 D loss:-0.6094 G loss:-2.212\n",
      "Epoch:  0063 D loss:-0.4987 G loss:-2.357\n",
      "Epoch:  0063 D loss:-0.7092 G loss:-2.165\n",
      "Epoch:  0063 D loss:-0.6446 G loss:-2.201\n",
      "Epoch:  0063 D loss:-0.7384 G loss:-2.14\n",
      "Epoch:  0063 D loss:-0.645 G loss:-2.021\n",
      "Epoch:  0063 D loss:-0.6452 G loss:-2.082\n",
      "Epoch:  0063 D loss:-0.6244 G loss:-2.163\n",
      "Epoch:  0063 D loss:-0.6451 G loss:-1.955\n",
      "Epoch:  0063 D loss:-0.6648 G loss:-2.002\n",
      "Epoch:  0063 D loss:-0.711 G loss:-1.984\n",
      "Epoch:  0063 D loss:-0.7415 G loss:-2.089\n",
      "Epoch:  0063 D loss:-0.8041 G loss:-1.992\n",
      "Epoch:  0063 D loss:-0.7432 G loss:-1.882\n",
      "Epoch:  0063 D loss:-0.62 G loss:-2.082\n",
      "Epoch:  0063 D loss:-0.6987 G loss:-2.015\n",
      "Epoch:  0063 D loss:-0.642 G loss:-2.13\n",
      "Epoch:  0063 D loss:-0.5171 G loss:-2.312\n",
      "Epoch:  0063 D loss:-0.6841 G loss:-2.096\n",
      "Epoch:  0063 D loss:-0.8724 G loss:-2.021\n",
      "Epoch:  0063 D loss:-0.6244 G loss:-2.191\n",
      "Epoch:  0063 D loss:-0.6838 G loss:-2.409\n",
      "Epoch:  0063 D loss:-0.6327 G loss:-2.322\n",
      "Epoch:  0063 D loss:-0.7086 G loss:-2.378\n",
      "Epoch:  0063 D loss:-0.5833 G loss:-2.158\n",
      "Epoch:  0063 D loss:-0.7054 G loss:-2.225\n",
      "Epoch:  0063 D loss:-0.6669 G loss:-2.089\n",
      "Epoch:  0063 D loss:-0.6226 G loss:-2.118\n",
      "Epoch:  0063 D loss:-0.6662 G loss:-2.234\n",
      "Epoch:  0063 D loss:-0.7871 G loss:-2.162\n",
      "Epoch:  0063 D loss:-0.8218 G loss:-1.923\n",
      "Epoch:  0063 D loss:-0.5891 G loss:-2.016\n",
      "Epoch:  0063 D loss:-0.7561 G loss:-1.741\n",
      "Epoch:  0063 D loss:-0.6759 G loss:-1.88\n",
      "Epoch:  0063 D loss:-0.7597 G loss:-2.046\n",
      "Epoch:  0063 D loss:-0.5715 G loss:-1.95\n",
      "Epoch:  0063 D loss:-0.8845 G loss:-1.925\n",
      "Epoch:  0063 D loss:-0.6683 G loss:-2.351\n",
      "Epoch:  0063 D loss:-0.68 G loss:-2.057\n",
      "Epoch:  0063 D loss:-0.7054 G loss:-2.046\n",
      "Epoch:  0063 D loss:-0.6242 G loss:-2.219\n",
      "Epoch:  0063 D loss:-0.6923 G loss:-2.146\n",
      "Epoch:  0063 D loss:-0.5785 G loss:-2.167\n",
      "Epoch:  0063 D loss:-0.7268 G loss:-2.048\n",
      "Epoch:  0063 D loss:-0.6168 G loss:-2.133\n",
      "Epoch:  0063 D loss:-0.7506 G loss:-2.004\n",
      "Epoch:  0063 D loss:-0.6562 G loss:-2.165\n",
      "Epoch:  0063 D loss:-0.6088 G loss:-2.42\n",
      "Epoch:  0063 D loss:-0.7225 G loss:-2.121\n",
      "Epoch:  0063 D loss:-0.6889 G loss:-2.213\n",
      "Epoch:  0063 D loss:-0.7245 G loss:-1.919\n",
      "Epoch:  0063 D loss:-0.7876 G loss:-2.057\n",
      "Epoch:  0063 D loss:-0.7659 G loss:-2.107\n",
      "Epoch:  0063 D loss:-0.8623 G loss:-1.937\n",
      "Epoch:  0063 D loss:-0.6544 G loss:-1.954\n",
      "Epoch:  0063 D loss:-0.8046 G loss:-1.895\n",
      "Epoch:  0063 D loss:-0.631 G loss:-2.03\n",
      "Epoch:  0063 D loss:-0.7911 G loss:-1.723\n",
      "Epoch:  0063 D loss:-0.6078 G loss:-1.974\n",
      "Epoch:  0063 D loss:-0.708 G loss:-2.234\n",
      "Epoch:  0063 D loss:-0.6703 G loss:-1.961\n",
      "Epoch:  0063 D loss:-0.6434 G loss:-2.127\n",
      "Epoch:  0063 D loss:-0.8773 G loss:-1.958\n",
      "Epoch:  0063 D loss:-0.5979 G loss:-2.223\n",
      "Epoch:  0063 D loss:-0.7183 G loss:-2.134\n",
      "Epoch:  0063 D loss:-0.7196 G loss:-2.131\n",
      "Epoch:  0063 D loss:-0.7307 G loss:-2.31\n",
      "Epoch:  0063 D loss:-0.6125 G loss:-1.955\n",
      "Epoch:  0063 D loss:-0.6812 G loss:-1.926\n",
      "Epoch:  0063 D loss:-0.6735 G loss:-2.272\n",
      "Epoch:  0063 D loss:-0.6544 G loss:-2.25\n",
      "Epoch:  0063 D loss:-0.6393 G loss:-2.244\n",
      "Epoch:  0063 D loss:-0.7741 G loss:-2.007\n",
      "Epoch:  0063 D loss:-0.7059 G loss:-2.156\n",
      "Epoch:  0063 D loss:-0.7752 G loss:-2.097\n",
      "Epoch:  0063 D loss:-0.9145 G loss:-1.74\n",
      "Epoch:  0063 D loss:-0.6648 G loss:-1.953\n",
      "Epoch:  0063 D loss:-0.6683 G loss:-1.973\n",
      "Epoch:  0063 D loss:-0.6871 G loss:-1.999\n",
      "Epoch:  0063 D loss:-0.6685 G loss:-1.998\n",
      "Epoch:  0063 D loss:-0.7471 G loss:-1.978\n",
      "Epoch:  0063 D loss:-0.6726 G loss:-2.186\n",
      "Epoch:  0063 D loss:-0.5835 G loss:-2.058\n",
      "Epoch:  0063 D loss:-0.6954 G loss:-1.907\n",
      "Epoch:  0063 D loss:-0.5576 G loss:-2.234\n",
      "Epoch:  0063 D loss:-0.5938 G loss:-2.133\n",
      "Epoch:  0063 D loss:-0.7156 G loss:-2.147\n",
      "Epoch:  0063 D loss:-0.7699 G loss:-2.001\n",
      "Epoch:  0063 D loss:-0.6505 G loss:-2.043\n",
      "Epoch:  0063 D loss:-0.5009 G loss:-2.484\n",
      "Epoch:  0063 D loss:-0.6941 G loss:-2.061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0063 D loss:-0.6461 G loss:-2.273\n",
      "Epoch:  0063 D loss:-0.6094 G loss:-2.327\n",
      "Epoch:  0063 D loss:-0.5638 G loss:-2.131\n",
      "Epoch:  0063 D loss:-0.7544 G loss:-2.171\n",
      "Epoch:  0063 D loss:-0.6401 G loss:-2.146\n",
      "Epoch:  0063 D loss:-0.4864 G loss:-1.994\n",
      "Epoch:  0063 D loss:-0.723 G loss:-2.026\n",
      "Epoch:  0063 D loss:-0.6466 G loss:-1.955\n",
      "Epoch:  0063 D loss:-0.6735 G loss:-2.04\n",
      "Epoch:  0063 D loss:-0.6538 G loss:-2.048\n",
      "Epoch:  0063 D loss:-0.6834 G loss:-2.121\n",
      "Epoch:  0063 D loss:-0.7051 G loss:-2.185\n",
      "Epoch:  0063 D loss:-0.6533 G loss:-2.182\n",
      "Epoch:  0063 D loss:-0.6585 G loss:-2.181\n",
      "Epoch:  0063 D loss:-0.5952 G loss:-2.371\n",
      "Epoch:  0063 D loss:-0.6285 G loss:-2.387\n",
      "Epoch:  0063 D loss:-0.5874 G loss:-2.266\n",
      "Epoch:  0063 D loss:-0.6617 G loss:-2.22\n",
      "Epoch:  0063 D loss:-0.6143 G loss:-2.181\n",
      "Epoch:  0063 D loss:-0.5191 G loss:-2.377\n",
      "Epoch:  0063 D loss:-0.589 G loss:-2.278\n",
      "Epoch:  0063 D loss:-0.562 G loss:-2.545\n",
      "Epoch:  0063 D loss:-0.6507 G loss:-2.127\n",
      "Epoch:  0063 D loss:-0.5105 G loss:-2.316\n",
      "Epoch:  0063 D loss:-0.6093 G loss:-2.094\n",
      "Epoch:  0063 D loss:-0.5481 G loss:-2.094\n",
      "Epoch:  0063 D loss:-0.5528 G loss:-2.108\n",
      "Epoch:  0063 D loss:-0.63 G loss:-2.134\n",
      "Epoch:  0063 D loss:-0.764 G loss:-1.978\n",
      "Epoch:  0063 D loss:-0.5713 G loss:-2.256\n",
      "Epoch:  0063 D loss:-0.8026 G loss:-2.168\n",
      "Epoch:  0063 D loss:-0.6995 G loss:-2.144\n",
      "Epoch:  0063 D loss:-0.6214 G loss:-2.324\n",
      "Epoch:  0063 D loss:-0.6114 G loss:-2.56\n",
      "Epoch:  0063 D loss:-0.6023 G loss:-2.331\n",
      "Epoch:  0063 D loss:-0.6588 G loss:-2.151\n",
      "Epoch:  0063 D loss:-0.733 G loss:-2.154\n",
      "Epoch:  0063 D loss:-0.6121 G loss:-2.111\n",
      "Epoch:  0063 D loss:-0.7444 G loss:-2.108\n",
      "Epoch:  0063 D loss:-0.6942 G loss:-2.043\n",
      "Epoch:  0063 D loss:-0.656 G loss:-2.164\n",
      "Epoch:  0063 D loss:-0.5378 G loss:-2.156\n",
      "Epoch:  0063 D loss:-0.5959 G loss:-1.938\n",
      "Epoch:  0063 D loss:-0.6406 G loss:-2.057\n",
      "Epoch:  0063 D loss:-0.6352 G loss:-2.153\n",
      "Epoch:  0063 D loss:-0.5681 G loss:-2.142\n",
      "Epoch:  0063 D loss:-0.6152 G loss:-2.195\n",
      "Epoch:  0063 D loss:-0.6226 G loss:-2.235\n",
      "Epoch:  0063 D loss:-0.5557 G loss:-2.408\n",
      "Epoch:  0063 D loss:-0.6765 G loss:-2.209\n",
      "Epoch:  0063 D loss:-0.7121 G loss:-2.171\n",
      "Epoch:  0063 D loss:-0.7465 G loss:-1.978\n",
      "Epoch:  0063 D loss:-0.6788 G loss:-2.076\n",
      "Epoch:  0063 D loss:-0.6937 G loss:-1.986\n",
      "Epoch:  0063 D loss:-0.6942 G loss:-2.094\n",
      "Epoch:  0063 D loss:-0.6055 G loss:-2.127\n",
      "Epoch:  0063 D loss:-0.6433 G loss:-2.073\n",
      "Epoch:  0063 D loss:-0.5554 G loss:-1.956\n",
      "Epoch:  0063 D loss:-0.7566 G loss:-2.139\n",
      "Epoch:  0063 D loss:-0.589 G loss:-2.131\n",
      "Epoch:  0063 D loss:-0.7313 G loss:-1.977\n",
      "Epoch:  0063 D loss:-0.6582 G loss:-2.061\n",
      "Epoch:  0063 D loss:-0.7664 G loss:-2.022\n",
      "Epoch:  0063 D loss:-0.6218 G loss:-1.936\n",
      "Epoch:  0063 D loss:-0.6881 G loss:-2.2\n",
      "Epoch:  0063 D loss:-0.7292 G loss:-2.177\n",
      "Epoch:  0063 D loss:-0.5212 G loss:-2.48\n",
      "Epoch:  0063 D loss:-0.6142 G loss:-2.332\n",
      "Epoch:  0063 D loss:-0.6034 G loss:-2.314\n",
      "Epoch:  0063 D loss:-0.6271 G loss:-2.3\n",
      "Epoch:  0063 D loss:-0.7396 G loss:-2.158\n",
      "Epoch:  0063 D loss:-0.6719 G loss:-2.037\n",
      "Epoch:  0063 D loss:-0.6607 G loss:-1.922\n",
      "Epoch:  0063 D loss:-0.6979 G loss:-1.983\n",
      "Epoch:  0063 D loss:-0.6964 G loss:-1.962\n",
      "Epoch:  0063 D loss:-0.6632 G loss:-1.781\n",
      "Epoch:  0063 D loss:-0.8741 G loss:-1.83\n",
      "Epoch:  0063 D loss:-0.6939 G loss:-1.813\n",
      "Epoch:  0063 D loss:-0.611 G loss:-1.987\n",
      "Epoch:  0063 D loss:-0.7791 G loss:-1.847\n",
      "Epoch:  0063 D loss:-0.563 G loss:-2.035\n",
      "Epoch:  0063 D loss:-0.8513 G loss:-2.063\n",
      "Epoch:  0063 D loss:-0.6289 G loss:-2.193\n",
      "Epoch:  0063 D loss:-0.5997 G loss:-2.202\n",
      "Epoch:  0063 D loss:-0.636 G loss:-2.437\n",
      "Epoch:  0063 D loss:-0.7049 G loss:-2.042\n",
      "Epoch:  0063 D loss:-0.7072 G loss:-2.234\n",
      "Epoch:  0063 D loss:-0.5992 G loss:-2.516\n",
      "Epoch:  0063 D loss:-0.6293 G loss:-2.218\n",
      "Epoch:  0063 D loss:-0.7895 G loss:-2.047\n",
      "Epoch:  0063 D loss:-0.754 G loss:-1.867\n",
      "Epoch:  0063 D loss:-0.6162 G loss:-2.107\n",
      "Epoch:  0063 D loss:-0.5607 G loss:-2.133\n",
      "Epoch:  0063 D loss:-0.6166 G loss:-1.92\n",
      "Epoch:  0063 D loss:-0.6449 G loss:-1.944\n",
      "Epoch:  0063 D loss:-0.6719 G loss:-2.132\n",
      "Epoch:  0063 D loss:-0.7513 G loss:-1.719\n",
      "Epoch:  0063 D loss:-0.6868 G loss:-1.983\n",
      "Epoch:  0063 D loss:-0.6826 G loss:-2.115\n",
      "Epoch:  0063 D loss:-0.7785 G loss:-2.134\n",
      "Epoch:  0063 D loss:-0.6339 G loss:-1.953\n",
      "Epoch:  0063 D loss:-0.7267 G loss:-2.061\n",
      "Epoch:  0063 D loss:-0.6676 G loss:-2.246\n",
      "Epoch:  0063 D loss:-0.7687 G loss:-2.134\n",
      "Epoch:  0063 D loss:-0.7962 G loss:-1.798\n",
      "Epoch:  0063 D loss:-0.69 G loss:-1.943\n",
      "Epoch:  0063 D loss:-0.7594 G loss:-1.955\n",
      "Epoch:  0063 D loss:-0.656 G loss:-2.057\n",
      "Epoch:  0063 D loss:-0.6667 G loss:-2.055\n",
      "Epoch:  0063 D loss:-0.7387 G loss:-1.98\n",
      "Epoch:  0063 D loss:-0.6894 G loss:-2.043\n",
      "Epoch:  0063 D loss:-0.848 G loss:-1.947\n",
      "Epoch:  0063 D loss:-0.5975 G loss:-2.189\n",
      "Epoch:  0063 D loss:-0.654 G loss:-1.954\n",
      "Epoch:  0063 D loss:-0.645 G loss:-2.13\n",
      "Epoch:  0063 D loss:-0.6293 G loss:-2.097\n",
      "Epoch:  0063 D loss:-0.6831 G loss:-2.176\n",
      "Epoch:  0063 D loss:-0.6647 G loss:-2.066\n",
      "Epoch:  0063 D loss:-0.6184 G loss:-1.896\n",
      "Epoch:  0063 D loss:-0.6542 G loss:-2.085\n",
      "Epoch:  0063 D loss:-0.8925 G loss:-1.982\n",
      "Epoch:  0063 D loss:-0.6582 G loss:-2.02\n",
      "Epoch:  0063 D loss:-0.6975 G loss:-2.099\n",
      "Epoch:  0063 D loss:-0.7519 G loss:-2.243\n",
      "Epoch:  0063 D loss:-0.7715 G loss:-2.007\n",
      "Epoch:  0063 D loss:-0.7215 G loss:-2.051\n",
      "Epoch:  0063 D loss:-0.6498 G loss:-2.041\n",
      "Epoch:  0063 D loss:-0.677 G loss:-1.909\n",
      "Epoch:  0063 D loss:-0.5957 G loss:-2.205\n",
      "Epoch:  0063 D loss:-0.7909 G loss:-2.106\n",
      "Epoch:  0063 D loss:-0.7079 G loss:-1.893\n",
      "Epoch:  0063 D loss:-0.595 G loss:-2.14\n",
      "Epoch:  0063 D loss:-0.7122 G loss:-2.03\n",
      "Epoch:  0063 D loss:-0.7011 G loss:-2.179\n",
      "Epoch:  0063 D loss:-0.7311 G loss:-1.922\n",
      "Epoch:  0063 D loss:-0.8161 G loss:-1.874\n",
      "Epoch:  0063 D loss:-0.6841 G loss:-2.076\n",
      "Epoch:  0063 D loss:-0.6025 G loss:-1.972\n",
      "Epoch:  0063 D loss:-0.641 G loss:-2.099\n",
      "Epoch:  0063 D loss:-0.742 G loss:-2.13\n",
      "Epoch:  0063 D loss:-0.6034 G loss:-2.308\n",
      "Epoch:  0063 D loss:-0.5584 G loss:-2.277\n",
      "Epoch:  0063 D loss:-0.7886 G loss:-2.13\n",
      "Epoch:  0063 D loss:-0.6606 G loss:-2.226\n",
      "Epoch:  0063 D loss:-0.7446 G loss:-2.209\n",
      "Epoch:  0063 D loss:-0.7141 G loss:-2.18\n",
      "Epoch:  0063 D loss:-0.6543 G loss:-2.385\n",
      "Epoch:  0063 D loss:-0.652 G loss:-2.131\n",
      "Epoch:  0063 D loss:-0.592 G loss:-2.131\n",
      "Epoch:  0063 D loss:-0.5677 G loss:-2.299\n",
      "Epoch:  0063 D loss:-0.5179 G loss:-2.272\n",
      "Epoch:  0063 D loss:-0.7099 G loss:-2.068\n",
      "Epoch:  0063 D loss:-0.5541 G loss:-1.975\n",
      "Epoch:  0063 D loss:-0.6295 G loss:-2.008\n",
      "Epoch:  0063 D loss:-0.6118 G loss:-2.012\n",
      "Epoch:  0063 D loss:-0.6679 G loss:-2.011\n",
      "Epoch:  0063 D loss:-0.6983 G loss:-1.951\n",
      "Epoch:  0063 D loss:-0.8112 G loss:-1.815\n",
      "Epoch:  0063 D loss:-0.5922 G loss:-2.055\n",
      "Epoch:  0063 D loss:-0.5467 G loss:-2.175\n",
      "Epoch:  0063 D loss:-0.7346 G loss:-2.075\n",
      "Epoch:  0063 D loss:-0.6436 G loss:-2.094\n",
      "Epoch:  0063 D loss:-0.7585 G loss:-2.181\n",
      "Epoch:  0063 D loss:-0.7942 G loss:-2.108\n",
      "Epoch:  0063 D loss:-0.6385 G loss:-2.146\n",
      "Epoch:  0063 D loss:-0.8461 G loss:-1.991\n",
      "Epoch:  0063 D loss:-0.7321 G loss:-1.906\n",
      "Epoch:  0063 D loss:-0.6993 G loss:-1.792\n",
      "Epoch:  0063 D loss:-0.7 G loss:-2.111\n",
      "Epoch:  0063 D loss:-0.6054 G loss:-1.917\n",
      "Epoch:  0063 D loss:-0.6689 G loss:-1.882\n",
      "Epoch:  0063 D loss:-0.5831 G loss:-1.808\n",
      "Epoch:  0063 D loss:-0.6028 G loss:-1.903\n",
      "Epoch:  0063 D loss:-0.6055 G loss:-2.002\n",
      "Epoch:  0063 D loss:-0.7075 G loss:-2.059\n",
      "Epoch:  0063 D loss:-0.6305 G loss:-2.1\n",
      "Epoch:  0063 D loss:-0.7766 G loss:-2.127\n",
      "Epoch:  0063 D loss:-0.7594 G loss:-2.209\n",
      "Epoch:  0063 D loss:-0.6753 G loss:-2.353\n",
      "Epoch:  0063 D loss:-0.5876 G loss:-2.317\n",
      "Epoch:  0063 D loss:-0.6756 G loss:-2.247\n",
      "Epoch:  0063 D loss:-0.7295 G loss:-2.165\n",
      "Epoch:  0063 D loss:-0.714 G loss:-2.043\n",
      "Epoch:  0063 D loss:-0.5849 G loss:-1.998\n",
      "Epoch:  0063 D loss:-0.7496 G loss:-2.073\n",
      "Epoch:  0063 D loss:-0.7236 G loss:-1.989\n",
      "Epoch:  0063 D loss:-0.6892 G loss:-2.008\n",
      "Epoch:  0063 D loss:-0.6835 G loss:-1.805\n",
      "Epoch:  0063 D loss:-0.725 G loss:-1.908\n",
      "Epoch:  0063 D loss:-0.5933 G loss:-1.942\n",
      "Epoch:  0063 D loss:-0.6912 G loss:-1.775\n",
      "Epoch:  0063 D loss:-0.6219 G loss:-1.878\n",
      "Epoch:  0063 D loss:-0.5857 G loss:-2.07\n",
      "Epoch:  0063 D loss:-0.7535 G loss:-1.954\n",
      "Epoch:  0063 D loss:-0.6633 G loss:-2.249\n",
      "Epoch:  0063 D loss:-0.576 G loss:-2.338\n",
      "Epoch:  0063 D loss:-0.7239 G loss:-2.263\n",
      "Epoch:  0063 D loss:-0.6943 G loss:-2.242\n",
      "Epoch:  0063 D loss:-0.6484 G loss:-2.308\n",
      "Epoch:  0063 D loss:-0.6325 G loss:-2.418\n",
      "Epoch:  0063 D loss:-0.7516 G loss:-2.052\n",
      "Epoch:  0063 D loss:-0.6762 G loss:-2.07\n",
      "Epoch:  0063 D loss:-0.5819 G loss:-2.223\n",
      "Epoch:  0063 D loss:-0.585 G loss:-2.119\n",
      "Epoch:  0063 D loss:-0.5975 G loss:-1.875\n",
      "Epoch:  0063 D loss:-0.6698 G loss:-1.989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0063 D loss:-0.657 G loss:-1.874\n",
      "Epoch:  0063 D loss:-0.7701 G loss:-1.865\n",
      "Epoch:  0063 D loss:-0.5386 G loss:-2.043\n",
      "Epoch:  0063 D loss:-0.6184 G loss:-2.035\n",
      "Epoch:  0063 D loss:-0.8166 G loss:-2.143\n",
      "Epoch:  0063 D loss:-0.6332 G loss:-2.049\n",
      "Epoch:  0063 D loss:-0.6874 G loss:-2.29\n",
      "Epoch:  0063 D loss:-0.7804 G loss:-2.152\n",
      "Epoch:  0063 D loss:-0.5318 G loss:-2.264\n",
      "Epoch:  0063 D loss:-0.646 G loss:-1.952\n",
      "Epoch:  0063 D loss:-0.5929 G loss:-2.206\n",
      "Epoch:  0063 D loss:-0.7095 G loss:-2.257\n",
      "Epoch:  0063 D loss:-0.7391 G loss:-2.133\n",
      "Epoch:  0063 D loss:-0.671 G loss:-2.025\n",
      "Epoch:  0063 D loss:-0.6173 G loss:-2.026\n",
      "Epoch:  0063 D loss:-0.638 G loss:-1.988\n",
      "Epoch:  0063 D loss:-0.6417 G loss:-2.208\n",
      "Epoch:  0063 D loss:-0.6394 G loss:-2.133\n",
      "Epoch:  0063 D loss:-0.6243 G loss:-2.171\n",
      "Epoch:  0063 D loss:-0.6385 G loss:-2.121\n",
      "Epoch:  0063 D loss:-0.7514 G loss:-1.944\n",
      "Epoch:  0063 D loss:-0.6862 G loss:-2.006\n",
      "Epoch:  0063 D loss:-0.673 G loss:-2.197\n",
      "Epoch:  0063 D loss:-0.6927 G loss:-1.955\n",
      "Epoch:  0063 D loss:-0.6695 G loss:-1.842\n",
      "Epoch:  0063 D loss:-0.589 G loss:-2.276\n",
      "Epoch:  0063 D loss:-0.6098 G loss:-2.228\n",
      "Epoch:  0063 D loss:-0.7315 G loss:-1.978\n",
      "Epoch:  0063 D loss:-0.768 G loss:-2.137\n",
      "Epoch:  0063 D loss:-0.8246 G loss:-2.139\n",
      "Epoch:  0063 D loss:-0.8449 G loss:-2.097\n",
      "Epoch:  0063 D loss:-0.6875 G loss:-1.906\n",
      "Epoch:  0063 D loss:-0.7188 G loss:-1.842\n",
      "Epoch:  0063 D loss:-0.626 G loss:-1.908\n",
      "Epoch:  0063 D loss:-0.6158 G loss:-1.97\n",
      "Epoch:  0063 D loss:-0.8312 G loss:-1.955\n",
      "Epoch:  0063 D loss:-0.7484 G loss:-1.985\n",
      "Epoch:  0063 D loss:-0.8608 G loss:-1.89\n",
      "Epoch:  0063 D loss:-0.7379 G loss:-1.914\n",
      "Epoch:  0063 D loss:-0.6932 G loss:-2.184\n",
      "Epoch:  0063 D loss:-0.7062 G loss:-2.094\n",
      "Epoch:  0063 D loss:-0.5391 G loss:-2.11\n",
      "Epoch:  0063 D loss:-0.7228 G loss:-1.908\n",
      "Epoch:  0063 D loss:-0.645 G loss:-2.047\n",
      "Epoch:  0063 D loss:-0.66 G loss:-2.25\n",
      "Epoch:  0063 D loss:-0.539 G loss:-2.069\n",
      "Epoch:  0063 D loss:-0.6416 G loss:-1.907\n",
      "Epoch:  0063 D loss:-0.6174 G loss:-2.199\n",
      "Epoch:  0063 D loss:-0.7366 G loss:-2.029\n",
      "Epoch:  0063 D loss:-0.5074 G loss:-2.104\n",
      "Epoch:  0063 D loss:-0.6812 G loss:-2.125\n",
      "Epoch:  0063 D loss:-0.6838 G loss:-2.053\n",
      "Epoch:  0063 D loss:-0.6797 G loss:-2.194\n",
      "Epoch:  0063 D loss:-0.756 G loss:-1.942\n",
      "Epoch:  0063 D loss:-0.6447 G loss:-1.909\n",
      "Epoch:  0063 D loss:-0.7569 G loss:-1.834\n",
      "Epoch:  0063 D loss:-0.7342 G loss:-2.229\n",
      "Epoch:  0063 D loss:-0.7905 G loss:-2.048\n",
      "Epoch:  0063 D loss:-0.6156 G loss:-2.226\n",
      "Epoch:  0063 D loss:-0.5296 G loss:-2.047\n",
      "Epoch:  0063 D loss:-0.8191 G loss:-1.99\n",
      "Epoch:  0063 D loss:-0.6582 G loss:-1.946\n",
      "Epoch:  0063 D loss:-0.6316 G loss:-2.05\n",
      "Epoch:  0063 D loss:-0.6407 G loss:-2.074\n",
      "Epoch:  0063 D loss:-0.8205 G loss:-1.985\n",
      "Epoch:  0064 D loss:-0.6277 G loss:-2.263\n",
      "Epoch:  0064 D loss:-0.7587 G loss:-1.974\n",
      "Epoch:  0064 D loss:-0.6643 G loss:-1.973\n",
      "Epoch:  0064 D loss:-0.651 G loss:-1.981\n",
      "Epoch:  0064 D loss:-0.7526 G loss:-1.938\n",
      "Epoch:  0064 D loss:-0.6887 G loss:-1.981\n",
      "Epoch:  0064 D loss:-0.6611 G loss:-2.0\n",
      "Epoch:  0064 D loss:-0.6881 G loss:-1.982\n",
      "Epoch:  0064 D loss:-0.7723 G loss:-1.937\n",
      "Epoch:  0064 D loss:-0.633 G loss:-1.86\n",
      "Epoch:  0064 D loss:-0.7005 G loss:-2.055\n",
      "Epoch:  0064 D loss:-0.7622 G loss:-2.048\n",
      "Epoch:  0064 D loss:-0.6981 G loss:-2.159\n",
      "Epoch:  0064 D loss:-0.7381 G loss:-2.101\n",
      "Epoch:  0064 D loss:-0.6277 G loss:-2.195\n",
      "Epoch:  0064 D loss:-0.6205 G loss:-2.251\n",
      "Epoch:  0064 D loss:-0.7318 G loss:-1.94\n",
      "Epoch:  0064 D loss:-0.7344 G loss:-2.075\n",
      "Epoch:  0064 D loss:-0.5995 G loss:-1.926\n",
      "Epoch:  0064 D loss:-0.7191 G loss:-1.823\n",
      "Epoch:  0064 D loss:-0.7442 G loss:-1.936\n",
      "Epoch:  0064 D loss:-0.6713 G loss:-2.132\n",
      "Epoch:  0064 D loss:-0.5777 G loss:-2.192\n",
      "Epoch:  0064 D loss:-0.7612 G loss:-1.994\n",
      "Epoch:  0064 D loss:-0.7284 G loss:-1.988\n",
      "Epoch:  0064 D loss:-0.6917 G loss:-2.258\n",
      "Epoch:  0064 D loss:-0.8923 G loss:-2.036\n",
      "Epoch:  0064 D loss:-0.6246 G loss:-2.114\n",
      "Epoch:  0064 D loss:-0.6752 G loss:-2.08\n",
      "Epoch:  0064 D loss:-0.6417 G loss:-2.007\n",
      "Epoch:  0064 D loss:-0.6611 G loss:-2.057\n",
      "Epoch:  0064 D loss:-0.7513 G loss:-2.003\n",
      "Epoch:  0064 D loss:-0.7634 G loss:-1.808\n",
      "Epoch:  0064 D loss:-0.7149 G loss:-1.679\n",
      "Epoch:  0064 D loss:-0.684 G loss:-2.135\n",
      "Epoch:  0064 D loss:-0.7036 G loss:-1.949\n",
      "Epoch:  0064 D loss:-0.5964 G loss:-2.14\n",
      "Epoch:  0064 D loss:-0.634 G loss:-2.271\n",
      "Epoch:  0064 D loss:-0.7198 G loss:-2.141\n",
      "Epoch:  0064 D loss:-0.7113 G loss:-2.066\n",
      "Epoch:  0064 D loss:-0.6367 G loss:-1.934\n",
      "Epoch:  0064 D loss:-0.8529 G loss:-2.073\n",
      "Epoch:  0064 D loss:-0.8553 G loss:-1.902\n",
      "Epoch:  0064 D loss:-0.7045 G loss:-2.004\n",
      "Epoch:  0064 D loss:-0.6256 G loss:-2.172\n",
      "Epoch:  0064 D loss:-0.5708 G loss:-2.077\n",
      "Epoch:  0064 D loss:-0.7147 G loss:-1.776\n",
      "Epoch:  0064 D loss:-0.7482 G loss:-1.852\n",
      "Epoch:  0064 D loss:-0.8175 G loss:-1.943\n",
      "Epoch:  0064 D loss:-0.6781 G loss:-2.106\n",
      "Epoch:  0064 D loss:-0.754 G loss:-2.153\n",
      "Epoch:  0064 D loss:-0.6763 G loss:-2.165\n",
      "Epoch:  0064 D loss:-0.6665 G loss:-2.015\n",
      "Epoch:  0064 D loss:-0.8457 G loss:-1.96\n",
      "Epoch:  0064 D loss:-0.8824 G loss:-1.787\n",
      "Epoch:  0064 D loss:-0.5766 G loss:-2.152\n",
      "Epoch:  0064 D loss:-0.7103 G loss:-1.918\n",
      "Epoch:  0064 D loss:-0.7003 G loss:-1.793\n",
      "Epoch:  0064 D loss:-0.6385 G loss:-1.839\n",
      "Epoch:  0064 D loss:-0.8141 G loss:-1.808\n",
      "Epoch:  0064 D loss:-0.5968 G loss:-1.963\n",
      "Epoch:  0064 D loss:-0.5935 G loss:-1.904\n",
      "Epoch:  0064 D loss:-0.6508 G loss:-2.117\n",
      "Epoch:  0064 D loss:-0.7753 G loss:-2.296\n",
      "Epoch:  0064 D loss:-0.7794 G loss:-2.083\n",
      "Epoch:  0064 D loss:-0.8095 G loss:-2.153\n",
      "Epoch:  0064 D loss:-0.6699 G loss:-2.257\n",
      "Epoch:  0064 D loss:-0.5819 G loss:-2.381\n",
      "Epoch:  0064 D loss:-0.651 G loss:-1.91\n",
      "Epoch:  0064 D loss:-0.6363 G loss:-2.212\n",
      "Epoch:  0064 D loss:-0.6829 G loss:-2.182\n",
      "Epoch:  0064 D loss:-0.6398 G loss:-2.171\n",
      "Epoch:  0064 D loss:-0.648 G loss:-1.886\n",
      "Epoch:  0064 D loss:-0.7006 G loss:-1.956\n",
      "Epoch:  0064 D loss:-0.6252 G loss:-2.171\n",
      "Epoch:  0064 D loss:-0.6991 G loss:-1.789\n",
      "Epoch:  0064 D loss:-0.6361 G loss:-1.893\n",
      "Epoch:  0064 D loss:-0.5449 G loss:-1.998\n",
      "Epoch:  0064 D loss:-0.7146 G loss:-1.971\n",
      "Epoch:  0064 D loss:-0.638 G loss:-2.11\n",
      "Epoch:  0064 D loss:-0.517 G loss:-2.344\n",
      "Epoch:  0064 D loss:-0.6653 G loss:-2.264\n",
      "Epoch:  0064 D loss:-0.871 G loss:-2.088\n",
      "Epoch:  0064 D loss:-0.8255 G loss:-2.129\n",
      "Epoch:  0064 D loss:-0.7282 G loss:-2.143\n",
      "Epoch:  0064 D loss:-0.5908 G loss:-2.24\n",
      "Epoch:  0064 D loss:-0.7302 G loss:-2.106\n",
      "Epoch:  0064 D loss:-0.6426 G loss:-2.044\n",
      "Epoch:  0064 D loss:-0.7775 G loss:-1.994\n",
      "Epoch:  0064 D loss:-0.5835 G loss:-2.147\n",
      "Epoch:  0064 D loss:-0.577 G loss:-2.038\n",
      "Epoch:  0064 D loss:-0.7163 G loss:-2.083\n",
      "Epoch:  0064 D loss:-0.6788 G loss:-2.154\n",
      "Epoch:  0064 D loss:-0.8076 G loss:-1.901\n",
      "Epoch:  0064 D loss:-0.7876 G loss:-2.04\n",
      "Epoch:  0064 D loss:-0.6975 G loss:-2.014\n",
      "Epoch:  0064 D loss:-0.6396 G loss:-2.009\n",
      "Epoch:  0064 D loss:-0.6821 G loss:-2.208\n",
      "Epoch:  0064 D loss:-0.6155 G loss:-2.154\n",
      "Epoch:  0064 D loss:-0.5773 G loss:-2.373\n",
      "Epoch:  0064 D loss:-0.6139 G loss:-2.215\n",
      "Epoch:  0064 D loss:-0.6343 G loss:-2.189\n",
      "Epoch:  0064 D loss:-0.6516 G loss:-2.229\n",
      "Epoch:  0064 D loss:-0.651 G loss:-1.952\n",
      "Epoch:  0064 D loss:-0.5308 G loss:-1.988\n",
      "Epoch:  0064 D loss:-0.7597 G loss:-1.922\n",
      "Epoch:  0064 D loss:-0.7097 G loss:-2.011\n",
      "Epoch:  0064 D loss:-0.7032 G loss:-1.963\n",
      "Epoch:  0064 D loss:-0.733 G loss:-1.868\n",
      "Epoch:  0064 D loss:-0.5917 G loss:-2.032\n",
      "Epoch:  0064 D loss:-0.7326 G loss:-1.985\n",
      "Epoch:  0064 D loss:-0.6558 G loss:-2.087\n",
      "Epoch:  0064 D loss:-0.6819 G loss:-2.388\n",
      "Epoch:  0064 D loss:-0.7306 G loss:-2.148\n",
      "Epoch:  0064 D loss:-0.7528 G loss:-2.119\n",
      "Epoch:  0064 D loss:-0.591 G loss:-2.333\n",
      "Epoch:  0064 D loss:-0.6791 G loss:-2.259\n",
      "Epoch:  0064 D loss:-0.6862 G loss:-2.155\n",
      "Epoch:  0064 D loss:-0.58 G loss:-2.241\n",
      "Epoch:  0064 D loss:-0.6935 G loss:-2.024\n",
      "Epoch:  0064 D loss:-0.5407 G loss:-1.983\n",
      "Epoch:  0064 D loss:-0.7801 G loss:-1.832\n",
      "Epoch:  0064 D loss:-0.6752 G loss:-1.997\n",
      "Epoch:  0064 D loss:-0.6794 G loss:-1.89\n",
      "Epoch:  0064 D loss:-0.5835 G loss:-2.101\n",
      "Epoch:  0064 D loss:-0.6992 G loss:-1.945\n",
      "Epoch:  0064 D loss:-0.7578 G loss:-1.971\n",
      "Epoch:  0064 D loss:-0.7213 G loss:-2.114\n",
      "Epoch:  0064 D loss:-0.7563 G loss:-2.216\n",
      "Epoch:  0064 D loss:-0.8336 G loss:-1.995\n",
      "Epoch:  0064 D loss:-0.7184 G loss:-2.237\n",
      "Epoch:  0064 D loss:-0.5891 G loss:-2.407\n",
      "Epoch:  0064 D loss:-0.7888 G loss:-2.297\n",
      "Epoch:  0064 D loss:-0.7087 G loss:-2.184\n",
      "Epoch:  0064 D loss:-0.6496 G loss:-2.058\n",
      "Epoch:  0064 D loss:-0.6304 G loss:-2.107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0064 D loss:-0.7031 G loss:-2.096\n",
      "Epoch:  0064 D loss:-0.6586 G loss:-1.997\n",
      "Epoch:  0064 D loss:-0.7293 G loss:-1.893\n",
      "Epoch:  0064 D loss:-0.5915 G loss:-1.915\n",
      "Epoch:  0064 D loss:-0.6505 G loss:-1.987\n",
      "Epoch:  0064 D loss:-0.5823 G loss:-2.083\n",
      "Epoch:  0064 D loss:-0.7727 G loss:-1.86\n",
      "Epoch:  0064 D loss:-0.5996 G loss:-2.385\n",
      "Epoch:  0064 D loss:-0.8696 G loss:-2.112\n",
      "Epoch:  0064 D loss:-0.6518 G loss:-2.216\n",
      "Epoch:  0064 D loss:-0.8278 G loss:-2.075\n",
      "Epoch:  0064 D loss:-0.7709 G loss:-1.952\n",
      "Epoch:  0064 D loss:-0.7157 G loss:-1.87\n",
      "Epoch:  0064 D loss:-0.7923 G loss:-2.021\n",
      "Epoch:  0064 D loss:-0.5612 G loss:-2.209\n",
      "Epoch:  0064 D loss:-0.6824 G loss:-2.025\n",
      "Epoch:  0064 D loss:-0.7061 G loss:-2.092\n",
      "Epoch:  0064 D loss:-0.6665 G loss:-2.034\n",
      "Epoch:  0064 D loss:-0.6934 G loss:-2.158\n",
      "Epoch:  0064 D loss:-0.7173 G loss:-2.006\n",
      "Epoch:  0064 D loss:-0.6859 G loss:-2.139\n",
      "Epoch:  0064 D loss:-0.5988 G loss:-2.145\n",
      "Epoch:  0064 D loss:-0.5929 G loss:-2.084\n",
      "Epoch:  0064 D loss:-0.7038 G loss:-2.448\n",
      "Epoch:  0064 D loss:-0.8466 G loss:-2.154\n",
      "Epoch:  0064 D loss:-0.6438 G loss:-2.247\n",
      "Epoch:  0064 D loss:-0.7074 G loss:-1.943\n",
      "Epoch:  0064 D loss:-0.7856 G loss:-1.861\n",
      "Epoch:  0064 D loss:-0.7262 G loss:-1.814\n",
      "Epoch:  0064 D loss:-0.6926 G loss:-1.984\n",
      "Epoch:  0064 D loss:-0.7835 G loss:-1.942\n",
      "Epoch:  0064 D loss:-0.7092 G loss:-1.951\n",
      "Epoch:  0064 D loss:-0.6673 G loss:-1.94\n",
      "Epoch:  0064 D loss:-0.58 G loss:-2.099\n",
      "Epoch:  0064 D loss:-0.7379 G loss:-2.052\n",
      "Epoch:  0064 D loss:-0.7053 G loss:-2.039\n",
      "Epoch:  0064 D loss:-0.7974 G loss:-1.971\n",
      "Epoch:  0064 D loss:-0.6645 G loss:-2.09\n",
      "Epoch:  0064 D loss:-0.5904 G loss:-2.237\n",
      "Epoch:  0064 D loss:-0.5767 G loss:-2.323\n",
      "Epoch:  0064 D loss:-0.6401 G loss:-2.179\n",
      "Epoch:  0064 D loss:-0.6055 G loss:-2.082\n",
      "Epoch:  0064 D loss:-0.5337 G loss:-2.245\n",
      "Epoch:  0064 D loss:-0.6324 G loss:-2.35\n",
      "Epoch:  0064 D loss:-0.5599 G loss:-2.184\n",
      "Epoch:  0064 D loss:-0.7034 G loss:-2.059\n",
      "Epoch:  0064 D loss:-0.6154 G loss:-2.011\n",
      "Epoch:  0064 D loss:-0.654 G loss:-2.187\n",
      "Epoch:  0064 D loss:-0.6679 G loss:-2.204\n",
      "Epoch:  0064 D loss:-0.6565 G loss:-2.131\n",
      "Epoch:  0064 D loss:-0.6464 G loss:-2.213\n",
      "Epoch:  0064 D loss:-0.6705 G loss:-2.109\n",
      "Epoch:  0064 D loss:-0.8139 G loss:-2.203\n",
      "Epoch:  0064 D loss:-0.6744 G loss:-2.102\n",
      "Epoch:  0064 D loss:-0.573 G loss:-2.188\n",
      "Epoch:  0064 D loss:-0.501 G loss:-2.409\n",
      "Epoch:  0064 D loss:-0.7085 G loss:-2.168\n",
      "Epoch:  0064 D loss:-0.5137 G loss:-2.432\n",
      "Epoch:  0064 D loss:-0.5548 G loss:-2.347\n",
      "Epoch:  0064 D loss:-0.6809 G loss:-2.259\n",
      "Epoch:  0064 D loss:-0.6197 G loss:-2.179\n",
      "Epoch:  0064 D loss:-0.5794 G loss:-2.121\n",
      "Epoch:  0064 D loss:-0.6568 G loss:-2.138\n",
      "Epoch:  0064 D loss:-0.5917 G loss:-1.989\n",
      "Epoch:  0064 D loss:-0.7031 G loss:-2.164\n",
      "Epoch:  0064 D loss:-0.8355 G loss:-1.957\n",
      "Epoch:  0064 D loss:-0.5977 G loss:-2.262\n",
      "Epoch:  0064 D loss:-0.6228 G loss:-1.983\n",
      "Epoch:  0064 D loss:-0.734 G loss:-1.923\n",
      "Epoch:  0064 D loss:-0.6184 G loss:-1.943\n",
      "Epoch:  0064 D loss:-0.5632 G loss:-2.047\n",
      "Epoch:  0064 D loss:-0.6208 G loss:-2.101\n",
      "Epoch:  0064 D loss:-0.7048 G loss:-2.289\n",
      "Epoch:  0064 D loss:-0.8112 G loss:-1.989\n",
      "Epoch:  0064 D loss:-0.7838 G loss:-2.182\n",
      "Epoch:  0064 D loss:-0.7088 G loss:-2.106\n",
      "Epoch:  0064 D loss:-0.5976 G loss:-2.162\n",
      "Epoch:  0064 D loss:-0.7377 G loss:-2.064\n",
      "Epoch:  0064 D loss:-0.6948 G loss:-1.942\n",
      "Epoch:  0064 D loss:-0.5695 G loss:-2.119\n",
      "Epoch:  0064 D loss:-0.8733 G loss:-2.003\n",
      "Epoch:  0064 D loss:-0.767 G loss:-1.844\n",
      "Epoch:  0064 D loss:-0.6333 G loss:-2.019\n",
      "Epoch:  0064 D loss:-0.63 G loss:-1.887\n",
      "Epoch:  0064 D loss:-0.8638 G loss:-1.979\n",
      "Epoch:  0064 D loss:-0.7669 G loss:-2.047\n",
      "Epoch:  0064 D loss:-0.7913 G loss:-1.85\n",
      "Epoch:  0064 D loss:-0.6233 G loss:-2.208\n",
      "Epoch:  0064 D loss:-0.6979 G loss:-1.989\n",
      "Epoch:  0064 D loss:-0.7169 G loss:-1.849\n",
      "Epoch:  0064 D loss:-0.7473 G loss:-2.001\n",
      "Epoch:  0064 D loss:-0.6126 G loss:-2.112\n",
      "Epoch:  0064 D loss:-0.7332 G loss:-2.206\n",
      "Epoch:  0064 D loss:-0.7605 G loss:-2.071\n",
      "Epoch:  0064 D loss:-0.7043 G loss:-2.053\n",
      "Epoch:  0064 D loss:-0.8013 G loss:-1.959\n",
      "Epoch:  0064 D loss:-0.6674 G loss:-2.088\n",
      "Epoch:  0064 D loss:-0.6733 G loss:-1.893\n",
      "Epoch:  0064 D loss:-0.8603 G loss:-1.941\n",
      "Epoch:  0064 D loss:-0.6315 G loss:-1.826\n",
      "Epoch:  0064 D loss:-0.7931 G loss:-1.876\n",
      "Epoch:  0064 D loss:-0.7058 G loss:-1.904\n",
      "Epoch:  0064 D loss:-0.7183 G loss:-1.806\n",
      "Epoch:  0064 D loss:-0.7651 G loss:-1.771\n",
      "Epoch:  0064 D loss:-0.8127 G loss:-1.949\n",
      "Epoch:  0064 D loss:-0.6724 G loss:-2.089\n",
      "Epoch:  0064 D loss:-0.7621 G loss:-1.968\n",
      "Epoch:  0064 D loss:-0.6772 G loss:-2.264\n",
      "Epoch:  0064 D loss:-0.5949 G loss:-2.243\n",
      "Epoch:  0064 D loss:-0.9314 G loss:-2.335\n",
      "Epoch:  0064 D loss:-0.7193 G loss:-2.064\n",
      "Epoch:  0064 D loss:-0.9183 G loss:-1.918\n",
      "Epoch:  0064 D loss:-0.6827 G loss:-2.069\n",
      "Epoch:  0064 D loss:-0.7044 G loss:-1.868\n",
      "Epoch:  0064 D loss:-0.77 G loss:-1.877\n",
      "Epoch:  0064 D loss:-0.7391 G loss:-1.861\n",
      "Epoch:  0064 D loss:-0.7014 G loss:-1.663\n",
      "Epoch:  0064 D loss:-0.7279 G loss:-1.713\n",
      "Epoch:  0064 D loss:-0.728 G loss:-1.668\n",
      "Epoch:  0064 D loss:-0.8864 G loss:-1.676\n",
      "Epoch:  0064 D loss:-0.7589 G loss:-1.799\n",
      "Epoch:  0064 D loss:-0.5929 G loss:-2.137\n",
      "Epoch:  0064 D loss:-0.6592 G loss:-2.201\n",
      "Epoch:  0064 D loss:-0.745 G loss:-2.186\n",
      "Epoch:  0064 D loss:-0.6546 G loss:-2.274\n",
      "Epoch:  0064 D loss:-0.6306 G loss:-2.187\n",
      "Epoch:  0064 D loss:-0.5093 G loss:-2.191\n",
      "Epoch:  0064 D loss:-0.6749 G loss:-2.218\n",
      "Epoch:  0064 D loss:-0.7866 G loss:-2.08\n",
      "Epoch:  0064 D loss:-0.8568 G loss:-1.913\n",
      "Epoch:  0064 D loss:-0.5803 G loss:-2.001\n",
      "Epoch:  0064 D loss:-0.5479 G loss:-1.971\n",
      "Epoch:  0064 D loss:-0.6792 G loss:-1.931\n",
      "Epoch:  0064 D loss:-0.81 G loss:-1.879\n",
      "Epoch:  0064 D loss:-0.888 G loss:-1.996\n",
      "Epoch:  0064 D loss:-0.7302 G loss:-1.717\n",
      "Epoch:  0064 D loss:-0.697 G loss:-1.676\n",
      "Epoch:  0064 D loss:-0.5928 G loss:-1.944\n",
      "Epoch:  0064 D loss:-0.7037 G loss:-1.82\n",
      "Epoch:  0064 D loss:-0.8659 G loss:-1.909\n",
      "Epoch:  0064 D loss:-0.7772 G loss:-2.155\n",
      "Epoch:  0064 D loss:-0.6133 G loss:-2.027\n",
      "Epoch:  0064 D loss:-0.7215 G loss:-2.117\n",
      "Epoch:  0064 D loss:-0.7233 G loss:-2.311\n",
      "Epoch:  0064 D loss:-0.6253 G loss:-2.19\n",
      "Epoch:  0064 D loss:-0.59 G loss:-2.133\n",
      "Epoch:  0064 D loss:-0.6785 G loss:-1.99\n",
      "Epoch:  0064 D loss:-0.8162 G loss:-2.13\n",
      "Epoch:  0064 D loss:-0.6264 G loss:-2.261\n",
      "Epoch:  0064 D loss:-0.6646 G loss:-2.007\n",
      "Epoch:  0064 D loss:-0.6928 G loss:-2.002\n",
      "Epoch:  0064 D loss:-0.7747 G loss:-1.947\n",
      "Epoch:  0064 D loss:-0.7753 G loss:-1.792\n",
      "Epoch:  0064 D loss:-0.6958 G loss:-1.812\n",
      "Epoch:  0064 D loss:-0.5406 G loss:-1.891\n",
      "Epoch:  0064 D loss:-0.6216 G loss:-2.096\n",
      "Epoch:  0064 D loss:-0.7561 G loss:-1.893\n",
      "Epoch:  0064 D loss:-0.5066 G loss:-2.194\n",
      "Epoch:  0064 D loss:-0.5624 G loss:-2.008\n",
      "Epoch:  0064 D loss:-0.5496 G loss:-2.198\n",
      "Epoch:  0064 D loss:-0.6819 G loss:-2.237\n",
      "Epoch:  0064 D loss:-0.7215 G loss:-2.064\n",
      "Epoch:  0064 D loss:-0.6803 G loss:-2.072\n",
      "Epoch:  0064 D loss:-0.6024 G loss:-2.184\n",
      "Epoch:  0064 D loss:-0.6243 G loss:-2.31\n",
      "Epoch:  0064 D loss:-0.6513 G loss:-2.188\n",
      "Epoch:  0064 D loss:-0.7789 G loss:-2.195\n",
      "Epoch:  0064 D loss:-0.6502 G loss:-2.202\n",
      "Epoch:  0064 D loss:-0.6465 G loss:-2.096\n",
      "Epoch:  0064 D loss:-0.699 G loss:-1.873\n",
      "Epoch:  0064 D loss:-0.713 G loss:-1.945\n",
      "Epoch:  0064 D loss:-0.6441 G loss:-1.797\n",
      "Epoch:  0064 D loss:-0.591 G loss:-1.744\n",
      "Epoch:  0064 D loss:-0.6228 G loss:-2.012\n",
      "Epoch:  0064 D loss:-0.6319 G loss:-1.94\n",
      "Epoch:  0064 D loss:-0.8763 G loss:-1.629\n",
      "Epoch:  0064 D loss:-0.589 G loss:-2.16\n",
      "Epoch:  0064 D loss:-0.6206 G loss:-2.225\n",
      "Epoch:  0064 D loss:-0.5906 G loss:-2.284\n",
      "Epoch:  0064 D loss:-0.6451 G loss:-2.155\n",
      "Epoch:  0064 D loss:-0.6583 G loss:-2.028\n",
      "Epoch:  0064 D loss:-0.7107 G loss:-2.268\n",
      "Epoch:  0064 D loss:-0.5278 G loss:-2.125\n",
      "Epoch:  0064 D loss:-0.6541 G loss:-2.302\n",
      "Epoch:  0064 D loss:-0.6945 G loss:-2.088\n",
      "Epoch:  0064 D loss:-0.6132 G loss:-1.965\n",
      "Epoch:  0064 D loss:-0.5922 G loss:-2.065\n",
      "Epoch:  0064 D loss:-0.6533 G loss:-1.951\n",
      "Epoch:  0064 D loss:-0.6524 G loss:-1.978\n",
      "Epoch:  0064 D loss:-0.6756 G loss:-1.904\n",
      "Epoch:  0064 D loss:-0.6612 G loss:-2.067\n",
      "Epoch:  0064 D loss:-0.6863 G loss:-1.998\n",
      "Epoch:  0064 D loss:-0.7197 G loss:-1.948\n",
      "Epoch:  0064 D loss:-0.82 G loss:-2.03\n",
      "Epoch:  0064 D loss:-0.6547 G loss:-2.007\n",
      "Epoch:  0064 D loss:-0.6636 G loss:-2.144\n",
      "Epoch:  0064 D loss:-0.6541 G loss:-2.087\n",
      "Epoch:  0064 D loss:-0.6391 G loss:-2.13\n",
      "Epoch:  0064 D loss:-0.737 G loss:-2.186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0064 D loss:-0.672 G loss:-2.228\n",
      "Epoch:  0064 D loss:-0.5807 G loss:-2.142\n",
      "Epoch:  0064 D loss:-0.5972 G loss:-2.117\n",
      "Epoch:  0064 D loss:-0.712 G loss:-1.939\n",
      "Epoch:  0064 D loss:-0.7664 G loss:-1.969\n",
      "Epoch:  0064 D loss:-0.7552 G loss:-2.053\n",
      "Epoch:  0064 D loss:-0.9201 G loss:-1.805\n",
      "Epoch:  0064 D loss:-0.7033 G loss:-1.846\n",
      "Epoch:  0064 D loss:-0.6645 G loss:-1.867\n",
      "Epoch:  0064 D loss:-0.7081 G loss:-1.888\n",
      "Epoch:  0064 D loss:-0.7203 G loss:-1.726\n",
      "Epoch:  0064 D loss:-0.5293 G loss:-1.964\n",
      "Epoch:  0064 D loss:-0.6436 G loss:-1.896\n",
      "Epoch:  0064 D loss:-0.5842 G loss:-2.183\n",
      "Epoch:  0064 D loss:-0.8354 G loss:-2.134\n",
      "Epoch:  0064 D loss:-0.6785 G loss:-2.216\n",
      "Epoch:  0064 D loss:-0.695 G loss:-2.379\n",
      "Epoch:  0064 D loss:-0.6723 G loss:-2.387\n",
      "Epoch:  0064 D loss:-0.7813 G loss:-2.026\n",
      "Epoch:  0064 D loss:-0.821 G loss:-2.2\n",
      "Epoch:  0064 D loss:-0.7922 G loss:-2.201\n",
      "Epoch:  0064 D loss:-0.7241 G loss:-2.305\n",
      "Epoch:  0064 D loss:-0.8661 G loss:-2.183\n",
      "Epoch:  0064 D loss:-0.7003 G loss:-2.239\n",
      "Epoch:  0064 D loss:-0.7345 G loss:-1.909\n",
      "Epoch:  0064 D loss:-0.8845 G loss:-1.898\n",
      "Epoch:  0064 D loss:-0.8107 G loss:-1.782\n",
      "Epoch:  0064 D loss:-0.5891 G loss:-1.969\n",
      "Epoch:  0064 D loss:-0.8103 G loss:-1.901\n",
      "Epoch:  0064 D loss:-0.6278 G loss:-1.925\n",
      "Epoch:  0064 D loss:-0.7225 G loss:-2.029\n",
      "Epoch:  0064 D loss:-0.7642 G loss:-1.908\n",
      "Epoch:  0064 D loss:-0.7046 G loss:-2.079\n",
      "Epoch:  0064 D loss:-0.6652 G loss:-2.02\n",
      "Epoch:  0064 D loss:-0.7167 G loss:-2.008\n",
      "Epoch:  0064 D loss:-0.6268 G loss:-2.309\n",
      "Epoch:  0064 D loss:-0.6924 G loss:-2.348\n",
      "Epoch:  0064 D loss:-0.5594 G loss:-2.261\n",
      "Epoch:  0064 D loss:-0.6449 G loss:-2.291\n",
      "Epoch:  0064 D loss:-0.6255 G loss:-2.113\n",
      "Epoch:  0064 D loss:-0.61 G loss:-2.265\n",
      "Epoch:  0064 D loss:-0.6723 G loss:-2.024\n",
      "Epoch:  0064 D loss:-0.7152 G loss:-2.036\n",
      "Epoch:  0064 D loss:-0.6409 G loss:-2.097\n",
      "Epoch:  0064 D loss:-0.6615 G loss:-1.978\n",
      "Epoch:  0064 D loss:-0.7252 G loss:-2.225\n",
      "Epoch:  0064 D loss:-0.7939 G loss:-1.975\n",
      "Epoch:  0064 D loss:-0.6874 G loss:-2.117\n",
      "Epoch:  0064 D loss:-0.667 G loss:-2.021\n",
      "Epoch:  0064 D loss:-0.6632 G loss:-2.179\n",
      "Epoch:  0064 D loss:-0.7031 G loss:-2.109\n",
      "Epoch:  0064 D loss:-0.6596 G loss:-2.108\n",
      "Epoch:  0064 D loss:-0.7148 G loss:-1.994\n",
      "Epoch:  0064 D loss:-0.7654 G loss:-2.071\n",
      "Epoch:  0064 D loss:-0.64 G loss:-2.244\n",
      "Epoch:  0064 D loss:-0.6585 G loss:-2.157\n",
      "Epoch:  0064 D loss:-0.7233 G loss:-2.227\n",
      "Epoch:  0064 D loss:-0.6791 G loss:-1.996\n",
      "Epoch:  0064 D loss:-0.7524 G loss:-2.061\n",
      "Epoch:  0064 D loss:-0.6134 G loss:-2.285\n",
      "Epoch:  0064 D loss:-0.6423 G loss:-2.039\n",
      "Epoch:  0064 D loss:-0.6783 G loss:-2.067\n",
      "Epoch:  0064 D loss:-0.5132 G loss:-2.147\n",
      "Epoch:  0064 D loss:-0.6951 G loss:-2.115\n",
      "Epoch:  0064 D loss:-0.6665 G loss:-2.265\n",
      "Epoch:  0064 D loss:-0.7617 G loss:-1.955\n",
      "Epoch:  0064 D loss:-0.8267 G loss:-2.024\n",
      "Epoch:  0064 D loss:-0.7834 G loss:-1.947\n",
      "Epoch:  0064 D loss:-0.7151 G loss:-1.97\n",
      "Epoch:  0064 D loss:-0.5253 G loss:-2.141\n",
      "Epoch:  0064 D loss:-0.7106 G loss:-1.997\n",
      "Epoch:  0064 D loss:-0.5792 G loss:-2.217\n",
      "Epoch:  0064 D loss:-0.6732 G loss:-2.025\n",
      "Epoch:  0064 D loss:-0.6838 G loss:-2.061\n",
      "Epoch:  0064 D loss:-0.8091 G loss:-2.109\n",
      "Epoch:  0064 D loss:-0.6762 G loss:-2.238\n",
      "Epoch:  0064 D loss:-0.7467 G loss:-2.314\n",
      "Epoch:  0064 D loss:-0.6397 G loss:-2.039\n",
      "Epoch:  0064 D loss:-0.596 G loss:-2.141\n",
      "Epoch:  0064 D loss:-0.5988 G loss:-2.207\n",
      "Epoch:  0064 D loss:-0.68 G loss:-2.087\n",
      "Epoch:  0064 D loss:-0.633 G loss:-2.28\n",
      "Epoch:  0064 D loss:-0.6842 G loss:-1.882\n",
      "Epoch:  0064 D loss:-0.7203 G loss:-2.071\n",
      "Epoch:  0064 D loss:-0.6681 G loss:-1.902\n",
      "Epoch:  0064 D loss:-0.661 G loss:-2.154\n",
      "Epoch:  0064 D loss:-0.7143 G loss:-2.123\n",
      "Epoch:  0064 D loss:-0.7462 G loss:-2.235\n",
      "Epoch:  0064 D loss:-0.7219 G loss:-1.927\n",
      "Epoch:  0064 D loss:-0.6997 G loss:-1.959\n",
      "Epoch:  0064 D loss:-0.663 G loss:-2.18\n",
      "Epoch:  0064 D loss:-0.752 G loss:-2.266\n",
      "Epoch:  0064 D loss:-0.8053 G loss:-2.137\n",
      "Epoch:  0064 D loss:-0.7289 G loss:-2.036\n",
      "Epoch:  0064 D loss:-0.6227 G loss:-2.0\n",
      "Epoch:  0064 D loss:-0.7841 G loss:-1.963\n",
      "Epoch:  0064 D loss:-0.6226 G loss:-2.205\n",
      "Epoch:  0064 D loss:-0.6368 G loss:-1.998\n",
      "Epoch:  0064 D loss:-0.5366 G loss:-2.25\n",
      "Epoch:  0064 D loss:-0.7034 G loss:-2.191\n",
      "Epoch:  0064 D loss:-0.6698 G loss:-2.197\n",
      "Epoch:  0064 D loss:-0.7336 G loss:-2.187\n",
      "Epoch:  0064 D loss:-0.699 G loss:-2.137\n",
      "Epoch:  0064 D loss:-0.5708 G loss:-2.151\n",
      "Epoch:  0064 D loss:-0.6758 G loss:-2.13\n",
      "Epoch:  0064 D loss:-0.5655 G loss:-2.162\n",
      "Epoch:  0064 D loss:-0.7324 G loss:-1.857\n",
      "Epoch:  0064 D loss:-0.6264 G loss:-2.13\n",
      "Epoch:  0064 D loss:-0.597 G loss:-2.006\n",
      "Epoch:  0064 D loss:-1.012 G loss:-1.986\n",
      "Epoch:  0064 D loss:-0.6345 G loss:-2.047\n",
      "Epoch:  0064 D loss:-0.7668 G loss:-1.907\n",
      "Epoch:  0064 D loss:-0.7056 G loss:-2.065\n",
      "Epoch:  0064 D loss:-0.6637 G loss:-2.262\n",
      "Epoch:  0064 D loss:-0.5816 G loss:-2.086\n",
      "Epoch:  0064 D loss:-0.6789 G loss:-2.186\n",
      "Epoch:  0064 D loss:-0.7379 G loss:-2.099\n",
      "Epoch:  0064 D loss:-0.6854 G loss:-2.228\n",
      "Epoch:  0064 D loss:-0.6707 G loss:-2.168\n",
      "Epoch:  0064 D loss:-0.6237 G loss:-2.122\n",
      "Epoch:  0064 D loss:-0.8337 G loss:-1.902\n",
      "Epoch:  0064 D loss:-0.5989 G loss:-2.062\n",
      "Epoch:  0064 D loss:-0.6961 G loss:-1.956\n",
      "Epoch:  0064 D loss:-0.5898 G loss:-1.77\n",
      "Epoch:  0064 D loss:-0.6306 G loss:-1.922\n",
      "Epoch:  0064 D loss:-0.5611 G loss:-2.198\n",
      "Epoch:  0064 D loss:-0.5983 G loss:-2.011\n",
      "Epoch:  0064 D loss:-0.6209 G loss:-2.041\n",
      "Epoch:  0064 D loss:-0.7039 G loss:-2.018\n",
      "Epoch:  0064 D loss:-0.5478 G loss:-2.329\n",
      "Epoch:  0064 D loss:-0.5303 G loss:-2.191\n",
      "Epoch:  0064 D loss:-0.7369 G loss:-2.218\n",
      "Epoch:  0064 D loss:-0.6866 G loss:-2.181\n",
      "Epoch:  0064 D loss:-0.6985 G loss:-2.19\n",
      "Epoch:  0064 D loss:-0.6902 G loss:-2.316\n",
      "Epoch:  0064 D loss:-0.5666 G loss:-2.221\n",
      "Epoch:  0064 D loss:-0.7292 G loss:-2.265\n",
      "Epoch:  0064 D loss:-0.8026 G loss:-2.126\n",
      "Epoch:  0064 D loss:-0.7244 G loss:-1.906\n",
      "Epoch:  0064 D loss:-0.6269 G loss:-2.212\n",
      "Epoch:  0064 D loss:-0.6969 G loss:-2.034\n",
      "Epoch:  0064 D loss:-0.6544 G loss:-2.01\n",
      "Epoch:  0064 D loss:-0.6609 G loss:-2.073\n",
      "Epoch:  0064 D loss:-0.5913 G loss:-2.022\n",
      "Epoch:  0064 D loss:-0.5456 G loss:-2.188\n",
      "Epoch:  0064 D loss:-0.6962 G loss:-2.213\n",
      "Epoch:  0064 D loss:-0.5 G loss:-2.167\n",
      "Epoch:  0064 D loss:-0.6305 G loss:-2.211\n",
      "Epoch:  0064 D loss:-0.6886 G loss:-2.05\n",
      "Epoch:  0064 D loss:-0.6391 G loss:-2.05\n",
      "Epoch:  0064 D loss:-0.6407 G loss:-2.252\n",
      "Epoch:  0064 D loss:-0.5921 G loss:-2.495\n",
      "Epoch:  0064 D loss:-0.7225 G loss:-2.295\n",
      "Epoch:  0064 D loss:-0.6946 G loss:-2.043\n",
      "Epoch:  0064 D loss:-0.5883 G loss:-2.176\n",
      "Epoch:  0064 D loss:-0.686 G loss:-1.94\n",
      "Epoch:  0064 D loss:-0.7003 G loss:-1.902\n",
      "Epoch:  0064 D loss:-0.7298 G loss:-1.935\n",
      "Epoch:  0064 D loss:-0.6952 G loss:-2.089\n",
      "Epoch:  0064 D loss:-0.6099 G loss:-1.998\n",
      "Epoch:  0064 D loss:-0.6878 G loss:-2.052\n",
      "Epoch:  0064 D loss:-0.7432 G loss:-2.184\n",
      "Epoch:  0064 D loss:-0.7883 G loss:-2.064\n",
      "Epoch:  0064 D loss:-0.6557 G loss:-2.034\n",
      "Epoch:  0064 D loss:-0.7293 G loss:-2.284\n",
      "Epoch:  0064 D loss:-0.7127 G loss:-2.152\n",
      "Epoch:  0064 D loss:-0.6436 G loss:-2.012\n",
      "Epoch:  0064 D loss:-0.6168 G loss:-2.176\n",
      "Epoch:  0064 D loss:-0.5211 G loss:-2.209\n",
      "Epoch:  0064 D loss:-0.6438 G loss:-2.105\n",
      "Epoch:  0064 D loss:-0.5195 G loss:-2.302\n",
      "Epoch:  0064 D loss:-0.5738 G loss:-2.19\n",
      "Epoch:  0064 D loss:-0.7464 G loss:-2.087\n",
      "Epoch:  0064 D loss:-0.6498 G loss:-2.092\n",
      "Epoch:  0064 D loss:-0.5466 G loss:-2.131\n",
      "Epoch:  0064 D loss:-0.6788 G loss:-1.988\n",
      "Epoch:  0064 D loss:-0.6242 G loss:-2.103\n",
      "Epoch:  0064 D loss:-0.7337 G loss:-2.142\n",
      "Epoch:  0064 D loss:-0.6767 G loss:-1.881\n",
      "Epoch:  0064 D loss:-0.6136 G loss:-1.989\n",
      "Epoch:  0064 D loss:-0.7535 G loss:-2.084\n",
      "Epoch:  0064 D loss:-0.7527 G loss:-2.045\n",
      "Epoch:  0064 D loss:-0.711 G loss:-2.224\n",
      "Epoch:  0064 D loss:-0.6846 G loss:-2.121\n",
      "Epoch:  0064 D loss:-0.6537 G loss:-2.171\n",
      "Epoch:  0064 D loss:-0.827 G loss:-2.209\n",
      "Epoch:  0064 D loss:-0.7113 G loss:-2.158\n",
      "Epoch:  0064 D loss:-0.718 G loss:-2.033\n",
      "Epoch:  0064 D loss:-0.6356 G loss:-2.016\n",
      "Epoch:  0064 D loss:-0.7339 G loss:-1.958\n",
      "Epoch:  0064 D loss:-0.6513 G loss:-1.948\n",
      "Epoch:  0064 D loss:-0.6092 G loss:-2.106\n",
      "Epoch:  0064 D loss:-0.6869 G loss:-1.909\n",
      "Epoch:  0064 D loss:-0.671 G loss:-2.174\n",
      "Epoch:  0064 D loss:-0.6182 G loss:-2.316\n",
      "Epoch:  0064 D loss:-0.769 G loss:-1.997\n",
      "Epoch:  0064 D loss:-0.9301 G loss:-2.117\n",
      "Epoch:  0064 D loss:-0.7423 G loss:-1.811\n",
      "Epoch:  0064 D loss:-0.7469 G loss:-1.989\n",
      "Epoch:  0064 D loss:-0.7012 G loss:-1.903\n",
      "Epoch:  0064 D loss:-0.7743 G loss:-1.843\n",
      "Epoch:  0064 D loss:-0.6996 G loss:-2.023\n",
      "Epoch:  0064 D loss:-0.6824 G loss:-2.031\n",
      "Epoch:  0064 D loss:-0.7648 G loss:-1.863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0064 D loss:-0.7303 G loss:-2.131\n",
      "Epoch:  0064 D loss:-0.6696 G loss:-1.951\n",
      "Epoch:  0064 D loss:-0.6226 G loss:-2.134\n",
      "Epoch:  0064 D loss:-0.7536 G loss:-1.952\n",
      "Epoch:  0064 D loss:-0.5968 G loss:-2.154\n",
      "Epoch:  0064 D loss:-0.5935 G loss:-2.125\n",
      "Epoch:  0064 D loss:-0.7763 G loss:-2.118\n",
      "Epoch:  0064 D loss:-0.7989 G loss:-2.114\n",
      "Epoch:  0064 D loss:-0.6985 G loss:-2.185\n",
      "Epoch:  0064 D loss:-0.9127 G loss:-2.064\n",
      "Epoch:  0064 D loss:-0.7558 G loss:-1.989\n",
      "Epoch:  0065 D loss:-0.7332 G loss:-1.846\n",
      "Epoch:  0065 D loss:-0.5721 G loss:-1.726\n",
      "Epoch:  0065 D loss:-0.6305 G loss:-1.951\n",
      "Epoch:  0065 D loss:-0.6876 G loss:-1.901\n",
      "Epoch:  0065 D loss:-0.8543 G loss:-1.926\n",
      "Epoch:  0065 D loss:-0.6753 G loss:-2.114\n",
      "Epoch:  0065 D loss:-0.5538 G loss:-2.157\n",
      "Epoch:  0065 D loss:-0.8658 G loss:-1.993\n",
      "Epoch:  0065 D loss:-0.6406 G loss:-2.225\n",
      "Epoch:  0065 D loss:-0.613 G loss:-2.308\n",
      "Epoch:  0065 D loss:-0.6734 G loss:-2.376\n",
      "Epoch:  0065 D loss:-0.6173 G loss:-2.143\n",
      "Epoch:  0065 D loss:-0.6566 G loss:-2.237\n",
      "Epoch:  0065 D loss:-0.7804 G loss:-2.123\n",
      "Epoch:  0065 D loss:-0.6616 G loss:-2.074\n",
      "Epoch:  0065 D loss:-0.7828 G loss:-1.949\n",
      "Epoch:  0065 D loss:-0.8269 G loss:-1.725\n",
      "Epoch:  0065 D loss:-0.6917 G loss:-1.796\n",
      "Epoch:  0065 D loss:-0.5622 G loss:-2.007\n",
      "Epoch:  0065 D loss:-0.6386 G loss:-2.209\n",
      "Epoch:  0065 D loss:-0.7041 G loss:-1.91\n",
      "Epoch:  0065 D loss:-0.6273 G loss:-1.971\n",
      "Epoch:  0065 D loss:-0.7404 G loss:-2.0\n",
      "Epoch:  0065 D loss:-0.6657 G loss:-2.022\n",
      "Epoch:  0065 D loss:-0.725 G loss:-2.096\n",
      "Epoch:  0065 D loss:-0.5842 G loss:-2.314\n",
      "Epoch:  0065 D loss:-0.8795 G loss:-2.01\n",
      "Epoch:  0065 D loss:-0.6458 G loss:-2.238\n",
      "Epoch:  0065 D loss:-0.8324 G loss:-1.948\n",
      "Epoch:  0065 D loss:-0.6663 G loss:-2.2\n",
      "Epoch:  0065 D loss:-0.6986 G loss:-2.258\n",
      "Epoch:  0065 D loss:-0.9074 G loss:-1.906\n",
      "Epoch:  0065 D loss:-0.9 G loss:-1.736\n",
      "Epoch:  0065 D loss:-0.9977 G loss:-1.446\n",
      "Epoch:  0065 D loss:-0.6794 G loss:-1.682\n",
      "Epoch:  0065 D loss:-0.6875 G loss:-1.811\n",
      "Epoch:  0065 D loss:-0.7239 G loss:-1.703\n",
      "Epoch:  0065 D loss:-0.7545 G loss:-1.847\n",
      "Epoch:  0065 D loss:-0.7185 G loss:-1.766\n",
      "Epoch:  0065 D loss:-0.6263 G loss:-1.966\n",
      "Epoch:  0065 D loss:-0.5861 G loss:-2.179\n",
      "Epoch:  0065 D loss:-0.6763 G loss:-2.092\n",
      "Epoch:  0065 D loss:-0.725 G loss:-2.358\n",
      "Epoch:  0065 D loss:-0.5114 G loss:-2.246\n",
      "Epoch:  0065 D loss:-0.6756 G loss:-2.311\n",
      "Epoch:  0065 D loss:-0.5652 G loss:-2.285\n",
      "Epoch:  0065 D loss:-0.6724 G loss:-2.167\n",
      "Epoch:  0065 D loss:-0.614 G loss:-2.14\n",
      "Epoch:  0065 D loss:-0.7201 G loss:-2.212\n",
      "Epoch:  0065 D loss:-0.6568 G loss:-2.137\n",
      "Epoch:  0065 D loss:-0.7199 G loss:-1.808\n",
      "Epoch:  0065 D loss:-0.5906 G loss:-2.061\n",
      "Epoch:  0065 D loss:-0.6676 G loss:-1.958\n",
      "Epoch:  0065 D loss:-0.515 G loss:-1.976\n",
      "Epoch:  0065 D loss:-0.6065 G loss:-1.978\n",
      "Epoch:  0065 D loss:-0.5412 G loss:-2.016\n",
      "Epoch:  0065 D loss:-0.6449 G loss:-1.933\n",
      "Epoch:  0065 D loss:-0.7293 G loss:-2.141\n",
      "Epoch:  0065 D loss:-0.611 G loss:-2.075\n",
      "Epoch:  0065 D loss:-0.7746 G loss:-2.14\n",
      "Epoch:  0065 D loss:-0.6722 G loss:-2.242\n",
      "Epoch:  0065 D loss:-0.786 G loss:-1.959\n",
      "Epoch:  0065 D loss:-0.6736 G loss:-2.086\n",
      "Epoch:  0065 D loss:-0.6983 G loss:-1.826\n",
      "Epoch:  0065 D loss:-0.685 G loss:-1.998\n",
      "Epoch:  0065 D loss:-0.7451 G loss:-1.953\n",
      "Epoch:  0065 D loss:-0.7107 G loss:-1.95\n",
      "Epoch:  0065 D loss:-0.65 G loss:-2.008\n",
      "Epoch:  0065 D loss:-0.7733 G loss:-1.846\n",
      "Epoch:  0065 D loss:-0.706 G loss:-2.038\n",
      "Epoch:  0065 D loss:-0.6727 G loss:-2.092\n",
      "Epoch:  0065 D loss:-0.656 G loss:-1.849\n",
      "Epoch:  0065 D loss:-0.6678 G loss:-2.123\n",
      "Epoch:  0065 D loss:-0.6962 G loss:-2.085\n",
      "Epoch:  0065 D loss:-0.7965 G loss:-2.183\n",
      "Epoch:  0065 D loss:-0.7152 G loss:-2.087\n",
      "Epoch:  0065 D loss:-0.7074 G loss:-1.914\n",
      "Epoch:  0065 D loss:-0.6458 G loss:-1.999\n",
      "Epoch:  0065 D loss:-0.5043 G loss:-2.157\n",
      "Epoch:  0065 D loss:-0.6244 G loss:-1.809\n",
      "Epoch:  0065 D loss:-0.6387 G loss:-1.965\n",
      "Epoch:  0065 D loss:-0.5837 G loss:-2.014\n",
      "Epoch:  0065 D loss:-0.6255 G loss:-2.087\n",
      "Epoch:  0065 D loss:-0.5812 G loss:-1.904\n",
      "Epoch:  0065 D loss:-0.6924 G loss:-2.023\n",
      "Epoch:  0065 D loss:-0.731 G loss:-1.882\n",
      "Epoch:  0065 D loss:-0.7052 G loss:-1.928\n",
      "Epoch:  0065 D loss:-0.7429 G loss:-1.932\n",
      "Epoch:  0065 D loss:-0.7834 G loss:-2.099\n",
      "Epoch:  0065 D loss:-0.7794 G loss:-2.194\n",
      "Epoch:  0065 D loss:-0.781 G loss:-1.957\n",
      "Epoch:  0065 D loss:-0.7349 G loss:-2.162\n",
      "Epoch:  0065 D loss:-0.825 G loss:-2.032\n",
      "Epoch:  0065 D loss:-0.6849 G loss:-1.838\n",
      "Epoch:  0065 D loss:-0.6739 G loss:-1.95\n",
      "Epoch:  0065 D loss:-0.6905 G loss:-1.926\n",
      "Epoch:  0065 D loss:-0.761 G loss:-1.788\n",
      "Epoch:  0065 D loss:-0.6828 G loss:-1.992\n",
      "Epoch:  0065 D loss:-0.6978 G loss:-2.037\n",
      "Epoch:  0065 D loss:-0.6686 G loss:-2.013\n",
      "Epoch:  0065 D loss:-0.5832 G loss:-2.197\n",
      "Epoch:  0065 D loss:-0.6126 G loss:-1.948\n",
      "Epoch:  0065 D loss:-0.6755 G loss:-2.039\n",
      "Epoch:  0065 D loss:-0.8293 G loss:-1.951\n",
      "Epoch:  0065 D loss:-0.7796 G loss:-1.912\n",
      "Epoch:  0065 D loss:-0.6603 G loss:-2.11\n",
      "Epoch:  0065 D loss:-0.6871 G loss:-1.981\n",
      "Epoch:  0065 D loss:-0.643 G loss:-1.995\n",
      "Epoch:  0065 D loss:-0.7228 G loss:-1.759\n",
      "Epoch:  0065 D loss:-0.6099 G loss:-1.928\n",
      "Epoch:  0065 D loss:-0.5112 G loss:-1.857\n",
      "Epoch:  0065 D loss:-0.6156 G loss:-1.869\n",
      "Epoch:  0065 D loss:-0.7013 G loss:-1.713\n",
      "Epoch:  0065 D loss:-0.7017 G loss:-1.772\n",
      "Epoch:  0065 D loss:-0.6612 G loss:-2.053\n",
      "Epoch:  0065 D loss:-0.6633 G loss:-2.077\n",
      "Epoch:  0065 D loss:-0.5602 G loss:-2.094\n",
      "Epoch:  0065 D loss:-0.6646 G loss:-2.223\n",
      "Epoch:  0065 D loss:-0.6196 G loss:-2.411\n",
      "Epoch:  0065 D loss:-0.6949 G loss:-2.231\n",
      "Epoch:  0065 D loss:-0.7882 G loss:-2.1\n",
      "Epoch:  0065 D loss:-0.7008 G loss:-2.022\n",
      "Epoch:  0065 D loss:-0.667 G loss:-1.88\n",
      "Epoch:  0065 D loss:-0.7156 G loss:-1.976\n",
      "Epoch:  0065 D loss:-0.7164 G loss:-1.834\n",
      "Epoch:  0065 D loss:-0.7326 G loss:-2.017\n",
      "Epoch:  0065 D loss:-0.6871 G loss:-1.977\n",
      "Epoch:  0065 D loss:-0.6243 G loss:-1.864\n",
      "Epoch:  0065 D loss:-0.7698 G loss:-1.873\n",
      "Epoch:  0065 D loss:-0.5996 G loss:-1.977\n",
      "Epoch:  0065 D loss:-0.7076 G loss:-2.117\n",
      "Epoch:  0065 D loss:-0.6398 G loss:-1.923\n",
      "Epoch:  0065 D loss:-0.6908 G loss:-2.031\n",
      "Epoch:  0065 D loss:-0.648 G loss:-2.259\n",
      "Epoch:  0065 D loss:-0.7112 G loss:-1.917\n",
      "Epoch:  0065 D loss:-0.6098 G loss:-2.099\n",
      "Epoch:  0065 D loss:-0.6547 G loss:-2.158\n",
      "Epoch:  0065 D loss:-0.6357 G loss:-2.304\n",
      "Epoch:  0065 D loss:-0.7008 G loss:-2.105\n",
      "Epoch:  0065 D loss:-0.6728 G loss:-2.055\n",
      "Epoch:  0065 D loss:-0.8505 G loss:-2.005\n",
      "Epoch:  0065 D loss:-0.6828 G loss:-1.777\n",
      "Epoch:  0065 D loss:-0.6504 G loss:-1.793\n",
      "Epoch:  0065 D loss:-0.6201 G loss:-2.087\n",
      "Epoch:  0065 D loss:-0.6929 G loss:-1.909\n",
      "Epoch:  0065 D loss:-0.7654 G loss:-1.793\n",
      "Epoch:  0065 D loss:-0.6297 G loss:-2.186\n",
      "Epoch:  0065 D loss:-0.7435 G loss:-2.181\n",
      "Epoch:  0065 D loss:-0.6356 G loss:-2.063\n",
      "Epoch:  0065 D loss:-0.7207 G loss:-1.988\n",
      "Epoch:  0065 D loss:-0.6863 G loss:-1.919\n",
      "Epoch:  0065 D loss:-0.7804 G loss:-1.843\n",
      "Epoch:  0065 D loss:-0.8549 G loss:-1.882\n",
      "Epoch:  0065 D loss:-0.7 G loss:-1.845\n",
      "Epoch:  0065 D loss:-0.5956 G loss:-1.886\n",
      "Epoch:  0065 D loss:-0.6265 G loss:-1.986\n",
      "Epoch:  0065 D loss:-0.6723 G loss:-1.958\n",
      "Epoch:  0065 D loss:-0.591 G loss:-2.01\n",
      "Epoch:  0065 D loss:-0.7653 G loss:-1.896\n",
      "Epoch:  0065 D loss:-0.6648 G loss:-2.09\n",
      "Epoch:  0065 D loss:-0.8028 G loss:-1.845\n",
      "Epoch:  0065 D loss:-0.7205 G loss:-2.189\n",
      "Epoch:  0065 D loss:-0.7141 G loss:-2.005\n",
      "Epoch:  0065 D loss:-0.7237 G loss:-2.063\n",
      "Epoch:  0065 D loss:-0.6447 G loss:-2.002\n",
      "Epoch:  0065 D loss:-0.6233 G loss:-2.242\n",
      "Epoch:  0065 D loss:-0.7454 G loss:-2.075\n",
      "Epoch:  0065 D loss:-0.7644 G loss:-2.157\n",
      "Epoch:  0065 D loss:-0.6541 G loss:-2.054\n",
      "Epoch:  0065 D loss:-0.7337 G loss:-1.973\n",
      "Epoch:  0065 D loss:-0.6328 G loss:-2.101\n",
      "Epoch:  0065 D loss:-0.706 G loss:-1.97\n",
      "Epoch:  0065 D loss:-0.7711 G loss:-2.035\n",
      "Epoch:  0065 D loss:-0.5972 G loss:-1.886\n",
      "Epoch:  0065 D loss:-0.7281 G loss:-2.016\n",
      "Epoch:  0065 D loss:-0.7793 G loss:-1.938\n",
      "Epoch:  0065 D loss:-0.7719 G loss:-2.056\n",
      "Epoch:  0065 D loss:-0.7009 G loss:-1.917\n",
      "Epoch:  0065 D loss:-0.8557 G loss:-1.902\n",
      "Epoch:  0065 D loss:-0.7578 G loss:-2.075\n",
      "Epoch:  0065 D loss:-0.6585 G loss:-2.055\n",
      "Epoch:  0065 D loss:-0.53 G loss:-2.175\n",
      "Epoch:  0065 D loss:-0.6838 G loss:-2.063\n",
      "Epoch:  0065 D loss:-0.7515 G loss:-2.189\n",
      "Epoch:  0065 D loss:-0.7663 G loss:-2.175\n",
      "Epoch:  0065 D loss:-0.6045 G loss:-2.068\n",
      "Epoch:  0065 D loss:-0.7618 G loss:-2.172\n",
      "Epoch:  0065 D loss:-0.8255 G loss:-1.824\n",
      "Epoch:  0065 D loss:-0.7219 G loss:-1.933\n",
      "Epoch:  0065 D loss:-0.6307 G loss:-2.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0065 D loss:-0.7581 G loss:-1.971\n",
      "Epoch:  0065 D loss:-0.7073 G loss:-1.888\n",
      "Epoch:  0065 D loss:-0.7263 G loss:-2.083\n",
      "Epoch:  0065 D loss:-0.6886 G loss:-2.088\n",
      "Epoch:  0065 D loss:-0.6885 G loss:-2.204\n",
      "Epoch:  0065 D loss:-0.6193 G loss:-2.192\n",
      "Epoch:  0065 D loss:-0.6961 G loss:-1.936\n",
      "Epoch:  0065 D loss:-0.6405 G loss:-2.223\n",
      "Epoch:  0065 D loss:-0.6005 G loss:-2.195\n",
      "Epoch:  0065 D loss:-0.7512 G loss:-1.984\n",
      "Epoch:  0065 D loss:-0.6673 G loss:-2.212\n",
      "Epoch:  0065 D loss:-0.681 G loss:-2.083\n",
      "Epoch:  0065 D loss:-0.8192 G loss:-2.134\n",
      "Epoch:  0065 D loss:-0.6185 G loss:-2.189\n",
      "Epoch:  0065 D loss:-0.7163 G loss:-2.133\n",
      "Epoch:  0065 D loss:-0.8208 G loss:-1.856\n",
      "Epoch:  0065 D loss:-0.7049 G loss:-1.991\n",
      "Epoch:  0065 D loss:-0.773 G loss:-2.009\n",
      "Epoch:  0065 D loss:-0.7742 G loss:-1.843\n",
      "Epoch:  0065 D loss:-0.8211 G loss:-1.806\n",
      "Epoch:  0065 D loss:-0.7761 G loss:-1.965\n",
      "Epoch:  0065 D loss:-0.6834 G loss:-1.941\n",
      "Epoch:  0065 D loss:-0.6429 G loss:-2.212\n",
      "Epoch:  0065 D loss:-0.5657 G loss:-2.298\n",
      "Epoch:  0065 D loss:-0.6957 G loss:-2.124\n",
      "Epoch:  0065 D loss:-0.6543 G loss:-2.237\n",
      "Epoch:  0065 D loss:-0.6475 G loss:-2.245\n",
      "Epoch:  0065 D loss:-0.754 G loss:-2.034\n",
      "Epoch:  0065 D loss:-0.7299 G loss:-2.081\n",
      "Epoch:  0065 D loss:-0.7279 G loss:-2.184\n",
      "Epoch:  0065 D loss:-0.7383 G loss:-2.03\n",
      "Epoch:  0065 D loss:-0.7042 G loss:-2.089\n",
      "Epoch:  0065 D loss:-0.6888 G loss:-2.119\n",
      "Epoch:  0065 D loss:-0.6642 G loss:-1.959\n",
      "Epoch:  0065 D loss:-0.7419 G loss:-1.847\n",
      "Epoch:  0065 D loss:-0.6884 G loss:-1.97\n",
      "Epoch:  0065 D loss:-0.656 G loss:-2.284\n",
      "Epoch:  0065 D loss:-0.5755 G loss:-2.193\n",
      "Epoch:  0065 D loss:-0.7411 G loss:-2.248\n",
      "Epoch:  0065 D loss:-0.7322 G loss:-2.293\n",
      "Epoch:  0065 D loss:-0.6873 G loss:-2.257\n",
      "Epoch:  0065 D loss:-0.5893 G loss:-2.189\n",
      "Epoch:  0065 D loss:-0.6871 G loss:-2.134\n",
      "Epoch:  0065 D loss:-0.617 G loss:-2.188\n",
      "Epoch:  0065 D loss:-0.774 G loss:-2.046\n",
      "Epoch:  0065 D loss:-0.6769 G loss:-2.023\n",
      "Epoch:  0065 D loss:-0.7099 G loss:-1.908\n",
      "Epoch:  0065 D loss:-0.804 G loss:-1.816\n",
      "Epoch:  0065 D loss:-0.8367 G loss:-1.903\n",
      "Epoch:  0065 D loss:-0.6551 G loss:-2.012\n",
      "Epoch:  0065 D loss:-0.7515 G loss:-1.968\n",
      "Epoch:  0065 D loss:-0.6759 G loss:-1.927\n",
      "Epoch:  0065 D loss:-0.7168 G loss:-2.185\n",
      "Epoch:  0065 D loss:-0.6617 G loss:-2.165\n",
      "Epoch:  0065 D loss:-0.788 G loss:-2.046\n",
      "Epoch:  0065 D loss:-0.7236 G loss:-2.276\n",
      "Epoch:  0065 D loss:-0.4516 G loss:-2.182\n",
      "Epoch:  0065 D loss:-0.6211 G loss:-1.989\n",
      "Epoch:  0065 D loss:-0.5383 G loss:-2.318\n",
      "Epoch:  0065 D loss:-0.7776 G loss:-2.002\n",
      "Epoch:  0065 D loss:-0.6673 G loss:-2.322\n",
      "Epoch:  0065 D loss:-0.6471 G loss:-2.126\n",
      "Epoch:  0065 D loss:-0.6921 G loss:-2.086\n",
      "Epoch:  0065 D loss:-0.5715 G loss:-2.191\n",
      "Epoch:  0065 D loss:-0.8024 G loss:-2.048\n",
      "Epoch:  0065 D loss:-0.7158 G loss:-2.168\n",
      "Epoch:  0065 D loss:-0.7215 G loss:-2.002\n",
      "Epoch:  0065 D loss:-0.5719 G loss:-1.969\n",
      "Epoch:  0065 D loss:-0.9225 G loss:-1.736\n",
      "Epoch:  0065 D loss:-0.7367 G loss:-1.804\n",
      "Epoch:  0065 D loss:-0.6648 G loss:-2.059\n",
      "Epoch:  0065 D loss:-0.6399 G loss:-2.165\n",
      "Epoch:  0065 D loss:-0.6434 G loss:-2.112\n",
      "Epoch:  0065 D loss:-0.6414 G loss:-1.918\n",
      "Epoch:  0065 D loss:-0.5887 G loss:-2.264\n",
      "Epoch:  0065 D loss:-0.77 G loss:-2.255\n",
      "Epoch:  0065 D loss:-0.6759 G loss:-2.22\n",
      "Epoch:  0065 D loss:-0.6932 G loss:-2.287\n",
      "Epoch:  0065 D loss:-0.7173 G loss:-2.203\n",
      "Epoch:  0065 D loss:-0.8161 G loss:-2.26\n",
      "Epoch:  0065 D loss:-0.9241 G loss:-2.011\n",
      "Epoch:  0065 D loss:-0.6983 G loss:-2.06\n",
      "Epoch:  0065 D loss:-0.7405 G loss:-1.876\n",
      "Epoch:  0065 D loss:-0.7096 G loss:-1.83\n",
      "Epoch:  0065 D loss:-0.641 G loss:-1.727\n",
      "Epoch:  0065 D loss:-0.8005 G loss:-1.715\n",
      "Epoch:  0065 D loss:-0.8654 G loss:-1.653\n",
      "Epoch:  0065 D loss:-0.6662 G loss:-2.07\n",
      "Epoch:  0065 D loss:-0.7394 G loss:-1.978\n",
      "Epoch:  0065 D loss:-0.6965 G loss:-2.095\n",
      "Epoch:  0065 D loss:-0.6297 G loss:-2.394\n",
      "Epoch:  0065 D loss:-0.7763 G loss:-2.027\n",
      "Epoch:  0065 D loss:-0.7576 G loss:-2.103\n",
      "Epoch:  0065 D loss:-0.7314 G loss:-1.904\n",
      "Epoch:  0065 D loss:-0.8197 G loss:-1.993\n",
      "Epoch:  0065 D loss:-0.6504 G loss:-2.1\n",
      "Epoch:  0065 D loss:-0.7518 G loss:-2.191\n",
      "Epoch:  0065 D loss:-0.5356 G loss:-2.229\n",
      "Epoch:  0065 D loss:-0.5162 G loss:-2.319\n",
      "Epoch:  0065 D loss:-0.6525 G loss:-2.075\n",
      "Epoch:  0065 D loss:-0.542 G loss:-2.273\n",
      "Epoch:  0065 D loss:-0.6597 G loss:-2.174\n",
      "Epoch:  0065 D loss:-0.5942 G loss:-1.96\n",
      "Epoch:  0065 D loss:-0.752 G loss:-2.314\n",
      "Epoch:  0065 D loss:-0.7226 G loss:-2.053\n",
      "Epoch:  0065 D loss:-0.5714 G loss:-2.299\n",
      "Epoch:  0065 D loss:-0.7005 G loss:-2.112\n",
      "Epoch:  0065 D loss:-0.5949 G loss:-2.238\n",
      "Epoch:  0065 D loss:-0.7185 G loss:-2.06\n",
      "Epoch:  0065 D loss:-0.7364 G loss:-1.954\n",
      "Epoch:  0065 D loss:-0.8261 G loss:-2.051\n",
      "Epoch:  0065 D loss:-0.6213 G loss:-2.063\n",
      "Epoch:  0065 D loss:-0.6293 G loss:-1.967\n",
      "Epoch:  0065 D loss:-0.7389 G loss:-2.004\n",
      "Epoch:  0065 D loss:-0.5836 G loss:-2.09\n",
      "Epoch:  0065 D loss:-0.9212 G loss:-1.846\n",
      "Epoch:  0065 D loss:-0.8596 G loss:-1.77\n",
      "Epoch:  0065 D loss:-0.6583 G loss:-1.967\n",
      "Epoch:  0065 D loss:-0.7426 G loss:-2.42\n",
      "Epoch:  0065 D loss:-0.6477 G loss:-2.215\n",
      "Epoch:  0065 D loss:-0.7434 G loss:-2.004\n",
      "Epoch:  0065 D loss:-0.6511 G loss:-2.088\n",
      "Epoch:  0065 D loss:-0.5959 G loss:-1.965\n",
      "Epoch:  0065 D loss:-0.6254 G loss:-2.096\n",
      "Epoch:  0065 D loss:-0.6895 G loss:-2.158\n",
      "Epoch:  0065 D loss:-0.736 G loss:-2.139\n",
      "Epoch:  0065 D loss:-0.6835 G loss:-2.059\n",
      "Epoch:  0065 D loss:-0.8582 G loss:-2.116\n",
      "Epoch:  0065 D loss:-0.7373 G loss:-2.137\n",
      "Epoch:  0065 D loss:-0.5683 G loss:-2.0\n",
      "Epoch:  0065 D loss:-0.6332 G loss:-2.114\n",
      "Epoch:  0065 D loss:-0.592 G loss:-1.982\n",
      "Epoch:  0065 D loss:-0.6638 G loss:-2.076\n",
      "Epoch:  0065 D loss:-0.7278 G loss:-2.035\n",
      "Epoch:  0065 D loss:-0.6519 G loss:-2.259\n",
      "Epoch:  0065 D loss:-0.7226 G loss:-2.126\n",
      "Epoch:  0065 D loss:-0.7117 G loss:-1.89\n",
      "Epoch:  0065 D loss:-0.6787 G loss:-1.927\n",
      "Epoch:  0065 D loss:-0.7202 G loss:-1.944\n",
      "Epoch:  0065 D loss:-0.7323 G loss:-2.127\n",
      "Epoch:  0065 D loss:-0.8038 G loss:-1.964\n",
      "Epoch:  0065 D loss:-0.7505 G loss:-1.98\n",
      "Epoch:  0065 D loss:-0.6034 G loss:-1.958\n",
      "Epoch:  0065 D loss:-0.7163 G loss:-1.965\n",
      "Epoch:  0065 D loss:-0.7459 G loss:-2.147\n",
      "Epoch:  0065 D loss:-0.6991 G loss:-1.967\n",
      "Epoch:  0065 D loss:-0.7798 G loss:-1.98\n",
      "Epoch:  0065 D loss:-0.6955 G loss:-1.948\n",
      "Epoch:  0065 D loss:-0.6645 G loss:-2.033\n",
      "Epoch:  0065 D loss:-0.7319 G loss:-1.841\n",
      "Epoch:  0065 D loss:-0.6872 G loss:-1.957\n",
      "Epoch:  0065 D loss:-0.6663 G loss:-1.982\n",
      "Epoch:  0065 D loss:-0.7949 G loss:-2.119\n",
      "Epoch:  0065 D loss:-0.7115 G loss:-2.012\n",
      "Epoch:  0065 D loss:-0.6387 G loss:-2.031\n",
      "Epoch:  0065 D loss:-0.7539 G loss:-1.962\n",
      "Epoch:  0065 D loss:-0.6356 G loss:-1.979\n",
      "Epoch:  0065 D loss:-0.6087 G loss:-2.15\n",
      "Epoch:  0065 D loss:-0.7755 G loss:-1.942\n",
      "Epoch:  0065 D loss:-0.563 G loss:-2.023\n",
      "Epoch:  0065 D loss:-0.6007 G loss:-2.11\n",
      "Epoch:  0065 D loss:-0.6192 G loss:-2.304\n",
      "Epoch:  0065 D loss:-0.6411 G loss:-2.216\n",
      "Epoch:  0065 D loss:-0.7555 G loss:-2.007\n",
      "Epoch:  0065 D loss:-0.7295 G loss:-2.132\n",
      "Epoch:  0065 D loss:-0.6198 G loss:-2.122\n",
      "Epoch:  0065 D loss:-0.6466 G loss:-2.153\n",
      "Epoch:  0065 D loss:-0.6263 G loss:-2.022\n",
      "Epoch:  0065 D loss:-0.7505 G loss:-2.047\n",
      "Epoch:  0065 D loss:-0.7483 G loss:-2.099\n",
      "Epoch:  0065 D loss:-0.6247 G loss:-2.03\n",
      "Epoch:  0065 D loss:-0.6938 G loss:-2.065\n",
      "Epoch:  0065 D loss:-0.6983 G loss:-2.023\n",
      "Epoch:  0065 D loss:-0.6697 G loss:-2.174\n",
      "Epoch:  0065 D loss:-0.6853 G loss:-2.144\n",
      "Epoch:  0065 D loss:-0.571 G loss:-2.257\n",
      "Epoch:  0065 D loss:-0.686 G loss:-2.182\n",
      "Epoch:  0065 D loss:-0.5808 G loss:-2.206\n",
      "Epoch:  0065 D loss:-0.7047 G loss:-2.032\n",
      "Epoch:  0065 D loss:-0.8314 G loss:-2.072\n",
      "Epoch:  0065 D loss:-0.6451 G loss:-1.968\n",
      "Epoch:  0065 D loss:-0.7252 G loss:-2.142\n",
      "Epoch:  0065 D loss:-0.6846 G loss:-2.059\n",
      "Epoch:  0065 D loss:-0.6544 G loss:-1.986\n",
      "Epoch:  0065 D loss:-0.7061 G loss:-1.863\n",
      "Epoch:  0065 D loss:-0.7788 G loss:-1.921\n",
      "Epoch:  0065 D loss:-0.6894 G loss:-1.995\n",
      "Epoch:  0065 D loss:-0.7283 G loss:-1.934\n",
      "Epoch:  0065 D loss:-0.7898 G loss:-1.943\n",
      "Epoch:  0065 D loss:-0.7661 G loss:-1.945\n",
      "Epoch:  0065 D loss:-0.6277 G loss:-2.011\n",
      "Epoch:  0065 D loss:-0.6734 G loss:-1.892\n",
      "Epoch:  0065 D loss:-0.6341 G loss:-2.027\n",
      "Epoch:  0065 D loss:-0.7669 G loss:-1.912\n",
      "Epoch:  0065 D loss:-0.6759 G loss:-1.948\n",
      "Epoch:  0065 D loss:-0.7024 G loss:-2.222\n",
      "Epoch:  0065 D loss:-0.792 G loss:-1.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0065 D loss:-0.6998 G loss:-1.981\n",
      "Epoch:  0065 D loss:-0.5143 G loss:-2.152\n",
      "Epoch:  0065 D loss:-0.7561 G loss:-2.169\n",
      "Epoch:  0065 D loss:-0.6867 G loss:-2.09\n",
      "Epoch:  0065 D loss:-0.7352 G loss:-2.196\n",
      "Epoch:  0065 D loss:-0.6591 G loss:-1.822\n",
      "Epoch:  0065 D loss:-0.7244 G loss:-1.987\n",
      "Epoch:  0065 D loss:-0.6031 G loss:-1.929\n",
      "Epoch:  0065 D loss:-0.649 G loss:-1.936\n",
      "Epoch:  0065 D loss:-0.7843 G loss:-1.966\n",
      "Epoch:  0065 D loss:-0.7481 G loss:-1.993\n",
      "Epoch:  0065 D loss:-0.7649 G loss:-2.05\n",
      "Epoch:  0065 D loss:-0.5864 G loss:-2.159\n",
      "Epoch:  0065 D loss:-0.705 G loss:-1.845\n",
      "Epoch:  0065 D loss:-0.6481 G loss:-2.034\n",
      "Epoch:  0065 D loss:-0.7444 G loss:-1.966\n",
      "Epoch:  0065 D loss:-0.7659 G loss:-2.052\n",
      "Epoch:  0065 D loss:-0.7665 G loss:-1.896\n",
      "Epoch:  0065 D loss:-0.7558 G loss:-1.965\n",
      "Epoch:  0065 D loss:-0.6933 G loss:-2.126\n",
      "Epoch:  0065 D loss:-0.5071 G loss:-1.942\n",
      "Epoch:  0065 D loss:-0.7811 G loss:-1.837\n",
      "Epoch:  0065 D loss:-0.6517 G loss:-1.941\n",
      "Epoch:  0065 D loss:-0.7041 G loss:-1.812\n",
      "Epoch:  0065 D loss:-0.7881 G loss:-1.973\n",
      "Epoch:  0065 D loss:-0.6815 G loss:-2.013\n",
      "Epoch:  0065 D loss:-0.7846 G loss:-1.728\n",
      "Epoch:  0065 D loss:-0.6659 G loss:-1.878\n",
      "Epoch:  0065 D loss:-0.6775 G loss:-1.936\n",
      "Epoch:  0065 D loss:-0.6661 G loss:-1.968\n",
      "Epoch:  0065 D loss:-0.6849 G loss:-2.098\n",
      "Epoch:  0065 D loss:-0.7814 G loss:-1.967\n",
      "Epoch:  0065 D loss:-0.6461 G loss:-2.244\n",
      "Epoch:  0065 D loss:-0.5482 G loss:-2.118\n",
      "Epoch:  0065 D loss:-0.6479 G loss:-2.064\n",
      "Epoch:  0065 D loss:-0.6184 G loss:-2.07\n",
      "Epoch:  0065 D loss:-0.6745 G loss:-2.013\n",
      "Epoch:  0065 D loss:-0.6911 G loss:-2.038\n",
      "Epoch:  0065 D loss:-0.8039 G loss:-1.844\n",
      "Epoch:  0065 D loss:-0.7154 G loss:-1.823\n",
      "Epoch:  0065 D loss:-0.6605 G loss:-2.002\n",
      "Epoch:  0065 D loss:-0.8086 G loss:-1.615\n",
      "Epoch:  0065 D loss:-0.6319 G loss:-1.897\n",
      "Epoch:  0065 D loss:-0.8579 G loss:-1.824\n",
      "Epoch:  0065 D loss:-0.7003 G loss:-1.867\n",
      "Epoch:  0065 D loss:-0.6255 G loss:-1.973\n",
      "Epoch:  0065 D loss:-0.588 G loss:-2.06\n",
      "Epoch:  0065 D loss:-0.8199 G loss:-2.106\n",
      "Epoch:  0065 D loss:-0.5913 G loss:-2.344\n",
      "Epoch:  0065 D loss:-0.8308 G loss:-2.1\n",
      "Epoch:  0065 D loss:-0.7767 G loss:-2.128\n",
      "Epoch:  0065 D loss:-0.7953 G loss:-2.132\n",
      "Epoch:  0065 D loss:-0.7148 G loss:-1.927\n",
      "Epoch:  0065 D loss:-0.6574 G loss:-2.107\n",
      "Epoch:  0065 D loss:-0.8367 G loss:-1.903\n",
      "Epoch:  0065 D loss:-0.7085 G loss:-2.059\n",
      "Epoch:  0065 D loss:-0.7322 G loss:-1.939\n",
      "Epoch:  0065 D loss:-0.8992 G loss:-1.73\n",
      "Epoch:  0065 D loss:-0.7785 G loss:-1.562\n",
      "Epoch:  0065 D loss:-0.7626 G loss:-1.789\n",
      "Epoch:  0065 D loss:-0.7558 G loss:-1.953\n",
      "Epoch:  0065 D loss:-0.8318 G loss:-1.763\n",
      "Epoch:  0065 D loss:-0.7455 G loss:-1.936\n",
      "Epoch:  0065 D loss:-0.7407 G loss:-2.068\n",
      "Epoch:  0065 D loss:-0.66 G loss:-2.041\n",
      "Epoch:  0065 D loss:-0.7138 G loss:-2.124\n",
      "Epoch:  0065 D loss:-0.6391 G loss:-2.054\n",
      "Epoch:  0065 D loss:-0.7665 G loss:-2.088\n",
      "Epoch:  0065 D loss:-0.6149 G loss:-1.994\n",
      "Epoch:  0065 D loss:-0.7781 G loss:-2.02\n",
      "Epoch:  0065 D loss:-0.6249 G loss:-1.946\n",
      "Epoch:  0065 D loss:-0.6221 G loss:-1.972\n",
      "Epoch:  0065 D loss:-0.6681 G loss:-1.949\n",
      "Epoch:  0065 D loss:-0.7399 G loss:-2.059\n",
      "Epoch:  0065 D loss:-0.7336 G loss:-2.105\n",
      "Epoch:  0065 D loss:-0.5471 G loss:-2.157\n",
      "Epoch:  0065 D loss:-0.5803 G loss:-2.084\n",
      "Epoch:  0065 D loss:-0.6708 G loss:-2.046\n",
      "Epoch:  0065 D loss:-0.6088 G loss:-2.279\n",
      "Epoch:  0065 D loss:-0.7757 G loss:-2.156\n",
      "Epoch:  0065 D loss:-0.7079 G loss:-1.978\n",
      "Epoch:  0065 D loss:-0.6212 G loss:-2.104\n",
      "Epoch:  0065 D loss:-0.7172 G loss:-2.171\n",
      "Epoch:  0065 D loss:-0.685 G loss:-2.039\n",
      "Epoch:  0065 D loss:-0.6872 G loss:-2.323\n",
      "Epoch:  0065 D loss:-0.6564 G loss:-2.085\n",
      "Epoch:  0065 D loss:-0.5631 G loss:-2.125\n",
      "Epoch:  0065 D loss:-0.6032 G loss:-2.076\n",
      "Epoch:  0065 D loss:-0.5888 G loss:-2.037\n",
      "Epoch:  0065 D loss:-0.5683 G loss:-2.254\n",
      "Epoch:  0065 D loss:-0.7614 G loss:-2.113\n",
      "Epoch:  0065 D loss:-0.7541 G loss:-2.131\n",
      "Epoch:  0065 D loss:-0.4923 G loss:-2.603\n",
      "Epoch:  0065 D loss:-0.7047 G loss:-2.232\n",
      "Epoch:  0065 D loss:-0.6941 G loss:-2.077\n",
      "Epoch:  0065 D loss:-0.815 G loss:-1.953\n",
      "Epoch:  0065 D loss:-0.6081 G loss:-1.922\n",
      "Epoch:  0065 D loss:-0.61 G loss:-2.12\n",
      "Epoch:  0065 D loss:-0.6208 G loss:-1.847\n",
      "Epoch:  0065 D loss:-0.6925 G loss:-2.038\n",
      "Epoch:  0065 D loss:-0.749 G loss:-2.041\n",
      "Epoch:  0065 D loss:-0.5941 G loss:-1.912\n",
      "Epoch:  0065 D loss:-0.6249 G loss:-2.011\n",
      "Epoch:  0065 D loss:-0.6451 G loss:-2.014\n",
      "Epoch:  0065 D loss:-0.6344 G loss:-2.224\n",
      "Epoch:  0065 D loss:-0.6778 G loss:-1.906\n",
      "Epoch:  0065 D loss:-0.6511 G loss:-2.126\n",
      "Epoch:  0065 D loss:-0.5907 G loss:-2.205\n",
      "Epoch:  0065 D loss:-0.6999 G loss:-2.068\n",
      "Epoch:  0065 D loss:-0.8016 G loss:-2.205\n",
      "Epoch:  0065 D loss:-0.7085 G loss:-2.102\n",
      "Epoch:  0065 D loss:-0.6201 G loss:-2.208\n",
      "Epoch:  0065 D loss:-0.5326 G loss:-2.139\n",
      "Epoch:  0065 D loss:-0.6306 G loss:-2.06\n",
      "Epoch:  0065 D loss:-0.6119 G loss:-1.981\n",
      "Epoch:  0065 D loss:-0.6514 G loss:-1.871\n",
      "Epoch:  0065 D loss:-0.6362 G loss:-2.002\n",
      "Epoch:  0065 D loss:-0.6142 G loss:-2.078\n",
      "Epoch:  0065 D loss:-0.6189 G loss:-1.962\n",
      "Epoch:  0065 D loss:-0.6231 G loss:-2.329\n",
      "Epoch:  0065 D loss:-0.6895 G loss:-2.104\n",
      "Epoch:  0065 D loss:-0.624 G loss:-1.985\n",
      "Epoch:  0065 D loss:-0.7307 G loss:-2.226\n",
      "Epoch:  0065 D loss:-0.6975 G loss:-2.168\n",
      "Epoch:  0065 D loss:-0.6659 G loss:-2.292\n",
      "Epoch:  0065 D loss:-0.5569 G loss:-2.423\n",
      "Epoch:  0065 D loss:-0.5979 G loss:-2.457\n",
      "Epoch:  0065 D loss:-0.6883 G loss:-2.11\n",
      "Epoch:  0065 D loss:-0.6659 G loss:-2.186\n",
      "Epoch:  0065 D loss:-0.744 G loss:-1.957\n",
      "Epoch:  0065 D loss:-0.7103 G loss:-2.13\n",
      "Epoch:  0065 D loss:-0.6846 G loss:-2.043\n",
      "Epoch:  0065 D loss:-0.736 G loss:-2.076\n",
      "Epoch:  0065 D loss:-0.6504 G loss:-2.141\n",
      "Epoch:  0065 D loss:-0.6461 G loss:-2.018\n",
      "Epoch:  0065 D loss:-0.7697 G loss:-1.946\n",
      "Epoch:  0065 D loss:-0.6376 G loss:-1.911\n",
      "Epoch:  0065 D loss:-0.6503 G loss:-2.03\n",
      "Epoch:  0065 D loss:-0.7261 G loss:-1.957\n",
      "Epoch:  0065 D loss:-0.7057 G loss:-2.089\n",
      "Epoch:  0065 D loss:-0.641 G loss:-2.266\n",
      "Epoch:  0065 D loss:-0.6913 G loss:-2.294\n",
      "Epoch:  0065 D loss:-0.6796 G loss:-2.172\n",
      "Epoch:  0065 D loss:-0.7265 G loss:-2.488\n",
      "Epoch:  0065 D loss:-0.7511 G loss:-2.14\n",
      "Epoch:  0065 D loss:-0.6081 G loss:-2.202\n",
      "Epoch:  0065 D loss:-0.7914 G loss:-2.147\n",
      "Epoch:  0065 D loss:-0.8225 G loss:-1.803\n",
      "Epoch:  0065 D loss:-0.7013 G loss:-1.961\n",
      "Epoch:  0065 D loss:-0.7213 G loss:-1.792\n",
      "Epoch:  0065 D loss:-0.7126 G loss:-2.093\n",
      "Epoch:  0065 D loss:-0.7311 G loss:-1.769\n",
      "Epoch:  0065 D loss:-0.6733 G loss:-1.898\n",
      "Epoch:  0065 D loss:-0.6565 G loss:-1.804\n",
      "Epoch:  0065 D loss:-0.8568 G loss:-1.928\n",
      "Epoch:  0065 D loss:-0.6518 G loss:-2.248\n",
      "Epoch:  0065 D loss:-0.5498 G loss:-2.425\n",
      "Epoch:  0065 D loss:-0.6358 G loss:-2.332\n",
      "Epoch:  0065 D loss:-0.7142 G loss:-2.272\n",
      "Epoch:  0065 D loss:-0.611 G loss:-2.297\n",
      "Epoch:  0065 D loss:-0.6766 G loss:-2.225\n",
      "Epoch:  0065 D loss:-0.7378 G loss:-2.073\n",
      "Epoch:  0065 D loss:-0.7211 G loss:-2.25\n",
      "Epoch:  0066 D loss:-0.6905 G loss:-2.171\n",
      "Epoch:  0066 D loss:-0.7574 G loss:-1.971\n",
      "Epoch:  0066 D loss:-0.684 G loss:-1.891\n",
      "Epoch:  0066 D loss:-0.6754 G loss:-1.88\n",
      "Epoch:  0066 D loss:-0.6142 G loss:-2.03\n",
      "Epoch:  0066 D loss:-0.6941 G loss:-1.993\n",
      "Epoch:  0066 D loss:-0.5986 G loss:-2.004\n",
      "Epoch:  0066 D loss:-0.7391 G loss:-1.96\n",
      "Epoch:  0066 D loss:-0.741 G loss:-2.131\n",
      "Epoch:  0066 D loss:-0.7124 G loss:-2.122\n",
      "Epoch:  0066 D loss:-0.7455 G loss:-2.293\n",
      "Epoch:  0066 D loss:-0.6116 G loss:-2.146\n",
      "Epoch:  0066 D loss:-0.7865 G loss:-2.224\n",
      "Epoch:  0066 D loss:-0.8694 G loss:-2.055\n",
      "Epoch:  0066 D loss:-0.7991 G loss:-2.123\n",
      "Epoch:  0066 D loss:-0.6781 G loss:-2.085\n",
      "Epoch:  0066 D loss:-0.7647 G loss:-2.104\n",
      "Epoch:  0066 D loss:-0.8053 G loss:-1.954\n",
      "Epoch:  0066 D loss:-0.8044 G loss:-2.094\n",
      "Epoch:  0066 D loss:-0.5916 G loss:-2.047\n",
      "Epoch:  0066 D loss:-0.6101 G loss:-2.136\n",
      "Epoch:  0066 D loss:-0.788 G loss:-1.851\n",
      "Epoch:  0066 D loss:-0.8725 G loss:-1.814\n",
      "Epoch:  0066 D loss:-0.7362 G loss:-1.886\n",
      "Epoch:  0066 D loss:-0.7684 G loss:-1.943\n",
      "Epoch:  0066 D loss:-0.7574 G loss:-1.989\n",
      "Epoch:  0066 D loss:-0.6698 G loss:-1.961\n",
      "Epoch:  0066 D loss:-0.7379 G loss:-2.077\n",
      "Epoch:  0066 D loss:-0.654 G loss:-2.001\n",
      "Epoch:  0066 D loss:-0.6715 G loss:-2.121\n",
      "Epoch:  0066 D loss:-0.7954 G loss:-2.028\n",
      "Epoch:  0066 D loss:-0.7304 G loss:-2.05\n",
      "Epoch:  0066 D loss:-0.672 G loss:-2.195\n",
      "Epoch:  0066 D loss:-0.6277 G loss:-2.168\n",
      "Epoch:  0066 D loss:-0.5746 G loss:-2.113\n",
      "Epoch:  0066 D loss:-0.5851 G loss:-2.205\n",
      "Epoch:  0066 D loss:-0.596 G loss:-1.973\n",
      "Epoch:  0066 D loss:-0.6241 G loss:-2.198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0066 D loss:-0.8309 G loss:-2.127\n",
      "Epoch:  0066 D loss:-0.6847 G loss:-2.06\n",
      "Epoch:  0066 D loss:-0.5732 G loss:-2.26\n",
      "Epoch:  0066 D loss:-0.6213 G loss:-2.244\n",
      "Epoch:  0066 D loss:-0.7082 G loss:-2.132\n",
      "Epoch:  0066 D loss:-0.7837 G loss:-1.947\n",
      "Epoch:  0066 D loss:-0.7012 G loss:-2.115\n",
      "Epoch:  0066 D loss:-0.8679 G loss:-1.742\n",
      "Epoch:  0066 D loss:-0.737 G loss:-1.959\n",
      "Epoch:  0066 D loss:-0.6598 G loss:-2.081\n",
      "Epoch:  0066 D loss:-0.7047 G loss:-2.259\n",
      "Epoch:  0066 D loss:-0.7432 G loss:-2.197\n",
      "Epoch:  0066 D loss:-0.5051 G loss:-2.359\n",
      "Epoch:  0066 D loss:-0.5826 G loss:-2.305\n",
      "Epoch:  0066 D loss:-0.6197 G loss:-2.115\n",
      "Epoch:  0066 D loss:-0.7017 G loss:-2.06\n",
      "Epoch:  0066 D loss:-0.7876 G loss:-2.119\n",
      "Epoch:  0066 D loss:-0.741 G loss:-2.297\n",
      "Epoch:  0066 D loss:-0.7376 G loss:-2.019\n",
      "Epoch:  0066 D loss:-0.66 G loss:-2.186\n",
      "Epoch:  0066 D loss:-0.5873 G loss:-1.95\n",
      "Epoch:  0066 D loss:-0.6287 G loss:-2.188\n",
      "Epoch:  0066 D loss:-0.7638 G loss:-2.017\n",
      "Epoch:  0066 D loss:-0.5895 G loss:-2.174\n",
      "Epoch:  0066 D loss:-0.7277 G loss:-2.03\n",
      "Epoch:  0066 D loss:-0.6424 G loss:-2.077\n",
      "Epoch:  0066 D loss:-0.8157 G loss:-1.86\n",
      "Epoch:  0066 D loss:-0.6264 G loss:-1.926\n",
      "Epoch:  0066 D loss:-0.4825 G loss:-2.241\n",
      "Epoch:  0066 D loss:-0.659 G loss:-2.265\n",
      "Epoch:  0066 D loss:-0.7024 G loss:-2.145\n",
      "Epoch:  0066 D loss:-0.6511 G loss:-2.535\n",
      "Epoch:  0066 D loss:-0.6044 G loss:-2.216\n",
      "Epoch:  0066 D loss:-0.7311 G loss:-2.244\n",
      "Epoch:  0066 D loss:-0.5548 G loss:-2.361\n",
      "Epoch:  0066 D loss:-0.693 G loss:-2.199\n",
      "Epoch:  0066 D loss:-0.6724 G loss:-2.184\n",
      "Epoch:  0066 D loss:-0.5884 G loss:-2.042\n",
      "Epoch:  0066 D loss:-0.7699 G loss:-1.92\n",
      "Epoch:  0066 D loss:-0.5777 G loss:-2.199\n",
      "Epoch:  0066 D loss:-0.5956 G loss:-2.035\n",
      "Epoch:  0066 D loss:-0.6883 G loss:-2.037\n",
      "Epoch:  0066 D loss:-0.6772 G loss:-2.245\n",
      "Epoch:  0066 D loss:-0.642 G loss:-2.187\n",
      "Epoch:  0066 D loss:-0.6817 G loss:-1.958\n",
      "Epoch:  0066 D loss:-0.5759 G loss:-1.897\n",
      "Epoch:  0066 D loss:-0.7066 G loss:-1.976\n",
      "Epoch:  0066 D loss:-0.7899 G loss:-2.176\n",
      "Epoch:  0066 D loss:-0.6992 G loss:-2.178\n",
      "Epoch:  0066 D loss:-0.7586 G loss:-1.937\n",
      "Epoch:  0066 D loss:-0.5725 G loss:-2.209\n",
      "Epoch:  0066 D loss:-0.5991 G loss:-1.998\n",
      "Epoch:  0066 D loss:-0.6119 G loss:-2.115\n",
      "Epoch:  0066 D loss:-0.5875 G loss:-2.136\n",
      "Epoch:  0066 D loss:-0.5243 G loss:-2.146\n",
      "Epoch:  0066 D loss:-0.6662 G loss:-2.066\n",
      "Epoch:  0066 D loss:-0.7123 G loss:-2.034\n",
      "Epoch:  0066 D loss:-0.7363 G loss:-2.07\n",
      "Epoch:  0066 D loss:-0.6346 G loss:-1.884\n",
      "Epoch:  0066 D loss:-0.5869 G loss:-2.038\n",
      "Epoch:  0066 D loss:-0.693 G loss:-2.262\n",
      "Epoch:  0066 D loss:-0.8285 G loss:-1.992\n",
      "Epoch:  0066 D loss:-0.6541 G loss:-2.074\n",
      "Epoch:  0066 D loss:-0.667 G loss:-2.087\n",
      "Epoch:  0066 D loss:-0.6841 G loss:-2.2\n",
      "Epoch:  0066 D loss:-0.7047 G loss:-2.218\n",
      "Epoch:  0066 D loss:-0.7424 G loss:-2.115\n",
      "Epoch:  0066 D loss:-0.6554 G loss:-2.193\n",
      "Epoch:  0066 D loss:-0.7433 G loss:-2.27\n",
      "Epoch:  0066 D loss:-0.665 G loss:-2.112\n",
      "Epoch:  0066 D loss:-0.5751 G loss:-2.298\n",
      "Epoch:  0066 D loss:-0.7189 G loss:-2.121\n",
      "Epoch:  0066 D loss:-0.7378 G loss:-2.311\n",
      "Epoch:  0066 D loss:-0.6675 G loss:-2.183\n",
      "Epoch:  0066 D loss:-0.717 G loss:-2.015\n",
      "Epoch:  0066 D loss:-0.8158 G loss:-1.943\n",
      "Epoch:  0066 D loss:-0.6115 G loss:-2.139\n",
      "Epoch:  0066 D loss:-0.6681 G loss:-1.779\n",
      "Epoch:  0066 D loss:-0.7678 G loss:-2.041\n",
      "Epoch:  0066 D loss:-0.6449 G loss:-1.96\n",
      "Epoch:  0066 D loss:-0.6593 G loss:-2.042\n",
      "Epoch:  0066 D loss:-0.7245 G loss:-1.976\n",
      "Epoch:  0066 D loss:-0.5548 G loss:-2.182\n",
      "Epoch:  0066 D loss:-0.612 G loss:-2.073\n",
      "Epoch:  0066 D loss:-0.6836 G loss:-2.23\n",
      "Epoch:  0066 D loss:-0.6547 G loss:-2.111\n",
      "Epoch:  0066 D loss:-0.8388 G loss:-1.997\n",
      "Epoch:  0066 D loss:-0.7654 G loss:-2.043\n",
      "Epoch:  0066 D loss:-0.6436 G loss:-1.881\n",
      "Epoch:  0066 D loss:-0.6951 G loss:-1.958\n",
      "Epoch:  0066 D loss:-0.7661 G loss:-1.962\n",
      "Epoch:  0066 D loss:-0.6399 G loss:-1.856\n",
      "Epoch:  0066 D loss:-0.7046 G loss:-2.05\n",
      "Epoch:  0066 D loss:-0.6278 G loss:-2.037\n",
      "Epoch:  0066 D loss:-0.6988 G loss:-2.016\n",
      "Epoch:  0066 D loss:-0.7217 G loss:-2.041\n",
      "Epoch:  0066 D loss:-0.583 G loss:-2.112\n",
      "Epoch:  0066 D loss:-0.6687 G loss:-2.058\n",
      "Epoch:  0066 D loss:-0.6796 G loss:-1.857\n",
      "Epoch:  0066 D loss:-0.7029 G loss:-1.969\n",
      "Epoch:  0066 D loss:-0.6464 G loss:-1.973\n",
      "Epoch:  0066 D loss:-0.8281 G loss:-2.147\n",
      "Epoch:  0066 D loss:-0.6647 G loss:-2.129\n",
      "Epoch:  0066 D loss:-0.5639 G loss:-2.086\n",
      "Epoch:  0066 D loss:-0.5459 G loss:-2.238\n",
      "Epoch:  0066 D loss:-0.7082 G loss:-2.055\n",
      "Epoch:  0066 D loss:-0.5972 G loss:-2.265\n",
      "Epoch:  0066 D loss:-0.7394 G loss:-2.187\n",
      "Epoch:  0066 D loss:-0.7165 G loss:-2.286\n",
      "Epoch:  0066 D loss:-0.7469 G loss:-2.162\n",
      "Epoch:  0066 D loss:-0.7 G loss:-2.222\n",
      "Epoch:  0066 D loss:-0.6346 G loss:-2.249\n",
      "Epoch:  0066 D loss:-0.5756 G loss:-2.097\n",
      "Epoch:  0066 D loss:-0.7351 G loss:-2.082\n",
      "Epoch:  0066 D loss:-0.6787 G loss:-2.081\n",
      "Epoch:  0066 D loss:-0.6715 G loss:-2.041\n",
      "Epoch:  0066 D loss:-0.7521 G loss:-1.991\n",
      "Epoch:  0066 D loss:-0.6705 G loss:-2.036\n",
      "Epoch:  0066 D loss:-0.6324 G loss:-2.091\n",
      "Epoch:  0066 D loss:-0.6194 G loss:-2.047\n",
      "Epoch:  0066 D loss:-0.6703 G loss:-2.171\n",
      "Epoch:  0066 D loss:-0.7226 G loss:-2.23\n",
      "Epoch:  0066 D loss:-0.7785 G loss:-2.081\n",
      "Epoch:  0066 D loss:-0.734 G loss:-2.172\n",
      "Epoch:  0066 D loss:-0.8163 G loss:-2.122\n",
      "Epoch:  0066 D loss:-0.8532 G loss:-2.003\n",
      "Epoch:  0066 D loss:-0.6664 G loss:-1.892\n",
      "Epoch:  0066 D loss:-0.807 G loss:-1.929\n",
      "Epoch:  0066 D loss:-0.7532 G loss:-1.97\n",
      "Epoch:  0066 D loss:-0.8644 G loss:-1.911\n",
      "Epoch:  0066 D loss:-0.7872 G loss:-1.976\n",
      "Epoch:  0066 D loss:-0.6515 G loss:-2.107\n",
      "Epoch:  0066 D loss:-0.7366 G loss:-1.929\n",
      "Epoch:  0066 D loss:-0.7715 G loss:-1.78\n",
      "Epoch:  0066 D loss:-0.8104 G loss:-1.966\n",
      "Epoch:  0066 D loss:-0.7289 G loss:-1.922\n",
      "Epoch:  0066 D loss:-0.7553 G loss:-1.971\n",
      "Epoch:  0066 D loss:-0.7511 G loss:-2.083\n",
      "Epoch:  0066 D loss:-0.7232 G loss:-2.037\n",
      "Epoch:  0066 D loss:-0.8473 G loss:-1.9\n",
      "Epoch:  0066 D loss:-0.7364 G loss:-1.804\n",
      "Epoch:  0066 D loss:-0.7142 G loss:-2.016\n",
      "Epoch:  0066 D loss:-0.6652 G loss:-1.943\n",
      "Epoch:  0066 D loss:-0.7603 G loss:-2.01\n",
      "Epoch:  0066 D loss:-0.749 G loss:-2.115\n",
      "Epoch:  0066 D loss:-0.6136 G loss:-2.249\n",
      "Epoch:  0066 D loss:-0.6012 G loss:-2.042\n",
      "Epoch:  0066 D loss:-0.7183 G loss:-1.873\n",
      "Epoch:  0066 D loss:-0.6371 G loss:-2.208\n",
      "Epoch:  0066 D loss:-0.5876 G loss:-2.062\n",
      "Epoch:  0066 D loss:-0.6117 G loss:-1.978\n",
      "Epoch:  0066 D loss:-0.5766 G loss:-2.013\n",
      "Epoch:  0066 D loss:-0.7604 G loss:-1.733\n",
      "Epoch:  0066 D loss:-0.6869 G loss:-2.043\n",
      "Epoch:  0066 D loss:-0.6114 G loss:-2.313\n",
      "Epoch:  0066 D loss:-0.6865 G loss:-2.044\n",
      "Epoch:  0066 D loss:-0.8901 G loss:-1.912\n",
      "Epoch:  0066 D loss:-0.7035 G loss:-2.196\n",
      "Epoch:  0066 D loss:-0.8522 G loss:-2.076\n",
      "Epoch:  0066 D loss:-0.7259 G loss:-2.154\n",
      "Epoch:  0066 D loss:-0.5511 G loss:-2.086\n",
      "Epoch:  0066 D loss:-0.8101 G loss:-1.908\n",
      "Epoch:  0066 D loss:-0.7473 G loss:-1.917\n",
      "Epoch:  0066 D loss:-0.6542 G loss:-2.228\n",
      "Epoch:  0066 D loss:-0.796 G loss:-2.251\n",
      "Epoch:  0066 D loss:-0.5734 G loss:-2.136\n",
      "Epoch:  0066 D loss:-0.6168 G loss:-2.028\n",
      "Epoch:  0066 D loss:-0.747 G loss:-1.715\n",
      "Epoch:  0066 D loss:-0.5727 G loss:-2.014\n",
      "Epoch:  0066 D loss:-0.6863 G loss:-2.204\n",
      "Epoch:  0066 D loss:-0.7872 G loss:-2.035\n",
      "Epoch:  0066 D loss:-0.7558 G loss:-1.979\n",
      "Epoch:  0066 D loss:-0.7109 G loss:-2.064\n",
      "Epoch:  0066 D loss:-0.7503 G loss:-1.782\n",
      "Epoch:  0066 D loss:-0.6241 G loss:-1.9\n",
      "Epoch:  0066 D loss:-0.6366 G loss:-1.901\n",
      "Epoch:  0066 D loss:-0.7737 G loss:-1.955\n",
      "Epoch:  0066 D loss:-0.7346 G loss:-1.798\n",
      "Epoch:  0066 D loss:-0.6643 G loss:-1.93\n",
      "Epoch:  0066 D loss:-0.7153 G loss:-2.058\n",
      "Epoch:  0066 D loss:-0.7552 G loss:-2.065\n",
      "Epoch:  0066 D loss:-0.6324 G loss:-2.29\n",
      "Epoch:  0066 D loss:-0.6933 G loss:-2.114\n",
      "Epoch:  0066 D loss:-0.8166 G loss:-2.024\n",
      "Epoch:  0066 D loss:-0.6464 G loss:-2.008\n",
      "Epoch:  0066 D loss:-0.7345 G loss:-2.1\n",
      "Epoch:  0066 D loss:-0.7905 G loss:-1.907\n",
      "Epoch:  0066 D loss:-0.6638 G loss:-2.281\n",
      "Epoch:  0066 D loss:-0.6854 G loss:-1.973\n",
      "Epoch:  0066 D loss:-0.7315 G loss:-1.968\n",
      "Epoch:  0066 D loss:-0.6272 G loss:-1.918\n",
      "Epoch:  0066 D loss:-0.7363 G loss:-1.902\n",
      "Epoch:  0066 D loss:-0.5445 G loss:-2.152\n",
      "Epoch:  0066 D loss:-0.7582 G loss:-1.954\n",
      "Epoch:  0066 D loss:-0.7058 G loss:-1.892\n",
      "Epoch:  0066 D loss:-0.6451 G loss:-2.028\n",
      "Epoch:  0066 D loss:-0.5711 G loss:-2.065\n",
      "Epoch:  0066 D loss:-0.5845 G loss:-2.031\n",
      "Epoch:  0066 D loss:-0.6615 G loss:-2.073\n",
      "Epoch:  0066 D loss:-0.6658 G loss:-2.069\n",
      "Epoch:  0066 D loss:-0.7361 G loss:-1.926\n",
      "Epoch:  0066 D loss:-0.799 G loss:-2.037\n",
      "Epoch:  0066 D loss:-0.6518 G loss:-2.017\n",
      "Epoch:  0066 D loss:-0.6007 G loss:-2.172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0066 D loss:-0.7716 G loss:-2.014\n",
      "Epoch:  0066 D loss:-0.6217 G loss:-2.056\n",
      "Epoch:  0066 D loss:-0.6105 G loss:-2.137\n",
      "Epoch:  0066 D loss:-0.7135 G loss:-2.244\n",
      "Epoch:  0066 D loss:-0.7332 G loss:-2.24\n",
      "Epoch:  0066 D loss:-0.7455 G loss:-2.187\n",
      "Epoch:  0066 D loss:-0.7696 G loss:-2.059\n",
      "Epoch:  0066 D loss:-0.6331 G loss:-2.099\n",
      "Epoch:  0066 D loss:-0.5765 G loss:-1.982\n",
      "Epoch:  0066 D loss:-0.7058 G loss:-1.709\n",
      "Epoch:  0066 D loss:-0.8459 G loss:-1.779\n",
      "Epoch:  0066 D loss:-0.576 G loss:-1.718\n",
      "Epoch:  0066 D loss:-0.7584 G loss:-1.958\n",
      "Epoch:  0066 D loss:-0.7021 G loss:-2.265\n",
      "Epoch:  0066 D loss:-0.6522 G loss:-2.047\n",
      "Epoch:  0066 D loss:-0.6499 G loss:-2.205\n",
      "Epoch:  0066 D loss:-0.7068 G loss:-2.255\n",
      "Epoch:  0066 D loss:-0.7321 G loss:-2.22\n",
      "Epoch:  0066 D loss:-0.734 G loss:-2.179\n",
      "Epoch:  0066 D loss:-0.5681 G loss:-2.075\n",
      "Epoch:  0066 D loss:-0.6433 G loss:-2.159\n",
      "Epoch:  0066 D loss:-0.8385 G loss:-2.04\n",
      "Epoch:  0066 D loss:-0.7436 G loss:-1.961\n",
      "Epoch:  0066 D loss:-0.6284 G loss:-2.189\n",
      "Epoch:  0066 D loss:-0.6727 G loss:-2.111\n",
      "Epoch:  0066 D loss:-0.7197 G loss:-1.907\n",
      "Epoch:  0066 D loss:-0.7447 G loss:-1.846\n",
      "Epoch:  0066 D loss:-0.7548 G loss:-1.702\n",
      "Epoch:  0066 D loss:-0.635 G loss:-1.871\n",
      "Epoch:  0066 D loss:-0.8087 G loss:-1.731\n",
      "Epoch:  0066 D loss:-0.667 G loss:-2.138\n",
      "Epoch:  0066 D loss:-0.6223 G loss:-2.131\n",
      "Epoch:  0066 D loss:-0.6156 G loss:-2.343\n",
      "Epoch:  0066 D loss:-0.7214 G loss:-2.374\n",
      "Epoch:  0066 D loss:-0.6161 G loss:-2.371\n",
      "Epoch:  0066 D loss:-0.6499 G loss:-2.316\n",
      "Epoch:  0066 D loss:-0.7873 G loss:-2.135\n",
      "Epoch:  0066 D loss:-0.6171 G loss:-2.184\n",
      "Epoch:  0066 D loss:-0.7901 G loss:-2.123\n",
      "Epoch:  0066 D loss:-0.5577 G loss:-2.15\n",
      "Epoch:  0066 D loss:-0.9128 G loss:-1.976\n",
      "Epoch:  0066 D loss:-0.7283 G loss:-1.924\n",
      "Epoch:  0066 D loss:-0.8073 G loss:-2.053\n",
      "Epoch:  0066 D loss:-0.655 G loss:-1.883\n",
      "Epoch:  0066 D loss:-0.7496 G loss:-1.847\n",
      "Epoch:  0066 D loss:-0.7355 G loss:-1.721\n",
      "Epoch:  0066 D loss:-0.5748 G loss:-2.042\n",
      "Epoch:  0066 D loss:-0.7098 G loss:-2.048\n",
      "Epoch:  0066 D loss:-0.6615 G loss:-2.162\n",
      "Epoch:  0066 D loss:-0.6916 G loss:-2.267\n",
      "Epoch:  0066 D loss:-0.7765 G loss:-2.111\n",
      "Epoch:  0066 D loss:-0.7255 G loss:-2.232\n",
      "Epoch:  0066 D loss:-0.8246 G loss:-2.393\n",
      "Epoch:  0066 D loss:-0.7011 G loss:-2.306\n",
      "Epoch:  0066 D loss:-0.8042 G loss:-2.185\n",
      "Epoch:  0066 D loss:-0.8481 G loss:-2.093\n",
      "Epoch:  0066 D loss:-0.6764 G loss:-2.05\n",
      "Epoch:  0066 D loss:-0.6956 G loss:-1.913\n",
      "Epoch:  0066 D loss:-0.7506 G loss:-1.981\n",
      "Epoch:  0066 D loss:-0.6744 G loss:-2.144\n",
      "Epoch:  0066 D loss:-0.6557 G loss:-2.023\n",
      "Epoch:  0066 D loss:-0.6664 G loss:-1.996\n",
      "Epoch:  0066 D loss:-0.6837 G loss:-2.03\n",
      "Epoch:  0066 D loss:-0.7313 G loss:-2.003\n",
      "Epoch:  0066 D loss:-0.748 G loss:-1.796\n",
      "Epoch:  0066 D loss:-0.6256 G loss:-2.238\n",
      "Epoch:  0066 D loss:-0.571 G loss:-2.079\n",
      "Epoch:  0066 D loss:-0.6971 G loss:-2.195\n",
      "Epoch:  0066 D loss:-0.7539 G loss:-2.086\n",
      "Epoch:  0066 D loss:-0.6961 G loss:-1.945\n",
      "Epoch:  0066 D loss:-0.7199 G loss:-2.086\n",
      "Epoch:  0066 D loss:-0.6261 G loss:-2.39\n",
      "Epoch:  0066 D loss:-0.7694 G loss:-2.109\n",
      "Epoch:  0066 D loss:-0.6829 G loss:-2.121\n",
      "Epoch:  0066 D loss:-0.7004 G loss:-2.163\n",
      "Epoch:  0066 D loss:-0.8837 G loss:-2.024\n",
      "Epoch:  0066 D loss:-0.7038 G loss:-1.993\n",
      "Epoch:  0066 D loss:-0.8028 G loss:-2.05\n",
      "Epoch:  0066 D loss:-0.6002 G loss:-2.119\n",
      "Epoch:  0066 D loss:-0.7291 G loss:-1.943\n",
      "Epoch:  0066 D loss:-0.6941 G loss:-1.932\n",
      "Epoch:  0066 D loss:-0.7419 G loss:-2.045\n",
      "Epoch:  0066 D loss:-0.7803 G loss:-1.806\n",
      "Epoch:  0066 D loss:-0.6792 G loss:-1.851\n",
      "Epoch:  0066 D loss:-0.83 G loss:-1.761\n",
      "Epoch:  0066 D loss:-0.6714 G loss:-1.928\n",
      "Epoch:  0066 D loss:-0.7536 G loss:-1.952\n",
      "Epoch:  0066 D loss:-0.5823 G loss:-2.205\n",
      "Epoch:  0066 D loss:-0.6528 G loss:-2.196\n",
      "Epoch:  0066 D loss:-0.7243 G loss:-2.318\n",
      "Epoch:  0066 D loss:-0.6468 G loss:-2.255\n",
      "Epoch:  0066 D loss:-0.7557 G loss:-2.151\n",
      "Epoch:  0066 D loss:-0.8578 G loss:-2.265\n",
      "Epoch:  0066 D loss:-0.7285 G loss:-1.909\n",
      "Epoch:  0066 D loss:-0.76 G loss:-2.054\n",
      "Epoch:  0066 D loss:-0.7187 G loss:-1.916\n",
      "Epoch:  0066 D loss:-0.842 G loss:-1.858\n",
      "Epoch:  0066 D loss:-0.737 G loss:-1.979\n",
      "Epoch:  0066 D loss:-0.5842 G loss:-1.953\n",
      "Epoch:  0066 D loss:-0.7696 G loss:-1.959\n",
      "Epoch:  0066 D loss:-0.7747 G loss:-1.886\n",
      "Epoch:  0066 D loss:-0.6745 G loss:-1.877\n",
      "Epoch:  0066 D loss:-0.8347 G loss:-1.884\n",
      "Epoch:  0066 D loss:-0.6456 G loss:-2.023\n",
      "Epoch:  0066 D loss:-0.6611 G loss:-2.246\n",
      "Epoch:  0066 D loss:-0.7806 G loss:-2.197\n",
      "Epoch:  0066 D loss:-0.6044 G loss:-2.045\n",
      "Epoch:  0066 D loss:-0.6171 G loss:-2.114\n",
      "Epoch:  0066 D loss:-0.6142 G loss:-2.169\n",
      "Epoch:  0066 D loss:-0.7615 G loss:-2.303\n",
      "Epoch:  0066 D loss:-0.7586 G loss:-2.103\n",
      "Epoch:  0066 D loss:-0.6066 G loss:-2.143\n",
      "Epoch:  0066 D loss:-0.8221 G loss:-1.929\n",
      "Epoch:  0066 D loss:-0.7341 G loss:-1.924\n",
      "Epoch:  0066 D loss:-0.6685 G loss:-2.076\n",
      "Epoch:  0066 D loss:-0.8141 G loss:-1.782\n",
      "Epoch:  0066 D loss:-0.7442 G loss:-2.005\n",
      "Epoch:  0066 D loss:-0.6626 G loss:-2.104\n",
      "Epoch:  0066 D loss:-0.7662 G loss:-1.933\n",
      "Epoch:  0066 D loss:-0.643 G loss:-2.024\n",
      "Epoch:  0066 D loss:-0.7525 G loss:-1.898\n",
      "Epoch:  0066 D loss:-0.6013 G loss:-1.971\n",
      "Epoch:  0066 D loss:-0.8598 G loss:-1.865\n",
      "Epoch:  0066 D loss:-0.7223 G loss:-2.005\n",
      "Epoch:  0066 D loss:-0.5499 G loss:-2.085\n",
      "Epoch:  0066 D loss:-0.8017 G loss:-1.905\n",
      "Epoch:  0066 D loss:-0.709 G loss:-1.939\n",
      "Epoch:  0066 D loss:-0.6604 G loss:-2.23\n",
      "Epoch:  0066 D loss:-0.7576 G loss:-2.108\n",
      "Epoch:  0066 D loss:-0.5238 G loss:-1.988\n",
      "Epoch:  0066 D loss:-0.6469 G loss:-2.159\n",
      "Epoch:  0066 D loss:-0.6457 G loss:-2.1\n",
      "Epoch:  0066 D loss:-0.5981 G loss:-2.028\n",
      "Epoch:  0066 D loss:-0.5315 G loss:-2.39\n",
      "Epoch:  0066 D loss:-0.5935 G loss:-2.214\n",
      "Epoch:  0066 D loss:-0.6289 G loss:-2.204\n",
      "Epoch:  0066 D loss:-0.7116 G loss:-2.217\n",
      "Epoch:  0066 D loss:-0.6208 G loss:-2.292\n",
      "Epoch:  0066 D loss:-0.5461 G loss:-2.075\n",
      "Epoch:  0066 D loss:-0.591 G loss:-2.324\n",
      "Epoch:  0066 D loss:-0.6368 G loss:-2.275\n",
      "Epoch:  0066 D loss:-0.7746 G loss:-2.137\n",
      "Epoch:  0066 D loss:-0.6135 G loss:-2.039\n",
      "Epoch:  0066 D loss:-0.6435 G loss:-2.009\n",
      "Epoch:  0066 D loss:-0.5878 G loss:-2.069\n",
      "Epoch:  0066 D loss:-0.737 G loss:-1.941\n",
      "Epoch:  0066 D loss:-0.5618 G loss:-2.163\n",
      "Epoch:  0066 D loss:-0.6189 G loss:-2.161\n",
      "Epoch:  0066 D loss:-0.6757 G loss:-2.032\n",
      "Epoch:  0066 D loss:-0.6173 G loss:-2.144\n",
      "Epoch:  0066 D loss:-0.7285 G loss:-1.982\n",
      "Epoch:  0066 D loss:-0.571 G loss:-1.923\n",
      "Epoch:  0066 D loss:-0.6073 G loss:-2.072\n",
      "Epoch:  0066 D loss:-0.5899 G loss:-2.358\n",
      "Epoch:  0066 D loss:-0.6745 G loss:-2.393\n",
      "Epoch:  0066 D loss:-0.8003 G loss:-2.244\n",
      "Epoch:  0066 D loss:-0.588 G loss:-2.405\n",
      "Epoch:  0066 D loss:-0.6247 G loss:-2.133\n",
      "Epoch:  0066 D loss:-0.7227 G loss:-2.22\n",
      "Epoch:  0066 D loss:-0.6813 G loss:-2.108\n",
      "Epoch:  0066 D loss:-0.7144 G loss:-1.985\n",
      "Epoch:  0066 D loss:-0.6021 G loss:-2.049\n",
      "Epoch:  0066 D loss:-0.5974 G loss:-1.925\n",
      "Epoch:  0066 D loss:-0.7593 G loss:-1.955\n",
      "Epoch:  0066 D loss:-0.7686 G loss:-2.035\n",
      "Epoch:  0066 D loss:-0.6314 G loss:-2.002\n",
      "Epoch:  0066 D loss:-0.5992 G loss:-2.121\n",
      "Epoch:  0066 D loss:-0.686 G loss:-2.195\n",
      "Epoch:  0066 D loss:-0.5744 G loss:-2.268\n",
      "Epoch:  0066 D loss:-0.6148 G loss:-2.253\n",
      "Epoch:  0066 D loss:-0.6408 G loss:-2.096\n",
      "Epoch:  0066 D loss:-0.6088 G loss:-2.221\n",
      "Epoch:  0066 D loss:-0.7554 G loss:-2.1\n",
      "Epoch:  0066 D loss:-0.6984 G loss:-2.217\n",
      "Epoch:  0066 D loss:-0.6975 G loss:-2.236\n",
      "Epoch:  0066 D loss:-0.7496 G loss:-2.312\n",
      "Epoch:  0066 D loss:-0.7126 G loss:-2.154\n",
      "Epoch:  0066 D loss:-0.6151 G loss:-2.153\n",
      "Epoch:  0066 D loss:-0.8849 G loss:-2.145\n",
      "Epoch:  0066 D loss:-0.7323 G loss:-1.946\n",
      "Epoch:  0066 D loss:-0.7868 G loss:-1.847\n",
      "Epoch:  0066 D loss:-0.7357 G loss:-1.823\n",
      "Epoch:  0066 D loss:-0.7005 G loss:-1.869\n",
      "Epoch:  0066 D loss:-0.7116 G loss:-2.136\n",
      "Epoch:  0066 D loss:-0.5903 G loss:-2.007\n",
      "Epoch:  0066 D loss:-0.6347 G loss:-1.988\n",
      "Epoch:  0066 D loss:-0.813 G loss:-2.21\n",
      "Epoch:  0066 D loss:-0.6982 G loss:-2.185\n",
      "Epoch:  0066 D loss:-0.8467 G loss:-2.026\n",
      "Epoch:  0066 D loss:-0.6796 G loss:-2.188\n",
      "Epoch:  0066 D loss:-0.5183 G loss:-2.308\n",
      "Epoch:  0066 D loss:-0.7151 G loss:-2.24\n",
      "Epoch:  0066 D loss:-0.6401 G loss:-2.172\n",
      "Epoch:  0066 D loss:-0.8197 G loss:-2.104\n",
      "Epoch:  0066 D loss:-0.8082 G loss:-1.913\n",
      "Epoch:  0066 D loss:-0.6858 G loss:-2.053\n",
      "Epoch:  0066 D loss:-0.8548 G loss:-2.139\n",
      "Epoch:  0066 D loss:-0.6793 G loss:-1.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0066 D loss:-0.7663 G loss:-2.032\n",
      "Epoch:  0066 D loss:-0.7472 G loss:-2.028\n",
      "Epoch:  0066 D loss:-0.7529 G loss:-1.991\n",
      "Epoch:  0066 D loss:-0.6159 G loss:-2.053\n",
      "Epoch:  0066 D loss:-0.7809 G loss:-1.844\n",
      "Epoch:  0066 D loss:-0.7163 G loss:-1.901\n",
      "Epoch:  0066 D loss:-0.6139 G loss:-1.917\n",
      "Epoch:  0066 D loss:-0.6906 G loss:-1.838\n",
      "Epoch:  0066 D loss:-0.6798 G loss:-2.024\n",
      "Epoch:  0066 D loss:-0.6683 G loss:-2.014\n",
      "Epoch:  0066 D loss:-0.687 G loss:-1.9\n",
      "Epoch:  0066 D loss:-0.7945 G loss:-1.918\n",
      "Epoch:  0066 D loss:-0.871 G loss:-1.975\n",
      "Epoch:  0066 D loss:-0.7151 G loss:-2.042\n",
      "Epoch:  0066 D loss:-0.6142 G loss:-2.11\n",
      "Epoch:  0066 D loss:-0.7182 G loss:-2.052\n",
      "Epoch:  0066 D loss:-0.6606 G loss:-2.178\n",
      "Epoch:  0066 D loss:-0.8333 G loss:-2.156\n",
      "Epoch:  0066 D loss:-0.661 G loss:-2.223\n",
      "Epoch:  0066 D loss:-0.7483 G loss:-2.158\n",
      "Epoch:  0066 D loss:-0.6284 G loss:-2.161\n",
      "Epoch:  0066 D loss:-0.6859 G loss:-2.046\n",
      "Epoch:  0066 D loss:-0.775 G loss:-2.276\n",
      "Epoch:  0066 D loss:-0.7233 G loss:-2.108\n",
      "Epoch:  0066 D loss:-0.6441 G loss:-2.023\n",
      "Epoch:  0066 D loss:-0.7525 G loss:-1.974\n",
      "Epoch:  0066 D loss:-0.7033 G loss:-2.111\n",
      "Epoch:  0066 D loss:-0.7795 G loss:-1.87\n",
      "Epoch:  0066 D loss:-0.742 G loss:-1.842\n",
      "Epoch:  0066 D loss:-0.8442 G loss:-1.969\n",
      "Epoch:  0066 D loss:-0.617 G loss:-2.198\n",
      "Epoch:  0066 D loss:-0.6969 G loss:-2.012\n",
      "Epoch:  0066 D loss:-0.4928 G loss:-1.993\n",
      "Epoch:  0066 D loss:-0.7408 G loss:-2.105\n",
      "Epoch:  0066 D loss:-0.5343 G loss:-2.177\n",
      "Epoch:  0066 D loss:-0.8004 G loss:-2.314\n",
      "Epoch:  0066 D loss:-0.8079 G loss:-2.229\n",
      "Epoch:  0066 D loss:-0.6868 G loss:-2.246\n",
      "Epoch:  0066 D loss:-1.001 G loss:-1.947\n",
      "Epoch:  0066 D loss:-0.7576 G loss:-2.219\n",
      "Epoch:  0066 D loss:-0.8699 G loss:-2.043\n",
      "Epoch:  0066 D loss:-0.6452 G loss:-1.851\n",
      "Epoch:  0066 D loss:-0.6935 G loss:-1.98\n",
      "Epoch:  0066 D loss:-0.6218 G loss:-2.004\n",
      "Epoch:  0066 D loss:-0.6906 G loss:-1.818\n",
      "Epoch:  0066 D loss:-0.7348 G loss:-1.871\n",
      "Epoch:  0066 D loss:-0.6901 G loss:-1.943\n",
      "Epoch:  0066 D loss:-0.5873 G loss:-1.837\n",
      "Epoch:  0066 D loss:-0.645 G loss:-2.055\n",
      "Epoch:  0066 D loss:-0.6739 G loss:-2.031\n",
      "Epoch:  0066 D loss:-0.7221 G loss:-1.923\n",
      "Epoch:  0066 D loss:-0.6717 G loss:-2.068\n",
      "Epoch:  0066 D loss:-0.6491 G loss:-2.184\n",
      "Epoch:  0066 D loss:-0.7078 G loss:-2.145\n",
      "Epoch:  0066 D loss:-0.7083 G loss:-2.11\n",
      "Epoch:  0066 D loss:-0.7266 G loss:-2.183\n",
      "Epoch:  0066 D loss:-0.4937 G loss:-2.368\n",
      "Epoch:  0066 D loss:-0.6888 G loss:-2.146\n",
      "Epoch:  0066 D loss:-0.8238 G loss:-1.967\n",
      "Epoch:  0066 D loss:-0.7206 G loss:-1.934\n",
      "Epoch:  0066 D loss:-0.615 G loss:-2.067\n",
      "Epoch:  0066 D loss:-0.6934 G loss:-2.221\n",
      "Epoch:  0066 D loss:-0.6395 G loss:-1.932\n",
      "Epoch:  0066 D loss:-0.6831 G loss:-1.932\n",
      "Epoch:  0066 D loss:-0.7453 G loss:-2.014\n",
      "Epoch:  0066 D loss:-0.6746 G loss:-1.886\n",
      "Epoch:  0066 D loss:-0.7895 G loss:-1.869\n",
      "Epoch:  0066 D loss:-0.6155 G loss:-2.168\n",
      "Epoch:  0066 D loss:-0.8425 G loss:-1.857\n",
      "Epoch:  0066 D loss:-0.6317 G loss:-1.94\n",
      "Epoch:  0066 D loss:-0.7511 G loss:-1.905\n",
      "Epoch:  0066 D loss:-0.7419 G loss:-2.01\n",
      "Epoch:  0066 D loss:-0.6876 G loss:-2.154\n",
      "Epoch:  0066 D loss:-0.525 G loss:-2.283\n",
      "Epoch:  0066 D loss:-0.6623 G loss:-2.28\n",
      "Epoch:  0066 D loss:-0.9076 G loss:-2.025\n",
      "Epoch:  0066 D loss:-0.7358 G loss:-1.966\n",
      "Epoch:  0066 D loss:-0.7457 G loss:-2.207\n",
      "Epoch:  0066 D loss:-0.6315 G loss:-2.096\n",
      "Epoch:  0066 D loss:-0.6919 G loss:-2.039\n",
      "Epoch:  0066 D loss:-0.6874 G loss:-2.04\n",
      "Epoch:  0066 D loss:-0.6833 G loss:-2.102\n",
      "Epoch:  0066 D loss:-0.7204 G loss:-1.988\n",
      "Epoch:  0066 D loss:-0.5624 G loss:-2.037\n",
      "Epoch:  0066 D loss:-0.761 G loss:-1.865\n",
      "Epoch:  0066 D loss:-0.5997 G loss:-2.079\n",
      "Epoch:  0066 D loss:-0.6703 G loss:-1.78\n",
      "Epoch:  0066 D loss:-0.7748 G loss:-2.131\n",
      "Epoch:  0066 D loss:-0.6 G loss:-2.17\n",
      "Epoch:  0066 D loss:-0.6029 G loss:-2.191\n",
      "Epoch:  0066 D loss:-0.748 G loss:-1.92\n",
      "Epoch:  0066 D loss:-0.6746 G loss:-2.184\n",
      "Epoch:  0066 D loss:-0.8063 G loss:-2.261\n",
      "Epoch:  0066 D loss:-0.6594 G loss:-2.229\n",
      "Epoch:  0066 D loss:-0.6435 G loss:-2.029\n",
      "Epoch:  0066 D loss:-0.7278 G loss:-2.12\n",
      "Epoch:  0066 D loss:-0.6971 G loss:-2.09\n",
      "Epoch:  0066 D loss:-0.7911 G loss:-2.02\n",
      "Epoch:  0066 D loss:-0.6964 G loss:-2.104\n",
      "Epoch:  0066 D loss:-0.8375 G loss:-1.964\n",
      "Epoch:  0066 D loss:-0.7269 G loss:-1.925\n",
      "Epoch:  0066 D loss:-0.6277 G loss:-1.802\n",
      "Epoch:  0066 D loss:-0.6527 G loss:-1.936\n",
      "Epoch:  0066 D loss:-0.5371 G loss:-2.086\n",
      "Epoch:  0066 D loss:-0.6729 G loss:-1.788\n",
      "Epoch:  0066 D loss:-0.7255 G loss:-1.858\n",
      "Epoch:  0066 D loss:-0.647 G loss:-1.996\n",
      "Epoch:  0066 D loss:-0.7918 G loss:-1.837\n",
      "Epoch:  0066 D loss:-0.7619 G loss:-2.036\n",
      "Epoch:  0066 D loss:-0.52 G loss:-2.163\n",
      "Epoch:  0067 D loss:-0.5951 G loss:-2.305\n",
      "Epoch:  0067 D loss:-0.6859 G loss:-2.231\n",
      "Epoch:  0067 D loss:-0.6564 G loss:-2.249\n",
      "Epoch:  0067 D loss:-0.7644 G loss:-2.178\n",
      "Epoch:  0067 D loss:-0.6467 G loss:-2.495\n",
      "Epoch:  0067 D loss:-0.5287 G loss:-2.366\n",
      "Epoch:  0067 D loss:-0.7043 G loss:-2.163\n",
      "Epoch:  0067 D loss:-0.5261 G loss:-2.169\n",
      "Epoch:  0067 D loss:-0.6792 G loss:-1.873\n",
      "Epoch:  0067 D loss:-0.7494 G loss:-1.814\n",
      "Epoch:  0067 D loss:-0.6622 G loss:-2.008\n",
      "Epoch:  0067 D loss:-0.5781 G loss:-1.934\n",
      "Epoch:  0067 D loss:-0.6771 G loss:-1.94\n",
      "Epoch:  0067 D loss:-0.6365 G loss:-2.035\n",
      "Epoch:  0067 D loss:-0.6151 G loss:-1.964\n",
      "Epoch:  0067 D loss:-0.5728 G loss:-1.966\n",
      "Epoch:  0067 D loss:-0.668 G loss:-2.008\n",
      "Epoch:  0067 D loss:-0.6007 G loss:-2.251\n",
      "Epoch:  0067 D loss:-0.5121 G loss:-2.348\n",
      "Epoch:  0067 D loss:-0.7802 G loss:-2.605\n",
      "Epoch:  0067 D loss:-0.6556 G loss:-2.37\n",
      "Epoch:  0067 D loss:-0.6738 G loss:-2.351\n",
      "Epoch:  0067 D loss:-0.6033 G loss:-2.19\n",
      "Epoch:  0067 D loss:-0.6825 G loss:-2.187\n",
      "Epoch:  0067 D loss:-0.674 G loss:-2.273\n",
      "Epoch:  0067 D loss:-0.7327 G loss:-2.015\n",
      "Epoch:  0067 D loss:-0.7273 G loss:-1.99\n",
      "Epoch:  0067 D loss:-0.6612 G loss:-1.744\n",
      "Epoch:  0067 D loss:-0.6403 G loss:-1.847\n",
      "Epoch:  0067 D loss:-0.6212 G loss:-2.015\n",
      "Epoch:  0067 D loss:-0.6993 G loss:-1.886\n",
      "Epoch:  0067 D loss:-0.821 G loss:-1.714\n",
      "Epoch:  0067 D loss:-0.7407 G loss:-1.89\n",
      "Epoch:  0067 D loss:-0.6905 G loss:-2.19\n",
      "Epoch:  0067 D loss:-0.6194 G loss:-2.528\n",
      "Epoch:  0067 D loss:-0.6701 G loss:-2.364\n",
      "Epoch:  0067 D loss:-0.6295 G loss:-2.42\n",
      "Epoch:  0067 D loss:-0.6773 G loss:-2.384\n",
      "Epoch:  0067 D loss:-0.6609 G loss:-2.241\n",
      "Epoch:  0067 D loss:-0.6725 G loss:-2.142\n",
      "Epoch:  0067 D loss:-0.6263 G loss:-2.188\n",
      "Epoch:  0067 D loss:-0.5876 G loss:-2.092\n",
      "Epoch:  0067 D loss:-0.7081 G loss:-2.19\n",
      "Epoch:  0067 D loss:-0.7935 G loss:-2.052\n",
      "Epoch:  0067 D loss:-0.5543 G loss:-2.274\n",
      "Epoch:  0067 D loss:-0.6821 G loss:-1.988\n",
      "Epoch:  0067 D loss:-0.562 G loss:-2.06\n",
      "Epoch:  0067 D loss:-0.7839 G loss:-1.843\n",
      "Epoch:  0067 D loss:-0.6715 G loss:-2.028\n",
      "Epoch:  0067 D loss:-0.8195 G loss:-1.74\n",
      "Epoch:  0067 D loss:-0.7176 G loss:-2.014\n",
      "Epoch:  0067 D loss:-0.6911 G loss:-2.019\n",
      "Epoch:  0067 D loss:-0.6949 G loss:-2.098\n",
      "Epoch:  0067 D loss:-0.8714 G loss:-2.079\n",
      "Epoch:  0067 D loss:-0.712 G loss:-2.218\n",
      "Epoch:  0067 D loss:-0.7647 G loss:-2.248\n",
      "Epoch:  0067 D loss:-0.5075 G loss:-2.286\n",
      "Epoch:  0067 D loss:-0.7368 G loss:-2.103\n",
      "Epoch:  0067 D loss:-0.6564 G loss:-2.254\n",
      "Epoch:  0067 D loss:-0.8701 G loss:-1.917\n",
      "Epoch:  0067 D loss:-0.7676 G loss:-2.25\n",
      "Epoch:  0067 D loss:-0.6771 G loss:-2.09\n",
      "Epoch:  0067 D loss:-0.6765 G loss:-2.211\n",
      "Epoch:  0067 D loss:-0.7045 G loss:-2.274\n",
      "Epoch:  0067 D loss:-0.6309 G loss:-2.164\n",
      "Epoch:  0067 D loss:-0.884 G loss:-1.886\n",
      "Epoch:  0067 D loss:-0.7862 G loss:-1.982\n",
      "Epoch:  0067 D loss:-0.7278 G loss:-1.656\n",
      "Epoch:  0067 D loss:-0.8011 G loss:-1.728\n",
      "Epoch:  0067 D loss:-0.6529 G loss:-1.78\n",
      "Epoch:  0067 D loss:-0.6763 G loss:-1.824\n",
      "Epoch:  0067 D loss:-0.6514 G loss:-1.992\n",
      "Epoch:  0067 D loss:-0.7549 G loss:-1.88\n",
      "Epoch:  0067 D loss:-0.6851 G loss:-2.115\n",
      "Epoch:  0067 D loss:-0.6838 G loss:-2.203\n",
      "Epoch:  0067 D loss:-0.773 G loss:-2.003\n",
      "Epoch:  0067 D loss:-0.7296 G loss:-2.098\n",
      "Epoch:  0067 D loss:-0.7192 G loss:-2.251\n",
      "Epoch:  0067 D loss:-0.7523 G loss:-2.352\n",
      "Epoch:  0067 D loss:-0.6025 G loss:-2.433\n",
      "Epoch:  0067 D loss:-0.7613 G loss:-2.255\n",
      "Epoch:  0067 D loss:-0.8806 G loss:-2.138\n",
      "Epoch:  0067 D loss:-0.733 G loss:-1.884\n",
      "Epoch:  0067 D loss:-0.5952 G loss:-1.896\n",
      "Epoch:  0067 D loss:-0.78 G loss:-1.875\n",
      "Epoch:  0067 D loss:-0.8074 G loss:-1.862\n",
      "Epoch:  0067 D loss:-0.671 G loss:-1.926\n",
      "Epoch:  0067 D loss:-0.8244 G loss:-1.743\n",
      "Epoch:  0067 D loss:-0.6251 G loss:-1.986\n",
      "Epoch:  0067 D loss:-0.7409 G loss:-1.982\n",
      "Epoch:  0067 D loss:-0.4959 G loss:-2.141\n",
      "Epoch:  0067 D loss:-0.6704 G loss:-2.229\n",
      "Epoch:  0067 D loss:-0.6826 G loss:-2.126\n",
      "Epoch:  0067 D loss:-0.6666 G loss:-2.011\n",
      "Epoch:  0067 D loss:-0.7694 G loss:-2.368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0067 D loss:-0.9044 G loss:-2.409\n",
      "Epoch:  0067 D loss:-0.7166 G loss:-2.217\n",
      "Epoch:  0067 D loss:-0.7568 G loss:-2.174\n",
      "Epoch:  0067 D loss:-0.7958 G loss:-1.986\n",
      "Epoch:  0067 D loss:-0.6509 G loss:-1.82\n",
      "Epoch:  0067 D loss:-0.6383 G loss:-1.976\n",
      "Epoch:  0067 D loss:-0.5965 G loss:-2.03\n",
      "Epoch:  0067 D loss:-0.6162 G loss:-1.869\n",
      "Epoch:  0067 D loss:-0.7769 G loss:-1.938\n",
      "Epoch:  0067 D loss:-0.698 G loss:-2.019\n",
      "Epoch:  0067 D loss:-0.5589 G loss:-2.189\n",
      "Epoch:  0067 D loss:-0.6543 G loss:-2.163\n",
      "Epoch:  0067 D loss:-0.6395 G loss:-2.102\n",
      "Epoch:  0067 D loss:-0.6412 G loss:-2.183\n",
      "Epoch:  0067 D loss:-0.6308 G loss:-2.293\n",
      "Epoch:  0067 D loss:-0.608 G loss:-2.206\n",
      "Epoch:  0067 D loss:-0.7759 G loss:-2.111\n",
      "Epoch:  0067 D loss:-0.7687 G loss:-2.083\n",
      "Epoch:  0067 D loss:-0.7038 G loss:-1.92\n",
      "Epoch:  0067 D loss:-0.6334 G loss:-2.157\n",
      "Epoch:  0067 D loss:-0.754 G loss:-2.072\n",
      "Epoch:  0067 D loss:-0.7356 G loss:-2.079\n",
      "Epoch:  0067 D loss:-0.7093 G loss:-2.0\n",
      "Epoch:  0067 D loss:-0.7744 G loss:-1.978\n",
      "Epoch:  0067 D loss:-0.7941 G loss:-2.031\n",
      "Epoch:  0067 D loss:-0.8816 G loss:-1.966\n",
      "Epoch:  0067 D loss:-0.5288 G loss:-2.127\n",
      "Epoch:  0067 D loss:-0.6502 G loss:-2.061\n",
      "Epoch:  0067 D loss:-0.7046 G loss:-1.946\n",
      "Epoch:  0067 D loss:-0.717 G loss:-2.324\n",
      "Epoch:  0067 D loss:-0.6632 G loss:-2.126\n",
      "Epoch:  0067 D loss:-0.7418 G loss:-2.103\n",
      "Epoch:  0067 D loss:-0.7918 G loss:-1.997\n",
      "Epoch:  0067 D loss:-0.6189 G loss:-2.214\n",
      "Epoch:  0067 D loss:-0.7542 G loss:-2.25\n",
      "Epoch:  0067 D loss:-0.6988 G loss:-2.164\n",
      "Epoch:  0067 D loss:-0.6891 G loss:-1.936\n",
      "Epoch:  0067 D loss:-0.6969 G loss:-2.246\n",
      "Epoch:  0067 D loss:-0.5524 G loss:-2.211\n",
      "Epoch:  0067 D loss:-0.5765 G loss:-1.854\n",
      "Epoch:  0067 D loss:-0.705 G loss:-2.051\n",
      "Epoch:  0067 D loss:-0.6676 G loss:-2.051\n",
      "Epoch:  0067 D loss:-0.6039 G loss:-2.006\n",
      "Epoch:  0067 D loss:-0.6909 G loss:-1.96\n",
      "Epoch:  0067 D loss:-0.5834 G loss:-2.185\n",
      "Epoch:  0067 D loss:-0.6485 G loss:-2.211\n",
      "Epoch:  0067 D loss:-0.5955 G loss:-2.067\n",
      "Epoch:  0067 D loss:-0.6684 G loss:-2.097\n",
      "Epoch:  0067 D loss:-0.6397 G loss:-2.065\n",
      "Epoch:  0067 D loss:-0.6337 G loss:-2.316\n",
      "Epoch:  0067 D loss:-0.8433 G loss:-2.026\n",
      "Epoch:  0067 D loss:-0.7432 G loss:-2.007\n",
      "Epoch:  0067 D loss:-0.8541 G loss:-2.24\n",
      "Epoch:  0067 D loss:-0.5855 G loss:-2.207\n",
      "Epoch:  0067 D loss:-0.5959 G loss:-1.969\n",
      "Epoch:  0067 D loss:-0.6429 G loss:-1.91\n",
      "Epoch:  0067 D loss:-0.8296 G loss:-1.719\n",
      "Epoch:  0067 D loss:-0.8725 G loss:-2.096\n",
      "Epoch:  0067 D loss:-0.7328 G loss:-2.058\n",
      "Epoch:  0067 D loss:-0.5868 G loss:-2.039\n",
      "Epoch:  0067 D loss:-0.5442 G loss:-2.246\n",
      "Epoch:  0067 D loss:-0.7137 G loss:-1.997\n",
      "Epoch:  0067 D loss:-0.5709 G loss:-2.121\n",
      "Epoch:  0067 D loss:-0.7129 G loss:-2.057\n",
      "Epoch:  0067 D loss:-0.6343 G loss:-2.142\n",
      "Epoch:  0067 D loss:-0.7632 G loss:-1.892\n",
      "Epoch:  0067 D loss:-0.6922 G loss:-1.961\n",
      "Epoch:  0067 D loss:-0.5887 G loss:-2.372\n",
      "Epoch:  0067 D loss:-0.7157 G loss:-2.05\n",
      "Epoch:  0067 D loss:-0.6448 G loss:-2.193\n",
      "Epoch:  0067 D loss:-0.7033 G loss:-2.176\n",
      "Epoch:  0067 D loss:-0.7071 G loss:-2.098\n",
      "Epoch:  0067 D loss:-0.6383 G loss:-2.186\n",
      "Epoch:  0067 D loss:-0.7096 G loss:-2.001\n",
      "Epoch:  0067 D loss:-0.6157 G loss:-2.039\n",
      "Epoch:  0067 D loss:-0.6509 G loss:-2.095\n",
      "Epoch:  0067 D loss:-0.5781 G loss:-2.065\n",
      "Epoch:  0067 D loss:-0.6582 G loss:-2.043\n",
      "Epoch:  0067 D loss:-0.6138 G loss:-1.956\n",
      "Epoch:  0067 D loss:-0.6637 G loss:-1.859\n",
      "Epoch:  0067 D loss:-0.7087 G loss:-2.051\n",
      "Epoch:  0067 D loss:-0.7195 G loss:-2.209\n",
      "Epoch:  0067 D loss:-0.6665 G loss:-2.082\n",
      "Epoch:  0067 D loss:-0.8273 G loss:-2.021\n",
      "Epoch:  0067 D loss:-0.8653 G loss:-2.204\n",
      "Epoch:  0067 D loss:-0.7112 G loss:-2.322\n",
      "Epoch:  0067 D loss:-0.6647 G loss:-1.911\n",
      "Epoch:  0067 D loss:-0.584 G loss:-2.033\n",
      "Epoch:  0067 D loss:-0.5592 G loss:-1.913\n",
      "Epoch:  0067 D loss:-0.682 G loss:-1.883\n",
      "Epoch:  0067 D loss:-0.5619 G loss:-1.758\n",
      "Epoch:  0067 D loss:-0.6349 G loss:-1.733\n",
      "Epoch:  0067 D loss:-0.7423 G loss:-1.959\n",
      "Epoch:  0067 D loss:-0.5532 G loss:-2.087\n",
      "Epoch:  0067 D loss:-0.6078 G loss:-2.126\n",
      "Epoch:  0067 D loss:-0.7369 G loss:-2.221\n",
      "Epoch:  0067 D loss:-0.6435 G loss:-2.332\n",
      "Epoch:  0067 D loss:-0.7104 G loss:-2.299\n",
      "Epoch:  0067 D loss:-0.7787 G loss:-2.294\n",
      "Epoch:  0067 D loss:-0.8135 G loss:-2.433\n",
      "Epoch:  0067 D loss:-0.7385 G loss:-2.134\n",
      "Epoch:  0067 D loss:-0.7747 G loss:-2.048\n",
      "Epoch:  0067 D loss:-0.7524 G loss:-1.917\n",
      "Epoch:  0067 D loss:-0.5806 G loss:-1.978\n",
      "Epoch:  0067 D loss:-0.7855 G loss:-1.753\n",
      "Epoch:  0067 D loss:-0.7363 G loss:-1.773\n",
      "Epoch:  0067 D loss:-0.8043 G loss:-1.702\n",
      "Epoch:  0067 D loss:-0.7341 G loss:-1.917\n",
      "Epoch:  0067 D loss:-0.8027 G loss:-1.77\n",
      "Epoch:  0067 D loss:-0.798 G loss:-1.938\n",
      "Epoch:  0067 D loss:-0.5262 G loss:-2.19\n",
      "Epoch:  0067 D loss:-0.6598 G loss:-1.935\n",
      "Epoch:  0067 D loss:-0.7257 G loss:-2.053\n",
      "Epoch:  0067 D loss:-0.6634 G loss:-2.162\n",
      "Epoch:  0067 D loss:-0.8112 G loss:-2.071\n",
      "Epoch:  0067 D loss:-0.6768 G loss:-2.313\n",
      "Epoch:  0067 D loss:-0.6232 G loss:-2.263\n",
      "Epoch:  0067 D loss:-0.7329 G loss:-2.343\n",
      "Epoch:  0067 D loss:-0.6961 G loss:-2.069\n",
      "Epoch:  0067 D loss:-0.724 G loss:-1.986\n",
      "Epoch:  0067 D loss:-0.8359 G loss:-1.722\n",
      "Epoch:  0067 D loss:-0.7177 G loss:-1.819\n",
      "Epoch:  0067 D loss:-0.6488 G loss:-1.981\n",
      "Epoch:  0067 D loss:-0.6747 G loss:-1.803\n",
      "Epoch:  0067 D loss:-0.792 G loss:-1.74\n",
      "Epoch:  0067 D loss:-0.7273 G loss:-1.849\n",
      "Epoch:  0067 D loss:-0.796 G loss:-1.953\n",
      "Epoch:  0067 D loss:-0.6031 G loss:-2.19\n",
      "Epoch:  0067 D loss:-0.6733 G loss:-2.203\n",
      "Epoch:  0067 D loss:-0.7953 G loss:-2.053\n",
      "Epoch:  0067 D loss:-0.8096 G loss:-1.985\n",
      "Epoch:  0067 D loss:-0.72 G loss:-2.006\n",
      "Epoch:  0067 D loss:-0.6724 G loss:-2.362\n",
      "Epoch:  0067 D loss:-0.6272 G loss:-2.2\n",
      "Epoch:  0067 D loss:-0.7433 G loss:-2.165\n",
      "Epoch:  0067 D loss:-0.7506 G loss:-2.094\n",
      "Epoch:  0067 D loss:-0.9061 G loss:-1.804\n",
      "Epoch:  0067 D loss:-0.7731 G loss:-1.965\n",
      "Epoch:  0067 D loss:-0.7451 G loss:-1.94\n",
      "Epoch:  0067 D loss:-0.6783 G loss:-2.07\n",
      "Epoch:  0067 D loss:-0.6026 G loss:-1.94\n",
      "Epoch:  0067 D loss:-0.6998 G loss:-1.957\n",
      "Epoch:  0067 D loss:-0.7126 G loss:-1.779\n",
      "Epoch:  0067 D loss:-0.6395 G loss:-2.06\n",
      "Epoch:  0067 D loss:-0.7588 G loss:-2.035\n",
      "Epoch:  0067 D loss:-0.6241 G loss:-2.05\n",
      "Epoch:  0067 D loss:-0.592 G loss:-2.211\n",
      "Epoch:  0067 D loss:-0.5767 G loss:-2.301\n",
      "Epoch:  0067 D loss:-0.6857 G loss:-2.148\n",
      "Epoch:  0067 D loss:-0.7209 G loss:-2.094\n",
      "Epoch:  0067 D loss:-0.6641 G loss:-2.169\n",
      "Epoch:  0067 D loss:-0.6038 G loss:-2.235\n",
      "Epoch:  0067 D loss:-0.7644 G loss:-2.073\n",
      "Epoch:  0067 D loss:-0.7898 G loss:-2.226\n",
      "Epoch:  0067 D loss:-0.6847 G loss:-2.132\n",
      "Epoch:  0067 D loss:-0.7281 G loss:-2.067\n",
      "Epoch:  0067 D loss:-0.6123 G loss:-1.967\n",
      "Epoch:  0067 D loss:-0.6082 G loss:-2.129\n",
      "Epoch:  0067 D loss:-0.6278 G loss:-1.9\n",
      "Epoch:  0067 D loss:-0.5203 G loss:-2.018\n",
      "Epoch:  0067 D loss:-0.5723 G loss:-2.119\n",
      "Epoch:  0067 D loss:-0.8132 G loss:-2.04\n",
      "Epoch:  0067 D loss:-0.573 G loss:-2.096\n",
      "Epoch:  0067 D loss:-0.6601 G loss:-2.122\n",
      "Epoch:  0067 D loss:-0.6561 G loss:-2.451\n",
      "Epoch:  0067 D loss:-0.5298 G loss:-2.365\n",
      "Epoch:  0067 D loss:-0.6006 G loss:-2.429\n",
      "Epoch:  0067 D loss:-0.4763 G loss:-2.352\n",
      "Epoch:  0067 D loss:-0.6466 G loss:-2.259\n",
      "Epoch:  0067 D loss:-0.5959 G loss:-2.101\n",
      "Epoch:  0067 D loss:-0.5343 G loss:-2.272\n",
      "Epoch:  0067 D loss:-0.5997 G loss:-2.117\n",
      "Epoch:  0067 D loss:-0.6355 G loss:-1.847\n",
      "Epoch:  0067 D loss:-0.7867 G loss:-1.818\n",
      "Epoch:  0067 D loss:-0.5748 G loss:-1.996\n",
      "Epoch:  0067 D loss:-0.6611 G loss:-2.133\n",
      "Epoch:  0067 D loss:-0.815 G loss:-1.904\n",
      "Epoch:  0067 D loss:-0.6855 G loss:-1.924\n",
      "Epoch:  0067 D loss:-0.6021 G loss:-2.142\n",
      "Epoch:  0067 D loss:-0.6938 G loss:-2.205\n",
      "Epoch:  0067 D loss:-0.579 G loss:-2.122\n",
      "Epoch:  0067 D loss:-0.5827 G loss:-2.238\n",
      "Epoch:  0067 D loss:-0.6541 G loss:-2.222\n",
      "Epoch:  0067 D loss:-0.6697 G loss:-2.167\n",
      "Epoch:  0067 D loss:-0.6744 G loss:-2.183\n",
      "Epoch:  0067 D loss:-0.7518 G loss:-2.001\n",
      "Epoch:  0067 D loss:-0.8067 G loss:-2.071\n",
      "Epoch:  0067 D loss:-0.6604 G loss:-2.029\n",
      "Epoch:  0067 D loss:-0.63 G loss:-2.082\n",
      "Epoch:  0067 D loss:-0.5862 G loss:-2.221\n",
      "Epoch:  0067 D loss:-0.5759 G loss:-2.076\n",
      "Epoch:  0067 D loss:-0.5855 G loss:-2.008\n",
      "Epoch:  0067 D loss:-0.5026 G loss:-2.152\n",
      "Epoch:  0067 D loss:-0.6143 G loss:-2.087\n",
      "Epoch:  0067 D loss:-0.6257 G loss:-2.361\n",
      "Epoch:  0067 D loss:-0.655 G loss:-2.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0067 D loss:-0.5135 G loss:-2.376\n",
      "Epoch:  0067 D loss:-0.6481 G loss:-2.048\n",
      "Epoch:  0067 D loss:-0.764 G loss:-2.218\n",
      "Epoch:  0067 D loss:-0.62 G loss:-2.312\n",
      "Epoch:  0067 D loss:-0.6607 G loss:-2.133\n",
      "Epoch:  0067 D loss:-0.5457 G loss:-2.31\n",
      "Epoch:  0067 D loss:-0.7506 G loss:-2.238\n",
      "Epoch:  0067 D loss:-0.5959 G loss:-2.268\n",
      "Epoch:  0067 D loss:-0.6853 G loss:-2.085\n",
      "Epoch:  0067 D loss:-0.8492 G loss:-1.884\n",
      "Epoch:  0067 D loss:-0.7183 G loss:-1.94\n",
      "Epoch:  0067 D loss:-0.5631 G loss:-1.998\n",
      "Epoch:  0067 D loss:-0.6808 G loss:-1.803\n",
      "Epoch:  0067 D loss:-0.7035 G loss:-1.837\n",
      "Epoch:  0067 D loss:-0.6979 G loss:-2.056\n",
      "Epoch:  0067 D loss:-0.6854 G loss:-1.941\n",
      "Epoch:  0067 D loss:-0.7192 G loss:-1.843\n",
      "Epoch:  0067 D loss:-0.7621 G loss:-1.872\n",
      "Epoch:  0067 D loss:-0.6231 G loss:-2.124\n",
      "Epoch:  0067 D loss:-0.6657 G loss:-2.102\n",
      "Epoch:  0067 D loss:-0.7123 G loss:-2.136\n",
      "Epoch:  0067 D loss:-0.6496 G loss:-2.076\n",
      "Epoch:  0067 D loss:-0.6223 G loss:-2.086\n",
      "Epoch:  0067 D loss:-0.6848 G loss:-2.304\n",
      "Epoch:  0067 D loss:-0.8416 G loss:-2.225\n",
      "Epoch:  0067 D loss:-0.6347 G loss:-2.123\n",
      "Epoch:  0067 D loss:-0.592 G loss:-2.184\n",
      "Epoch:  0067 D loss:-0.7424 G loss:-2.018\n",
      "Epoch:  0067 D loss:-0.794 G loss:-1.898\n",
      "Epoch:  0067 D loss:-0.8593 G loss:-1.868\n",
      "Epoch:  0067 D loss:-0.7601 G loss:-1.923\n",
      "Epoch:  0067 D loss:-0.6741 G loss:-1.982\n",
      "Epoch:  0067 D loss:-0.5922 G loss:-1.923\n",
      "Epoch:  0067 D loss:-0.7415 G loss:-1.9\n",
      "Epoch:  0067 D loss:-0.7283 G loss:-1.871\n",
      "Epoch:  0067 D loss:-0.7692 G loss:-1.903\n",
      "Epoch:  0067 D loss:-0.7333 G loss:-1.924\n",
      "Epoch:  0067 D loss:-0.6871 G loss:-2.064\n",
      "Epoch:  0067 D loss:-0.9434 G loss:-2.015\n",
      "Epoch:  0067 D loss:-0.7002 G loss:-2.091\n",
      "Epoch:  0067 D loss:-0.7883 G loss:-1.978\n",
      "Epoch:  0067 D loss:-0.8247 G loss:-1.925\n",
      "Epoch:  0067 D loss:-0.7501 G loss:-2.106\n",
      "Epoch:  0067 D loss:-0.7736 G loss:-2.052\n",
      "Epoch:  0067 D loss:-0.7211 G loss:-2.172\n",
      "Epoch:  0067 D loss:-0.6797 G loss:-1.998\n",
      "Epoch:  0067 D loss:-0.7019 G loss:-1.823\n",
      "Epoch:  0067 D loss:-0.8033 G loss:-1.901\n",
      "Epoch:  0067 D loss:-0.8553 G loss:-1.852\n",
      "Epoch:  0067 D loss:-0.7956 G loss:-1.959\n",
      "Epoch:  0067 D loss:-0.7462 G loss:-1.885\n",
      "Epoch:  0067 D loss:-0.6738 G loss:-1.924\n",
      "Epoch:  0067 D loss:-0.7139 G loss:-1.876\n",
      "Epoch:  0067 D loss:-0.7136 G loss:-2.063\n",
      "Epoch:  0067 D loss:-0.6634 G loss:-2.021\n",
      "Epoch:  0067 D loss:-0.6304 G loss:-2.15\n",
      "Epoch:  0067 D loss:-0.6816 G loss:-1.953\n",
      "Epoch:  0067 D loss:-0.6315 G loss:-1.989\n",
      "Epoch:  0067 D loss:-0.7269 G loss:-2.344\n",
      "Epoch:  0067 D loss:-0.6339 G loss:-2.067\n",
      "Epoch:  0067 D loss:-0.7127 G loss:-2.123\n",
      "Epoch:  0067 D loss:-0.6493 G loss:-2.11\n",
      "Epoch:  0067 D loss:-0.6365 G loss:-1.985\n",
      "Epoch:  0067 D loss:-0.624 G loss:-1.963\n",
      "Epoch:  0067 D loss:-0.6771 G loss:-1.971\n",
      "Epoch:  0067 D loss:-0.72 G loss:-1.91\n",
      "Epoch:  0067 D loss:-0.5632 G loss:-2.313\n",
      "Epoch:  0067 D loss:-0.8387 G loss:-2.083\n",
      "Epoch:  0067 D loss:-0.6607 G loss:-1.911\n",
      "Epoch:  0067 D loss:-1.024 G loss:-1.917\n",
      "Epoch:  0067 D loss:-0.6997 G loss:-2.155\n",
      "Epoch:  0067 D loss:-0.7285 G loss:-1.974\n",
      "Epoch:  0067 D loss:-0.7651 G loss:-1.833\n",
      "Epoch:  0067 D loss:-0.8407 G loss:-1.645\n",
      "Epoch:  0067 D loss:-0.8296 G loss:-1.981\n",
      "Epoch:  0067 D loss:-0.6369 G loss:-2.191\n",
      "Epoch:  0067 D loss:-0.7588 G loss:-2.065\n",
      "Epoch:  0067 D loss:-0.7994 G loss:-1.987\n",
      "Epoch:  0067 D loss:-0.6676 G loss:-2.223\n",
      "Epoch:  0067 D loss:-0.7238 G loss:-1.899\n",
      "Epoch:  0067 D loss:-0.7168 G loss:-2.09\n",
      "Epoch:  0067 D loss:-0.6528 G loss:-2.249\n",
      "Epoch:  0067 D loss:-0.8363 G loss:-1.948\n",
      "Epoch:  0067 D loss:-0.5965 G loss:-2.103\n",
      "Epoch:  0067 D loss:-0.5896 G loss:-2.367\n",
      "Epoch:  0067 D loss:-0.7465 G loss:-2.077\n",
      "Epoch:  0067 D loss:-0.8219 G loss:-2.108\n",
      "Epoch:  0067 D loss:-0.8267 G loss:-2.092\n",
      "Epoch:  0067 D loss:-0.7098 G loss:-2.379\n",
      "Epoch:  0067 D loss:-0.771 G loss:-1.848\n",
      "Epoch:  0067 D loss:-0.6491 G loss:-1.896\n",
      "Epoch:  0067 D loss:-0.7779 G loss:-1.887\n",
      "Epoch:  0067 D loss:-0.6298 G loss:-2.095\n",
      "Epoch:  0067 D loss:-0.6071 G loss:-1.9\n",
      "Epoch:  0067 D loss:-0.7468 G loss:-2.115\n",
      "Epoch:  0067 D loss:-0.563 G loss:-2.117\n",
      "Epoch:  0067 D loss:-0.6069 G loss:-2.152\n",
      "Epoch:  0067 D loss:-0.7521 G loss:-1.992\n",
      "Epoch:  0067 D loss:-0.7431 G loss:-2.072\n",
      "Epoch:  0067 D loss:-0.7323 G loss:-1.873\n",
      "Epoch:  0067 D loss:-0.7728 G loss:-1.8\n",
      "Epoch:  0067 D loss:-0.5992 G loss:-2.258\n",
      "Epoch:  0067 D loss:-0.6285 G loss:-2.052\n",
      "Epoch:  0067 D loss:-0.7111 G loss:-1.909\n",
      "Epoch:  0067 D loss:-0.6184 G loss:-2.039\n",
      "Epoch:  0067 D loss:-0.7365 G loss:-2.11\n",
      "Epoch:  0067 D loss:-0.561 G loss:-2.19\n",
      "Epoch:  0067 D loss:-0.6254 G loss:-2.117\n",
      "Epoch:  0067 D loss:-0.5154 G loss:-2.51\n",
      "Epoch:  0067 D loss:-0.6676 G loss:-2.064\n",
      "Epoch:  0067 D loss:-0.6997 G loss:-2.204\n",
      "Epoch:  0067 D loss:-0.6209 G loss:-2.094\n",
      "Epoch:  0067 D loss:-0.5857 G loss:-2.265\n",
      "Epoch:  0067 D loss:-0.6216 G loss:-2.11\n",
      "Epoch:  0067 D loss:-0.7048 G loss:-2.343\n",
      "Epoch:  0067 D loss:-0.8219 G loss:-2.167\n",
      "Epoch:  0067 D loss:-0.559 G loss:-2.288\n",
      "Epoch:  0067 D loss:-0.6942 G loss:-1.984\n",
      "Epoch:  0067 D loss:-0.7289 G loss:-1.839\n",
      "Epoch:  0067 D loss:-0.6414 G loss:-1.984\n",
      "Epoch:  0067 D loss:-0.6351 G loss:-1.898\n",
      "Epoch:  0067 D loss:-0.6842 G loss:-2.019\n",
      "Epoch:  0067 D loss:-0.6034 G loss:-2.154\n",
      "Epoch:  0067 D loss:-0.6822 G loss:-2.001\n",
      "Epoch:  0067 D loss:-0.6318 G loss:-2.102\n",
      "Epoch:  0067 D loss:-0.6158 G loss:-2.281\n",
      "Epoch:  0067 D loss:-0.6494 G loss:-2.238\n",
      "Epoch:  0067 D loss:-0.7854 G loss:-2.117\n",
      "Epoch:  0067 D loss:-0.6407 G loss:-2.278\n",
      "Epoch:  0067 D loss:-0.6988 G loss:-2.114\n",
      "Epoch:  0067 D loss:-0.5938 G loss:-2.332\n",
      "Epoch:  0067 D loss:-0.7195 G loss:-2.216\n",
      "Epoch:  0067 D loss:-0.8128 G loss:-2.088\n",
      "Epoch:  0067 D loss:-0.8583 G loss:-2.109\n",
      "Epoch:  0067 D loss:-0.6102 G loss:-2.17\n",
      "Epoch:  0067 D loss:-0.6738 G loss:-2.032\n",
      "Epoch:  0067 D loss:-0.5836 G loss:-1.957\n",
      "Epoch:  0067 D loss:-0.6795 G loss:-2.133\n",
      "Epoch:  0067 D loss:-0.7393 G loss:-1.807\n",
      "Epoch:  0067 D loss:-0.6965 G loss:-1.903\n",
      "Epoch:  0067 D loss:-0.6739 G loss:-1.855\n",
      "Epoch:  0067 D loss:-0.6766 G loss:-2.032\n",
      "Epoch:  0067 D loss:-0.6927 G loss:-1.961\n",
      "Epoch:  0067 D loss:-0.7613 G loss:-2.218\n",
      "Epoch:  0067 D loss:-0.6637 G loss:-2.209\n",
      "Epoch:  0067 D loss:-0.5598 G loss:-2.2\n",
      "Epoch:  0067 D loss:-0.7696 G loss:-2.23\n",
      "Epoch:  0067 D loss:-0.6762 G loss:-2.229\n",
      "Epoch:  0067 D loss:-0.8393 G loss:-2.028\n",
      "Epoch:  0067 D loss:-0.665 G loss:-2.01\n",
      "Epoch:  0067 D loss:-0.7577 G loss:-1.942\n",
      "Epoch:  0067 D loss:-0.8826 G loss:-1.862\n",
      "Epoch:  0067 D loss:-0.7218 G loss:-2.12\n",
      "Epoch:  0067 D loss:-0.5055 G loss:-2.071\n",
      "Epoch:  0067 D loss:-0.7267 G loss:-1.862\n",
      "Epoch:  0067 D loss:-0.6453 G loss:-2.114\n",
      "Epoch:  0067 D loss:-0.7553 G loss:-1.943\n",
      "Epoch:  0067 D loss:-0.6339 G loss:-2.09\n",
      "Epoch:  0067 D loss:-0.5856 G loss:-2.084\n",
      "Epoch:  0067 D loss:-0.7259 G loss:-2.138\n",
      "Epoch:  0067 D loss:-0.6719 G loss:-2.155\n",
      "Epoch:  0067 D loss:-0.7374 G loss:-2.062\n",
      "Epoch:  0067 D loss:-0.5525 G loss:-2.395\n",
      "Epoch:  0067 D loss:-0.7381 G loss:-2.243\n",
      "Epoch:  0067 D loss:-0.77 G loss:-2.172\n",
      "Epoch:  0067 D loss:-0.6803 G loss:-2.109\n",
      "Epoch:  0067 D loss:-0.7829 G loss:-1.799\n",
      "Epoch:  0067 D loss:-0.6836 G loss:-1.996\n",
      "Epoch:  0067 D loss:-0.7394 G loss:-1.987\n",
      "Epoch:  0067 D loss:-0.7718 G loss:-1.981\n",
      "Epoch:  0067 D loss:-0.6349 G loss:-2.141\n",
      "Epoch:  0067 D loss:-0.7146 G loss:-2.004\n",
      "Epoch:  0067 D loss:-0.6363 G loss:-1.962\n",
      "Epoch:  0067 D loss:-0.6049 G loss:-2.004\n",
      "Epoch:  0067 D loss:-0.7914 G loss:-1.737\n",
      "Epoch:  0067 D loss:-0.6301 G loss:-2.108\n",
      "Epoch:  0067 D loss:-0.6946 G loss:-2.26\n",
      "Epoch:  0067 D loss:-0.8273 G loss:-2.169\n",
      "Epoch:  0067 D loss:-0.6403 G loss:-2.079\n",
      "Epoch:  0067 D loss:-0.7122 G loss:-2.111\n",
      "Epoch:  0067 D loss:-0.5762 G loss:-1.957\n",
      "Epoch:  0067 D loss:-0.702 G loss:-2.139\n",
      "Epoch:  0067 D loss:-0.8282 G loss:-1.939\n",
      "Epoch:  0067 D loss:-0.7595 G loss:-1.957\n",
      "Epoch:  0067 D loss:-0.7083 G loss:-1.992\n",
      "Epoch:  0067 D loss:-0.8431 G loss:-2.069\n",
      "Epoch:  0067 D loss:-0.7062 G loss:-1.999\n",
      "Epoch:  0067 D loss:-0.7315 G loss:-2.138\n",
      "Epoch:  0067 D loss:-0.6635 G loss:-2.219\n",
      "Epoch:  0067 D loss:-0.7745 G loss:-2.103\n",
      "Epoch:  0067 D loss:-0.6962 G loss:-2.164\n",
      "Epoch:  0067 D loss:-0.6961 G loss:-2.109\n",
      "Epoch:  0067 D loss:-0.7348 G loss:-2.192\n",
      "Epoch:  0067 D loss:-0.7155 G loss:-1.915\n",
      "Epoch:  0067 D loss:-0.6842 G loss:-2.11\n",
      "Epoch:  0067 D loss:-0.845 G loss:-1.969\n",
      "Epoch:  0067 D loss:-0.7115 G loss:-1.95\n",
      "Epoch:  0067 D loss:-0.7916 G loss:-1.936\n",
      "Epoch:  0067 D loss:-0.8483 G loss:-1.866\n",
      "Epoch:  0067 D loss:-0.6828 G loss:-1.857\n",
      "Epoch:  0067 D loss:-0.7143 G loss:-2.037\n",
      "Epoch:  0067 D loss:-0.8368 G loss:-1.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0067 D loss:-0.7651 G loss:-2.008\n",
      "Epoch:  0067 D loss:-0.6378 G loss:-1.946\n",
      "Epoch:  0067 D loss:-0.7235 G loss:-1.891\n",
      "Epoch:  0067 D loss:-0.7281 G loss:-1.836\n",
      "Epoch:  0067 D loss:-0.7336 G loss:-2.066\n",
      "Epoch:  0067 D loss:-0.706 G loss:-2.002\n",
      "Epoch:  0067 D loss:-0.6787 G loss:-2.204\n",
      "Epoch:  0067 D loss:-0.7743 G loss:-2.125\n",
      "Epoch:  0067 D loss:-0.7409 G loss:-2.171\n",
      "Epoch:  0067 D loss:-0.8556 G loss:-1.948\n",
      "Epoch:  0067 D loss:-0.9292 G loss:-1.909\n",
      "Epoch:  0067 D loss:-0.7244 G loss:-2.041\n",
      "Epoch:  0067 D loss:-0.7321 G loss:-1.937\n",
      "Epoch:  0067 D loss:-0.7257 G loss:-1.799\n",
      "Epoch:  0067 D loss:-0.7734 G loss:-1.792\n",
      "Epoch:  0067 D loss:-0.5205 G loss:-1.964\n",
      "Epoch:  0067 D loss:-0.8765 G loss:-1.796\n",
      "Epoch:  0067 D loss:-0.7651 G loss:-2.052\n",
      "Epoch:  0067 D loss:-0.8188 G loss:-1.878\n",
      "Epoch:  0067 D loss:-0.7388 G loss:-2.048\n",
      "Epoch:  0067 D loss:-0.6058 G loss:-2.103\n",
      "Epoch:  0067 D loss:-0.6666 G loss:-2.056\n",
      "Epoch:  0067 D loss:-0.8216 G loss:-2.045\n",
      "Epoch:  0067 D loss:-0.7208 G loss:-2.191\n",
      "Epoch:  0067 D loss:-0.6532 G loss:-2.152\n",
      "Epoch:  0067 D loss:-0.7796 G loss:-2.286\n",
      "Epoch:  0067 D loss:-0.7693 G loss:-2.1\n",
      "Epoch:  0067 D loss:-0.797 G loss:-2.036\n",
      "Epoch:  0067 D loss:-0.7574 G loss:-2.021\n",
      "Epoch:  0067 D loss:-0.7057 G loss:-2.105\n",
      "Epoch:  0067 D loss:-0.6746 G loss:-2.146\n",
      "Epoch:  0067 D loss:-0.7004 G loss:-1.867\n",
      "Epoch:  0067 D loss:-0.5896 G loss:-1.888\n",
      "Epoch:  0067 D loss:-0.7317 G loss:-2.059\n",
      "Epoch:  0067 D loss:-0.6484 G loss:-1.902\n",
      "Epoch:  0067 D loss:-0.7482 G loss:-1.866\n",
      "Epoch:  0067 D loss:-0.7032 G loss:-1.967\n",
      "Epoch:  0067 D loss:-0.729 G loss:-1.951\n",
      "Epoch:  0067 D loss:-0.7196 G loss:-2.135\n",
      "Epoch:  0067 D loss:-0.6984 G loss:-2.208\n",
      "Epoch:  0067 D loss:-0.7345 G loss:-2.149\n",
      "Epoch:  0067 D loss:-0.7882 G loss:-2.072\n",
      "Epoch:  0067 D loss:-0.7082 G loss:-2.319\n",
      "Epoch:  0067 D loss:-0.6581 G loss:-2.002\n",
      "Epoch:  0067 D loss:-0.8922 G loss:-1.906\n",
      "Epoch:  0067 D loss:-0.6231 G loss:-2.077\n",
      "Epoch:  0067 D loss:-0.6611 G loss:-1.932\n",
      "Epoch:  0067 D loss:-0.6346 G loss:-1.779\n",
      "Epoch:  0067 D loss:-0.6915 G loss:-1.877\n",
      "Epoch:  0067 D loss:-0.7095 G loss:-1.913\n",
      "Epoch:  0067 D loss:-0.7119 G loss:-1.863\n",
      "Epoch:  0067 D loss:-0.7801 G loss:-1.966\n",
      "Epoch:  0067 D loss:-0.6812 G loss:-2.069\n",
      "Epoch:  0067 D loss:-0.6206 G loss:-2.063\n",
      "Epoch:  0067 D loss:-0.6124 G loss:-2.035\n",
      "Epoch:  0067 D loss:-0.7168 G loss:-2.053\n",
      "Epoch:  0067 D loss:-0.6345 G loss:-2.077\n",
      "Epoch:  0068 D loss:-0.567 G loss:-2.128\n",
      "Epoch:  0068 D loss:-0.6236 G loss:-2.248\n",
      "Epoch:  0068 D loss:-0.5838 G loss:-2.08\n",
      "Epoch:  0068 D loss:-0.6393 G loss:-2.085\n",
      "Epoch:  0068 D loss:-0.471 G loss:-2.217\n",
      "Epoch:  0068 D loss:-0.7016 G loss:-2.025\n",
      "Epoch:  0068 D loss:-0.5618 G loss:-2.116\n",
      "Epoch:  0068 D loss:-0.7521 G loss:-2.155\n",
      "Epoch:  0068 D loss:-0.7363 G loss:-1.941\n",
      "Epoch:  0068 D loss:-0.6683 G loss:-2.432\n",
      "Epoch:  0068 D loss:-0.6843 G loss:-2.367\n",
      "Epoch:  0068 D loss:-0.6204 G loss:-2.27\n",
      "Epoch:  0068 D loss:-0.7374 G loss:-1.944\n",
      "Epoch:  0068 D loss:-0.6112 G loss:-1.954\n",
      "Epoch:  0068 D loss:-0.5992 G loss:-2.146\n",
      "Epoch:  0068 D loss:-0.6668 G loss:-2.161\n",
      "Epoch:  0068 D loss:-0.6235 G loss:-2.011\n",
      "Epoch:  0068 D loss:-0.7084 G loss:-1.95\n",
      "Epoch:  0068 D loss:-0.7695 G loss:-1.953\n",
      "Epoch:  0068 D loss:-0.5538 G loss:-2.075\n",
      "Epoch:  0068 D loss:-0.7194 G loss:-2.112\n",
      "Epoch:  0068 D loss:-0.6228 G loss:-2.186\n",
      "Epoch:  0068 D loss:-0.6274 G loss:-2.293\n",
      "Epoch:  0068 D loss:-0.661 G loss:-2.219\n",
      "Epoch:  0068 D loss:-0.7049 G loss:-2.203\n",
      "Epoch:  0068 D loss:-0.7584 G loss:-2.347\n",
      "Epoch:  0068 D loss:-0.6235 G loss:-2.075\n",
      "Epoch:  0068 D loss:-0.6326 G loss:-2.042\n",
      "Epoch:  0068 D loss:-0.5891 G loss:-1.931\n",
      "Epoch:  0068 D loss:-0.7137 G loss:-1.954\n",
      "Epoch:  0068 D loss:-0.7591 G loss:-1.832\n",
      "Epoch:  0068 D loss:-0.6212 G loss:-2.238\n",
      "Epoch:  0068 D loss:-0.7276 G loss:-2.028\n",
      "Epoch:  0068 D loss:-0.6452 G loss:-2.018\n",
      "Epoch:  0068 D loss:-0.8403 G loss:-1.99\n",
      "Epoch:  0068 D loss:-0.7628 G loss:-2.222\n",
      "Epoch:  0068 D loss:-0.7166 G loss:-2.049\n",
      "Epoch:  0068 D loss:-0.7587 G loss:-1.953\n",
      "Epoch:  0068 D loss:-0.5777 G loss:-1.912\n",
      "Epoch:  0068 D loss:-0.6251 G loss:-2.074\n",
      "Epoch:  0068 D loss:-0.7729 G loss:-2.006\n",
      "Epoch:  0068 D loss:-0.6548 G loss:-1.829\n",
      "Epoch:  0068 D loss:-0.6858 G loss:-1.88\n",
      "Epoch:  0068 D loss:-0.7518 G loss:-1.884\n",
      "Epoch:  0068 D loss:-0.6984 G loss:-2.037\n",
      "Epoch:  0068 D loss:-0.7512 G loss:-2.062\n",
      "Epoch:  0068 D loss:-0.6907 G loss:-2.095\n",
      "Epoch:  0068 D loss:-0.5953 G loss:-2.293\n",
      "Epoch:  0068 D loss:-0.7448 G loss:-2.12\n",
      "Epoch:  0068 D loss:-0.6852 G loss:-2.293\n",
      "Epoch:  0068 D loss:-0.7352 G loss:-1.965\n",
      "Epoch:  0068 D loss:-0.7249 G loss:-1.968\n",
      "Epoch:  0068 D loss:-0.7235 G loss:-1.857\n",
      "Epoch:  0068 D loss:-0.8653 G loss:-1.797\n",
      "Epoch:  0068 D loss:-0.6957 G loss:-1.959\n",
      "Epoch:  0068 D loss:-0.7627 G loss:-1.764\n",
      "Epoch:  0068 D loss:-0.6512 G loss:-1.934\n",
      "Epoch:  0068 D loss:-0.7001 G loss:-1.843\n",
      "Epoch:  0068 D loss:-0.768 G loss:-1.824\n",
      "Epoch:  0068 D loss:-0.6243 G loss:-1.865\n",
      "Epoch:  0068 D loss:-0.8275 G loss:-1.955\n",
      "Epoch:  0068 D loss:-0.9421 G loss:-1.983\n",
      "Epoch:  0068 D loss:-0.5689 G loss:-2.33\n",
      "Epoch:  0068 D loss:-0.7883 G loss:-2.36\n",
      "Epoch:  0068 D loss:-0.6377 G loss:-2.179\n",
      "Epoch:  0068 D loss:-0.7283 G loss:-2.235\n",
      "Epoch:  0068 D loss:-0.6549 G loss:-2.301\n",
      "Epoch:  0068 D loss:-0.724 G loss:-2.202\n",
      "Epoch:  0068 D loss:-0.8401 G loss:-2.118\n",
      "Epoch:  0068 D loss:-0.7367 G loss:-1.954\n",
      "Epoch:  0068 D loss:-0.6676 G loss:-1.95\n",
      "Epoch:  0068 D loss:-0.7469 G loss:-1.868\n",
      "Epoch:  0068 D loss:-0.7081 G loss:-1.839\n",
      "Epoch:  0068 D loss:-0.754 G loss:-1.914\n",
      "Epoch:  0068 D loss:-0.6321 G loss:-1.87\n",
      "Epoch:  0068 D loss:-0.7342 G loss:-1.825\n",
      "Epoch:  0068 D loss:-0.7504 G loss:-2.174\n",
      "Epoch:  0068 D loss:-0.7425 G loss:-2.129\n",
      "Epoch:  0068 D loss:-0.6969 G loss:-1.968\n",
      "Epoch:  0068 D loss:-0.6568 G loss:-2.13\n",
      "Epoch:  0068 D loss:-0.7428 G loss:-2.262\n",
      "Epoch:  0068 D loss:-0.7172 G loss:-2.198\n",
      "Epoch:  0068 D loss:-0.7217 G loss:-2.499\n",
      "Epoch:  0068 D loss:-0.6532 G loss:-2.299\n",
      "Epoch:  0068 D loss:-0.6944 G loss:-2.498\n",
      "Epoch:  0068 D loss:-0.6021 G loss:-2.441\n",
      "Epoch:  0068 D loss:-0.8091 G loss:-2.271\n",
      "Epoch:  0068 D loss:-0.9122 G loss:-1.9\n",
      "Epoch:  0068 D loss:-0.691 G loss:-2.013\n",
      "Epoch:  0068 D loss:-0.7829 G loss:-1.803\n",
      "Epoch:  0068 D loss:-0.6719 G loss:-1.8\n",
      "Epoch:  0068 D loss:-0.7646 G loss:-1.77\n",
      "Epoch:  0068 D loss:-0.7469 G loss:-1.834\n",
      "Epoch:  0068 D loss:-0.7299 G loss:-1.807\n",
      "Epoch:  0068 D loss:-0.6632 G loss:-2.095\n",
      "Epoch:  0068 D loss:-0.7755 G loss:-2.083\n",
      "Epoch:  0068 D loss:-0.7898 G loss:-2.199\n",
      "Epoch:  0068 D loss:-0.8615 G loss:-2.254\n",
      "Epoch:  0068 D loss:-0.7399 G loss:-2.059\n",
      "Epoch:  0068 D loss:-0.8024 G loss:-2.008\n",
      "Epoch:  0068 D loss:-0.6232 G loss:-2.412\n",
      "Epoch:  0068 D loss:-0.6648 G loss:-2.273\n",
      "Epoch:  0068 D loss:-0.8103 G loss:-2.136\n",
      "Epoch:  0068 D loss:-0.8134 G loss:-2.075\n",
      "Epoch:  0068 D loss:-0.7528 G loss:-2.125\n",
      "Epoch:  0068 D loss:-0.7918 G loss:-1.902\n",
      "Epoch:  0068 D loss:-0.627 G loss:-2.147\n",
      "Epoch:  0068 D loss:-0.8333 G loss:-1.934\n",
      "Epoch:  0068 D loss:-0.6878 G loss:-1.881\n",
      "Epoch:  0068 D loss:-0.6415 G loss:-1.956\n",
      "Epoch:  0068 D loss:-0.5758 G loss:-1.959\n",
      "Epoch:  0068 D loss:-0.7283 G loss:-2.17\n",
      "Epoch:  0068 D loss:-0.7652 G loss:-2.023\n",
      "Epoch:  0068 D loss:-0.7596 G loss:-2.167\n",
      "Epoch:  0068 D loss:-0.5502 G loss:-2.096\n",
      "Epoch:  0068 D loss:-0.7632 G loss:-2.042\n",
      "Epoch:  0068 D loss:-0.8326 G loss:-2.066\n",
      "Epoch:  0068 D loss:-0.6483 G loss:-2.255\n",
      "Epoch:  0068 D loss:-0.725 G loss:-2.095\n",
      "Epoch:  0068 D loss:-0.7495 G loss:-2.171\n",
      "Epoch:  0068 D loss:-0.7138 G loss:-2.088\n",
      "Epoch:  0068 D loss:-0.8364 G loss:-2.002\n",
      "Epoch:  0068 D loss:-0.6207 G loss:-1.932\n",
      "Epoch:  0068 D loss:-0.6603 G loss:-1.862\n",
      "Epoch:  0068 D loss:-0.7337 G loss:-1.883\n",
      "Epoch:  0068 D loss:-0.7976 G loss:-1.856\n",
      "Epoch:  0068 D loss:-0.6857 G loss:-1.879\n",
      "Epoch:  0068 D loss:-0.7549 G loss:-1.92\n",
      "Epoch:  0068 D loss:-0.8272 G loss:-1.849\n",
      "Epoch:  0068 D loss:-0.7286 G loss:-2.085\n",
      "Epoch:  0068 D loss:-0.8076 G loss:-1.96\n",
      "Epoch:  0068 D loss:-0.772 G loss:-2.077\n",
      "Epoch:  0068 D loss:-0.6926 G loss:-2.015\n",
      "Epoch:  0068 D loss:-0.8437 G loss:-1.809\n",
      "Epoch:  0068 D loss:-0.7032 G loss:-2.233\n",
      "Epoch:  0068 D loss:-0.6809 G loss:-2.385\n",
      "Epoch:  0068 D loss:-0.7449 G loss:-2.197\n",
      "Epoch:  0068 D loss:-0.8028 G loss:-2.056\n",
      "Epoch:  0068 D loss:-0.7697 G loss:-1.986\n",
      "Epoch:  0068 D loss:-0.6057 G loss:-2.022\n",
      "Epoch:  0068 D loss:-0.7642 G loss:-1.868\n",
      "Epoch:  0068 D loss:-0.7276 G loss:-1.855\n",
      "Epoch:  0068 D loss:-0.7629 G loss:-1.786\n",
      "Epoch:  0068 D loss:-0.6665 G loss:-1.989\n",
      "Epoch:  0068 D loss:-0.6817 G loss:-1.899\n",
      "Epoch:  0068 D loss:-0.7411 G loss:-2.037\n",
      "Epoch:  0068 D loss:-0.7169 G loss:-1.934\n",
      "Epoch:  0068 D loss:-0.8878 G loss:-1.919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0068 D loss:-0.9121 G loss:-2.071\n",
      "Epoch:  0068 D loss:-0.8059 G loss:-2.085\n",
      "Epoch:  0068 D loss:-0.6208 G loss:-1.923\n",
      "Epoch:  0068 D loss:-0.8694 G loss:-1.928\n",
      "Epoch:  0068 D loss:-0.7589 G loss:-2.095\n",
      "Epoch:  0068 D loss:-0.8138 G loss:-1.886\n",
      "Epoch:  0068 D loss:-0.8253 G loss:-1.677\n",
      "Epoch:  0068 D loss:-0.6691 G loss:-2.027\n",
      "Epoch:  0068 D loss:-0.7096 G loss:-2.058\n",
      "Epoch:  0068 D loss:-0.9298 G loss:-1.905\n",
      "Epoch:  0068 D loss:-0.7301 G loss:-1.879\n",
      "Epoch:  0068 D loss:-0.6146 G loss:-2.189\n",
      "Epoch:  0068 D loss:-0.7387 G loss:-2.041\n",
      "Epoch:  0068 D loss:-0.7718 G loss:-1.715\n",
      "Epoch:  0068 D loss:-0.8103 G loss:-1.878\n",
      "Epoch:  0068 D loss:-0.6637 G loss:-2.166\n",
      "Epoch:  0068 D loss:-0.7366 G loss:-1.829\n",
      "Epoch:  0068 D loss:-0.7486 G loss:-1.856\n",
      "Epoch:  0068 D loss:-0.7178 G loss:-2.045\n",
      "Epoch:  0068 D loss:-0.7284 G loss:-2.136\n",
      "Epoch:  0068 D loss:-0.6481 G loss:-2.162\n",
      "Epoch:  0068 D loss:-0.5737 G loss:-2.152\n",
      "Epoch:  0068 D loss:-0.613 G loss:-2.028\n",
      "Epoch:  0068 D loss:-0.5387 G loss:-2.092\n",
      "Epoch:  0068 D loss:-0.6875 G loss:-2.186\n",
      "Epoch:  0068 D loss:-0.5923 G loss:-2.225\n",
      "Epoch:  0068 D loss:-0.5798 G loss:-2.373\n",
      "Epoch:  0068 D loss:-0.629 G loss:-2.076\n",
      "Epoch:  0068 D loss:-0.6472 G loss:-2.22\n",
      "Epoch:  0068 D loss:-0.5911 G loss:-2.098\n",
      "Epoch:  0068 D loss:-0.5865 G loss:-2.168\n",
      "Epoch:  0068 D loss:-0.6449 G loss:-2.363\n",
      "Epoch:  0068 D loss:-0.7239 G loss:-2.119\n",
      "Epoch:  0068 D loss:-0.7222 G loss:-2.066\n",
      "Epoch:  0068 D loss:-0.5782 G loss:-2.24\n",
      "Epoch:  0068 D loss:-0.5802 G loss:-2.15\n",
      "Epoch:  0068 D loss:-0.6467 G loss:-2.078\n",
      "Epoch:  0068 D loss:-0.8436 G loss:-1.826\n",
      "Epoch:  0068 D loss:-0.7721 G loss:-1.943\n",
      "Epoch:  0068 D loss:-0.7286 G loss:-1.901\n",
      "Epoch:  0068 D loss:-0.711 G loss:-1.966\n",
      "Epoch:  0068 D loss:-0.6491 G loss:-2.112\n",
      "Epoch:  0068 D loss:-0.7829 G loss:-2.121\n",
      "Epoch:  0068 D loss:-0.7471 G loss:-2.188\n",
      "Epoch:  0068 D loss:-0.5455 G loss:-2.057\n",
      "Epoch:  0068 D loss:-0.6668 G loss:-2.019\n",
      "Epoch:  0068 D loss:-0.6011 G loss:-1.982\n",
      "Epoch:  0068 D loss:-0.6016 G loss:-2.005\n",
      "Epoch:  0068 D loss:-0.785 G loss:-1.926\n",
      "Epoch:  0068 D loss:-0.6339 G loss:-2.233\n",
      "Epoch:  0068 D loss:-0.6979 G loss:-2.212\n",
      "Epoch:  0068 D loss:-0.599 G loss:-2.209\n",
      "Epoch:  0068 D loss:-0.5765 G loss:-1.976\n",
      "Epoch:  0068 D loss:-0.6629 G loss:-2.2\n",
      "Epoch:  0068 D loss:-0.6348 G loss:-1.983\n",
      "Epoch:  0068 D loss:-0.6565 G loss:-2.135\n",
      "Epoch:  0068 D loss:-0.6304 G loss:-2.174\n",
      "Epoch:  0068 D loss:-0.625 G loss:-2.098\n",
      "Epoch:  0068 D loss:-0.6512 G loss:-2.062\n",
      "Epoch:  0068 D loss:-0.5874 G loss:-2.189\n",
      "Epoch:  0068 D loss:-0.5339 G loss:-2.235\n",
      "Epoch:  0068 D loss:-0.722 G loss:-2.091\n",
      "Epoch:  0068 D loss:-0.5979 G loss:-2.123\n",
      "Epoch:  0068 D loss:-0.5903 G loss:-2.318\n",
      "Epoch:  0068 D loss:-0.5699 G loss:-2.093\n",
      "Epoch:  0068 D loss:-0.7236 G loss:-2.121\n",
      "Epoch:  0068 D loss:-0.7786 G loss:-1.984\n",
      "Epoch:  0068 D loss:-0.7274 G loss:-2.001\n",
      "Epoch:  0068 D loss:-0.633 G loss:-2.056\n",
      "Epoch:  0068 D loss:-0.5995 G loss:-2.092\n",
      "Epoch:  0068 D loss:-0.7224 G loss:-2.237\n",
      "Epoch:  0068 D loss:-0.5865 G loss:-2.227\n",
      "Epoch:  0068 D loss:-0.6624 G loss:-1.904\n",
      "Epoch:  0068 D loss:-0.7154 G loss:-1.923\n",
      "Epoch:  0068 D loss:-0.8081 G loss:-1.947\n",
      "Epoch:  0068 D loss:-0.7182 G loss:-1.969\n",
      "Epoch:  0068 D loss:-0.7071 G loss:-1.903\n",
      "Epoch:  0068 D loss:-0.7211 G loss:-2.116\n",
      "Epoch:  0068 D loss:-0.7383 G loss:-2.137\n",
      "Epoch:  0068 D loss:-0.7613 G loss:-2.065\n",
      "Epoch:  0068 D loss:-0.7053 G loss:-1.912\n",
      "Epoch:  0068 D loss:-0.5877 G loss:-2.186\n",
      "Epoch:  0068 D loss:-0.6234 G loss:-2.098\n",
      "Epoch:  0068 D loss:-0.7563 G loss:-1.89\n",
      "Epoch:  0068 D loss:-0.7082 G loss:-2.143\n",
      "Epoch:  0068 D loss:-0.7269 G loss:-1.995\n",
      "Epoch:  0068 D loss:-0.6954 G loss:-2.376\n",
      "Epoch:  0068 D loss:-0.7696 G loss:-2.054\n",
      "Epoch:  0068 D loss:-0.7712 G loss:-1.808\n",
      "Epoch:  0068 D loss:-0.7262 G loss:-2.01\n",
      "Epoch:  0068 D loss:-0.6972 G loss:-2.053\n",
      "Epoch:  0068 D loss:-0.7808 G loss:-1.775\n",
      "Epoch:  0068 D loss:-0.7502 G loss:-1.892\n",
      "Epoch:  0068 D loss:-0.7186 G loss:-1.768\n",
      "Epoch:  0068 D loss:-0.9098 G loss:-1.686\n",
      "Epoch:  0068 D loss:-0.7945 G loss:-1.784\n",
      "Epoch:  0068 D loss:-0.8221 G loss:-1.902\n",
      "Epoch:  0068 D loss:-0.7729 G loss:-1.765\n",
      "Epoch:  0068 D loss:-0.8308 G loss:-1.806\n",
      "Epoch:  0068 D loss:-0.8913 G loss:-1.947\n",
      "Epoch:  0068 D loss:-0.678 G loss:-2.299\n",
      "Epoch:  0068 D loss:-0.6888 G loss:-2.091\n",
      "Epoch:  0068 D loss:-0.7115 G loss:-1.99\n",
      "Epoch:  0068 D loss:-0.699 G loss:-2.187\n",
      "Epoch:  0068 D loss:-0.767 G loss:-2.017\n",
      "Epoch:  0068 D loss:-0.6843 G loss:-2.033\n",
      "Epoch:  0068 D loss:-0.7404 G loss:-2.211\n",
      "Epoch:  0068 D loss:-0.7782 G loss:-2.03\n",
      "Epoch:  0068 D loss:-0.5715 G loss:-2.023\n",
      "Epoch:  0068 D loss:-0.7551 G loss:-1.757\n",
      "Epoch:  0068 D loss:-0.6532 G loss:-2.192\n",
      "Epoch:  0068 D loss:-0.8687 G loss:-1.796\n",
      "Epoch:  0068 D loss:-0.7141 G loss:-1.796\n",
      "Epoch:  0068 D loss:-0.6931 G loss:-2.067\n",
      "Epoch:  0068 D loss:-0.8143 G loss:-1.799\n",
      "Epoch:  0068 D loss:-0.6407 G loss:-1.955\n",
      "Epoch:  0068 D loss:-0.7356 G loss:-1.947\n",
      "Epoch:  0068 D loss:-0.7046 G loss:-1.936\n",
      "Epoch:  0068 D loss:-0.8001 G loss:-2.198\n",
      "Epoch:  0068 D loss:-0.6997 G loss:-2.128\n",
      "Epoch:  0068 D loss:-0.6832 G loss:-2.222\n",
      "Epoch:  0068 D loss:-0.7536 G loss:-2.123\n",
      "Epoch:  0068 D loss:-0.6368 G loss:-2.106\n",
      "Epoch:  0068 D loss:-0.8381 G loss:-1.954\n",
      "Epoch:  0068 D loss:-0.7763 G loss:-1.893\n",
      "Epoch:  0068 D loss:-0.674 G loss:-1.853\n",
      "Epoch:  0068 D loss:-0.7387 G loss:-1.969\n",
      "Epoch:  0068 D loss:-0.714 G loss:-2.022\n",
      "Epoch:  0068 D loss:-0.8454 G loss:-1.877\n",
      "Epoch:  0068 D loss:-0.7515 G loss:-1.871\n",
      "Epoch:  0068 D loss:-0.806 G loss:-1.925\n",
      "Epoch:  0068 D loss:-0.8037 G loss:-2.013\n",
      "Epoch:  0068 D loss:-0.6432 G loss:-1.971\n",
      "Epoch:  0068 D loss:-0.78 G loss:-2.045\n",
      "Epoch:  0068 D loss:-0.6777 G loss:-2.109\n",
      "Epoch:  0068 D loss:-0.77 G loss:-1.989\n",
      "Epoch:  0068 D loss:-0.7461 G loss:-1.967\n",
      "Epoch:  0068 D loss:-0.7538 G loss:-1.955\n",
      "Epoch:  0068 D loss:-0.6238 G loss:-2.103\n",
      "Epoch:  0068 D loss:-0.634 G loss:-2.15\n",
      "Epoch:  0068 D loss:-0.6977 G loss:-1.937\n",
      "Epoch:  0068 D loss:-0.5591 G loss:-2.129\n",
      "Epoch:  0068 D loss:-0.7086 G loss:-2.202\n",
      "Epoch:  0068 D loss:-0.672 G loss:-1.979\n",
      "Epoch:  0068 D loss:-0.6856 G loss:-2.123\n",
      "Epoch:  0068 D loss:-0.6771 G loss:-1.96\n",
      "Epoch:  0068 D loss:-0.6553 G loss:-1.85\n",
      "Epoch:  0068 D loss:-0.6535 G loss:-1.901\n",
      "Epoch:  0068 D loss:-0.748 G loss:-1.944\n",
      "Epoch:  0068 D loss:-0.8357 G loss:-1.847\n",
      "Epoch:  0068 D loss:-0.6332 G loss:-1.895\n",
      "Epoch:  0068 D loss:-0.6408 G loss:-1.938\n",
      "Epoch:  0068 D loss:-0.7153 G loss:-1.893\n",
      "Epoch:  0068 D loss:-0.8123 G loss:-2.145\n",
      "Epoch:  0068 D loss:-0.6549 G loss:-2.182\n",
      "Epoch:  0068 D loss:-0.6575 G loss:-2.209\n",
      "Epoch:  0068 D loss:-0.5851 G loss:-2.255\n",
      "Epoch:  0068 D loss:-0.7777 G loss:-1.957\n",
      "Epoch:  0068 D loss:-0.7306 G loss:-1.995\n",
      "Epoch:  0068 D loss:-0.5427 G loss:-2.255\n",
      "Epoch:  0068 D loss:-0.7264 G loss:-2.32\n",
      "Epoch:  0068 D loss:-0.7137 G loss:-1.991\n",
      "Epoch:  0068 D loss:-0.7892 G loss:-2.01\n",
      "Epoch:  0068 D loss:-0.7488 G loss:-1.969\n",
      "Epoch:  0068 D loss:-0.6376 G loss:-2.103\n",
      "Epoch:  0068 D loss:-0.5774 G loss:-2.001\n",
      "Epoch:  0068 D loss:-0.652 G loss:-2.007\n",
      "Epoch:  0068 D loss:-0.7949 G loss:-1.83\n",
      "Epoch:  0068 D loss:-0.7593 G loss:-2.039\n",
      "Epoch:  0068 D loss:-0.7355 G loss:-2.086\n",
      "Epoch:  0068 D loss:-0.7433 G loss:-2.078\n",
      "Epoch:  0068 D loss:-0.686 G loss:-2.069\n",
      "Epoch:  0068 D loss:-0.6632 G loss:-2.085\n",
      "Epoch:  0068 D loss:-0.6965 G loss:-1.9\n",
      "Epoch:  0068 D loss:-0.6744 G loss:-2.127\n",
      "Epoch:  0068 D loss:-0.6467 G loss:-2.112\n",
      "Epoch:  0068 D loss:-0.8591 G loss:-1.947\n",
      "Epoch:  0068 D loss:-0.7013 G loss:-2.035\n",
      "Epoch:  0068 D loss:-0.6356 G loss:-1.988\n",
      "Epoch:  0068 D loss:-0.7779 G loss:-2.017\n",
      "Epoch:  0068 D loss:-0.6774 G loss:-2.057\n",
      "Epoch:  0068 D loss:-0.6441 G loss:-2.005\n",
      "Epoch:  0068 D loss:-0.8409 G loss:-2.081\n",
      "Epoch:  0068 D loss:-0.6371 G loss:-1.923\n",
      "Epoch:  0068 D loss:-0.8184 G loss:-1.896\n",
      "Epoch:  0068 D loss:-0.8264 G loss:-2.077\n",
      "Epoch:  0068 D loss:-0.7169 G loss:-1.836\n",
      "Epoch:  0068 D loss:-0.7793 G loss:-1.933\n",
      "Epoch:  0068 D loss:-0.6659 G loss:-1.958\n",
      "Epoch:  0068 D loss:-0.7596 G loss:-1.86\n",
      "Epoch:  0068 D loss:-0.6988 G loss:-1.925\n",
      "Epoch:  0068 D loss:-0.6177 G loss:-2.12\n",
      "Epoch:  0068 D loss:-0.7546 G loss:-2.134\n",
      "Epoch:  0068 D loss:-0.5672 G loss:-2.163\n",
      "Epoch:  0068 D loss:-0.712 G loss:-2.13\n",
      "Epoch:  0068 D loss:-0.7407 G loss:-2.098\n",
      "Epoch:  0068 D loss:-0.6551 G loss:-2.145\n",
      "Epoch:  0068 D loss:-0.8073 G loss:-2.276\n",
      "Epoch:  0068 D loss:-0.6981 G loss:-2.135\n",
      "Epoch:  0068 D loss:-0.6272 G loss:-2.034\n",
      "Epoch:  0068 D loss:-0.722 G loss:-1.988\n",
      "Epoch:  0068 D loss:-0.6601 G loss:-1.852\n",
      "Epoch:  0068 D loss:-0.5903 G loss:-1.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0068 D loss:-0.6896 G loss:-2.103\n",
      "Epoch:  0068 D loss:-0.6726 G loss:-2.065\n",
      "Epoch:  0068 D loss:-0.6863 G loss:-1.979\n",
      "Epoch:  0068 D loss:-0.5577 G loss:-2.07\n",
      "Epoch:  0068 D loss:-0.7032 G loss:-2.123\n",
      "Epoch:  0068 D loss:-0.7033 G loss:-1.949\n",
      "Epoch:  0068 D loss:-0.6297 G loss:-1.936\n",
      "Epoch:  0068 D loss:-0.7124 G loss:-1.947\n",
      "Epoch:  0068 D loss:-0.6046 G loss:-2.027\n",
      "Epoch:  0068 D loss:-0.7437 G loss:-2.145\n",
      "Epoch:  0068 D loss:-0.6345 G loss:-1.995\n",
      "Epoch:  0068 D loss:-0.7385 G loss:-2.155\n",
      "Epoch:  0068 D loss:-0.587 G loss:-2.291\n",
      "Epoch:  0068 D loss:-0.698 G loss:-2.083\n",
      "Epoch:  0068 D loss:-0.6758 G loss:-2.078\n",
      "Epoch:  0068 D loss:-0.867 G loss:-2.13\n",
      "Epoch:  0068 D loss:-0.7783 G loss:-2.102\n",
      "Epoch:  0068 D loss:-0.6875 G loss:-2.138\n",
      "Epoch:  0068 D loss:-0.7596 G loss:-1.737\n",
      "Epoch:  0068 D loss:-0.7907 G loss:-1.961\n",
      "Epoch:  0068 D loss:-0.6436 G loss:-2.001\n",
      "Epoch:  0068 D loss:-0.7825 G loss:-2.048\n",
      "Epoch:  0068 D loss:-0.8795 G loss:-1.888\n",
      "Epoch:  0068 D loss:-0.6846 G loss:-1.964\n",
      "Epoch:  0068 D loss:-0.6185 G loss:-1.813\n",
      "Epoch:  0068 D loss:-0.6933 G loss:-1.83\n",
      "Epoch:  0068 D loss:-0.7928 G loss:-1.792\n",
      "Epoch:  0068 D loss:-0.7468 G loss:-1.911\n",
      "Epoch:  0068 D loss:-0.7684 G loss:-2.037\n",
      "Epoch:  0068 D loss:-0.805 G loss:-2.188\n",
      "Epoch:  0068 D loss:-0.7431 G loss:-2.059\n",
      "Epoch:  0068 D loss:-0.7547 G loss:-2.058\n",
      "Epoch:  0068 D loss:-0.732 G loss:-2.049\n",
      "Epoch:  0068 D loss:-0.7022 G loss:-1.848\n",
      "Epoch:  0068 D loss:-0.6565 G loss:-1.997\n",
      "Epoch:  0068 D loss:-0.7824 G loss:-1.962\n",
      "Epoch:  0068 D loss:-0.5775 G loss:-2.209\n",
      "Epoch:  0068 D loss:-0.629 G loss:-2.049\n",
      "Epoch:  0068 D loss:-0.686 G loss:-2.091\n",
      "Epoch:  0068 D loss:-0.768 G loss:-2.11\n",
      "Epoch:  0068 D loss:-0.7039 G loss:-1.941\n",
      "Epoch:  0068 D loss:-0.6479 G loss:-2.194\n",
      "Epoch:  0068 D loss:-0.7218 G loss:-2.077\n",
      "Epoch:  0068 D loss:-0.5928 G loss:-2.186\n",
      "Epoch:  0068 D loss:-0.7889 G loss:-2.019\n",
      "Epoch:  0068 D loss:-0.7283 G loss:-2.013\n",
      "Epoch:  0068 D loss:-0.5744 G loss:-2.039\n",
      "Epoch:  0068 D loss:-0.7181 G loss:-1.985\n",
      "Epoch:  0068 D loss:-0.6116 G loss:-2.109\n",
      "Epoch:  0068 D loss:-0.6828 G loss:-1.893\n",
      "Epoch:  0068 D loss:-0.6818 G loss:-1.967\n",
      "Epoch:  0068 D loss:-0.6158 G loss:-2.038\n",
      "Epoch:  0068 D loss:-0.6378 G loss:-2.002\n",
      "Epoch:  0068 D loss:-0.6335 G loss:-2.136\n",
      "Epoch:  0068 D loss:-0.6946 G loss:-2.021\n",
      "Epoch:  0068 D loss:-0.6173 G loss:-1.991\n",
      "Epoch:  0068 D loss:-0.737 G loss:-2.093\n",
      "Epoch:  0068 D loss:-0.6182 G loss:-2.209\n",
      "Epoch:  0068 D loss:-0.6173 G loss:-2.232\n",
      "Epoch:  0068 D loss:-0.6291 G loss:-1.974\n",
      "Epoch:  0068 D loss:-0.6239 G loss:-2.038\n",
      "Epoch:  0068 D loss:-0.6465 G loss:-2.159\n",
      "Epoch:  0068 D loss:-0.6004 G loss:-2.098\n",
      "Epoch:  0068 D loss:-0.5771 G loss:-2.104\n",
      "Epoch:  0068 D loss:-0.7731 G loss:-2.088\n",
      "Epoch:  0068 D loss:-0.7122 G loss:-2.044\n",
      "Epoch:  0068 D loss:-0.5323 G loss:-2.346\n",
      "Epoch:  0068 D loss:-0.7031 G loss:-2.064\n",
      "Epoch:  0068 D loss:-0.6066 G loss:-2.029\n",
      "Epoch:  0068 D loss:-0.644 G loss:-1.989\n",
      "Epoch:  0068 D loss:-0.6726 G loss:-2.118\n",
      "Epoch:  0068 D loss:-0.6864 G loss:-1.852\n",
      "Epoch:  0068 D loss:-0.6413 G loss:-2.051\n",
      "Epoch:  0068 D loss:-0.713 G loss:-2.022\n",
      "Epoch:  0068 D loss:-0.6884 G loss:-1.836\n",
      "Epoch:  0068 D loss:-0.5644 G loss:-1.994\n",
      "Epoch:  0068 D loss:-0.5519 G loss:-2.08\n",
      "Epoch:  0068 D loss:-0.545 G loss:-2.239\n",
      "Epoch:  0068 D loss:-0.5387 G loss:-2.293\n",
      "Epoch:  0068 D loss:-0.6617 G loss:-2.237\n",
      "Epoch:  0068 D loss:-0.6436 G loss:-2.156\n",
      "Epoch:  0068 D loss:-0.6538 G loss:-2.134\n",
      "Epoch:  0068 D loss:-0.5886 G loss:-2.42\n",
      "Epoch:  0068 D loss:-0.5617 G loss:-2.037\n",
      "Epoch:  0068 D loss:-0.6647 G loss:-1.939\n",
      "Epoch:  0068 D loss:-0.6666 G loss:-1.955\n",
      "Epoch:  0068 D loss:-0.6663 G loss:-1.974\n",
      "Epoch:  0068 D loss:-0.6696 G loss:-2.301\n",
      "Epoch:  0068 D loss:-0.6591 G loss:-2.157\n",
      "Epoch:  0068 D loss:-0.6346 G loss:-2.119\n",
      "Epoch:  0068 D loss:-0.6212 G loss:-2.222\n",
      "Epoch:  0068 D loss:-0.6868 G loss:-2.058\n",
      "Epoch:  0068 D loss:-0.5797 G loss:-2.072\n",
      "Epoch:  0068 D loss:-0.505 G loss:-2.171\n",
      "Epoch:  0068 D loss:-0.5994 G loss:-2.201\n",
      "Epoch:  0068 D loss:-0.7672 G loss:-2.117\n",
      "Epoch:  0068 D loss:-0.6413 G loss:-1.923\n",
      "Epoch:  0068 D loss:-0.6053 G loss:-2.214\n",
      "Epoch:  0068 D loss:-0.7341 G loss:-2.045\n",
      "Epoch:  0068 D loss:-0.5779 G loss:-2.177\n",
      "Epoch:  0068 D loss:-0.5714 G loss:-2.245\n",
      "Epoch:  0068 D loss:-0.4854 G loss:-2.079\n",
      "Epoch:  0068 D loss:-0.6103 G loss:-2.24\n",
      "Epoch:  0068 D loss:-0.5893 G loss:-2.033\n",
      "Epoch:  0068 D loss:-0.7567 G loss:-1.902\n",
      "Epoch:  0068 D loss:-0.6036 G loss:-2.191\n",
      "Epoch:  0068 D loss:-0.7545 G loss:-1.958\n",
      "Epoch:  0068 D loss:-0.6692 G loss:-2.049\n",
      "Epoch:  0068 D loss:-0.6671 G loss:-2.032\n",
      "Epoch:  0068 D loss:-0.5222 G loss:-2.313\n",
      "Epoch:  0068 D loss:-0.6309 G loss:-2.079\n",
      "Epoch:  0068 D loss:-0.7295 G loss:-1.909\n",
      "Epoch:  0068 D loss:-0.8766 G loss:-1.769\n",
      "Epoch:  0068 D loss:-0.6362 G loss:-2.128\n",
      "Epoch:  0068 D loss:-0.6602 G loss:-2.043\n",
      "Epoch:  0068 D loss:-0.7761 G loss:-2.062\n",
      "Epoch:  0068 D loss:-0.545 G loss:-2.153\n",
      "Epoch:  0068 D loss:-0.5631 G loss:-2.474\n",
      "Epoch:  0068 D loss:-0.7392 G loss:-2.073\n",
      "Epoch:  0068 D loss:-0.7659 G loss:-2.186\n",
      "Epoch:  0068 D loss:-0.6695 G loss:-2.037\n",
      "Epoch:  0068 D loss:-0.7957 G loss:-1.918\n",
      "Epoch:  0068 D loss:-0.6422 G loss:-2.063\n",
      "Epoch:  0068 D loss:-0.8263 G loss:-1.922\n",
      "Epoch:  0068 D loss:-0.6949 G loss:-1.962\n",
      "Epoch:  0068 D loss:-0.7395 G loss:-1.815\n",
      "Epoch:  0068 D loss:-0.6957 G loss:-1.821\n",
      "Epoch:  0068 D loss:-0.6715 G loss:-2.021\n",
      "Epoch:  0068 D loss:-0.7805 G loss:-1.723\n",
      "Epoch:  0068 D loss:-0.8569 G loss:-1.927\n",
      "Epoch:  0068 D loss:-0.6606 G loss:-2.034\n",
      "Epoch:  0068 D loss:-0.7571 G loss:-1.868\n",
      "Epoch:  0068 D loss:-0.6251 G loss:-1.869\n",
      "Epoch:  0068 D loss:-0.6732 G loss:-2.086\n",
      "Epoch:  0068 D loss:-0.665 G loss:-2.155\n",
      "Epoch:  0068 D loss:-0.8591 G loss:-1.96\n",
      "Epoch:  0068 D loss:-0.6214 G loss:-2.065\n",
      "Epoch:  0068 D loss:-0.6376 G loss:-2.22\n",
      "Epoch:  0068 D loss:-0.7082 G loss:-2.129\n",
      "Epoch:  0068 D loss:-0.6987 G loss:-2.229\n",
      "Epoch:  0068 D loss:-0.6428 G loss:-2.067\n",
      "Epoch:  0068 D loss:-0.6235 G loss:-1.933\n",
      "Epoch:  0068 D loss:-0.822 G loss:-1.748\n",
      "Epoch:  0068 D loss:-0.6598 G loss:-2.106\n",
      "Epoch:  0068 D loss:-0.7156 G loss:-1.808\n",
      "Epoch:  0068 D loss:-0.6072 G loss:-1.887\n",
      "Epoch:  0068 D loss:-0.8464 G loss:-1.981\n",
      "Epoch:  0068 D loss:-0.704 G loss:-1.978\n",
      "Epoch:  0068 D loss:-0.7306 G loss:-2.091\n",
      "Epoch:  0068 D loss:-0.6364 G loss:-2.075\n",
      "Epoch:  0068 D loss:-0.6842 G loss:-1.886\n",
      "Epoch:  0068 D loss:-0.6958 G loss:-2.101\n",
      "Epoch:  0068 D loss:-0.8067 G loss:-1.769\n",
      "Epoch:  0068 D loss:-0.7478 G loss:-2.023\n",
      "Epoch:  0068 D loss:-0.7932 G loss:-1.847\n",
      "Epoch:  0068 D loss:-0.7248 G loss:-1.868\n",
      "Epoch:  0068 D loss:-0.6725 G loss:-2.015\n",
      "Epoch:  0068 D loss:-0.6125 G loss:-1.966\n",
      "Epoch:  0068 D loss:-0.7213 G loss:-1.99\n",
      "Epoch:  0068 D loss:-0.6833 G loss:-2.104\n",
      "Epoch:  0068 D loss:-0.6239 G loss:-2.092\n",
      "Epoch:  0068 D loss:-0.7959 G loss:-2.036\n",
      "Epoch:  0068 D loss:-0.7063 G loss:-2.112\n",
      "Epoch:  0068 D loss:-0.6594 G loss:-2.107\n",
      "Epoch:  0068 D loss:-0.7445 G loss:-2.396\n",
      "Epoch:  0068 D loss:-0.6091 G loss:-2.063\n",
      "Epoch:  0068 D loss:-0.7508 G loss:-1.995\n",
      "Epoch:  0068 D loss:-0.7152 G loss:-1.9\n",
      "Epoch:  0068 D loss:-0.7296 G loss:-1.957\n",
      "Epoch:  0068 D loss:-0.861 G loss:-1.793\n",
      "Epoch:  0068 D loss:-0.7879 G loss:-1.938\n",
      "Epoch:  0068 D loss:-0.7111 G loss:-1.827\n",
      "Epoch:  0068 D loss:-0.6251 G loss:-1.931\n",
      "Epoch:  0068 D loss:-0.5949 G loss:-2.126\n",
      "Epoch:  0068 D loss:-0.6194 G loss:-1.97\n",
      "Epoch:  0068 D loss:-0.6088 G loss:-2.061\n",
      "Epoch:  0068 D loss:-0.5558 G loss:-2.0\n",
      "Epoch:  0068 D loss:-0.6982 G loss:-2.205\n",
      "Epoch:  0068 D loss:-0.7919 G loss:-1.919\n",
      "Epoch:  0068 D loss:-0.7852 G loss:-2.04\n",
      "Epoch:  0068 D loss:-0.7098 G loss:-2.231\n",
      "Epoch:  0068 D loss:-0.8046 G loss:-2.074\n",
      "Epoch:  0068 D loss:-0.8017 G loss:-2.154\n",
      "Epoch:  0068 D loss:-0.7885 G loss:-2.02\n",
      "Epoch:  0068 D loss:-0.7118 G loss:-1.944\n",
      "Epoch:  0068 D loss:-0.7351 G loss:-2.048\n",
      "Epoch:  0068 D loss:-0.7185 G loss:-1.809\n",
      "Epoch:  0068 D loss:-0.768 G loss:-1.668\n",
      "Epoch:  0068 D loss:-0.6346 G loss:-1.758\n",
      "Epoch:  0068 D loss:-0.5547 G loss:-2.041\n",
      "Epoch:  0068 D loss:-0.6888 G loss:-2.033\n",
      "Epoch:  0068 D loss:-0.7481 G loss:-1.89\n",
      "Epoch:  0068 D loss:-0.5895 G loss:-2.193\n",
      "Epoch:  0068 D loss:-0.7202 G loss:-2.091\n",
      "Epoch:  0068 D loss:-0.5635 G loss:-2.053\n",
      "Epoch:  0068 D loss:-0.7733 G loss:-1.998\n",
      "Epoch:  0068 D loss:-0.6505 G loss:-2.288\n",
      "Epoch:  0068 D loss:-0.7856 G loss:-2.241\n",
      "Epoch:  0068 D loss:-0.722 G loss:-2.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0069 D loss:-0.6819 G loss:-2.12\n",
      "Epoch:  0069 D loss:-0.659 G loss:-1.952\n",
      "Epoch:  0069 D loss:-0.7016 G loss:-1.907\n",
      "Epoch:  0069 D loss:-0.614 G loss:-2.219\n",
      "Epoch:  0069 D loss:-0.786 G loss:-1.999\n",
      "Epoch:  0069 D loss:-0.7138 G loss:-2.028\n",
      "Epoch:  0069 D loss:-0.7919 G loss:-1.795\n",
      "Epoch:  0069 D loss:-0.6881 G loss:-2.045\n",
      "Epoch:  0069 D loss:-0.6832 G loss:-2.02\n",
      "Epoch:  0069 D loss:-0.7932 G loss:-1.895\n",
      "Epoch:  0069 D loss:-0.7537 G loss:-2.108\n",
      "Epoch:  0069 D loss:-0.7339 G loss:-2.094\n",
      "Epoch:  0069 D loss:-0.6639 G loss:-1.923\n",
      "Epoch:  0069 D loss:-0.6882 G loss:-2.091\n",
      "Epoch:  0069 D loss:-0.6592 G loss:-2.118\n",
      "Epoch:  0069 D loss:-0.7369 G loss:-1.948\n",
      "Epoch:  0069 D loss:-0.777 G loss:-2.062\n",
      "Epoch:  0069 D loss:-0.5986 G loss:-1.932\n",
      "Epoch:  0069 D loss:-0.6489 G loss:-2.068\n",
      "Epoch:  0069 D loss:-0.8045 G loss:-1.758\n",
      "Epoch:  0069 D loss:-0.6605 G loss:-2.264\n",
      "Epoch:  0069 D loss:-0.5289 G loss:-2.059\n",
      "Epoch:  0069 D loss:-0.7341 G loss:-2.102\n",
      "Epoch:  0069 D loss:-0.6582 G loss:-2.115\n",
      "Epoch:  0069 D loss:-0.6532 G loss:-2.327\n",
      "Epoch:  0069 D loss:-0.7568 G loss:-2.129\n",
      "Epoch:  0069 D loss:-0.6489 G loss:-2.15\n",
      "Epoch:  0069 D loss:-0.6431 G loss:-2.152\n",
      "Epoch:  0069 D loss:-0.6352 G loss:-2.11\n",
      "Epoch:  0069 D loss:-0.7836 G loss:-1.998\n",
      "Epoch:  0069 D loss:-0.6622 G loss:-2.048\n",
      "Epoch:  0069 D loss:-0.6874 G loss:-1.951\n",
      "Epoch:  0069 D loss:-0.8488 G loss:-1.969\n",
      "Epoch:  0069 D loss:-0.747 G loss:-2.039\n",
      "Epoch:  0069 D loss:-0.7889 G loss:-1.768\n",
      "Epoch:  0069 D loss:-0.67 G loss:-1.859\n",
      "Epoch:  0069 D loss:-0.7195 G loss:-2.078\n",
      "Epoch:  0069 D loss:-0.6156 G loss:-2.167\n",
      "Epoch:  0069 D loss:-0.6985 G loss:-1.937\n",
      "Epoch:  0069 D loss:-0.6768 G loss:-2.032\n",
      "Epoch:  0069 D loss:-0.7445 G loss:-2.089\n",
      "Epoch:  0069 D loss:-0.6448 G loss:-2.042\n",
      "Epoch:  0069 D loss:-0.5748 G loss:-2.191\n",
      "Epoch:  0069 D loss:-0.8284 G loss:-1.855\n",
      "Epoch:  0069 D loss:-0.6142 G loss:-2.018\n",
      "Epoch:  0069 D loss:-0.6724 G loss:-2.239\n",
      "Epoch:  0069 D loss:-0.6224 G loss:-2.37\n",
      "Epoch:  0069 D loss:-0.6852 G loss:-2.074\n",
      "Epoch:  0069 D loss:-0.6637 G loss:-1.927\n",
      "Epoch:  0069 D loss:-0.6276 G loss:-2.007\n",
      "Epoch:  0069 D loss:-0.6361 G loss:-1.965\n",
      "Epoch:  0069 D loss:-0.6561 G loss:-2.082\n",
      "Epoch:  0069 D loss:-0.6297 G loss:-2.101\n",
      "Epoch:  0069 D loss:-0.6781 G loss:-1.963\n",
      "Epoch:  0069 D loss:-0.8115 G loss:-1.971\n",
      "Epoch:  0069 D loss:-0.6635 G loss:-1.997\n",
      "Epoch:  0069 D loss:-0.5747 G loss:-2.145\n",
      "Epoch:  0069 D loss:-0.7252 G loss:-2.112\n",
      "Epoch:  0069 D loss:-0.5832 G loss:-2.132\n",
      "Epoch:  0069 D loss:-0.7986 G loss:-1.934\n",
      "Epoch:  0069 D loss:-0.7338 G loss:-1.769\n",
      "Epoch:  0069 D loss:-0.7106 G loss:-2.068\n",
      "Epoch:  0069 D loss:-0.6975 G loss:-1.937\n",
      "Epoch:  0069 D loss:-0.6494 G loss:-2.055\n",
      "Epoch:  0069 D loss:-0.7748 G loss:-2.11\n",
      "Epoch:  0069 D loss:-0.6498 G loss:-1.933\n",
      "Epoch:  0069 D loss:-0.7221 G loss:-1.939\n",
      "Epoch:  0069 D loss:-0.7035 G loss:-2.003\n",
      "Epoch:  0069 D loss:-0.7407 G loss:-1.99\n",
      "Epoch:  0069 D loss:-0.6195 G loss:-2.189\n",
      "Epoch:  0069 D loss:-0.7064 G loss:-2.179\n",
      "Epoch:  0069 D loss:-0.6568 G loss:-2.261\n",
      "Epoch:  0069 D loss:-0.6025 G loss:-2.185\n",
      "Epoch:  0069 D loss:-0.633 G loss:-2.099\n",
      "Epoch:  0069 D loss:-0.6999 G loss:-1.951\n",
      "Epoch:  0069 D loss:-0.7586 G loss:-1.894\n",
      "Epoch:  0069 D loss:-0.7063 G loss:-1.8\n",
      "Epoch:  0069 D loss:-0.6147 G loss:-2.052\n",
      "Epoch:  0069 D loss:-0.6657 G loss:-2.13\n",
      "Epoch:  0069 D loss:-0.7276 G loss:-1.801\n",
      "Epoch:  0069 D loss:-0.6794 G loss:-1.793\n",
      "Epoch:  0069 D loss:-0.7192 G loss:-2.013\n",
      "Epoch:  0069 D loss:-0.5343 G loss:-2.194\n",
      "Epoch:  0069 D loss:-0.7626 G loss:-2.026\n",
      "Epoch:  0069 D loss:-0.703 G loss:-1.828\n",
      "Epoch:  0069 D loss:-0.6212 G loss:-2.029\n",
      "Epoch:  0069 D loss:-0.7128 G loss:-1.997\n",
      "Epoch:  0069 D loss:-0.7282 G loss:-2.006\n",
      "Epoch:  0069 D loss:-0.5772 G loss:-2.082\n",
      "Epoch:  0069 D loss:-0.8251 G loss:-1.916\n",
      "Epoch:  0069 D loss:-0.7567 G loss:-2.137\n",
      "Epoch:  0069 D loss:-0.7158 G loss:-1.945\n",
      "Epoch:  0069 D loss:-0.7975 G loss:-2.017\n",
      "Epoch:  0069 D loss:-0.6595 G loss:-2.095\n",
      "Epoch:  0069 D loss:-0.7758 G loss:-1.971\n",
      "Epoch:  0069 D loss:-0.6199 G loss:-2.068\n",
      "Epoch:  0069 D loss:-0.5853 G loss:-1.933\n",
      "Epoch:  0069 D loss:-0.6979 G loss:-2.042\n",
      "Epoch:  0069 D loss:-0.6867 G loss:-2.125\n",
      "Epoch:  0069 D loss:-0.6702 G loss:-1.977\n",
      "Epoch:  0069 D loss:-0.6199 G loss:-1.876\n",
      "Epoch:  0069 D loss:-0.6566 G loss:-1.852\n",
      "Epoch:  0069 D loss:-0.7216 G loss:-1.957\n",
      "Epoch:  0069 D loss:-0.7552 G loss:-1.911\n",
      "Epoch:  0069 D loss:-0.7258 G loss:-1.98\n",
      "Epoch:  0069 D loss:-0.767 G loss:-1.872\n",
      "Epoch:  0069 D loss:-0.7273 G loss:-1.904\n",
      "Epoch:  0069 D loss:-0.9217 G loss:-1.802\n",
      "Epoch:  0069 D loss:-0.6563 G loss:-2.192\n",
      "Epoch:  0069 D loss:-0.7331 G loss:-2.033\n",
      "Epoch:  0069 D loss:-0.688 G loss:-2.115\n",
      "Epoch:  0069 D loss:-0.7401 G loss:-2.19\n",
      "Epoch:  0069 D loss:-0.5862 G loss:-2.06\n",
      "Epoch:  0069 D loss:-0.703 G loss:-2.155\n",
      "Epoch:  0069 D loss:-0.7301 G loss:-2.042\n",
      "Epoch:  0069 D loss:-0.5084 G loss:-2.195\n",
      "Epoch:  0069 D loss:-0.7958 G loss:-1.944\n",
      "Epoch:  0069 D loss:-0.7848 G loss:-2.111\n",
      "Epoch:  0069 D loss:-0.7175 G loss:-2.08\n",
      "Epoch:  0069 D loss:-0.7585 G loss:-1.826\n",
      "Epoch:  0069 D loss:-0.6098 G loss:-2.153\n",
      "Epoch:  0069 D loss:-0.5887 G loss:-1.951\n",
      "Epoch:  0069 D loss:-0.7082 G loss:-2.105\n",
      "Epoch:  0069 D loss:-0.8297 G loss:-1.878\n",
      "Epoch:  0069 D loss:-0.5974 G loss:-2.281\n",
      "Epoch:  0069 D loss:-0.6953 G loss:-2.03\n",
      "Epoch:  0069 D loss:-0.8508 G loss:-1.871\n",
      "Epoch:  0069 D loss:-0.7167 G loss:-1.999\n",
      "Epoch:  0069 D loss:-0.7398 G loss:-1.852\n",
      "Epoch:  0069 D loss:-0.5788 G loss:-2.156\n",
      "Epoch:  0069 D loss:-0.7291 G loss:-1.905\n",
      "Epoch:  0069 D loss:-0.7764 G loss:-2.126\n",
      "Epoch:  0069 D loss:-0.6813 G loss:-2.087\n",
      "Epoch:  0069 D loss:-0.6599 G loss:-2.031\n",
      "Epoch:  0069 D loss:-0.748 G loss:-1.884\n",
      "Epoch:  0069 D loss:-0.5836 G loss:-2.354\n",
      "Epoch:  0069 D loss:-0.8602 G loss:-2.26\n",
      "Epoch:  0069 D loss:-0.6612 G loss:-2.237\n",
      "Epoch:  0069 D loss:-0.6427 G loss:-2.026\n",
      "Epoch:  0069 D loss:-0.6688 G loss:-1.967\n",
      "Epoch:  0069 D loss:-0.5831 G loss:-2.088\n",
      "Epoch:  0069 D loss:-0.5982 G loss:-1.951\n",
      "Epoch:  0069 D loss:-0.8624 G loss:-1.851\n",
      "Epoch:  0069 D loss:-0.6947 G loss:-1.758\n",
      "Epoch:  0069 D loss:-0.5653 G loss:-2.243\n",
      "Epoch:  0069 D loss:-0.6105 G loss:-2.058\n",
      "Epoch:  0069 D loss:-0.6327 G loss:-2.001\n",
      "Epoch:  0069 D loss:-0.692 G loss:-2.021\n",
      "Epoch:  0069 D loss:-0.5713 G loss:-2.256\n",
      "Epoch:  0069 D loss:-0.8385 G loss:-1.984\n",
      "Epoch:  0069 D loss:-0.5896 G loss:-2.297\n",
      "Epoch:  0069 D loss:-0.6068 G loss:-2.155\n",
      "Epoch:  0069 D loss:-0.6673 G loss:-2.287\n",
      "Epoch:  0069 D loss:-0.6394 G loss:-2.129\n",
      "Epoch:  0069 D loss:-0.6682 G loss:-2.016\n",
      "Epoch:  0069 D loss:-0.6848 G loss:-2.164\n",
      "Epoch:  0069 D loss:-0.6466 G loss:-1.932\n",
      "Epoch:  0069 D loss:-0.5781 G loss:-2.291\n",
      "Epoch:  0069 D loss:-0.6359 G loss:-2.252\n",
      "Epoch:  0069 D loss:-0.5524 G loss:-2.241\n",
      "Epoch:  0069 D loss:-0.6987 G loss:-2.118\n",
      "Epoch:  0069 D loss:-0.8721 G loss:-2.032\n",
      "Epoch:  0069 D loss:-0.6776 G loss:-1.948\n",
      "Epoch:  0069 D loss:-0.6684 G loss:-2.055\n",
      "Epoch:  0069 D loss:-0.6985 G loss:-1.904\n",
      "Epoch:  0069 D loss:-0.8109 G loss:-1.784\n",
      "Epoch:  0069 D loss:-0.6138 G loss:-2.146\n",
      "Epoch:  0069 D loss:-0.5241 G loss:-2.181\n",
      "Epoch:  0069 D loss:-0.7132 G loss:-2.154\n",
      "Epoch:  0069 D loss:-0.798 G loss:-1.921\n",
      "Epoch:  0069 D loss:-0.7353 G loss:-1.792\n",
      "Epoch:  0069 D loss:-0.6647 G loss:-2.086\n",
      "Epoch:  0069 D loss:-0.7446 G loss:-2.083\n",
      "Epoch:  0069 D loss:-0.8819 G loss:-1.789\n",
      "Epoch:  0069 D loss:-0.6778 G loss:-2.157\n",
      "Epoch:  0069 D loss:-0.7353 G loss:-1.931\n",
      "Epoch:  0069 D loss:-0.7387 G loss:-2.003\n",
      "Epoch:  0069 D loss:-0.5681 G loss:-2.256\n",
      "Epoch:  0069 D loss:-0.8022 G loss:-2.0\n",
      "Epoch:  0069 D loss:-0.823 G loss:-2.12\n",
      "Epoch:  0069 D loss:-0.6606 G loss:-2.116\n",
      "Epoch:  0069 D loss:-0.821 G loss:-1.819\n",
      "Epoch:  0069 D loss:-0.6539 G loss:-2.029\n",
      "Epoch:  0069 D loss:-0.7121 G loss:-1.798\n",
      "Epoch:  0069 D loss:-0.7444 G loss:-1.783\n",
      "Epoch:  0069 D loss:-0.6392 G loss:-2.052\n",
      "Epoch:  0069 D loss:-0.7514 G loss:-1.96\n",
      "Epoch:  0069 D loss:-0.7211 G loss:-2.122\n",
      "Epoch:  0069 D loss:-0.7543 G loss:-2.067\n",
      "Epoch:  0069 D loss:-0.689 G loss:-1.91\n",
      "Epoch:  0069 D loss:-0.7297 G loss:-2.073\n",
      "Epoch:  0069 D loss:-0.5483 G loss:-2.11\n",
      "Epoch:  0069 D loss:-0.683 G loss:-2.246\n",
      "Epoch:  0069 D loss:-0.6539 G loss:-2.048\n",
      "Epoch:  0069 D loss:-0.6904 G loss:-2.121\n",
      "Epoch:  0069 D loss:-0.6739 G loss:-1.943\n",
      "Epoch:  0069 D loss:-0.6973 G loss:-1.705\n",
      "Epoch:  0069 D loss:-0.647 G loss:-2.027\n",
      "Epoch:  0069 D loss:-0.706 G loss:-2.063\n",
      "Epoch:  0069 D loss:-0.6259 G loss:-1.806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0069 D loss:-0.6391 G loss:-2.082\n",
      "Epoch:  0069 D loss:-0.735 G loss:-1.974\n",
      "Epoch:  0069 D loss:-0.6886 G loss:-2.178\n",
      "Epoch:  0069 D loss:-0.6553 G loss:-2.155\n",
      "Epoch:  0069 D loss:-0.5782 G loss:-2.188\n",
      "Epoch:  0069 D loss:-0.5889 G loss:-2.167\n",
      "Epoch:  0069 D loss:-0.6348 G loss:-2.051\n",
      "Epoch:  0069 D loss:-0.627 G loss:-2.158\n",
      "Epoch:  0069 D loss:-0.5542 G loss:-2.21\n",
      "Epoch:  0069 D loss:-0.6234 G loss:-2.307\n",
      "Epoch:  0069 D loss:-0.8463 G loss:-2.266\n",
      "Epoch:  0069 D loss:-0.6341 G loss:-2.329\n",
      "Epoch:  0069 D loss:-0.6419 G loss:-2.037\n",
      "Epoch:  0069 D loss:-0.6134 G loss:-2.149\n",
      "Epoch:  0069 D loss:-0.7209 G loss:-2.056\n",
      "Epoch:  0069 D loss:-0.6514 G loss:-1.819\n",
      "Epoch:  0069 D loss:-0.5604 G loss:-1.982\n",
      "Epoch:  0069 D loss:-0.6244 G loss:-2.145\n",
      "Epoch:  0069 D loss:-0.6652 G loss:-2.078\n",
      "Epoch:  0069 D loss:-0.6534 G loss:-2.095\n",
      "Epoch:  0069 D loss:-0.7561 G loss:-1.965\n",
      "Epoch:  0069 D loss:-0.6931 G loss:-2.217\n",
      "Epoch:  0069 D loss:-0.6274 G loss:-2.032\n",
      "Epoch:  0069 D loss:-0.6858 G loss:-2.163\n",
      "Epoch:  0069 D loss:-0.6872 G loss:-2.135\n",
      "Epoch:  0069 D loss:-0.6932 G loss:-2.069\n",
      "Epoch:  0069 D loss:-0.6089 G loss:-2.235\n",
      "Epoch:  0069 D loss:-0.6781 G loss:-2.233\n",
      "Epoch:  0069 D loss:-0.5961 G loss:-2.293\n",
      "Epoch:  0069 D loss:-0.6199 G loss:-2.35\n",
      "Epoch:  0069 D loss:-0.7671 G loss:-1.996\n",
      "Epoch:  0069 D loss:-0.6504 G loss:-2.038\n",
      "Epoch:  0069 D loss:-0.6952 G loss:-2.102\n",
      "Epoch:  0069 D loss:-0.5647 G loss:-2.006\n",
      "Epoch:  0069 D loss:-0.6783 G loss:-2.01\n",
      "Epoch:  0069 D loss:-0.5928 G loss:-2.012\n",
      "Epoch:  0069 D loss:-0.6463 G loss:-2.052\n",
      "Epoch:  0069 D loss:-0.6718 G loss:-2.113\n",
      "Epoch:  0069 D loss:-0.737 G loss:-1.935\n",
      "Epoch:  0069 D loss:-0.6572 G loss:-1.97\n",
      "Epoch:  0069 D loss:-0.6838 G loss:-2.231\n",
      "Epoch:  0069 D loss:-0.8032 G loss:-2.029\n",
      "Epoch:  0069 D loss:-0.5846 G loss:-2.07\n",
      "Epoch:  0069 D loss:-0.6917 G loss:-2.078\n",
      "Epoch:  0069 D loss:-0.714 G loss:-1.997\n",
      "Epoch:  0069 D loss:-0.6032 G loss:-2.146\n",
      "Epoch:  0069 D loss:-0.7538 G loss:-2.237\n",
      "Epoch:  0069 D loss:-0.8347 G loss:-2.158\n",
      "Epoch:  0069 D loss:-0.6558 G loss:-2.06\n",
      "Epoch:  0069 D loss:-0.7347 G loss:-2.002\n",
      "Epoch:  0069 D loss:-0.5411 G loss:-2.065\n",
      "Epoch:  0069 D loss:-0.7356 G loss:-1.877\n",
      "Epoch:  0069 D loss:-0.6663 G loss:-1.951\n",
      "Epoch:  0069 D loss:-0.6897 G loss:-1.928\n",
      "Epoch:  0069 D loss:-0.8174 G loss:-2.046\n",
      "Epoch:  0069 D loss:-0.6896 G loss:-2.045\n",
      "Epoch:  0069 D loss:-0.6788 G loss:-2.136\n",
      "Epoch:  0069 D loss:-0.7622 G loss:-2.119\n",
      "Epoch:  0069 D loss:-0.6308 G loss:-2.203\n",
      "Epoch:  0069 D loss:-0.7113 G loss:-1.985\n",
      "Epoch:  0069 D loss:-0.8068 G loss:-1.941\n",
      "Epoch:  0069 D loss:-0.7255 G loss:-1.761\n",
      "Epoch:  0069 D loss:-0.5635 G loss:-1.725\n",
      "Epoch:  0069 D loss:-0.6462 G loss:-2.087\n",
      "Epoch:  0069 D loss:-0.6787 G loss:-2.118\n",
      "Epoch:  0069 D loss:-0.912 G loss:-1.887\n",
      "Epoch:  0069 D loss:-0.6301 G loss:-2.215\n",
      "Epoch:  0069 D loss:-0.7871 G loss:-2.006\n",
      "Epoch:  0069 D loss:-0.789 G loss:-2.007\n",
      "Epoch:  0069 D loss:-0.613 G loss:-2.092\n",
      "Epoch:  0069 D loss:-0.8439 G loss:-1.947\n",
      "Epoch:  0069 D loss:-0.6438 G loss:-2.102\n",
      "Epoch:  0069 D loss:-0.6833 G loss:-1.91\n",
      "Epoch:  0069 D loss:-0.7205 G loss:-2.039\n",
      "Epoch:  0069 D loss:-0.8224 G loss:-1.842\n",
      "Epoch:  0069 D loss:-0.5939 G loss:-2.048\n",
      "Epoch:  0069 D loss:-0.6816 G loss:-2.011\n",
      "Epoch:  0069 D loss:-0.6818 G loss:-1.925\n",
      "Epoch:  0069 D loss:-0.6006 G loss:-2.172\n",
      "Epoch:  0069 D loss:-0.705 G loss:-2.119\n",
      "Epoch:  0069 D loss:-0.832 G loss:-1.921\n",
      "Epoch:  0069 D loss:-0.7728 G loss:-1.972\n",
      "Epoch:  0069 D loss:-0.8601 G loss:-1.94\n",
      "Epoch:  0069 D loss:-0.7118 G loss:-2.04\n",
      "Epoch:  0069 D loss:-0.7112 G loss:-2.032\n",
      "Epoch:  0069 D loss:-0.6531 G loss:-1.934\n",
      "Epoch:  0069 D loss:-0.7651 G loss:-1.872\n",
      "Epoch:  0069 D loss:-0.7389 G loss:-1.743\n",
      "Epoch:  0069 D loss:-0.6284 G loss:-2.136\n",
      "Epoch:  0069 D loss:-0.816 G loss:-1.859\n",
      "Epoch:  0069 D loss:-0.6825 G loss:-2.162\n",
      "Epoch:  0069 D loss:-0.619 G loss:-2.405\n",
      "Epoch:  0069 D loss:-0.7343 G loss:-2.1\n",
      "Epoch:  0069 D loss:-0.7565 G loss:-2.007\n",
      "Epoch:  0069 D loss:-0.7344 G loss:-2.045\n",
      "Epoch:  0069 D loss:-0.7215 G loss:-2.156\n",
      "Epoch:  0069 D loss:-0.7902 G loss:-1.712\n",
      "Epoch:  0069 D loss:-0.634 G loss:-1.996\n",
      "Epoch:  0069 D loss:-0.6491 G loss:-1.974\n",
      "Epoch:  0069 D loss:-0.5999 G loss:-2.098\n",
      "Epoch:  0069 D loss:-0.7614 G loss:-1.987\n",
      "Epoch:  0069 D loss:-0.7984 G loss:-1.906\n",
      "Epoch:  0069 D loss:-0.5452 G loss:-2.197\n",
      "Epoch:  0069 D loss:-0.6444 G loss:-2.011\n",
      "Epoch:  0069 D loss:-0.7121 G loss:-2.17\n",
      "Epoch:  0069 D loss:-0.6476 G loss:-2.227\n",
      "Epoch:  0069 D loss:-0.6575 G loss:-2.24\n",
      "Epoch:  0069 D loss:-0.619 G loss:-2.244\n",
      "Epoch:  0069 D loss:-0.5992 G loss:-2.352\n",
      "Epoch:  0069 D loss:-0.6995 G loss:-1.978\n",
      "Epoch:  0069 D loss:-0.6205 G loss:-2.271\n",
      "Epoch:  0069 D loss:-0.7122 G loss:-1.887\n",
      "Epoch:  0069 D loss:-0.6458 G loss:-1.743\n",
      "Epoch:  0069 D loss:-0.7295 G loss:-2.015\n",
      "Epoch:  0069 D loss:-0.6412 G loss:-1.88\n",
      "Epoch:  0069 D loss:-0.5558 G loss:-2.028\n",
      "Epoch:  0069 D loss:-0.6924 G loss:-1.822\n",
      "Epoch:  0069 D loss:-0.6453 G loss:-2.089\n",
      "Epoch:  0069 D loss:-0.6145 G loss:-2.062\n",
      "Epoch:  0069 D loss:-0.6391 G loss:-2.081\n",
      "Epoch:  0069 D loss:-0.6905 G loss:-2.068\n",
      "Epoch:  0069 D loss:-0.7034 G loss:-1.976\n",
      "Epoch:  0069 D loss:-0.6583 G loss:-1.871\n",
      "Epoch:  0069 D loss:-0.634 G loss:-2.007\n",
      "Epoch:  0069 D loss:-0.6996 G loss:-2.052\n",
      "Epoch:  0069 D loss:-0.5384 G loss:-2.308\n",
      "Epoch:  0069 D loss:-0.637 G loss:-2.205\n",
      "Epoch:  0069 D loss:-0.7086 G loss:-2.063\n",
      "Epoch:  0069 D loss:-0.761 G loss:-2.07\n",
      "Epoch:  0069 D loss:-0.6511 G loss:-2.245\n",
      "Epoch:  0069 D loss:-0.6177 G loss:-2.188\n",
      "Epoch:  0069 D loss:-0.6768 G loss:-2.243\n",
      "Epoch:  0069 D loss:-0.8663 G loss:-1.871\n",
      "Epoch:  0069 D loss:-0.7281 G loss:-2.085\n",
      "Epoch:  0069 D loss:-0.8096 G loss:-1.84\n",
      "Epoch:  0069 D loss:-0.807 G loss:-1.728\n",
      "Epoch:  0069 D loss:-0.8138 G loss:-1.609\n",
      "Epoch:  0069 D loss:-0.623 G loss:-1.891\n",
      "Epoch:  0069 D loss:-0.7111 G loss:-1.699\n",
      "Epoch:  0069 D loss:-0.6544 G loss:-1.955\n",
      "Epoch:  0069 D loss:-0.711 G loss:-1.963\n",
      "Epoch:  0069 D loss:-0.639 G loss:-2.186\n",
      "Epoch:  0069 D loss:-0.7455 G loss:-2.412\n",
      "Epoch:  0069 D loss:-0.6551 G loss:-2.168\n",
      "Epoch:  0069 D loss:-0.7352 G loss:-2.109\n",
      "Epoch:  0069 D loss:-0.5887 G loss:-2.252\n",
      "Epoch:  0069 D loss:-0.6412 G loss:-1.962\n",
      "Epoch:  0069 D loss:-0.6112 G loss:-2.089\n",
      "Epoch:  0069 D loss:-0.809 G loss:-1.667\n",
      "Epoch:  0069 D loss:-0.7613 G loss:-1.959\n",
      "Epoch:  0069 D loss:-0.7459 G loss:-2.04\n",
      "Epoch:  0069 D loss:-0.8758 G loss:-1.839\n",
      "Epoch:  0069 D loss:-0.8997 G loss:-2.124\n",
      "Epoch:  0069 D loss:-0.6861 G loss:-1.979\n",
      "Epoch:  0069 D loss:-0.6081 G loss:-1.996\n",
      "Epoch:  0069 D loss:-0.7915 G loss:-1.749\n",
      "Epoch:  0069 D loss:-0.6593 G loss:-2.0\n",
      "Epoch:  0069 D loss:-0.7062 G loss:-2.055\n",
      "Epoch:  0069 D loss:-0.6915 G loss:-1.913\n",
      "Epoch:  0069 D loss:-0.6886 G loss:-2.051\n",
      "Epoch:  0069 D loss:-0.6668 G loss:-2.047\n",
      "Epoch:  0069 D loss:-0.7352 G loss:-2.206\n",
      "Epoch:  0069 D loss:-0.6698 G loss:-2.271\n",
      "Epoch:  0069 D loss:-0.6505 G loss:-2.167\n",
      "Epoch:  0069 D loss:-0.5879 G loss:-2.177\n",
      "Epoch:  0069 D loss:-0.7279 G loss:-2.044\n",
      "Epoch:  0069 D loss:-0.6071 G loss:-2.285\n",
      "Epoch:  0069 D loss:-0.7435 G loss:-2.015\n",
      "Epoch:  0069 D loss:-0.7125 G loss:-1.851\n",
      "Epoch:  0069 D loss:-0.5754 G loss:-2.09\n",
      "Epoch:  0069 D loss:-0.7443 G loss:-1.855\n",
      "Epoch:  0069 D loss:-0.5933 G loss:-1.918\n",
      "Epoch:  0069 D loss:-0.6937 G loss:-1.965\n",
      "Epoch:  0069 D loss:-0.7216 G loss:-2.021\n",
      "Epoch:  0069 D loss:-0.7434 G loss:-1.854\n",
      "Epoch:  0069 D loss:-0.7263 G loss:-1.862\n",
      "Epoch:  0069 D loss:-0.4929 G loss:-1.98\n",
      "Epoch:  0069 D loss:-0.6818 G loss:-2.101\n",
      "Epoch:  0069 D loss:-0.6153 G loss:-2.118\n",
      "Epoch:  0069 D loss:-0.5735 G loss:-2.209\n",
      "Epoch:  0069 D loss:-0.6519 G loss:-2.348\n",
      "Epoch:  0069 D loss:-0.5622 G loss:-2.274\n",
      "Epoch:  0069 D loss:-0.586 G loss:-2.335\n",
      "Epoch:  0069 D loss:-0.5861 G loss:-2.328\n",
      "Epoch:  0069 D loss:-0.7884 G loss:-2.547\n",
      "Epoch:  0069 D loss:-0.5632 G loss:-2.388\n",
      "Epoch:  0069 D loss:-0.6659 G loss:-2.142\n",
      "Epoch:  0069 D loss:-0.608 G loss:-2.193\n",
      "Epoch:  0069 D loss:-0.5296 G loss:-2.345\n",
      "Epoch:  0069 D loss:-0.6815 G loss:-1.918\n",
      "Epoch:  0069 D loss:-0.6229 G loss:-2.012\n",
      "Epoch:  0069 D loss:-0.7761 G loss:-1.729\n",
      "Epoch:  0069 D loss:-0.5791 G loss:-2.076\n",
      "Epoch:  0069 D loss:-0.6392 G loss:-1.862\n",
      "Epoch:  0069 D loss:-0.4975 G loss:-2.007\n",
      "Epoch:  0069 D loss:-0.573 G loss:-2.143\n",
      "Epoch:  0069 D loss:-0.7014 G loss:-1.829\n",
      "Epoch:  0069 D loss:-0.6171 G loss:-2.006\n",
      "Epoch:  0069 D loss:-0.5683 G loss:-2.261\n",
      "Epoch:  0069 D loss:-0.7694 G loss:-2.124\n",
      "Epoch:  0069 D loss:-0.6099 G loss:-2.041\n",
      "Epoch:  0069 D loss:-0.6257 G loss:-2.192\n",
      "Epoch:  0069 D loss:-0.8533 G loss:-2.067\n",
      "Epoch:  0069 D loss:-0.5958 G loss:-2.287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0069 D loss:-0.6733 G loss:-2.085\n",
      "Epoch:  0069 D loss:-0.6231 G loss:-2.26\n",
      "Epoch:  0069 D loss:-0.6976 G loss:-1.984\n",
      "Epoch:  0069 D loss:-0.6873 G loss:-2.104\n",
      "Epoch:  0069 D loss:-0.6827 G loss:-2.226\n",
      "Epoch:  0069 D loss:-0.5743 G loss:-1.842\n",
      "Epoch:  0069 D loss:-0.562 G loss:-2.237\n",
      "Epoch:  0069 D loss:-0.6521 G loss:-1.904\n",
      "Epoch:  0069 D loss:-0.7941 G loss:-1.709\n",
      "Epoch:  0069 D loss:-0.6198 G loss:-2.177\n",
      "Epoch:  0069 D loss:-0.5773 G loss:-2.246\n",
      "Epoch:  0069 D loss:-0.7181 G loss:-2.104\n",
      "Epoch:  0069 D loss:-0.451 G loss:-2.074\n",
      "Epoch:  0069 D loss:-0.6822 G loss:-2.238\n",
      "Epoch:  0069 D loss:-0.6854 G loss:-2.165\n",
      "Epoch:  0069 D loss:-0.6337 G loss:-2.029\n",
      "Epoch:  0069 D loss:-0.5175 G loss:-2.241\n",
      "Epoch:  0069 D loss:-0.5898 G loss:-2.104\n",
      "Epoch:  0069 D loss:-0.5506 G loss:-2.229\n",
      "Epoch:  0069 D loss:-0.7417 G loss:-1.971\n",
      "Epoch:  0069 D loss:-0.8154 G loss:-1.858\n",
      "Epoch:  0069 D loss:-0.6742 G loss:-2.067\n",
      "Epoch:  0069 D loss:-0.643 G loss:-1.819\n",
      "Epoch:  0069 D loss:-0.7589 G loss:-1.92\n",
      "Epoch:  0069 D loss:-0.6289 G loss:-2.179\n",
      "Epoch:  0069 D loss:-0.5855 G loss:-2.133\n",
      "Epoch:  0069 D loss:-0.7186 G loss:-2.01\n",
      "Epoch:  0069 D loss:-0.7643 G loss:-1.905\n",
      "Epoch:  0069 D loss:-0.6435 G loss:-2.026\n",
      "Epoch:  0069 D loss:-0.7256 G loss:-2.062\n",
      "Epoch:  0069 D loss:-0.7207 G loss:-2.115\n",
      "Epoch:  0069 D loss:-0.6862 G loss:-1.96\n",
      "Epoch:  0069 D loss:-0.5478 G loss:-2.13\n",
      "Epoch:  0069 D loss:-0.612 G loss:-2.197\n",
      "Epoch:  0069 D loss:-0.7614 G loss:-2.196\n",
      "Epoch:  0069 D loss:-0.8554 G loss:-2.056\n",
      "Epoch:  0069 D loss:-0.6738 G loss:-2.054\n",
      "Epoch:  0069 D loss:-0.7506 G loss:-1.873\n",
      "Epoch:  0069 D loss:-0.6953 G loss:-1.911\n",
      "Epoch:  0069 D loss:-0.7161 G loss:-1.879\n",
      "Epoch:  0069 D loss:-0.7241 G loss:-1.916\n",
      "Epoch:  0069 D loss:-0.6261 G loss:-1.885\n",
      "Epoch:  0069 D loss:-0.6072 G loss:-2.06\n",
      "Epoch:  0069 D loss:-0.6612 G loss:-2.034\n",
      "Epoch:  0069 D loss:-0.7358 G loss:-2.058\n",
      "Epoch:  0069 D loss:-0.6339 G loss:-2.141\n",
      "Epoch:  0069 D loss:-0.6938 G loss:-1.772\n",
      "Epoch:  0069 D loss:-0.7399 G loss:-2.002\n",
      "Epoch:  0069 D loss:-0.7611 G loss:-2.199\n",
      "Epoch:  0069 D loss:-0.538 G loss:-2.243\n",
      "Epoch:  0069 D loss:-0.5957 G loss:-2.145\n",
      "Epoch:  0069 D loss:-0.7934 G loss:-2.035\n",
      "Epoch:  0069 D loss:-0.7311 G loss:-2.258\n",
      "Epoch:  0069 D loss:-0.7491 G loss:-2.188\n",
      "Epoch:  0069 D loss:-0.7938 G loss:-2.065\n",
      "Epoch:  0069 D loss:-0.7377 G loss:-2.159\n",
      "Epoch:  0069 D loss:-0.6294 G loss:-2.095\n",
      "Epoch:  0069 D loss:-0.7516 G loss:-2.091\n",
      "Epoch:  0069 D loss:-0.8313 G loss:-1.942\n",
      "Epoch:  0069 D loss:-0.7253 G loss:-1.947\n",
      "Epoch:  0069 D loss:-0.8101 G loss:-1.832\n",
      "Epoch:  0069 D loss:-0.7564 G loss:-1.922\n",
      "Epoch:  0069 D loss:-0.6543 G loss:-1.901\n",
      "Epoch:  0069 D loss:-0.7798 G loss:-1.859\n",
      "Epoch:  0069 D loss:-0.7894 G loss:-1.897\n",
      "Epoch:  0069 D loss:-0.6628 G loss:-1.815\n",
      "Epoch:  0069 D loss:-0.8496 G loss:-1.793\n",
      "Epoch:  0069 D loss:-0.7437 G loss:-1.93\n",
      "Epoch:  0069 D loss:-0.5469 G loss:-2.215\n",
      "Epoch:  0069 D loss:-0.8264 G loss:-2.0\n",
      "Epoch:  0069 D loss:-0.711 G loss:-2.199\n",
      "Epoch:  0069 D loss:-0.7251 G loss:-2.234\n",
      "Epoch:  0069 D loss:-0.8405 G loss:-2.059\n",
      "Epoch:  0069 D loss:-0.6709 G loss:-2.148\n",
      "Epoch:  0069 D loss:-0.7035 G loss:-2.038\n",
      "Epoch:  0069 D loss:-0.6744 G loss:-2.016\n",
      "Epoch:  0069 D loss:-0.8135 G loss:-1.953\n",
      "Epoch:  0069 D loss:-0.7046 G loss:-1.937\n",
      "Epoch:  0069 D loss:-0.6274 G loss:-1.805\n",
      "Epoch:  0069 D loss:-0.7612 G loss:-1.843\n",
      "Epoch:  0069 D loss:-0.6276 G loss:-2.075\n",
      "Epoch:  0069 D loss:-0.7347 G loss:-2.26\n",
      "Epoch:  0069 D loss:-0.695 G loss:-2.085\n",
      "Epoch:  0069 D loss:-0.6544 G loss:-2.035\n",
      "Epoch:  0069 D loss:-0.7282 G loss:-2.238\n",
      "Epoch:  0069 D loss:-0.8091 G loss:-1.999\n",
      "Epoch:  0069 D loss:-0.8089 G loss:-2.079\n",
      "Epoch:  0069 D loss:-0.6552 G loss:-2.169\n",
      "Epoch:  0069 D loss:-0.5796 G loss:-2.299\n",
      "Epoch:  0069 D loss:-0.6041 G loss:-2.161\n",
      "Epoch:  0069 D loss:-0.6698 G loss:-2.067\n",
      "Epoch:  0069 D loss:-0.5279 G loss:-1.931\n",
      "Epoch:  0069 D loss:-0.6134 G loss:-1.965\n",
      "Epoch:  0069 D loss:-0.6676 G loss:-1.923\n",
      "Epoch:  0069 D loss:-0.7543 G loss:-1.965\n",
      "Epoch:  0069 D loss:-0.7225 G loss:-1.983\n",
      "Epoch:  0069 D loss:-0.7515 G loss:-1.95\n",
      "Epoch:  0069 D loss:-0.7463 G loss:-1.955\n",
      "Epoch:  0069 D loss:-0.5813 G loss:-2.084\n",
      "Epoch:  0069 D loss:-0.7162 G loss:-2.035\n",
      "Epoch:  0069 D loss:-0.7023 G loss:-2.134\n",
      "Epoch:  0069 D loss:-0.6542 G loss:-2.091\n",
      "Epoch:  0069 D loss:-0.6666 G loss:-2.14\n",
      "Epoch:  0069 D loss:-0.7361 G loss:-2.035\n",
      "Epoch:  0069 D loss:-0.7631 G loss:-2.097\n",
      "Epoch:  0069 D loss:-0.8031 G loss:-1.962\n",
      "Epoch:  0069 D loss:-0.5627 G loss:-2.081\n",
      "Epoch:  0069 D loss:-0.7743 G loss:-2.091\n",
      "Epoch:  0069 D loss:-0.6732 G loss:-2.082\n",
      "Epoch:  0069 D loss:-0.7246 G loss:-1.992\n",
      "Epoch:  0069 D loss:-0.8573 G loss:-1.752\n",
      "Epoch:  0069 D loss:-0.7935 G loss:-1.936\n",
      "Epoch:  0069 D loss:-0.6879 G loss:-2.069\n",
      "Epoch:  0069 D loss:-0.8124 G loss:-1.827\n",
      "Epoch:  0069 D loss:-0.6077 G loss:-1.933\n",
      "Epoch:  0069 D loss:-0.7526 G loss:-1.92\n",
      "Epoch:  0069 D loss:-0.6036 G loss:-2.041\n",
      "Epoch:  0069 D loss:-0.7231 G loss:-1.894\n",
      "Epoch:  0069 D loss:-0.6849 G loss:-2.036\n",
      "Epoch:  0069 D loss:-0.7133 G loss:-2.088\n",
      "Epoch:  0069 D loss:-0.6763 G loss:-2.094\n",
      "Epoch:  0069 D loss:-0.7557 G loss:-2.122\n",
      "Epoch:  0069 D loss:-0.6465 G loss:-2.176\n",
      "Epoch:  0069 D loss:-0.6043 G loss:-1.912\n",
      "Epoch:  0069 D loss:-0.7173 G loss:-2.05\n",
      "Epoch:  0069 D loss:-0.6821 G loss:-2.048\n",
      "Epoch:  0069 D loss:-0.5922 G loss:-2.002\n",
      "Epoch:  0069 D loss:-0.6936 G loss:-2.035\n",
      "Epoch:  0069 D loss:-0.6319 G loss:-2.206\n",
      "Epoch:  0069 D loss:-0.5308 G loss:-2.408\n",
      "Epoch:  0069 D loss:-0.6864 G loss:-2.256\n",
      "Epoch:  0069 D loss:-0.7289 G loss:-2.075\n",
      "Epoch:  0069 D loss:-0.7227 G loss:-2.11\n",
      "Epoch:  0069 D loss:-0.679 G loss:-2.17\n",
      "Epoch:  0069 D loss:-0.6737 G loss:-2.193\n",
      "Epoch:  0069 D loss:-0.5843 G loss:-1.932\n",
      "Epoch:  0069 D loss:-0.6126 G loss:-2.044\n",
      "Epoch:  0069 D loss:-0.7224 G loss:-1.853\n",
      "Epoch:  0069 D loss:-0.5337 G loss:-2.076\n",
      "Epoch:  0069 D loss:-0.6254 G loss:-1.98\n",
      "Epoch:  0069 D loss:-0.6723 G loss:-1.82\n",
      "Epoch:  0069 D loss:-0.8389 G loss:-1.616\n",
      "Epoch:  0069 D loss:-0.5384 G loss:-2.122\n",
      "Epoch:  0069 D loss:-0.6314 G loss:-1.996\n",
      "Epoch:  0069 D loss:-0.7769 G loss:-2.102\n",
      "Epoch:  0069 D loss:-0.6575 G loss:-2.253\n",
      "Epoch:  0070 D loss:-0.5703 G loss:-2.216\n",
      "Epoch:  0070 D loss:-0.7242 G loss:-2.207\n",
      "Epoch:  0070 D loss:-0.795 G loss:-2.423\n",
      "Epoch:  0070 D loss:-0.7087 G loss:-2.305\n",
      "Epoch:  0070 D loss:-0.7154 G loss:-2.121\n",
      "Epoch:  0070 D loss:-0.5395 G loss:-2.134\n",
      "Epoch:  0070 D loss:-0.5976 G loss:-1.993\n",
      "Epoch:  0070 D loss:-0.6789 G loss:-1.774\n",
      "Epoch:  0070 D loss:-0.7471 G loss:-1.705\n",
      "Epoch:  0070 D loss:-0.6283 G loss:-1.816\n",
      "Epoch:  0070 D loss:-0.5836 G loss:-1.963\n",
      "Epoch:  0070 D loss:-0.7232 G loss:-1.903\n",
      "Epoch:  0070 D loss:-0.6993 G loss:-1.896\n",
      "Epoch:  0070 D loss:-0.6808 G loss:-2.099\n",
      "Epoch:  0070 D loss:-0.6599 G loss:-2.165\n",
      "Epoch:  0070 D loss:-0.6049 G loss:-2.13\n",
      "Epoch:  0070 D loss:-0.6414 G loss:-2.405\n",
      "Epoch:  0070 D loss:-0.8597 G loss:-2.132\n",
      "Epoch:  0070 D loss:-0.778 G loss:-2.134\n",
      "Epoch:  0070 D loss:-0.5203 G loss:-2.416\n",
      "Epoch:  0070 D loss:-0.7987 G loss:-2.274\n",
      "Epoch:  0070 D loss:-0.8013 G loss:-2.247\n",
      "Epoch:  0070 D loss:-0.7161 G loss:-1.898\n",
      "Epoch:  0070 D loss:-0.566 G loss:-2.026\n",
      "Epoch:  0070 D loss:-0.5814 G loss:-2.029\n",
      "Epoch:  0070 D loss:-0.7823 G loss:-1.981\n",
      "Epoch:  0070 D loss:-0.6615 G loss:-1.952\n",
      "Epoch:  0070 D loss:-0.8668 G loss:-2.11\n",
      "Epoch:  0070 D loss:-0.6326 G loss:-1.837\n",
      "Epoch:  0070 D loss:-0.5908 G loss:-2.147\n",
      "Epoch:  0070 D loss:-0.7136 G loss:-1.845\n",
      "Epoch:  0070 D loss:-0.6605 G loss:-1.936\n",
      "Epoch:  0070 D loss:-0.7108 G loss:-1.907\n",
      "Epoch:  0070 D loss:-0.6675 G loss:-2.031\n",
      "Epoch:  0070 D loss:-0.6033 G loss:-2.044\n",
      "Epoch:  0070 D loss:-0.7741 G loss:-1.917\n",
      "Epoch:  0070 D loss:-0.6901 G loss:-1.905\n",
      "Epoch:  0070 D loss:-0.7907 G loss:-1.88\n",
      "Epoch:  0070 D loss:-0.7889 G loss:-2.036\n",
      "Epoch:  0070 D loss:-0.7257 G loss:-1.94\n",
      "Epoch:  0070 D loss:-0.5985 G loss:-2.152\n",
      "Epoch:  0070 D loss:-0.7776 G loss:-2.037\n",
      "Epoch:  0070 D loss:-0.6193 G loss:-2.014\n",
      "Epoch:  0070 D loss:-0.7004 G loss:-2.062\n",
      "Epoch:  0070 D loss:-0.6874 G loss:-2.125\n",
      "Epoch:  0070 D loss:-0.7005 G loss:-2.195\n",
      "Epoch:  0070 D loss:-0.9437 G loss:-2.014\n",
      "Epoch:  0070 D loss:-0.7417 G loss:-1.922\n",
      "Epoch:  0070 D loss:-0.7494 G loss:-2.04\n",
      "Epoch:  0070 D loss:-0.6723 G loss:-1.89\n",
      "Epoch:  0070 D loss:-0.753 G loss:-1.92\n",
      "Epoch:  0070 D loss:-0.8299 G loss:-1.968\n",
      "Epoch:  0070 D loss:-0.5967 G loss:-2.124\n",
      "Epoch:  0070 D loss:-0.7696 G loss:-1.859\n",
      "Epoch:  0070 D loss:-0.9031 G loss:-1.908\n",
      "Epoch:  0070 D loss:-0.755 G loss:-1.793\n",
      "Epoch:  0070 D loss:-0.6465 G loss:-1.942\n",
      "Epoch:  0070 D loss:-0.6802 G loss:-2.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0070 D loss:-0.7694 G loss:-1.991\n",
      "Epoch:  0070 D loss:-0.7757 G loss:-1.841\n",
      "Epoch:  0070 D loss:-0.7923 G loss:-1.881\n",
      "Epoch:  0070 D loss:-0.6666 G loss:-1.851\n",
      "Epoch:  0070 D loss:-0.7475 G loss:-1.889\n",
      "Epoch:  0070 D loss:-0.7678 G loss:-1.795\n",
      "Epoch:  0070 D loss:-0.7529 G loss:-1.961\n",
      "Epoch:  0070 D loss:-0.7689 G loss:-1.854\n",
      "Epoch:  0070 D loss:-0.8071 G loss:-1.759\n",
      "Epoch:  0070 D loss:-0.6651 G loss:-1.925\n",
      "Epoch:  0070 D loss:-0.7794 G loss:-2.175\n",
      "Epoch:  0070 D loss:-0.6602 G loss:-2.05\n",
      "Epoch:  0070 D loss:-0.7576 G loss:-2.167\n",
      "Epoch:  0070 D loss:-0.5954 G loss:-2.132\n",
      "Epoch:  0070 D loss:-0.6419 G loss:-2.108\n",
      "Epoch:  0070 D loss:-0.5912 G loss:-2.134\n",
      "Epoch:  0070 D loss:-0.7026 G loss:-2.225\n",
      "Epoch:  0070 D loss:-0.6818 G loss:-2.256\n",
      "Epoch:  0070 D loss:-0.6218 G loss:-2.224\n",
      "Epoch:  0070 D loss:-0.6108 G loss:-2.184\n",
      "Epoch:  0070 D loss:-0.7621 G loss:-2.179\n",
      "Epoch:  0070 D loss:-0.7468 G loss:-2.149\n",
      "Epoch:  0070 D loss:-0.6818 G loss:-2.108\n",
      "Epoch:  0070 D loss:-0.6792 G loss:-2.001\n",
      "Epoch:  0070 D loss:-0.7016 G loss:-1.899\n",
      "Epoch:  0070 D loss:-0.6803 G loss:-1.911\n",
      "Epoch:  0070 D loss:-0.603 G loss:-2.176\n",
      "Epoch:  0070 D loss:-0.7047 G loss:-2.091\n",
      "Epoch:  0070 D loss:-0.65 G loss:-2.05\n",
      "Epoch:  0070 D loss:-0.6811 G loss:-2.053\n",
      "Epoch:  0070 D loss:-0.5934 G loss:-1.929\n",
      "Epoch:  0070 D loss:-0.8141 G loss:-1.923\n",
      "Epoch:  0070 D loss:-0.5645 G loss:-2.164\n",
      "Epoch:  0070 D loss:-0.6733 G loss:-2.18\n",
      "Epoch:  0070 D loss:-0.7338 G loss:-2.021\n",
      "Epoch:  0070 D loss:-0.8833 G loss:-1.875\n",
      "Epoch:  0070 D loss:-0.7489 G loss:-1.887\n",
      "Epoch:  0070 D loss:-0.7997 G loss:-1.704\n",
      "Epoch:  0070 D loss:-0.7089 G loss:-2.029\n",
      "Epoch:  0070 D loss:-0.6954 G loss:-2.106\n",
      "Epoch:  0070 D loss:-0.533 G loss:-2.143\n",
      "Epoch:  0070 D loss:-0.6286 G loss:-2.17\n",
      "Epoch:  0070 D loss:-0.8044 G loss:-1.771\n",
      "Epoch:  0070 D loss:-0.6648 G loss:-2.017\n",
      "Epoch:  0070 D loss:-0.5825 G loss:-2.175\n",
      "Epoch:  0070 D loss:-0.6383 G loss:-1.957\n",
      "Epoch:  0070 D loss:-0.6146 G loss:-1.993\n",
      "Epoch:  0070 D loss:-0.5341 G loss:-2.195\n",
      "Epoch:  0070 D loss:-0.6657 G loss:-2.432\n",
      "Epoch:  0070 D loss:-0.5789 G loss:-2.311\n",
      "Epoch:  0070 D loss:-0.5938 G loss:-2.172\n",
      "Epoch:  0070 D loss:-0.656 G loss:-2.228\n",
      "Epoch:  0070 D loss:-0.6388 G loss:-1.968\n",
      "Epoch:  0070 D loss:-0.7934 G loss:-1.994\n",
      "Epoch:  0070 D loss:-0.7524 G loss:-2.253\n",
      "Epoch:  0070 D loss:-0.8297 G loss:-1.898\n",
      "Epoch:  0070 D loss:-0.6014 G loss:-2.078\n",
      "Epoch:  0070 D loss:-0.5862 G loss:-2.082\n",
      "Epoch:  0070 D loss:-0.7306 G loss:-2.123\n",
      "Epoch:  0070 D loss:-0.5538 G loss:-2.238\n",
      "Epoch:  0070 D loss:-0.5437 G loss:-2.169\n",
      "Epoch:  0070 D loss:-0.6331 G loss:-2.086\n",
      "Epoch:  0070 D loss:-0.644 G loss:-2.205\n",
      "Epoch:  0070 D loss:-0.5969 G loss:-2.186\n",
      "Epoch:  0070 D loss:-0.7151 G loss:-2.144\n",
      "Epoch:  0070 D loss:-0.6303 G loss:-2.257\n",
      "Epoch:  0070 D loss:-0.6869 G loss:-2.26\n",
      "Epoch:  0070 D loss:-0.6933 G loss:-2.1\n",
      "Epoch:  0070 D loss:-0.5149 G loss:-2.067\n",
      "Epoch:  0070 D loss:-0.7119 G loss:-2.078\n",
      "Epoch:  0070 D loss:-0.5721 G loss:-2.064\n",
      "Epoch:  0070 D loss:-0.5916 G loss:-2.004\n",
      "Epoch:  0070 D loss:-0.5826 G loss:-2.025\n",
      "Epoch:  0070 D loss:-0.6358 G loss:-1.793\n",
      "Epoch:  0070 D loss:-0.6963 G loss:-2.028\n",
      "Epoch:  0070 D loss:-0.7285 G loss:-2.059\n",
      "Epoch:  0070 D loss:-0.642 G loss:-2.121\n",
      "Epoch:  0070 D loss:-0.5654 G loss:-2.052\n",
      "Epoch:  0070 D loss:-0.7626 G loss:-1.992\n",
      "Epoch:  0070 D loss:-0.6437 G loss:-2.116\n",
      "Epoch:  0070 D loss:-0.629 G loss:-2.03\n",
      "Epoch:  0070 D loss:-0.7003 G loss:-1.992\n",
      "Epoch:  0070 D loss:-0.5976 G loss:-2.199\n",
      "Epoch:  0070 D loss:-0.6113 G loss:-1.921\n",
      "Epoch:  0070 D loss:-0.5709 G loss:-2.149\n",
      "Epoch:  0070 D loss:-0.4831 G loss:-2.223\n",
      "Epoch:  0070 D loss:-0.6537 G loss:-1.98\n",
      "Epoch:  0070 D loss:-0.7593 G loss:-1.882\n",
      "Epoch:  0070 D loss:-0.757 G loss:-2.12\n",
      "Epoch:  0070 D loss:-0.5784 G loss:-2.309\n",
      "Epoch:  0070 D loss:-0.7754 G loss:-2.076\n",
      "Epoch:  0070 D loss:-0.7216 G loss:-2.126\n",
      "Epoch:  0070 D loss:-0.6306 G loss:-2.135\n",
      "Epoch:  0070 D loss:-0.6679 G loss:-2.019\n",
      "Epoch:  0070 D loss:-0.858 G loss:-1.809\n",
      "Epoch:  0070 D loss:-0.7112 G loss:-1.863\n",
      "Epoch:  0070 D loss:-0.5593 G loss:-2.039\n",
      "Epoch:  0070 D loss:-0.5871 G loss:-1.98\n",
      "Epoch:  0070 D loss:-0.6668 G loss:-1.985\n",
      "Epoch:  0070 D loss:-0.6148 G loss:-2.061\n",
      "Epoch:  0070 D loss:-0.6219 G loss:-2.036\n",
      "Epoch:  0070 D loss:-0.6592 G loss:-1.967\n",
      "Epoch:  0070 D loss:-0.5559 G loss:-2.082\n",
      "Epoch:  0070 D loss:-0.6403 G loss:-2.195\n",
      "Epoch:  0070 D loss:-0.796 G loss:-2.266\n",
      "Epoch:  0070 D loss:-0.6719 G loss:-2.25\n",
      "Epoch:  0070 D loss:-0.6155 G loss:-2.175\n",
      "Epoch:  0070 D loss:-0.5811 G loss:-2.2\n",
      "Epoch:  0070 D loss:-0.6539 G loss:-2.218\n",
      "Epoch:  0070 D loss:-0.7965 G loss:-2.0\n",
      "Epoch:  0070 D loss:-0.7743 G loss:-2.027\n",
      "Epoch:  0070 D loss:-0.7663 G loss:-1.942\n",
      "Epoch:  0070 D loss:-0.7042 G loss:-1.967\n",
      "Epoch:  0070 D loss:-0.7555 G loss:-1.769\n",
      "Epoch:  0070 D loss:-0.7641 G loss:-1.845\n",
      "Epoch:  0070 D loss:-0.819 G loss:-1.865\n",
      "Epoch:  0070 D loss:-0.6916 G loss:-1.791\n",
      "Epoch:  0070 D loss:-0.6789 G loss:-1.829\n",
      "Epoch:  0070 D loss:-0.7528 G loss:-1.878\n",
      "Epoch:  0070 D loss:-0.7098 G loss:-2.126\n",
      "Epoch:  0070 D loss:-0.743 G loss:-2.086\n",
      "Epoch:  0070 D loss:-0.8356 G loss:-2.093\n",
      "Epoch:  0070 D loss:-0.782 G loss:-2.184\n",
      "Epoch:  0070 D loss:-0.6751 G loss:-2.369\n",
      "Epoch:  0070 D loss:-0.7313 G loss:-2.3\n",
      "Epoch:  0070 D loss:-0.5225 G loss:-2.338\n",
      "Epoch:  0070 D loss:-0.6606 G loss:-2.184\n",
      "Epoch:  0070 D loss:-0.7197 G loss:-1.931\n",
      "Epoch:  0070 D loss:-0.6544 G loss:-1.818\n",
      "Epoch:  0070 D loss:-0.6098 G loss:-1.886\n",
      "Epoch:  0070 D loss:-0.7049 G loss:-1.919\n",
      "Epoch:  0070 D loss:-0.7103 G loss:-1.828\n",
      "Epoch:  0070 D loss:-0.7004 G loss:-2.008\n",
      "Epoch:  0070 D loss:-0.5861 G loss:-1.963\n",
      "Epoch:  0070 D loss:-0.7091 G loss:-2.159\n",
      "Epoch:  0070 D loss:-0.6925 G loss:-1.945\n",
      "Epoch:  0070 D loss:-0.6731 G loss:-2.047\n",
      "Epoch:  0070 D loss:-0.7811 G loss:-2.236\n",
      "Epoch:  0070 D loss:-0.7717 G loss:-1.965\n",
      "Epoch:  0070 D loss:-0.6876 G loss:-1.96\n",
      "Epoch:  0070 D loss:-0.7091 G loss:-1.999\n",
      "Epoch:  0070 D loss:-0.7579 G loss:-1.843\n",
      "Epoch:  0070 D loss:-0.7217 G loss:-1.931\n",
      "Epoch:  0070 D loss:-0.6234 G loss:-2.061\n",
      "Epoch:  0070 D loss:-0.7778 G loss:-1.874\n",
      "Epoch:  0070 D loss:-0.9098 G loss:-1.789\n",
      "Epoch:  0070 D loss:-0.7315 G loss:-2.076\n",
      "Epoch:  0070 D loss:-0.7217 G loss:-2.014\n",
      "Epoch:  0070 D loss:-0.7458 G loss:-1.896\n",
      "Epoch:  0070 D loss:-0.7678 G loss:-2.005\n",
      "Epoch:  0070 D loss:-0.5761 G loss:-2.088\n",
      "Epoch:  0070 D loss:-0.7445 G loss:-2.057\n",
      "Epoch:  0070 D loss:-0.5585 G loss:-2.093\n",
      "Epoch:  0070 D loss:-0.7079 G loss:-2.119\n",
      "Epoch:  0070 D loss:-0.7274 G loss:-2.253\n",
      "Epoch:  0070 D loss:-0.8349 G loss:-2.121\n",
      "Epoch:  0070 D loss:-0.673 G loss:-2.252\n",
      "Epoch:  0070 D loss:-0.6956 G loss:-2.181\n",
      "Epoch:  0070 D loss:-0.7249 G loss:-2.095\n",
      "Epoch:  0070 D loss:-0.6962 G loss:-1.957\n",
      "Epoch:  0070 D loss:-0.7244 G loss:-1.886\n",
      "Epoch:  0070 D loss:-0.583 G loss:-1.852\n",
      "Epoch:  0070 D loss:-0.7658 G loss:-1.789\n",
      "Epoch:  0070 D loss:-0.7034 G loss:-2.037\n",
      "Epoch:  0070 D loss:-0.6916 G loss:-1.769\n",
      "Epoch:  0070 D loss:-0.7106 G loss:-1.684\n",
      "Epoch:  0070 D loss:-0.8752 G loss:-1.818\n",
      "Epoch:  0070 D loss:-0.8428 G loss:-1.846\n",
      "Epoch:  0070 D loss:-0.805 G loss:-2.069\n",
      "Epoch:  0070 D loss:-0.663 G loss:-2.011\n",
      "Epoch:  0070 D loss:-0.743 G loss:-2.244\n",
      "Epoch:  0070 D loss:-0.6921 G loss:-1.959\n",
      "Epoch:  0070 D loss:-0.6219 G loss:-2.365\n",
      "Epoch:  0070 D loss:-0.6675 G loss:-2.211\n",
      "Epoch:  0070 D loss:-0.7768 G loss:-2.239\n",
      "Epoch:  0070 D loss:-0.7454 G loss:-2.075\n",
      "Epoch:  0070 D loss:-0.754 G loss:-2.129\n",
      "Epoch:  0070 D loss:-0.6532 G loss:-2.083\n",
      "Epoch:  0070 D loss:-0.7371 G loss:-1.884\n",
      "Epoch:  0070 D loss:-0.6621 G loss:-1.886\n",
      "Epoch:  0070 D loss:-0.6738 G loss:-2.098\n",
      "Epoch:  0070 D loss:-0.6806 G loss:-2.017\n",
      "Epoch:  0070 D loss:-0.7854 G loss:-1.718\n",
      "Epoch:  0070 D loss:-0.5604 G loss:-2.039\n",
      "Epoch:  0070 D loss:-0.5711 G loss:-2.213\n",
      "Epoch:  0070 D loss:-0.7502 G loss:-1.972\n",
      "Epoch:  0070 D loss:-0.6269 G loss:-2.148\n",
      "Epoch:  0070 D loss:-0.8181 G loss:-1.744\n",
      "Epoch:  0070 D loss:-0.8244 G loss:-1.866\n",
      "Epoch:  0070 D loss:-0.6651 G loss:-1.967\n",
      "Epoch:  0070 D loss:-0.6872 G loss:-1.945\n",
      "Epoch:  0070 D loss:-0.6935 G loss:-1.944\n",
      "Epoch:  0070 D loss:-0.6502 G loss:-1.946\n",
      "Epoch:  0070 D loss:-0.5501 G loss:-1.947\n",
      "Epoch:  0070 D loss:-0.6972 G loss:-1.938\n",
      "Epoch:  0070 D loss:-0.8318 G loss:-2.238\n",
      "Epoch:  0070 D loss:-0.7256 G loss:-1.954\n",
      "Epoch:  0070 D loss:-0.572 G loss:-1.896\n",
      "Epoch:  0070 D loss:-0.5764 G loss:-2.041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0070 D loss:-0.5782 G loss:-2.079\n",
      "Epoch:  0070 D loss:-0.6736 G loss:-1.937\n",
      "Epoch:  0070 D loss:-0.7812 G loss:-2.136\n",
      "Epoch:  0070 D loss:-0.7675 G loss:-2.127\n",
      "Epoch:  0070 D loss:-0.5022 G loss:-2.079\n",
      "Epoch:  0070 D loss:-0.7534 G loss:-1.989\n",
      "Epoch:  0070 D loss:-0.7686 G loss:-2.072\n",
      "Epoch:  0070 D loss:-0.6248 G loss:-2.199\n",
      "Epoch:  0070 D loss:-0.6915 G loss:-1.98\n",
      "Epoch:  0070 D loss:-0.6242 G loss:-1.873\n",
      "Epoch:  0070 D loss:-0.6407 G loss:-1.894\n",
      "Epoch:  0070 D loss:-0.6358 G loss:-1.97\n",
      "Epoch:  0070 D loss:-0.6399 G loss:-2.035\n",
      "Epoch:  0070 D loss:-0.688 G loss:-1.887\n",
      "Epoch:  0070 D loss:-0.6768 G loss:-1.916\n",
      "Epoch:  0070 D loss:-0.5859 G loss:-1.924\n",
      "Epoch:  0070 D loss:-0.795 G loss:-1.843\n",
      "Epoch:  0070 D loss:-0.677 G loss:-2.009\n",
      "Epoch:  0070 D loss:-0.6969 G loss:-1.873\n",
      "Epoch:  0070 D loss:-0.6004 G loss:-2.064\n",
      "Epoch:  0070 D loss:-0.6998 G loss:-1.977\n",
      "Epoch:  0070 D loss:-0.5549 G loss:-2.216\n",
      "Epoch:  0070 D loss:-0.6527 G loss:-2.265\n",
      "Epoch:  0070 D loss:-0.6821 G loss:-2.094\n",
      "Epoch:  0070 D loss:-0.7263 G loss:-2.058\n",
      "Epoch:  0070 D loss:-0.6798 G loss:-1.943\n",
      "Epoch:  0070 D loss:-0.6425 G loss:-2.05\n",
      "Epoch:  0070 D loss:-0.6515 G loss:-2.231\n",
      "Epoch:  0070 D loss:-0.705 G loss:-1.942\n",
      "Epoch:  0070 D loss:-0.7584 G loss:-1.863\n",
      "Epoch:  0070 D loss:-0.7753 G loss:-1.914\n",
      "Epoch:  0070 D loss:-0.6281 G loss:-2.069\n",
      "Epoch:  0070 D loss:-0.687 G loss:-1.975\n",
      "Epoch:  0070 D loss:-0.6646 G loss:-1.924\n",
      "Epoch:  0070 D loss:-0.6018 G loss:-2.027\n",
      "Epoch:  0070 D loss:-0.5847 G loss:-1.986\n",
      "Epoch:  0070 D loss:-0.7297 G loss:-1.908\n",
      "Epoch:  0070 D loss:-0.4938 G loss:-2.482\n",
      "Epoch:  0070 D loss:-0.7856 G loss:-2.004\n",
      "Epoch:  0070 D loss:-0.6731 G loss:-2.124\n",
      "Epoch:  0070 D loss:-0.6517 G loss:-2.263\n",
      "Epoch:  0070 D loss:-0.6759 G loss:-2.134\n",
      "Epoch:  0070 D loss:-0.718 G loss:-2.208\n",
      "Epoch:  0070 D loss:-0.6913 G loss:-2.303\n",
      "Epoch:  0070 D loss:-0.6571 G loss:-2.166\n",
      "Epoch:  0070 D loss:-0.747 G loss:-2.263\n",
      "Epoch:  0070 D loss:-0.7657 G loss:-1.995\n",
      "Epoch:  0070 D loss:-0.6738 G loss:-1.723\n",
      "Epoch:  0070 D loss:-0.8044 G loss:-1.775\n",
      "Epoch:  0070 D loss:-0.6352 G loss:-1.551\n",
      "Epoch:  0070 D loss:-0.7601 G loss:-1.603\n",
      "Epoch:  0070 D loss:-0.6332 G loss:-1.982\n",
      "Epoch:  0070 D loss:-0.5848 G loss:-2.166\n",
      "Epoch:  0070 D loss:-0.6381 G loss:-2.04\n",
      "Epoch:  0070 D loss:-0.6857 G loss:-1.949\n",
      "Epoch:  0070 D loss:-0.7237 G loss:-2.076\n",
      "Epoch:  0070 D loss:-0.537 G loss:-2.206\n",
      "Epoch:  0070 D loss:-0.5644 G loss:-2.39\n",
      "Epoch:  0070 D loss:-0.6732 G loss:-2.172\n",
      "Epoch:  0070 D loss:-0.5508 G loss:-2.21\n",
      "Epoch:  0070 D loss:-0.5077 G loss:-2.334\n",
      "Epoch:  0070 D loss:-0.8798 G loss:-1.943\n",
      "Epoch:  0070 D loss:-0.7101 G loss:-2.136\n",
      "Epoch:  0070 D loss:-0.7432 G loss:-1.832\n",
      "Epoch:  0070 D loss:-0.5588 G loss:-1.944\n",
      "Epoch:  0070 D loss:-0.7076 G loss:-1.84\n",
      "Epoch:  0070 D loss:-0.7131 G loss:-2.005\n",
      "Epoch:  0070 D loss:-0.674 G loss:-1.943\n",
      "Epoch:  0070 D loss:-0.7652 G loss:-1.883\n",
      "Epoch:  0070 D loss:-0.7452 G loss:-1.946\n",
      "Epoch:  0070 D loss:-0.7386 G loss:-2.02\n",
      "Epoch:  0070 D loss:-0.8113 G loss:-2.013\n",
      "Epoch:  0070 D loss:-0.6701 G loss:-2.253\n",
      "Epoch:  0070 D loss:-0.5774 G loss:-2.21\n",
      "Epoch:  0070 D loss:-0.5405 G loss:-2.236\n",
      "Epoch:  0070 D loss:-1.0 G loss:-1.751\n",
      "Epoch:  0070 D loss:-0.7576 G loss:-2.189\n",
      "Epoch:  0070 D loss:-0.6594 G loss:-2.063\n",
      "Epoch:  0070 D loss:-0.7005 G loss:-2.024\n",
      "Epoch:  0070 D loss:-0.6924 G loss:-2.133\n",
      "Epoch:  0070 D loss:-0.6439 G loss:-2.039\n",
      "Epoch:  0070 D loss:-0.6997 G loss:-1.814\n",
      "Epoch:  0070 D loss:-0.6557 G loss:-1.936\n",
      "Epoch:  0070 D loss:-0.8116 G loss:-1.808\n",
      "Epoch:  0070 D loss:-0.8086 G loss:-1.821\n",
      "Epoch:  0070 D loss:-0.6849 G loss:-1.914\n",
      "Epoch:  0070 D loss:-0.7077 G loss:-1.938\n",
      "Epoch:  0070 D loss:-0.6396 G loss:-1.72\n",
      "Epoch:  0070 D loss:-0.7032 G loss:-1.926\n",
      "Epoch:  0070 D loss:-0.697 G loss:-1.845\n",
      "Epoch:  0070 D loss:-0.6933 G loss:-1.954\n",
      "Epoch:  0070 D loss:-0.7347 G loss:-2.214\n",
      "Epoch:  0070 D loss:-0.8207 G loss:-2.117\n",
      "Epoch:  0070 D loss:-0.6063 G loss:-2.046\n",
      "Epoch:  0070 D loss:-0.578 G loss:-2.236\n",
      "Epoch:  0070 D loss:-0.6456 G loss:-2.082\n",
      "Epoch:  0070 D loss:-0.7867 G loss:-1.928\n",
      "Epoch:  0070 D loss:-0.6746 G loss:-2.06\n",
      "Epoch:  0070 D loss:-0.672 G loss:-1.884\n",
      "Epoch:  0070 D loss:-0.7114 G loss:-1.726\n",
      "Epoch:  0070 D loss:-0.725 G loss:-2.002\n",
      "Epoch:  0070 D loss:-0.7329 G loss:-1.782\n",
      "Epoch:  0070 D loss:-0.5568 G loss:-2.169\n",
      "Epoch:  0070 D loss:-0.6828 G loss:-1.993\n",
      "Epoch:  0070 D loss:-0.6757 G loss:-1.997\n",
      "Epoch:  0070 D loss:-0.7544 G loss:-2.024\n",
      "Epoch:  0070 D loss:-0.6779 G loss:-2.168\n",
      "Epoch:  0070 D loss:-0.7563 G loss:-2.059\n",
      "Epoch:  0070 D loss:-0.5774 G loss:-2.273\n",
      "Epoch:  0070 D loss:-0.5987 G loss:-2.249\n",
      "Epoch:  0070 D loss:-0.6948 G loss:-2.173\n",
      "Epoch:  0070 D loss:-0.7042 G loss:-2.178\n",
      "Epoch:  0070 D loss:-0.6397 G loss:-2.308\n",
      "Epoch:  0070 D loss:-0.6096 G loss:-2.162\n",
      "Epoch:  0070 D loss:-0.7815 G loss:-2.086\n",
      "Epoch:  0070 D loss:-0.6502 G loss:-2.109\n",
      "Epoch:  0070 D loss:-0.6913 G loss:-2.065\n",
      "Epoch:  0070 D loss:-0.5936 G loss:-2.036\n",
      "Epoch:  0070 D loss:-0.62 G loss:-2.118\n",
      "Epoch:  0070 D loss:-0.7709 G loss:-1.987\n",
      "Epoch:  0070 D loss:-0.6742 G loss:-1.908\n",
      "Epoch:  0070 D loss:-0.6943 G loss:-2.027\n",
      "Epoch:  0070 D loss:-0.766 G loss:-1.877\n",
      "Epoch:  0070 D loss:-0.5856 G loss:-2.109\n",
      "Epoch:  0070 D loss:-0.802 G loss:-2.057\n",
      "Epoch:  0070 D loss:-0.6879 G loss:-2.129\n",
      "Epoch:  0070 D loss:-0.7543 G loss:-1.99\n",
      "Epoch:  0070 D loss:-0.7307 G loss:-2.056\n",
      "Epoch:  0070 D loss:-0.7446 G loss:-2.108\n",
      "Epoch:  0070 D loss:-0.7022 G loss:-2.166\n",
      "Epoch:  0070 D loss:-0.7877 G loss:-2.016\n",
      "Epoch:  0070 D loss:-0.7963 G loss:-1.949\n",
      "Epoch:  0070 D loss:-0.614 G loss:-2.069\n",
      "Epoch:  0070 D loss:-0.709 G loss:-1.867\n",
      "Epoch:  0070 D loss:-0.6952 G loss:-1.928\n",
      "Epoch:  0070 D loss:-0.5851 G loss:-2.106\n",
      "Epoch:  0070 D loss:-0.8321 G loss:-2.071\n",
      "Epoch:  0070 D loss:-0.6298 G loss:-1.972\n",
      "Epoch:  0070 D loss:-0.5966 G loss:-2.168\n",
      "Epoch:  0070 D loss:-0.5661 G loss:-2.127\n",
      "Epoch:  0070 D loss:-0.7026 G loss:-2.127\n",
      "Epoch:  0070 D loss:-0.6864 G loss:-1.948\n",
      "Epoch:  0070 D loss:-0.6609 G loss:-1.751\n",
      "Epoch:  0070 D loss:-0.6542 G loss:-1.813\n",
      "Epoch:  0070 D loss:-0.7318 G loss:-1.949\n",
      "Epoch:  0070 D loss:-0.8058 G loss:-2.187\n",
      "Epoch:  0070 D loss:-0.9019 G loss:-2.142\n",
      "Epoch:  0070 D loss:-0.6574 G loss:-2.047\n",
      "Epoch:  0070 D loss:-0.7844 G loss:-1.955\n",
      "Epoch:  0070 D loss:-0.7175 G loss:-1.983\n",
      "Epoch:  0070 D loss:-0.6175 G loss:-2.095\n",
      "Epoch:  0070 D loss:-0.7949 G loss:-2.033\n",
      "Epoch:  0070 D loss:-0.6532 G loss:-1.695\n",
      "Epoch:  0070 D loss:-0.7955 G loss:-1.857\n",
      "Epoch:  0070 D loss:-0.6616 G loss:-1.827\n",
      "Epoch:  0070 D loss:-0.66 G loss:-2.065\n",
      "Epoch:  0070 D loss:-0.6265 G loss:-1.916\n",
      "Epoch:  0070 D loss:-0.7443 G loss:-2.084\n",
      "Epoch:  0070 D loss:-0.7376 G loss:-2.03\n",
      "Epoch:  0070 D loss:-0.7079 G loss:-2.296\n",
      "Epoch:  0070 D loss:-0.6869 G loss:-2.027\n",
      "Epoch:  0070 D loss:-0.7884 G loss:-2.01\n",
      "Epoch:  0070 D loss:-0.5922 G loss:-2.229\n",
      "Epoch:  0070 D loss:-0.8514 G loss:-1.835\n",
      "Epoch:  0070 D loss:-0.7983 G loss:-1.982\n",
      "Epoch:  0070 D loss:-0.5498 G loss:-2.108\n",
      "Epoch:  0070 D loss:-0.6597 G loss:-2.096\n",
      "Epoch:  0070 D loss:-0.7705 G loss:-1.996\n",
      "Epoch:  0070 D loss:-0.7446 G loss:-1.949\n",
      "Epoch:  0070 D loss:-0.5955 G loss:-1.994\n",
      "Epoch:  0070 D loss:-0.6301 G loss:-2.218\n",
      "Epoch:  0070 D loss:-0.7714 G loss:-2.01\n",
      "Epoch:  0070 D loss:-0.6364 G loss:-2.104\n",
      "Epoch:  0070 D loss:-0.7021 G loss:-1.769\n",
      "Epoch:  0070 D loss:-0.8491 G loss:-1.886\n",
      "Epoch:  0070 D loss:-0.8474 G loss:-1.886\n",
      "Epoch:  0070 D loss:-0.662 G loss:-1.959\n",
      "Epoch:  0070 D loss:-0.9551 G loss:-1.839\n",
      "Epoch:  0070 D loss:-0.6702 G loss:-1.996\n",
      "Epoch:  0070 D loss:-0.838 G loss:-1.914\n",
      "Epoch:  0070 D loss:-0.7024 G loss:-1.9\n",
      "Epoch:  0070 D loss:-0.6205 G loss:-2.12\n",
      "Epoch:  0070 D loss:-0.8288 G loss:-1.911\n",
      "Epoch:  0070 D loss:-0.7277 G loss:-1.976\n",
      "Epoch:  0070 D loss:-0.7602 G loss:-1.965\n",
      "Epoch:  0070 D loss:-0.7541 G loss:-2.0\n",
      "Epoch:  0070 D loss:-0.6935 G loss:-2.247\n",
      "Epoch:  0070 D loss:-0.5461 G loss:-2.345\n",
      "Epoch:  0070 D loss:-0.7062 G loss:-2.128\n",
      "Epoch:  0070 D loss:-0.769 G loss:-1.883\n",
      "Epoch:  0070 D loss:-0.6583 G loss:-2.05\n",
      "Epoch:  0070 D loss:-0.7234 G loss:-1.958\n",
      "Epoch:  0070 D loss:-0.8309 G loss:-2.016\n",
      "Epoch:  0070 D loss:-0.7657 G loss:-1.974\n",
      "Epoch:  0070 D loss:-0.9326 G loss:-1.945\n",
      "Epoch:  0070 D loss:-0.7946 G loss:-1.951\n",
      "Epoch:  0070 D loss:-0.7048 G loss:-2.004\n",
      "Epoch:  0070 D loss:-0.7278 G loss:-1.855\n",
      "Epoch:  0070 D loss:-0.8431 G loss:-1.982\n",
      "Epoch:  0070 D loss:-0.7932 G loss:-1.924\n",
      "Epoch:  0070 D loss:-0.8838 G loss:-1.91\n",
      "Epoch:  0070 D loss:-0.6376 G loss:-2.063\n",
      "Epoch:  0070 D loss:-0.6825 G loss:-1.939\n",
      "Epoch:  0070 D loss:-0.7438 G loss:-1.918\n",
      "Epoch:  0070 D loss:-0.8697 G loss:-1.933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0070 D loss:-0.61 G loss:-2.314\n",
      "Epoch:  0070 D loss:-0.7248 G loss:-2.403\n",
      "Epoch:  0070 D loss:-0.6066 G loss:-2.061\n",
      "Epoch:  0070 D loss:-0.7411 G loss:-2.001\n",
      "Epoch:  0070 D loss:-0.8346 G loss:-1.938\n",
      "Epoch:  0070 D loss:-0.7384 G loss:-2.233\n",
      "Epoch:  0070 D loss:-0.6898 G loss:-2.136\n",
      "Epoch:  0070 D loss:-0.6769 G loss:-1.909\n",
      "Epoch:  0070 D loss:-0.7776 G loss:-1.798\n",
      "Epoch:  0070 D loss:-0.7901 G loss:-1.85\n",
      "Epoch:  0070 D loss:-0.6704 G loss:-2.038\n",
      "Epoch:  0070 D loss:-0.6691 G loss:-1.942\n",
      "Epoch:  0070 D loss:-0.6355 G loss:-2.062\n",
      "Epoch:  0070 D loss:-0.6276 G loss:-2.193\n",
      "Epoch:  0070 D loss:-0.7282 G loss:-2.237\n",
      "Epoch:  0070 D loss:-0.8258 G loss:-2.097\n",
      "Epoch:  0070 D loss:-0.8708 G loss:-1.898\n",
      "Epoch:  0070 D loss:-0.6676 G loss:-2.006\n",
      "Epoch:  0070 D loss:-0.7367 G loss:-1.875\n",
      "Epoch:  0070 D loss:-0.6039 G loss:-2.294\n",
      "Epoch:  0070 D loss:-0.6202 G loss:-2.01\n",
      "Epoch:  0070 D loss:-0.6544 G loss:-2.227\n",
      "Epoch:  0070 D loss:-0.5013 G loss:-2.33\n",
      "Epoch:  0070 D loss:-0.6254 G loss:-2.41\n",
      "Epoch:  0070 D loss:-0.718 G loss:-2.016\n",
      "Epoch:  0070 D loss:-0.6617 G loss:-1.972\n",
      "Epoch:  0070 D loss:-0.9054 G loss:-2.183\n",
      "Epoch:  0070 D loss:-0.7392 G loss:-2.092\n",
      "Epoch:  0070 D loss:-0.6004 G loss:-2.205\n",
      "Epoch:  0070 D loss:-0.7493 G loss:-2.102\n",
      "Epoch:  0070 D loss:-0.694 G loss:-2.015\n",
      "Epoch:  0070 D loss:-0.7021 G loss:-2.03\n",
      "Epoch:  0070 D loss:-0.634 G loss:-2.099\n",
      "Epoch:  0070 D loss:-0.5993 G loss:-2.143\n",
      "Epoch:  0070 D loss:-0.7747 G loss:-1.69\n",
      "Epoch:  0070 D loss:-0.6642 G loss:-2.071\n",
      "Epoch:  0070 D loss:-0.7039 G loss:-2.046\n",
      "Epoch:  0070 D loss:-0.7027 G loss:-1.982\n",
      "Epoch:  0070 D loss:-0.6468 G loss:-2.16\n",
      "Epoch:  0070 D loss:-0.5211 G loss:-2.221\n",
      "Epoch:  0070 D loss:-0.8213 G loss:-2.081\n",
      "Epoch:  0070 D loss:-0.7325 G loss:-2.15\n",
      "Epoch:  0070 D loss:-0.6695 G loss:-2.084\n",
      "Epoch:  0070 D loss:-0.6651 G loss:-2.104\n",
      "Epoch:  0070 D loss:-0.6655 G loss:-1.962\n",
      "Epoch:  0070 D loss:-0.6658 G loss:-1.92\n",
      "Epoch:  0070 D loss:-0.5377 G loss:-1.911\n",
      "Epoch:  0070 D loss:-0.5308 G loss:-2.013\n",
      "Epoch:  0070 D loss:-0.6699 G loss:-2.095\n",
      "Epoch:  0070 D loss:-0.6033 G loss:-2.077\n",
      "Epoch:  0070 D loss:-0.6882 G loss:-2.181\n",
      "Epoch:  0070 D loss:-0.6738 G loss:-2.219\n",
      "Epoch:  0070 D loss:-0.609 G loss:-2.181\n",
      "Epoch:  0070 D loss:-0.5985 G loss:-2.355\n",
      "Epoch:  0070 D loss:-0.6656 G loss:-2.03\n",
      "Epoch:  0070 D loss:-0.732 G loss:-2.255\n",
      "Epoch:  0070 D loss:-0.8473 G loss:-2.263\n",
      "Epoch:  0070 D loss:-0.6192 G loss:-2.142\n",
      "Epoch:  0070 D loss:-0.7081 G loss:-2.111\n",
      "Epoch:  0070 D loss:-0.6878 G loss:-2.07\n",
      "Epoch:  0070 D loss:-0.7855 G loss:-2.05\n",
      "Epoch:  0070 D loss:-0.7963 G loss:-2.026\n",
      "Epoch:  0070 D loss:-0.6549 G loss:-2.016\n",
      "Epoch:  0070 D loss:-0.6902 G loss:-1.998\n",
      "Epoch:  0070 D loss:-0.7291 G loss:-1.734\n",
      "Epoch:  0070 D loss:-0.6593 G loss:-1.902\n",
      "Epoch:  0070 D loss:-0.7484 G loss:-1.888\n",
      "Epoch:  0070 D loss:-0.6207 G loss:-2.149\n",
      "Epoch:  0070 D loss:-0.6577 G loss:-2.402\n",
      "Epoch:  0070 D loss:-0.7337 G loss:-2.286\n",
      "Epoch:  0070 D loss:-0.5744 G loss:-2.293\n",
      "Epoch:  0070 D loss:-0.6649 G loss:-2.187\n",
      "Epoch:  0070 D loss:-0.7009 G loss:-2.109\n",
      "Epoch:  0070 D loss:-0.6216 G loss:-2.144\n",
      "Epoch:  0070 D loss:-0.6178 G loss:-2.112\n",
      "Epoch:  0070 D loss:-0.6292 G loss:-2.119\n",
      "Epoch:  0070 D loss:-0.6849 G loss:-2.125\n",
      "Epoch:  0070 D loss:-0.6563 G loss:-1.92\n",
      "Epoch:  0070 D loss:-0.5822 G loss:-2.124\n",
      "Epoch:  0070 D loss:-0.7135 G loss:-1.974\n",
      "Epoch:  0070 D loss:-0.6934 G loss:-2.12\n",
      "Epoch:  0070 D loss:-0.7157 G loss:-1.991\n",
      "Epoch:  0070 D loss:-0.7019 G loss:-1.959\n",
      "Epoch:  0070 D loss:-0.6383 G loss:-1.979\n",
      "Epoch:  0070 D loss:-0.7009 G loss:-2.127\n",
      "Epoch:  0070 D loss:-0.7109 G loss:-1.719\n",
      "Epoch:  0070 D loss:-0.6661 G loss:-2.126\n",
      "Epoch:  0070 D loss:-0.7302 G loss:-1.953\n",
      "Epoch:  0071 D loss:-0.5686 G loss:-2.002\n",
      "Epoch:  0071 D loss:-0.7653 G loss:-2.041\n",
      "Epoch:  0071 D loss:-0.6779 G loss:-2.045\n",
      "Epoch:  0071 D loss:-0.7861 G loss:-2.193\n",
      "Epoch:  0071 D loss:-0.7397 G loss:-2.142\n",
      "Epoch:  0071 D loss:-0.6724 G loss:-2.194\n",
      "Epoch:  0071 D loss:-0.6363 G loss:-2.051\n",
      "Epoch:  0071 D loss:-0.6591 G loss:-2.246\n",
      "Epoch:  0071 D loss:-0.5359 G loss:-2.113\n",
      "Epoch:  0071 D loss:-0.6965 G loss:-1.851\n",
      "Epoch:  0071 D loss:-0.6892 G loss:-2.003\n",
      "Epoch:  0071 D loss:-0.7464 G loss:-2.137\n",
      "Epoch:  0071 D loss:-0.7348 G loss:-1.946\n",
      "Epoch:  0071 D loss:-0.5915 G loss:-2.039\n",
      "Epoch:  0071 D loss:-0.6259 G loss:-2.072\n",
      "Epoch:  0071 D loss:-0.6443 G loss:-1.966\n",
      "Epoch:  0071 D loss:-0.6303 G loss:-2.05\n",
      "Epoch:  0071 D loss:-0.6477 G loss:-1.776\n",
      "Epoch:  0071 D loss:-0.6054 G loss:-2.014\n",
      "Epoch:  0071 D loss:-0.6254 G loss:-2.211\n",
      "Epoch:  0071 D loss:-0.6409 G loss:-2.082\n",
      "Epoch:  0071 D loss:-0.6607 G loss:-2.013\n",
      "Epoch:  0071 D loss:-0.7469 G loss:-2.211\n",
      "Epoch:  0071 D loss:-0.7724 G loss:-1.881\n",
      "Epoch:  0071 D loss:-0.6584 G loss:-2.121\n",
      "Epoch:  0071 D loss:-0.7908 G loss:-1.859\n",
      "Epoch:  0071 D loss:-0.7741 G loss:-1.794\n",
      "Epoch:  0071 D loss:-0.8671 G loss:-1.712\n",
      "Epoch:  0071 D loss:-0.7805 G loss:-1.843\n",
      "Epoch:  0071 D loss:-0.7478 G loss:-1.852\n",
      "Epoch:  0071 D loss:-0.6507 G loss:-2.076\n",
      "Epoch:  0071 D loss:-0.6389 G loss:-2.081\n",
      "Epoch:  0071 D loss:-0.6621 G loss:-2.017\n",
      "Epoch:  0071 D loss:-0.8186 G loss:-1.958\n",
      "Epoch:  0071 D loss:-0.6691 G loss:-2.064\n",
      "Epoch:  0071 D loss:-0.5942 G loss:-2.059\n",
      "Epoch:  0071 D loss:-0.6562 G loss:-2.04\n",
      "Epoch:  0071 D loss:-0.8108 G loss:-1.874\n",
      "Epoch:  0071 D loss:-0.7625 G loss:-2.032\n",
      "Epoch:  0071 D loss:-0.5602 G loss:-2.106\n",
      "Epoch:  0071 D loss:-0.8146 G loss:-1.671\n",
      "Epoch:  0071 D loss:-0.857 G loss:-1.848\n",
      "Epoch:  0071 D loss:-0.7901 G loss:-1.821\n",
      "Epoch:  0071 D loss:-0.684 G loss:-1.763\n",
      "Epoch:  0071 D loss:-0.9029 G loss:-1.862\n",
      "Epoch:  0071 D loss:-0.6886 G loss:-1.942\n",
      "Epoch:  0071 D loss:-0.7289 G loss:-1.766\n",
      "Epoch:  0071 D loss:-0.6872 G loss:-1.839\n",
      "Epoch:  0071 D loss:-0.8875 G loss:-1.725\n",
      "Epoch:  0071 D loss:-0.7028 G loss:-1.878\n",
      "Epoch:  0071 D loss:-0.7785 G loss:-1.92\n",
      "Epoch:  0071 D loss:-0.6716 G loss:-1.85\n",
      "Epoch:  0071 D loss:-0.7377 G loss:-2.097\n",
      "Epoch:  0071 D loss:-0.769 G loss:-2.023\n",
      "Epoch:  0071 D loss:-0.6544 G loss:-2.039\n",
      "Epoch:  0071 D loss:-0.58 G loss:-2.182\n",
      "Epoch:  0071 D loss:-0.8061 G loss:-2.03\n",
      "Epoch:  0071 D loss:-0.848 G loss:-1.874\n",
      "Epoch:  0071 D loss:-0.6634 G loss:-2.121\n",
      "Epoch:  0071 D loss:-0.7057 G loss:-1.889\n",
      "Epoch:  0071 D loss:-0.6773 G loss:-2.122\n",
      "Epoch:  0071 D loss:-0.7177 G loss:-2.013\n",
      "Epoch:  0071 D loss:-0.8033 G loss:-2.104\n",
      "Epoch:  0071 D loss:-0.6468 G loss:-1.837\n",
      "Epoch:  0071 D loss:-0.7568 G loss:-1.766\n",
      "Epoch:  0071 D loss:-0.8107 G loss:-1.74\n",
      "Epoch:  0071 D loss:-0.7343 G loss:-1.784\n",
      "Epoch:  0071 D loss:-0.7323 G loss:-1.882\n",
      "Epoch:  0071 D loss:-0.7155 G loss:-1.919\n",
      "Epoch:  0071 D loss:-0.8069 G loss:-1.785\n",
      "Epoch:  0071 D loss:-0.821 G loss:-1.8\n",
      "Epoch:  0071 D loss:-0.7367 G loss:-2.102\n",
      "Epoch:  0071 D loss:-0.6503 G loss:-2.133\n",
      "Epoch:  0071 D loss:-0.7888 G loss:-1.997\n",
      "Epoch:  0071 D loss:-0.6984 G loss:-1.93\n",
      "Epoch:  0071 D loss:-0.6798 G loss:-2.107\n",
      "Epoch:  0071 D loss:-0.6186 G loss:-2.098\n",
      "Epoch:  0071 D loss:-0.6497 G loss:-1.974\n",
      "Epoch:  0071 D loss:-0.7638 G loss:-1.96\n",
      "Epoch:  0071 D loss:-0.6399 G loss:-2.094\n",
      "Epoch:  0071 D loss:-0.7689 G loss:-1.926\n",
      "Epoch:  0071 D loss:-0.7441 G loss:-1.916\n",
      "Epoch:  0071 D loss:-0.6838 G loss:-2.02\n",
      "Epoch:  0071 D loss:-0.8401 G loss:-1.902\n",
      "Epoch:  0071 D loss:-0.6652 G loss:-1.961\n",
      "Epoch:  0071 D loss:-0.6537 G loss:-1.901\n",
      "Epoch:  0071 D loss:-0.6771 G loss:-1.956\n",
      "Epoch:  0071 D loss:-0.6474 G loss:-1.97\n",
      "Epoch:  0071 D loss:-0.7544 G loss:-1.931\n",
      "Epoch:  0071 D loss:-0.7119 G loss:-1.911\n",
      "Epoch:  0071 D loss:-0.6759 G loss:-2.175\n",
      "Epoch:  0071 D loss:-0.6448 G loss:-2.266\n",
      "Epoch:  0071 D loss:-0.5869 G loss:-2.465\n",
      "Epoch:  0071 D loss:-0.8247 G loss:-2.253\n",
      "Epoch:  0071 D loss:-0.7442 G loss:-1.976\n",
      "Epoch:  0071 D loss:-0.5916 G loss:-2.242\n",
      "Epoch:  0071 D loss:-0.8613 G loss:-1.754\n",
      "Epoch:  0071 D loss:-0.7506 G loss:-1.933\n",
      "Epoch:  0071 D loss:-0.7837 G loss:-1.834\n",
      "Epoch:  0071 D loss:-0.5763 G loss:-2.021\n",
      "Epoch:  0071 D loss:-0.7477 G loss:-1.935\n",
      "Epoch:  0071 D loss:-0.7808 G loss:-1.81\n",
      "Epoch:  0071 D loss:-0.6889 G loss:-1.926\n",
      "Epoch:  0071 D loss:-0.7447 G loss:-1.821\n",
      "Epoch:  0071 D loss:-0.6339 G loss:-2.051\n",
      "Epoch:  0071 D loss:-0.773 G loss:-2.007\n",
      "Epoch:  0071 D loss:-0.9077 G loss:-1.997\n",
      "Epoch:  0071 D loss:-0.7502 G loss:-1.979\n",
      "Epoch:  0071 D loss:-0.664 G loss:-1.948\n",
      "Epoch:  0071 D loss:-0.5956 G loss:-2.098\n",
      "Epoch:  0071 D loss:-0.7991 G loss:-1.801\n",
      "Epoch:  0071 D loss:-0.8135 G loss:-1.9\n",
      "Epoch:  0071 D loss:-0.6506 G loss:-2.169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0071 D loss:-0.6509 G loss:-2.151\n",
      "Epoch:  0071 D loss:-0.721 G loss:-2.053\n",
      "Epoch:  0071 D loss:-0.749 G loss:-2.109\n",
      "Epoch:  0071 D loss:-0.6289 G loss:-2.002\n",
      "Epoch:  0071 D loss:-0.7472 G loss:-2.262\n",
      "Epoch:  0071 D loss:-0.7929 G loss:-2.04\n",
      "Epoch:  0071 D loss:-0.7074 G loss:-1.831\n",
      "Epoch:  0071 D loss:-0.8405 G loss:-1.872\n",
      "Epoch:  0071 D loss:-0.6985 G loss:-1.956\n",
      "Epoch:  0071 D loss:-0.767 G loss:-1.802\n",
      "Epoch:  0071 D loss:-0.7997 G loss:-2.031\n",
      "Epoch:  0071 D loss:-0.6954 G loss:-2.26\n",
      "Epoch:  0071 D loss:-0.823 G loss:-2.17\n",
      "Epoch:  0071 D loss:-0.8267 G loss:-2.058\n",
      "Epoch:  0071 D loss:-0.8098 G loss:-1.935\n",
      "Epoch:  0071 D loss:-0.6771 G loss:-1.892\n",
      "Epoch:  0071 D loss:-0.7536 G loss:-1.984\n",
      "Epoch:  0071 D loss:-0.6677 G loss:-1.873\n",
      "Epoch:  0071 D loss:-0.6812 G loss:-1.708\n",
      "Epoch:  0071 D loss:-0.7303 G loss:-1.665\n",
      "Epoch:  0071 D loss:-0.7039 G loss:-1.874\n",
      "Epoch:  0071 D loss:-0.6271 G loss:-1.836\n",
      "Epoch:  0071 D loss:-0.7397 G loss:-2.148\n",
      "Epoch:  0071 D loss:-0.6527 G loss:-2.156\n",
      "Epoch:  0071 D loss:-0.655 G loss:-2.124\n",
      "Epoch:  0071 D loss:-0.6966 G loss:-2.145\n",
      "Epoch:  0071 D loss:-0.7699 G loss:-2.212\n",
      "Epoch:  0071 D loss:-0.897 G loss:-2.248\n",
      "Epoch:  0071 D loss:-0.7217 G loss:-2.179\n",
      "Epoch:  0071 D loss:-0.6944 G loss:-1.921\n",
      "Epoch:  0071 D loss:-0.6791 G loss:-2.138\n",
      "Epoch:  0071 D loss:-0.7406 G loss:-1.919\n",
      "Epoch:  0071 D loss:-0.7036 G loss:-1.933\n",
      "Epoch:  0071 D loss:-0.6806 G loss:-1.751\n",
      "Epoch:  0071 D loss:-0.5856 G loss:-1.929\n",
      "Epoch:  0071 D loss:-0.6278 G loss:-1.96\n",
      "Epoch:  0071 D loss:-0.6899 G loss:-1.855\n",
      "Epoch:  0071 D loss:-0.7135 G loss:-1.939\n",
      "Epoch:  0071 D loss:-0.6838 G loss:-1.899\n",
      "Epoch:  0071 D loss:-0.6884 G loss:-2.038\n",
      "Epoch:  0071 D loss:-0.6565 G loss:-2.162\n",
      "Epoch:  0071 D loss:-0.6716 G loss:-2.181\n",
      "Epoch:  0071 D loss:-0.666 G loss:-2.258\n",
      "Epoch:  0071 D loss:-0.6545 G loss:-2.246\n",
      "Epoch:  0071 D loss:-0.6501 G loss:-2.201\n",
      "Epoch:  0071 D loss:-0.4964 G loss:-2.406\n",
      "Epoch:  0071 D loss:-0.7138 G loss:-2.116\n",
      "Epoch:  0071 D loss:-0.6003 G loss:-2.281\n",
      "Epoch:  0071 D loss:-0.7123 G loss:-2.149\n",
      "Epoch:  0071 D loss:-0.8208 G loss:-2.144\n",
      "Epoch:  0071 D loss:-0.7201 G loss:-2.087\n",
      "Epoch:  0071 D loss:-0.6911 G loss:-2.062\n",
      "Epoch:  0071 D loss:-0.6671 G loss:-1.949\n",
      "Epoch:  0071 D loss:-0.7846 G loss:-1.737\n",
      "Epoch:  0071 D loss:-0.6623 G loss:-1.893\n",
      "Epoch:  0071 D loss:-0.8332 G loss:-1.771\n",
      "Epoch:  0071 D loss:-0.6367 G loss:-1.992\n",
      "Epoch:  0071 D loss:-0.6463 G loss:-2.03\n",
      "Epoch:  0071 D loss:-0.5565 G loss:-2.105\n",
      "Epoch:  0071 D loss:-0.6485 G loss:-2.364\n",
      "Epoch:  0071 D loss:-0.6231 G loss:-2.054\n",
      "Epoch:  0071 D loss:-0.6789 G loss:-2.043\n",
      "Epoch:  0071 D loss:-0.6049 G loss:-2.203\n",
      "Epoch:  0071 D loss:-0.6382 G loss:-2.14\n",
      "Epoch:  0071 D loss:-0.5471 G loss:-2.178\n",
      "Epoch:  0071 D loss:-0.7135 G loss:-1.958\n",
      "Epoch:  0071 D loss:-0.6618 G loss:-2.01\n",
      "Epoch:  0071 D loss:-0.633 G loss:-2.008\n",
      "Epoch:  0071 D loss:-0.6491 G loss:-1.972\n",
      "Epoch:  0071 D loss:-0.6414 G loss:-1.98\n",
      "Epoch:  0071 D loss:-0.6745 G loss:-2.038\n",
      "Epoch:  0071 D loss:-0.7216 G loss:-2.065\n",
      "Epoch:  0071 D loss:-0.7053 G loss:-2.026\n",
      "Epoch:  0071 D loss:-0.5953 G loss:-2.116\n",
      "Epoch:  0071 D loss:-0.6014 G loss:-2.242\n",
      "Epoch:  0071 D loss:-0.5662 G loss:-2.248\n",
      "Epoch:  0071 D loss:-0.7152 G loss:-2.137\n",
      "Epoch:  0071 D loss:-0.7608 G loss:-2.035\n",
      "Epoch:  0071 D loss:-0.7633 G loss:-2.203\n",
      "Epoch:  0071 D loss:-0.6384 G loss:-2.062\n",
      "Epoch:  0071 D loss:-0.6946 G loss:-2.14\n",
      "Epoch:  0071 D loss:-0.5992 G loss:-2.112\n",
      "Epoch:  0071 D loss:-0.5395 G loss:-2.274\n",
      "Epoch:  0071 D loss:-0.6454 G loss:-1.994\n",
      "Epoch:  0071 D loss:-0.6016 G loss:-2.112\n",
      "Epoch:  0071 D loss:-0.6913 G loss:-1.997\n",
      "Epoch:  0071 D loss:-0.6667 G loss:-2.136\n",
      "Epoch:  0071 D loss:-0.6798 G loss:-2.003\n",
      "Epoch:  0071 D loss:-0.5822 G loss:-2.181\n",
      "Epoch:  0071 D loss:-0.6977 G loss:-2.061\n",
      "Epoch:  0071 D loss:-0.6388 G loss:-2.263\n",
      "Epoch:  0071 D loss:-0.6822 G loss:-2.096\n",
      "Epoch:  0071 D loss:-0.6615 G loss:-1.964\n",
      "Epoch:  0071 D loss:-0.6405 G loss:-2.127\n",
      "Epoch:  0071 D loss:-0.6555 G loss:-2.184\n",
      "Epoch:  0071 D loss:-0.7133 G loss:-2.074\n",
      "Epoch:  0071 D loss:-0.7876 G loss:-1.904\n",
      "Epoch:  0071 D loss:-0.6839 G loss:-2.08\n",
      "Epoch:  0071 D loss:-0.6554 G loss:-2.027\n",
      "Epoch:  0071 D loss:-0.7776 G loss:-1.879\n",
      "Epoch:  0071 D loss:-0.6961 G loss:-2.039\n",
      "Epoch:  0071 D loss:-0.7106 G loss:-1.973\n",
      "Epoch:  0071 D loss:-0.6005 G loss:-2.197\n",
      "Epoch:  0071 D loss:-0.811 G loss:-2.151\n",
      "Epoch:  0071 D loss:-0.5956 G loss:-2.295\n",
      "Epoch:  0071 D loss:-0.55 G loss:-2.108\n",
      "Epoch:  0071 D loss:-0.624 G loss:-2.037\n",
      "Epoch:  0071 D loss:-0.6628 G loss:-2.306\n",
      "Epoch:  0071 D loss:-0.7701 G loss:-2.119\n",
      "Epoch:  0071 D loss:-0.7981 G loss:-2.058\n",
      "Epoch:  0071 D loss:-0.7258 G loss:-2.138\n",
      "Epoch:  0071 D loss:-0.6821 G loss:-1.935\n",
      "Epoch:  0071 D loss:-0.6787 G loss:-2.107\n",
      "Epoch:  0071 D loss:-0.6762 G loss:-1.971\n",
      "Epoch:  0071 D loss:-0.8291 G loss:-1.833\n",
      "Epoch:  0071 D loss:-0.7867 G loss:-2.114\n",
      "Epoch:  0071 D loss:-0.7845 G loss:-1.949\n",
      "Epoch:  0071 D loss:-0.6131 G loss:-2.024\n",
      "Epoch:  0071 D loss:-0.6373 G loss:-2.068\n",
      "Epoch:  0071 D loss:-0.7057 G loss:-2.116\n",
      "Epoch:  0071 D loss:-0.7959 G loss:-2.062\n",
      "Epoch:  0071 D loss:-0.7354 G loss:-2.147\n",
      "Epoch:  0071 D loss:-0.7287 G loss:-2.166\n",
      "Epoch:  0071 D loss:-0.6808 G loss:-2.149\n",
      "Epoch:  0071 D loss:-0.7263 G loss:-2.115\n",
      "Epoch:  0071 D loss:-0.7839 G loss:-1.978\n",
      "Epoch:  0071 D loss:-0.5871 G loss:-2.025\n",
      "Epoch:  0071 D loss:-0.6643 G loss:-1.886\n",
      "Epoch:  0071 D loss:-0.7093 G loss:-1.872\n",
      "Epoch:  0071 D loss:-0.778 G loss:-1.84\n",
      "Epoch:  0071 D loss:-0.8053 G loss:-1.752\n",
      "Epoch:  0071 D loss:-0.7038 G loss:-1.771\n",
      "Epoch:  0071 D loss:-0.7449 G loss:-2.052\n",
      "Epoch:  0071 D loss:-0.7024 G loss:-2.083\n",
      "Epoch:  0071 D loss:-0.6895 G loss:-2.254\n",
      "Epoch:  0071 D loss:-0.9316 G loss:-1.901\n",
      "Epoch:  0071 D loss:-0.4935 G loss:-2.197\n",
      "Epoch:  0071 D loss:-0.803 G loss:-1.939\n",
      "Epoch:  0071 D loss:-0.7643 G loss:-2.106\n",
      "Epoch:  0071 D loss:-0.7198 G loss:-2.254\n",
      "Epoch:  0071 D loss:-0.7774 G loss:-2.105\n",
      "Epoch:  0071 D loss:-0.6753 G loss:-2.021\n",
      "Epoch:  0071 D loss:-0.7516 G loss:-1.903\n",
      "Epoch:  0071 D loss:-0.9082 G loss:-1.894\n",
      "Epoch:  0071 D loss:-0.6659 G loss:-2.005\n",
      "Epoch:  0071 D loss:-0.8369 G loss:-2.066\n",
      "Epoch:  0071 D loss:-0.761 G loss:-1.894\n",
      "Epoch:  0071 D loss:-0.8727 G loss:-1.724\n",
      "Epoch:  0071 D loss:-0.8011 G loss:-1.786\n",
      "Epoch:  0071 D loss:-0.8089 G loss:-1.993\n",
      "Epoch:  0071 D loss:-0.779 G loss:-2.048\n",
      "Epoch:  0071 D loss:-0.8934 G loss:-1.9\n",
      "Epoch:  0071 D loss:-0.8308 G loss:-1.945\n",
      "Epoch:  0071 D loss:-0.7552 G loss:-1.855\n",
      "Epoch:  0071 D loss:-0.6039 G loss:-2.091\n",
      "Epoch:  0071 D loss:-0.6024 G loss:-2.149\n",
      "Epoch:  0071 D loss:-0.701 G loss:-2.057\n",
      "Epoch:  0071 D loss:-0.7994 G loss:-2.172\n",
      "Epoch:  0071 D loss:-0.8069 G loss:-2.201\n",
      "Epoch:  0071 D loss:-0.7756 G loss:-2.015\n",
      "Epoch:  0071 D loss:-0.7075 G loss:-1.992\n",
      "Epoch:  0071 D loss:-0.5937 G loss:-1.893\n",
      "Epoch:  0071 D loss:-0.7331 G loss:-1.804\n",
      "Epoch:  0071 D loss:-0.7674 G loss:-1.871\n",
      "Epoch:  0071 D loss:-0.658 G loss:-1.962\n",
      "Epoch:  0071 D loss:-0.7293 G loss:-1.997\n",
      "Epoch:  0071 D loss:-0.6768 G loss:-2.017\n",
      "Epoch:  0071 D loss:-0.791 G loss:-1.982\n",
      "Epoch:  0071 D loss:-0.6501 G loss:-1.861\n",
      "Epoch:  0071 D loss:-0.6739 G loss:-2.034\n",
      "Epoch:  0071 D loss:-0.8068 G loss:-1.906\n",
      "Epoch:  0071 D loss:-0.7068 G loss:-1.974\n",
      "Epoch:  0071 D loss:-0.7099 G loss:-1.968\n",
      "Epoch:  0071 D loss:-0.7976 G loss:-2.087\n",
      "Epoch:  0071 D loss:-0.7202 G loss:-2.125\n",
      "Epoch:  0071 D loss:-0.8018 G loss:-1.891\n",
      "Epoch:  0071 D loss:-0.7674 G loss:-2.127\n",
      "Epoch:  0071 D loss:-0.7316 G loss:-2.069\n",
      "Epoch:  0071 D loss:-0.8384 G loss:-1.947\n",
      "Epoch:  0071 D loss:-0.7679 G loss:-1.838\n",
      "Epoch:  0071 D loss:-0.6267 G loss:-1.938\n",
      "Epoch:  0071 D loss:-0.7691 G loss:-2.031\n",
      "Epoch:  0071 D loss:-0.7137 G loss:-1.962\n",
      "Epoch:  0071 D loss:-0.6364 G loss:-1.769\n",
      "Epoch:  0071 D loss:-0.789 G loss:-1.832\n",
      "Epoch:  0071 D loss:-0.6821 G loss:-2.01\n",
      "Epoch:  0071 D loss:-0.6726 G loss:-2.127\n",
      "Epoch:  0071 D loss:-0.7053 G loss:-1.887\n",
      "Epoch:  0071 D loss:-0.75 G loss:-2.127\n",
      "Epoch:  0071 D loss:-0.6963 G loss:-1.983\n",
      "Epoch:  0071 D loss:-0.6342 G loss:-1.973\n",
      "Epoch:  0071 D loss:-0.7898 G loss:-1.768\n",
      "Epoch:  0071 D loss:-0.8472 G loss:-1.732\n",
      "Epoch:  0071 D loss:-0.8092 G loss:-1.947\n",
      "Epoch:  0071 D loss:-0.523 G loss:-2.16\n",
      "Epoch:  0071 D loss:-0.7799 G loss:-2.193\n",
      "Epoch:  0071 D loss:-0.6392 G loss:-2.051\n",
      "Epoch:  0071 D loss:-0.6864 G loss:-2.023\n",
      "Epoch:  0071 D loss:-0.5929 G loss:-1.934\n",
      "Epoch:  0071 D loss:-0.8085 G loss:-2.144\n",
      "Epoch:  0071 D loss:-0.5876 G loss:-2.177\n",
      "Epoch:  0071 D loss:-0.5795 G loss:-2.232\n",
      "Epoch:  0071 D loss:-0.5508 G loss:-2.273\n",
      "Epoch:  0071 D loss:-0.6993 G loss:-2.077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0071 D loss:-0.6726 G loss:-1.842\n",
      "Epoch:  0071 D loss:-0.7224 G loss:-2.071\n",
      "Epoch:  0071 D loss:-0.543 G loss:-2.18\n",
      "Epoch:  0071 D loss:-0.6265 G loss:-2.082\n",
      "Epoch:  0071 D loss:-0.6282 G loss:-2.134\n",
      "Epoch:  0071 D loss:-0.6492 G loss:-2.155\n",
      "Epoch:  0071 D loss:-0.6946 G loss:-2.007\n",
      "Epoch:  0071 D loss:-0.5911 G loss:-2.148\n",
      "Epoch:  0071 D loss:-0.7508 G loss:-1.983\n",
      "Epoch:  0071 D loss:-0.7357 G loss:-1.813\n",
      "Epoch:  0071 D loss:-0.7235 G loss:-2.099\n",
      "Epoch:  0071 D loss:-0.7384 G loss:-2.035\n",
      "Epoch:  0071 D loss:-0.6371 G loss:-1.943\n",
      "Epoch:  0071 D loss:-0.6547 G loss:-2.163\n",
      "Epoch:  0071 D loss:-0.614 G loss:-2.106\n",
      "Epoch:  0071 D loss:-0.5682 G loss:-2.246\n",
      "Epoch:  0071 D loss:-0.6052 G loss:-2.166\n",
      "Epoch:  0071 D loss:-0.6129 G loss:-2.132\n",
      "Epoch:  0071 D loss:-0.6099 G loss:-2.128\n",
      "Epoch:  0071 D loss:-0.6629 G loss:-2.167\n",
      "Epoch:  0071 D loss:-0.5725 G loss:-2.18\n",
      "Epoch:  0071 D loss:-0.5843 G loss:-2.26\n",
      "Epoch:  0071 D loss:-0.7471 G loss:-1.949\n",
      "Epoch:  0071 D loss:-0.6523 G loss:-2.317\n",
      "Epoch:  0071 D loss:-0.5625 G loss:-2.075\n",
      "Epoch:  0071 D loss:-0.6644 G loss:-2.086\n",
      "Epoch:  0071 D loss:-0.5823 G loss:-1.918\n",
      "Epoch:  0071 D loss:-0.8384 G loss:-2.062\n",
      "Epoch:  0071 D loss:-0.5756 G loss:-2.045\n",
      "Epoch:  0071 D loss:-0.6679 G loss:-1.957\n",
      "Epoch:  0071 D loss:-0.5455 G loss:-2.012\n",
      "Epoch:  0071 D loss:-0.6241 G loss:-1.827\n",
      "Epoch:  0071 D loss:-0.7212 G loss:-1.962\n",
      "Epoch:  0071 D loss:-0.614 G loss:-2.199\n",
      "Epoch:  0071 D loss:-0.7128 G loss:-2.115\n",
      "Epoch:  0071 D loss:-0.5438 G loss:-2.337\n",
      "Epoch:  0071 D loss:-0.6624 G loss:-2.403\n",
      "Epoch:  0071 D loss:-0.7009 G loss:-2.429\n",
      "Epoch:  0071 D loss:-0.6777 G loss:-2.392\n",
      "Epoch:  0071 D loss:-0.7159 G loss:-2.232\n",
      "Epoch:  0071 D loss:-0.5228 G loss:-2.205\n",
      "Epoch:  0071 D loss:-0.7189 G loss:-1.795\n",
      "Epoch:  0071 D loss:-0.6301 G loss:-1.851\n",
      "Epoch:  0071 D loss:-0.6804 G loss:-1.914\n",
      "Epoch:  0071 D loss:-0.7607 G loss:-1.74\n",
      "Epoch:  0071 D loss:-0.7347 G loss:-1.622\n",
      "Epoch:  0071 D loss:-0.6585 G loss:-1.837\n",
      "Epoch:  0071 D loss:-0.5861 G loss:-2.073\n",
      "Epoch:  0071 D loss:-0.6299 G loss:-1.918\n",
      "Epoch:  0071 D loss:-0.6225 G loss:-2.091\n",
      "Epoch:  0071 D loss:-0.5998 G loss:-2.207\n",
      "Epoch:  0071 D loss:-0.7894 G loss:-2.096\n",
      "Epoch:  0071 D loss:-0.7354 G loss:-2.145\n",
      "Epoch:  0071 D loss:-0.7041 G loss:-2.056\n",
      "Epoch:  0071 D loss:-0.8704 G loss:-2.194\n",
      "Epoch:  0071 D loss:-0.7581 G loss:-2.35\n",
      "Epoch:  0071 D loss:-0.6507 G loss:-2.32\n",
      "Epoch:  0071 D loss:-0.7255 G loss:-2.076\n",
      "Epoch:  0071 D loss:-0.7393 G loss:-2.017\n",
      "Epoch:  0071 D loss:-0.6015 G loss:-2.028\n",
      "Epoch:  0071 D loss:-0.6001 G loss:-2.23\n",
      "Epoch:  0071 D loss:-0.6519 G loss:-2.07\n",
      "Epoch:  0071 D loss:-0.5684 G loss:-1.945\n",
      "Epoch:  0071 D loss:-0.672 G loss:-1.901\n",
      "Epoch:  0071 D loss:-0.6998 G loss:-1.734\n",
      "Epoch:  0071 D loss:-0.8619 G loss:-1.723\n",
      "Epoch:  0071 D loss:-0.6522 G loss:-1.969\n",
      "Epoch:  0071 D loss:-0.6536 G loss:-1.794\n",
      "Epoch:  0071 D loss:-0.5977 G loss:-2.124\n",
      "Epoch:  0071 D loss:-0.6703 G loss:-2.13\n",
      "Epoch:  0071 D loss:-0.6904 G loss:-2.097\n",
      "Epoch:  0071 D loss:-0.5672 G loss:-2.359\n",
      "Epoch:  0071 D loss:-0.7057 G loss:-2.209\n",
      "Epoch:  0071 D loss:-0.8189 G loss:-2.285\n",
      "Epoch:  0071 D loss:-0.6656 G loss:-2.213\n",
      "Epoch:  0071 D loss:-0.5678 G loss:-2.451\n",
      "Epoch:  0071 D loss:-0.7751 G loss:-2.228\n",
      "Epoch:  0071 D loss:-0.6352 G loss:-2.34\n",
      "Epoch:  0071 D loss:-0.582 G loss:-2.235\n",
      "Epoch:  0071 D loss:-0.6906 G loss:-2.066\n",
      "Epoch:  0071 D loss:-0.9403 G loss:-1.988\n",
      "Epoch:  0071 D loss:-0.7438 G loss:-1.999\n",
      "Epoch:  0071 D loss:-0.6701 G loss:-1.933\n",
      "Epoch:  0071 D loss:-0.7022 G loss:-1.773\n",
      "Epoch:  0071 D loss:-0.6543 G loss:-1.732\n",
      "Epoch:  0071 D loss:-0.6748 G loss:-1.869\n",
      "Epoch:  0071 D loss:-0.7098 G loss:-1.803\n",
      "Epoch:  0071 D loss:-0.6515 G loss:-1.875\n",
      "Epoch:  0071 D loss:-0.7506 G loss:-1.984\n",
      "Epoch:  0071 D loss:-0.6687 G loss:-2.102\n",
      "Epoch:  0071 D loss:-0.8231 G loss:-2.122\n",
      "Epoch:  0071 D loss:-0.5673 G loss:-2.145\n",
      "Epoch:  0071 D loss:-0.6077 G loss:-2.131\n",
      "Epoch:  0071 D loss:-0.9004 G loss:-2.107\n",
      "Epoch:  0071 D loss:-0.7104 G loss:-2.22\n",
      "Epoch:  0071 D loss:-0.7238 G loss:-2.019\n",
      "Epoch:  0071 D loss:-0.6633 G loss:-2.016\n",
      "Epoch:  0071 D loss:-0.8011 G loss:-1.878\n",
      "Epoch:  0071 D loss:-0.6823 G loss:-2.047\n",
      "Epoch:  0071 D loss:-0.8534 G loss:-1.797\n",
      "Epoch:  0071 D loss:-0.727 G loss:-1.874\n",
      "Epoch:  0071 D loss:-0.7661 G loss:-1.852\n",
      "Epoch:  0071 D loss:-0.7202 G loss:-1.862\n",
      "Epoch:  0071 D loss:-0.6951 G loss:-1.877\n",
      "Epoch:  0071 D loss:-0.7356 G loss:-2.13\n",
      "Epoch:  0071 D loss:-0.726 G loss:-2.05\n",
      "Epoch:  0071 D loss:-0.6833 G loss:-1.94\n",
      "Epoch:  0071 D loss:-0.6238 G loss:-2.036\n",
      "Epoch:  0071 D loss:-0.6741 G loss:-2.008\n",
      "Epoch:  0071 D loss:-0.7081 G loss:-1.977\n",
      "Epoch:  0071 D loss:-0.7441 G loss:-2.051\n",
      "Epoch:  0071 D loss:-0.7059 G loss:-1.924\n",
      "Epoch:  0071 D loss:-0.6454 G loss:-1.998\n",
      "Epoch:  0071 D loss:-0.6718 G loss:-1.912\n",
      "Epoch:  0071 D loss:-0.777 G loss:-1.963\n",
      "Epoch:  0071 D loss:-0.7301 G loss:-2.185\n",
      "Epoch:  0071 D loss:-0.7817 G loss:-2.066\n",
      "Epoch:  0071 D loss:-0.5956 G loss:-2.276\n",
      "Epoch:  0071 D loss:-0.7709 G loss:-2.15\n",
      "Epoch:  0071 D loss:-0.7804 G loss:-2.015\n",
      "Epoch:  0071 D loss:-0.8131 G loss:-1.977\n",
      "Epoch:  0071 D loss:-0.753 G loss:-2.003\n",
      "Epoch:  0071 D loss:-0.565 G loss:-2.166\n",
      "Epoch:  0071 D loss:-0.9141 G loss:-1.649\n",
      "Epoch:  0071 D loss:-0.6587 G loss:-2.102\n",
      "Epoch:  0071 D loss:-0.6261 G loss:-2.088\n",
      "Epoch:  0071 D loss:-0.7469 G loss:-1.996\n",
      "Epoch:  0071 D loss:-0.7832 G loss:-1.981\n",
      "Epoch:  0071 D loss:-0.8237 G loss:-1.892\n",
      "Epoch:  0071 D loss:-0.6959 G loss:-1.931\n",
      "Epoch:  0071 D loss:-0.769 G loss:-1.789\n",
      "Epoch:  0071 D loss:-0.6168 G loss:-2.087\n",
      "Epoch:  0071 D loss:-0.7205 G loss:-1.97\n",
      "Epoch:  0071 D loss:-0.6914 G loss:-1.927\n",
      "Epoch:  0071 D loss:-0.6719 G loss:-1.93\n",
      "Epoch:  0071 D loss:-0.6603 G loss:-2.057\n",
      "Epoch:  0071 D loss:-0.6592 G loss:-2.147\n",
      "Epoch:  0071 D loss:-0.6829 G loss:-1.956\n",
      "Epoch:  0071 D loss:-0.8558 G loss:-1.987\n",
      "Epoch:  0071 D loss:-0.6675 G loss:-2.138\n",
      "Epoch:  0071 D loss:-0.5712 G loss:-2.124\n",
      "Epoch:  0071 D loss:-0.7518 G loss:-1.921\n",
      "Epoch:  0071 D loss:-0.7053 G loss:-1.959\n",
      "Epoch:  0071 D loss:-0.7031 G loss:-1.946\n",
      "Epoch:  0071 D loss:-0.5359 G loss:-2.068\n",
      "Epoch:  0071 D loss:-0.7434 G loss:-2.105\n",
      "Epoch:  0071 D loss:-0.6133 G loss:-2.182\n",
      "Epoch:  0071 D loss:-0.8354 G loss:-2.03\n",
      "Epoch:  0071 D loss:-0.7054 G loss:-1.997\n",
      "Epoch:  0071 D loss:-0.7622 G loss:-2.034\n",
      "Epoch:  0071 D loss:-0.7391 G loss:-2.145\n",
      "Epoch:  0071 D loss:-0.6629 G loss:-2.01\n",
      "Epoch:  0071 D loss:-0.7514 G loss:-1.888\n",
      "Epoch:  0071 D loss:-0.6106 G loss:-1.905\n",
      "Epoch:  0071 D loss:-0.856 G loss:-1.749\n",
      "Epoch:  0071 D loss:-0.6917 G loss:-1.892\n",
      "Epoch:  0071 D loss:-0.5923 G loss:-2.135\n",
      "Epoch:  0071 D loss:-0.7862 G loss:-1.871\n",
      "Epoch:  0071 D loss:-0.687 G loss:-1.991\n",
      "Epoch:  0071 D loss:-0.8001 G loss:-1.8\n",
      "Epoch:  0071 D loss:-0.7183 G loss:-2.169\n",
      "Epoch:  0071 D loss:-0.8164 G loss:-2.129\n",
      "Epoch:  0071 D loss:-0.8196 G loss:-2.034\n",
      "Epoch:  0071 D loss:-0.7234 G loss:-2.049\n",
      "Epoch:  0071 D loss:-0.6281 G loss:-2.05\n",
      "Epoch:  0071 D loss:-0.7485 G loss:-2.025\n",
      "Epoch:  0071 D loss:-0.727 G loss:-1.968\n",
      "Epoch:  0071 D loss:-0.7191 G loss:-1.927\n",
      "Epoch:  0071 D loss:-0.7746 G loss:-1.724\n",
      "Epoch:  0071 D loss:-0.7881 G loss:-1.829\n",
      "Epoch:  0071 D loss:-0.8402 G loss:-1.901\n",
      "Epoch:  0071 D loss:-0.6518 G loss:-1.947\n",
      "Epoch:  0071 D loss:-0.6748 G loss:-2.04\n",
      "Epoch:  0071 D loss:-0.6611 G loss:-2.102\n",
      "Epoch:  0071 D loss:-0.6833 G loss:-2.051\n",
      "Epoch:  0071 D loss:-0.6407 G loss:-2.029\n",
      "Epoch:  0071 D loss:-0.7695 G loss:-2.172\n",
      "Epoch:  0071 D loss:-0.7117 G loss:-2.045\n",
      "Epoch:  0071 D loss:-0.6522 G loss:-2.079\n",
      "Epoch:  0071 D loss:-0.7853 G loss:-2.016\n",
      "Epoch:  0071 D loss:-0.8158 G loss:-1.928\n",
      "Epoch:  0071 D loss:-0.6534 G loss:-2.07\n",
      "Epoch:  0071 D loss:-0.6675 G loss:-2.07\n",
      "Epoch:  0071 D loss:-0.7451 G loss:-2.01\n",
      "Epoch:  0071 D loss:-0.6977 G loss:-1.857\n",
      "Epoch:  0071 D loss:-0.6205 G loss:-1.889\n",
      "Epoch:  0071 D loss:-0.7723 G loss:-2.068\n",
      "Epoch:  0071 D loss:-0.6054 G loss:-2.101\n",
      "Epoch:  0071 D loss:-0.6265 G loss:-2.03\n",
      "Epoch:  0071 D loss:-0.6917 G loss:-1.994\n",
      "Epoch:  0071 D loss:-0.7572 G loss:-1.904\n",
      "Epoch:  0071 D loss:-0.731 G loss:-2.065\n",
      "Epoch:  0071 D loss:-0.7328 G loss:-1.991\n",
      "Epoch:  0071 D loss:-0.6314 G loss:-2.177\n",
      "Epoch:  0071 D loss:-0.5882 G loss:-2.117\n",
      "Epoch:  0071 D loss:-0.718 G loss:-2.079\n",
      "Epoch:  0071 D loss:-0.7859 G loss:-1.922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0071 D loss:-0.7061 G loss:-1.801\n",
      "Epoch:  0071 D loss:-0.7574 G loss:-1.754\n",
      "Epoch:  0071 D loss:-0.6867 G loss:-1.982\n",
      "Epoch:  0071 D loss:-0.8305 G loss:-1.867\n",
      "Epoch:  0071 D loss:-0.7058 G loss:-1.97\n",
      "Epoch:  0071 D loss:-0.6593 G loss:-2.116\n",
      "Epoch:  0071 D loss:-0.6079 G loss:-2.059\n",
      "Epoch:  0071 D loss:-0.5054 G loss:-2.052\n",
      "Epoch:  0071 D loss:-0.6535 G loss:-1.949\n",
      "Epoch:  0071 D loss:-0.6117 G loss:-2.204\n",
      "Epoch:  0071 D loss:-0.6504 G loss:-2.338\n",
      "Epoch:  0071 D loss:-0.6028 G loss:-2.068\n",
      "Epoch:  0071 D loss:-0.8425 G loss:-2.144\n",
      "Epoch:  0071 D loss:-0.6628 G loss:-1.856\n",
      "Epoch:  0071 D loss:-0.6852 G loss:-2.003\n",
      "Epoch:  0071 D loss:-0.6779 G loss:-1.942\n",
      "Epoch:  0071 D loss:-0.6053 G loss:-2.253\n",
      "Epoch:  0071 D loss:-0.6639 G loss:-1.946\n",
      "Epoch:  0071 D loss:-0.7638 G loss:-2.156\n",
      "Epoch:  0071 D loss:-0.6216 G loss:-2.271\n",
      "Epoch:  0071 D loss:-0.6685 G loss:-2.076\n",
      "Epoch:  0071 D loss:-0.6354 G loss:-2.163\n",
      "Epoch:  0071 D loss:-0.6113 G loss:-2.079\n",
      "Epoch:  0071 D loss:-0.5915 G loss:-2.184\n",
      "Epoch:  0071 D loss:-0.6783 G loss:-1.903\n",
      "Epoch:  0071 D loss:-0.8107 G loss:-1.944\n",
      "Epoch:  0071 D loss:-0.6198 G loss:-1.991\n",
      "Epoch:  0071 D loss:-0.7485 G loss:-2.177\n",
      "Epoch:  0071 D loss:-0.6695 G loss:-2.083\n",
      "Epoch:  0071 D loss:-0.6932 G loss:-2.137\n",
      "Epoch:  0071 D loss:-0.6616 G loss:-2.069\n",
      "Epoch:  0071 D loss:-0.6707 G loss:-1.851\n",
      "Epoch:  0071 D loss:-0.5836 G loss:-2.223\n",
      "Epoch:  0071 D loss:-0.6484 G loss:-2.026\n",
      "Epoch:  0071 D loss:-0.6245 G loss:-2.045\n",
      "Epoch:  0071 D loss:-0.6171 G loss:-2.041\n",
      "Epoch:  0072 D loss:-0.5171 G loss:-2.354\n",
      "Epoch:  0072 D loss:-0.7673 G loss:-2.245\n",
      "Epoch:  0072 D loss:-0.7398 G loss:-1.881\n",
      "Epoch:  0072 D loss:-0.6097 G loss:-2.293\n",
      "Epoch:  0072 D loss:-0.5371 G loss:-2.167\n",
      "Epoch:  0072 D loss:-0.6278 G loss:-2.026\n",
      "Epoch:  0072 D loss:-0.5478 G loss:-2.313\n",
      "Epoch:  0072 D loss:-0.6424 G loss:-2.106\n",
      "Epoch:  0072 D loss:-0.534 G loss:-2.083\n",
      "Epoch:  0072 D loss:-0.549 G loss:-2.17\n",
      "Epoch:  0072 D loss:-0.5947 G loss:-2.263\n",
      "Epoch:  0072 D loss:-0.7027 G loss:-2.17\n",
      "Epoch:  0072 D loss:-0.7181 G loss:-2.051\n",
      "Epoch:  0072 D loss:-0.5555 G loss:-1.9\n",
      "Epoch:  0072 D loss:-0.6477 G loss:-2.053\n",
      "Epoch:  0072 D loss:-0.7593 G loss:-1.938\n",
      "Epoch:  0072 D loss:-0.627 G loss:-2.119\n",
      "Epoch:  0072 D loss:-0.6994 G loss:-1.904\n",
      "Epoch:  0072 D loss:-0.5561 G loss:-2.178\n",
      "Epoch:  0072 D loss:-0.591 G loss:-2.194\n",
      "Epoch:  0072 D loss:-0.8591 G loss:-1.982\n",
      "Epoch:  0072 D loss:-0.6762 G loss:-1.989\n",
      "Epoch:  0072 D loss:-0.669 G loss:-2.055\n",
      "Epoch:  0072 D loss:-0.7033 G loss:-1.884\n",
      "Epoch:  0072 D loss:-0.4309 G loss:-2.163\n",
      "Epoch:  0072 D loss:-0.5388 G loss:-1.953\n",
      "Epoch:  0072 D loss:-0.7394 G loss:-2.028\n",
      "Epoch:  0072 D loss:-0.6233 G loss:-2.062\n",
      "Epoch:  0072 D loss:-0.5795 G loss:-2.249\n",
      "Epoch:  0072 D loss:-0.629 G loss:-2.2\n",
      "Epoch:  0072 D loss:-0.6524 G loss:-2.358\n",
      "Epoch:  0072 D loss:-0.6071 G loss:-2.214\n",
      "Epoch:  0072 D loss:-0.7495 G loss:-1.945\n",
      "Epoch:  0072 D loss:-0.7038 G loss:-2.118\n",
      "Epoch:  0072 D loss:-0.737 G loss:-2.085\n",
      "Epoch:  0072 D loss:-0.5692 G loss:-2.136\n",
      "Epoch:  0072 D loss:-0.7329 G loss:-2.06\n",
      "Epoch:  0072 D loss:-0.6856 G loss:-2.221\n",
      "Epoch:  0072 D loss:-0.7449 G loss:-2.083\n",
      "Epoch:  0072 D loss:-0.5964 G loss:-2.161\n",
      "Epoch:  0072 D loss:-0.544 G loss:-2.146\n",
      "Epoch:  0072 D loss:-0.6806 G loss:-1.947\n",
      "Epoch:  0072 D loss:-0.6385 G loss:-2.109\n",
      "Epoch:  0072 D loss:-0.6238 G loss:-1.757\n",
      "Epoch:  0072 D loss:-0.6735 G loss:-1.89\n",
      "Epoch:  0072 D loss:-0.5803 G loss:-1.999\n",
      "Epoch:  0072 D loss:-0.5572 G loss:-2.018\n",
      "Epoch:  0072 D loss:-0.8168 G loss:-2.181\n",
      "Epoch:  0072 D loss:-0.7319 G loss:-1.893\n",
      "Epoch:  0072 D loss:-0.7036 G loss:-2.075\n",
      "Epoch:  0072 D loss:-0.5692 G loss:-2.186\n",
      "Epoch:  0072 D loss:-0.723 G loss:-1.911\n",
      "Epoch:  0072 D loss:-0.8509 G loss:-1.927\n",
      "Epoch:  0072 D loss:-0.8426 G loss:-1.992\n",
      "Epoch:  0072 D loss:-0.8799 G loss:-1.894\n",
      "Epoch:  0072 D loss:-0.6435 G loss:-2.146\n",
      "Epoch:  0072 D loss:-0.7354 G loss:-2.016\n",
      "Epoch:  0072 D loss:-0.5562 G loss:-2.139\n",
      "Epoch:  0072 D loss:-0.7145 G loss:-2.034\n",
      "Epoch:  0072 D loss:-0.7323 G loss:-1.998\n",
      "Epoch:  0072 D loss:-0.7308 G loss:-1.877\n",
      "Epoch:  0072 D loss:-0.6688 G loss:-1.883\n",
      "Epoch:  0072 D loss:-0.6887 G loss:-2.096\n",
      "Epoch:  0072 D loss:-0.7255 G loss:-2.083\n",
      "Epoch:  0072 D loss:-0.7114 G loss:-2.116\n",
      "Epoch:  0072 D loss:-0.5405 G loss:-2.104\n",
      "Epoch:  0072 D loss:-0.6655 G loss:-2.022\n",
      "Epoch:  0072 D loss:-0.7525 G loss:-1.858\n",
      "Epoch:  0072 D loss:-0.6394 G loss:-1.906\n",
      "Epoch:  0072 D loss:-0.7569 G loss:-2.015\n",
      "Epoch:  0072 D loss:-0.6161 G loss:-2.043\n",
      "Epoch:  0072 D loss:-0.7689 G loss:-1.897\n",
      "Epoch:  0072 D loss:-0.6836 G loss:-1.862\n",
      "Epoch:  0072 D loss:-0.781 G loss:-1.783\n",
      "Epoch:  0072 D loss:-0.813 G loss:-1.956\n",
      "Epoch:  0072 D loss:-0.7589 G loss:-1.931\n",
      "Epoch:  0072 D loss:-0.8177 G loss:-2.175\n",
      "Epoch:  0072 D loss:-0.6164 G loss:-2.148\n",
      "Epoch:  0072 D loss:-0.6542 G loss:-1.952\n",
      "Epoch:  0072 D loss:-0.7538 G loss:-1.863\n",
      "Epoch:  0072 D loss:-0.6715 G loss:-2.096\n",
      "Epoch:  0072 D loss:-0.8385 G loss:-1.884\n",
      "Epoch:  0072 D loss:-0.7747 G loss:-1.95\n",
      "Epoch:  0072 D loss:-0.8201 G loss:-1.859\n",
      "Epoch:  0072 D loss:-0.7028 G loss:-2.003\n",
      "Epoch:  0072 D loss:-0.6969 G loss:-1.916\n",
      "Epoch:  0072 D loss:-0.7137 G loss:-1.949\n",
      "Epoch:  0072 D loss:-0.7967 G loss:-1.837\n",
      "Epoch:  0072 D loss:-0.6527 G loss:-1.924\n",
      "Epoch:  0072 D loss:-0.6973 G loss:-1.777\n",
      "Epoch:  0072 D loss:-0.6758 G loss:-2.161\n",
      "Epoch:  0072 D loss:-0.7565 G loss:-2.111\n",
      "Epoch:  0072 D loss:-0.6804 G loss:-2.068\n",
      "Epoch:  0072 D loss:-0.6615 G loss:-2.115\n",
      "Epoch:  0072 D loss:-0.6529 G loss:-2.12\n",
      "Epoch:  0072 D loss:-0.6886 G loss:-1.932\n",
      "Epoch:  0072 D loss:-0.6937 G loss:-2.113\n",
      "Epoch:  0072 D loss:-0.6414 G loss:-2.065\n",
      "Epoch:  0072 D loss:-0.7308 G loss:-2.192\n",
      "Epoch:  0072 D loss:-0.758 G loss:-2.096\n",
      "Epoch:  0072 D loss:-0.7623 G loss:-1.821\n",
      "Epoch:  0072 D loss:-0.7661 G loss:-2.034\n",
      "Epoch:  0072 D loss:-0.6806 G loss:-1.854\n",
      "Epoch:  0072 D loss:-0.642 G loss:-1.921\n",
      "Epoch:  0072 D loss:-0.6926 G loss:-2.104\n",
      "Epoch:  0072 D loss:-0.7344 G loss:-1.894\n",
      "Epoch:  0072 D loss:-0.7843 G loss:-1.874\n",
      "Epoch:  0072 D loss:-0.78 G loss:-1.802\n",
      "Epoch:  0072 D loss:-0.6802 G loss:-1.977\n",
      "Epoch:  0072 D loss:-0.5762 G loss:-2.218\n",
      "Epoch:  0072 D loss:-0.8358 G loss:-2.074\n",
      "Epoch:  0072 D loss:-0.79 G loss:-2.049\n",
      "Epoch:  0072 D loss:-0.6241 G loss:-2.219\n",
      "Epoch:  0072 D loss:-0.8586 G loss:-2.12\n",
      "Epoch:  0072 D loss:-0.7095 G loss:-1.982\n",
      "Epoch:  0072 D loss:-0.6155 G loss:-2.02\n",
      "Epoch:  0072 D loss:-0.7051 G loss:-2.049\n",
      "Epoch:  0072 D loss:-0.7466 G loss:-2.236\n",
      "Epoch:  0072 D loss:-0.8345 G loss:-2.216\n",
      "Epoch:  0072 D loss:-0.6291 G loss:-2.019\n",
      "Epoch:  0072 D loss:-0.6734 G loss:-2.048\n",
      "Epoch:  0072 D loss:-0.7408 G loss:-1.816\n",
      "Epoch:  0072 D loss:-0.6524 G loss:-1.961\n",
      "Epoch:  0072 D loss:-0.7161 G loss:-1.748\n",
      "Epoch:  0072 D loss:-0.6286 G loss:-1.839\n",
      "Epoch:  0072 D loss:-0.6872 G loss:-2.041\n",
      "Epoch:  0072 D loss:-0.7542 G loss:-2.014\n",
      "Epoch:  0072 D loss:-0.6302 G loss:-1.856\n",
      "Epoch:  0072 D loss:-0.7102 G loss:-1.893\n",
      "Epoch:  0072 D loss:-0.7092 G loss:-1.849\n",
      "Epoch:  0072 D loss:-0.5709 G loss:-2.017\n",
      "Epoch:  0072 D loss:-0.6341 G loss:-2.095\n",
      "Epoch:  0072 D loss:-0.7924 G loss:-1.943\n",
      "Epoch:  0072 D loss:-0.6465 G loss:-2.204\n",
      "Epoch:  0072 D loss:-0.7691 G loss:-2.126\n",
      "Epoch:  0072 D loss:-0.7286 G loss:-2.297\n",
      "Epoch:  0072 D loss:-0.6259 G loss:-2.193\n",
      "Epoch:  0072 D loss:-0.7381 G loss:-2.083\n",
      "Epoch:  0072 D loss:-0.6133 G loss:-1.992\n",
      "Epoch:  0072 D loss:-0.6635 G loss:-2.048\n",
      "Epoch:  0072 D loss:-0.7405 G loss:-1.991\n",
      "Epoch:  0072 D loss:-0.7413 G loss:-2.015\n",
      "Epoch:  0072 D loss:-0.5969 G loss:-2.244\n",
      "Epoch:  0072 D loss:-0.5631 G loss:-2.127\n",
      "Epoch:  0072 D loss:-0.7604 G loss:-1.987\n",
      "Epoch:  0072 D loss:-0.6056 G loss:-2.13\n",
      "Epoch:  0072 D loss:-0.597 G loss:-2.139\n",
      "Epoch:  0072 D loss:-0.6287 G loss:-2.378\n",
      "Epoch:  0072 D loss:-0.663 G loss:-2.297\n",
      "Epoch:  0072 D loss:-0.7786 G loss:-2.012\n",
      "Epoch:  0072 D loss:-0.6478 G loss:-2.1\n",
      "Epoch:  0072 D loss:-0.7383 G loss:-2.22\n",
      "Epoch:  0072 D loss:-0.6764 G loss:-1.963\n",
      "Epoch:  0072 D loss:-0.6574 G loss:-2.091\n",
      "Epoch:  0072 D loss:-0.6476 G loss:-2.102\n",
      "Epoch:  0072 D loss:-0.6569 G loss:-1.935\n",
      "Epoch:  0072 D loss:-0.704 G loss:-1.907\n",
      "Epoch:  0072 D loss:-0.6759 G loss:-1.891\n",
      "Epoch:  0072 D loss:-0.7726 G loss:-1.946\n",
      "Epoch:  0072 D loss:-0.6813 G loss:-1.931\n",
      "Epoch:  0072 D loss:-0.6036 G loss:-2.085\n",
      "Epoch:  0072 D loss:-0.7798 G loss:-2.226\n",
      "Epoch:  0072 D loss:-0.6556 G loss:-1.955\n",
      "Epoch:  0072 D loss:-0.5696 G loss:-2.031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0072 D loss:-0.7577 G loss:-2.166\n",
      "Epoch:  0072 D loss:-0.6292 G loss:-1.996\n",
      "Epoch:  0072 D loss:-0.662 G loss:-2.134\n",
      "Epoch:  0072 D loss:-0.6849 G loss:-2.11\n",
      "Epoch:  0072 D loss:-0.6618 G loss:-2.094\n",
      "Epoch:  0072 D loss:-0.6231 G loss:-2.125\n",
      "Epoch:  0072 D loss:-0.7506 G loss:-2.036\n",
      "Epoch:  0072 D loss:-0.572 G loss:-2.167\n",
      "Epoch:  0072 D loss:-0.5635 G loss:-2.109\n",
      "Epoch:  0072 D loss:-0.5188 G loss:-2.235\n",
      "Epoch:  0072 D loss:-0.6054 G loss:-2.048\n",
      "Epoch:  0072 D loss:-0.9314 G loss:-1.766\n",
      "Epoch:  0072 D loss:-0.6609 G loss:-2.066\n",
      "Epoch:  0072 D loss:-0.772 G loss:-1.876\n",
      "Epoch:  0072 D loss:-0.6797 G loss:-2.171\n",
      "Epoch:  0072 D loss:-0.6769 G loss:-2.183\n",
      "Epoch:  0072 D loss:-0.6182 G loss:-2.125\n",
      "Epoch:  0072 D loss:-0.7128 G loss:-2.128\n",
      "Epoch:  0072 D loss:-0.6087 G loss:-2.19\n",
      "Epoch:  0072 D loss:-0.7441 G loss:-2.214\n",
      "Epoch:  0072 D loss:-0.6166 G loss:-2.09\n",
      "Epoch:  0072 D loss:-0.6518 G loss:-2.349\n",
      "Epoch:  0072 D loss:-0.7263 G loss:-2.098\n",
      "Epoch:  0072 D loss:-0.6083 G loss:-2.021\n",
      "Epoch:  0072 D loss:-0.8226 G loss:-1.914\n",
      "Epoch:  0072 D loss:-0.6974 G loss:-1.98\n",
      "Epoch:  0072 D loss:-0.8334 G loss:-1.761\n",
      "Epoch:  0072 D loss:-0.7105 G loss:-1.844\n",
      "Epoch:  0072 D loss:-0.6484 G loss:-2.011\n",
      "Epoch:  0072 D loss:-0.624 G loss:-2.205\n",
      "Epoch:  0072 D loss:-0.9006 G loss:-1.954\n",
      "Epoch:  0072 D loss:-0.6585 G loss:-2.197\n",
      "Epoch:  0072 D loss:-0.7169 G loss:-2.081\n",
      "Epoch:  0072 D loss:-0.6868 G loss:-2.167\n",
      "Epoch:  0072 D loss:-0.6913 G loss:-2.101\n",
      "Epoch:  0072 D loss:-0.6581 G loss:-2.114\n",
      "Epoch:  0072 D loss:-0.7521 G loss:-2.042\n",
      "Epoch:  0072 D loss:-0.8482 G loss:-1.938\n",
      "Epoch:  0072 D loss:-0.6121 G loss:-2.106\n",
      "Epoch:  0072 D loss:-0.6931 G loss:-2.048\n",
      "Epoch:  0072 D loss:-0.7502 G loss:-2.02\n",
      "Epoch:  0072 D loss:-0.6676 G loss:-2.181\n",
      "Epoch:  0072 D loss:-0.7257 G loss:-1.996\n",
      "Epoch:  0072 D loss:-0.7117 G loss:-2.009\n",
      "Epoch:  0072 D loss:-0.7686 G loss:-2.028\n",
      "Epoch:  0072 D loss:-0.6555 G loss:-1.939\n",
      "Epoch:  0072 D loss:-0.7601 G loss:-1.875\n",
      "Epoch:  0072 D loss:-0.7397 G loss:-1.864\n",
      "Epoch:  0072 D loss:-0.6966 G loss:-1.977\n",
      "Epoch:  0072 D loss:-0.7486 G loss:-1.969\n",
      "Epoch:  0072 D loss:-0.6544 G loss:-1.938\n",
      "Epoch:  0072 D loss:-0.6823 G loss:-2.053\n",
      "Epoch:  0072 D loss:-0.8706 G loss:-1.894\n",
      "Epoch:  0072 D loss:-0.7863 G loss:-2.163\n",
      "Epoch:  0072 D loss:-0.6761 G loss:-2.01\n",
      "Epoch:  0072 D loss:-0.7144 G loss:-1.953\n",
      "Epoch:  0072 D loss:-0.8937 G loss:-1.996\n",
      "Epoch:  0072 D loss:-0.6114 G loss:-2.194\n",
      "Epoch:  0072 D loss:-0.7718 G loss:-1.723\n",
      "Epoch:  0072 D loss:-0.7348 G loss:-2.046\n",
      "Epoch:  0072 D loss:-0.7609 G loss:-1.709\n",
      "Epoch:  0072 D loss:-0.5951 G loss:-1.853\n",
      "Epoch:  0072 D loss:-0.6447 G loss:-2.04\n",
      "Epoch:  0072 D loss:-0.7655 G loss:-1.91\n",
      "Epoch:  0072 D loss:-0.7015 G loss:-2.045\n",
      "Epoch:  0072 D loss:-0.7856 G loss:-1.895\n",
      "Epoch:  0072 D loss:-0.7936 G loss:-1.949\n",
      "Epoch:  0072 D loss:-0.7252 G loss:-2.122\n",
      "Epoch:  0072 D loss:-0.6591 G loss:-2.067\n",
      "Epoch:  0072 D loss:-0.7412 G loss:-2.09\n",
      "Epoch:  0072 D loss:-0.7 G loss:-1.892\n",
      "Epoch:  0072 D loss:-0.6672 G loss:-1.943\n",
      "Epoch:  0072 D loss:-0.705 G loss:-1.891\n",
      "Epoch:  0072 D loss:-0.6846 G loss:-2.134\n",
      "Epoch:  0072 D loss:-0.891 G loss:-2.048\n",
      "Epoch:  0072 D loss:-0.7827 G loss:-2.214\n",
      "Epoch:  0072 D loss:-0.7532 G loss:-2.095\n",
      "Epoch:  0072 D loss:-0.6604 G loss:-2.031\n",
      "Epoch:  0072 D loss:-0.6886 G loss:-2.011\n",
      "Epoch:  0072 D loss:-0.8512 G loss:-1.993\n",
      "Epoch:  0072 D loss:-0.6543 G loss:-1.892\n",
      "Epoch:  0072 D loss:-0.7765 G loss:-2.053\n",
      "Epoch:  0072 D loss:-0.7043 G loss:-2.15\n",
      "Epoch:  0072 D loss:-0.692 G loss:-2.143\n",
      "Epoch:  0072 D loss:-0.7456 G loss:-2.15\n",
      "Epoch:  0072 D loss:-0.8918 G loss:-1.701\n",
      "Epoch:  0072 D loss:-0.6571 G loss:-1.975\n",
      "Epoch:  0072 D loss:-0.7053 G loss:-1.957\n",
      "Epoch:  0072 D loss:-0.7242 G loss:-2.0\n",
      "Epoch:  0072 D loss:-0.8065 G loss:-1.802\n",
      "Epoch:  0072 D loss:-0.7672 G loss:-1.984\n",
      "Epoch:  0072 D loss:-0.5695 G loss:-2.23\n",
      "Epoch:  0072 D loss:-0.8613 G loss:-1.791\n",
      "Epoch:  0072 D loss:-0.7967 G loss:-2.045\n",
      "Epoch:  0072 D loss:-0.7749 G loss:-1.833\n",
      "Epoch:  0072 D loss:-0.6917 G loss:-2.069\n",
      "Epoch:  0072 D loss:-0.781 G loss:-1.838\n",
      "Epoch:  0072 D loss:-0.6271 G loss:-2.178\n",
      "Epoch:  0072 D loss:-0.7336 G loss:-2.043\n",
      "Epoch:  0072 D loss:-0.649 G loss:-2.068\n",
      "Epoch:  0072 D loss:-0.7192 G loss:-2.104\n",
      "Epoch:  0072 D loss:-0.671 G loss:-1.948\n",
      "Epoch:  0072 D loss:-0.8086 G loss:-1.967\n",
      "Epoch:  0072 D loss:-0.806 G loss:-2.068\n",
      "Epoch:  0072 D loss:-0.7373 G loss:-2.024\n",
      "Epoch:  0072 D loss:-0.8436 G loss:-1.951\n",
      "Epoch:  0072 D loss:-0.6202 G loss:-1.903\n",
      "Epoch:  0072 D loss:-0.7148 G loss:-1.807\n",
      "Epoch:  0072 D loss:-0.8835 G loss:-1.893\n",
      "Epoch:  0072 D loss:-0.619 G loss:-1.922\n",
      "Epoch:  0072 D loss:-0.6847 G loss:-1.987\n",
      "Epoch:  0072 D loss:-0.6696 G loss:-1.898\n",
      "Epoch:  0072 D loss:-0.5979 G loss:-2.048\n",
      "Epoch:  0072 D loss:-0.6583 G loss:-2.15\n",
      "Epoch:  0072 D loss:-0.6892 G loss:-2.021\n",
      "Epoch:  0072 D loss:-0.6282 G loss:-2.275\n",
      "Epoch:  0072 D loss:-0.585 G loss:-2.133\n",
      "Epoch:  0072 D loss:-0.6897 G loss:-2.059\n",
      "Epoch:  0072 D loss:-0.6941 G loss:-2.103\n",
      "Epoch:  0072 D loss:-0.6802 G loss:-2.225\n",
      "Epoch:  0072 D loss:-0.7963 G loss:-1.916\n",
      "Epoch:  0072 D loss:-0.7411 G loss:-2.016\n",
      "Epoch:  0072 D loss:-0.778 G loss:-1.934\n",
      "Epoch:  0072 D loss:-0.8904 G loss:-2.198\n",
      "Epoch:  0072 D loss:-0.7355 G loss:-1.887\n",
      "Epoch:  0072 D loss:-0.6078 G loss:-2.016\n",
      "Epoch:  0072 D loss:-0.6612 G loss:-2.179\n",
      "Epoch:  0072 D loss:-0.6795 G loss:-1.958\n",
      "Epoch:  0072 D loss:-0.6452 G loss:-1.884\n",
      "Epoch:  0072 D loss:-0.6696 G loss:-1.893\n",
      "Epoch:  0072 D loss:-0.6782 G loss:-2.0\n",
      "Epoch:  0072 D loss:-0.6705 G loss:-1.885\n",
      "Epoch:  0072 D loss:-0.7038 G loss:-2.118\n",
      "Epoch:  0072 D loss:-0.7101 G loss:-2.094\n",
      "Epoch:  0072 D loss:-0.7399 G loss:-2.07\n",
      "Epoch:  0072 D loss:-0.8059 G loss:-2.191\n",
      "Epoch:  0072 D loss:-0.6881 G loss:-2.024\n",
      "Epoch:  0072 D loss:-0.5944 G loss:-2.291\n",
      "Epoch:  0072 D loss:-0.6967 G loss:-2.105\n",
      "Epoch:  0072 D loss:-0.6175 G loss:-2.023\n",
      "Epoch:  0072 D loss:-0.626 G loss:-2.127\n",
      "Epoch:  0072 D loss:-0.6102 G loss:-1.881\n",
      "Epoch:  0072 D loss:-0.6515 G loss:-2.082\n",
      "Epoch:  0072 D loss:-0.7358 G loss:-2.062\n",
      "Epoch:  0072 D loss:-0.5841 G loss:-2.131\n",
      "Epoch:  0072 D loss:-0.6274 G loss:-2.147\n",
      "Epoch:  0072 D loss:-0.6197 G loss:-1.998\n",
      "Epoch:  0072 D loss:-0.6533 G loss:-1.989\n",
      "Epoch:  0072 D loss:-0.7333 G loss:-1.912\n",
      "Epoch:  0072 D loss:-0.6923 G loss:-2.157\n",
      "Epoch:  0072 D loss:-0.6008 G loss:-2.001\n",
      "Epoch:  0072 D loss:-0.7814 G loss:-2.044\n",
      "Epoch:  0072 D loss:-0.8003 G loss:-1.978\n",
      "Epoch:  0072 D loss:-0.755 G loss:-1.99\n",
      "Epoch:  0072 D loss:-0.7249 G loss:-2.098\n",
      "Epoch:  0072 D loss:-0.7434 G loss:-1.858\n",
      "Epoch:  0072 D loss:-0.6637 G loss:-2.015\n",
      "Epoch:  0072 D loss:-0.6704 G loss:-1.959\n",
      "Epoch:  0072 D loss:-0.6652 G loss:-2.424\n",
      "Epoch:  0072 D loss:-0.676 G loss:-2.203\n",
      "Epoch:  0072 D loss:-0.7702 G loss:-2.163\n",
      "Epoch:  0072 D loss:-0.6563 G loss:-1.982\n",
      "Epoch:  0072 D loss:-0.6186 G loss:-2.159\n",
      "Epoch:  0072 D loss:-0.6103 G loss:-1.979\n",
      "Epoch:  0072 D loss:-0.6599 G loss:-1.979\n",
      "Epoch:  0072 D loss:-0.641 G loss:-2.231\n",
      "Epoch:  0072 D loss:-0.7157 G loss:-2.243\n",
      "Epoch:  0072 D loss:-0.7213 G loss:-2.021\n",
      "Epoch:  0072 D loss:-0.5856 G loss:-2.026\n",
      "Epoch:  0072 D loss:-0.7007 G loss:-1.898\n",
      "Epoch:  0072 D loss:-0.7302 G loss:-1.794\n",
      "Epoch:  0072 D loss:-0.8038 G loss:-1.793\n",
      "Epoch:  0072 D loss:-0.7 G loss:-2.076\n",
      "Epoch:  0072 D loss:-0.8214 G loss:-1.916\n",
      "Epoch:  0072 D loss:-0.7293 G loss:-1.996\n",
      "Epoch:  0072 D loss:-0.587 G loss:-1.83\n",
      "Epoch:  0072 D loss:-0.6888 G loss:-2.046\n",
      "Epoch:  0072 D loss:-0.7135 G loss:-2.111\n",
      "Epoch:  0072 D loss:-0.6236 G loss:-2.181\n",
      "Epoch:  0072 D loss:-0.5886 G loss:-2.356\n",
      "Epoch:  0072 D loss:-0.5821 G loss:-2.176\n",
      "Epoch:  0072 D loss:-0.5713 G loss:-2.304\n",
      "Epoch:  0072 D loss:-0.5741 G loss:-2.21\n",
      "Epoch:  0072 D loss:-0.7002 G loss:-2.048\n",
      "Epoch:  0072 D loss:-0.7185 G loss:-1.94\n",
      "Epoch:  0072 D loss:-0.6706 G loss:-1.969\n",
      "Epoch:  0072 D loss:-0.7901 G loss:-2.078\n",
      "Epoch:  0072 D loss:-0.7496 G loss:-1.937\n",
      "Epoch:  0072 D loss:-0.6113 G loss:-1.843\n",
      "Epoch:  0072 D loss:-0.6401 G loss:-2.044\n",
      "Epoch:  0072 D loss:-0.7448 G loss:-1.962\n",
      "Epoch:  0072 D loss:-0.9144 G loss:-1.888\n",
      "Epoch:  0072 D loss:-0.5593 G loss:-2.085\n",
      "Epoch:  0072 D loss:-0.7304 G loss:-2.058\n",
      "Epoch:  0072 D loss:-0.7083 G loss:-2.046\n",
      "Epoch:  0072 D loss:-0.7556 G loss:-1.98\n",
      "Epoch:  0072 D loss:-0.692 G loss:-2.098\n",
      "Epoch:  0072 D loss:-0.6164 G loss:-2.055\n",
      "Epoch:  0072 D loss:-0.8382 G loss:-1.976\n",
      "Epoch:  0072 D loss:-0.5978 G loss:-2.128\n",
      "Epoch:  0072 D loss:-0.7593 G loss:-1.876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0072 D loss:-0.8534 G loss:-1.853\n",
      "Epoch:  0072 D loss:-0.588 G loss:-1.974\n",
      "Epoch:  0072 D loss:-0.7975 G loss:-2.059\n",
      "Epoch:  0072 D loss:-0.6612 G loss:-2.323\n",
      "Epoch:  0072 D loss:-0.6389 G loss:-2.267\n",
      "Epoch:  0072 D loss:-0.8972 G loss:-1.947\n",
      "Epoch:  0072 D loss:-0.6481 G loss:-2.104\n",
      "Epoch:  0072 D loss:-0.6655 G loss:-2.107\n",
      "Epoch:  0072 D loss:-0.7245 G loss:-1.939\n",
      "Epoch:  0072 D loss:-0.8651 G loss:-1.76\n",
      "Epoch:  0072 D loss:-0.6973 G loss:-2.037\n",
      "Epoch:  0072 D loss:-0.8179 G loss:-1.907\n",
      "Epoch:  0072 D loss:-0.677 G loss:-1.862\n",
      "Epoch:  0072 D loss:-0.8734 G loss:-1.667\n",
      "Epoch:  0072 D loss:-0.8525 G loss:-1.934\n",
      "Epoch:  0072 D loss:-0.8451 G loss:-1.903\n",
      "Epoch:  0072 D loss:-0.7826 G loss:-2.079\n",
      "Epoch:  0072 D loss:-0.7265 G loss:-1.829\n",
      "Epoch:  0072 D loss:-0.8031 G loss:-2.115\n",
      "Epoch:  0072 D loss:-0.6708 G loss:-1.904\n",
      "Epoch:  0072 D loss:-0.8276 G loss:-1.835\n",
      "Epoch:  0072 D loss:-0.7332 G loss:-1.892\n",
      "Epoch:  0072 D loss:-0.6856 G loss:-1.969\n",
      "Epoch:  0072 D loss:-0.9022 G loss:-1.612\n",
      "Epoch:  0072 D loss:-0.8401 G loss:-2.019\n",
      "Epoch:  0072 D loss:-0.7677 G loss:-1.657\n",
      "Epoch:  0072 D loss:-0.7485 G loss:-1.795\n",
      "Epoch:  0072 D loss:-0.7685 G loss:-1.853\n",
      "Epoch:  0072 D loss:-0.6709 G loss:-2.194\n",
      "Epoch:  0072 D loss:-0.7786 G loss:-1.943\n",
      "Epoch:  0072 D loss:-0.7984 G loss:-2.026\n",
      "Epoch:  0072 D loss:-0.7431 G loss:-2.106\n",
      "Epoch:  0072 D loss:-0.7797 G loss:-1.894\n",
      "Epoch:  0072 D loss:-0.761 G loss:-2.099\n",
      "Epoch:  0072 D loss:-0.6807 G loss:-2.004\n",
      "Epoch:  0072 D loss:-0.844 G loss:-1.891\n",
      "Epoch:  0072 D loss:-0.9422 G loss:-1.886\n",
      "Epoch:  0072 D loss:-0.7511 G loss:-2.105\n",
      "Epoch:  0072 D loss:-0.7985 G loss:-1.951\n",
      "Epoch:  0072 D loss:-0.9568 G loss:-1.801\n",
      "Epoch:  0072 D loss:-0.7718 G loss:-1.809\n",
      "Epoch:  0072 D loss:-0.7077 G loss:-1.971\n",
      "Epoch:  0072 D loss:-0.7432 G loss:-1.86\n",
      "Epoch:  0072 D loss:-0.6572 G loss:-2.178\n",
      "Epoch:  0072 D loss:-0.7849 G loss:-1.767\n",
      "Epoch:  0072 D loss:-0.8122 G loss:-1.847\n",
      "Epoch:  0072 D loss:-0.6369 G loss:-1.859\n",
      "Epoch:  0072 D loss:-0.7801 G loss:-1.858\n",
      "Epoch:  0072 D loss:-0.7975 G loss:-1.871\n",
      "Epoch:  0072 D loss:-0.6507 G loss:-2.223\n",
      "Epoch:  0072 D loss:-0.8015 G loss:-2.214\n",
      "Epoch:  0072 D loss:-0.8923 G loss:-1.996\n",
      "Epoch:  0072 D loss:-0.7208 G loss:-2.141\n",
      "Epoch:  0072 D loss:-0.792 G loss:-2.158\n",
      "Epoch:  0072 D loss:-0.7478 G loss:-2.13\n",
      "Epoch:  0072 D loss:-0.8431 G loss:-2.056\n",
      "Epoch:  0072 D loss:-0.7125 G loss:-2.038\n",
      "Epoch:  0072 D loss:-0.7661 G loss:-2.116\n",
      "Epoch:  0072 D loss:-0.9166 G loss:-1.895\n",
      "Epoch:  0072 D loss:-0.6049 G loss:-2.14\n",
      "Epoch:  0072 D loss:-0.6082 G loss:-1.913\n",
      "Epoch:  0072 D loss:-0.7682 G loss:-1.669\n",
      "Epoch:  0072 D loss:-0.6805 G loss:-1.759\n",
      "Epoch:  0072 D loss:-0.6418 G loss:-1.996\n",
      "Epoch:  0072 D loss:-0.7677 G loss:-1.834\n",
      "Epoch:  0072 D loss:-0.7415 G loss:-1.911\n",
      "Epoch:  0072 D loss:-0.7105 G loss:-1.92\n",
      "Epoch:  0072 D loss:-0.705 G loss:-2.004\n",
      "Epoch:  0072 D loss:-0.6874 G loss:-1.993\n",
      "Epoch:  0072 D loss:-0.7988 G loss:-2.145\n",
      "Epoch:  0072 D loss:-0.7269 G loss:-2.093\n",
      "Epoch:  0072 D loss:-0.7993 G loss:-2.076\n",
      "Epoch:  0072 D loss:-0.5992 G loss:-2.018\n",
      "Epoch:  0072 D loss:-0.6676 G loss:-2.018\n",
      "Epoch:  0072 D loss:-0.6453 G loss:-2.17\n",
      "Epoch:  0072 D loss:-0.6718 G loss:-2.012\n",
      "Epoch:  0072 D loss:-0.8183 G loss:-1.898\n",
      "Epoch:  0072 D loss:-0.711 G loss:-1.798\n",
      "Epoch:  0072 D loss:-0.7639 G loss:-1.952\n",
      "Epoch:  0072 D loss:-0.7524 G loss:-1.917\n",
      "Epoch:  0072 D loss:-0.6594 G loss:-1.958\n",
      "Epoch:  0072 D loss:-0.7137 G loss:-2.003\n",
      "Epoch:  0072 D loss:-0.5963 G loss:-1.971\n",
      "Epoch:  0072 D loss:-0.6166 G loss:-2.113\n",
      "Epoch:  0072 D loss:-0.5788 G loss:-2.162\n",
      "Epoch:  0072 D loss:-0.773 G loss:-2.104\n",
      "Epoch:  0072 D loss:-0.5946 G loss:-2.125\n",
      "Epoch:  0072 D loss:-0.7449 G loss:-2.136\n",
      "Epoch:  0072 D loss:-0.7289 G loss:-2.314\n",
      "Epoch:  0072 D loss:-0.6361 G loss:-2.146\n",
      "Epoch:  0072 D loss:-0.6898 G loss:-1.961\n",
      "Epoch:  0072 D loss:-0.5884 G loss:-2.208\n",
      "Epoch:  0072 D loss:-0.747 G loss:-1.9\n",
      "Epoch:  0072 D loss:-0.6672 G loss:-1.929\n",
      "Epoch:  0072 D loss:-0.5757 G loss:-1.992\n",
      "Epoch:  0072 D loss:-0.6623 G loss:-1.897\n",
      "Epoch:  0072 D loss:-0.6394 G loss:-1.921\n",
      "Epoch:  0072 D loss:-0.6116 G loss:-1.986\n",
      "Epoch:  0072 D loss:-0.7113 G loss:-2.038\n",
      "Epoch:  0072 D loss:-0.6919 G loss:-2.2\n",
      "Epoch:  0072 D loss:-0.5847 G loss:-2.072\n",
      "Epoch:  0072 D loss:-0.6495 G loss:-2.287\n",
      "Epoch:  0072 D loss:-0.6205 G loss:-2.155\n",
      "Epoch:  0072 D loss:-0.6309 G loss:-2.118\n",
      "Epoch:  0072 D loss:-0.7656 G loss:-1.979\n",
      "Epoch:  0072 D loss:-0.654 G loss:-2.241\n",
      "Epoch:  0072 D loss:-0.6463 G loss:-2.025\n",
      "Epoch:  0072 D loss:-0.629 G loss:-1.856\n",
      "Epoch:  0072 D loss:-0.5548 G loss:-1.977\n",
      "Epoch:  0072 D loss:-0.8351 G loss:-1.789\n",
      "Epoch:  0072 D loss:-0.7158 G loss:-1.72\n",
      "Epoch:  0072 D loss:-0.5641 G loss:-1.998\n",
      "Epoch:  0072 D loss:-0.7281 G loss:-1.901\n",
      "Epoch:  0072 D loss:-0.7111 G loss:-1.929\n",
      "Epoch:  0072 D loss:-0.6636 G loss:-2.096\n",
      "Epoch:  0072 D loss:-0.6708 G loss:-2.331\n",
      "Epoch:  0072 D loss:-0.577 G loss:-2.291\n",
      "Epoch:  0072 D loss:-0.6909 G loss:-2.164\n",
      "Epoch:  0072 D loss:-0.7637 G loss:-2.129\n",
      "Epoch:  0072 D loss:-0.6374 G loss:-2.199\n",
      "Epoch:  0072 D loss:-0.7949 G loss:-2.137\n",
      "Epoch:  0072 D loss:-0.7115 G loss:-1.925\n",
      "Epoch:  0072 D loss:-0.7821 G loss:-1.985\n",
      "Epoch:  0072 D loss:-0.6463 G loss:-2.049\n",
      "Epoch:  0072 D loss:-0.6939 G loss:-1.897\n",
      "Epoch:  0072 D loss:-0.721 G loss:-1.971\n",
      "Epoch:  0072 D loss:-0.7264 G loss:-1.657\n",
      "Epoch:  0072 D loss:-0.6766 G loss:-1.937\n",
      "Epoch:  0072 D loss:-0.7085 G loss:-1.89\n",
      "Epoch:  0072 D loss:-0.7093 G loss:-2.05\n",
      "Epoch:  0072 D loss:-0.6761 G loss:-2.045\n",
      "Epoch:  0072 D loss:-0.6299 G loss:-2.209\n",
      "Epoch:  0072 D loss:-0.6777 G loss:-2.045\n",
      "Epoch:  0072 D loss:-0.8415 G loss:-1.975\n",
      "Epoch:  0072 D loss:-0.663 G loss:-1.989\n",
      "Epoch:  0072 D loss:-0.6989 G loss:-1.935\n",
      "Epoch:  0072 D loss:-0.7831 G loss:-1.833\n",
      "Epoch:  0072 D loss:-0.7427 G loss:-1.817\n",
      "Epoch:  0072 D loss:-0.703 G loss:-1.898\n",
      "Epoch:  0072 D loss:-0.7494 G loss:-2.109\n",
      "Epoch:  0072 D loss:-0.6879 G loss:-1.854\n",
      "Epoch:  0072 D loss:-0.6791 G loss:-1.929\n",
      "Epoch:  0072 D loss:-0.7443 G loss:-1.849\n",
      "Epoch:  0072 D loss:-0.9124 G loss:-2.005\n",
      "Epoch:  0072 D loss:-0.792 G loss:-2.085\n",
      "Epoch:  0072 D loss:-0.7277 G loss:-2.023\n",
      "Epoch:  0072 D loss:-0.6998 G loss:-2.011\n",
      "Epoch:  0072 D loss:-0.6433 G loss:-1.995\n",
      "Epoch:  0072 D loss:-0.74 G loss:-1.964\n",
      "Epoch:  0072 D loss:-0.8152 G loss:-1.902\n",
      "Epoch:  0072 D loss:-0.7311 G loss:-1.834\n",
      "Epoch:  0072 D loss:-0.7273 G loss:-2.069\n",
      "Epoch:  0072 D loss:-0.7099 G loss:-1.954\n",
      "Epoch:  0072 D loss:-0.8247 G loss:-2.222\n",
      "Epoch:  0072 D loss:-0.7971 G loss:-1.936\n",
      "Epoch:  0072 D loss:-0.7534 G loss:-1.799\n",
      "Epoch:  0072 D loss:-0.7375 G loss:-1.979\n",
      "Epoch:  0072 D loss:-0.7151 G loss:-2.01\n",
      "Epoch:  0072 D loss:-0.7804 G loss:-2.006\n",
      "Epoch:  0072 D loss:-0.8216 G loss:-1.859\n",
      "Epoch:  0072 D loss:-0.7263 G loss:-1.943\n",
      "Epoch:  0072 D loss:-0.6824 G loss:-2.05\n",
      "Epoch:  0072 D loss:-0.7229 G loss:-2.12\n",
      "Epoch:  0072 D loss:-0.6835 G loss:-2.056\n",
      "Epoch:  0072 D loss:-0.6829 G loss:-1.941\n",
      "Epoch:  0072 D loss:-0.7078 G loss:-2.04\n",
      "Epoch:  0072 D loss:-0.8533 G loss:-2.022\n",
      "Epoch:  0072 D loss:-0.7217 G loss:-1.84\n",
      "Epoch:  0072 D loss:-0.7682 G loss:-1.932\n",
      "Epoch:  0072 D loss:-0.6917 G loss:-1.972\n",
      "Epoch:  0072 D loss:-0.8161 G loss:-1.853\n",
      "Epoch:  0072 D loss:-0.7749 G loss:-1.919\n",
      "Epoch:  0072 D loss:-0.7361 G loss:-2.107\n",
      "Epoch:  0072 D loss:-0.7124 G loss:-2.027\n",
      "Epoch:  0072 D loss:-0.6972 G loss:-1.888\n",
      "Epoch:  0072 D loss:-0.7595 G loss:-1.904\n",
      "Epoch:  0072 D loss:-0.6852 G loss:-2.427\n",
      "Epoch:  0072 D loss:-0.7325 G loss:-2.099\n",
      "Epoch:  0072 D loss:-0.7137 G loss:-2.112\n",
      "Epoch:  0072 D loss:-0.9049 G loss:-1.838\n",
      "Epoch:  0072 D loss:-0.7793 G loss:-1.769\n",
      "Epoch:  0072 D loss:-0.7443 G loss:-1.992\n",
      "Epoch:  0072 D loss:-0.6685 G loss:-2.13\n",
      "Epoch:  0072 D loss:-0.7661 G loss:-2.034\n",
      "Epoch:  0072 D loss:-0.6973 G loss:-2.134\n",
      "Epoch:  0073 D loss:-0.7235 G loss:-2.014\n",
      "Epoch:  0073 D loss:-0.6652 G loss:-1.934\n",
      "Epoch:  0073 D loss:-0.6664 G loss:-1.871\n",
      "Epoch:  0073 D loss:-0.7569 G loss:-1.897\n",
      "Epoch:  0073 D loss:-0.7767 G loss:-1.826\n",
      "Epoch:  0073 D loss:-0.5764 G loss:-2.158\n",
      "Epoch:  0073 D loss:-0.6828 G loss:-2.143\n",
      "Epoch:  0073 D loss:-0.8595 G loss:-2.107\n",
      "Epoch:  0073 D loss:-0.773 G loss:-2.162\n",
      "Epoch:  0073 D loss:-0.7393 G loss:-1.956\n",
      "Epoch:  0073 D loss:-0.8965 G loss:-1.798\n",
      "Epoch:  0073 D loss:-0.6947 G loss:-2.118\n",
      "Epoch:  0073 D loss:-0.6991 G loss:-2.118\n",
      "Epoch:  0073 D loss:-0.7819 G loss:-1.864\n",
      "Epoch:  0073 D loss:-0.8361 G loss:-1.876\n",
      "Epoch:  0073 D loss:-0.8938 G loss:-1.995\n",
      "Epoch:  0073 D loss:-0.8036 G loss:-1.903\n",
      "Epoch:  0073 D loss:-0.7433 G loss:-2.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0073 D loss:-0.7368 G loss:-1.764\n",
      "Epoch:  0073 D loss:-0.7057 G loss:-1.935\n",
      "Epoch:  0073 D loss:-0.6082 G loss:-2.135\n",
      "Epoch:  0073 D loss:-0.6957 G loss:-2.028\n",
      "Epoch:  0073 D loss:-0.7427 G loss:-2.053\n",
      "Epoch:  0073 D loss:-0.7996 G loss:-2.028\n",
      "Epoch:  0073 D loss:-0.6703 G loss:-1.76\n",
      "Epoch:  0073 D loss:-0.8317 G loss:-1.998\n",
      "Epoch:  0073 D loss:-0.788 G loss:-2.107\n",
      "Epoch:  0073 D loss:-0.571 G loss:-2.136\n",
      "Epoch:  0073 D loss:-0.7241 G loss:-1.993\n",
      "Epoch:  0073 D loss:-0.7342 G loss:-2.127\n",
      "Epoch:  0073 D loss:-0.7209 G loss:-2.005\n",
      "Epoch:  0073 D loss:-0.6058 G loss:-2.13\n",
      "Epoch:  0073 D loss:-0.7243 G loss:-1.982\n",
      "Epoch:  0073 D loss:-0.6929 G loss:-2.072\n",
      "Epoch:  0073 D loss:-0.6556 G loss:-1.912\n",
      "Epoch:  0073 D loss:-0.715 G loss:-1.884\n",
      "Epoch:  0073 D loss:-0.8257 G loss:-1.946\n",
      "Epoch:  0073 D loss:-0.6608 G loss:-1.968\n",
      "Epoch:  0073 D loss:-0.7463 G loss:-2.099\n",
      "Epoch:  0073 D loss:-0.6316 G loss:-2.198\n",
      "Epoch:  0073 D loss:-0.6361 G loss:-2.147\n",
      "Epoch:  0073 D loss:-0.7257 G loss:-1.966\n",
      "Epoch:  0073 D loss:-0.5687 G loss:-2.209\n",
      "Epoch:  0073 D loss:-0.761 G loss:-2.067\n",
      "Epoch:  0073 D loss:-0.7809 G loss:-1.96\n",
      "Epoch:  0073 D loss:-0.646 G loss:-2.216\n",
      "Epoch:  0073 D loss:-0.6913 G loss:-1.987\n",
      "Epoch:  0073 D loss:-0.5946 G loss:-2.283\n",
      "Epoch:  0073 D loss:-0.7094 G loss:-1.906\n",
      "Epoch:  0073 D loss:-0.7117 G loss:-1.863\n",
      "Epoch:  0073 D loss:-0.5906 G loss:-2.185\n",
      "Epoch:  0073 D loss:-0.7337 G loss:-2.141\n",
      "Epoch:  0073 D loss:-0.7012 G loss:-2.137\n",
      "Epoch:  0073 D loss:-0.8311 G loss:-1.925\n",
      "Epoch:  0073 D loss:-0.7044 G loss:-2.19\n",
      "Epoch:  0073 D loss:-0.6957 G loss:-1.988\n",
      "Epoch:  0073 D loss:-0.7452 G loss:-1.988\n",
      "Epoch:  0073 D loss:-0.6616 G loss:-2.109\n",
      "Epoch:  0073 D loss:-0.6598 G loss:-2.288\n",
      "Epoch:  0073 D loss:-0.5779 G loss:-2.409\n",
      "Epoch:  0073 D loss:-0.5732 G loss:-2.022\n",
      "Epoch:  0073 D loss:-0.617 G loss:-2.281\n",
      "Epoch:  0073 D loss:-0.5969 G loss:-2.427\n",
      "Epoch:  0073 D loss:-0.5628 G loss:-2.394\n",
      "Epoch:  0073 D loss:-0.701 G loss:-2.225\n",
      "Epoch:  0073 D loss:-0.7508 G loss:-2.045\n",
      "Epoch:  0073 D loss:-0.6861 G loss:-2.034\n",
      "Epoch:  0073 D loss:-0.5983 G loss:-2.11\n",
      "Epoch:  0073 D loss:-0.7394 G loss:-2.056\n",
      "Epoch:  0073 D loss:-0.9089 G loss:-1.789\n",
      "Epoch:  0073 D loss:-0.7453 G loss:-1.692\n",
      "Epoch:  0073 D loss:-0.6826 G loss:-1.738\n",
      "Epoch:  0073 D loss:-0.7763 G loss:-1.781\n",
      "Epoch:  0073 D loss:-0.673 G loss:-1.827\n",
      "Epoch:  0073 D loss:-0.6889 G loss:-1.978\n",
      "Epoch:  0073 D loss:-0.556 G loss:-2.292\n",
      "Epoch:  0073 D loss:-0.5833 G loss:-2.11\n",
      "Epoch:  0073 D loss:-0.5844 G loss:-2.414\n",
      "Epoch:  0073 D loss:-0.7257 G loss:-2.59\n",
      "Epoch:  0073 D loss:-0.6086 G loss:-2.251\n",
      "Epoch:  0073 D loss:-0.6068 G loss:-2.255\n",
      "Epoch:  0073 D loss:-0.6543 G loss:-2.36\n",
      "Epoch:  0073 D loss:-0.8181 G loss:-1.778\n",
      "Epoch:  0073 D loss:-0.5871 G loss:-2.11\n",
      "Epoch:  0073 D loss:-0.7034 G loss:-2.045\n",
      "Epoch:  0073 D loss:-0.7001 G loss:-1.86\n",
      "Epoch:  0073 D loss:-0.7555 G loss:-1.892\n",
      "Epoch:  0073 D loss:-0.7256 G loss:-1.685\n",
      "Epoch:  0073 D loss:-0.663 G loss:-1.803\n",
      "Epoch:  0073 D loss:-0.5911 G loss:-2.06\n",
      "Epoch:  0073 D loss:-0.8113 G loss:-1.804\n",
      "Epoch:  0073 D loss:-0.5684 G loss:-2.082\n",
      "Epoch:  0073 D loss:-0.6734 G loss:-2.312\n",
      "Epoch:  0073 D loss:-0.6341 G loss:-2.169\n",
      "Epoch:  0073 D loss:-0.5809 G loss:-2.215\n",
      "Epoch:  0073 D loss:-0.785 G loss:-2.16\n",
      "Epoch:  0073 D loss:-0.584 G loss:-2.006\n",
      "Epoch:  0073 D loss:-0.802 G loss:-1.953\n",
      "Epoch:  0073 D loss:-0.7958 G loss:-2.067\n",
      "Epoch:  0073 D loss:-0.6024 G loss:-2.363\n",
      "Epoch:  0073 D loss:-0.6981 G loss:-2.136\n",
      "Epoch:  0073 D loss:-0.8514 G loss:-2.052\n",
      "Epoch:  0073 D loss:-0.8478 G loss:-1.96\n",
      "Epoch:  0073 D loss:-0.7649 G loss:-1.806\n",
      "Epoch:  0073 D loss:-0.7384 G loss:-1.967\n",
      "Epoch:  0073 D loss:-0.6694 G loss:-2.002\n",
      "Epoch:  0073 D loss:-0.6292 G loss:-1.893\n",
      "Epoch:  0073 D loss:-0.8368 G loss:-1.793\n",
      "Epoch:  0073 D loss:-0.6991 G loss:-1.923\n",
      "Epoch:  0073 D loss:-0.625 G loss:-1.943\n",
      "Epoch:  0073 D loss:-0.8078 G loss:-1.778\n",
      "Epoch:  0073 D loss:-0.7768 G loss:-1.964\n",
      "Epoch:  0073 D loss:-0.8063 G loss:-2.016\n",
      "Epoch:  0073 D loss:-0.757 G loss:-2.063\n",
      "Epoch:  0073 D loss:-0.7379 G loss:-2.005\n",
      "Epoch:  0073 D loss:-0.6979 G loss:-2.04\n",
      "Epoch:  0073 D loss:-0.716 G loss:-2.076\n",
      "Epoch:  0073 D loss:-0.6152 G loss:-2.078\n",
      "Epoch:  0073 D loss:-0.7575 G loss:-2.133\n",
      "Epoch:  0073 D loss:-0.8331 G loss:-1.908\n",
      "Epoch:  0073 D loss:-0.7607 G loss:-1.978\n",
      "Epoch:  0073 D loss:-0.8765 G loss:-1.776\n",
      "Epoch:  0073 D loss:-0.7174 G loss:-1.884\n",
      "Epoch:  0073 D loss:-0.7915 G loss:-1.865\n",
      "Epoch:  0073 D loss:-0.7974 G loss:-1.837\n",
      "Epoch:  0073 D loss:-0.8378 G loss:-1.872\n",
      "Epoch:  0073 D loss:-0.6837 G loss:-1.816\n",
      "Epoch:  0073 D loss:-0.7092 G loss:-2.18\n",
      "Epoch:  0073 D loss:-0.7308 G loss:-2.039\n",
      "Epoch:  0073 D loss:-0.78 G loss:-1.933\n",
      "Epoch:  0073 D loss:-0.8886 G loss:-1.82\n",
      "Epoch:  0073 D loss:-0.7453 G loss:-2.182\n",
      "Epoch:  0073 D loss:-1.025 G loss:-1.973\n",
      "Epoch:  0073 D loss:-0.8352 G loss:-1.986\n",
      "Epoch:  0073 D loss:-0.8433 G loss:-1.816\n",
      "Epoch:  0073 D loss:-0.6712 G loss:-1.838\n",
      "Epoch:  0073 D loss:-0.8137 G loss:-1.817\n",
      "Epoch:  0073 D loss:-0.8105 G loss:-1.811\n",
      "Epoch:  0073 D loss:-0.8911 G loss:-1.703\n",
      "Epoch:  0073 D loss:-0.7514 G loss:-1.93\n",
      "Epoch:  0073 D loss:-0.8115 G loss:-1.907\n",
      "Epoch:  0073 D loss:-0.7302 G loss:-1.732\n",
      "Epoch:  0073 D loss:-0.8167 G loss:-1.971\n",
      "Epoch:  0073 D loss:-0.7476 G loss:-2.131\n",
      "Epoch:  0073 D loss:-0.635 G loss:-2.052\n",
      "Epoch:  0073 D loss:-0.7276 G loss:-1.876\n",
      "Epoch:  0073 D loss:-0.5974 G loss:-1.959\n",
      "Epoch:  0073 D loss:-0.7045 G loss:-2.086\n",
      "Epoch:  0073 D loss:-0.8413 G loss:-2.016\n",
      "Epoch:  0073 D loss:-0.7568 G loss:-2.018\n",
      "Epoch:  0073 D loss:-0.7737 G loss:-1.787\n",
      "Epoch:  0073 D loss:-0.8636 G loss:-1.775\n",
      "Epoch:  0073 D loss:-0.7256 G loss:-1.986\n",
      "Epoch:  0073 D loss:-0.637 G loss:-2.072\n",
      "Epoch:  0073 D loss:-0.8163 G loss:-1.827\n",
      "Epoch:  0073 D loss:-0.6465 G loss:-1.946\n",
      "Epoch:  0073 D loss:-0.7496 G loss:-2.106\n",
      "Epoch:  0073 D loss:-0.635 G loss:-1.934\n",
      "Epoch:  0073 D loss:-0.7255 G loss:-1.787\n",
      "Epoch:  0073 D loss:-0.6315 G loss:-2.043\n",
      "Epoch:  0073 D loss:-0.7725 G loss:-1.881\n",
      "Epoch:  0073 D loss:-0.6542 G loss:-2.034\n",
      "Epoch:  0073 D loss:-0.6954 G loss:-2.071\n",
      "Epoch:  0073 D loss:-0.7208 G loss:-2.004\n",
      "Epoch:  0073 D loss:-0.565 G loss:-2.274\n",
      "Epoch:  0073 D loss:-0.6059 G loss:-2.205\n",
      "Epoch:  0073 D loss:-0.8314 G loss:-2.148\n",
      "Epoch:  0073 D loss:-0.6946 G loss:-2.139\n",
      "Epoch:  0073 D loss:-0.6425 G loss:-1.969\n",
      "Epoch:  0073 D loss:-0.8516 G loss:-1.922\n",
      "Epoch:  0073 D loss:-0.6647 G loss:-1.964\n",
      "Epoch:  0073 D loss:-0.6882 G loss:-1.987\n",
      "Epoch:  0073 D loss:-0.8302 G loss:-1.918\n",
      "Epoch:  0073 D loss:-0.7419 G loss:-1.647\n",
      "Epoch:  0073 D loss:-0.6305 G loss:-2.102\n",
      "Epoch:  0073 D loss:-0.7065 G loss:-1.759\n",
      "Epoch:  0073 D loss:-0.7294 G loss:-1.912\n",
      "Epoch:  0073 D loss:-0.7313 G loss:-1.966\n",
      "Epoch:  0073 D loss:-0.7828 G loss:-1.898\n",
      "Epoch:  0073 D loss:-0.6729 G loss:-1.961\n",
      "Epoch:  0073 D loss:-0.6127 G loss:-2.05\n",
      "Epoch:  0073 D loss:-0.6161 G loss:-2.163\n",
      "Epoch:  0073 D loss:-0.6298 G loss:-2.222\n",
      "Epoch:  0073 D loss:-0.7922 G loss:-2.22\n",
      "Epoch:  0073 D loss:-0.6283 G loss:-2.128\n",
      "Epoch:  0073 D loss:-0.5912 G loss:-2.129\n",
      "Epoch:  0073 D loss:-0.5146 G loss:-2.088\n",
      "Epoch:  0073 D loss:-0.6069 G loss:-2.133\n",
      "Epoch:  0073 D loss:-0.658 G loss:-2.027\n",
      "Epoch:  0073 D loss:-0.6182 G loss:-2.039\n",
      "Epoch:  0073 D loss:-0.7179 G loss:-2.011\n",
      "Epoch:  0073 D loss:-0.5624 G loss:-2.063\n",
      "Epoch:  0073 D loss:-0.5712 G loss:-2.102\n",
      "Epoch:  0073 D loss:-0.6346 G loss:-2.142\n",
      "Epoch:  0073 D loss:-0.6011 G loss:-2.109\n",
      "Epoch:  0073 D loss:-0.68 G loss:-2.216\n",
      "Epoch:  0073 D loss:-0.7198 G loss:-2.01\n",
      "Epoch:  0073 D loss:-0.5689 G loss:-2.051\n",
      "Epoch:  0073 D loss:-0.6654 G loss:-2.208\n",
      "Epoch:  0073 D loss:-0.6441 G loss:-2.244\n",
      "Epoch:  0073 D loss:-0.7466 G loss:-2.15\n",
      "Epoch:  0073 D loss:-0.6179 G loss:-2.326\n",
      "Epoch:  0073 D loss:-0.6292 G loss:-2.173\n",
      "Epoch:  0073 D loss:-0.6899 G loss:-2.14\n",
      "Epoch:  0073 D loss:-0.7655 G loss:-1.965\n",
      "Epoch:  0073 D loss:-0.5684 G loss:-2.054\n",
      "Epoch:  0073 D loss:-0.6585 G loss:-1.834\n",
      "Epoch:  0073 D loss:-0.7208 G loss:-1.897\n",
      "Epoch:  0073 D loss:-0.6708 G loss:-1.903\n",
      "Epoch:  0073 D loss:-0.719 G loss:-1.828\n",
      "Epoch:  0073 D loss:-0.6768 G loss:-1.967\n",
      "Epoch:  0073 D loss:-0.7229 G loss:-1.873\n",
      "Epoch:  0073 D loss:-0.6765 G loss:-2.041\n",
      "Epoch:  0073 D loss:-0.7754 G loss:-2.012\n",
      "Epoch:  0073 D loss:-0.6696 G loss:-2.112\n",
      "Epoch:  0073 D loss:-0.6067 G loss:-2.047\n",
      "Epoch:  0073 D loss:-0.745 G loss:-2.096\n",
      "Epoch:  0073 D loss:-0.6697 G loss:-2.312\n",
      "Epoch:  0073 D loss:-0.5961 G loss:-2.177\n",
      "Epoch:  0073 D loss:-0.6767 G loss:-1.984\n",
      "Epoch:  0073 D loss:-0.5991 G loss:-2.183\n",
      "Epoch:  0073 D loss:-0.6927 G loss:-2.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0073 D loss:-0.7322 G loss:-2.054\n",
      "Epoch:  0073 D loss:-0.7105 G loss:-2.161\n",
      "Epoch:  0073 D loss:-0.5883 G loss:-2.092\n",
      "Epoch:  0073 D loss:-0.7925 G loss:-2.022\n",
      "Epoch:  0073 D loss:-0.6527 G loss:-2.21\n",
      "Epoch:  0073 D loss:-0.7716 G loss:-1.871\n",
      "Epoch:  0073 D loss:-0.6308 G loss:-2.267\n",
      "Epoch:  0073 D loss:-0.8688 G loss:-2.112\n",
      "Epoch:  0073 D loss:-0.6742 G loss:-2.058\n",
      "Epoch:  0073 D loss:-0.8368 G loss:-1.677\n",
      "Epoch:  0073 D loss:-0.6618 G loss:-1.917\n",
      "Epoch:  0073 D loss:-0.7914 G loss:-1.825\n",
      "Epoch:  0073 D loss:-0.6744 G loss:-1.862\n",
      "Epoch:  0073 D loss:-0.6692 G loss:-1.949\n",
      "Epoch:  0073 D loss:-0.8211 G loss:-1.769\n",
      "Epoch:  0073 D loss:-0.6605 G loss:-2.135\n",
      "Epoch:  0073 D loss:-0.6499 G loss:-2.077\n",
      "Epoch:  0073 D loss:-0.6707 G loss:-1.997\n",
      "Epoch:  0073 D loss:-0.8484 G loss:-1.84\n",
      "Epoch:  0073 D loss:-0.9041 G loss:-2.035\n",
      "Epoch:  0073 D loss:-0.7666 G loss:-1.852\n",
      "Epoch:  0073 D loss:-0.8142 G loss:-1.849\n",
      "Epoch:  0073 D loss:-0.7182 G loss:-2.058\n",
      "Epoch:  0073 D loss:-0.9208 G loss:-1.981\n",
      "Epoch:  0073 D loss:-0.8396 G loss:-1.809\n",
      "Epoch:  0073 D loss:-0.6491 G loss:-1.925\n",
      "Epoch:  0073 D loss:-0.8783 G loss:-1.923\n",
      "Epoch:  0073 D loss:-0.8094 G loss:-1.998\n",
      "Epoch:  0073 D loss:-0.7525 G loss:-1.959\n",
      "Epoch:  0073 D loss:-0.8945 G loss:-1.86\n",
      "Epoch:  0073 D loss:-0.74 G loss:-1.883\n",
      "Epoch:  0073 D loss:-0.6419 G loss:-1.912\n",
      "Epoch:  0073 D loss:-0.6906 G loss:-2.086\n",
      "Epoch:  0073 D loss:-0.8459 G loss:-2.093\n",
      "Epoch:  0073 D loss:-0.6266 G loss:-2.168\n",
      "Epoch:  0073 D loss:-0.6959 G loss:-2.078\n",
      "Epoch:  0073 D loss:-0.6727 G loss:-1.995\n",
      "Epoch:  0073 D loss:-0.7606 G loss:-1.97\n",
      "Epoch:  0073 D loss:-0.7501 G loss:-1.947\n",
      "Epoch:  0073 D loss:-0.6637 G loss:-2.217\n",
      "Epoch:  0073 D loss:-0.687 G loss:-2.348\n",
      "Epoch:  0073 D loss:-0.7248 G loss:-2.046\n",
      "Epoch:  0073 D loss:-0.6764 G loss:-1.952\n",
      "Epoch:  0073 D loss:-0.7508 G loss:-2.061\n",
      "Epoch:  0073 D loss:-0.5912 G loss:-1.91\n",
      "Epoch:  0073 D loss:-0.8705 G loss:-1.849\n",
      "Epoch:  0073 D loss:-0.7111 G loss:-1.761\n",
      "Epoch:  0073 D loss:-0.7945 G loss:-1.94\n",
      "Epoch:  0073 D loss:-0.8183 G loss:-1.934\n",
      "Epoch:  0073 D loss:-0.7577 G loss:-1.861\n",
      "Epoch:  0073 D loss:-0.8678 G loss:-1.973\n",
      "Epoch:  0073 D loss:-0.6837 G loss:-2.09\n",
      "Epoch:  0073 D loss:-0.882 G loss:-1.931\n",
      "Epoch:  0073 D loss:-0.8384 G loss:-1.933\n",
      "Epoch:  0073 D loss:-0.7529 G loss:-2.042\n",
      "Epoch:  0073 D loss:-0.8573 G loss:-1.972\n",
      "Epoch:  0073 D loss:-0.637 G loss:-2.139\n",
      "Epoch:  0073 D loss:-0.6923 G loss:-2.161\n",
      "Epoch:  0073 D loss:-0.7025 G loss:-2.027\n",
      "Epoch:  0073 D loss:-0.6082 G loss:-2.183\n",
      "Epoch:  0073 D loss:-0.6231 G loss:-2.136\n",
      "Epoch:  0073 D loss:-0.6878 G loss:-2.218\n",
      "Epoch:  0073 D loss:-0.6477 G loss:-2.081\n",
      "Epoch:  0073 D loss:-0.7584 G loss:-1.957\n",
      "Epoch:  0073 D loss:-0.7259 G loss:-2.027\n",
      "Epoch:  0073 D loss:-0.7492 G loss:-2.105\n",
      "Epoch:  0073 D loss:-0.7738 G loss:-2.096\n",
      "Epoch:  0073 D loss:-0.5888 G loss:-2.207\n",
      "Epoch:  0073 D loss:-0.8655 G loss:-2.222\n",
      "Epoch:  0073 D loss:-0.5644 G loss:-2.185\n",
      "Epoch:  0073 D loss:-0.5636 G loss:-2.109\n",
      "Epoch:  0073 D loss:-0.5874 G loss:-2.089\n",
      "Epoch:  0073 D loss:-0.7006 G loss:-2.236\n",
      "Epoch:  0073 D loss:-0.5877 G loss:-2.218\n",
      "Epoch:  0073 D loss:-0.6947 G loss:-2.046\n",
      "Epoch:  0073 D loss:-0.6037 G loss:-2.065\n",
      "Epoch:  0073 D loss:-0.6311 G loss:-2.041\n",
      "Epoch:  0073 D loss:-0.8069 G loss:-1.877\n",
      "Epoch:  0073 D loss:-0.7818 G loss:-2.033\n",
      "Epoch:  0073 D loss:-0.7662 G loss:-1.944\n",
      "Epoch:  0073 D loss:-0.7532 G loss:-1.925\n",
      "Epoch:  0073 D loss:-0.7399 G loss:-2.055\n",
      "Epoch:  0073 D loss:-0.7698 G loss:-2.02\n",
      "Epoch:  0073 D loss:-0.7044 G loss:-2.163\n",
      "Epoch:  0073 D loss:-0.784 G loss:-2.084\n",
      "Epoch:  0073 D loss:-0.6743 G loss:-2.259\n",
      "Epoch:  0073 D loss:-0.6828 G loss:-2.246\n",
      "Epoch:  0073 D loss:-0.7225 G loss:-1.949\n",
      "Epoch:  0073 D loss:-0.7518 G loss:-2.026\n",
      "Epoch:  0073 D loss:-0.5767 G loss:-1.825\n",
      "Epoch:  0073 D loss:-0.7754 G loss:-1.92\n",
      "Epoch:  0073 D loss:-0.606 G loss:-2.116\n",
      "Epoch:  0073 D loss:-0.6797 G loss:-1.98\n",
      "Epoch:  0073 D loss:-0.5593 G loss:-2.086\n",
      "Epoch:  0073 D loss:-0.5888 G loss:-2.157\n",
      "Epoch:  0073 D loss:-0.7039 G loss:-2.359\n",
      "Epoch:  0073 D loss:-0.6352 G loss:-2.296\n",
      "Epoch:  0073 D loss:-0.5581 G loss:-2.254\n",
      "Epoch:  0073 D loss:-0.6832 G loss:-2.114\n",
      "Epoch:  0073 D loss:-0.7473 G loss:-2.167\n",
      "Epoch:  0073 D loss:-0.6123 G loss:-2.167\n",
      "Epoch:  0073 D loss:-0.7246 G loss:-2.203\n",
      "Epoch:  0073 D loss:-0.696 G loss:-1.938\n",
      "Epoch:  0073 D loss:-0.668 G loss:-2.092\n",
      "Epoch:  0073 D loss:-0.6484 G loss:-2.072\n",
      "Epoch:  0073 D loss:-0.6069 G loss:-2.175\n",
      "Epoch:  0073 D loss:-0.7366 G loss:-1.901\n",
      "Epoch:  0073 D loss:-0.6469 G loss:-2.02\n",
      "Epoch:  0073 D loss:-0.7759 G loss:-1.935\n",
      "Epoch:  0073 D loss:-0.6291 G loss:-2.186\n",
      "Epoch:  0073 D loss:-0.6908 G loss:-1.993\n",
      "Epoch:  0073 D loss:-0.5696 G loss:-1.992\n",
      "Epoch:  0073 D loss:-0.7975 G loss:-1.887\n",
      "Epoch:  0073 D loss:-0.7663 G loss:-2.176\n",
      "Epoch:  0073 D loss:-0.6858 G loss:-2.104\n",
      "Epoch:  0073 D loss:-0.6588 G loss:-2.115\n",
      "Epoch:  0073 D loss:-0.7194 G loss:-1.896\n",
      "Epoch:  0073 D loss:-0.6293 G loss:-2.094\n",
      "Epoch:  0073 D loss:-0.6384 G loss:-2.089\n",
      "Epoch:  0073 D loss:-0.7446 G loss:-1.935\n",
      "Epoch:  0073 D loss:-0.6805 G loss:-2.059\n",
      "Epoch:  0073 D loss:-0.8461 G loss:-1.854\n",
      "Epoch:  0073 D loss:-0.8321 G loss:-1.993\n",
      "Epoch:  0073 D loss:-0.6865 G loss:-1.9\n",
      "Epoch:  0073 D loss:-0.7929 G loss:-1.991\n",
      "Epoch:  0073 D loss:-0.7949 G loss:-2.168\n",
      "Epoch:  0073 D loss:-0.618 G loss:-2.084\n",
      "Epoch:  0073 D loss:-0.7112 G loss:-1.905\n",
      "Epoch:  0073 D loss:-0.7092 G loss:-2.155\n",
      "Epoch:  0073 D loss:-0.7262 G loss:-2.09\n",
      "Epoch:  0073 D loss:-0.85 G loss:-1.988\n",
      "Epoch:  0073 D loss:-0.7019 G loss:-1.963\n",
      "Epoch:  0073 D loss:-0.5894 G loss:-2.017\n",
      "Epoch:  0073 D loss:-0.711 G loss:-1.915\n",
      "Epoch:  0073 D loss:-0.7412 G loss:-1.904\n",
      "Epoch:  0073 D loss:-0.7333 G loss:-1.948\n",
      "Epoch:  0073 D loss:-0.7477 G loss:-1.959\n",
      "Epoch:  0073 D loss:-0.683 G loss:-2.043\n",
      "Epoch:  0073 D loss:-0.9672 G loss:-2.053\n",
      "Epoch:  0073 D loss:-0.7717 G loss:-2.116\n",
      "Epoch:  0073 D loss:-0.6919 G loss:-1.983\n",
      "Epoch:  0073 D loss:-0.72 G loss:-1.94\n",
      "Epoch:  0073 D loss:-0.7071 G loss:-1.901\n",
      "Epoch:  0073 D loss:-0.7146 G loss:-2.076\n",
      "Epoch:  0073 D loss:-0.7675 G loss:-2.095\n",
      "Epoch:  0073 D loss:-0.7337 G loss:-1.957\n",
      "Epoch:  0073 D loss:-0.6929 G loss:-1.935\n",
      "Epoch:  0073 D loss:-0.8941 G loss:-1.857\n",
      "Epoch:  0073 D loss:-0.7819 G loss:-2.031\n",
      "Epoch:  0073 D loss:-0.6206 G loss:-2.278\n",
      "Epoch:  0073 D loss:-0.8337 G loss:-2.223\n",
      "Epoch:  0073 D loss:-0.5764 G loss:-2.14\n",
      "Epoch:  0073 D loss:-0.7077 G loss:-2.018\n",
      "Epoch:  0073 D loss:-0.6125 G loss:-2.157\n",
      "Epoch:  0073 D loss:-0.832 G loss:-1.947\n",
      "Epoch:  0073 D loss:-0.7192 G loss:-2.062\n",
      "Epoch:  0073 D loss:-0.7119 G loss:-2.02\n",
      "Epoch:  0073 D loss:-0.6816 G loss:-1.993\n",
      "Epoch:  0073 D loss:-0.7915 G loss:-2.001\n",
      "Epoch:  0073 D loss:-0.7974 G loss:-1.977\n",
      "Epoch:  0073 D loss:-0.7847 G loss:-1.854\n",
      "Epoch:  0073 D loss:-0.7077 G loss:-1.825\n",
      "Epoch:  0073 D loss:-0.7608 G loss:-2.132\n",
      "Epoch:  0073 D loss:-0.7003 G loss:-2.114\n",
      "Epoch:  0073 D loss:-0.637 G loss:-2.15\n",
      "Epoch:  0073 D loss:-0.6491 G loss:-2.398\n",
      "Epoch:  0073 D loss:-0.7312 G loss:-1.976\n",
      "Epoch:  0073 D loss:-0.6362 G loss:-2.109\n",
      "Epoch:  0073 D loss:-0.7773 G loss:-1.943\n",
      "Epoch:  0073 D loss:-0.8741 G loss:-1.826\n",
      "Epoch:  0073 D loss:-0.8279 G loss:-1.776\n",
      "Epoch:  0073 D loss:-0.7295 G loss:-2.112\n",
      "Epoch:  0073 D loss:-0.7194 G loss:-1.821\n",
      "Epoch:  0073 D loss:-0.8078 G loss:-1.929\n",
      "Epoch:  0073 D loss:-0.7943 G loss:-1.761\n",
      "Epoch:  0073 D loss:-0.7419 G loss:-2.192\n",
      "Epoch:  0073 D loss:-0.7802 G loss:-2.076\n",
      "Epoch:  0073 D loss:-0.6857 G loss:-1.912\n",
      "Epoch:  0073 D loss:-0.736 G loss:-1.955\n",
      "Epoch:  0073 D loss:-0.7004 G loss:-2.015\n",
      "Epoch:  0073 D loss:-0.6989 G loss:-2.262\n",
      "Epoch:  0073 D loss:-0.7263 G loss:-1.99\n",
      "Epoch:  0073 D loss:-0.7672 G loss:-2.256\n",
      "Epoch:  0073 D loss:-0.7812 G loss:-1.795\n",
      "Epoch:  0073 D loss:-0.6331 G loss:-2.155\n",
      "Epoch:  0073 D loss:-0.7479 G loss:-2.163\n",
      "Epoch:  0073 D loss:-0.6367 G loss:-2.12\n",
      "Epoch:  0073 D loss:-0.7074 G loss:-2.229\n",
      "Epoch:  0073 D loss:-0.6191 G loss:-2.099\n",
      "Epoch:  0073 D loss:-0.6988 G loss:-2.218\n",
      "Epoch:  0073 D loss:-0.7071 G loss:-2.221\n",
      "Epoch:  0073 D loss:-0.8503 G loss:-2.057\n",
      "Epoch:  0073 D loss:-0.8122 G loss:-1.934\n",
      "Epoch:  0073 D loss:-0.8156 G loss:-2.098\n",
      "Epoch:  0073 D loss:-0.7364 G loss:-2.054\n",
      "Epoch:  0073 D loss:-0.5295 G loss:-2.128\n",
      "Epoch:  0073 D loss:-0.6871 G loss:-1.951\n",
      "Epoch:  0073 D loss:-0.6282 G loss:-2.102\n",
      "Epoch:  0073 D loss:-0.5742 G loss:-2.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0073 D loss:-0.7702 G loss:-1.974\n",
      "Epoch:  0073 D loss:-0.6666 G loss:-2.089\n",
      "Epoch:  0073 D loss:-0.8275 G loss:-2.158\n",
      "Epoch:  0073 D loss:-0.7588 G loss:-2.063\n",
      "Epoch:  0073 D loss:-0.7024 G loss:-2.08\n",
      "Epoch:  0073 D loss:-0.6987 G loss:-2.333\n",
      "Epoch:  0073 D loss:-0.6937 G loss:-2.134\n",
      "Epoch:  0073 D loss:-0.6469 G loss:-2.249\n",
      "Epoch:  0073 D loss:-0.6907 G loss:-1.873\n",
      "Epoch:  0073 D loss:-0.6613 G loss:-2.186\n",
      "Epoch:  0073 D loss:-0.5478 G loss:-2.091\n",
      "Epoch:  0073 D loss:-0.627 G loss:-1.916\n",
      "Epoch:  0073 D loss:-0.7297 G loss:-2.04\n",
      "Epoch:  0073 D loss:-0.5903 G loss:-2.193\n",
      "Epoch:  0073 D loss:-0.6925 G loss:-2.019\n",
      "Epoch:  0073 D loss:-0.6617 G loss:-2.049\n",
      "Epoch:  0073 D loss:-0.6112 G loss:-2.251\n",
      "Epoch:  0073 D loss:-0.7182 G loss:-2.081\n",
      "Epoch:  0073 D loss:-0.6844 G loss:-1.91\n",
      "Epoch:  0073 D loss:-0.725 G loss:-2.088\n",
      "Epoch:  0073 D loss:-0.6891 G loss:-2.064\n",
      "Epoch:  0073 D loss:-0.7558 G loss:-2.055\n",
      "Epoch:  0073 D loss:-0.7364 G loss:-2.051\n",
      "Epoch:  0073 D loss:-0.6813 G loss:-2.033\n",
      "Epoch:  0073 D loss:-0.6917 G loss:-1.98\n",
      "Epoch:  0073 D loss:-0.5873 G loss:-2.127\n",
      "Epoch:  0073 D loss:-0.6436 G loss:-1.934\n",
      "Epoch:  0073 D loss:-0.6523 G loss:-2.106\n",
      "Epoch:  0073 D loss:-0.5534 G loss:-2.151\n",
      "Epoch:  0073 D loss:-0.7689 G loss:-2.163\n",
      "Epoch:  0073 D loss:-0.6738 G loss:-2.122\n",
      "Epoch:  0073 D loss:-0.8184 G loss:-2.029\n",
      "Epoch:  0073 D loss:-0.6018 G loss:-2.323\n",
      "Epoch:  0073 D loss:-0.6087 G loss:-2.186\n",
      "Epoch:  0073 D loss:-0.6853 G loss:-2.299\n",
      "Epoch:  0073 D loss:-0.6321 G loss:-2.113\n",
      "Epoch:  0073 D loss:-0.6491 G loss:-2.041\n",
      "Epoch:  0073 D loss:-0.6331 G loss:-1.918\n",
      "Epoch:  0073 D loss:-0.7176 G loss:-1.954\n",
      "Epoch:  0073 D loss:-0.7421 G loss:-1.931\n",
      "Epoch:  0073 D loss:-0.743 G loss:-1.961\n",
      "Epoch:  0073 D loss:-0.7849 G loss:-2.092\n",
      "Epoch:  0073 D loss:-0.6828 G loss:-2.024\n",
      "Epoch:  0073 D loss:-0.7034 G loss:-2.104\n",
      "Epoch:  0073 D loss:-0.7246 G loss:-2.04\n",
      "Epoch:  0073 D loss:-0.7803 G loss:-2.064\n",
      "Epoch:  0073 D loss:-0.7488 G loss:-2.138\n",
      "Epoch:  0073 D loss:-0.5775 G loss:-2.015\n",
      "Epoch:  0073 D loss:-0.6828 G loss:-2.148\n",
      "Epoch:  0073 D loss:-0.676 G loss:-1.987\n",
      "Epoch:  0073 D loss:-0.544 G loss:-2.039\n",
      "Epoch:  0073 D loss:-0.6686 G loss:-2.053\n",
      "Epoch:  0073 D loss:-0.6745 G loss:-1.922\n",
      "Epoch:  0073 D loss:-0.7678 G loss:-2.079\n",
      "Epoch:  0073 D loss:-0.8309 G loss:-1.844\n",
      "Epoch:  0073 D loss:-0.775 G loss:-2.022\n",
      "Epoch:  0073 D loss:-0.6321 G loss:-2.234\n",
      "Epoch:  0073 D loss:-0.8473 G loss:-2.017\n",
      "Epoch:  0073 D loss:-0.6724 G loss:-2.108\n",
      "Epoch:  0073 D loss:-0.8458 G loss:-1.852\n",
      "Epoch:  0073 D loss:-0.7545 G loss:-2.178\n",
      "Epoch:  0073 D loss:-0.832 G loss:-1.997\n",
      "Epoch:  0073 D loss:-0.7377 G loss:-2.129\n",
      "Epoch:  0073 D loss:-0.7928 G loss:-1.779\n",
      "Epoch:  0073 D loss:-0.7397 G loss:-1.875\n",
      "Epoch:  0073 D loss:-0.6804 G loss:-1.998\n",
      "Epoch:  0073 D loss:-0.6631 G loss:-2.052\n",
      "Epoch:  0073 D loss:-0.819 G loss:-1.815\n",
      "Epoch:  0073 D loss:-0.7795 G loss:-1.952\n",
      "Epoch:  0073 D loss:-0.6813 G loss:-2.036\n",
      "Epoch:  0073 D loss:-0.5932 G loss:-2.05\n",
      "Epoch:  0073 D loss:-0.7896 G loss:-1.856\n",
      "Epoch:  0073 D loss:-0.668 G loss:-2.124\n",
      "Epoch:  0073 D loss:-0.7948 G loss:-1.728\n",
      "Epoch:  0073 D loss:-0.6875 G loss:-2.126\n",
      "Epoch:  0073 D loss:-0.7968 G loss:-2.081\n",
      "Epoch:  0073 D loss:-0.7909 G loss:-1.882\n",
      "Epoch:  0073 D loss:-0.8098 G loss:-2.044\n",
      "Epoch:  0073 D loss:-0.7893 G loss:-1.854\n",
      "Epoch:  0073 D loss:-0.7889 G loss:-1.883\n",
      "Epoch:  0073 D loss:-0.5836 G loss:-2.085\n",
      "Epoch:  0073 D loss:-0.7295 G loss:-1.912\n",
      "Epoch:  0073 D loss:-0.7257 G loss:-1.905\n",
      "Epoch:  0073 D loss:-0.8325 G loss:-1.877\n",
      "Epoch:  0073 D loss:-0.7355 G loss:-1.956\n",
      "Epoch:  0073 D loss:-0.7339 G loss:-1.963\n",
      "Epoch:  0073 D loss:-0.7198 G loss:-2.315\n",
      "Epoch:  0073 D loss:-0.8496 G loss:-1.917\n",
      "Epoch:  0073 D loss:-0.9192 G loss:-2.002\n",
      "Epoch:  0073 D loss:-0.7313 G loss:-1.943\n",
      "Epoch:  0073 D loss:-0.753 G loss:-1.859\n",
      "Epoch:  0073 D loss:-0.8756 G loss:-2.021\n",
      "Epoch:  0073 D loss:-0.8233 G loss:-2.007\n",
      "Epoch:  0073 D loss:-0.7369 G loss:-1.924\n",
      "Epoch:  0073 D loss:-0.6838 G loss:-2.287\n",
      "Epoch:  0073 D loss:-0.8339 G loss:-1.935\n",
      "Epoch:  0073 D loss:-0.7832 G loss:-1.761\n",
      "Epoch:  0073 D loss:-0.7595 G loss:-1.764\n",
      "Epoch:  0073 D loss:-0.8868 G loss:-1.852\n",
      "Epoch:  0073 D loss:-0.6924 G loss:-1.966\n",
      "Epoch:  0073 D loss:-0.7357 G loss:-1.851\n",
      "Epoch:  0073 D loss:-0.7187 G loss:-1.754\n",
      "Epoch:  0073 D loss:-0.6119 G loss:-1.955\n",
      "Epoch:  0073 D loss:-0.9201 G loss:-1.796\n",
      "Epoch:  0073 D loss:-0.7599 G loss:-1.934\n",
      "Epoch:  0073 D loss:-0.6946 G loss:-1.963\n",
      "Epoch:  0073 D loss:-0.7078 G loss:-1.989\n",
      "Epoch:  0073 D loss:-0.83 G loss:-1.883\n",
      "Epoch:  0073 D loss:-0.7136 G loss:-1.976\n",
      "Epoch:  0073 D loss:-0.7084 G loss:-1.98\n",
      "Epoch:  0073 D loss:-0.8651 G loss:-2.102\n",
      "Epoch:  0073 D loss:-0.8805 G loss:-1.874\n",
      "Epoch:  0073 D loss:-0.69 G loss:-1.95\n",
      "Epoch:  0073 D loss:-0.7652 G loss:-1.886\n",
      "Epoch:  0073 D loss:-0.7537 G loss:-1.924\n",
      "Epoch:  0073 D loss:-0.6741 G loss:-1.904\n",
      "Epoch:  0073 D loss:-0.6801 G loss:-1.996\n",
      "Epoch:  0073 D loss:-0.7097 G loss:-1.909\n",
      "Epoch:  0073 D loss:-0.7078 G loss:-2.009\n",
      "Epoch:  0073 D loss:-0.722 G loss:-1.883\n",
      "Epoch:  0073 D loss:-0.7833 G loss:-1.946\n",
      "Epoch:  0073 D loss:-0.5575 G loss:-2.163\n",
      "Epoch:  0073 D loss:-0.686 G loss:-1.876\n",
      "Epoch:  0073 D loss:-0.7377 G loss:-2.214\n",
      "Epoch:  0073 D loss:-0.7007 G loss:-1.912\n",
      "Epoch:  0073 D loss:-0.7244 G loss:-2.203\n",
      "Epoch:  0073 D loss:-0.7441 G loss:-2.207\n",
      "Epoch:  0073 D loss:-0.7433 G loss:-2.009\n",
      "Epoch:  0073 D loss:-0.6351 G loss:-2.031\n",
      "Epoch:  0074 D loss:-0.6864 G loss:-1.988\n",
      "Epoch:  0074 D loss:-0.6287 G loss:-2.113\n",
      "Epoch:  0074 D loss:-0.6759 G loss:-2.115\n",
      "Epoch:  0074 D loss:-0.6082 G loss:-2.065\n",
      "Epoch:  0074 D loss:-0.7815 G loss:-2.065\n",
      "Epoch:  0074 D loss:-0.613 G loss:-1.951\n",
      "Epoch:  0074 D loss:-0.7446 G loss:-1.906\n",
      "Epoch:  0074 D loss:-0.7058 G loss:-2.227\n",
      "Epoch:  0074 D loss:-0.7913 G loss:-2.038\n",
      "Epoch:  0074 D loss:-0.8484 G loss:-1.972\n",
      "Epoch:  0074 D loss:-0.6649 G loss:-2.05\n",
      "Epoch:  0074 D loss:-0.7869 G loss:-2.128\n",
      "Epoch:  0074 D loss:-0.7033 G loss:-1.931\n",
      "Epoch:  0074 D loss:-0.6268 G loss:-2.115\n",
      "Epoch:  0074 D loss:-0.7561 G loss:-1.905\n",
      "Epoch:  0074 D loss:-0.8708 G loss:-1.695\n",
      "Epoch:  0074 D loss:-0.6311 G loss:-2.193\n",
      "Epoch:  0074 D loss:-0.6593 G loss:-1.881\n",
      "Epoch:  0074 D loss:-0.6599 G loss:-2.137\n",
      "Epoch:  0074 D loss:-0.64 G loss:-2.043\n",
      "Epoch:  0074 D loss:-0.7129 G loss:-1.951\n",
      "Epoch:  0074 D loss:-0.5469 G loss:-2.442\n",
      "Epoch:  0074 D loss:-0.5192 G loss:-2.129\n",
      "Epoch:  0074 D loss:-0.5444 G loss:-2.178\n",
      "Epoch:  0074 D loss:-0.6757 G loss:-2.102\n",
      "Epoch:  0074 D loss:-0.7314 G loss:-2.102\n",
      "Epoch:  0074 D loss:-0.5977 G loss:-2.39\n",
      "Epoch:  0074 D loss:-0.6502 G loss:-2.153\n",
      "Epoch:  0074 D loss:-0.6918 G loss:-2.147\n",
      "Epoch:  0074 D loss:-0.686 G loss:-2.108\n",
      "Epoch:  0074 D loss:-0.8665 G loss:-2.097\n",
      "Epoch:  0074 D loss:-0.6688 G loss:-1.993\n",
      "Epoch:  0074 D loss:-0.7443 G loss:-2.133\n",
      "Epoch:  0074 D loss:-0.7528 G loss:-2.036\n",
      "Epoch:  0074 D loss:-0.7932 G loss:-2.06\n",
      "Epoch:  0074 D loss:-0.7335 G loss:-1.987\n",
      "Epoch:  0074 D loss:-0.7845 G loss:-1.971\n",
      "Epoch:  0074 D loss:-0.7071 G loss:-1.857\n",
      "Epoch:  0074 D loss:-0.6506 G loss:-1.817\n",
      "Epoch:  0074 D loss:-0.7034 G loss:-1.726\n",
      "Epoch:  0074 D loss:-0.821 G loss:-1.884\n",
      "Epoch:  0074 D loss:-0.7754 G loss:-1.979\n",
      "Epoch:  0074 D loss:-0.7009 G loss:-1.806\n",
      "Epoch:  0074 D loss:-0.7395 G loss:-1.877\n",
      "Epoch:  0074 D loss:-0.7197 G loss:-2.059\n",
      "Epoch:  0074 D loss:-0.7868 G loss:-2.16\n",
      "Epoch:  0074 D loss:-0.6869 G loss:-2.025\n",
      "Epoch:  0074 D loss:-0.7101 G loss:-2.113\n",
      "Epoch:  0074 D loss:-0.6747 G loss:-2.328\n",
      "Epoch:  0074 D loss:-0.6633 G loss:-2.142\n",
      "Epoch:  0074 D loss:-0.7366 G loss:-2.113\n",
      "Epoch:  0074 D loss:-0.652 G loss:-2.151\n",
      "Epoch:  0074 D loss:-0.732 G loss:-2.072\n",
      "Epoch:  0074 D loss:-0.6946 G loss:-1.99\n",
      "Epoch:  0074 D loss:-0.6434 G loss:-1.985\n",
      "Epoch:  0074 D loss:-0.6042 G loss:-2.202\n",
      "Epoch:  0074 D loss:-0.7094 G loss:-1.982\n",
      "Epoch:  0074 D loss:-0.5925 G loss:-2.199\n",
      "Epoch:  0074 D loss:-0.7682 G loss:-1.914\n",
      "Epoch:  0074 D loss:-0.7443 G loss:-1.792\n",
      "Epoch:  0074 D loss:-0.7335 G loss:-1.899\n",
      "Epoch:  0074 D loss:-0.6774 G loss:-1.868\n",
      "Epoch:  0074 D loss:-0.5997 G loss:-2.187\n",
      "Epoch:  0074 D loss:-0.614 G loss:-2.163\n",
      "Epoch:  0074 D loss:-0.7281 G loss:-2.077\n",
      "Epoch:  0074 D loss:-0.7415 G loss:-1.913\n",
      "Epoch:  0074 D loss:-0.6798 G loss:-2.134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0074 D loss:-0.6076 G loss:-2.151\n",
      "Epoch:  0074 D loss:-0.8209 G loss:-1.976\n",
      "Epoch:  0074 D loss:-0.7358 G loss:-1.958\n",
      "Epoch:  0074 D loss:-0.7456 G loss:-2.142\n",
      "Epoch:  0074 D loss:-0.7385 G loss:-1.936\n",
      "Epoch:  0074 D loss:-0.595 G loss:-2.216\n",
      "Epoch:  0074 D loss:-0.6949 G loss:-1.974\n",
      "Epoch:  0074 D loss:-0.7463 G loss:-1.967\n",
      "Epoch:  0074 D loss:-0.5986 G loss:-1.929\n",
      "Epoch:  0074 D loss:-0.753 G loss:-1.924\n",
      "Epoch:  0074 D loss:-0.7211 G loss:-2.009\n",
      "Epoch:  0074 D loss:-0.6605 G loss:-2.108\n",
      "Epoch:  0074 D loss:-0.786 G loss:-1.942\n",
      "Epoch:  0074 D loss:-0.6528 G loss:-1.966\n",
      "Epoch:  0074 D loss:-0.5592 G loss:-2.283\n",
      "Epoch:  0074 D loss:-0.8324 G loss:-1.983\n",
      "Epoch:  0074 D loss:-0.6241 G loss:-2.184\n",
      "Epoch:  0074 D loss:-0.6393 G loss:-1.932\n",
      "Epoch:  0074 D loss:-0.6985 G loss:-1.87\n",
      "Epoch:  0074 D loss:-0.6483 G loss:-1.915\n",
      "Epoch:  0074 D loss:-0.6863 G loss:-1.802\n",
      "Epoch:  0074 D loss:-0.7842 G loss:-1.935\n",
      "Epoch:  0074 D loss:-0.6477 G loss:-2.158\n",
      "Epoch:  0074 D loss:-0.6751 G loss:-2.051\n",
      "Epoch:  0074 D loss:-0.6662 G loss:-2.17\n",
      "Epoch:  0074 D loss:-0.5956 G loss:-2.07\n",
      "Epoch:  0074 D loss:-0.6615 G loss:-2.109\n",
      "Epoch:  0074 D loss:-0.5989 G loss:-2.076\n",
      "Epoch:  0074 D loss:-0.7569 G loss:-1.939\n",
      "Epoch:  0074 D loss:-0.7692 G loss:-2.062\n",
      "Epoch:  0074 D loss:-0.732 G loss:-1.826\n",
      "Epoch:  0074 D loss:-0.8199 G loss:-1.953\n",
      "Epoch:  0074 D loss:-0.7795 G loss:-1.991\n",
      "Epoch:  0074 D loss:-0.6835 G loss:-2.095\n",
      "Epoch:  0074 D loss:-0.6844 G loss:-1.941\n",
      "Epoch:  0074 D loss:-0.7136 G loss:-2.035\n",
      "Epoch:  0074 D loss:-0.658 G loss:-1.807\n",
      "Epoch:  0074 D loss:-0.6742 G loss:-1.969\n",
      "Epoch:  0074 D loss:-0.6639 G loss:-2.054\n",
      "Epoch:  0074 D loss:-0.5945 G loss:-2.045\n",
      "Epoch:  0074 D loss:-0.8324 G loss:-2.119\n",
      "Epoch:  0074 D loss:-0.7324 G loss:-1.979\n",
      "Epoch:  0074 D loss:-0.7521 G loss:-1.891\n",
      "Epoch:  0074 D loss:-0.7417 G loss:-1.99\n",
      "Epoch:  0074 D loss:-0.9042 G loss:-1.901\n",
      "Epoch:  0074 D loss:-0.7062 G loss:-2.027\n",
      "Epoch:  0074 D loss:-0.9245 G loss:-1.769\n",
      "Epoch:  0074 D loss:-0.8662 G loss:-1.873\n",
      "Epoch:  0074 D loss:-0.5626 G loss:-2.062\n",
      "Epoch:  0074 D loss:-0.7644 G loss:-1.884\n",
      "Epoch:  0074 D loss:-0.6003 G loss:-2.189\n",
      "Epoch:  0074 D loss:-0.5921 G loss:-1.969\n",
      "Epoch:  0074 D loss:-0.6528 G loss:-2.218\n",
      "Epoch:  0074 D loss:-0.7186 G loss:-2.011\n",
      "Epoch:  0074 D loss:-0.7849 G loss:-2.32\n",
      "Epoch:  0074 D loss:-0.671 G loss:-1.883\n",
      "Epoch:  0074 D loss:-0.5721 G loss:-2.063\n",
      "Epoch:  0074 D loss:-0.7301 G loss:-2.037\n",
      "Epoch:  0074 D loss:-0.6434 G loss:-2.16\n",
      "Epoch:  0074 D loss:-0.6628 G loss:-1.958\n",
      "Epoch:  0074 D loss:-0.6134 G loss:-2.038\n",
      "Epoch:  0074 D loss:-0.556 G loss:-2.239\n",
      "Epoch:  0074 D loss:-0.6141 G loss:-2.191\n",
      "Epoch:  0074 D loss:-0.7676 G loss:-1.874\n",
      "Epoch:  0074 D loss:-0.7898 G loss:-1.853\n",
      "Epoch:  0074 D loss:-0.6727 G loss:-1.989\n",
      "Epoch:  0074 D loss:-0.7162 G loss:-2.132\n",
      "Epoch:  0074 D loss:-0.7172 G loss:-2.09\n",
      "Epoch:  0074 D loss:-0.8789 G loss:-1.905\n",
      "Epoch:  0074 D loss:-0.6943 G loss:-2.302\n",
      "Epoch:  0074 D loss:-0.8525 G loss:-2.033\n",
      "Epoch:  0074 D loss:-0.7036 G loss:-2.349\n",
      "Epoch:  0074 D loss:-0.7124 G loss:-2.052\n",
      "Epoch:  0074 D loss:-0.695 G loss:-1.974\n",
      "Epoch:  0074 D loss:-0.808 G loss:-2.05\n",
      "Epoch:  0074 D loss:-0.6902 G loss:-1.866\n",
      "Epoch:  0074 D loss:-0.7947 G loss:-1.852\n",
      "Epoch:  0074 D loss:-0.7118 G loss:-1.795\n",
      "Epoch:  0074 D loss:-0.6893 G loss:-1.659\n",
      "Epoch:  0074 D loss:-0.9017 G loss:-1.75\n",
      "Epoch:  0074 D loss:-0.739 G loss:-1.754\n",
      "Epoch:  0074 D loss:-0.767 G loss:-2.073\n",
      "Epoch:  0074 D loss:-0.782 G loss:-1.93\n",
      "Epoch:  0074 D loss:-0.9571 G loss:-2.047\n",
      "Epoch:  0074 D loss:-0.681 G loss:-2.049\n",
      "Epoch:  0074 D loss:-0.6559 G loss:-2.18\n",
      "Epoch:  0074 D loss:-0.6999 G loss:-2.383\n",
      "Epoch:  0074 D loss:-0.6441 G loss:-2.134\n",
      "Epoch:  0074 D loss:-0.6628 G loss:-2.074\n",
      "Epoch:  0074 D loss:-0.8001 G loss:-1.974\n",
      "Epoch:  0074 D loss:-0.854 G loss:-1.721\n",
      "Epoch:  0074 D loss:-0.8364 G loss:-1.713\n",
      "Epoch:  0074 D loss:-0.8102 G loss:-1.952\n",
      "Epoch:  0074 D loss:-0.6057 G loss:-2.248\n",
      "Epoch:  0074 D loss:-0.7757 G loss:-2.004\n",
      "Epoch:  0074 D loss:-0.6747 G loss:-1.924\n",
      "Epoch:  0074 D loss:-0.6382 G loss:-2.05\n",
      "Epoch:  0074 D loss:-0.7714 G loss:-1.847\n",
      "Epoch:  0074 D loss:-0.9922 G loss:-1.989\n",
      "Epoch:  0074 D loss:-0.7537 G loss:-1.878\n",
      "Epoch:  0074 D loss:-0.7805 G loss:-1.837\n",
      "Epoch:  0074 D loss:-0.6438 G loss:-1.947\n",
      "Epoch:  0074 D loss:-0.7287 G loss:-1.983\n",
      "Epoch:  0074 D loss:-0.6996 G loss:-2.003\n",
      "Epoch:  0074 D loss:-0.7903 G loss:-1.815\n",
      "Epoch:  0074 D loss:-0.6202 G loss:-2.091\n",
      "Epoch:  0074 D loss:-0.5859 G loss:-2.067\n",
      "Epoch:  0074 D loss:-0.7204 G loss:-2.065\n",
      "Epoch:  0074 D loss:-0.691 G loss:-2.079\n",
      "Epoch:  0074 D loss:-0.641 G loss:-2.334\n",
      "Epoch:  0074 D loss:-0.8518 G loss:-1.936\n",
      "Epoch:  0074 D loss:-0.7645 G loss:-2.242\n",
      "Epoch:  0074 D loss:-0.6832 G loss:-1.883\n",
      "Epoch:  0074 D loss:-0.687 G loss:-1.958\n",
      "Epoch:  0074 D loss:-0.7601 G loss:-2.086\n",
      "Epoch:  0074 D loss:-0.6108 G loss:-2.079\n",
      "Epoch:  0074 D loss:-0.6616 G loss:-2.006\n",
      "Epoch:  0074 D loss:-0.6991 G loss:-1.935\n",
      "Epoch:  0074 D loss:-0.6293 G loss:-2.05\n",
      "Epoch:  0074 D loss:-0.6021 G loss:-2.07\n",
      "Epoch:  0074 D loss:-0.7832 G loss:-1.999\n",
      "Epoch:  0074 D loss:-0.6575 G loss:-1.998\n",
      "Epoch:  0074 D loss:-0.6988 G loss:-2.101\n",
      "Epoch:  0074 D loss:-0.8039 G loss:-2.021\n",
      "Epoch:  0074 D loss:-0.5984 G loss:-2.158\n",
      "Epoch:  0074 D loss:-0.6985 G loss:-2.042\n",
      "Epoch:  0074 D loss:-0.715 G loss:-1.915\n",
      "Epoch:  0074 D loss:-0.7375 G loss:-2.041\n",
      "Epoch:  0074 D loss:-0.8082 G loss:-1.892\n",
      "Epoch:  0074 D loss:-0.7103 G loss:-1.864\n",
      "Epoch:  0074 D loss:-0.7135 G loss:-2.122\n",
      "Epoch:  0074 D loss:-0.8392 G loss:-2.103\n",
      "Epoch:  0074 D loss:-0.6201 G loss:-2.335\n",
      "Epoch:  0074 D loss:-0.7571 G loss:-1.816\n",
      "Epoch:  0074 D loss:-0.7826 G loss:-2.05\n",
      "Epoch:  0074 D loss:-0.7088 G loss:-2.271\n",
      "Epoch:  0074 D loss:-0.6477 G loss:-1.947\n",
      "Epoch:  0074 D loss:-0.8384 G loss:-1.99\n",
      "Epoch:  0074 D loss:-0.7741 G loss:-1.949\n",
      "Epoch:  0074 D loss:-0.6681 G loss:-1.925\n",
      "Epoch:  0074 D loss:-0.6727 G loss:-1.833\n",
      "Epoch:  0074 D loss:-0.681 G loss:-1.905\n",
      "Epoch:  0074 D loss:-0.7953 G loss:-2.068\n",
      "Epoch:  0074 D loss:-0.7112 G loss:-2.195\n",
      "Epoch:  0074 D loss:-0.6191 G loss:-2.17\n",
      "Epoch:  0074 D loss:-0.6445 G loss:-2.257\n",
      "Epoch:  0074 D loss:-0.6872 G loss:-1.983\n",
      "Epoch:  0074 D loss:-0.7409 G loss:-1.9\n",
      "Epoch:  0074 D loss:-0.7016 G loss:-2.168\n",
      "Epoch:  0074 D loss:-0.6429 G loss:-2.289\n",
      "Epoch:  0074 D loss:-0.6982 G loss:-2.172\n",
      "Epoch:  0074 D loss:-0.9106 G loss:-2.097\n",
      "Epoch:  0074 D loss:-0.6633 G loss:-2.113\n",
      "Epoch:  0074 D loss:-0.6931 G loss:-2.037\n",
      "Epoch:  0074 D loss:-0.7105 G loss:-2.111\n",
      "Epoch:  0074 D loss:-0.6549 G loss:-2.028\n",
      "Epoch:  0074 D loss:-0.7524 G loss:-1.855\n",
      "Epoch:  0074 D loss:-0.7391 G loss:-2.136\n",
      "Epoch:  0074 D loss:-0.8285 G loss:-1.938\n",
      "Epoch:  0074 D loss:-0.7745 G loss:-1.916\n",
      "Epoch:  0074 D loss:-0.7288 G loss:-1.971\n",
      "Epoch:  0074 D loss:-0.7015 G loss:-1.965\n",
      "Epoch:  0074 D loss:-0.6129 G loss:-2.057\n",
      "Epoch:  0074 D loss:-0.6824 G loss:-2.022\n",
      "Epoch:  0074 D loss:-0.6102 G loss:-2.197\n",
      "Epoch:  0074 D loss:-0.6398 G loss:-2.18\n",
      "Epoch:  0074 D loss:-0.6863 G loss:-2.152\n",
      "Epoch:  0074 D loss:-0.82 G loss:-2.088\n",
      "Epoch:  0074 D loss:-0.5878 G loss:-2.275\n",
      "Epoch:  0074 D loss:-0.6733 G loss:-2.116\n",
      "Epoch:  0074 D loss:-0.5842 G loss:-2.072\n",
      "Epoch:  0074 D loss:-0.8328 G loss:-1.969\n",
      "Epoch:  0074 D loss:-0.7336 G loss:-2.04\n",
      "Epoch:  0074 D loss:-0.6874 G loss:-1.97\n",
      "Epoch:  0074 D loss:-0.7137 G loss:-1.94\n",
      "Epoch:  0074 D loss:-0.685 G loss:-1.912\n",
      "Epoch:  0074 D loss:-0.6291 G loss:-2.048\n",
      "Epoch:  0074 D loss:-0.758 G loss:-1.973\n",
      "Epoch:  0074 D loss:-0.652 G loss:-2.31\n",
      "Epoch:  0074 D loss:-0.6089 G loss:-2.045\n",
      "Epoch:  0074 D loss:-0.6271 G loss:-2.099\n",
      "Epoch:  0074 D loss:-0.7134 G loss:-2.006\n",
      "Epoch:  0074 D loss:-0.6493 G loss:-2.23\n",
      "Epoch:  0074 D loss:-0.6184 G loss:-2.052\n",
      "Epoch:  0074 D loss:-0.8067 G loss:-1.82\n",
      "Epoch:  0074 D loss:-0.6587 G loss:-1.993\n",
      "Epoch:  0074 D loss:-0.8217 G loss:-2.114\n",
      "Epoch:  0074 D loss:-0.6235 G loss:-2.102\n",
      "Epoch:  0074 D loss:-0.69 G loss:-1.888\n",
      "Epoch:  0074 D loss:-0.6651 G loss:-1.868\n",
      "Epoch:  0074 D loss:-0.6936 G loss:-2.0\n",
      "Epoch:  0074 D loss:-0.7749 G loss:-1.975\n",
      "Epoch:  0074 D loss:-0.6333 G loss:-2.123\n",
      "Epoch:  0074 D loss:-0.6239 G loss:-2.24\n",
      "Epoch:  0074 D loss:-0.8092 G loss:-1.896\n",
      "Epoch:  0074 D loss:-0.6263 G loss:-2.07\n",
      "Epoch:  0074 D loss:-0.631 G loss:-2.096\n",
      "Epoch:  0074 D loss:-0.7695 G loss:-2.18\n",
      "Epoch:  0074 D loss:-0.8053 G loss:-2.146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0074 D loss:-0.7587 G loss:-2.139\n",
      "Epoch:  0074 D loss:-0.653 G loss:-2.128\n",
      "Epoch:  0074 D loss:-0.7042 G loss:-2.105\n",
      "Epoch:  0074 D loss:-0.6 G loss:-2.227\n",
      "Epoch:  0074 D loss:-0.5921 G loss:-2.129\n",
      "Epoch:  0074 D loss:-0.6893 G loss:-2.281\n",
      "Epoch:  0074 D loss:-0.8807 G loss:-2.056\n",
      "Epoch:  0074 D loss:-0.7404 G loss:-2.023\n",
      "Epoch:  0074 D loss:-0.6699 G loss:-1.967\n",
      "Epoch:  0074 D loss:-0.7051 G loss:-1.954\n",
      "Epoch:  0074 D loss:-0.7216 G loss:-1.734\n",
      "Epoch:  0074 D loss:-0.7182 G loss:-1.868\n",
      "Epoch:  0074 D loss:-0.6661 G loss:-1.767\n",
      "Epoch:  0074 D loss:-0.6777 G loss:-1.987\n",
      "Epoch:  0074 D loss:-0.6852 G loss:-1.917\n",
      "Epoch:  0074 D loss:-0.8042 G loss:-2.269\n",
      "Epoch:  0074 D loss:-0.7948 G loss:-1.868\n",
      "Epoch:  0074 D loss:-0.581 G loss:-2.308\n",
      "Epoch:  0074 D loss:-0.6649 G loss:-2.34\n",
      "Epoch:  0074 D loss:-0.7253 G loss:-2.363\n",
      "Epoch:  0074 D loss:-0.6327 G loss:-2.371\n",
      "Epoch:  0074 D loss:-0.7029 G loss:-2.121\n",
      "Epoch:  0074 D loss:-0.6816 G loss:-2.062\n",
      "Epoch:  0074 D loss:-0.7394 G loss:-2.208\n",
      "Epoch:  0074 D loss:-0.7327 G loss:-2.038\n",
      "Epoch:  0074 D loss:-0.6998 G loss:-1.967\n",
      "Epoch:  0074 D loss:-0.7556 G loss:-1.876\n",
      "Epoch:  0074 D loss:-0.8129 G loss:-1.928\n",
      "Epoch:  0074 D loss:-0.6001 G loss:-1.95\n",
      "Epoch:  0074 D loss:-0.693 G loss:-1.985\n",
      "Epoch:  0074 D loss:-0.6954 G loss:-1.952\n",
      "Epoch:  0074 D loss:-0.8057 G loss:-2.141\n",
      "Epoch:  0074 D loss:-0.6453 G loss:-2.2\n",
      "Epoch:  0074 D loss:-0.7892 G loss:-2.325\n",
      "Epoch:  0074 D loss:-0.7398 G loss:-2.24\n",
      "Epoch:  0074 D loss:-0.6617 G loss:-2.12\n",
      "Epoch:  0074 D loss:-0.7591 G loss:-2.021\n",
      "Epoch:  0074 D loss:-0.6186 G loss:-2.163\n",
      "Epoch:  0074 D loss:-0.6387 G loss:-2.155\n",
      "Epoch:  0074 D loss:-0.6986 G loss:-2.023\n",
      "Epoch:  0074 D loss:-0.8092 G loss:-1.792\n",
      "Epoch:  0074 D loss:-0.7214 G loss:-1.903\n",
      "Epoch:  0074 D loss:-0.744 G loss:-2.018\n",
      "Epoch:  0074 D loss:-0.6287 G loss:-2.007\n",
      "Epoch:  0074 D loss:-0.7007 G loss:-2.094\n",
      "Epoch:  0074 D loss:-0.674 G loss:-1.915\n",
      "Epoch:  0074 D loss:-0.5589 G loss:-2.084\n",
      "Epoch:  0074 D loss:-0.5889 G loss:-2.173\n",
      "Epoch:  0074 D loss:-0.7538 G loss:-2.213\n",
      "Epoch:  0074 D loss:-0.7868 G loss:-2.049\n",
      "Epoch:  0074 D loss:-0.7077 G loss:-1.964\n",
      "Epoch:  0074 D loss:-0.6562 G loss:-2.128\n",
      "Epoch:  0074 D loss:-0.7087 G loss:-1.933\n",
      "Epoch:  0074 D loss:-0.7595 G loss:-1.864\n",
      "Epoch:  0074 D loss:-0.6148 G loss:-2.039\n",
      "Epoch:  0074 D loss:-0.6014 G loss:-2.135\n",
      "Epoch:  0074 D loss:-0.872 G loss:-1.887\n",
      "Epoch:  0074 D loss:-0.6656 G loss:-2.045\n",
      "Epoch:  0074 D loss:-0.8625 G loss:-2.13\n",
      "Epoch:  0074 D loss:-0.7563 G loss:-2.274\n",
      "Epoch:  0074 D loss:-0.6381 G loss:-2.294\n",
      "Epoch:  0074 D loss:-0.6015 G loss:-2.328\n",
      "Epoch:  0074 D loss:-0.7297 G loss:-2.151\n",
      "Epoch:  0074 D loss:-0.805 G loss:-1.932\n",
      "Epoch:  0074 D loss:-0.7408 G loss:-2.093\n",
      "Epoch:  0074 D loss:-0.7868 G loss:-1.826\n",
      "Epoch:  0074 D loss:-0.7051 G loss:-2.064\n",
      "Epoch:  0074 D loss:-0.6888 G loss:-1.889\n",
      "Epoch:  0074 D loss:-0.9251 G loss:-1.644\n",
      "Epoch:  0074 D loss:-0.7165 G loss:-1.83\n",
      "Epoch:  0074 D loss:-0.551 G loss:-2.198\n",
      "Epoch:  0074 D loss:-0.6944 G loss:-2.093\n",
      "Epoch:  0074 D loss:-0.8332 G loss:-1.943\n",
      "Epoch:  0074 D loss:-0.6517 G loss:-2.169\n",
      "Epoch:  0074 D loss:-0.8622 G loss:-1.92\n",
      "Epoch:  0074 D loss:-0.7216 G loss:-2.202\n",
      "Epoch:  0074 D loss:-0.8255 G loss:-1.969\n",
      "Epoch:  0074 D loss:-0.7052 G loss:-1.963\n",
      "Epoch:  0074 D loss:-0.89 G loss:-1.789\n",
      "Epoch:  0074 D loss:-0.7743 G loss:-2.012\n",
      "Epoch:  0074 D loss:-0.7273 G loss:-1.871\n",
      "Epoch:  0074 D loss:-0.64 G loss:-2.02\n",
      "Epoch:  0074 D loss:-0.6625 G loss:-2.128\n",
      "Epoch:  0074 D loss:-0.7571 G loss:-1.996\n",
      "Epoch:  0074 D loss:-0.6487 G loss:-2.118\n",
      "Epoch:  0074 D loss:-0.7868 G loss:-1.851\n",
      "Epoch:  0074 D loss:-0.7326 G loss:-1.936\n",
      "Epoch:  0074 D loss:-0.7164 G loss:-1.718\n",
      "Epoch:  0074 D loss:-0.8272 G loss:-1.777\n",
      "Epoch:  0074 D loss:-0.7517 G loss:-1.913\n",
      "Epoch:  0074 D loss:-0.7876 G loss:-2.009\n",
      "Epoch:  0074 D loss:-0.7667 G loss:-1.896\n",
      "Epoch:  0074 D loss:-0.7747 G loss:-1.814\n",
      "Epoch:  0074 D loss:-0.81 G loss:-1.951\n",
      "Epoch:  0074 D loss:-0.6351 G loss:-1.863\n",
      "Epoch:  0074 D loss:-0.6318 G loss:-2.325\n",
      "Epoch:  0074 D loss:-0.7235 G loss:-2.109\n",
      "Epoch:  0074 D loss:-0.8073 G loss:-2.037\n",
      "Epoch:  0074 D loss:-0.7753 G loss:-1.882\n",
      "Epoch:  0074 D loss:-0.6145 G loss:-1.955\n",
      "Epoch:  0074 D loss:-0.8123 G loss:-2.031\n",
      "Epoch:  0074 D loss:-0.8197 G loss:-2.064\n",
      "Epoch:  0074 D loss:-0.7108 G loss:-2.003\n",
      "Epoch:  0074 D loss:-0.7653 G loss:-1.798\n",
      "Epoch:  0074 D loss:-0.7662 G loss:-1.667\n",
      "Epoch:  0074 D loss:-0.7474 G loss:-1.852\n",
      "Epoch:  0074 D loss:-0.7263 G loss:-1.844\n",
      "Epoch:  0074 D loss:-0.8905 G loss:-1.814\n",
      "Epoch:  0074 D loss:-0.9594 G loss:-2.084\n",
      "Epoch:  0074 D loss:-0.7226 G loss:-2.097\n",
      "Epoch:  0074 D loss:-0.7735 G loss:-1.937\n",
      "Epoch:  0074 D loss:-0.8793 G loss:-1.873\n",
      "Epoch:  0074 D loss:-0.7603 G loss:-1.876\n",
      "Epoch:  0074 D loss:-0.79 G loss:-2.14\n",
      "Epoch:  0074 D loss:-0.7094 G loss:-1.965\n",
      "Epoch:  0074 D loss:-0.8592 G loss:-1.991\n",
      "Epoch:  0074 D loss:-0.7672 G loss:-1.904\n",
      "Epoch:  0074 D loss:-0.7659 G loss:-1.859\n",
      "Epoch:  0074 D loss:-0.6681 G loss:-1.958\n",
      "Epoch:  0074 D loss:-0.7329 G loss:-1.872\n",
      "Epoch:  0074 D loss:-0.5955 G loss:-2.002\n",
      "Epoch:  0074 D loss:-0.7026 G loss:-1.893\n",
      "Epoch:  0074 D loss:-0.7673 G loss:-1.837\n",
      "Epoch:  0074 D loss:-0.6474 G loss:-2.171\n",
      "Epoch:  0074 D loss:-0.8374 G loss:-1.769\n",
      "Epoch:  0074 D loss:-0.7427 G loss:-2.004\n",
      "Epoch:  0074 D loss:-0.6889 G loss:-2.229\n",
      "Epoch:  0074 D loss:-0.6295 G loss:-2.156\n",
      "Epoch:  0074 D loss:-0.6562 G loss:-2.207\n",
      "Epoch:  0074 D loss:-0.7805 G loss:-2.096\n",
      "Epoch:  0074 D loss:-0.6537 G loss:-2.352\n",
      "Epoch:  0074 D loss:-0.6525 G loss:-2.249\n",
      "Epoch:  0074 D loss:-0.8193 G loss:-2.016\n",
      "Epoch:  0074 D loss:-0.6889 G loss:-2.139\n",
      "Epoch:  0074 D loss:-0.7627 G loss:-2.024\n",
      "Epoch:  0074 D loss:-0.85 G loss:-1.883\n",
      "Epoch:  0074 D loss:-0.8308 G loss:-1.81\n",
      "Epoch:  0074 D loss:-0.752 G loss:-1.872\n",
      "Epoch:  0074 D loss:-0.7139 G loss:-2.148\n",
      "Epoch:  0074 D loss:-0.7323 G loss:-1.777\n",
      "Epoch:  0074 D loss:-0.7779 G loss:-2.094\n",
      "Epoch:  0074 D loss:-0.7444 G loss:-1.973\n",
      "Epoch:  0074 D loss:-0.6572 G loss:-1.975\n",
      "Epoch:  0074 D loss:-0.7841 G loss:-1.895\n",
      "Epoch:  0074 D loss:-0.5596 G loss:-1.933\n",
      "Epoch:  0074 D loss:-0.7006 G loss:-2.086\n",
      "Epoch:  0074 D loss:-0.7541 G loss:-1.87\n",
      "Epoch:  0074 D loss:-0.7072 G loss:-2.174\n",
      "Epoch:  0074 D loss:-0.8012 G loss:-1.839\n",
      "Epoch:  0074 D loss:-0.7134 G loss:-1.84\n",
      "Epoch:  0074 D loss:-0.612 G loss:-1.94\n",
      "Epoch:  0074 D loss:-0.7642 G loss:-2.109\n",
      "Epoch:  0074 D loss:-0.7188 G loss:-2.273\n",
      "Epoch:  0074 D loss:-0.7103 G loss:-2.155\n",
      "Epoch:  0074 D loss:-0.6027 G loss:-2.12\n",
      "Epoch:  0074 D loss:-0.6188 G loss:-2.234\n",
      "Epoch:  0074 D loss:-0.7402 G loss:-2.243\n",
      "Epoch:  0074 D loss:-0.7681 G loss:-2.106\n",
      "Epoch:  0074 D loss:-0.6256 G loss:-2.114\n",
      "Epoch:  0074 D loss:-0.6855 G loss:-1.886\n",
      "Epoch:  0074 D loss:-0.6504 G loss:-2.226\n",
      "Epoch:  0074 D loss:-0.8109 G loss:-2.01\n",
      "Epoch:  0074 D loss:-0.7324 G loss:-2.131\n",
      "Epoch:  0074 D loss:-0.8846 G loss:-1.947\n",
      "Epoch:  0074 D loss:-0.6928 G loss:-1.932\n",
      "Epoch:  0074 D loss:-0.6851 G loss:-1.992\n",
      "Epoch:  0074 D loss:-0.5615 G loss:-2.235\n",
      "Epoch:  0074 D loss:-0.6026 G loss:-1.931\n",
      "Epoch:  0074 D loss:-0.779 G loss:-1.987\n",
      "Epoch:  0074 D loss:-0.6934 G loss:-2.028\n",
      "Epoch:  0074 D loss:-0.6668 G loss:-1.982\n",
      "Epoch:  0074 D loss:-0.7151 G loss:-2.065\n",
      "Epoch:  0074 D loss:-0.7887 G loss:-2.07\n",
      "Epoch:  0074 D loss:-0.7295 G loss:-1.909\n",
      "Epoch:  0074 D loss:-0.7701 G loss:-1.952\n",
      "Epoch:  0074 D loss:-0.6766 G loss:-1.987\n",
      "Epoch:  0074 D loss:-0.5876 G loss:-2.135\n",
      "Epoch:  0074 D loss:-0.7115 G loss:-2.013\n",
      "Epoch:  0074 D loss:-0.6831 G loss:-1.949\n",
      "Epoch:  0074 D loss:-0.6034 G loss:-2.104\n",
      "Epoch:  0074 D loss:-0.7106 G loss:-1.954\n",
      "Epoch:  0074 D loss:-0.7593 G loss:-2.047\n",
      "Epoch:  0074 D loss:-0.6412 G loss:-2.126\n",
      "Epoch:  0074 D loss:-0.7353 G loss:-2.324\n",
      "Epoch:  0074 D loss:-0.6748 G loss:-2.04\n",
      "Epoch:  0074 D loss:-0.7612 G loss:-2.155\n",
      "Epoch:  0074 D loss:-0.9627 G loss:-1.887\n",
      "Epoch:  0074 D loss:-0.6655 G loss:-2.019\n",
      "Epoch:  0074 D loss:-0.826 G loss:-2.025\n",
      "Epoch:  0074 D loss:-0.7068 G loss:-1.806\n",
      "Epoch:  0074 D loss:-0.8036 G loss:-1.954\n",
      "Epoch:  0074 D loss:-0.7142 G loss:-1.948\n",
      "Epoch:  0074 D loss:-0.8095 G loss:-2.005\n",
      "Epoch:  0074 D loss:-0.6904 G loss:-1.99\n",
      "Epoch:  0074 D loss:-0.706 G loss:-2.033\n",
      "Epoch:  0074 D loss:-0.6554 G loss:-2.128\n",
      "Epoch:  0074 D loss:-0.7501 G loss:-2.059\n",
      "Epoch:  0074 D loss:-0.592 G loss:-2.27\n",
      "Epoch:  0074 D loss:-0.6577 G loss:-2.362\n",
      "Epoch:  0074 D loss:-0.7629 G loss:-2.139\n",
      "Epoch:  0074 D loss:-0.7665 G loss:-1.89\n",
      "Epoch:  0074 D loss:-0.7021 G loss:-1.971\n",
      "Epoch:  0074 D loss:-0.7483 G loss:-1.959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0074 D loss:-0.8635 G loss:-2.003\n",
      "Epoch:  0074 D loss:-0.6626 G loss:-2.17\n",
      "Epoch:  0074 D loss:-0.6494 G loss:-2.264\n",
      "Epoch:  0074 D loss:-0.6979 G loss:-2.192\n",
      "Epoch:  0074 D loss:-0.633 G loss:-2.293\n",
      "Epoch:  0074 D loss:-0.613 G loss:-2.263\n",
      "Epoch:  0074 D loss:-0.7231 G loss:-2.025\n",
      "Epoch:  0074 D loss:-0.7066 G loss:-2.151\n",
      "Epoch:  0074 D loss:-0.6727 G loss:-2.112\n",
      "Epoch:  0074 D loss:-0.7237 G loss:-1.945\n",
      "Epoch:  0074 D loss:-0.8459 G loss:-1.975\n",
      "Epoch:  0074 D loss:-0.6497 G loss:-2.149\n",
      "Epoch:  0074 D loss:-0.7129 G loss:-1.976\n",
      "Epoch:  0074 D loss:-0.6944 G loss:-1.808\n",
      "Epoch:  0074 D loss:-0.7303 G loss:-1.849\n",
      "Epoch:  0074 D loss:-0.6623 G loss:-2.003\n",
      "Epoch:  0074 D loss:-0.6609 G loss:-1.931\n",
      "Epoch:  0074 D loss:-0.6925 G loss:-2.045\n",
      "Epoch:  0074 D loss:-0.6539 G loss:-2.23\n",
      "Epoch:  0074 D loss:-0.7787 G loss:-1.894\n",
      "Epoch:  0074 D loss:-0.6646 G loss:-1.952\n",
      "Epoch:  0074 D loss:-0.7827 G loss:-2.217\n",
      "Epoch:  0074 D loss:-0.73 G loss:-2.046\n",
      "Epoch:  0074 D loss:-0.6595 G loss:-2.121\n",
      "Epoch:  0074 D loss:-0.6287 G loss:-2.038\n",
      "Epoch:  0074 D loss:-0.851 G loss:-1.937\n",
      "Epoch:  0074 D loss:-0.74 G loss:-1.829\n",
      "Epoch:  0074 D loss:-0.6346 G loss:-2.14\n",
      "Epoch:  0074 D loss:-0.7514 G loss:-1.974\n",
      "Epoch:  0074 D loss:-0.7797 G loss:-1.985\n",
      "Epoch:  0074 D loss:-0.6925 G loss:-2.136\n",
      "Epoch:  0074 D loss:-0.7522 G loss:-1.896\n",
      "Epoch:  0074 D loss:-0.7514 G loss:-1.865\n",
      "Epoch:  0074 D loss:-0.7293 G loss:-2.175\n",
      "Epoch:  0074 D loss:-0.607 G loss:-1.975\n",
      "Epoch:  0074 D loss:-0.723 G loss:-2.067\n",
      "Epoch:  0074 D loss:-0.8736 G loss:-2.042\n",
      "Epoch:  0074 D loss:-0.6746 G loss:-2.135\n",
      "Epoch:  0074 D loss:-0.7119 G loss:-2.248\n",
      "Epoch:  0074 D loss:-0.6247 G loss:-2.23\n",
      "Epoch:  0074 D loss:-0.6691 G loss:-2.276\n",
      "Epoch:  0074 D loss:-0.6845 G loss:-2.05\n",
      "Epoch:  0074 D loss:-0.5487 G loss:-2.075\n",
      "Epoch:  0074 D loss:-0.7311 G loss:-2.082\n",
      "Epoch:  0074 D loss:-0.9289 G loss:-1.872\n",
      "Epoch:  0074 D loss:-0.7917 G loss:-1.848\n",
      "Epoch:  0074 D loss:-0.657 G loss:-1.999\n",
      "Epoch:  0074 D loss:-0.6633 G loss:-1.946\n",
      "Epoch:  0074 D loss:-0.7176 G loss:-2.042\n",
      "Epoch:  0074 D loss:-0.6225 G loss:-1.967\n",
      "Epoch:  0074 D loss:-0.6086 G loss:-2.104\n",
      "Epoch:  0074 D loss:-0.7581 G loss:-1.965\n",
      "Epoch:  0074 D loss:-0.6949 G loss:-2.223\n",
      "Epoch:  0074 D loss:-0.8346 G loss:-1.982\n",
      "Epoch:  0074 D loss:-0.7299 G loss:-2.083\n",
      "Epoch:  0074 D loss:-0.6395 G loss:-1.788\n",
      "Epoch:  0074 D loss:-0.6666 G loss:-2.025\n",
      "Epoch:  0074 D loss:-0.6042 G loss:-1.991\n",
      "Epoch:  0074 D loss:-0.6399 G loss:-2.197\n",
      "Epoch:  0074 D loss:-0.6993 G loss:-2.12\n",
      "Epoch:  0074 D loss:-0.5997 G loss:-2.317\n",
      "Epoch:  0074 D loss:-0.7866 G loss:-1.996\n",
      "Epoch:  0074 D loss:-0.788 G loss:-2.267\n",
      "Epoch:  0074 D loss:-0.6604 G loss:-2.204\n",
      "Epoch:  0074 D loss:-0.7385 G loss:-2.114\n",
      "Epoch:  0074 D loss:-0.7942 G loss:-2.006\n",
      "Epoch:  0074 D loss:-0.7148 G loss:-2.027\n",
      "Epoch:  0074 D loss:-0.5759 G loss:-2.04\n",
      "Epoch:  0074 D loss:-0.7097 G loss:-2.018\n",
      "Epoch:  0074 D loss:-0.5989 G loss:-2.17\n",
      "Epoch:  0074 D loss:-0.9473 G loss:-1.925\n",
      "Epoch:  0074 D loss:-0.666 G loss:-1.871\n",
      "Epoch:  0074 D loss:-0.719 G loss:-1.891\n",
      "Epoch:  0074 D loss:-0.7919 G loss:-1.916\n",
      "Epoch:  0074 D loss:-0.7002 G loss:-1.939\n",
      "Epoch:  0074 D loss:-0.8221 G loss:-1.927\n",
      "Epoch:  0074 D loss:-0.7622 G loss:-2.117\n",
      "Epoch:  0074 D loss:-0.7907 G loss:-1.875\n",
      "Epoch:  0074 D loss:-0.7818 G loss:-2.078\n",
      "Epoch:  0074 D loss:-0.862 G loss:-2.027\n",
      "Epoch:  0074 D loss:-0.6319 G loss:-2.196\n",
      "Epoch:  0075 D loss:-0.8209 G loss:-1.976\n",
      "Epoch:  0075 D loss:-0.7235 G loss:-2.076\n",
      "Epoch:  0075 D loss:-0.7584 G loss:-1.864\n",
      "Epoch:  0075 D loss:-0.8514 G loss:-1.8\n",
      "Epoch:  0075 D loss:-0.7612 G loss:-1.932\n",
      "Epoch:  0075 D loss:-0.6684 G loss:-2.049\n",
      "Epoch:  0075 D loss:-0.7488 G loss:-1.794\n",
      "Epoch:  0075 D loss:-0.7256 G loss:-1.97\n",
      "Epoch:  0075 D loss:-0.6621 G loss:-1.941\n",
      "Epoch:  0075 D loss:-0.7392 G loss:-1.924\n",
      "Epoch:  0075 D loss:-0.8034 G loss:-2.018\n",
      "Epoch:  0075 D loss:-0.9176 G loss:-1.868\n",
      "Epoch:  0075 D loss:-0.6501 G loss:-2.289\n",
      "Epoch:  0075 D loss:-0.7126 G loss:-1.953\n",
      "Epoch:  0075 D loss:-0.8669 G loss:-1.967\n",
      "Epoch:  0075 D loss:-0.5641 G loss:-2.285\n",
      "Epoch:  0075 D loss:-0.7065 G loss:-2.101\n",
      "Epoch:  0075 D loss:-0.6951 G loss:-1.861\n",
      "Epoch:  0075 D loss:-0.6963 G loss:-1.986\n",
      "Epoch:  0075 D loss:-0.6414 G loss:-2.181\n",
      "Epoch:  0075 D loss:-0.6317 G loss:-2.077\n",
      "Epoch:  0075 D loss:-0.721 G loss:-1.992\n",
      "Epoch:  0075 D loss:-0.8994 G loss:-1.925\n",
      "Epoch:  0075 D loss:-0.574 G loss:-2.066\n",
      "Epoch:  0075 D loss:-0.8375 G loss:-1.935\n",
      "Epoch:  0075 D loss:-0.7187 G loss:-2.018\n",
      "Epoch:  0075 D loss:-0.6536 G loss:-2.053\n",
      "Epoch:  0075 D loss:-0.8229 G loss:-1.818\n",
      "Epoch:  0075 D loss:-0.6256 G loss:-1.981\n",
      "Epoch:  0075 D loss:-0.7332 G loss:-1.958\n",
      "Epoch:  0075 D loss:-0.7109 G loss:-2.18\n",
      "Epoch:  0075 D loss:-0.6911 G loss:-2.021\n",
      "Epoch:  0075 D loss:-0.7426 G loss:-2.3\n",
      "Epoch:  0075 D loss:-0.6324 G loss:-2.012\n",
      "Epoch:  0075 D loss:-0.6982 G loss:-1.983\n",
      "Epoch:  0075 D loss:-0.77 G loss:-2.113\n",
      "Epoch:  0075 D loss:-0.5884 G loss:-2.099\n",
      "Epoch:  0075 D loss:-0.6929 G loss:-2.01\n",
      "Epoch:  0075 D loss:-0.7597 G loss:-1.902\n",
      "Epoch:  0075 D loss:-0.7958 G loss:-1.913\n",
      "Epoch:  0075 D loss:-0.6369 G loss:-2.017\n",
      "Epoch:  0075 D loss:-0.7291 G loss:-1.942\n",
      "Epoch:  0075 D loss:-0.7856 G loss:-1.948\n",
      "Epoch:  0075 D loss:-0.6488 G loss:-2.019\n",
      "Epoch:  0075 D loss:-0.801 G loss:-1.944\n",
      "Epoch:  0075 D loss:-0.7315 G loss:-2.059\n",
      "Epoch:  0075 D loss:-0.7116 G loss:-1.965\n",
      "Epoch:  0075 D loss:-0.7435 G loss:-2.04\n",
      "Epoch:  0075 D loss:-0.8268 G loss:-1.982\n",
      "Epoch:  0075 D loss:-0.7437 G loss:-2.059\n",
      "Epoch:  0075 D loss:-0.7128 G loss:-2.002\n",
      "Epoch:  0075 D loss:-0.7171 G loss:-1.917\n",
      "Epoch:  0075 D loss:-0.638 G loss:-2.116\n",
      "Epoch:  0075 D loss:-0.6299 G loss:-2.165\n",
      "Epoch:  0075 D loss:-0.6465 G loss:-2.057\n",
      "Epoch:  0075 D loss:-0.5977 G loss:-2.143\n",
      "Epoch:  0075 D loss:-0.7609 G loss:-2.055\n",
      "Epoch:  0075 D loss:-0.892 G loss:-1.974\n",
      "Epoch:  0075 D loss:-0.7755 G loss:-1.887\n",
      "Epoch:  0075 D loss:-0.5971 G loss:-1.963\n",
      "Epoch:  0075 D loss:-0.6523 G loss:-2.158\n",
      "Epoch:  0075 D loss:-0.5453 G loss:-1.96\n",
      "Epoch:  0075 D loss:-0.829 G loss:-2.189\n",
      "Epoch:  0075 D loss:-0.7296 G loss:-2.067\n",
      "Epoch:  0075 D loss:-0.721 G loss:-1.82\n",
      "Epoch:  0075 D loss:-0.7488 G loss:-1.894\n",
      "Epoch:  0075 D loss:-0.6818 G loss:-2.186\n",
      "Epoch:  0075 D loss:-0.6935 G loss:-2.043\n",
      "Epoch:  0075 D loss:-0.4829 G loss:-2.393\n",
      "Epoch:  0075 D loss:-0.6992 G loss:-2.195\n",
      "Epoch:  0075 D loss:-0.6538 G loss:-1.952\n",
      "Epoch:  0075 D loss:-0.5949 G loss:-2.275\n",
      "Epoch:  0075 D loss:-0.7492 G loss:-2.031\n",
      "Epoch:  0075 D loss:-0.6241 G loss:-2.161\n",
      "Epoch:  0075 D loss:-0.7825 G loss:-2.061\n",
      "Epoch:  0075 D loss:-0.7242 G loss:-2.13\n",
      "Epoch:  0075 D loss:-0.7805 G loss:-2.092\n",
      "Epoch:  0075 D loss:-0.6621 G loss:-2.282\n",
      "Epoch:  0075 D loss:-0.7504 G loss:-2.007\n",
      "Epoch:  0075 D loss:-0.711 G loss:-1.905\n",
      "Epoch:  0075 D loss:-0.6143 G loss:-2.155\n",
      "Epoch:  0075 D loss:-0.6559 G loss:-2.101\n",
      "Epoch:  0075 D loss:-0.6774 G loss:-1.926\n",
      "Epoch:  0075 D loss:-0.5713 G loss:-2.176\n",
      "Epoch:  0075 D loss:-0.7924 G loss:-1.957\n",
      "Epoch:  0075 D loss:-0.7878 G loss:-1.793\n",
      "Epoch:  0075 D loss:-0.6615 G loss:-1.994\n",
      "Epoch:  0075 D loss:-0.803 G loss:-1.937\n",
      "Epoch:  0075 D loss:-0.628 G loss:-2.085\n",
      "Epoch:  0075 D loss:-0.627 G loss:-2.079\n",
      "Epoch:  0075 D loss:-0.6301 G loss:-2.25\n",
      "Epoch:  0075 D loss:-0.6859 G loss:-2.226\n",
      "Epoch:  0075 D loss:-0.8557 G loss:-2.169\n",
      "Epoch:  0075 D loss:-0.6527 G loss:-2.037\n",
      "Epoch:  0075 D loss:-0.7547 G loss:-1.865\n",
      "Epoch:  0075 D loss:-0.7027 G loss:-2.081\n",
      "Epoch:  0075 D loss:-0.6408 G loss:-1.974\n",
      "Epoch:  0075 D loss:-0.7048 G loss:-1.908\n",
      "Epoch:  0075 D loss:-0.7245 G loss:-1.901\n",
      "Epoch:  0075 D loss:-0.7172 G loss:-1.756\n",
      "Epoch:  0075 D loss:-0.6723 G loss:-1.996\n",
      "Epoch:  0075 D loss:-0.788 G loss:-1.921\n",
      "Epoch:  0075 D loss:-0.7178 G loss:-2.01\n",
      "Epoch:  0075 D loss:-0.6723 G loss:-2.193\n",
      "Epoch:  0075 D loss:-0.7361 G loss:-1.942\n",
      "Epoch:  0075 D loss:-0.7461 G loss:-1.893\n",
      "Epoch:  0075 D loss:-0.6908 G loss:-2.128\n",
      "Epoch:  0075 D loss:-0.7618 G loss:-2.097\n",
      "Epoch:  0075 D loss:-0.6278 G loss:-2.053\n",
      "Epoch:  0075 D loss:-0.7141 G loss:-2.138\n",
      "Epoch:  0075 D loss:-0.7222 G loss:-1.969\n",
      "Epoch:  0075 D loss:-0.7556 G loss:-2.017\n",
      "Epoch:  0075 D loss:-0.7375 G loss:-1.899\n",
      "Epoch:  0075 D loss:-0.6767 G loss:-1.972\n",
      "Epoch:  0075 D loss:-0.6132 G loss:-1.785\n",
      "Epoch:  0075 D loss:-0.7421 G loss:-1.941\n",
      "Epoch:  0075 D loss:-0.703 G loss:-1.918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0075 D loss:-0.7529 G loss:-1.956\n",
      "Epoch:  0075 D loss:-0.7309 G loss:-2.217\n",
      "Epoch:  0075 D loss:-0.6572 G loss:-2.159\n",
      "Epoch:  0075 D loss:-0.8214 G loss:-2.14\n",
      "Epoch:  0075 D loss:-0.828 G loss:-2.145\n",
      "Epoch:  0075 D loss:-0.7122 G loss:-2.324\n",
      "Epoch:  0075 D loss:-0.7049 G loss:-2.303\n",
      "Epoch:  0075 D loss:-0.8136 G loss:-2.188\n",
      "Epoch:  0075 D loss:-0.6893 G loss:-2.024\n",
      "Epoch:  0075 D loss:-0.7492 G loss:-2.156\n",
      "Epoch:  0075 D loss:-0.7823 G loss:-1.852\n",
      "Epoch:  0075 D loss:-0.781 G loss:-1.772\n",
      "Epoch:  0075 D loss:-0.6872 G loss:-1.795\n",
      "Epoch:  0075 D loss:-0.7294 G loss:-2.031\n",
      "Epoch:  0075 D loss:-0.7673 G loss:-2.102\n",
      "Epoch:  0075 D loss:-0.7185 G loss:-1.864\n",
      "Epoch:  0075 D loss:-0.6678 G loss:-2.007\n",
      "Epoch:  0075 D loss:-0.8145 G loss:-2.114\n",
      "Epoch:  0075 D loss:-0.6721 G loss:-2.195\n",
      "Epoch:  0075 D loss:-0.6185 G loss:-2.014\n",
      "Epoch:  0075 D loss:-0.6232 G loss:-2.085\n",
      "Epoch:  0075 D loss:-0.6298 G loss:-2.197\n",
      "Epoch:  0075 D loss:-0.5749 G loss:-2.092\n",
      "Epoch:  0075 D loss:-0.7782 G loss:-1.981\n",
      "Epoch:  0075 D loss:-0.6153 G loss:-2.128\n",
      "Epoch:  0075 D loss:-0.6373 G loss:-2.229\n",
      "Epoch:  0075 D loss:-0.8986 G loss:-1.773\n",
      "Epoch:  0075 D loss:-0.726 G loss:-1.855\n",
      "Epoch:  0075 D loss:-0.7249 G loss:-1.854\n",
      "Epoch:  0075 D loss:-0.9381 G loss:-1.729\n",
      "Epoch:  0075 D loss:-0.8638 G loss:-1.86\n",
      "Epoch:  0075 D loss:-0.7172 G loss:-1.911\n",
      "Epoch:  0075 D loss:-0.8353 G loss:-1.753\n",
      "Epoch:  0075 D loss:-0.6539 G loss:-1.951\n",
      "Epoch:  0075 D loss:-0.8393 G loss:-1.902\n",
      "Epoch:  0075 D loss:-0.6935 G loss:-1.791\n",
      "Epoch:  0075 D loss:-0.8606 G loss:-1.942\n",
      "Epoch:  0075 D loss:-0.6384 G loss:-2.277\n",
      "Epoch:  0075 D loss:-0.6765 G loss:-2.226\n",
      "Epoch:  0075 D loss:-0.7697 G loss:-2.03\n",
      "Epoch:  0075 D loss:-0.537 G loss:-2.211\n",
      "Epoch:  0075 D loss:-0.732 G loss:-2.046\n",
      "Epoch:  0075 D loss:-0.684 G loss:-2.008\n",
      "Epoch:  0075 D loss:-0.6758 G loss:-2.015\n",
      "Epoch:  0075 D loss:-0.7463 G loss:-1.994\n",
      "Epoch:  0075 D loss:-0.7084 G loss:-2.139\n",
      "Epoch:  0075 D loss:-0.7369 G loss:-1.966\n",
      "Epoch:  0075 D loss:-0.694 G loss:-1.874\n",
      "Epoch:  0075 D loss:-0.6553 G loss:-1.974\n",
      "Epoch:  0075 D loss:-0.8196 G loss:-1.929\n",
      "Epoch:  0075 D loss:-0.701 G loss:-1.971\n",
      "Epoch:  0075 D loss:-0.8056 G loss:-1.906\n",
      "Epoch:  0075 D loss:-0.6769 G loss:-1.914\n",
      "Epoch:  0075 D loss:-0.7029 G loss:-2.033\n",
      "Epoch:  0075 D loss:-0.6578 G loss:-2.208\n",
      "Epoch:  0075 D loss:-0.9131 G loss:-2.111\n",
      "Epoch:  0075 D loss:-0.5544 G loss:-2.356\n",
      "Epoch:  0075 D loss:-0.7783 G loss:-1.968\n",
      "Epoch:  0075 D loss:-0.8045 G loss:-1.961\n",
      "Epoch:  0075 D loss:-0.7409 G loss:-1.875\n",
      "Epoch:  0075 D loss:-0.7759 G loss:-2.039\n",
      "Epoch:  0075 D loss:-0.8381 G loss:-1.911\n",
      "Epoch:  0075 D loss:-0.7495 G loss:-2.076\n",
      "Epoch:  0075 D loss:-0.7047 G loss:-1.955\n",
      "Epoch:  0075 D loss:-0.7421 G loss:-1.711\n",
      "Epoch:  0075 D loss:-0.9676 G loss:-1.836\n",
      "Epoch:  0075 D loss:-0.7972 G loss:-1.878\n",
      "Epoch:  0075 D loss:-0.7357 G loss:-1.992\n",
      "Epoch:  0075 D loss:-0.6888 G loss:-2.039\n",
      "Epoch:  0075 D loss:-0.7359 G loss:-2.027\n",
      "Epoch:  0075 D loss:-0.6403 G loss:-2.242\n",
      "Epoch:  0075 D loss:-0.5944 G loss:-2.269\n",
      "Epoch:  0075 D loss:-0.6824 G loss:-1.928\n",
      "Epoch:  0075 D loss:-0.5326 G loss:-2.203\n",
      "Epoch:  0075 D loss:-0.726 G loss:-2.024\n",
      "Epoch:  0075 D loss:-0.6496 G loss:-2.468\n",
      "Epoch:  0075 D loss:-0.8799 G loss:-2.009\n",
      "Epoch:  0075 D loss:-0.7505 G loss:-1.988\n",
      "Epoch:  0075 D loss:-0.7708 G loss:-1.841\n",
      "Epoch:  0075 D loss:-0.9274 G loss:-1.794\n",
      "Epoch:  0075 D loss:-0.6416 G loss:-1.754\n",
      "Epoch:  0075 D loss:-0.9739 G loss:-1.551\n",
      "Epoch:  0075 D loss:-0.7371 G loss:-1.858\n",
      "Epoch:  0075 D loss:-0.8027 G loss:-1.791\n",
      "Epoch:  0075 D loss:-0.7878 G loss:-2.017\n",
      "Epoch:  0075 D loss:-0.8941 G loss:-1.913\n",
      "Epoch:  0075 D loss:-0.7097 G loss:-2.026\n",
      "Epoch:  0075 D loss:-0.768 G loss:-2.147\n",
      "Epoch:  0075 D loss:-0.6924 G loss:-2.062\n",
      "Epoch:  0075 D loss:-0.8046 G loss:-2.171\n",
      "Epoch:  0075 D loss:-0.846 G loss:-2.147\n",
      "Epoch:  0075 D loss:-0.8035 G loss:-1.89\n",
      "Epoch:  0075 D loss:-0.6999 G loss:-1.861\n",
      "Epoch:  0075 D loss:-0.676 G loss:-1.965\n",
      "Epoch:  0075 D loss:-0.7144 G loss:-2.172\n",
      "Epoch:  0075 D loss:-0.8553 G loss:-1.791\n",
      "Epoch:  0075 D loss:-0.7793 G loss:-1.739\n",
      "Epoch:  0075 D loss:-0.7062 G loss:-1.958\n",
      "Epoch:  0075 D loss:-0.6299 G loss:-2.089\n",
      "Epoch:  0075 D loss:-0.7599 G loss:-2.087\n",
      "Epoch:  0075 D loss:-0.6293 G loss:-2.096\n",
      "Epoch:  0075 D loss:-0.7631 G loss:-2.031\n",
      "Epoch:  0075 D loss:-0.7662 G loss:-1.909\n",
      "Epoch:  0075 D loss:-0.7814 G loss:-2.201\n",
      "Epoch:  0075 D loss:-0.883 G loss:-1.835\n",
      "Epoch:  0075 D loss:-0.7193 G loss:-2.01\n",
      "Epoch:  0075 D loss:-0.6735 G loss:-2.08\n",
      "Epoch:  0075 D loss:-0.7219 G loss:-1.931\n",
      "Epoch:  0075 D loss:-0.7615 G loss:-1.895\n",
      "Epoch:  0075 D loss:-0.7349 G loss:-2.152\n",
      "Epoch:  0075 D loss:-0.6588 G loss:-2.12\n",
      "Epoch:  0075 D loss:-0.7029 G loss:-1.897\n",
      "Epoch:  0075 D loss:-0.6429 G loss:-2.116\n",
      "Epoch:  0075 D loss:-0.7391 G loss:-1.973\n",
      "Epoch:  0075 D loss:-0.8632 G loss:-1.847\n",
      "Epoch:  0075 D loss:-0.7024 G loss:-2.015\n",
      "Epoch:  0075 D loss:-0.726 G loss:-2.083\n",
      "Epoch:  0075 D loss:-0.6099 G loss:-2.166\n",
      "Epoch:  0075 D loss:-0.6317 G loss:-2.13\n",
      "Epoch:  0075 D loss:-0.6163 G loss:-2.228\n",
      "Epoch:  0075 D loss:-0.7561 G loss:-2.173\n",
      "Epoch:  0075 D loss:-0.5416 G loss:-2.135\n",
      "Epoch:  0075 D loss:-0.5393 G loss:-2.089\n",
      "Epoch:  0075 D loss:-0.6711 G loss:-2.12\n",
      "Epoch:  0075 D loss:-0.7995 G loss:-2.081\n",
      "Epoch:  0075 D loss:-0.718 G loss:-2.214\n",
      "Epoch:  0075 D loss:-0.6237 G loss:-1.974\n",
      "Epoch:  0075 D loss:-0.8314 G loss:-1.728\n",
      "Epoch:  0075 D loss:-0.557 G loss:-1.968\n",
      "Epoch:  0075 D loss:-0.779 G loss:-1.947\n",
      "Epoch:  0075 D loss:-0.6629 G loss:-1.805\n",
      "Epoch:  0075 D loss:-0.5888 G loss:-2.075\n",
      "Epoch:  0075 D loss:-0.7119 G loss:-1.912\n",
      "Epoch:  0075 D loss:-0.6637 G loss:-2.115\n",
      "Epoch:  0075 D loss:-0.6986 G loss:-2.296\n",
      "Epoch:  0075 D loss:-0.7426 G loss:-2.119\n",
      "Epoch:  0075 D loss:-0.7705 G loss:-2.242\n",
      "Epoch:  0075 D loss:-0.5232 G loss:-2.39\n",
      "Epoch:  0075 D loss:-0.6648 G loss:-2.166\n",
      "Epoch:  0075 D loss:-0.7488 G loss:-2.317\n",
      "Epoch:  0075 D loss:-0.7457 G loss:-2.058\n",
      "Epoch:  0075 D loss:-0.843 G loss:-2.065\n",
      "Epoch:  0075 D loss:-0.6943 G loss:-1.863\n",
      "Epoch:  0075 D loss:-0.7239 G loss:-2.013\n",
      "Epoch:  0075 D loss:-0.6262 G loss:-2.097\n",
      "Epoch:  0075 D loss:-0.7324 G loss:-1.839\n",
      "Epoch:  0075 D loss:-0.8197 G loss:-1.851\n",
      "Epoch:  0075 D loss:-0.7002 G loss:-1.949\n",
      "Epoch:  0075 D loss:-0.5958 G loss:-1.929\n",
      "Epoch:  0075 D loss:-0.8186 G loss:-1.634\n",
      "Epoch:  0075 D loss:-0.7256 G loss:-2.017\n",
      "Epoch:  0075 D loss:-0.6652 G loss:-2.14\n",
      "Epoch:  0075 D loss:-0.6043 G loss:-2.298\n",
      "Epoch:  0075 D loss:-0.6359 G loss:-2.08\n",
      "Epoch:  0075 D loss:-0.6786 G loss:-2.399\n",
      "Epoch:  0075 D loss:-0.6639 G loss:-2.3\n",
      "Epoch:  0075 D loss:-0.6062 G loss:-2.349\n",
      "Epoch:  0075 D loss:-0.6248 G loss:-2.272\n",
      "Epoch:  0075 D loss:-0.6888 G loss:-2.186\n",
      "Epoch:  0075 D loss:-0.5791 G loss:-1.86\n",
      "Epoch:  0075 D loss:-0.689 G loss:-1.911\n",
      "Epoch:  0075 D loss:-0.6152 G loss:-2.047\n",
      "Epoch:  0075 D loss:-0.642 G loss:-1.903\n",
      "Epoch:  0075 D loss:-0.7289 G loss:-2.048\n",
      "Epoch:  0075 D loss:-0.7616 G loss:-1.906\n",
      "Epoch:  0075 D loss:-0.6312 G loss:-1.936\n",
      "Epoch:  0075 D loss:-0.6554 G loss:-2.104\n",
      "Epoch:  0075 D loss:-0.691 G loss:-2.146\n",
      "Epoch:  0075 D loss:-0.6679 G loss:-2.231\n",
      "Epoch:  0075 D loss:-0.6497 G loss:-2.129\n",
      "Epoch:  0075 D loss:-0.6649 G loss:-2.214\n",
      "Epoch:  0075 D loss:-0.5996 G loss:-2.24\n",
      "Epoch:  0075 D loss:-0.6915 G loss:-2.154\n",
      "Epoch:  0075 D loss:-0.7698 G loss:-2.014\n",
      "Epoch:  0075 D loss:-0.6083 G loss:-2.099\n",
      "Epoch:  0075 D loss:-0.828 G loss:-1.847\n",
      "Epoch:  0075 D loss:-0.801 G loss:-1.753\n",
      "Epoch:  0075 D loss:-0.7301 G loss:-1.92\n",
      "Epoch:  0075 D loss:-0.7839 G loss:-1.981\n",
      "Epoch:  0075 D loss:-0.5518 G loss:-2.078\n",
      "Epoch:  0075 D loss:-0.7088 G loss:-1.936\n",
      "Epoch:  0075 D loss:-0.6672 G loss:-1.988\n",
      "Epoch:  0075 D loss:-0.5902 G loss:-2.125\n",
      "Epoch:  0075 D loss:-0.6999 G loss:-1.996\n",
      "Epoch:  0075 D loss:-0.6264 G loss:-1.968\n",
      "Epoch:  0075 D loss:-0.69 G loss:-2.037\n",
      "Epoch:  0075 D loss:-0.7802 G loss:-2.004\n",
      "Epoch:  0075 D loss:-0.7814 G loss:-2.092\n",
      "Epoch:  0075 D loss:-0.7721 G loss:-2.12\n",
      "Epoch:  0075 D loss:-0.7293 G loss:-2.176\n",
      "Epoch:  0075 D loss:-0.7367 G loss:-2.109\n",
      "Epoch:  0075 D loss:-0.6203 G loss:-2.19\n",
      "Epoch:  0075 D loss:-0.8408 G loss:-1.951\n",
      "Epoch:  0075 D loss:-0.6437 G loss:-2.246\n",
      "Epoch:  0075 D loss:-0.7904 G loss:-1.962\n",
      "Epoch:  0075 D loss:-0.5444 G loss:-1.993\n",
      "Epoch:  0075 D loss:-0.6933 G loss:-1.926\n",
      "Epoch:  0075 D loss:-0.6766 G loss:-1.931\n",
      "Epoch:  0075 D loss:-0.7495 G loss:-1.984\n",
      "Epoch:  0075 D loss:-0.7107 G loss:-1.861\n",
      "Epoch:  0075 D loss:-0.6901 G loss:-1.92\n",
      "Epoch:  0075 D loss:-0.7383 G loss:-1.857\n",
      "Epoch:  0075 D loss:-0.7507 G loss:-1.744\n",
      "Epoch:  0075 D loss:-0.7005 G loss:-1.897\n",
      "Epoch:  0075 D loss:-0.6764 G loss:-2.098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0075 D loss:-0.7392 G loss:-2.145\n",
      "Epoch:  0075 D loss:-0.7408 G loss:-2.31\n",
      "Epoch:  0075 D loss:-0.7294 G loss:-2.325\n",
      "Epoch:  0075 D loss:-0.8006 G loss:-2.074\n",
      "Epoch:  0075 D loss:-0.742 G loss:-2.245\n",
      "Epoch:  0075 D loss:-0.8563 G loss:-2.171\n",
      "Epoch:  0075 D loss:-0.7466 G loss:-1.97\n",
      "Epoch:  0075 D loss:-0.6754 G loss:-2.068\n",
      "Epoch:  0075 D loss:-0.6817 G loss:-1.76\n",
      "Epoch:  0075 D loss:-0.7744 G loss:-1.809\n",
      "Epoch:  0075 D loss:-0.6558 G loss:-1.844\n",
      "Epoch:  0075 D loss:-0.7278 G loss:-1.818\n",
      "Epoch:  0075 D loss:-0.7947 G loss:-1.747\n",
      "Epoch:  0075 D loss:-0.8217 G loss:-1.813\n",
      "Epoch:  0075 D loss:-0.9693 G loss:-1.684\n",
      "Epoch:  0075 D loss:-0.6677 G loss:-1.871\n",
      "Epoch:  0075 D loss:-0.622 G loss:-2.182\n",
      "Epoch:  0075 D loss:-0.7905 G loss:-2.214\n",
      "Epoch:  0075 D loss:-0.7163 G loss:-2.084\n",
      "Epoch:  0075 D loss:-0.7027 G loss:-2.2\n",
      "Epoch:  0075 D loss:-0.7922 G loss:-1.995\n",
      "Epoch:  0075 D loss:-0.7648 G loss:-2.208\n",
      "Epoch:  0075 D loss:-0.8193 G loss:-2.096\n",
      "Epoch:  0075 D loss:-0.7164 G loss:-2.091\n",
      "Epoch:  0075 D loss:-0.6929 G loss:-2.133\n",
      "Epoch:  0075 D loss:-0.8096 G loss:-2.134\n",
      "Epoch:  0075 D loss:-0.7579 G loss:-1.845\n",
      "Epoch:  0075 D loss:-0.8202 G loss:-1.904\n",
      "Epoch:  0075 D loss:-0.8173 G loss:-1.772\n",
      "Epoch:  0075 D loss:-0.6593 G loss:-1.893\n",
      "Epoch:  0075 D loss:-0.6173 G loss:-2.056\n",
      "Epoch:  0075 D loss:-0.6244 G loss:-2.115\n",
      "Epoch:  0075 D loss:-0.8634 G loss:-1.717\n",
      "Epoch:  0075 D loss:-0.707 G loss:-1.847\n",
      "Epoch:  0075 D loss:-0.7113 G loss:-1.908\n",
      "Epoch:  0075 D loss:-0.8441 G loss:-1.715\n",
      "Epoch:  0075 D loss:-0.8637 G loss:-1.905\n",
      "Epoch:  0075 D loss:-0.6574 G loss:-1.752\n",
      "Epoch:  0075 D loss:-0.6986 G loss:-1.986\n",
      "Epoch:  0075 D loss:-0.6287 G loss:-2.045\n",
      "Epoch:  0075 D loss:-0.7019 G loss:-2.015\n",
      "Epoch:  0075 D loss:-0.6656 G loss:-2.005\n",
      "Epoch:  0075 D loss:-0.9474 G loss:-2.033\n",
      "Epoch:  0075 D loss:-0.6182 G loss:-2.083\n",
      "Epoch:  0075 D loss:-0.8193 G loss:-1.963\n",
      "Epoch:  0075 D loss:-0.6862 G loss:-2.074\n",
      "Epoch:  0075 D loss:-0.6822 G loss:-1.908\n",
      "Epoch:  0075 D loss:-0.7477 G loss:-1.86\n",
      "Epoch:  0075 D loss:-0.7679 G loss:-1.939\n",
      "Epoch:  0075 D loss:-0.7813 G loss:-1.929\n",
      "Epoch:  0075 D loss:-0.7546 G loss:-1.918\n",
      "Epoch:  0075 D loss:-0.7856 G loss:-2.04\n",
      "Epoch:  0075 D loss:-0.7634 G loss:-2.023\n",
      "Epoch:  0075 D loss:-0.8694 G loss:-1.664\n",
      "Epoch:  0075 D loss:-0.7063 G loss:-1.828\n",
      "Epoch:  0075 D loss:-0.6672 G loss:-1.933\n",
      "Epoch:  0075 D loss:-0.6826 G loss:-1.874\n",
      "Epoch:  0075 D loss:-0.8393 G loss:-1.886\n",
      "Epoch:  0075 D loss:-0.6576 G loss:-2.143\n",
      "Epoch:  0075 D loss:-0.7465 G loss:-2.041\n",
      "Epoch:  0075 D loss:-0.807 G loss:-2.181\n",
      "Epoch:  0075 D loss:-0.8239 G loss:-2.039\n",
      "Epoch:  0075 D loss:-0.6967 G loss:-2.131\n",
      "Epoch:  0075 D loss:-0.7892 G loss:-2.008\n",
      "Epoch:  0075 D loss:-0.6057 G loss:-2.239\n",
      "Epoch:  0075 D loss:-0.9221 G loss:-1.962\n",
      "Epoch:  0075 D loss:-0.7903 G loss:-1.692\n",
      "Epoch:  0075 D loss:-0.8659 G loss:-1.837\n",
      "Epoch:  0075 D loss:-0.7408 G loss:-2.048\n",
      "Epoch:  0075 D loss:-0.9379 G loss:-1.829\n",
      "Epoch:  0075 D loss:-0.7213 G loss:-2.164\n",
      "Epoch:  0075 D loss:-0.7086 G loss:-2.086\n",
      "Epoch:  0075 D loss:-0.7341 G loss:-2.046\n",
      "Epoch:  0075 D loss:-0.6522 G loss:-2.06\n",
      "Epoch:  0075 D loss:-0.783 G loss:-2.004\n",
      "Epoch:  0075 D loss:-0.6141 G loss:-2.018\n",
      "Epoch:  0075 D loss:-0.6256 G loss:-2.211\n",
      "Epoch:  0075 D loss:-0.7864 G loss:-1.738\n",
      "Epoch:  0075 D loss:-0.7683 G loss:-1.794\n",
      "Epoch:  0075 D loss:-0.753 G loss:-1.771\n",
      "Epoch:  0075 D loss:-0.7769 G loss:-1.838\n",
      "Epoch:  0075 D loss:-0.6527 G loss:-1.986\n",
      "Epoch:  0075 D loss:-0.6917 G loss:-1.816\n",
      "Epoch:  0075 D loss:-0.7565 G loss:-1.996\n",
      "Epoch:  0075 D loss:-0.6983 G loss:-1.961\n",
      "Epoch:  0075 D loss:-0.8301 G loss:-2.129\n",
      "Epoch:  0075 D loss:-0.6833 G loss:-2.229\n",
      "Epoch:  0075 D loss:-0.7902 G loss:-2.083\n",
      "Epoch:  0075 D loss:-0.8487 G loss:-1.852\n",
      "Epoch:  0075 D loss:-0.6343 G loss:-2.201\n",
      "Epoch:  0075 D loss:-0.5438 G loss:-1.927\n",
      "Epoch:  0075 D loss:-0.8122 G loss:-1.943\n",
      "Epoch:  0075 D loss:-0.6758 G loss:-2.012\n",
      "Epoch:  0075 D loss:-0.6512 G loss:-2.088\n",
      "Epoch:  0075 D loss:-0.8426 G loss:-1.917\n",
      "Epoch:  0075 D loss:-0.6851 G loss:-2.036\n",
      "Epoch:  0075 D loss:-0.6811 G loss:-1.961\n",
      "Epoch:  0075 D loss:-0.6927 G loss:-1.992\n",
      "Epoch:  0075 D loss:-0.7581 G loss:-2.13\n",
      "Epoch:  0075 D loss:-0.6617 G loss:-2.204\n",
      "Epoch:  0075 D loss:-0.6173 G loss:-2.197\n",
      "Epoch:  0075 D loss:-0.7816 G loss:-1.95\n",
      "Epoch:  0075 D loss:-0.5954 G loss:-2.081\n",
      "Epoch:  0075 D loss:-0.7755 G loss:-1.806\n",
      "Epoch:  0075 D loss:-0.7303 G loss:-2.117\n",
      "Epoch:  0075 D loss:-0.8002 G loss:-1.851\n",
      "Epoch:  0075 D loss:-0.7639 G loss:-1.86\n",
      "Epoch:  0075 D loss:-0.7885 G loss:-1.783\n",
      "Epoch:  0075 D loss:-0.7205 G loss:-1.828\n",
      "Epoch:  0075 D loss:-0.774 G loss:-1.826\n",
      "Epoch:  0075 D loss:-0.6717 G loss:-1.927\n",
      "Epoch:  0075 D loss:-0.7906 G loss:-1.907\n",
      "Epoch:  0075 D loss:-0.75 G loss:-1.973\n",
      "Epoch:  0075 D loss:-0.8228 G loss:-1.965\n",
      "Epoch:  0075 D loss:-0.9089 G loss:-1.802\n",
      "Epoch:  0075 D loss:-0.8162 G loss:-1.975\n",
      "Epoch:  0075 D loss:-0.7454 G loss:-1.908\n",
      "Epoch:  0075 D loss:-0.743 G loss:-2.099\n",
      "Epoch:  0075 D loss:-0.798 G loss:-2.198\n",
      "Epoch:  0075 D loss:-0.7505 G loss:-2.231\n",
      "Epoch:  0075 D loss:-0.6873 G loss:-2.217\n",
      "Epoch:  0075 D loss:-0.6723 G loss:-2.023\n",
      "Epoch:  0075 D loss:-0.7187 G loss:-2.016\n",
      "Epoch:  0075 D loss:-0.6181 G loss:-2.204\n",
      "Epoch:  0075 D loss:-0.5983 G loss:-1.892\n",
      "Epoch:  0075 D loss:-0.7752 G loss:-1.83\n",
      "Epoch:  0075 D loss:-0.7625 G loss:-1.79\n",
      "Epoch:  0075 D loss:-0.8012 G loss:-2.022\n",
      "Epoch:  0075 D loss:-0.8348 G loss:-1.848\n",
      "Epoch:  0075 D loss:-0.6613 G loss:-2.136\n",
      "Epoch:  0075 D loss:-0.804 G loss:-1.934\n",
      "Epoch:  0075 D loss:-0.6163 G loss:-2.137\n",
      "Epoch:  0075 D loss:-0.6821 G loss:-1.976\n",
      "Epoch:  0075 D loss:-0.5807 G loss:-2.284\n",
      "Epoch:  0075 D loss:-0.5523 G loss:-2.048\n",
      "Epoch:  0075 D loss:-0.6435 G loss:-2.182\n",
      "Epoch:  0075 D loss:-0.643 G loss:-2.175\n",
      "Epoch:  0075 D loss:-0.74 G loss:-2.278\n",
      "Epoch:  0075 D loss:-0.8927 G loss:-2.201\n",
      "Epoch:  0075 D loss:-0.7107 G loss:-2.102\n",
      "Epoch:  0075 D loss:-0.6597 G loss:-2.139\n",
      "Epoch:  0075 D loss:-0.7853 G loss:-2.146\n",
      "Epoch:  0075 D loss:-0.7813 G loss:-1.894\n",
      "Epoch:  0075 D loss:-0.7366 G loss:-1.89\n",
      "Epoch:  0075 D loss:-0.6195 G loss:-1.952\n",
      "Epoch:  0075 D loss:-0.6463 G loss:-1.892\n",
      "Epoch:  0075 D loss:-0.837 G loss:-1.818\n",
      "Epoch:  0075 D loss:-0.8636 G loss:-1.724\n",
      "Epoch:  0075 D loss:-0.741 G loss:-1.821\n",
      "Epoch:  0075 D loss:-0.6082 G loss:-2.011\n",
      "Epoch:  0075 D loss:-0.6488 G loss:-1.995\n",
      "Epoch:  0075 D loss:-0.6407 G loss:-2.09\n",
      "Epoch:  0075 D loss:-0.8542 G loss:-1.921\n",
      "Epoch:  0075 D loss:-0.6203 G loss:-2.394\n",
      "Epoch:  0075 D loss:-0.7212 G loss:-2.226\n",
      "Epoch:  0075 D loss:-1.002 G loss:-2.07\n",
      "Epoch:  0075 D loss:-0.7274 G loss:-2.307\n",
      "Epoch:  0075 D loss:-0.8071 G loss:-1.936\n",
      "Epoch:  0075 D loss:-0.5841 G loss:-2.108\n",
      "Epoch:  0075 D loss:-0.7684 G loss:-1.845\n",
      "Epoch:  0075 D loss:-0.6224 G loss:-2.003\n",
      "Epoch:  0075 D loss:-0.731 G loss:-1.822\n",
      "Epoch:  0075 D loss:-0.7973 G loss:-1.66\n",
      "Epoch:  0075 D loss:-0.5835 G loss:-1.93\n",
      "Epoch:  0075 D loss:-0.6721 G loss:-1.998\n",
      "Epoch:  0075 D loss:-0.6237 G loss:-1.887\n",
      "Epoch:  0075 D loss:-0.7162 G loss:-1.955\n",
      "Epoch:  0075 D loss:-0.6311 G loss:-1.922\n",
      "Epoch:  0075 D loss:-0.7153 G loss:-2.027\n",
      "Epoch:  0075 D loss:-0.705 G loss:-2.081\n",
      "Epoch:  0075 D loss:-0.7078 G loss:-2.115\n",
      "Epoch:  0075 D loss:-0.6954 G loss:-1.811\n",
      "Epoch:  0075 D loss:-0.6171 G loss:-2.203\n",
      "Epoch:  0075 D loss:-0.6696 G loss:-1.959\n",
      "Epoch:  0075 D loss:-0.6416 G loss:-2.05\n",
      "Epoch:  0075 D loss:-0.718 G loss:-2.226\n",
      "Epoch:  0075 D loss:-0.6608 G loss:-2.054\n",
      "Epoch:  0075 D loss:-0.5816 G loss:-2.177\n",
      "Epoch:  0075 D loss:-0.8844 G loss:-2.132\n",
      "Epoch:  0075 D loss:-0.6457 G loss:-2.138\n",
      "Epoch:  0075 D loss:-0.6629 G loss:-2.022\n",
      "Epoch:  0075 D loss:-0.6639 G loss:-2.116\n",
      "Epoch:  0075 D loss:-0.6576 G loss:-1.97\n",
      "Epoch:  0075 D loss:-0.6667 G loss:-1.836\n",
      "Epoch:  0075 D loss:-0.6809 G loss:-1.791\n",
      "Epoch:  0075 D loss:-0.9655 G loss:-1.875\n",
      "Epoch:  0075 D loss:-0.6859 G loss:-1.915\n",
      "Epoch:  0075 D loss:-0.6364 G loss:-2.027\n",
      "Epoch:  0075 D loss:-0.6609 G loss:-2.093\n",
      "Epoch:  0075 D loss:-0.8001 G loss:-1.927\n",
      "Epoch:  0075 D loss:-0.7574 G loss:-2.082\n",
      "Epoch:  0075 D loss:-0.7414 G loss:-2.006\n",
      "Epoch:  0075 D loss:-0.666 G loss:-1.952\n",
      "Epoch:  0075 D loss:-0.8498 G loss:-1.941\n",
      "Epoch:  0075 D loss:-0.7511 G loss:-2.045\n",
      "Epoch:  0075 D loss:-0.6912 G loss:-1.988\n",
      "Epoch:  0075 D loss:-0.7116 G loss:-2.14\n",
      "Epoch:  0075 D loss:-0.7561 G loss:-1.976\n",
      "Epoch:  0075 D loss:-0.7942 G loss:-1.818\n",
      "Epoch:  0075 D loss:-0.7107 G loss:-2.007\n",
      "Epoch:  0075 D loss:-0.6127 G loss:-2.255\n",
      "Epoch:  0075 D loss:-0.7703 G loss:-2.0\n",
      "Epoch:  0075 D loss:-0.5932 G loss:-1.962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0075 D loss:-0.6947 G loss:-1.982\n",
      "Epoch:  0075 D loss:-0.8677 G loss:-1.808\n",
      "Epoch:  0075 D loss:-0.7122 G loss:-1.884\n",
      "Epoch:  0075 D loss:-0.7306 G loss:-1.836\n",
      "Epoch:  0075 D loss:-0.7639 G loss:-1.977\n",
      "Epoch:  0075 D loss:-0.7584 G loss:-1.781\n",
      "Epoch:  0075 D loss:-0.8371 G loss:-1.885\n",
      "Epoch:  0075 D loss:-0.8071 G loss:-1.948\n",
      "Epoch:  0075 D loss:-0.7469 G loss:-2.102\n",
      "Epoch:  0075 D loss:-0.6503 G loss:-1.912\n",
      "Epoch:  0075 D loss:-0.679 G loss:-2.08\n",
      "Epoch:  0075 D loss:-0.7287 G loss:-2.214\n",
      "Epoch:  0075 D loss:-0.7123 G loss:-2.065\n",
      "Epoch:  0075 D loss:-0.6485 G loss:-2.118\n",
      "Epoch:  0075 D loss:-0.6875 G loss:-1.946\n",
      "Epoch:  0075 D loss:-0.668 G loss:-1.863\n",
      "Epoch:  0075 D loss:-0.7652 G loss:-2.157\n",
      "Epoch:  0075 D loss:-0.6915 G loss:-2.038\n",
      "Epoch:  0075 D loss:-0.6083 G loss:-2.027\n",
      "Epoch:  0075 D loss:-0.723 G loss:-1.912\n",
      "Epoch:  0075 D loss:-0.7962 G loss:-1.985\n",
      "Epoch:  0075 D loss:-0.678 G loss:-1.947\n",
      "Epoch:  0075 D loss:-0.665 G loss:-2.075\n",
      "Epoch:  0075 D loss:-0.7451 G loss:-1.933\n",
      "Epoch:  0075 D loss:-0.589 G loss:-2.135\n",
      "Epoch:  0076 D loss:-0.6207 G loss:-2.115\n",
      "Epoch:  0076 D loss:-0.6092 G loss:-2.14\n",
      "Epoch:  0076 D loss:-0.7269 G loss:-2.161\n",
      "Epoch:  0076 D loss:-0.6796 G loss:-2.245\n",
      "Epoch:  0076 D loss:-0.7665 G loss:-2.137\n",
      "Epoch:  0076 D loss:-0.7114 G loss:-2.154\n",
      "Epoch:  0076 D loss:-0.6984 G loss:-2.015\n",
      "Epoch:  0076 D loss:-0.6894 G loss:-2.087\n",
      "Epoch:  0076 D loss:-0.6107 G loss:-2.102\n",
      "Epoch:  0076 D loss:-0.671 G loss:-1.896\n",
      "Epoch:  0076 D loss:-0.7458 G loss:-1.983\n",
      "Epoch:  0076 D loss:-0.6858 G loss:-1.931\n",
      "Epoch:  0076 D loss:-0.6678 G loss:-1.905\n",
      "Epoch:  0076 D loss:-0.8074 G loss:-1.869\n",
      "Epoch:  0076 D loss:-0.7322 G loss:-1.937\n",
      "Epoch:  0076 D loss:-0.686 G loss:-1.688\n",
      "Epoch:  0076 D loss:-0.6446 G loss:-2.111\n",
      "Epoch:  0076 D loss:-0.7322 G loss:-1.75\n",
      "Epoch:  0076 D loss:-0.7797 G loss:-1.818\n",
      "Epoch:  0076 D loss:-0.8023 G loss:-1.838\n",
      "Epoch:  0076 D loss:-0.6929 G loss:-1.837\n",
      "Epoch:  0076 D loss:-0.738 G loss:-2.085\n",
      "Epoch:  0076 D loss:-0.8981 G loss:-2.178\n",
      "Epoch:  0076 D loss:-0.5915 G loss:-2.161\n",
      "Epoch:  0076 D loss:-0.7212 G loss:-2.036\n",
      "Epoch:  0076 D loss:-0.8695 G loss:-2.071\n",
      "Epoch:  0076 D loss:-0.7908 G loss:-1.88\n",
      "Epoch:  0076 D loss:-0.5418 G loss:-1.955\n",
      "Epoch:  0076 D loss:-0.8264 G loss:-1.829\n",
      "Epoch:  0076 D loss:-0.6927 G loss:-1.911\n",
      "Epoch:  0076 D loss:-0.7992 G loss:-1.919\n",
      "Epoch:  0076 D loss:-0.5594 G loss:-2.112\n",
      "Epoch:  0076 D loss:-0.7772 G loss:-1.812\n",
      "Epoch:  0076 D loss:-0.6007 G loss:-2.065\n",
      "Epoch:  0076 D loss:-0.7391 G loss:-2.06\n",
      "Epoch:  0076 D loss:-0.728 G loss:-2.085\n",
      "Epoch:  0076 D loss:-0.7268 G loss:-2.005\n",
      "Epoch:  0076 D loss:-0.6143 G loss:-2.078\n",
      "Epoch:  0076 D loss:-0.6785 G loss:-1.975\n",
      "Epoch:  0076 D loss:-0.7347 G loss:-1.893\n",
      "Epoch:  0076 D loss:-0.8073 G loss:-1.574\n",
      "Epoch:  0076 D loss:-0.7882 G loss:-1.731\n",
      "Epoch:  0076 D loss:-0.7253 G loss:-1.821\n",
      "Epoch:  0076 D loss:-0.5631 G loss:-2.134\n",
      "Epoch:  0076 D loss:-0.761 G loss:-1.751\n",
      "Epoch:  0076 D loss:-0.6991 G loss:-1.832\n",
      "Epoch:  0076 D loss:-0.751 G loss:-1.995\n",
      "Epoch:  0076 D loss:-0.763 G loss:-2.046\n",
      "Epoch:  0076 D loss:-0.7531 G loss:-2.021\n",
      "Epoch:  0076 D loss:-0.7973 G loss:-2.184\n",
      "Epoch:  0076 D loss:-0.9251 G loss:-2.033\n",
      "Epoch:  0076 D loss:-0.7962 G loss:-2.163\n",
      "Epoch:  0076 D loss:-0.7498 G loss:-1.993\n",
      "Epoch:  0076 D loss:-0.8193 G loss:-1.936\n",
      "Epoch:  0076 D loss:-0.8297 G loss:-2.022\n",
      "Epoch:  0076 D loss:-0.6885 G loss:-1.972\n",
      "Epoch:  0076 D loss:-0.6764 G loss:-1.664\n",
      "Epoch:  0076 D loss:-0.8604 G loss:-1.719\n",
      "Epoch:  0076 D loss:-0.7219 G loss:-1.726\n",
      "Epoch:  0076 D loss:-0.8072 G loss:-1.7\n",
      "Epoch:  0076 D loss:-0.6317 G loss:-1.948\n",
      "Epoch:  0076 D loss:-0.6592 G loss:-1.965\n",
      "Epoch:  0076 D loss:-0.7093 G loss:-2.081\n",
      "Epoch:  0076 D loss:-0.6824 G loss:-2.022\n",
      "Epoch:  0076 D loss:-0.7052 G loss:-1.898\n",
      "Epoch:  0076 D loss:-0.6321 G loss:-2.073\n",
      "Epoch:  0076 D loss:-0.7022 G loss:-1.986\n",
      "Epoch:  0076 D loss:-0.8722 G loss:-2.097\n",
      "Epoch:  0076 D loss:-0.708 G loss:-2.136\n",
      "Epoch:  0076 D loss:-0.758 G loss:-2.092\n",
      "Epoch:  0076 D loss:-0.8144 G loss:-2.005\n",
      "Epoch:  0076 D loss:-0.6868 G loss:-2.055\n",
      "Epoch:  0076 D loss:-0.6303 G loss:-1.988\n",
      "Epoch:  0076 D loss:-0.7821 G loss:-1.875\n",
      "Epoch:  0076 D loss:-0.6973 G loss:-1.802\n",
      "Epoch:  0076 D loss:-0.7011 G loss:-1.86\n",
      "Epoch:  0076 D loss:-0.7369 G loss:-1.712\n",
      "Epoch:  0076 D loss:-0.7455 G loss:-1.808\n",
      "Epoch:  0076 D loss:-0.7732 G loss:-1.876\n",
      "Epoch:  0076 D loss:-0.7037 G loss:-1.811\n",
      "Epoch:  0076 D loss:-0.611 G loss:-1.942\n",
      "Epoch:  0076 D loss:-0.8087 G loss:-1.889\n",
      "Epoch:  0076 D loss:-0.7192 G loss:-1.862\n",
      "Epoch:  0076 D loss:-0.7211 G loss:-1.931\n",
      "Epoch:  0076 D loss:-0.7817 G loss:-1.865\n",
      "Epoch:  0076 D loss:-0.6889 G loss:-2.029\n",
      "Epoch:  0076 D loss:-0.6554 G loss:-1.839\n",
      "Epoch:  0076 D loss:-0.6311 G loss:-2.12\n",
      "Epoch:  0076 D loss:-0.7939 G loss:-1.963\n",
      "Epoch:  0076 D loss:-0.648 G loss:-2.216\n",
      "Epoch:  0076 D loss:-0.7331 G loss:-2.069\n",
      "Epoch:  0076 D loss:-0.6148 G loss:-2.235\n",
      "Epoch:  0076 D loss:-0.7689 G loss:-2.171\n",
      "Epoch:  0076 D loss:-0.7429 G loss:-2.03\n",
      "Epoch:  0076 D loss:-0.6859 G loss:-2.003\n",
      "Epoch:  0076 D loss:-0.6611 G loss:-2.059\n",
      "Epoch:  0076 D loss:-0.6802 G loss:-1.988\n",
      "Epoch:  0076 D loss:-0.8256 G loss:-1.868\n",
      "Epoch:  0076 D loss:-0.7113 G loss:-1.988\n",
      "Epoch:  0076 D loss:-0.6763 G loss:-1.809\n",
      "Epoch:  0076 D loss:-0.7463 G loss:-1.598\n",
      "Epoch:  0076 D loss:-0.6301 G loss:-2.007\n",
      "Epoch:  0076 D loss:-0.6804 G loss:-2.037\n",
      "Epoch:  0076 D loss:-0.6904 G loss:-2.12\n",
      "Epoch:  0076 D loss:-0.5931 G loss:-2.151\n",
      "Epoch:  0076 D loss:-0.7124 G loss:-2.041\n",
      "Epoch:  0076 D loss:-0.6969 G loss:-2.17\n",
      "Epoch:  0076 D loss:-0.7505 G loss:-2.034\n",
      "Epoch:  0076 D loss:-0.6341 G loss:-2.16\n",
      "Epoch:  0076 D loss:-0.7253 G loss:-1.819\n",
      "Epoch:  0076 D loss:-0.7048 G loss:-1.98\n",
      "Epoch:  0076 D loss:-0.7313 G loss:-2.116\n",
      "Epoch:  0076 D loss:-0.594 G loss:-2.2\n",
      "Epoch:  0076 D loss:-0.7669 G loss:-1.809\n",
      "Epoch:  0076 D loss:-0.7178 G loss:-1.938\n",
      "Epoch:  0076 D loss:-0.7557 G loss:-1.901\n",
      "Epoch:  0076 D loss:-0.7556 G loss:-2.125\n",
      "Epoch:  0076 D loss:-0.7557 G loss:-1.827\n",
      "Epoch:  0076 D loss:-0.7199 G loss:-1.927\n",
      "Epoch:  0076 D loss:-0.7019 G loss:-1.901\n",
      "Epoch:  0076 D loss:-0.843 G loss:-1.916\n",
      "Epoch:  0076 D loss:-0.6151 G loss:-1.896\n",
      "Epoch:  0076 D loss:-0.5965 G loss:-1.961\n",
      "Epoch:  0076 D loss:-0.7327 G loss:-1.996\n",
      "Epoch:  0076 D loss:-0.6436 G loss:-1.969\n",
      "Epoch:  0076 D loss:-0.6957 G loss:-1.938\n",
      "Epoch:  0076 D loss:-0.6135 G loss:-2.147\n",
      "Epoch:  0076 D loss:-0.8695 G loss:-2.099\n",
      "Epoch:  0076 D loss:-0.7121 G loss:-2.004\n",
      "Epoch:  0076 D loss:-0.646 G loss:-2.295\n",
      "Epoch:  0076 D loss:-0.6952 G loss:-2.114\n",
      "Epoch:  0076 D loss:-0.6536 G loss:-2.215\n",
      "Epoch:  0076 D loss:-0.8522 G loss:-1.867\n",
      "Epoch:  0076 D loss:-0.7294 G loss:-1.984\n",
      "Epoch:  0076 D loss:-0.8461 G loss:-1.811\n",
      "Epoch:  0076 D loss:-0.6003 G loss:-1.79\n",
      "Epoch:  0076 D loss:-0.7825 G loss:-1.949\n",
      "Epoch:  0076 D loss:-0.7838 G loss:-1.985\n",
      "Epoch:  0076 D loss:-0.7705 G loss:-1.821\n",
      "Epoch:  0076 D loss:-0.6261 G loss:-1.868\n",
      "Epoch:  0076 D loss:-0.6758 G loss:-1.932\n",
      "Epoch:  0076 D loss:-0.667 G loss:-2.079\n",
      "Epoch:  0076 D loss:-0.6525 G loss:-1.98\n",
      "Epoch:  0076 D loss:-0.7524 G loss:-1.793\n",
      "Epoch:  0076 D loss:-0.7129 G loss:-2.319\n",
      "Epoch:  0076 D loss:-0.6009 G loss:-2.205\n",
      "Epoch:  0076 D loss:-0.7943 G loss:-2.212\n",
      "Epoch:  0076 D loss:-0.7744 G loss:-1.924\n",
      "Epoch:  0076 D loss:-0.8428 G loss:-2.072\n",
      "Epoch:  0076 D loss:-0.8246 G loss:-1.91\n",
      "Epoch:  0076 D loss:-0.6723 G loss:-1.814\n",
      "Epoch:  0076 D loss:-0.637 G loss:-1.796\n",
      "Epoch:  0076 D loss:-0.7672 G loss:-1.746\n",
      "Epoch:  0076 D loss:-0.783 G loss:-1.928\n",
      "Epoch:  0076 D loss:-0.7616 G loss:-1.776\n",
      "Epoch:  0076 D loss:-0.7624 G loss:-1.64\n",
      "Epoch:  0076 D loss:-0.7813 G loss:-1.769\n",
      "Epoch:  0076 D loss:-0.7121 G loss:-1.796\n",
      "Epoch:  0076 D loss:-0.8063 G loss:-1.892\n",
      "Epoch:  0076 D loss:-0.6436 G loss:-2.225\n",
      "Epoch:  0076 D loss:-0.6798 G loss:-2.132\n",
      "Epoch:  0076 D loss:-0.6434 G loss:-2.046\n",
      "Epoch:  0076 D loss:-0.7903 G loss:-2.127\n",
      "Epoch:  0076 D loss:-0.8177 G loss:-2.063\n",
      "Epoch:  0076 D loss:-0.7732 G loss:-2.08\n",
      "Epoch:  0076 D loss:-0.7386 G loss:-1.885\n",
      "Epoch:  0076 D loss:-0.7271 G loss:-2.028\n",
      "Epoch:  0076 D loss:-0.7309 G loss:-1.825\n",
      "Epoch:  0076 D loss:-0.6868 G loss:-1.974\n",
      "Epoch:  0076 D loss:-0.6443 G loss:-1.946\n",
      "Epoch:  0076 D loss:-0.7212 G loss:-1.718\n",
      "Epoch:  0076 D loss:-0.5829 G loss:-1.848\n",
      "Epoch:  0076 D loss:-0.6751 G loss:-1.821\n",
      "Epoch:  0076 D loss:-0.6658 G loss:-2.08\n",
      "Epoch:  0076 D loss:-0.7541 G loss:-1.891\n",
      "Epoch:  0076 D loss:-0.6082 G loss:-2.023\n",
      "Epoch:  0076 D loss:-0.7342 G loss:-1.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0076 D loss:-0.6969 G loss:-2.158\n",
      "Epoch:  0076 D loss:-0.6966 G loss:-2.005\n",
      "Epoch:  0076 D loss:-0.6766 G loss:-2.254\n",
      "Epoch:  0076 D loss:-0.7788 G loss:-1.978\n",
      "Epoch:  0076 D loss:-0.7088 G loss:-2.117\n",
      "Epoch:  0076 D loss:-0.6899 G loss:-1.947\n",
      "Epoch:  0076 D loss:-0.7439 G loss:-2.08\n",
      "Epoch:  0076 D loss:-0.6432 G loss:-1.853\n",
      "Epoch:  0076 D loss:-0.7405 G loss:-1.887\n",
      "Epoch:  0076 D loss:-0.7264 G loss:-2.005\n",
      "Epoch:  0076 D loss:-0.6764 G loss:-1.952\n",
      "Epoch:  0076 D loss:-0.8209 G loss:-1.958\n",
      "Epoch:  0076 D loss:-0.7145 G loss:-1.903\n",
      "Epoch:  0076 D loss:-0.7337 G loss:-1.946\n",
      "Epoch:  0076 D loss:-0.7342 G loss:-1.8\n",
      "Epoch:  0076 D loss:-0.7726 G loss:-1.97\n",
      "Epoch:  0076 D loss:-0.7342 G loss:-1.822\n",
      "Epoch:  0076 D loss:-0.6834 G loss:-1.747\n",
      "Epoch:  0076 D loss:-0.8079 G loss:-1.806\n",
      "Epoch:  0076 D loss:-0.8275 G loss:-1.725\n",
      "Epoch:  0076 D loss:-0.7017 G loss:-2.027\n",
      "Epoch:  0076 D loss:-0.8049 G loss:-1.843\n",
      "Epoch:  0076 D loss:-0.8089 G loss:-2.024\n",
      "Epoch:  0076 D loss:-0.8055 G loss:-2.168\n",
      "Epoch:  0076 D loss:-0.8208 G loss:-2.183\n",
      "Epoch:  0076 D loss:-0.8393 G loss:-2.003\n",
      "Epoch:  0076 D loss:-0.7294 G loss:-1.959\n",
      "Epoch:  0076 D loss:-0.782 G loss:-2.122\n",
      "Epoch:  0076 D loss:-0.7533 G loss:-1.831\n",
      "Epoch:  0076 D loss:-0.8144 G loss:-1.987\n",
      "Epoch:  0076 D loss:-0.7133 G loss:-1.989\n",
      "Epoch:  0076 D loss:-0.7791 G loss:-1.875\n",
      "Epoch:  0076 D loss:-0.7303 G loss:-1.744\n",
      "Epoch:  0076 D loss:-0.6272 G loss:-1.91\n",
      "Epoch:  0076 D loss:-0.6209 G loss:-2.036\n",
      "Epoch:  0076 D loss:-0.6607 G loss:-1.884\n",
      "Epoch:  0076 D loss:-0.7663 G loss:-1.991\n",
      "Epoch:  0076 D loss:-0.8776 G loss:-1.98\n",
      "Epoch:  0076 D loss:-0.7138 G loss:-2.024\n",
      "Epoch:  0076 D loss:-0.5946 G loss:-2.037\n",
      "Epoch:  0076 D loss:-0.7844 G loss:-1.903\n",
      "Epoch:  0076 D loss:-0.8015 G loss:-2.04\n",
      "Epoch:  0076 D loss:-0.6066 G loss:-2.075\n",
      "Epoch:  0076 D loss:-0.7998 G loss:-1.852\n",
      "Epoch:  0076 D loss:-0.6244 G loss:-2.072\n",
      "Epoch:  0076 D loss:-0.6834 G loss:-2.126\n",
      "Epoch:  0076 D loss:-0.7001 G loss:-1.983\n",
      "Epoch:  0076 D loss:-0.628 G loss:-2.031\n",
      "Epoch:  0076 D loss:-0.6911 G loss:-2.057\n",
      "Epoch:  0076 D loss:-0.7609 G loss:-1.851\n",
      "Epoch:  0076 D loss:-0.7789 G loss:-1.863\n",
      "Epoch:  0076 D loss:-0.7028 G loss:-2.046\n",
      "Epoch:  0076 D loss:-0.7776 G loss:-1.968\n",
      "Epoch:  0076 D loss:-0.7201 G loss:-1.984\n",
      "Epoch:  0076 D loss:-0.6993 G loss:-2.061\n",
      "Epoch:  0076 D loss:-0.8687 G loss:-1.987\n",
      "Epoch:  0076 D loss:-0.7306 G loss:-2.198\n",
      "Epoch:  0076 D loss:-0.7105 G loss:-1.883\n",
      "Epoch:  0076 D loss:-0.6081 G loss:-2.105\n",
      "Epoch:  0076 D loss:-0.6016 G loss:-1.999\n",
      "Epoch:  0076 D loss:-0.5635 G loss:-2.252\n",
      "Epoch:  0076 D loss:-0.6761 G loss:-1.978\n",
      "Epoch:  0076 D loss:-0.6172 G loss:-1.917\n",
      "Epoch:  0076 D loss:-0.6948 G loss:-1.797\n",
      "Epoch:  0076 D loss:-0.7045 G loss:-1.754\n",
      "Epoch:  0076 D loss:-0.6988 G loss:-1.96\n",
      "Epoch:  0076 D loss:-0.7114 G loss:-1.723\n",
      "Epoch:  0076 D loss:-0.6772 G loss:-2.084\n",
      "Epoch:  0076 D loss:-0.6762 G loss:-2.113\n",
      "Epoch:  0076 D loss:-0.6793 G loss:-2.174\n",
      "Epoch:  0076 D loss:-0.8164 G loss:-2.096\n",
      "Epoch:  0076 D loss:-0.5924 G loss:-2.153\n",
      "Epoch:  0076 D loss:-0.6953 G loss:-2.14\n",
      "Epoch:  0076 D loss:-0.6993 G loss:-1.941\n",
      "Epoch:  0076 D loss:-0.8672 G loss:-1.802\n",
      "Epoch:  0076 D loss:-0.7929 G loss:-1.928\n",
      "Epoch:  0076 D loss:-0.8776 G loss:-1.918\n",
      "Epoch:  0076 D loss:-0.6069 G loss:-2.029\n",
      "Epoch:  0076 D loss:-0.7441 G loss:-1.801\n",
      "Epoch:  0076 D loss:-0.7827 G loss:-1.827\n",
      "Epoch:  0076 D loss:-0.8613 G loss:-1.893\n",
      "Epoch:  0076 D loss:-0.6801 G loss:-1.837\n",
      "Epoch:  0076 D loss:-0.7957 G loss:-1.753\n",
      "Epoch:  0076 D loss:-0.8725 G loss:-1.797\n",
      "Epoch:  0076 D loss:-0.7448 G loss:-1.915\n",
      "Epoch:  0076 D loss:-0.7498 G loss:-2.069\n",
      "Epoch:  0076 D loss:-0.6678 G loss:-2.032\n",
      "Epoch:  0076 D loss:-0.7629 G loss:-1.94\n",
      "Epoch:  0076 D loss:-0.7267 G loss:-2.199\n",
      "Epoch:  0076 D loss:-0.6455 G loss:-2.113\n",
      "Epoch:  0076 D loss:-0.7958 G loss:-1.881\n",
      "Epoch:  0076 D loss:-0.5928 G loss:-2.018\n",
      "Epoch:  0076 D loss:-0.7276 G loss:-1.878\n",
      "Epoch:  0076 D loss:-0.6953 G loss:-2.124\n",
      "Epoch:  0076 D loss:-0.6745 G loss:-1.897\n",
      "Epoch:  0076 D loss:-0.7153 G loss:-2.003\n",
      "Epoch:  0076 D loss:-0.7301 G loss:-1.992\n",
      "Epoch:  0076 D loss:-0.6926 G loss:-1.83\n",
      "Epoch:  0076 D loss:-0.9068 G loss:-1.791\n",
      "Epoch:  0076 D loss:-0.702 G loss:-1.942\n",
      "Epoch:  0076 D loss:-0.7318 G loss:-1.955\n",
      "Epoch:  0076 D loss:-0.7478 G loss:-2.05\n",
      "Epoch:  0076 D loss:-0.8783 G loss:-1.888\n",
      "Epoch:  0076 D loss:-0.7628 G loss:-1.993\n",
      "Epoch:  0076 D loss:-0.6811 G loss:-1.931\n",
      "Epoch:  0076 D loss:-0.8299 G loss:-1.9\n",
      "Epoch:  0076 D loss:-0.7107 G loss:-1.985\n",
      "Epoch:  0076 D loss:-0.6995 G loss:-1.856\n",
      "Epoch:  0076 D loss:-0.7352 G loss:-2.059\n",
      "Epoch:  0076 D loss:-0.6257 G loss:-2.015\n",
      "Epoch:  0076 D loss:-0.7497 G loss:-1.872\n",
      "Epoch:  0076 D loss:-0.785 G loss:-1.873\n",
      "Epoch:  0076 D loss:-0.6335 G loss:-2.015\n",
      "Epoch:  0076 D loss:-0.6501 G loss:-1.786\n",
      "Epoch:  0076 D loss:-0.7718 G loss:-1.864\n",
      "Epoch:  0076 D loss:-0.76 G loss:-1.883\n",
      "Epoch:  0076 D loss:-0.7152 G loss:-1.865\n",
      "Epoch:  0076 D loss:-0.7087 G loss:-1.969\n",
      "Epoch:  0076 D loss:-0.7169 G loss:-1.934\n",
      "Epoch:  0076 D loss:-0.6803 G loss:-1.792\n",
      "Epoch:  0076 D loss:-0.7814 G loss:-1.824\n",
      "Epoch:  0076 D loss:-0.8058 G loss:-2.016\n",
      "Epoch:  0076 D loss:-0.6714 G loss:-2.048\n",
      "Epoch:  0076 D loss:-0.7203 G loss:-2.191\n",
      "Epoch:  0076 D loss:-0.7073 G loss:-2.074\n",
      "Epoch:  0076 D loss:-0.6766 G loss:-2.037\n",
      "Epoch:  0076 D loss:-0.8113 G loss:-1.992\n",
      "Epoch:  0076 D loss:-0.8741 G loss:-1.828\n",
      "Epoch:  0076 D loss:-0.6567 G loss:-2.055\n",
      "Epoch:  0076 D loss:-0.7549 G loss:-1.776\n",
      "Epoch:  0076 D loss:-0.8486 G loss:-1.774\n",
      "Epoch:  0076 D loss:-0.8073 G loss:-1.976\n",
      "Epoch:  0076 D loss:-0.7503 G loss:-1.902\n",
      "Epoch:  0076 D loss:-0.7075 G loss:-2.059\n",
      "Epoch:  0076 D loss:-0.6583 G loss:-1.992\n",
      "Epoch:  0076 D loss:-0.8005 G loss:-1.946\n",
      "Epoch:  0076 D loss:-0.8239 G loss:-1.793\n",
      "Epoch:  0076 D loss:-0.6952 G loss:-2.074\n",
      "Epoch:  0076 D loss:-0.7896 G loss:-1.925\n",
      "Epoch:  0076 D loss:-0.656 G loss:-2.325\n",
      "Epoch:  0076 D loss:-0.7186 G loss:-1.934\n",
      "Epoch:  0076 D loss:-0.7247 G loss:-2.098\n",
      "Epoch:  0076 D loss:-0.6607 G loss:-2.252\n",
      "Epoch:  0076 D loss:-0.5347 G loss:-2.202\n",
      "Epoch:  0076 D loss:-0.7884 G loss:-1.92\n",
      "Epoch:  0076 D loss:-0.7344 G loss:-1.987\n",
      "Epoch:  0076 D loss:-0.6654 G loss:-2.023\n",
      "Epoch:  0076 D loss:-0.6413 G loss:-1.758\n",
      "Epoch:  0076 D loss:-0.8871 G loss:-1.88\n",
      "Epoch:  0076 D loss:-0.7066 G loss:-2.025\n",
      "Epoch:  0076 D loss:-0.8675 G loss:-1.912\n",
      "Epoch:  0076 D loss:-0.7502 G loss:-2.059\n",
      "Epoch:  0076 D loss:-0.8458 G loss:-1.846\n",
      "Epoch:  0076 D loss:-0.6649 G loss:-2.102\n",
      "Epoch:  0076 D loss:-0.7342 G loss:-1.996\n",
      "Epoch:  0076 D loss:-0.7374 G loss:-2.114\n",
      "Epoch:  0076 D loss:-0.6578 G loss:-2.288\n",
      "Epoch:  0076 D loss:-0.6927 G loss:-2.177\n",
      "Epoch:  0076 D loss:-0.6854 G loss:-1.831\n",
      "Epoch:  0076 D loss:-0.5829 G loss:-2.071\n",
      "Epoch:  0076 D loss:-0.6648 G loss:-1.975\n",
      "Epoch:  0076 D loss:-0.7558 G loss:-1.94\n",
      "Epoch:  0076 D loss:-0.6909 G loss:-2.192\n",
      "Epoch:  0076 D loss:-0.7678 G loss:-2.091\n",
      "Epoch:  0076 D loss:-0.8337 G loss:-1.758\n",
      "Epoch:  0076 D loss:-0.744 G loss:-1.83\n",
      "Epoch:  0076 D loss:-0.7222 G loss:-1.709\n",
      "Epoch:  0076 D loss:-0.6716 G loss:-2.122\n",
      "Epoch:  0076 D loss:-0.6583 G loss:-2.181\n",
      "Epoch:  0076 D loss:-0.7215 G loss:-1.861\n",
      "Epoch:  0076 D loss:-0.7746 G loss:-2.0\n",
      "Epoch:  0076 D loss:-0.7862 G loss:-1.985\n",
      "Epoch:  0076 D loss:-0.673 G loss:-1.805\n",
      "Epoch:  0076 D loss:-0.5762 G loss:-2.154\n",
      "Epoch:  0076 D loss:-0.6359 G loss:-1.937\n",
      "Epoch:  0076 D loss:-0.7021 G loss:-2.006\n",
      "Epoch:  0076 D loss:-0.6442 G loss:-2.106\n",
      "Epoch:  0076 D loss:-0.8076 G loss:-2.144\n",
      "Epoch:  0076 D loss:-0.6424 G loss:-2.204\n",
      "Epoch:  0076 D loss:-0.7124 G loss:-2.088\n",
      "Epoch:  0076 D loss:-0.6735 G loss:-2.073\n",
      "Epoch:  0076 D loss:-0.7064 G loss:-2.059\n",
      "Epoch:  0076 D loss:-0.9298 G loss:-1.809\n",
      "Epoch:  0076 D loss:-0.6788 G loss:-1.894\n",
      "Epoch:  0076 D loss:-0.7574 G loss:-1.757\n",
      "Epoch:  0076 D loss:-0.7241 G loss:-1.687\n",
      "Epoch:  0076 D loss:-0.7596 G loss:-1.792\n",
      "Epoch:  0076 D loss:-0.7401 G loss:-1.811\n",
      "Epoch:  0076 D loss:-0.7399 G loss:-1.857\n",
      "Epoch:  0076 D loss:-0.8473 G loss:-1.778\n",
      "Epoch:  0076 D loss:-0.5737 G loss:-2.226\n",
      "Epoch:  0076 D loss:-0.7274 G loss:-1.967\n",
      "Epoch:  0076 D loss:-0.6556 G loss:-2.058\n",
      "Epoch:  0076 D loss:-0.848 G loss:-1.906\n",
      "Epoch:  0076 D loss:-0.728 G loss:-2.115\n",
      "Epoch:  0076 D loss:-0.6358 G loss:-2.236\n",
      "Epoch:  0076 D loss:-0.7239 G loss:-2.084\n",
      "Epoch:  0076 D loss:-0.6851 G loss:-2.357\n",
      "Epoch:  0076 D loss:-0.7962 G loss:-1.989\n",
      "Epoch:  0076 D loss:-0.7528 G loss:-2.05\n",
      "Epoch:  0076 D loss:-0.7891 G loss:-1.948\n",
      "Epoch:  0076 D loss:-0.8671 G loss:-1.847\n",
      "Epoch:  0076 D loss:-0.6251 G loss:-1.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0076 D loss:-0.7116 G loss:-1.929\n",
      "Epoch:  0076 D loss:-0.8947 G loss:-1.703\n",
      "Epoch:  0076 D loss:-0.7148 G loss:-1.75\n",
      "Epoch:  0076 D loss:-0.6865 G loss:-1.899\n",
      "Epoch:  0076 D loss:-0.7729 G loss:-1.831\n",
      "Epoch:  0076 D loss:-0.7938 G loss:-1.869\n",
      "Epoch:  0076 D loss:-0.6484 G loss:-2.215\n",
      "Epoch:  0076 D loss:-0.7591 G loss:-2.048\n",
      "Epoch:  0076 D loss:-0.7174 G loss:-2.007\n",
      "Epoch:  0076 D loss:-0.8163 G loss:-1.945\n",
      "Epoch:  0076 D loss:-0.6514 G loss:-2.111\n",
      "Epoch:  0076 D loss:-0.7152 G loss:-1.981\n",
      "Epoch:  0076 D loss:-0.7269 G loss:-1.98\n",
      "Epoch:  0076 D loss:-0.7268 G loss:-2.016\n",
      "Epoch:  0076 D loss:-0.7469 G loss:-2.03\n",
      "Epoch:  0076 D loss:-0.742 G loss:-1.949\n",
      "Epoch:  0076 D loss:-0.6335 G loss:-2.057\n",
      "Epoch:  0076 D loss:-0.8198 G loss:-1.713\n",
      "Epoch:  0076 D loss:-0.7569 G loss:-1.887\n",
      "Epoch:  0076 D loss:-0.8815 G loss:-1.546\n",
      "Epoch:  0076 D loss:-0.6743 G loss:-1.891\n",
      "Epoch:  0076 D loss:-0.816 G loss:-1.794\n",
      "Epoch:  0076 D loss:-0.7798 G loss:-1.908\n",
      "Epoch:  0076 D loss:-0.611 G loss:-1.869\n",
      "Epoch:  0076 D loss:-0.6467 G loss:-1.93\n",
      "Epoch:  0076 D loss:-0.585 G loss:-2.212\n",
      "Epoch:  0076 D loss:-0.8865 G loss:-1.948\n",
      "Epoch:  0076 D loss:-0.5965 G loss:-2.231\n",
      "Epoch:  0076 D loss:-0.7941 G loss:-1.866\n",
      "Epoch:  0076 D loss:-0.8911 G loss:-1.77\n",
      "Epoch:  0076 D loss:-0.6702 G loss:-2.016\n",
      "Epoch:  0076 D loss:-0.7415 G loss:-1.931\n",
      "Epoch:  0076 D loss:-0.8106 G loss:-1.794\n",
      "Epoch:  0076 D loss:-0.576 G loss:-2.13\n",
      "Epoch:  0076 D loss:-0.8931 G loss:-1.984\n",
      "Epoch:  0076 D loss:-0.6798 G loss:-1.873\n",
      "Epoch:  0076 D loss:-0.7274 G loss:-2.042\n",
      "Epoch:  0076 D loss:-0.6611 G loss:-2.06\n",
      "Epoch:  0076 D loss:-0.7797 G loss:-1.942\n",
      "Epoch:  0076 D loss:-0.7006 G loss:-1.902\n",
      "Epoch:  0076 D loss:-0.6746 G loss:-1.813\n",
      "Epoch:  0076 D loss:-0.6534 G loss:-2.134\n",
      "Epoch:  0076 D loss:-0.76 G loss:-2.181\n",
      "Epoch:  0076 D loss:-0.8584 G loss:-2.057\n",
      "Epoch:  0076 D loss:-0.6489 G loss:-1.838\n",
      "Epoch:  0076 D loss:-0.6998 G loss:-1.944\n",
      "Epoch:  0076 D loss:-0.7385 G loss:-1.977\n",
      "Epoch:  0076 D loss:-0.5015 G loss:-1.998\n",
      "Epoch:  0076 D loss:-0.7829 G loss:-1.888\n",
      "Epoch:  0076 D loss:-0.6512 G loss:-2.01\n",
      "Epoch:  0076 D loss:-0.8686 G loss:-1.668\n",
      "Epoch:  0076 D loss:-0.6897 G loss:-1.816\n",
      "Epoch:  0076 D loss:-0.605 G loss:-2.004\n",
      "Epoch:  0076 D loss:-0.7707 G loss:-1.924\n",
      "Epoch:  0076 D loss:-0.7421 G loss:-1.872\n",
      "Epoch:  0076 D loss:-0.6398 G loss:-1.977\n",
      "Epoch:  0076 D loss:-0.6149 G loss:-2.134\n",
      "Epoch:  0076 D loss:-0.7322 G loss:-2.091\n",
      "Epoch:  0076 D loss:-0.6732 G loss:-1.977\n",
      "Epoch:  0076 D loss:-0.696 G loss:-1.997\n",
      "Epoch:  0076 D loss:-0.5437 G loss:-2.145\n",
      "Epoch:  0076 D loss:-0.6358 G loss:-2.084\n",
      "Epoch:  0076 D loss:-0.847 G loss:-1.89\n",
      "Epoch:  0076 D loss:-0.7387 G loss:-1.843\n",
      "Epoch:  0076 D loss:-0.6108 G loss:-2.005\n",
      "Epoch:  0076 D loss:-0.7284 G loss:-1.975\n",
      "Epoch:  0076 D loss:-0.6854 G loss:-2.165\n",
      "Epoch:  0076 D loss:-0.6487 G loss:-2.108\n",
      "Epoch:  0076 D loss:-0.8423 G loss:-1.785\n",
      "Epoch:  0076 D loss:-0.6077 G loss:-2.126\n",
      "Epoch:  0076 D loss:-0.5717 G loss:-1.956\n",
      "Epoch:  0076 D loss:-0.6862 G loss:-1.905\n",
      "Epoch:  0076 D loss:-0.6901 G loss:-2.042\n",
      "Epoch:  0076 D loss:-0.7315 G loss:-1.977\n",
      "Epoch:  0076 D loss:-0.6725 G loss:-1.94\n",
      "Epoch:  0076 D loss:-0.6407 G loss:-2.125\n",
      "Epoch:  0076 D loss:-0.7144 G loss:-1.941\n",
      "Epoch:  0076 D loss:-0.6693 G loss:-1.919\n",
      "Epoch:  0076 D loss:-0.6926 G loss:-1.876\n",
      "Epoch:  0076 D loss:-0.7371 G loss:-2.036\n",
      "Epoch:  0076 D loss:-0.7358 G loss:-2.103\n",
      "Epoch:  0076 D loss:-0.709 G loss:-2.201\n",
      "Epoch:  0076 D loss:-0.5982 G loss:-2.098\n",
      "Epoch:  0076 D loss:-0.7166 G loss:-2.085\n",
      "Epoch:  0076 D loss:-0.6621 G loss:-1.809\n",
      "Epoch:  0076 D loss:-0.7713 G loss:-2.016\n",
      "Epoch:  0076 D loss:-0.7669 G loss:-1.989\n",
      "Epoch:  0076 D loss:-0.6258 G loss:-1.826\n",
      "Epoch:  0076 D loss:-0.7048 G loss:-1.966\n",
      "Epoch:  0076 D loss:-0.749 G loss:-1.844\n",
      "Epoch:  0076 D loss:-0.6343 G loss:-1.829\n",
      "Epoch:  0076 D loss:-0.7366 G loss:-1.861\n",
      "Epoch:  0076 D loss:-0.6805 G loss:-1.997\n",
      "Epoch:  0076 D loss:-0.7438 G loss:-2.021\n",
      "Epoch:  0076 D loss:-0.6246 G loss:-1.997\n",
      "Epoch:  0076 D loss:-0.7574 G loss:-1.998\n",
      "Epoch:  0076 D loss:-0.7052 G loss:-2.034\n",
      "Epoch:  0076 D loss:-0.6815 G loss:-1.959\n",
      "Epoch:  0076 D loss:-0.7204 G loss:-1.945\n",
      "Epoch:  0076 D loss:-0.7333 G loss:-1.984\n",
      "Epoch:  0076 D loss:-0.661 G loss:-2.104\n",
      "Epoch:  0076 D loss:-0.6262 G loss:-2.226\n",
      "Epoch:  0076 D loss:-0.731 G loss:-2.053\n",
      "Epoch:  0076 D loss:-0.6338 G loss:-2.211\n",
      "Epoch:  0076 D loss:-0.7682 G loss:-2.007\n",
      "Epoch:  0076 D loss:-0.7246 G loss:-1.97\n",
      "Epoch:  0076 D loss:-0.8541 G loss:-1.787\n",
      "Epoch:  0076 D loss:-0.9146 G loss:-2.073\n",
      "Epoch:  0076 D loss:-0.8294 G loss:-1.794\n",
      "Epoch:  0076 D loss:-0.6208 G loss:-2.002\n",
      "Epoch:  0076 D loss:-0.6162 G loss:-2.107\n",
      "Epoch:  0076 D loss:-0.7274 G loss:-1.846\n",
      "Epoch:  0076 D loss:-0.6894 G loss:-1.824\n",
      "Epoch:  0076 D loss:-0.7482 G loss:-1.956\n",
      "Epoch:  0076 D loss:-0.7331 G loss:-1.997\n",
      "Epoch:  0076 D loss:-0.6716 G loss:-1.97\n",
      "Epoch:  0076 D loss:-0.8182 G loss:-1.802\n",
      "Epoch:  0076 D loss:-0.7144 G loss:-1.951\n",
      "Epoch:  0076 D loss:-0.7187 G loss:-1.778\n",
      "Epoch:  0076 D loss:-0.6791 G loss:-1.91\n",
      "Epoch:  0076 D loss:-0.6289 G loss:-2.007\n",
      "Epoch:  0076 D loss:-0.8518 G loss:-1.958\n",
      "Epoch:  0076 D loss:-0.7913 G loss:-1.92\n",
      "Epoch:  0076 D loss:-0.7208 G loss:-2.034\n",
      "Epoch:  0076 D loss:-0.6623 G loss:-2.06\n",
      "Epoch:  0076 D loss:-0.7327 G loss:-2.032\n",
      "Epoch:  0076 D loss:-0.8103 G loss:-1.836\n",
      "Epoch:  0076 D loss:-0.5866 G loss:-2.018\n",
      "Epoch:  0076 D loss:-0.7582 G loss:-1.826\n",
      "Epoch:  0076 D loss:-0.8293 G loss:-1.689\n",
      "Epoch:  0076 D loss:-0.8453 G loss:-1.721\n",
      "Epoch:  0076 D loss:-0.7933 G loss:-1.624\n",
      "Epoch:  0076 D loss:-0.842 G loss:-1.62\n",
      "Epoch:  0076 D loss:-0.7004 G loss:-1.954\n",
      "Epoch:  0076 D loss:-0.6542 G loss:-1.977\n",
      "Epoch:  0076 D loss:-0.6598 G loss:-1.933\n",
      "Epoch:  0076 D loss:-0.6607 G loss:-2.118\n",
      "Epoch:  0076 D loss:-0.8492 G loss:-1.915\n",
      "Epoch:  0076 D loss:-0.6888 G loss:-2.196\n",
      "Epoch:  0076 D loss:-0.7442 G loss:-2.164\n",
      "Epoch:  0076 D loss:-0.7763 G loss:-1.984\n",
      "Epoch:  0076 D loss:-0.652 G loss:-2.207\n",
      "Epoch:  0076 D loss:-0.7123 G loss:-2.108\n",
      "Epoch:  0076 D loss:-0.7483 G loss:-1.983\n",
      "Epoch:  0076 D loss:-0.6939 G loss:-1.839\n",
      "Epoch:  0076 D loss:-0.744 G loss:-1.94\n",
      "Epoch:  0076 D loss:-0.7077 G loss:-1.993\n",
      "Epoch:  0076 D loss:-0.6351 G loss:-1.882\n",
      "Epoch:  0076 D loss:-0.7057 G loss:-1.739\n",
      "Epoch:  0076 D loss:-0.8341 G loss:-1.788\n",
      "Epoch:  0076 D loss:-0.6719 G loss:-1.899\n",
      "Epoch:  0076 D loss:-0.8256 G loss:-1.765\n",
      "Epoch:  0076 D loss:-0.8709 G loss:-1.715\n",
      "Epoch:  0076 D loss:-0.6893 G loss:-1.878\n",
      "Epoch:  0076 D loss:-0.7202 G loss:-1.94\n",
      "Epoch:  0076 D loss:-0.6324 G loss:-1.948\n",
      "Epoch:  0076 D loss:-0.8025 G loss:-2.013\n",
      "Epoch:  0076 D loss:-0.6768 G loss:-2.034\n",
      "Epoch:  0076 D loss:-0.7593 G loss:-1.944\n",
      "Epoch:  0076 D loss:-0.8065 G loss:-2.054\n",
      "Epoch:  0076 D loss:-0.892 G loss:-1.994\n",
      "Epoch:  0076 D loss:-0.603 G loss:-2.194\n",
      "Epoch:  0076 D loss:-0.6947 G loss:-1.874\n",
      "Epoch:  0076 D loss:-0.8061 G loss:-1.816\n",
      "Epoch:  0076 D loss:-0.7254 G loss:-1.988\n",
      "Epoch:  0076 D loss:-0.7037 G loss:-1.821\n",
      "Epoch:  0076 D loss:-0.6161 G loss:-2.015\n",
      "Epoch:  0076 D loss:-0.7369 G loss:-1.831\n",
      "Epoch:  0076 D loss:-0.7421 G loss:-1.837\n",
      "Epoch:  0076 D loss:-0.7066 G loss:-1.832\n",
      "Epoch:  0077 D loss:-0.6847 G loss:-2.018\n",
      "Epoch:  0077 D loss:-0.6642 G loss:-1.962\n",
      "Epoch:  0077 D loss:-0.6684 G loss:-2.021\n",
      "Epoch:  0077 D loss:-0.711 G loss:-2.066\n",
      "Epoch:  0077 D loss:-0.6654 G loss:-2.008\n",
      "Epoch:  0077 D loss:-0.8155 G loss:-1.815\n",
      "Epoch:  0077 D loss:-0.6212 G loss:-2.118\n",
      "Epoch:  0077 D loss:-0.5647 G loss:-2.266\n",
      "Epoch:  0077 D loss:-0.6703 G loss:-1.959\n",
      "Epoch:  0077 D loss:-0.7336 G loss:-2.087\n",
      "Epoch:  0077 D loss:-0.6877 G loss:-2.036\n",
      "Epoch:  0077 D loss:-0.7338 G loss:-1.856\n",
      "Epoch:  0077 D loss:-0.7696 G loss:-1.83\n",
      "Epoch:  0077 D loss:-0.7892 G loss:-1.925\n",
      "Epoch:  0077 D loss:-0.7061 G loss:-1.91\n",
      "Epoch:  0077 D loss:-0.7503 G loss:-2.012\n",
      "Epoch:  0077 D loss:-0.7305 G loss:-1.986\n",
      "Epoch:  0077 D loss:-0.6861 G loss:-1.976\n",
      "Epoch:  0077 D loss:-0.7001 G loss:-1.84\n",
      "Epoch:  0077 D loss:-0.593 G loss:-2.162\n",
      "Epoch:  0077 D loss:-0.767 G loss:-2.058\n",
      "Epoch:  0077 D loss:-0.6645 G loss:-2.149\n",
      "Epoch:  0077 D loss:-0.7152 G loss:-2.086\n",
      "Epoch:  0077 D loss:-0.7071 G loss:-2.043\n",
      "Epoch:  0077 D loss:-0.748 G loss:-2.042\n",
      "Epoch:  0077 D loss:-0.6797 G loss:-1.787\n",
      "Epoch:  0077 D loss:-0.7032 G loss:-1.967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0077 D loss:-0.6461 G loss:-2.091\n",
      "Epoch:  0077 D loss:-0.6766 G loss:-1.726\n",
      "Epoch:  0077 D loss:-0.6365 G loss:-1.817\n",
      "Epoch:  0077 D loss:-0.5888 G loss:-1.99\n",
      "Epoch:  0077 D loss:-0.7353 G loss:-2.056\n",
      "Epoch:  0077 D loss:-0.6771 G loss:-1.907\n",
      "Epoch:  0077 D loss:-0.7096 G loss:-1.958\n",
      "Epoch:  0077 D loss:-0.7295 G loss:-1.958\n",
      "Epoch:  0077 D loss:-0.7855 G loss:-2.108\n",
      "Epoch:  0077 D loss:-0.7303 G loss:-2.078\n",
      "Epoch:  0077 D loss:-0.683 G loss:-1.994\n",
      "Epoch:  0077 D loss:-0.7727 G loss:-2.008\n",
      "Epoch:  0077 D loss:-0.7592 G loss:-2.088\n",
      "Epoch:  0077 D loss:-0.6017 G loss:-2.149\n",
      "Epoch:  0077 D loss:-0.7402 G loss:-1.874\n",
      "Epoch:  0077 D loss:-0.6549 G loss:-2.016\n",
      "Epoch:  0077 D loss:-0.5813 G loss:-2.255\n",
      "Epoch:  0077 D loss:-0.6213 G loss:-1.93\n",
      "Epoch:  0077 D loss:-0.7062 G loss:-1.973\n",
      "Epoch:  0077 D loss:-0.8545 G loss:-1.822\n",
      "Epoch:  0077 D loss:-0.7579 G loss:-2.063\n",
      "Epoch:  0077 D loss:-0.7051 G loss:-2.011\n",
      "Epoch:  0077 D loss:-0.7687 G loss:-1.93\n",
      "Epoch:  0077 D loss:-0.6568 G loss:-2.069\n",
      "Epoch:  0077 D loss:-0.5818 G loss:-2.092\n",
      "Epoch:  0077 D loss:-0.7093 G loss:-1.921\n",
      "Epoch:  0077 D loss:-0.6337 G loss:-1.943\n",
      "Epoch:  0077 D loss:-0.7387 G loss:-1.751\n",
      "Epoch:  0077 D loss:-0.623 G loss:-1.944\n",
      "Epoch:  0077 D loss:-0.6747 G loss:-1.763\n",
      "Epoch:  0077 D loss:-0.8148 G loss:-1.916\n",
      "Epoch:  0077 D loss:-0.6715 G loss:-2.057\n",
      "Epoch:  0077 D loss:-0.5959 G loss:-2.144\n",
      "Epoch:  0077 D loss:-0.651 G loss:-2.005\n",
      "Epoch:  0077 D loss:-0.682 G loss:-1.931\n",
      "Epoch:  0077 D loss:-0.9464 G loss:-2.069\n",
      "Epoch:  0077 D loss:-0.7642 G loss:-2.127\n",
      "Epoch:  0077 D loss:-0.7869 G loss:-2.025\n",
      "Epoch:  0077 D loss:-0.6679 G loss:-1.974\n",
      "Epoch:  0077 D loss:-0.8045 G loss:-1.796\n",
      "Epoch:  0077 D loss:-0.7059 G loss:-1.874\n",
      "Epoch:  0077 D loss:-0.7434 G loss:-1.905\n",
      "Epoch:  0077 D loss:-0.8885 G loss:-1.729\n",
      "Epoch:  0077 D loss:-0.6687 G loss:-1.902\n",
      "Epoch:  0077 D loss:-0.7545 G loss:-1.971\n",
      "Epoch:  0077 D loss:-0.7133 G loss:-1.765\n",
      "Epoch:  0077 D loss:-0.7438 G loss:-1.711\n",
      "Epoch:  0077 D loss:-0.6057 G loss:-1.988\n",
      "Epoch:  0077 D loss:-0.8486 G loss:-1.85\n",
      "Epoch:  0077 D loss:-0.82 G loss:-1.978\n",
      "Epoch:  0077 D loss:-0.7506 G loss:-2.018\n",
      "Epoch:  0077 D loss:-0.697 G loss:-2.262\n",
      "Epoch:  0077 D loss:-0.6985 G loss:-2.151\n",
      "Epoch:  0077 D loss:-0.7115 G loss:-1.894\n",
      "Epoch:  0077 D loss:-0.5776 G loss:-1.998\n",
      "Epoch:  0077 D loss:-0.7487 G loss:-1.991\n",
      "Epoch:  0077 D loss:-0.7707 G loss:-2.186\n",
      "Epoch:  0077 D loss:-0.6202 G loss:-2.073\n",
      "Epoch:  0077 D loss:-0.8616 G loss:-1.808\n",
      "Epoch:  0077 D loss:-0.6668 G loss:-1.99\n",
      "Epoch:  0077 D loss:-0.8468 G loss:-1.821\n",
      "Epoch:  0077 D loss:-0.8169 G loss:-1.864\n",
      "Epoch:  0077 D loss:-0.7648 G loss:-1.79\n",
      "Epoch:  0077 D loss:-0.6326 G loss:-1.803\n",
      "Epoch:  0077 D loss:-0.7106 G loss:-1.848\n",
      "Epoch:  0077 D loss:-0.6856 G loss:-1.805\n",
      "Epoch:  0077 D loss:-0.6739 G loss:-1.862\n",
      "Epoch:  0077 D loss:-0.7027 G loss:-1.873\n",
      "Epoch:  0077 D loss:-0.7596 G loss:-1.714\n",
      "Epoch:  0077 D loss:-0.813 G loss:-1.728\n",
      "Epoch:  0077 D loss:-0.6294 G loss:-1.923\n",
      "Epoch:  0077 D loss:-0.8778 G loss:-1.922\n",
      "Epoch:  0077 D loss:-0.7862 G loss:-1.85\n",
      "Epoch:  0077 D loss:-0.7773 G loss:-1.962\n",
      "Epoch:  0077 D loss:-0.8668 G loss:-1.967\n",
      "Epoch:  0077 D loss:-0.7425 G loss:-1.948\n",
      "Epoch:  0077 D loss:-0.6862 G loss:-1.963\n",
      "Epoch:  0077 D loss:-0.6929 G loss:-1.99\n",
      "Epoch:  0077 D loss:-0.8653 G loss:-1.723\n",
      "Epoch:  0077 D loss:-0.8552 G loss:-1.659\n",
      "Epoch:  0077 D loss:-0.7588 G loss:-1.844\n",
      "Epoch:  0077 D loss:-0.8172 G loss:-1.968\n",
      "Epoch:  0077 D loss:-0.7135 G loss:-2.04\n",
      "Epoch:  0077 D loss:-0.6894 G loss:-2.126\n",
      "Epoch:  0077 D loss:-0.5375 G loss:-2.027\n",
      "Epoch:  0077 D loss:-0.7735 G loss:-2.021\n",
      "Epoch:  0077 D loss:-0.6787 G loss:-2.023\n",
      "Epoch:  0077 D loss:-0.8525 G loss:-1.761\n",
      "Epoch:  0077 D loss:-0.7469 G loss:-1.942\n",
      "Epoch:  0077 D loss:-0.729 G loss:-1.919\n",
      "Epoch:  0077 D loss:-0.6381 G loss:-1.927\n",
      "Epoch:  0077 D loss:-0.6873 G loss:-1.891\n",
      "Epoch:  0077 D loss:-0.6683 G loss:-1.976\n",
      "Epoch:  0077 D loss:-0.7797 G loss:-2.017\n",
      "Epoch:  0077 D loss:-0.7238 G loss:-1.9\n",
      "Epoch:  0077 D loss:-0.5983 G loss:-2.009\n",
      "Epoch:  0077 D loss:-0.6312 G loss:-2.07\n",
      "Epoch:  0077 D loss:-0.8889 G loss:-1.842\n",
      "Epoch:  0077 D loss:-0.9125 G loss:-2.011\n",
      "Epoch:  0077 D loss:-0.7456 G loss:-1.791\n",
      "Epoch:  0077 D loss:-0.8093 G loss:-1.983\n",
      "Epoch:  0077 D loss:-0.6638 G loss:-2.154\n",
      "Epoch:  0077 D loss:-0.7304 G loss:-1.816\n",
      "Epoch:  0077 D loss:-0.8015 G loss:-1.801\n",
      "Epoch:  0077 D loss:-0.6573 G loss:-1.996\n",
      "Epoch:  0077 D loss:-0.5605 G loss:-2.04\n",
      "Epoch:  0077 D loss:-0.7196 G loss:-2.134\n",
      "Epoch:  0077 D loss:-0.6763 G loss:-2.021\n",
      "Epoch:  0077 D loss:-0.6052 G loss:-2.053\n",
      "Epoch:  0077 D loss:-0.6627 G loss:-2.019\n",
      "Epoch:  0077 D loss:-0.6035 G loss:-2.061\n",
      "Epoch:  0077 D loss:-0.5813 G loss:-2.101\n",
      "Epoch:  0077 D loss:-0.5732 G loss:-2.05\n",
      "Epoch:  0077 D loss:-0.7292 G loss:-2.06\n",
      "Epoch:  0077 D loss:-0.7813 G loss:-2.11\n",
      "Epoch:  0077 D loss:-0.723 G loss:-2.026\n",
      "Epoch:  0077 D loss:-0.7218 G loss:-2.261\n",
      "Epoch:  0077 D loss:-0.6735 G loss:-2.079\n",
      "Epoch:  0077 D loss:-0.7575 G loss:-1.913\n",
      "Epoch:  0077 D loss:-0.6427 G loss:-2.053\n",
      "Epoch:  0077 D loss:-0.6106 G loss:-2.175\n",
      "Epoch:  0077 D loss:-0.7228 G loss:-2.032\n",
      "Epoch:  0077 D loss:-0.6382 G loss:-2.227\n",
      "Epoch:  0077 D loss:-0.6825 G loss:-1.885\n",
      "Epoch:  0077 D loss:-0.803 G loss:-1.668\n",
      "Epoch:  0077 D loss:-0.6746 G loss:-1.989\n",
      "Epoch:  0077 D loss:-0.6034 G loss:-2.098\n",
      "Epoch:  0077 D loss:-0.5384 G loss:-2.265\n",
      "Epoch:  0077 D loss:-0.6812 G loss:-2.068\n",
      "Epoch:  0077 D loss:-0.6134 G loss:-2.026\n",
      "Epoch:  0077 D loss:-0.6872 G loss:-1.907\n",
      "Epoch:  0077 D loss:-0.5875 G loss:-2.187\n",
      "Epoch:  0077 D loss:-0.7015 G loss:-1.856\n",
      "Epoch:  0077 D loss:-0.6494 G loss:-2.185\n",
      "Epoch:  0077 D loss:-0.6979 G loss:-2.249\n",
      "Epoch:  0077 D loss:-0.5733 G loss:-2.22\n",
      "Epoch:  0077 D loss:-0.6256 G loss:-2.165\n",
      "Epoch:  0077 D loss:-0.6478 G loss:-2.125\n",
      "Epoch:  0077 D loss:-0.7262 G loss:-1.918\n",
      "Epoch:  0077 D loss:-0.7422 G loss:-1.874\n",
      "Epoch:  0077 D loss:-0.6076 G loss:-1.921\n",
      "Epoch:  0077 D loss:-0.629 G loss:-1.895\n",
      "Epoch:  0077 D loss:-0.6639 G loss:-2.187\n",
      "Epoch:  0077 D loss:-0.8104 G loss:-2.128\n",
      "Epoch:  0077 D loss:-0.6938 G loss:-2.238\n",
      "Epoch:  0077 D loss:-0.9094 G loss:-1.862\n",
      "Epoch:  0077 D loss:-0.6512 G loss:-1.941\n",
      "Epoch:  0077 D loss:-0.7842 G loss:-1.941\n",
      "Epoch:  0077 D loss:-0.6504 G loss:-2.004\n",
      "Epoch:  0077 D loss:-0.7706 G loss:-1.935\n",
      "Epoch:  0077 D loss:-0.707 G loss:-2.055\n",
      "Epoch:  0077 D loss:-0.7532 G loss:-1.878\n",
      "Epoch:  0077 D loss:-0.7791 G loss:-1.714\n",
      "Epoch:  0077 D loss:-0.6583 G loss:-1.87\n",
      "Epoch:  0077 D loss:-0.717 G loss:-2.102\n",
      "Epoch:  0077 D loss:-0.613 G loss:-2.041\n",
      "Epoch:  0077 D loss:-0.7501 G loss:-1.911\n",
      "Epoch:  0077 D loss:-0.6002 G loss:-2.109\n",
      "Epoch:  0077 D loss:-0.6261 G loss:-2.101\n",
      "Epoch:  0077 D loss:-0.7256 G loss:-2.017\n",
      "Epoch:  0077 D loss:-0.7422 G loss:-2.084\n",
      "Epoch:  0077 D loss:-0.737 G loss:-2.074\n",
      "Epoch:  0077 D loss:-0.5906 G loss:-2.015\n",
      "Epoch:  0077 D loss:-0.6175 G loss:-1.972\n",
      "Epoch:  0077 D loss:-0.6574 G loss:-1.964\n",
      "Epoch:  0077 D loss:-0.8114 G loss:-2.001\n",
      "Epoch:  0077 D loss:-0.7088 G loss:-1.997\n",
      "Epoch:  0077 D loss:-0.6794 G loss:-1.966\n",
      "Epoch:  0077 D loss:-0.6328 G loss:-1.959\n",
      "Epoch:  0077 D loss:-0.5545 G loss:-1.929\n",
      "Epoch:  0077 D loss:-0.6033 G loss:-1.784\n",
      "Epoch:  0077 D loss:-0.6686 G loss:-1.854\n",
      "Epoch:  0077 D loss:-0.673 G loss:-2.085\n",
      "Epoch:  0077 D loss:-0.6132 G loss:-2.012\n",
      "Epoch:  0077 D loss:-0.8507 G loss:-1.964\n",
      "Epoch:  0077 D loss:-0.5914 G loss:-2.081\n",
      "Epoch:  0077 D loss:-0.6618 G loss:-1.996\n",
      "Epoch:  0077 D loss:-0.678 G loss:-2.019\n",
      "Epoch:  0077 D loss:-0.6778 G loss:-2.128\n",
      "Epoch:  0077 D loss:-0.6756 G loss:-1.959\n",
      "Epoch:  0077 D loss:-0.7109 G loss:-2.007\n",
      "Epoch:  0077 D loss:-0.637 G loss:-2.422\n",
      "Epoch:  0077 D loss:-0.7871 G loss:-2.053\n",
      "Epoch:  0077 D loss:-0.6024 G loss:-2.224\n",
      "Epoch:  0077 D loss:-0.7726 G loss:-1.956\n",
      "Epoch:  0077 D loss:-0.7273 G loss:-2.088\n",
      "Epoch:  0077 D loss:-0.7406 G loss:-2.154\n",
      "Epoch:  0077 D loss:-0.676 G loss:-2.037\n",
      "Epoch:  0077 D loss:-0.8029 G loss:-1.858\n",
      "Epoch:  0077 D loss:-0.8265 G loss:-1.908\n",
      "Epoch:  0077 D loss:-0.7818 G loss:-2.021\n",
      "Epoch:  0077 D loss:-0.6868 G loss:-2.075\n",
      "Epoch:  0077 D loss:-0.759 G loss:-1.741\n",
      "Epoch:  0077 D loss:-0.7451 G loss:-1.777\n",
      "Epoch:  0077 D loss:-0.6529 G loss:-1.731\n",
      "Epoch:  0077 D loss:-0.787 G loss:-1.783\n",
      "Epoch:  0077 D loss:-0.7555 G loss:-1.926\n",
      "Epoch:  0077 D loss:-0.6499 G loss:-2.093\n",
      "Epoch:  0077 D loss:-0.7481 G loss:-1.968\n",
      "Epoch:  0077 D loss:-0.8723 G loss:-1.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0077 D loss:-0.7241 G loss:-1.97\n",
      "Epoch:  0077 D loss:-0.6737 G loss:-2.087\n",
      "Epoch:  0077 D loss:-0.7872 G loss:-1.906\n",
      "Epoch:  0077 D loss:-0.7856 G loss:-1.971\n",
      "Epoch:  0077 D loss:-0.6332 G loss:-2.012\n",
      "Epoch:  0077 D loss:-0.8159 G loss:-2.044\n",
      "Epoch:  0077 D loss:-0.6846 G loss:-2.056\n",
      "Epoch:  0077 D loss:-0.878 G loss:-1.777\n",
      "Epoch:  0077 D loss:-0.7927 G loss:-1.616\n",
      "Epoch:  0077 D loss:-0.8111 G loss:-1.918\n",
      "Epoch:  0077 D loss:-0.7868 G loss:-1.803\n",
      "Epoch:  0077 D loss:-0.8036 G loss:-1.809\n",
      "Epoch:  0077 D loss:-0.6789 G loss:-2.148\n",
      "Epoch:  0077 D loss:-0.5994 G loss:-2.056\n",
      "Epoch:  0077 D loss:-0.7216 G loss:-1.774\n",
      "Epoch:  0077 D loss:-0.7874 G loss:-1.763\n",
      "Epoch:  0077 D loss:-0.78 G loss:-1.991\n",
      "Epoch:  0077 D loss:-0.732 G loss:-2.166\n",
      "Epoch:  0077 D loss:-0.7741 G loss:-1.873\n",
      "Epoch:  0077 D loss:-0.7643 G loss:-1.916\n",
      "Epoch:  0077 D loss:-0.6861 G loss:-1.907\n",
      "Epoch:  0077 D loss:-0.8628 G loss:-1.921\n",
      "Epoch:  0077 D loss:-0.7254 G loss:-1.948\n",
      "Epoch:  0077 D loss:-0.6839 G loss:-2.1\n",
      "Epoch:  0077 D loss:-0.7462 G loss:-1.951\n",
      "Epoch:  0077 D loss:-0.6461 G loss:-2.0\n",
      "Epoch:  0077 D loss:-0.7658 G loss:-1.921\n",
      "Epoch:  0077 D loss:-0.7299 G loss:-1.803\n",
      "Epoch:  0077 D loss:-0.7745 G loss:-2.167\n",
      "Epoch:  0077 D loss:-0.7661 G loss:-1.901\n",
      "Epoch:  0077 D loss:-0.65 G loss:-1.973\n",
      "Epoch:  0077 D loss:-0.6474 G loss:-1.944\n",
      "Epoch:  0077 D loss:-0.9381 G loss:-1.766\n",
      "Epoch:  0077 D loss:-0.6464 G loss:-1.824\n",
      "Epoch:  0077 D loss:-0.8277 G loss:-1.825\n",
      "Epoch:  0077 D loss:-0.7223 G loss:-1.899\n",
      "Epoch:  0077 D loss:-0.8131 G loss:-1.998\n",
      "Epoch:  0077 D loss:-0.5725 G loss:-2.092\n",
      "Epoch:  0077 D loss:-0.8258 G loss:-2.059\n",
      "Epoch:  0077 D loss:-0.7508 G loss:-1.823\n",
      "Epoch:  0077 D loss:-0.6625 G loss:-2.137\n",
      "Epoch:  0077 D loss:-0.7193 G loss:-1.917\n",
      "Epoch:  0077 D loss:-0.8391 G loss:-1.98\n",
      "Epoch:  0077 D loss:-0.7102 G loss:-2.062\n",
      "Epoch:  0077 D loss:-0.6549 G loss:-2.161\n",
      "Epoch:  0077 D loss:-0.7158 G loss:-2.176\n",
      "Epoch:  0077 D loss:-0.7932 G loss:-1.966\n",
      "Epoch:  0077 D loss:-0.8783 G loss:-1.691\n",
      "Epoch:  0077 D loss:-0.7699 G loss:-1.953\n",
      "Epoch:  0077 D loss:-0.7672 G loss:-1.899\n",
      "Epoch:  0077 D loss:-0.6901 G loss:-2.008\n",
      "Epoch:  0077 D loss:-0.8328 G loss:-1.798\n",
      "Epoch:  0077 D loss:-0.9053 G loss:-1.689\n",
      "Epoch:  0077 D loss:-0.8131 G loss:-1.701\n",
      "Epoch:  0077 D loss:-0.6563 G loss:-1.821\n",
      "Epoch:  0077 D loss:-0.6691 G loss:-1.848\n",
      "Epoch:  0077 D loss:-0.777 G loss:-1.914\n",
      "Epoch:  0077 D loss:-0.5533 G loss:-2.342\n",
      "Epoch:  0077 D loss:-0.6769 G loss:-2.138\n",
      "Epoch:  0077 D loss:-0.7953 G loss:-1.766\n",
      "Epoch:  0077 D loss:-0.7538 G loss:-1.964\n",
      "Epoch:  0077 D loss:-0.7638 G loss:-2.015\n",
      "Epoch:  0077 D loss:-0.5349 G loss:-1.992\n",
      "Epoch:  0077 D loss:-0.7206 G loss:-2.168\n",
      "Epoch:  0077 D loss:-0.7494 G loss:-1.981\n",
      "Epoch:  0077 D loss:-0.7168 G loss:-1.867\n",
      "Epoch:  0077 D loss:-0.9296 G loss:-1.764\n",
      "Epoch:  0077 D loss:-0.7555 G loss:-1.964\n",
      "Epoch:  0077 D loss:-0.6357 G loss:-1.835\n",
      "Epoch:  0077 D loss:-0.7987 G loss:-1.951\n",
      "Epoch:  0077 D loss:-0.6873 G loss:-2.014\n",
      "Epoch:  0077 D loss:-0.663 G loss:-1.764\n",
      "Epoch:  0077 D loss:-0.6641 G loss:-1.851\n",
      "Epoch:  0077 D loss:-0.7451 G loss:-1.821\n",
      "Epoch:  0077 D loss:-0.5562 G loss:-2.025\n",
      "Epoch:  0077 D loss:-0.6541 G loss:-1.988\n",
      "Epoch:  0077 D loss:-0.8537 G loss:-1.562\n",
      "Epoch:  0077 D loss:-0.7402 G loss:-2.089\n",
      "Epoch:  0077 D loss:-0.9488 G loss:-1.969\n",
      "Epoch:  0077 D loss:-0.9322 G loss:-1.863\n",
      "Epoch:  0077 D loss:-0.7229 G loss:-1.945\n",
      "Epoch:  0077 D loss:-0.7026 G loss:-1.869\n",
      "Epoch:  0077 D loss:-0.6197 G loss:-1.868\n",
      "Epoch:  0077 D loss:-0.7567 G loss:-1.776\n",
      "Epoch:  0077 D loss:-0.7599 G loss:-1.756\n",
      "Epoch:  0077 D loss:-0.7095 G loss:-1.928\n",
      "Epoch:  0077 D loss:-0.7225 G loss:-1.937\n",
      "Epoch:  0077 D loss:-0.7395 G loss:-2.087\n",
      "Epoch:  0077 D loss:-0.7774 G loss:-2.269\n",
      "Epoch:  0077 D loss:-0.6599 G loss:-2.356\n",
      "Epoch:  0077 D loss:-0.727 G loss:-2.146\n",
      "Epoch:  0077 D loss:-0.7595 G loss:-2.059\n",
      "Epoch:  0077 D loss:-0.7553 G loss:-2.236\n",
      "Epoch:  0077 D loss:-0.8073 G loss:-1.903\n",
      "Epoch:  0077 D loss:-0.6229 G loss:-1.961\n",
      "Epoch:  0077 D loss:-0.584 G loss:-1.797\n",
      "Epoch:  0077 D loss:-0.6993 G loss:-1.674\n",
      "Epoch:  0077 D loss:-0.7462 G loss:-1.719\n",
      "Epoch:  0077 D loss:-0.7596 G loss:-1.876\n",
      "Epoch:  0077 D loss:-0.7847 G loss:-1.857\n",
      "Epoch:  0077 D loss:-0.7014 G loss:-1.987\n",
      "Epoch:  0077 D loss:-0.6672 G loss:-1.853\n",
      "Epoch:  0077 D loss:-0.6331 G loss:-2.004\n",
      "Epoch:  0077 D loss:-0.6262 G loss:-2.077\n",
      "Epoch:  0077 D loss:-0.7795 G loss:-2.129\n",
      "Epoch:  0077 D loss:-0.758 G loss:-2.201\n",
      "Epoch:  0077 D loss:-0.615 G loss:-2.192\n",
      "Epoch:  0077 D loss:-0.6083 G loss:-2.131\n",
      "Epoch:  0077 D loss:-0.5482 G loss:-2.25\n",
      "Epoch:  0077 D loss:-0.7733 G loss:-2.138\n",
      "Epoch:  0077 D loss:-0.6209 G loss:-1.993\n",
      "Epoch:  0077 D loss:-0.6296 G loss:-2.119\n",
      "Epoch:  0077 D loss:-0.7865 G loss:-2.112\n",
      "Epoch:  0077 D loss:-0.5822 G loss:-2.103\n",
      "Epoch:  0077 D loss:-0.7336 G loss:-2.025\n",
      "Epoch:  0077 D loss:-0.7137 G loss:-1.858\n",
      "Epoch:  0077 D loss:-0.7999 G loss:-1.874\n",
      "Epoch:  0077 D loss:-0.5853 G loss:-1.98\n",
      "Epoch:  0077 D loss:-0.7619 G loss:-1.883\n",
      "Epoch:  0077 D loss:-0.6561 G loss:-2.038\n",
      "Epoch:  0077 D loss:-0.545 G loss:-2.013\n",
      "Epoch:  0077 D loss:-0.6571 G loss:-1.953\n",
      "Epoch:  0077 D loss:-0.8176 G loss:-1.864\n",
      "Epoch:  0077 D loss:-0.7823 G loss:-1.949\n",
      "Epoch:  0077 D loss:-0.6558 G loss:-2.057\n",
      "Epoch:  0077 D loss:-0.7315 G loss:-2.092\n",
      "Epoch:  0077 D loss:-0.6933 G loss:-1.909\n",
      "Epoch:  0077 D loss:-0.7352 G loss:-1.941\n",
      "Epoch:  0077 D loss:-0.7606 G loss:-1.743\n",
      "Epoch:  0077 D loss:-0.8466 G loss:-1.85\n",
      "Epoch:  0077 D loss:-0.6801 G loss:-1.752\n",
      "Epoch:  0077 D loss:-0.5949 G loss:-1.914\n",
      "Epoch:  0077 D loss:-0.6748 G loss:-2.062\n",
      "Epoch:  0077 D loss:-0.7487 G loss:-1.95\n",
      "Epoch:  0077 D loss:-0.7223 G loss:-1.83\n",
      "Epoch:  0077 D loss:-0.6858 G loss:-2.116\n",
      "Epoch:  0077 D loss:-0.8102 G loss:-1.992\n",
      "Epoch:  0077 D loss:-0.6145 G loss:-2.136\n",
      "Epoch:  0077 D loss:-0.7026 G loss:-2.041\n",
      "Epoch:  0077 D loss:-0.7342 G loss:-2.11\n",
      "Epoch:  0077 D loss:-0.6264 G loss:-2.133\n",
      "Epoch:  0077 D loss:-0.6659 G loss:-2.099\n",
      "Epoch:  0077 D loss:-0.8269 G loss:-2.11\n",
      "Epoch:  0077 D loss:-0.6562 G loss:-1.907\n",
      "Epoch:  0077 D loss:-0.6119 G loss:-1.907\n",
      "Epoch:  0077 D loss:-0.6425 G loss:-2.35\n",
      "Epoch:  0077 D loss:-0.6704 G loss:-2.105\n",
      "Epoch:  0077 D loss:-0.6881 G loss:-2.135\n",
      "Epoch:  0077 D loss:-0.6858 G loss:-2.123\n",
      "Epoch:  0077 D loss:-0.6371 G loss:-2.106\n",
      "Epoch:  0077 D loss:-0.6331 G loss:-2.276\n",
      "Epoch:  0077 D loss:-0.6953 G loss:-2.126\n",
      "Epoch:  0077 D loss:-0.7116 G loss:-2.0\n",
      "Epoch:  0077 D loss:-0.6429 G loss:-2.095\n",
      "Epoch:  0077 D loss:-0.618 G loss:-1.875\n",
      "Epoch:  0077 D loss:-0.7107 G loss:-1.875\n",
      "Epoch:  0077 D loss:-0.6633 G loss:-2.047\n",
      "Epoch:  0077 D loss:-0.6727 G loss:-2.049\n",
      "Epoch:  0077 D loss:-0.6188 G loss:-2.033\n",
      "Epoch:  0077 D loss:-0.5865 G loss:-2.182\n",
      "Epoch:  0077 D loss:-0.7617 G loss:-1.927\n",
      "Epoch:  0077 D loss:-0.8106 G loss:-1.86\n",
      "Epoch:  0077 D loss:-0.7475 G loss:-2.019\n",
      "Epoch:  0077 D loss:-0.8462 G loss:-2.012\n",
      "Epoch:  0077 D loss:-0.6606 G loss:-2.19\n",
      "Epoch:  0077 D loss:-0.6554 G loss:-1.907\n",
      "Epoch:  0077 D loss:-0.6394 G loss:-2.335\n",
      "Epoch:  0077 D loss:-0.5995 G loss:-2.207\n",
      "Epoch:  0077 D loss:-0.7286 G loss:-1.985\n",
      "Epoch:  0077 D loss:-0.5543 G loss:-2.129\n",
      "Epoch:  0077 D loss:-0.778 G loss:-1.96\n",
      "Epoch:  0077 D loss:-0.6404 G loss:-1.862\n",
      "Epoch:  0077 D loss:-0.6922 G loss:-1.835\n",
      "Epoch:  0077 D loss:-0.72 G loss:-1.858\n",
      "Epoch:  0077 D loss:-0.8115 G loss:-1.989\n",
      "Epoch:  0077 D loss:-0.7351 G loss:-1.991\n",
      "Epoch:  0077 D loss:-0.7664 G loss:-1.783\n",
      "Epoch:  0077 D loss:-0.7187 G loss:-2.025\n",
      "Epoch:  0077 D loss:-0.6917 G loss:-2.07\n",
      "Epoch:  0077 D loss:-0.7505 G loss:-2.15\n",
      "Epoch:  0077 D loss:-0.927 G loss:-2.054\n",
      "Epoch:  0077 D loss:-0.6733 G loss:-1.944\n",
      "Epoch:  0077 D loss:-0.6701 G loss:-2.077\n",
      "Epoch:  0077 D loss:-0.8714 G loss:-1.837\n",
      "Epoch:  0077 D loss:-0.9026 G loss:-2.098\n",
      "Epoch:  0077 D loss:-0.6783 G loss:-2.019\n",
      "Epoch:  0077 D loss:-0.6119 G loss:-1.881\n",
      "Epoch:  0077 D loss:-0.7323 G loss:-1.848\n",
      "Epoch:  0077 D loss:-0.8368 G loss:-1.686\n",
      "Epoch:  0077 D loss:-0.7832 G loss:-1.716\n",
      "Epoch:  0077 D loss:-0.7434 G loss:-2.025\n",
      "Epoch:  0077 D loss:-0.749 G loss:-1.852\n",
      "Epoch:  0077 D loss:-0.7386 G loss:-2.138\n",
      "Epoch:  0077 D loss:-0.6943 G loss:-1.869\n",
      "Epoch:  0077 D loss:-0.7384 G loss:-1.848\n",
      "Epoch:  0077 D loss:-0.6297 G loss:-2.13\n",
      "Epoch:  0077 D loss:-0.806 G loss:-2.025\n",
      "Epoch:  0077 D loss:-0.6486 G loss:-2.178\n",
      "Epoch:  0077 D loss:-0.7825 G loss:-2.178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0077 D loss:-0.7278 G loss:-2.205\n",
      "Epoch:  0077 D loss:-0.7477 G loss:-2.123\n",
      "Epoch:  0077 D loss:-0.735 G loss:-2.113\n",
      "Epoch:  0077 D loss:-0.7008 G loss:-1.958\n",
      "Epoch:  0077 D loss:-0.7803 G loss:-1.975\n",
      "Epoch:  0077 D loss:-0.7417 G loss:-2.137\n",
      "Epoch:  0077 D loss:-0.8115 G loss:-1.716\n",
      "Epoch:  0077 D loss:-0.9578 G loss:-1.73\n",
      "Epoch:  0077 D loss:-0.5532 G loss:-1.912\n",
      "Epoch:  0077 D loss:-0.7718 G loss:-1.855\n",
      "Epoch:  0077 D loss:-0.7912 G loss:-1.877\n",
      "Epoch:  0077 D loss:-0.6375 G loss:-1.851\n",
      "Epoch:  0077 D loss:-0.7167 G loss:-2.077\n",
      "Epoch:  0077 D loss:-0.7015 G loss:-2.011\n",
      "Epoch:  0077 D loss:-0.7519 G loss:-1.953\n",
      "Epoch:  0077 D loss:-0.7083 G loss:-2.081\n",
      "Epoch:  0077 D loss:-0.7973 G loss:-2.157\n",
      "Epoch:  0077 D loss:-0.8308 G loss:-2.233\n",
      "Epoch:  0077 D loss:-0.7975 G loss:-2.147\n",
      "Epoch:  0077 D loss:-0.7538 G loss:-2.045\n",
      "Epoch:  0077 D loss:-0.6979 G loss:-2.008\n",
      "Epoch:  0077 D loss:-0.7193 G loss:-2.036\n",
      "Epoch:  0077 D loss:-0.7143 G loss:-1.897\n",
      "Epoch:  0077 D loss:-0.7479 G loss:-1.662\n",
      "Epoch:  0077 D loss:-0.7829 G loss:-1.86\n",
      "Epoch:  0077 D loss:-0.6597 G loss:-1.867\n",
      "Epoch:  0077 D loss:-0.7381 G loss:-1.793\n",
      "Epoch:  0077 D loss:-0.7121 G loss:-1.823\n",
      "Epoch:  0077 D loss:-0.6879 G loss:-1.848\n",
      "Epoch:  0077 D loss:-0.7299 G loss:-1.767\n",
      "Epoch:  0077 D loss:-0.6933 G loss:-1.952\n",
      "Epoch:  0077 D loss:-0.7885 G loss:-1.821\n",
      "Epoch:  0077 D loss:-0.623 G loss:-2.085\n",
      "Epoch:  0077 D loss:-0.8235 G loss:-1.966\n",
      "Epoch:  0077 D loss:-0.6079 G loss:-2.127\n",
      "Epoch:  0077 D loss:-0.561 G loss:-2.101\n",
      "Epoch:  0077 D loss:-0.7111 G loss:-2.144\n",
      "Epoch:  0077 D loss:-0.703 G loss:-1.971\n",
      "Epoch:  0077 D loss:-0.6739 G loss:-2.011\n",
      "Epoch:  0077 D loss:-0.795 G loss:-2.172\n",
      "Epoch:  0077 D loss:-0.6449 G loss:-2.023\n",
      "Epoch:  0077 D loss:-0.637 G loss:-1.91\n",
      "Epoch:  0077 D loss:-0.6981 G loss:-1.669\n",
      "Epoch:  0077 D loss:-0.7399 G loss:-1.835\n",
      "Epoch:  0077 D loss:-0.7286 G loss:-1.875\n",
      "Epoch:  0077 D loss:-0.5269 G loss:-1.895\n",
      "Epoch:  0077 D loss:-0.6254 G loss:-1.82\n",
      "Epoch:  0077 D loss:-0.6433 G loss:-2.1\n",
      "Epoch:  0077 D loss:-0.6519 G loss:-2.226\n",
      "Epoch:  0077 D loss:-0.7041 G loss:-2.164\n",
      "Epoch:  0077 D loss:-0.7881 G loss:-2.102\n",
      "Epoch:  0077 D loss:-0.661 G loss:-2.047\n",
      "Epoch:  0077 D loss:-0.6474 G loss:-2.188\n",
      "Epoch:  0077 D loss:-0.6792 G loss:-2.292\n",
      "Epoch:  0077 D loss:-0.7287 G loss:-2.141\n",
      "Epoch:  0077 D loss:-0.5473 G loss:-2.208\n",
      "Epoch:  0077 D loss:-0.5999 G loss:-2.143\n",
      "Epoch:  0077 D loss:-0.7061 G loss:-2.155\n",
      "Epoch:  0077 D loss:-0.6709 G loss:-1.889\n",
      "Epoch:  0077 D loss:-0.586 G loss:-2.052\n",
      "Epoch:  0077 D loss:-0.677 G loss:-1.76\n",
      "Epoch:  0077 D loss:-0.639 G loss:-1.938\n",
      "Epoch:  0077 D loss:-0.6776 G loss:-1.925\n",
      "Epoch:  0077 D loss:-0.7364 G loss:-1.88\n",
      "Epoch:  0077 D loss:-0.7775 G loss:-1.826\n",
      "Epoch:  0077 D loss:-0.7466 G loss:-2.119\n",
      "Epoch:  0077 D loss:-0.6359 G loss:-2.051\n",
      "Epoch:  0077 D loss:-0.6198 G loss:-2.073\n",
      "Epoch:  0077 D loss:-0.565 G loss:-2.313\n",
      "Epoch:  0077 D loss:-0.5875 G loss:-2.16\n",
      "Epoch:  0077 D loss:-0.9163 G loss:-2.075\n",
      "Epoch:  0077 D loss:-0.8083 G loss:-2.102\n",
      "Epoch:  0077 D loss:-0.7106 G loss:-2.028\n",
      "Epoch:  0077 D loss:-0.5636 G loss:-2.206\n",
      "Epoch:  0077 D loss:-0.6366 G loss:-1.831\n",
      "Epoch:  0077 D loss:-0.6807 G loss:-1.903\n",
      "Epoch:  0077 D loss:-0.7074 G loss:-1.87\n",
      "Epoch:  0077 D loss:-0.61 G loss:-1.952\n",
      "Epoch:  0077 D loss:-0.5682 G loss:-1.983\n",
      "Epoch:  0077 D loss:-0.6832 G loss:-1.821\n",
      "Epoch:  0077 D loss:-0.6092 G loss:-1.965\n",
      "Epoch:  0077 D loss:-0.6474 G loss:-2.003\n",
      "Epoch:  0077 D loss:-0.6167 G loss:-1.938\n",
      "Epoch:  0077 D loss:-0.7464 G loss:-1.857\n",
      "Epoch:  0077 D loss:-0.6465 G loss:-1.986\n",
      "Epoch:  0077 D loss:-0.7071 G loss:-1.922\n",
      "Epoch:  0077 D loss:-0.6975 G loss:-2.16\n",
      "Epoch:  0077 D loss:-0.6194 G loss:-2.195\n",
      "Epoch:  0077 D loss:-0.6287 G loss:-2.296\n",
      "Epoch:  0077 D loss:-0.7037 G loss:-2.115\n",
      "Epoch:  0077 D loss:-0.7607 G loss:-1.963\n",
      "Epoch:  0077 D loss:-0.7303 G loss:-1.858\n",
      "Epoch:  0077 D loss:-0.7145 G loss:-1.871\n",
      "Epoch:  0077 D loss:-0.6308 G loss:-1.972\n",
      "Epoch:  0077 D loss:-0.8097 G loss:-1.75\n",
      "Epoch:  0077 D loss:-0.6868 G loss:-1.89\n",
      "Epoch:  0077 D loss:-0.6547 G loss:-1.951\n",
      "Epoch:  0077 D loss:-0.7891 G loss:-1.69\n",
      "Epoch:  0077 D loss:-0.7437 G loss:-1.896\n",
      "Epoch:  0077 D loss:-0.7083 G loss:-2.18\n",
      "Epoch:  0077 D loss:-0.626 G loss:-2.09\n",
      "Epoch:  0077 D loss:-0.8237 G loss:-1.822\n",
      "Epoch:  0077 D loss:-0.6876 G loss:-2.03\n",
      "Epoch:  0077 D loss:-0.6271 G loss:-2.066\n",
      "Epoch:  0077 D loss:-0.6324 G loss:-2.146\n",
      "Epoch:  0077 D loss:-0.6411 G loss:-2.302\n",
      "Epoch:  0077 D loss:-0.6708 G loss:-1.963\n",
      "Epoch:  0077 D loss:-0.6095 G loss:-2.147\n",
      "Epoch:  0077 D loss:-0.7131 G loss:-1.926\n",
      "Epoch:  0077 D loss:-0.6775 G loss:-2.08\n",
      "Epoch:  0077 D loss:-0.6593 G loss:-2.138\n",
      "Epoch:  0077 D loss:-0.7471 G loss:-1.981\n",
      "Epoch:  0077 D loss:-0.7076 G loss:-2.099\n",
      "Epoch:  0077 D loss:-0.7273 G loss:-2.032\n",
      "Epoch:  0077 D loss:-0.6445 G loss:-1.967\n",
      "Epoch:  0077 D loss:-0.6441 G loss:-1.929\n",
      "Epoch:  0077 D loss:-0.6887 G loss:-1.82\n",
      "Epoch:  0077 D loss:-0.6755 G loss:-1.909\n",
      "Epoch:  0077 D loss:-0.6578 G loss:-1.856\n",
      "Epoch:  0077 D loss:-0.5887 G loss:-2.008\n",
      "Epoch:  0077 D loss:-0.6064 G loss:-2.152\n",
      "Epoch:  0077 D loss:-0.6658 G loss:-1.995\n",
      "Epoch:  0077 D loss:-0.7857 G loss:-1.843\n",
      "Epoch:  0077 D loss:-0.8287 G loss:-2.003\n",
      "Epoch:  0078 D loss:-0.6792 G loss:-1.908\n",
      "Epoch:  0078 D loss:-0.7784 G loss:-1.806\n",
      "Epoch:  0078 D loss:-0.6825 G loss:-1.846\n",
      "Epoch:  0078 D loss:-0.8247 G loss:-1.94\n",
      "Epoch:  0078 D loss:-0.7789 G loss:-1.903\n",
      "Epoch:  0078 D loss:-0.7122 G loss:-2.009\n",
      "Epoch:  0078 D loss:-0.6074 G loss:-2.286\n",
      "Epoch:  0078 D loss:-0.7196 G loss:-1.986\n",
      "Epoch:  0078 D loss:-0.7669 G loss:-2.182\n",
      "Epoch:  0078 D loss:-0.7577 G loss:-2.037\n",
      "Epoch:  0078 D loss:-0.7337 G loss:-2.028\n",
      "Epoch:  0078 D loss:-0.6796 G loss:-1.904\n",
      "Epoch:  0078 D loss:-0.8149 G loss:-1.739\n",
      "Epoch:  0078 D loss:-0.8273 G loss:-1.822\n",
      "Epoch:  0078 D loss:-0.6066 G loss:-1.854\n",
      "Epoch:  0078 D loss:-0.6332 G loss:-1.798\n",
      "Epoch:  0078 D loss:-0.7294 G loss:-1.923\n",
      "Epoch:  0078 D loss:-0.8033 G loss:-2.0\n",
      "Epoch:  0078 D loss:-0.7557 G loss:-1.795\n",
      "Epoch:  0078 D loss:-0.7069 G loss:-1.962\n",
      "Epoch:  0078 D loss:-0.7154 G loss:-2.019\n",
      "Epoch:  0078 D loss:-0.6297 G loss:-2.298\n",
      "Epoch:  0078 D loss:-0.8186 G loss:-1.987\n",
      "Epoch:  0078 D loss:-0.7487 G loss:-2.228\n",
      "Epoch:  0078 D loss:-0.6358 G loss:-1.947\n",
      "Epoch:  0078 D loss:-0.6782 G loss:-1.969\n",
      "Epoch:  0078 D loss:-0.826 G loss:-1.826\n",
      "Epoch:  0078 D loss:-0.9147 G loss:-1.754\n",
      "Epoch:  0078 D loss:-0.747 G loss:-1.89\n",
      "Epoch:  0078 D loss:-0.8073 G loss:-1.883\n",
      "Epoch:  0078 D loss:-0.6781 G loss:-1.881\n",
      "Epoch:  0078 D loss:-0.7648 G loss:-1.747\n",
      "Epoch:  0078 D loss:-0.8617 G loss:-1.931\n",
      "Epoch:  0078 D loss:-0.6817 G loss:-1.857\n",
      "Epoch:  0078 D loss:-0.6737 G loss:-1.955\n",
      "Epoch:  0078 D loss:-0.7069 G loss:-1.94\n",
      "Epoch:  0078 D loss:-0.7135 G loss:-2.08\n",
      "Epoch:  0078 D loss:-0.7681 G loss:-1.965\n",
      "Epoch:  0078 D loss:-0.6988 G loss:-2.108\n",
      "Epoch:  0078 D loss:-0.6943 G loss:-2.112\n",
      "Epoch:  0078 D loss:-0.7478 G loss:-1.833\n",
      "Epoch:  0078 D loss:-0.7439 G loss:-1.956\n",
      "Epoch:  0078 D loss:-0.6938 G loss:-1.891\n",
      "Epoch:  0078 D loss:-0.6941 G loss:-1.796\n",
      "Epoch:  0078 D loss:-0.8153 G loss:-1.729\n",
      "Epoch:  0078 D loss:-0.7671 G loss:-1.897\n",
      "Epoch:  0078 D loss:-0.777 G loss:-1.907\n",
      "Epoch:  0078 D loss:-0.6308 G loss:-1.922\n",
      "Epoch:  0078 D loss:-0.6202 G loss:-2.007\n",
      "Epoch:  0078 D loss:-0.6015 G loss:-2.017\n",
      "Epoch:  0078 D loss:-0.8539 G loss:-1.993\n",
      "Epoch:  0078 D loss:-0.704 G loss:-1.984\n",
      "Epoch:  0078 D loss:-0.7926 G loss:-1.931\n",
      "Epoch:  0078 D loss:-0.6227 G loss:-1.859\n",
      "Epoch:  0078 D loss:-0.6763 G loss:-1.887\n",
      "Epoch:  0078 D loss:-0.7373 G loss:-2.087\n",
      "Epoch:  0078 D loss:-0.6701 G loss:-1.948\n",
      "Epoch:  0078 D loss:-0.7347 G loss:-2.099\n",
      "Epoch:  0078 D loss:-0.7303 G loss:-2.111\n",
      "Epoch:  0078 D loss:-0.6625 G loss:-2.139\n",
      "Epoch:  0078 D loss:-0.7073 G loss:-2.085\n",
      "Epoch:  0078 D loss:-0.7168 G loss:-2.014\n",
      "Epoch:  0078 D loss:-0.7874 G loss:-1.945\n",
      "Epoch:  0078 D loss:-0.5909 G loss:-2.034\n",
      "Epoch:  0078 D loss:-0.7063 G loss:-1.748\n",
      "Epoch:  0078 D loss:-0.8457 G loss:-1.829\n",
      "Epoch:  0078 D loss:-0.6603 G loss:-2.222\n",
      "Epoch:  0078 D loss:-0.7054 G loss:-1.92\n",
      "Epoch:  0078 D loss:-0.7502 G loss:-2.051\n",
      "Epoch:  0078 D loss:-0.5756 G loss:-2.142\n",
      "Epoch:  0078 D loss:-0.7463 G loss:-1.879\n",
      "Epoch:  0078 D loss:-0.6792 G loss:-1.876\n",
      "Epoch:  0078 D loss:-0.6576 G loss:-1.966\n",
      "Epoch:  0078 D loss:-0.6941 G loss:-1.676\n",
      "Epoch:  0078 D loss:-0.693 G loss:-2.166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0078 D loss:-0.6582 G loss:-2.149\n",
      "Epoch:  0078 D loss:-0.7376 G loss:-2.15\n",
      "Epoch:  0078 D loss:-0.7905 G loss:-2.054\n",
      "Epoch:  0078 D loss:-0.6709 G loss:-1.999\n",
      "Epoch:  0078 D loss:-0.6523 G loss:-2.223\n",
      "Epoch:  0078 D loss:-0.7743 G loss:-2.027\n",
      "Epoch:  0078 D loss:-0.7496 G loss:-1.929\n",
      "Epoch:  0078 D loss:-0.6382 G loss:-2.154\n",
      "Epoch:  0078 D loss:-0.7091 G loss:-1.928\n",
      "Epoch:  0078 D loss:-0.6673 G loss:-2.122\n",
      "Epoch:  0078 D loss:-0.5949 G loss:-2.017\n",
      "Epoch:  0078 D loss:-0.7835 G loss:-2.101\n",
      "Epoch:  0078 D loss:-0.7753 G loss:-1.824\n",
      "Epoch:  0078 D loss:-0.7292 G loss:-1.897\n",
      "Epoch:  0078 D loss:-0.6606 G loss:-1.887\n",
      "Epoch:  0078 D loss:-0.7195 G loss:-1.99\n",
      "Epoch:  0078 D loss:-0.6367 G loss:-2.067\n",
      "Epoch:  0078 D loss:-0.6314 G loss:-2.075\n",
      "Epoch:  0078 D loss:-0.6293 G loss:-2.243\n",
      "Epoch:  0078 D loss:-0.6654 G loss:-2.015\n",
      "Epoch:  0078 D loss:-0.641 G loss:-1.999\n",
      "Epoch:  0078 D loss:-0.585 G loss:-2.25\n",
      "Epoch:  0078 D loss:-0.5901 G loss:-2.186\n",
      "Epoch:  0078 D loss:-0.6525 G loss:-2.039\n",
      "Epoch:  0078 D loss:-0.7013 G loss:-2.082\n",
      "Epoch:  0078 D loss:-0.6002 G loss:-2.174\n",
      "Epoch:  0078 D loss:-0.5931 G loss:-2.03\n",
      "Epoch:  0078 D loss:-0.5341 G loss:-2.112\n",
      "Epoch:  0078 D loss:-0.6562 G loss:-2.124\n",
      "Epoch:  0078 D loss:-0.6973 G loss:-1.974\n",
      "Epoch:  0078 D loss:-0.7644 G loss:-2.045\n",
      "Epoch:  0078 D loss:-0.597 G loss:-2.006\n",
      "Epoch:  0078 D loss:-0.6436 G loss:-2.042\n",
      "Epoch:  0078 D loss:-0.8609 G loss:-1.923\n",
      "Epoch:  0078 D loss:-0.7129 G loss:-2.192\n",
      "Epoch:  0078 D loss:-0.6888 G loss:-2.072\n",
      "Epoch:  0078 D loss:-0.717 G loss:-1.909\n",
      "Epoch:  0078 D loss:-0.8366 G loss:-1.922\n",
      "Epoch:  0078 D loss:-0.5464 G loss:-2.326\n",
      "Epoch:  0078 D loss:-0.659 G loss:-1.902\n",
      "Epoch:  0078 D loss:-0.6578 G loss:-2.183\n",
      "Epoch:  0078 D loss:-0.7551 G loss:-1.866\n",
      "Epoch:  0078 D loss:-0.6955 G loss:-2.073\n",
      "Epoch:  0078 D loss:-0.6446 G loss:-1.908\n",
      "Epoch:  0078 D loss:-0.5524 G loss:-2.089\n",
      "Epoch:  0078 D loss:-0.7178 G loss:-1.765\n",
      "Epoch:  0078 D loss:-0.7383 G loss:-1.848\n",
      "Epoch:  0078 D loss:-0.7415 G loss:-2.364\n",
      "Epoch:  0078 D loss:-0.7558 G loss:-1.987\n",
      "Epoch:  0078 D loss:-0.7308 G loss:-2.032\n",
      "Epoch:  0078 D loss:-0.7429 G loss:-2.192\n",
      "Epoch:  0078 D loss:-0.6716 G loss:-1.953\n",
      "Epoch:  0078 D loss:-0.7444 G loss:-1.995\n",
      "Epoch:  0078 D loss:-0.711 G loss:-1.905\n",
      "Epoch:  0078 D loss:-0.6358 G loss:-1.997\n",
      "Epoch:  0078 D loss:-0.5874 G loss:-2.102\n",
      "Epoch:  0078 D loss:-0.6395 G loss:-2.119\n",
      "Epoch:  0078 D loss:-0.6083 G loss:-2.291\n",
      "Epoch:  0078 D loss:-0.7251 G loss:-2.176\n",
      "Epoch:  0078 D loss:-0.6764 G loss:-2.137\n",
      "Epoch:  0078 D loss:-0.7485 G loss:-1.924\n",
      "Epoch:  0078 D loss:-0.6901 G loss:-1.976\n",
      "Epoch:  0078 D loss:-0.7354 G loss:-2.063\n",
      "Epoch:  0078 D loss:-0.6249 G loss:-2.005\n",
      "Epoch:  0078 D loss:-0.6069 G loss:-1.931\n",
      "Epoch:  0078 D loss:-0.8173 G loss:-1.871\n",
      "Epoch:  0078 D loss:-0.7083 G loss:-2.113\n",
      "Epoch:  0078 D loss:-0.7707 G loss:-2.191\n",
      "Epoch:  0078 D loss:-0.6829 G loss:-2.123\n",
      "Epoch:  0078 D loss:-0.628 G loss:-2.279\n",
      "Epoch:  0078 D loss:-0.6977 G loss:-1.718\n",
      "Epoch:  0078 D loss:-0.7184 G loss:-2.085\n",
      "Epoch:  0078 D loss:-0.7983 G loss:-1.819\n",
      "Epoch:  0078 D loss:-0.6255 G loss:-2.052\n",
      "Epoch:  0078 D loss:-0.7059 G loss:-1.943\n",
      "Epoch:  0078 D loss:-0.6914 G loss:-2.141\n",
      "Epoch:  0078 D loss:-0.7324 G loss:-1.698\n",
      "Epoch:  0078 D loss:-0.6586 G loss:-1.916\n",
      "Epoch:  0078 D loss:-0.6616 G loss:-2.022\n",
      "Epoch:  0078 D loss:-0.6087 G loss:-2.054\n",
      "Epoch:  0078 D loss:-0.7788 G loss:-1.95\n",
      "Epoch:  0078 D loss:-0.7814 G loss:-1.925\n",
      "Epoch:  0078 D loss:-0.6903 G loss:-1.993\n",
      "Epoch:  0078 D loss:-0.6523 G loss:-2.037\n",
      "Epoch:  0078 D loss:-0.8289 G loss:-1.903\n",
      "Epoch:  0078 D loss:-0.8609 G loss:-2.076\n",
      "Epoch:  0078 D loss:-0.7511 G loss:-2.09\n",
      "Epoch:  0078 D loss:-0.8804 G loss:-1.998\n",
      "Epoch:  0078 D loss:-0.7767 G loss:-1.775\n",
      "Epoch:  0078 D loss:-0.8013 G loss:-1.802\n",
      "Epoch:  0078 D loss:-0.7056 G loss:-2.05\n",
      "Epoch:  0078 D loss:-0.8451 G loss:-1.688\n",
      "Epoch:  0078 D loss:-0.7607 G loss:-1.965\n",
      "Epoch:  0078 D loss:-0.801 G loss:-1.699\n",
      "Epoch:  0078 D loss:-0.6855 G loss:-1.924\n",
      "Epoch:  0078 D loss:-0.6485 G loss:-2.106\n",
      "Epoch:  0078 D loss:-0.7969 G loss:-1.834\n",
      "Epoch:  0078 D loss:-0.7305 G loss:-2.144\n",
      "Epoch:  0078 D loss:-0.7402 G loss:-1.833\n",
      "Epoch:  0078 D loss:-0.8741 G loss:-2.019\n",
      "Epoch:  0078 D loss:-0.7977 G loss:-2.103\n",
      "Epoch:  0078 D loss:-0.6984 G loss:-2.095\n",
      "Epoch:  0078 D loss:-0.8003 G loss:-1.916\n",
      "Epoch:  0078 D loss:-0.658 G loss:-2.016\n",
      "Epoch:  0078 D loss:-0.7447 G loss:-1.97\n",
      "Epoch:  0078 D loss:-0.803 G loss:-1.901\n",
      "Epoch:  0078 D loss:-0.7535 G loss:-2.04\n",
      "Epoch:  0078 D loss:-0.76 G loss:-1.881\n",
      "Epoch:  0078 D loss:-0.7802 G loss:-1.709\n",
      "Epoch:  0078 D loss:-0.5895 G loss:-1.921\n",
      "Epoch:  0078 D loss:-0.7338 G loss:-1.968\n",
      "Epoch:  0078 D loss:-0.7426 G loss:-2.01\n",
      "Epoch:  0078 D loss:-0.8266 G loss:-2.047\n",
      "Epoch:  0078 D loss:-0.7145 G loss:-2.223\n",
      "Epoch:  0078 D loss:-0.7529 G loss:-1.999\n",
      "Epoch:  0078 D loss:-0.6171 G loss:-2.098\n",
      "Epoch:  0078 D loss:-0.7925 G loss:-1.92\n",
      "Epoch:  0078 D loss:-0.7459 G loss:-2.002\n",
      "Epoch:  0078 D loss:-0.6613 G loss:-2.132\n",
      "Epoch:  0078 D loss:-0.8405 G loss:-1.857\n",
      "Epoch:  0078 D loss:-0.7872 G loss:-1.926\n",
      "Epoch:  0078 D loss:-0.6543 G loss:-1.917\n",
      "Epoch:  0078 D loss:-0.7344 G loss:-1.85\n",
      "Epoch:  0078 D loss:-0.7124 G loss:-1.896\n",
      "Epoch:  0078 D loss:-0.6094 G loss:-1.976\n",
      "Epoch:  0078 D loss:-0.6874 G loss:-1.963\n",
      "Epoch:  0078 D loss:-0.7434 G loss:-1.719\n",
      "Epoch:  0078 D loss:-0.752 G loss:-1.932\n",
      "Epoch:  0078 D loss:-0.6386 G loss:-1.994\n",
      "Epoch:  0078 D loss:-0.6524 G loss:-2.29\n",
      "Epoch:  0078 D loss:-0.766 G loss:-2.123\n",
      "Epoch:  0078 D loss:-0.7035 G loss:-2.15\n",
      "Epoch:  0078 D loss:-0.6404 G loss:-1.957\n",
      "Epoch:  0078 D loss:-0.6964 G loss:-2.133\n",
      "Epoch:  0078 D loss:-0.7141 G loss:-2.122\n",
      "Epoch:  0078 D loss:-0.7921 G loss:-1.862\n",
      "Epoch:  0078 D loss:-0.8571 G loss:-1.799\n",
      "Epoch:  0078 D loss:-0.6704 G loss:-1.888\n",
      "Epoch:  0078 D loss:-0.617 G loss:-1.957\n",
      "Epoch:  0078 D loss:-0.6978 G loss:-2.005\n",
      "Epoch:  0078 D loss:-0.7437 G loss:-2.055\n",
      "Epoch:  0078 D loss:-0.6343 G loss:-2.073\n",
      "Epoch:  0078 D loss:-0.6323 G loss:-1.949\n",
      "Epoch:  0078 D loss:-0.6958 G loss:-2.019\n",
      "Epoch:  0078 D loss:-0.7346 G loss:-1.97\n",
      "Epoch:  0078 D loss:-0.8684 G loss:-1.977\n",
      "Epoch:  0078 D loss:-0.7084 G loss:-2.067\n",
      "Epoch:  0078 D loss:-0.7778 G loss:-2.251\n",
      "Epoch:  0078 D loss:-0.7737 G loss:-1.958\n",
      "Epoch:  0078 D loss:-0.7089 G loss:-2.001\n",
      "Epoch:  0078 D loss:-0.7217 G loss:-2.205\n",
      "Epoch:  0078 D loss:-0.7025 G loss:-2.058\n",
      "Epoch:  0078 D loss:-0.7222 G loss:-2.033\n",
      "Epoch:  0078 D loss:-0.7292 G loss:-1.892\n",
      "Epoch:  0078 D loss:-0.772 G loss:-1.866\n",
      "Epoch:  0078 D loss:-0.8565 G loss:-1.89\n",
      "Epoch:  0078 D loss:-0.6729 G loss:-1.809\n",
      "Epoch:  0078 D loss:-0.6265 G loss:-1.841\n",
      "Epoch:  0078 D loss:-0.6313 G loss:-1.799\n",
      "Epoch:  0078 D loss:-0.7059 G loss:-2.08\n",
      "Epoch:  0078 D loss:-0.6746 G loss:-2.164\n",
      "Epoch:  0078 D loss:-0.6198 G loss:-2.097\n",
      "Epoch:  0078 D loss:-0.7593 G loss:-1.803\n",
      "Epoch:  0078 D loss:-0.6974 G loss:-2.083\n",
      "Epoch:  0078 D loss:-0.6563 G loss:-2.133\n",
      "Epoch:  0078 D loss:-0.6445 G loss:-2.06\n",
      "Epoch:  0078 D loss:-0.917 G loss:-2.122\n",
      "Epoch:  0078 D loss:-0.7975 G loss:-1.788\n",
      "Epoch:  0078 D loss:-0.6395 G loss:-1.897\n",
      "Epoch:  0078 D loss:-0.6277 G loss:-1.82\n",
      "Epoch:  0078 D loss:-0.6834 G loss:-1.965\n",
      "Epoch:  0078 D loss:-0.6049 G loss:-1.98\n",
      "Epoch:  0078 D loss:-0.724 G loss:-1.836\n",
      "Epoch:  0078 D loss:-0.6579 G loss:-1.945\n",
      "Epoch:  0078 D loss:-0.6798 G loss:-2.014\n",
      "Epoch:  0078 D loss:-0.7134 G loss:-1.897\n",
      "Epoch:  0078 D loss:-0.6397 G loss:-1.984\n",
      "Epoch:  0078 D loss:-0.7351 G loss:-2.163\n",
      "Epoch:  0078 D loss:-0.6144 G loss:-2.311\n",
      "Epoch:  0078 D loss:-0.8607 G loss:-2.038\n",
      "Epoch:  0078 D loss:-0.7634 G loss:-2.201\n",
      "Epoch:  0078 D loss:-0.6862 G loss:-2.1\n",
      "Epoch:  0078 D loss:-0.6753 G loss:-2.068\n",
      "Epoch:  0078 D loss:-0.6848 G loss:-2.083\n",
      "Epoch:  0078 D loss:-0.7311 G loss:-2.086\n",
      "Epoch:  0078 D loss:-0.7502 G loss:-1.957\n",
      "Epoch:  0078 D loss:-0.7572 G loss:-1.998\n",
      "Epoch:  0078 D loss:-0.6307 G loss:-2.061\n",
      "Epoch:  0078 D loss:-0.6918 G loss:-1.678\n",
      "Epoch:  0078 D loss:-0.7628 G loss:-1.792\n",
      "Epoch:  0078 D loss:-0.6501 G loss:-1.994\n",
      "Epoch:  0078 D loss:-0.7473 G loss:-1.904\n",
      "Epoch:  0078 D loss:-0.6338 G loss:-1.871\n",
      "Epoch:  0078 D loss:-0.6546 G loss:-2.084\n",
      "Epoch:  0078 D loss:-0.8156 G loss:-1.885\n",
      "Epoch:  0078 D loss:-0.6688 G loss:-2.106\n",
      "Epoch:  0078 D loss:-0.6339 G loss:-2.041\n",
      "Epoch:  0078 D loss:-0.8325 G loss:-2.027\n",
      "Epoch:  0078 D loss:-0.8322 G loss:-1.821\n",
      "Epoch:  0078 D loss:-0.6487 G loss:-1.945\n",
      "Epoch:  0078 D loss:-0.579 G loss:-1.919\n",
      "Epoch:  0078 D loss:-0.7295 G loss:-1.777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0078 D loss:-0.6634 G loss:-2.004\n",
      "Epoch:  0078 D loss:-0.6573 G loss:-1.995\n",
      "Epoch:  0078 D loss:-0.6914 G loss:-1.902\n",
      "Epoch:  0078 D loss:-0.5356 G loss:-2.196\n",
      "Epoch:  0078 D loss:-0.637 G loss:-2.022\n",
      "Epoch:  0078 D loss:-0.8608 G loss:-1.854\n",
      "Epoch:  0078 D loss:-0.7706 G loss:-1.948\n",
      "Epoch:  0078 D loss:-0.7841 G loss:-2.087\n",
      "Epoch:  0078 D loss:-0.7985 G loss:-1.815\n",
      "Epoch:  0078 D loss:-0.7327 G loss:-2.065\n",
      "Epoch:  0078 D loss:-0.7913 G loss:-1.97\n",
      "Epoch:  0078 D loss:-0.7581 G loss:-2.053\n",
      "Epoch:  0078 D loss:-0.7479 G loss:-1.891\n",
      "Epoch:  0078 D loss:-0.7389 G loss:-1.765\n",
      "Epoch:  0078 D loss:-0.8774 G loss:-1.727\n",
      "Epoch:  0078 D loss:-0.7074 G loss:-1.889\n",
      "Epoch:  0078 D loss:-0.7771 G loss:-1.771\n",
      "Epoch:  0078 D loss:-0.6857 G loss:-2.069\n",
      "Epoch:  0078 D loss:-0.7011 G loss:-1.959\n",
      "Epoch:  0078 D loss:-0.6722 G loss:-1.822\n",
      "Epoch:  0078 D loss:-0.6813 G loss:-1.872\n",
      "Epoch:  0078 D loss:-0.7124 G loss:-1.981\n",
      "Epoch:  0078 D loss:-0.8328 G loss:-1.801\n",
      "Epoch:  0078 D loss:-0.7581 G loss:-1.884\n",
      "Epoch:  0078 D loss:-0.7473 G loss:-2.027\n",
      "Epoch:  0078 D loss:-0.8129 G loss:-1.644\n",
      "Epoch:  0078 D loss:-0.747 G loss:-1.978\n",
      "Epoch:  0078 D loss:-0.5759 G loss:-2.163\n",
      "Epoch:  0078 D loss:-0.708 G loss:-2.098\n",
      "Epoch:  0078 D loss:-0.7461 G loss:-2.006\n",
      "Epoch:  0078 D loss:-0.698 G loss:-2.058\n",
      "Epoch:  0078 D loss:-0.7248 G loss:-1.986\n",
      "Epoch:  0078 D loss:-0.687 G loss:-2.001\n",
      "Epoch:  0078 D loss:-0.6629 G loss:-1.895\n",
      "Epoch:  0078 D loss:-0.7234 G loss:-1.95\n",
      "Epoch:  0078 D loss:-0.7131 G loss:-2.103\n",
      "Epoch:  0078 D loss:-0.6457 G loss:-2.134\n",
      "Epoch:  0078 D loss:-0.8257 G loss:-2.043\n",
      "Epoch:  0078 D loss:-0.7306 G loss:-1.973\n",
      "Epoch:  0078 D loss:-0.6922 G loss:-1.878\n",
      "Epoch:  0078 D loss:-0.7339 G loss:-2.055\n",
      "Epoch:  0078 D loss:-0.6172 G loss:-2.022\n",
      "Epoch:  0078 D loss:-0.7291 G loss:-1.991\n",
      "Epoch:  0078 D loss:-0.7173 G loss:-2.114\n",
      "Epoch:  0078 D loss:-0.7053 G loss:-2.075\n",
      "Epoch:  0078 D loss:-0.7313 G loss:-2.093\n",
      "Epoch:  0078 D loss:-0.7071 G loss:-1.819\n",
      "Epoch:  0078 D loss:-0.6599 G loss:-2.095\n",
      "Epoch:  0078 D loss:-0.7541 G loss:-2.009\n",
      "Epoch:  0078 D loss:-0.8346 G loss:-1.943\n",
      "Epoch:  0078 D loss:-0.8035 G loss:-1.857\n",
      "Epoch:  0078 D loss:-0.7069 G loss:-1.782\n",
      "Epoch:  0078 D loss:-0.7155 G loss:-1.962\n",
      "Epoch:  0078 D loss:-0.6967 G loss:-2.062\n",
      "Epoch:  0078 D loss:-0.6331 G loss:-2.152\n",
      "Epoch:  0078 D loss:-0.6119 G loss:-2.106\n",
      "Epoch:  0078 D loss:-0.5093 G loss:-2.289\n",
      "Epoch:  0078 D loss:-0.6572 G loss:-2.243\n",
      "Epoch:  0078 D loss:-0.6277 G loss:-2.116\n",
      "Epoch:  0078 D loss:-0.6852 G loss:-2.206\n",
      "Epoch:  0078 D loss:-0.7737 G loss:-2.077\n",
      "Epoch:  0078 D loss:-0.7954 G loss:-1.904\n",
      "Epoch:  0078 D loss:-0.7813 G loss:-1.898\n",
      "Epoch:  0078 D loss:-0.6083 G loss:-1.973\n",
      "Epoch:  0078 D loss:-0.6497 G loss:-1.654\n",
      "Epoch:  0078 D loss:-0.7075 G loss:-1.679\n",
      "Epoch:  0078 D loss:-0.6982 G loss:-1.755\n",
      "Epoch:  0078 D loss:-0.7233 G loss:-1.718\n",
      "Epoch:  0078 D loss:-0.7309 G loss:-1.967\n",
      "Epoch:  0078 D loss:-0.608 G loss:-2.151\n",
      "Epoch:  0078 D loss:-0.5354 G loss:-2.225\n",
      "Epoch:  0078 D loss:-0.6557 G loss:-2.581\n",
      "Epoch:  0078 D loss:-0.773 G loss:-2.092\n",
      "Epoch:  0078 D loss:-0.7475 G loss:-2.318\n",
      "Epoch:  0078 D loss:-0.6685 G loss:-2.145\n",
      "Epoch:  0078 D loss:-0.6589 G loss:-1.836\n",
      "Epoch:  0078 D loss:-0.6862 G loss:-2.01\n",
      "Epoch:  0078 D loss:-0.6482 G loss:-1.879\n",
      "Epoch:  0078 D loss:-0.6385 G loss:-2.009\n",
      "Epoch:  0078 D loss:-0.6372 G loss:-1.876\n",
      "Epoch:  0078 D loss:-0.6961 G loss:-1.876\n",
      "Epoch:  0078 D loss:-0.681 G loss:-1.881\n",
      "Epoch:  0078 D loss:-0.7458 G loss:-1.829\n",
      "Epoch:  0078 D loss:-0.7127 G loss:-1.969\n",
      "Epoch:  0078 D loss:-0.5867 G loss:-2.301\n",
      "Epoch:  0078 D loss:-0.6743 G loss:-2.14\n",
      "Epoch:  0078 D loss:-0.6462 G loss:-2.214\n",
      "Epoch:  0078 D loss:-0.7472 G loss:-1.913\n",
      "Epoch:  0078 D loss:-0.6602 G loss:-2.156\n",
      "Epoch:  0078 D loss:-0.6869 G loss:-1.869\n",
      "Epoch:  0078 D loss:-0.8134 G loss:-1.871\n",
      "Epoch:  0078 D loss:-0.7771 G loss:-2.229\n",
      "Epoch:  0078 D loss:-0.7275 G loss:-1.736\n",
      "Epoch:  0078 D loss:-0.6996 G loss:-1.967\n",
      "Epoch:  0078 D loss:-0.9363 G loss:-1.664\n",
      "Epoch:  0078 D loss:-0.7788 G loss:-1.596\n",
      "Epoch:  0078 D loss:-0.7959 G loss:-1.936\n",
      "Epoch:  0078 D loss:-0.7678 G loss:-1.783\n",
      "Epoch:  0078 D loss:-0.8998 G loss:-1.923\n",
      "Epoch:  0078 D loss:-0.7483 G loss:-2.104\n",
      "Epoch:  0078 D loss:-0.7161 G loss:-2.18\n",
      "Epoch:  0078 D loss:-0.5495 G loss:-2.27\n",
      "Epoch:  0078 D loss:-0.7022 G loss:-2.198\n",
      "Epoch:  0078 D loss:-0.698 G loss:-2.157\n",
      "Epoch:  0078 D loss:-0.6945 G loss:-1.972\n",
      "Epoch:  0078 D loss:-0.5456 G loss:-2.065\n",
      "Epoch:  0078 D loss:-0.763 G loss:-1.926\n",
      "Epoch:  0078 D loss:-0.832 G loss:-2.059\n",
      "Epoch:  0078 D loss:-0.7675 G loss:-1.81\n",
      "Epoch:  0078 D loss:-0.7242 G loss:-1.909\n",
      "Epoch:  0078 D loss:-0.7141 G loss:-1.89\n",
      "Epoch:  0078 D loss:-0.7513 G loss:-1.898\n",
      "Epoch:  0078 D loss:-0.6827 G loss:-1.864\n",
      "Epoch:  0078 D loss:-0.5874 G loss:-1.988\n",
      "Epoch:  0078 D loss:-0.686 G loss:-1.965\n",
      "Epoch:  0078 D loss:-0.7701 G loss:-1.876\n",
      "Epoch:  0078 D loss:-0.7268 G loss:-1.953\n",
      "Epoch:  0078 D loss:-0.7753 G loss:-2.016\n",
      "Epoch:  0078 D loss:-0.7101 G loss:-1.816\n",
      "Epoch:  0078 D loss:-0.6853 G loss:-2.001\n",
      "Epoch:  0078 D loss:-0.7162 G loss:-1.972\n",
      "Epoch:  0078 D loss:-0.7744 G loss:-1.857\n",
      "Epoch:  0078 D loss:-0.7224 G loss:-1.967\n",
      "Epoch:  0078 D loss:-0.7555 G loss:-1.866\n",
      "Epoch:  0078 D loss:-0.6861 G loss:-1.983\n",
      "Epoch:  0078 D loss:-0.7478 G loss:-2.162\n",
      "Epoch:  0078 D loss:-0.7446 G loss:-1.932\n",
      "Epoch:  0078 D loss:-0.6454 G loss:-2.025\n",
      "Epoch:  0078 D loss:-0.7408 G loss:-2.14\n",
      "Epoch:  0078 D loss:-0.6525 G loss:-2.038\n",
      "Epoch:  0078 D loss:-0.8681 G loss:-1.674\n",
      "Epoch:  0078 D loss:-0.6559 G loss:-1.946\n",
      "Epoch:  0078 D loss:-0.7039 G loss:-1.776\n",
      "Epoch:  0078 D loss:-0.7013 G loss:-1.821\n",
      "Epoch:  0078 D loss:-0.5816 G loss:-1.842\n",
      "Epoch:  0078 D loss:-0.6032 G loss:-1.983\n",
      "Epoch:  0078 D loss:-0.752 G loss:-1.948\n",
      "Epoch:  0078 D loss:-0.7251 G loss:-2.008\n",
      "Epoch:  0078 D loss:-0.6166 G loss:-2.071\n",
      "Epoch:  0078 D loss:-0.733 G loss:-2.067\n",
      "Epoch:  0078 D loss:-0.6497 G loss:-2.032\n",
      "Epoch:  0078 D loss:-0.8265 G loss:-1.941\n",
      "Epoch:  0078 D loss:-0.5593 G loss:-2.158\n",
      "Epoch:  0078 D loss:-0.7993 G loss:-1.902\n",
      "Epoch:  0078 D loss:-0.8157 G loss:-1.966\n",
      "Epoch:  0078 D loss:-0.682 G loss:-1.927\n",
      "Epoch:  0078 D loss:-0.6742 G loss:-2.269\n",
      "Epoch:  0078 D loss:-0.7637 G loss:-2.051\n",
      "Epoch:  0078 D loss:-0.6081 G loss:-2.083\n",
      "Epoch:  0078 D loss:-0.7301 G loss:-1.979\n",
      "Epoch:  0078 D loss:-0.818 G loss:-1.927\n",
      "Epoch:  0078 D loss:-0.8808 G loss:-1.759\n",
      "Epoch:  0078 D loss:-0.631 G loss:-1.803\n",
      "Epoch:  0078 D loss:-0.6894 G loss:-1.922\n",
      "Epoch:  0078 D loss:-0.7675 G loss:-1.912\n",
      "Epoch:  0078 D loss:-0.633 G loss:-2.104\n",
      "Epoch:  0078 D loss:-0.6029 G loss:-2.046\n",
      "Epoch:  0078 D loss:-0.7406 G loss:-2.016\n",
      "Epoch:  0078 D loss:-0.6851 G loss:-2.034\n",
      "Epoch:  0078 D loss:-0.7163 G loss:-2.109\n",
      "Epoch:  0078 D loss:-0.698 G loss:-2.038\n",
      "Epoch:  0078 D loss:-0.7659 G loss:-2.04\n",
      "Epoch:  0078 D loss:-0.5599 G loss:-2.107\n",
      "Epoch:  0078 D loss:-0.712 G loss:-2.044\n",
      "Epoch:  0078 D loss:-0.6917 G loss:-1.821\n",
      "Epoch:  0078 D loss:-0.7855 G loss:-1.863\n",
      "Epoch:  0078 D loss:-0.7395 G loss:-1.972\n",
      "Epoch:  0078 D loss:-0.6467 G loss:-2.075\n",
      "Epoch:  0078 D loss:-0.7502 G loss:-1.863\n",
      "Epoch:  0078 D loss:-0.6347 G loss:-2.041\n",
      "Epoch:  0078 D loss:-0.7091 G loss:-2.046\n",
      "Epoch:  0078 D loss:-0.6677 G loss:-2.143\n",
      "Epoch:  0078 D loss:-0.8218 G loss:-2.051\n",
      "Epoch:  0078 D loss:-0.5857 G loss:-2.251\n",
      "Epoch:  0078 D loss:-0.5877 G loss:-2.171\n",
      "Epoch:  0078 D loss:-0.7786 G loss:-2.116\n",
      "Epoch:  0078 D loss:-0.7567 G loss:-2.076\n",
      "Epoch:  0078 D loss:-0.5909 G loss:-2.107\n",
      "Epoch:  0078 D loss:-0.7581 G loss:-2.065\n",
      "Epoch:  0078 D loss:-0.7142 G loss:-1.862\n",
      "Epoch:  0078 D loss:-0.7071 G loss:-1.776\n",
      "Epoch:  0078 D loss:-0.6739 G loss:-1.842\n",
      "Epoch:  0078 D loss:-0.6944 G loss:-1.813\n",
      "Epoch:  0078 D loss:-0.6332 G loss:-1.971\n",
      "Epoch:  0078 D loss:-0.8241 G loss:-1.985\n",
      "Epoch:  0078 D loss:-0.7959 G loss:-1.874\n",
      "Epoch:  0078 D loss:-0.7068 G loss:-1.925\n",
      "Epoch:  0078 D loss:-0.5377 G loss:-2.079\n",
      "Epoch:  0078 D loss:-0.5862 G loss:-2.033\n",
      "Epoch:  0078 D loss:-0.63 G loss:-1.914\n",
      "Epoch:  0078 D loss:-0.7786 G loss:-1.983\n",
      "Epoch:  0078 D loss:-0.7449 G loss:-2.118\n",
      "Epoch:  0078 D loss:-0.7657 G loss:-1.989\n",
      "Epoch:  0078 D loss:-0.7263 G loss:-1.996\n",
      "Epoch:  0078 D loss:-0.8037 G loss:-2.02\n",
      "Epoch:  0078 D loss:-0.7614 G loss:-1.987\n",
      "Epoch:  0078 D loss:-0.6656 G loss:-2.159\n",
      "Epoch:  0078 D loss:-0.5627 G loss:-1.954\n",
      "Epoch:  0078 D loss:-0.6832 G loss:-1.92\n",
      "Epoch:  0078 D loss:-0.7236 G loss:-2.159\n",
      "Epoch:  0078 D loss:-0.7021 G loss:-2.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0078 D loss:-0.7259 G loss:-1.868\n",
      "Epoch:  0078 D loss:-0.6805 G loss:-1.717\n",
      "Epoch:  0078 D loss:-0.7136 G loss:-1.884\n",
      "Epoch:  0078 D loss:-0.9624 G loss:-1.938\n",
      "Epoch:  0078 D loss:-0.7131 G loss:-1.875\n",
      "Epoch:  0078 D loss:-0.697 G loss:-2.051\n",
      "Epoch:  0078 D loss:-0.8435 G loss:-1.912\n",
      "Epoch:  0078 D loss:-0.7262 G loss:-1.771\n",
      "Epoch:  0078 D loss:-0.6418 G loss:-1.972\n",
      "Epoch:  0078 D loss:-0.7524 G loss:-1.765\n",
      "Epoch:  0078 D loss:-0.7603 G loss:-1.97\n",
      "Epoch:  0078 D loss:-0.6279 G loss:-1.943\n",
      "Epoch:  0078 D loss:-0.9021 G loss:-2.176\n",
      "Epoch:  0078 D loss:-0.7673 G loss:-2.051\n",
      "Epoch:  0078 D loss:-0.7561 G loss:-1.936\n",
      "Epoch:  0078 D loss:-0.6954 G loss:-1.909\n",
      "Epoch:  0078 D loss:-0.814 G loss:-1.819\n",
      "Epoch:  0078 D loss:-0.7463 G loss:-1.856\n",
      "Epoch:  0078 D loss:-0.6658 G loss:-1.911\n",
      "Epoch:  0078 D loss:-0.724 G loss:-2.014\n",
      "Epoch:  0078 D loss:-0.5891 G loss:-2.011\n",
      "Epoch:  0078 D loss:-0.7045 G loss:-1.977\n",
      "Epoch:  0078 D loss:-0.8386 G loss:-1.997\n",
      "Epoch:  0078 D loss:-0.5743 G loss:-2.166\n",
      "Epoch:  0078 D loss:-0.675 G loss:-2.078\n",
      "Epoch:  0078 D loss:-0.7441 G loss:-2.126\n",
      "Epoch:  0078 D loss:-0.7175 G loss:-1.981\n",
      "Epoch:  0078 D loss:-0.6026 G loss:-2.109\n",
      "Epoch:  0078 D loss:-0.7461 G loss:-1.995\n",
      "Epoch:  0078 D loss:-0.6848 G loss:-2.041\n",
      "Epoch:  0078 D loss:-0.8732 G loss:-1.783\n",
      "Epoch:  0078 D loss:-0.7299 G loss:-2.013\n",
      "Epoch:  0078 D loss:-0.839 G loss:-1.883\n",
      "Epoch:  0078 D loss:-0.7246 G loss:-1.922\n",
      "Epoch:  0078 D loss:-0.8593 G loss:-1.897\n",
      "Epoch:  0078 D loss:-0.6358 G loss:-2.109\n",
      "Epoch:  0078 D loss:-0.6935 G loss:-1.803\n",
      "Epoch:  0078 D loss:-0.6176 G loss:-2.06\n",
      "Epoch:  0078 D loss:-0.7279 G loss:-1.822\n",
      "Epoch:  0078 D loss:-0.7565 G loss:-1.807\n",
      "Epoch:  0078 D loss:-0.6587 G loss:-1.895\n",
      "Epoch:  0078 D loss:-0.8972 G loss:-1.611\n",
      "Epoch:  0078 D loss:-0.7741 G loss:-1.876\n",
      "Epoch:  0078 D loss:-0.711 G loss:-1.853\n",
      "Epoch:  0078 D loss:-0.6995 G loss:-2.201\n",
      "Epoch:  0078 D loss:-0.639 G loss:-2.083\n",
      "Epoch:  0078 D loss:-0.7924 G loss:-1.984\n",
      "Epoch:  0078 D loss:-0.9351 G loss:-1.838\n",
      "Epoch:  0078 D loss:-0.7364 G loss:-2.05\n",
      "Epoch:  0078 D loss:-0.8892 G loss:-2.114\n",
      "Epoch:  0078 D loss:-0.7264 G loss:-1.905\n",
      "Epoch:  0078 D loss:-0.5892 G loss:-2.033\n",
      "Epoch:  0078 D loss:-0.8091 G loss:-2.156\n",
      "Epoch:  0078 D loss:-0.8682 G loss:-1.867\n",
      "Epoch:  0078 D loss:-0.7484 G loss:-2.082\n",
      "Epoch:  0078 D loss:-0.6307 G loss:-1.912\n",
      "Epoch:  0078 D loss:-0.8068 G loss:-1.762\n",
      "Epoch:  0078 D loss:-0.7305 G loss:-1.961\n",
      "Epoch:  0078 D loss:-0.8855 G loss:-1.67\n",
      "Epoch:  0078 D loss:-0.6862 G loss:-1.921\n",
      "Epoch:  0078 D loss:-0.8339 G loss:-1.879\n",
      "Epoch:  0078 D loss:-0.6529 G loss:-2.045\n",
      "Epoch:  0078 D loss:-0.6438 G loss:-2.284\n",
      "Epoch:  0078 D loss:-0.6506 G loss:-1.974\n",
      "Epoch:  0078 D loss:-0.7222 G loss:-2.097\n",
      "Epoch:  0078 D loss:-0.6442 G loss:-2.136\n",
      "Epoch:  0078 D loss:-0.6882 G loss:-2.077\n",
      "Epoch:  0078 D loss:-0.7144 G loss:-1.941\n",
      "Epoch:  0078 D loss:-0.68 G loss:-1.976\n",
      "Epoch:  0078 D loss:-0.6798 G loss:-2.026\n",
      "Epoch:  0078 D loss:-0.6853 G loss:-2.054\n",
      "Epoch:  0078 D loss:-0.676 G loss:-2.055\n",
      "Epoch:  0079 D loss:-0.6344 G loss:-2.087\n",
      "Epoch:  0079 D loss:-0.8055 G loss:-1.928\n",
      "Epoch:  0079 D loss:-0.696 G loss:-1.879\n",
      "Epoch:  0079 D loss:-0.7173 G loss:-2.044\n",
      "Epoch:  0079 D loss:-0.7722 G loss:-2.158\n",
      "Epoch:  0079 D loss:-0.678 G loss:-2.108\n",
      "Epoch:  0079 D loss:-0.7817 G loss:-1.958\n",
      "Epoch:  0079 D loss:-0.7284 G loss:-1.898\n",
      "Epoch:  0079 D loss:-0.6122 G loss:-2.144\n",
      "Epoch:  0079 D loss:-0.6016 G loss:-2.004\n",
      "Epoch:  0079 D loss:-0.7133 G loss:-1.818\n",
      "Epoch:  0079 D loss:-0.6091 G loss:-2.186\n",
      "Epoch:  0079 D loss:-0.5926 G loss:-2.091\n",
      "Epoch:  0079 D loss:-0.6862 G loss:-2.055\n",
      "Epoch:  0079 D loss:-0.5678 G loss:-2.076\n",
      "Epoch:  0079 D loss:-0.7399 G loss:-1.913\n",
      "Epoch:  0079 D loss:-0.8013 G loss:-2.105\n",
      "Epoch:  0079 D loss:-0.7089 G loss:-2.31\n",
      "Epoch:  0079 D loss:-0.7296 G loss:-2.078\n",
      "Epoch:  0079 D loss:-0.7308 G loss:-1.93\n",
      "Epoch:  0079 D loss:-0.6996 G loss:-2.006\n",
      "Epoch:  0079 D loss:-0.7441 G loss:-1.776\n",
      "Epoch:  0079 D loss:-0.696 G loss:-1.775\n",
      "Epoch:  0079 D loss:-0.6803 G loss:-1.861\n",
      "Epoch:  0079 D loss:-0.7829 G loss:-1.913\n",
      "Epoch:  0079 D loss:-0.7466 G loss:-1.739\n",
      "Epoch:  0079 D loss:-0.5848 G loss:-1.965\n",
      "Epoch:  0079 D loss:-0.7119 G loss:-2.026\n",
      "Epoch:  0079 D loss:-0.6374 G loss:-2.14\n",
      "Epoch:  0079 D loss:-0.6997 G loss:-1.857\n",
      "Epoch:  0079 D loss:-0.6318 G loss:-2.077\n",
      "Epoch:  0079 D loss:-0.7878 G loss:-2.05\n",
      "Epoch:  0079 D loss:-0.6066 G loss:-2.322\n",
      "Epoch:  0079 D loss:-0.6798 G loss:-2.073\n",
      "Epoch:  0079 D loss:-0.7625 G loss:-2.157\n",
      "Epoch:  0079 D loss:-0.6376 G loss:-2.156\n",
      "Epoch:  0079 D loss:-0.6282 G loss:-1.907\n",
      "Epoch:  0079 D loss:-0.7524 G loss:-1.845\n",
      "Epoch:  0079 D loss:-0.6185 G loss:-2.005\n",
      "Epoch:  0079 D loss:-0.7781 G loss:-1.814\n",
      "Epoch:  0079 D loss:-0.5734 G loss:-2.06\n",
      "Epoch:  0079 D loss:-0.7428 G loss:-1.975\n",
      "Epoch:  0079 D loss:-0.7408 G loss:-1.951\n",
      "Epoch:  0079 D loss:-0.8123 G loss:-1.886\n",
      "Epoch:  0079 D loss:-0.6843 G loss:-1.819\n",
      "Epoch:  0079 D loss:-0.5463 G loss:-2.125\n",
      "Epoch:  0079 D loss:-0.6948 G loss:-1.952\n",
      "Epoch:  0079 D loss:-0.7241 G loss:-2.038\n",
      "Epoch:  0079 D loss:-0.7341 G loss:-2.069\n",
      "Epoch:  0079 D loss:-0.7469 G loss:-2.108\n",
      "Epoch:  0079 D loss:-0.6456 G loss:-2.066\n",
      "Epoch:  0079 D loss:-0.7213 G loss:-1.838\n",
      "Epoch:  0079 D loss:-0.6255 G loss:-2.227\n",
      "Epoch:  0079 D loss:-0.671 G loss:-2.199\n",
      "Epoch:  0079 D loss:-0.7828 G loss:-2.038\n",
      "Epoch:  0079 D loss:-0.5977 G loss:-2.06\n",
      "Epoch:  0079 D loss:-0.6642 G loss:-1.78\n",
      "Epoch:  0079 D loss:-0.7095 G loss:-1.845\n",
      "Epoch:  0079 D loss:-0.7214 G loss:-1.795\n",
      "Epoch:  0079 D loss:-0.6024 G loss:-2.107\n",
      "Epoch:  0079 D loss:-0.5743 G loss:-2.036\n",
      "Epoch:  0079 D loss:-0.8368 G loss:-1.779\n",
      "Epoch:  0079 D loss:-0.7572 G loss:-2.109\n",
      "Epoch:  0079 D loss:-0.7666 G loss:-2.071\n",
      "Epoch:  0079 D loss:-0.74 G loss:-1.789\n",
      "Epoch:  0079 D loss:-0.6847 G loss:-1.775\n",
      "Epoch:  0079 D loss:-0.7354 G loss:-2.051\n",
      "Epoch:  0079 D loss:-0.7186 G loss:-1.847\n",
      "Epoch:  0079 D loss:-0.6523 G loss:-2.065\n",
      "Epoch:  0079 D loss:-0.7464 G loss:-1.859\n",
      "Epoch:  0079 D loss:-0.7369 G loss:-1.865\n",
      "Epoch:  0079 D loss:-0.7248 G loss:-2.069\n",
      "Epoch:  0079 D loss:-0.7698 G loss:-2.139\n",
      "Epoch:  0079 D loss:-0.7933 G loss:-1.932\n",
      "Epoch:  0079 D loss:-0.6718 G loss:-1.887\n",
      "Epoch:  0079 D loss:-0.683 G loss:-1.849\n",
      "Epoch:  0079 D loss:-0.6667 G loss:-2.163\n",
      "Epoch:  0079 D loss:-0.6049 G loss:-2.059\n",
      "Epoch:  0079 D loss:-0.7249 G loss:-1.989\n",
      "Epoch:  0079 D loss:-0.6887 G loss:-2.008\n",
      "Epoch:  0079 D loss:-0.684 G loss:-2.209\n",
      "Epoch:  0079 D loss:-0.669 G loss:-2.272\n",
      "Epoch:  0079 D loss:-0.7465 G loss:-2.107\n",
      "Epoch:  0079 D loss:-0.8704 G loss:-1.965\n",
      "Epoch:  0079 D loss:-0.7121 G loss:-1.889\n",
      "Epoch:  0079 D loss:-0.8316 G loss:-2.05\n",
      "Epoch:  0079 D loss:-0.7642 G loss:-1.628\n",
      "Epoch:  0079 D loss:-0.8155 G loss:-2.021\n",
      "Epoch:  0079 D loss:-0.7896 G loss:-1.68\n",
      "Epoch:  0079 D loss:-0.788 G loss:-1.68\n",
      "Epoch:  0079 D loss:-0.695 G loss:-1.737\n",
      "Epoch:  0079 D loss:-0.8085 G loss:-1.826\n",
      "Epoch:  0079 D loss:-0.7326 G loss:-1.666\n",
      "Epoch:  0079 D loss:-0.7251 G loss:-1.892\n",
      "Epoch:  0079 D loss:-0.6703 G loss:-1.808\n",
      "Epoch:  0079 D loss:-0.7114 G loss:-1.898\n",
      "Epoch:  0079 D loss:-0.6811 G loss:-1.898\n",
      "Epoch:  0079 D loss:-0.8231 G loss:-1.974\n",
      "Epoch:  0079 D loss:-0.7704 G loss:-2.187\n",
      "Epoch:  0079 D loss:-0.607 G loss:-2.167\n",
      "Epoch:  0079 D loss:-0.7001 G loss:-2.079\n",
      "Epoch:  0079 D loss:-0.7378 G loss:-2.218\n",
      "Epoch:  0079 D loss:-0.7157 G loss:-2.142\n",
      "Epoch:  0079 D loss:-0.7318 G loss:-1.934\n",
      "Epoch:  0079 D loss:-0.7962 G loss:-2.086\n",
      "Epoch:  0079 D loss:-0.7142 G loss:-1.831\n",
      "Epoch:  0079 D loss:-0.6852 G loss:-1.914\n",
      "Epoch:  0079 D loss:-0.7017 G loss:-1.891\n",
      "Epoch:  0079 D loss:-0.7114 G loss:-1.944\n",
      "Epoch:  0079 D loss:-0.7657 G loss:-1.862\n",
      "Epoch:  0079 D loss:-0.8797 G loss:-1.909\n",
      "Epoch:  0079 D loss:-0.6423 G loss:-1.971\n",
      "Epoch:  0079 D loss:-0.7228 G loss:-1.914\n",
      "Epoch:  0079 D loss:-0.8025 G loss:-1.951\n",
      "Epoch:  0079 D loss:-0.6273 G loss:-1.977\n",
      "Epoch:  0079 D loss:-0.8058 G loss:-1.912\n",
      "Epoch:  0079 D loss:-0.6851 G loss:-1.967\n",
      "Epoch:  0079 D loss:-0.6854 G loss:-1.94\n",
      "Epoch:  0079 D loss:-0.7103 G loss:-2.026\n",
      "Epoch:  0079 D loss:-0.6201 G loss:-1.971\n",
      "Epoch:  0079 D loss:-0.8953 G loss:-1.955\n",
      "Epoch:  0079 D loss:-0.6357 G loss:-2.12\n",
      "Epoch:  0079 D loss:-0.6816 G loss:-1.995\n",
      "Epoch:  0079 D loss:-0.701 G loss:-2.01\n",
      "Epoch:  0079 D loss:-0.6423 G loss:-2.012\n",
      "Epoch:  0079 D loss:-0.7278 G loss:-1.961\n",
      "Epoch:  0079 D loss:-0.8549 G loss:-1.646\n",
      "Epoch:  0079 D loss:-0.7775 G loss:-1.649\n",
      "Epoch:  0079 D loss:-0.7264 G loss:-1.692\n",
      "Epoch:  0079 D loss:-0.7645 G loss:-1.766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0079 D loss:-0.609 G loss:-1.991\n",
      "Epoch:  0079 D loss:-0.7837 G loss:-1.971\n",
      "Epoch:  0079 D loss:-0.7283 G loss:-1.958\n",
      "Epoch:  0079 D loss:-0.7607 G loss:-1.843\n",
      "Epoch:  0079 D loss:-0.6547 G loss:-2.233\n",
      "Epoch:  0079 D loss:-0.7316 G loss:-2.021\n",
      "Epoch:  0079 D loss:-0.6742 G loss:-2.356\n",
      "Epoch:  0079 D loss:-0.7685 G loss:-2.201\n",
      "Epoch:  0079 D loss:-0.6336 G loss:-2.01\n",
      "Epoch:  0079 D loss:-0.611 G loss:-2.134\n",
      "Epoch:  0079 D loss:-0.6942 G loss:-2.25\n",
      "Epoch:  0079 D loss:-0.8667 G loss:-1.89\n",
      "Epoch:  0079 D loss:-0.6779 G loss:-1.908\n",
      "Epoch:  0079 D loss:-0.6539 G loss:-2.083\n",
      "Epoch:  0079 D loss:-0.6805 G loss:-1.872\n",
      "Epoch:  0079 D loss:-0.6915 G loss:-1.82\n",
      "Epoch:  0079 D loss:-0.7089 G loss:-1.894\n",
      "Epoch:  0079 D loss:-0.6818 G loss:-1.943\n",
      "Epoch:  0079 D loss:-0.6383 G loss:-1.938\n",
      "Epoch:  0079 D loss:-0.7221 G loss:-1.821\n",
      "Epoch:  0079 D loss:-0.8294 G loss:-1.929\n",
      "Epoch:  0079 D loss:-0.5956 G loss:-2.122\n",
      "Epoch:  0079 D loss:-0.6198 G loss:-2.263\n",
      "Epoch:  0079 D loss:-0.6234 G loss:-2.242\n",
      "Epoch:  0079 D loss:-0.4893 G loss:-2.287\n",
      "Epoch:  0079 D loss:-0.6341 G loss:-2.174\n",
      "Epoch:  0079 D loss:-0.6881 G loss:-2.044\n",
      "Epoch:  0079 D loss:-0.7651 G loss:-1.91\n",
      "Epoch:  0079 D loss:-0.6646 G loss:-2.065\n",
      "Epoch:  0079 D loss:-0.6333 G loss:-1.977\n",
      "Epoch:  0079 D loss:-0.7226 G loss:-1.964\n",
      "Epoch:  0079 D loss:-0.7266 G loss:-1.852\n",
      "Epoch:  0079 D loss:-0.5989 G loss:-2.021\n",
      "Epoch:  0079 D loss:-0.5807 G loss:-1.975\n",
      "Epoch:  0079 D loss:-0.5668 G loss:-2.145\n",
      "Epoch:  0079 D loss:-0.671 G loss:-1.911\n",
      "Epoch:  0079 D loss:-0.6325 G loss:-1.961\n",
      "Epoch:  0079 D loss:-0.7209 G loss:-2.191\n",
      "Epoch:  0079 D loss:-0.54 G loss:-2.337\n",
      "Epoch:  0079 D loss:-0.5834 G loss:-1.947\n",
      "Epoch:  0079 D loss:-0.6525 G loss:-1.903\n",
      "Epoch:  0079 D loss:-0.4678 G loss:-2.403\n",
      "Epoch:  0079 D loss:-0.5281 G loss:-2.314\n",
      "Epoch:  0079 D loss:-0.7258 G loss:-1.974\n",
      "Epoch:  0079 D loss:-0.6859 G loss:-2.255\n",
      "Epoch:  0079 D loss:-0.5923 G loss:-2.474\n",
      "Epoch:  0079 D loss:-0.5539 G loss:-2.205\n",
      "Epoch:  0079 D loss:-0.6834 G loss:-2.112\n",
      "Epoch:  0079 D loss:-0.4951 G loss:-2.241\n",
      "Epoch:  0079 D loss:-0.6744 G loss:-2.181\n",
      "Epoch:  0079 D loss:-0.7087 G loss:-2.142\n",
      "Epoch:  0079 D loss:-0.624 G loss:-2.107\n",
      "Epoch:  0079 D loss:-0.6618 G loss:-2.028\n",
      "Epoch:  0079 D loss:-0.6356 G loss:-1.979\n",
      "Epoch:  0079 D loss:-0.6307 G loss:-2.02\n",
      "Epoch:  0079 D loss:-0.7704 G loss:-1.963\n",
      "Epoch:  0079 D loss:-0.6479 G loss:-2.009\n",
      "Epoch:  0079 D loss:-0.6887 G loss:-2.09\n",
      "Epoch:  0079 D loss:-0.6668 G loss:-2.17\n",
      "Epoch:  0079 D loss:-0.6264 G loss:-2.01\n",
      "Epoch:  0079 D loss:-0.6567 G loss:-1.971\n",
      "Epoch:  0079 D loss:-0.6849 G loss:-2.294\n",
      "Epoch:  0079 D loss:-0.7462 G loss:-2.054\n",
      "Epoch:  0079 D loss:-0.5478 G loss:-2.277\n",
      "Epoch:  0079 D loss:-0.6342 G loss:-2.028\n",
      "Epoch:  0079 D loss:-0.7758 G loss:-2.034\n",
      "Epoch:  0079 D loss:-0.6549 G loss:-2.09\n",
      "Epoch:  0079 D loss:-0.6911 G loss:-1.91\n",
      "Epoch:  0079 D loss:-0.7977 G loss:-1.964\n",
      "Epoch:  0079 D loss:-0.5686 G loss:-2.251\n",
      "Epoch:  0079 D loss:-0.634 G loss:-2.181\n",
      "Epoch:  0079 D loss:-0.6753 G loss:-2.148\n",
      "Epoch:  0079 D loss:-0.7905 G loss:-1.992\n",
      "Epoch:  0079 D loss:-0.5387 G loss:-2.274\n",
      "Epoch:  0079 D loss:-0.6447 G loss:-1.987\n",
      "Epoch:  0079 D loss:-0.631 G loss:-2.01\n",
      "Epoch:  0079 D loss:-0.6725 G loss:-1.88\n",
      "Epoch:  0079 D loss:-0.6271 G loss:-2.087\n",
      "Epoch:  0079 D loss:-0.652 G loss:-1.988\n",
      "Epoch:  0079 D loss:-0.7345 G loss:-2.167\n",
      "Epoch:  0079 D loss:-0.5877 G loss:-2.069\n",
      "Epoch:  0079 D loss:-0.7339 G loss:-2.144\n",
      "Epoch:  0079 D loss:-0.6587 G loss:-1.975\n",
      "Epoch:  0079 D loss:-0.7869 G loss:-2.05\n",
      "Epoch:  0079 D loss:-0.7537 G loss:-2.02\n",
      "Epoch:  0079 D loss:-0.6832 G loss:-1.914\n",
      "Epoch:  0079 D loss:-0.6105 G loss:-2.0\n",
      "Epoch:  0079 D loss:-0.7443 G loss:-1.964\n",
      "Epoch:  0079 D loss:-0.7295 G loss:-2.132\n",
      "Epoch:  0079 D loss:-0.7794 G loss:-1.776\n",
      "Epoch:  0079 D loss:-0.6383 G loss:-1.873\n",
      "Epoch:  0079 D loss:-0.686 G loss:-1.969\n",
      "Epoch:  0079 D loss:-0.6983 G loss:-1.83\n",
      "Epoch:  0079 D loss:-0.8437 G loss:-1.895\n",
      "Epoch:  0079 D loss:-0.6426 G loss:-2.168\n",
      "Epoch:  0079 D loss:-0.679 G loss:-2.052\n",
      "Epoch:  0079 D loss:-0.7061 G loss:-2.208\n",
      "Epoch:  0079 D loss:-0.7027 G loss:-2.204\n",
      "Epoch:  0079 D loss:-0.5966 G loss:-2.14\n",
      "Epoch:  0079 D loss:-0.684 G loss:-2.185\n",
      "Epoch:  0079 D loss:-0.7008 G loss:-2.086\n",
      "Epoch:  0079 D loss:-0.6325 G loss:-2.038\n",
      "Epoch:  0079 D loss:-0.5799 G loss:-2.059\n",
      "Epoch:  0079 D loss:-0.8473 G loss:-2.16\n",
      "Epoch:  0079 D loss:-0.7476 G loss:-1.893\n",
      "Epoch:  0079 D loss:-0.708 G loss:-1.745\n",
      "Epoch:  0079 D loss:-0.8886 G loss:-1.734\n",
      "Epoch:  0079 D loss:-0.7301 G loss:-1.983\n",
      "Epoch:  0079 D loss:-0.9022 G loss:-1.946\n",
      "Epoch:  0079 D loss:-0.7921 G loss:-1.734\n",
      "Epoch:  0079 D loss:-0.7686 G loss:-1.896\n",
      "Epoch:  0079 D loss:-0.7417 G loss:-1.898\n",
      "Epoch:  0079 D loss:-0.8615 G loss:-1.746\n",
      "Epoch:  0079 D loss:-0.7313 G loss:-2.147\n",
      "Epoch:  0079 D loss:-0.6632 G loss:-2.24\n",
      "Epoch:  0079 D loss:-0.7516 G loss:-1.973\n",
      "Epoch:  0079 D loss:-0.85 G loss:-1.87\n",
      "Epoch:  0079 D loss:-0.8548 G loss:-1.797\n",
      "Epoch:  0079 D loss:-0.7534 G loss:-1.912\n",
      "Epoch:  0079 D loss:-0.8243 G loss:-1.799\n",
      "Epoch:  0079 D loss:-0.7299 G loss:-1.886\n",
      "Epoch:  0079 D loss:-0.8177 G loss:-1.863\n",
      "Epoch:  0079 D loss:-0.8348 G loss:-1.977\n",
      "Epoch:  0079 D loss:-0.8044 G loss:-1.787\n",
      "Epoch:  0079 D loss:-0.8897 G loss:-1.899\n",
      "Epoch:  0079 D loss:-0.7414 G loss:-1.92\n",
      "Epoch:  0079 D loss:-0.6935 G loss:-1.804\n",
      "Epoch:  0079 D loss:-0.8777 G loss:-1.848\n",
      "Epoch:  0079 D loss:-0.797 G loss:-2.022\n",
      "Epoch:  0079 D loss:-0.744 G loss:-1.962\n",
      "Epoch:  0079 D loss:-0.7364 G loss:-2.003\n",
      "Epoch:  0079 D loss:-0.8044 G loss:-1.572\n",
      "Epoch:  0079 D loss:-0.7299 G loss:-1.865\n",
      "Epoch:  0079 D loss:-0.7849 G loss:-1.832\n",
      "Epoch:  0079 D loss:-0.8266 G loss:-1.603\n",
      "Epoch:  0079 D loss:-0.655 G loss:-1.941\n",
      "Epoch:  0079 D loss:-0.7277 G loss:-1.886\n",
      "Epoch:  0079 D loss:-0.7639 G loss:-1.967\n",
      "Epoch:  0079 D loss:-0.7287 G loss:-1.989\n",
      "Epoch:  0079 D loss:-0.6235 G loss:-2.003\n",
      "Epoch:  0079 D loss:-0.668 G loss:-2.023\n",
      "Epoch:  0079 D loss:-0.5531 G loss:-2.127\n",
      "Epoch:  0079 D loss:-0.7318 G loss:-2.09\n",
      "Epoch:  0079 D loss:-0.7996 G loss:-2.303\n",
      "Epoch:  0079 D loss:-0.8272 G loss:-2.039\n",
      "Epoch:  0079 D loss:-0.658 G loss:-2.097\n",
      "Epoch:  0079 D loss:-0.9544 G loss:-1.94\n",
      "Epoch:  0079 D loss:-0.7651 G loss:-1.95\n",
      "Epoch:  0079 D loss:-0.7126 G loss:-1.976\n",
      "Epoch:  0079 D loss:-0.7225 G loss:-1.861\n",
      "Epoch:  0079 D loss:-0.6103 G loss:-2.088\n",
      "Epoch:  0079 D loss:-0.8046 G loss:-1.916\n",
      "Epoch:  0079 D loss:-0.8395 G loss:-1.76\n",
      "Epoch:  0079 D loss:-0.694 G loss:-1.771\n",
      "Epoch:  0079 D loss:-0.7355 G loss:-1.927\n",
      "Epoch:  0079 D loss:-0.6868 G loss:-2.061\n",
      "Epoch:  0079 D loss:-0.7196 G loss:-1.893\n",
      "Epoch:  0079 D loss:-0.5942 G loss:-1.986\n",
      "Epoch:  0079 D loss:-0.6583 G loss:-1.933\n",
      "Epoch:  0079 D loss:-0.681 G loss:-2.082\n",
      "Epoch:  0079 D loss:-0.4721 G loss:-2.281\n",
      "Epoch:  0079 D loss:-0.558 G loss:-2.466\n",
      "Epoch:  0079 D loss:-0.5697 G loss:-2.204\n",
      "Epoch:  0079 D loss:-0.6266 G loss:-2.083\n",
      "Epoch:  0079 D loss:-0.5695 G loss:-2.2\n",
      "Epoch:  0079 D loss:-0.6531 G loss:-1.871\n",
      "Epoch:  0079 D loss:-0.6413 G loss:-2.043\n",
      "Epoch:  0079 D loss:-0.6208 G loss:-2.264\n",
      "Epoch:  0079 D loss:-0.5445 G loss:-1.889\n",
      "Epoch:  0079 D loss:-0.7157 G loss:-2.019\n",
      "Epoch:  0079 D loss:-0.6704 G loss:-1.927\n",
      "Epoch:  0079 D loss:-0.5049 G loss:-2.117\n",
      "Epoch:  0079 D loss:-0.7367 G loss:-2.027\n",
      "Epoch:  0079 D loss:-0.8379 G loss:-2.183\n",
      "Epoch:  0079 D loss:-0.6642 G loss:-2.107\n",
      "Epoch:  0079 D loss:-0.7557 G loss:-2.131\n",
      "Epoch:  0079 D loss:-0.6943 G loss:-1.701\n",
      "Epoch:  0079 D loss:-0.7249 G loss:-1.79\n",
      "Epoch:  0079 D loss:-0.7844 G loss:-1.652\n",
      "Epoch:  0079 D loss:-0.6067 G loss:-1.825\n",
      "Epoch:  0079 D loss:-0.5687 G loss:-1.951\n",
      "Epoch:  0079 D loss:-0.6682 G loss:-1.966\n",
      "Epoch:  0079 D loss:-0.7221 G loss:-2.116\n",
      "Epoch:  0079 D loss:-0.7589 G loss:-2.261\n",
      "Epoch:  0079 D loss:-0.696 G loss:-2.23\n",
      "Epoch:  0079 D loss:-0.8079 G loss:-2.253\n",
      "Epoch:  0079 D loss:-0.6154 G loss:-2.2\n",
      "Epoch:  0079 D loss:-0.7032 G loss:-2.013\n",
      "Epoch:  0079 D loss:-0.795 G loss:-2.075\n",
      "Epoch:  0079 D loss:-0.5504 G loss:-2.075\n",
      "Epoch:  0079 D loss:-0.6536 G loss:-2.029\n",
      "Epoch:  0079 D loss:-0.6466 G loss:-1.877\n",
      "Epoch:  0079 D loss:-0.6337 G loss:-1.921\n",
      "Epoch:  0079 D loss:-0.7114 G loss:-2.019\n",
      "Epoch:  0079 D loss:-0.7565 G loss:-2.043\n",
      "Epoch:  0079 D loss:-0.7231 G loss:-1.996\n",
      "Epoch:  0079 D loss:-0.6631 G loss:-2.134\n",
      "Epoch:  0079 D loss:-0.6052 G loss:-2.06\n",
      "Epoch:  0079 D loss:-0.5406 G loss:-2.343\n",
      "Epoch:  0079 D loss:-0.7112 G loss:-2.225\n",
      "Epoch:  0079 D loss:-0.6278 G loss:-2.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0079 D loss:-0.617 G loss:-1.957\n",
      "Epoch:  0079 D loss:-0.5805 G loss:-1.941\n",
      "Epoch:  0079 D loss:-0.7649 G loss:-2.148\n",
      "Epoch:  0079 D loss:-0.6578 G loss:-2.007\n",
      "Epoch:  0079 D loss:-0.6467 G loss:-1.881\n",
      "Epoch:  0079 D loss:-0.6509 G loss:-2.041\n",
      "Epoch:  0079 D loss:-0.6617 G loss:-1.872\n",
      "Epoch:  0079 D loss:-0.6749 G loss:-2.03\n",
      "Epoch:  0079 D loss:-0.7079 G loss:-2.028\n",
      "Epoch:  0079 D loss:-0.6528 G loss:-2.031\n",
      "Epoch:  0079 D loss:-0.7348 G loss:-1.943\n",
      "Epoch:  0079 D loss:-0.615 G loss:-2.107\n",
      "Epoch:  0079 D loss:-0.6928 G loss:-2.135\n",
      "Epoch:  0079 D loss:-0.6708 G loss:-2.048\n",
      "Epoch:  0079 D loss:-0.6432 G loss:-2.06\n",
      "Epoch:  0079 D loss:-0.5941 G loss:-2.051\n",
      "Epoch:  0079 D loss:-0.6297 G loss:-2.128\n",
      "Epoch:  0079 D loss:-0.548 G loss:-2.257\n",
      "Epoch:  0079 D loss:-0.6237 G loss:-2.12\n",
      "Epoch:  0079 D loss:-0.6517 G loss:-2.039\n",
      "Epoch:  0079 D loss:-0.6155 G loss:-2.011\n",
      "Epoch:  0079 D loss:-0.7777 G loss:-2.002\n",
      "Epoch:  0079 D loss:-0.6897 G loss:-2.01\n",
      "Epoch:  0079 D loss:-0.6483 G loss:-2.155\n",
      "Epoch:  0079 D loss:-0.6736 G loss:-2.0\n",
      "Epoch:  0079 D loss:-0.6155 G loss:-1.999\n",
      "Epoch:  0079 D loss:-0.6189 G loss:-1.971\n",
      "Epoch:  0079 D loss:-0.6055 G loss:-1.97\n",
      "Epoch:  0079 D loss:-0.6862 G loss:-1.936\n",
      "Epoch:  0079 D loss:-0.5709 G loss:-1.806\n",
      "Epoch:  0079 D loss:-0.6216 G loss:-2.223\n",
      "Epoch:  0079 D loss:-0.625 G loss:-2.094\n",
      "Epoch:  0079 D loss:-0.7093 G loss:-1.979\n",
      "Epoch:  0079 D loss:-0.7256 G loss:-2.302\n",
      "Epoch:  0079 D loss:-0.5879 G loss:-2.081\n",
      "Epoch:  0079 D loss:-0.5676 G loss:-2.295\n",
      "Epoch:  0079 D loss:-0.6697 G loss:-2.211\n",
      "Epoch:  0079 D loss:-0.7631 G loss:-2.153\n",
      "Epoch:  0079 D loss:-0.7492 G loss:-2.098\n",
      "Epoch:  0079 D loss:-0.7016 G loss:-2.368\n",
      "Epoch:  0079 D loss:-0.6883 G loss:-2.286\n",
      "Epoch:  0079 D loss:-0.6814 G loss:-2.065\n",
      "Epoch:  0079 D loss:-0.6533 G loss:-2.055\n",
      "Epoch:  0079 D loss:-0.8188 G loss:-1.972\n",
      "Epoch:  0079 D loss:-0.6074 G loss:-1.925\n",
      "Epoch:  0079 D loss:-0.6379 G loss:-1.8\n",
      "Epoch:  0079 D loss:-0.792 G loss:-1.776\n",
      "Epoch:  0079 D loss:-0.7237 G loss:-1.925\n",
      "Epoch:  0079 D loss:-0.7758 G loss:-1.95\n",
      "Epoch:  0079 D loss:-0.594 G loss:-2.115\n",
      "Epoch:  0079 D loss:-0.7287 G loss:-1.95\n",
      "Epoch:  0079 D loss:-0.5836 G loss:-1.989\n",
      "Epoch:  0079 D loss:-0.805 G loss:-1.976\n",
      "Epoch:  0079 D loss:-0.724 G loss:-2.023\n",
      "Epoch:  0079 D loss:-0.8128 G loss:-2.171\n",
      "Epoch:  0079 D loss:-0.7155 G loss:-2.31\n",
      "Epoch:  0079 D loss:-0.7284 G loss:-1.94\n",
      "Epoch:  0079 D loss:-0.7511 G loss:-1.959\n",
      "Epoch:  0079 D loss:-0.7256 G loss:-1.921\n",
      "Epoch:  0079 D loss:-0.7256 G loss:-1.942\n",
      "Epoch:  0079 D loss:-0.715 G loss:-2.002\n",
      "Epoch:  0079 D loss:-0.7541 G loss:-1.803\n",
      "Epoch:  0079 D loss:-0.7496 G loss:-1.921\n",
      "Epoch:  0079 D loss:-0.6933 G loss:-1.958\n",
      "Epoch:  0079 D loss:-0.8504 G loss:-1.82\n",
      "Epoch:  0079 D loss:-0.6841 G loss:-1.842\n",
      "Epoch:  0079 D loss:-0.6523 G loss:-2.214\n",
      "Epoch:  0079 D loss:-0.6237 G loss:-2.146\n",
      "Epoch:  0079 D loss:-0.6467 G loss:-2.087\n",
      "Epoch:  0079 D loss:-0.6446 G loss:-2.158\n",
      "Epoch:  0079 D loss:-0.6441 G loss:-2.03\n",
      "Epoch:  0079 D loss:-0.7135 G loss:-2.045\n",
      "Epoch:  0079 D loss:-0.6019 G loss:-1.991\n",
      "Epoch:  0079 D loss:-0.8314 G loss:-1.902\n",
      "Epoch:  0079 D loss:-0.6669 G loss:-2.02\n",
      "Epoch:  0079 D loss:-0.5641 G loss:-2.075\n",
      "Epoch:  0079 D loss:-0.7842 G loss:-1.921\n",
      "Epoch:  0079 D loss:-0.8154 G loss:-1.915\n",
      "Epoch:  0079 D loss:-0.706 G loss:-1.867\n",
      "Epoch:  0079 D loss:-0.9751 G loss:-1.819\n",
      "Epoch:  0079 D loss:-0.6543 G loss:-1.92\n",
      "Epoch:  0079 D loss:-0.6881 G loss:-1.864\n",
      "Epoch:  0079 D loss:-0.7539 G loss:-1.811\n",
      "Epoch:  0079 D loss:-0.6878 G loss:-1.854\n",
      "Epoch:  0079 D loss:-0.7951 G loss:-1.953\n",
      "Epoch:  0079 D loss:-0.6967 G loss:-2.239\n",
      "Epoch:  0079 D loss:-0.7659 G loss:-1.901\n",
      "Epoch:  0079 D loss:-0.7898 G loss:-1.918\n",
      "Epoch:  0079 D loss:-0.7115 G loss:-1.954\n",
      "Epoch:  0079 D loss:-0.6377 G loss:-1.949\n",
      "Epoch:  0079 D loss:-0.6411 G loss:-2.057\n",
      "Epoch:  0079 D loss:-0.7067 G loss:-1.894\n",
      "Epoch:  0079 D loss:-0.7322 G loss:-1.88\n",
      "Epoch:  0079 D loss:-0.758 G loss:-1.922\n",
      "Epoch:  0079 D loss:-0.7206 G loss:-1.801\n",
      "Epoch:  0079 D loss:-0.7444 G loss:-1.85\n",
      "Epoch:  0079 D loss:-0.8673 G loss:-1.836\n",
      "Epoch:  0079 D loss:-0.7435 G loss:-1.916\n",
      "Epoch:  0079 D loss:-0.6504 G loss:-2.024\n",
      "Epoch:  0079 D loss:-0.7711 G loss:-2.136\n",
      "Epoch:  0079 D loss:-0.5393 G loss:-2.04\n",
      "Epoch:  0079 D loss:-0.7569 G loss:-1.892\n",
      "Epoch:  0079 D loss:-0.9238 G loss:-1.993\n",
      "Epoch:  0079 D loss:-0.813 G loss:-1.795\n",
      "Epoch:  0079 D loss:-0.6388 G loss:-1.951\n",
      "Epoch:  0079 D loss:-0.8371 G loss:-1.807\n",
      "Epoch:  0079 D loss:-0.8171 G loss:-1.926\n",
      "Epoch:  0079 D loss:-0.7592 G loss:-1.664\n",
      "Epoch:  0079 D loss:-0.7869 G loss:-1.871\n",
      "Epoch:  0079 D loss:-0.7748 G loss:-1.709\n",
      "Epoch:  0079 D loss:-0.7651 G loss:-1.934\n",
      "Epoch:  0079 D loss:-0.6606 G loss:-2.09\n",
      "Epoch:  0079 D loss:-0.7271 G loss:-1.81\n",
      "Epoch:  0079 D loss:-0.7183 G loss:-1.881\n",
      "Epoch:  0079 D loss:-0.7279 G loss:-2.093\n",
      "Epoch:  0079 D loss:-0.6676 G loss:-2.095\n",
      "Epoch:  0079 D loss:-0.7828 G loss:-1.826\n",
      "Epoch:  0079 D loss:-0.7044 G loss:-1.664\n",
      "Epoch:  0079 D loss:-0.7112 G loss:-2.045\n",
      "Epoch:  0079 D loss:-0.6035 G loss:-2.029\n",
      "Epoch:  0079 D loss:-0.6811 G loss:-1.99\n",
      "Epoch:  0079 D loss:-0.7104 G loss:-2.042\n",
      "Epoch:  0079 D loss:-0.7387 G loss:-1.995\n",
      "Epoch:  0079 D loss:-0.7485 G loss:-1.988\n",
      "Epoch:  0079 D loss:-0.7336 G loss:-2.006\n",
      "Epoch:  0079 D loss:-0.6388 G loss:-1.943\n",
      "Epoch:  0079 D loss:-0.8733 G loss:-1.867\n",
      "Epoch:  0079 D loss:-0.8234 G loss:-1.847\n",
      "Epoch:  0079 D loss:-0.5805 G loss:-1.942\n",
      "Epoch:  0079 D loss:-0.6816 G loss:-2.039\n",
      "Epoch:  0079 D loss:-0.7279 G loss:-1.869\n",
      "Epoch:  0079 D loss:-0.6725 G loss:-2.152\n",
      "Epoch:  0079 D loss:-0.7096 G loss:-1.926\n",
      "Epoch:  0079 D loss:-0.6947 G loss:-1.98\n",
      "Epoch:  0079 D loss:-0.7412 G loss:-2.024\n",
      "Epoch:  0079 D loss:-0.6927 G loss:-1.822\n",
      "Epoch:  0079 D loss:-0.5805 G loss:-2.227\n",
      "Epoch:  0079 D loss:-0.7058 G loss:-1.999\n",
      "Epoch:  0079 D loss:-0.7063 G loss:-2.156\n",
      "Epoch:  0079 D loss:-0.6821 G loss:-2.16\n",
      "Epoch:  0079 D loss:-0.6469 G loss:-2.052\n",
      "Epoch:  0079 D loss:-0.6975 G loss:-1.915\n",
      "Epoch:  0079 D loss:-0.8092 G loss:-1.918\n",
      "Epoch:  0079 D loss:-0.5885 G loss:-2.004\n",
      "Epoch:  0079 D loss:-0.7619 G loss:-1.876\n",
      "Epoch:  0079 D loss:-0.7258 G loss:-1.841\n",
      "Epoch:  0079 D loss:-0.7029 G loss:-1.998\n",
      "Epoch:  0079 D loss:-0.707 G loss:-1.873\n",
      "Epoch:  0079 D loss:-0.516 G loss:-2.169\n",
      "Epoch:  0079 D loss:-0.6763 G loss:-2.109\n",
      "Epoch:  0079 D loss:-0.8142 G loss:-2.066\n",
      "Epoch:  0079 D loss:-0.7555 G loss:-2.098\n",
      "Epoch:  0079 D loss:-0.6509 G loss:-2.097\n",
      "Epoch:  0079 D loss:-0.6297 G loss:-2.052\n",
      "Epoch:  0079 D loss:-0.7694 G loss:-2.016\n",
      "Epoch:  0079 D loss:-0.6703 G loss:-1.998\n",
      "Epoch:  0079 D loss:-0.7413 G loss:-1.878\n",
      "Epoch:  0079 D loss:-0.5492 G loss:-2.102\n",
      "Epoch:  0079 D loss:-0.6221 G loss:-1.862\n",
      "Epoch:  0079 D loss:-0.8032 G loss:-1.913\n",
      "Epoch:  0079 D loss:-0.7301 G loss:-1.967\n",
      "Epoch:  0079 D loss:-0.6561 G loss:-2.009\n",
      "Epoch:  0079 D loss:-0.7107 G loss:-1.749\n",
      "Epoch:  0079 D loss:-0.6118 G loss:-1.916\n",
      "Epoch:  0079 D loss:-0.6536 G loss:-2.035\n",
      "Epoch:  0079 D loss:-0.595 G loss:-1.974\n",
      "Epoch:  0079 D loss:-0.6149 G loss:-1.964\n",
      "Epoch:  0079 D loss:-0.6745 G loss:-2.095\n",
      "Epoch:  0079 D loss:-0.8315 G loss:-1.998\n",
      "Epoch:  0079 D loss:-0.6577 G loss:-2.009\n",
      "Epoch:  0079 D loss:-0.6719 G loss:-2.028\n",
      "Epoch:  0079 D loss:-0.7639 G loss:-1.893\n",
      "Epoch:  0079 D loss:-0.6732 G loss:-1.923\n",
      "Epoch:  0079 D loss:-0.7155 G loss:-1.927\n",
      "Epoch:  0079 D loss:-0.6523 G loss:-2.154\n",
      "Epoch:  0079 D loss:-0.8219 G loss:-1.94\n",
      "Epoch:  0079 D loss:-0.732 G loss:-2.231\n",
      "Epoch:  0079 D loss:-0.7313 G loss:-2.126\n",
      "Epoch:  0079 D loss:-0.6911 G loss:-2.02\n",
      "Epoch:  0079 D loss:-0.7287 G loss:-1.868\n",
      "Epoch:  0079 D loss:-0.5806 G loss:-2.095\n",
      "Epoch:  0079 D loss:-0.8612 G loss:-1.762\n",
      "Epoch:  0079 D loss:-0.6714 G loss:-2.037\n",
      "Epoch:  0079 D loss:-0.6886 G loss:-2.168\n",
      "Epoch:  0079 D loss:-0.5792 G loss:-2.156\n",
      "Epoch:  0079 D loss:-0.7617 G loss:-1.862\n",
      "Epoch:  0079 D loss:-0.6687 G loss:-2.131\n",
      "Epoch:  0079 D loss:-0.6149 G loss:-2.128\n",
      "Epoch:  0079 D loss:-0.7877 G loss:-1.843\n",
      "Epoch:  0079 D loss:-0.8417 G loss:-1.983\n",
      "Epoch:  0079 D loss:-0.6143 G loss:-2.128\n",
      "Epoch:  0079 D loss:-0.76 G loss:-1.856\n",
      "Epoch:  0079 D loss:-0.6968 G loss:-2.067\n",
      "Epoch:  0079 D loss:-0.7032 G loss:-1.919\n",
      "Epoch:  0079 D loss:-0.5799 G loss:-2.277\n",
      "Epoch:  0079 D loss:-0.589 G loss:-2.165\n",
      "Epoch:  0079 D loss:-0.5495 G loss:-2.261\n",
      "Epoch:  0079 D loss:-0.6352 G loss:-2.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0079 D loss:-0.6642 G loss:-2.122\n",
      "Epoch:  0079 D loss:-0.6846 G loss:-2.247\n",
      "Epoch:  0079 D loss:-0.7272 G loss:-2.04\n",
      "Epoch:  0079 D loss:-0.5814 G loss:-2.023\n",
      "Epoch:  0079 D loss:-0.6893 G loss:-2.076\n",
      "Epoch:  0079 D loss:-0.5663 G loss:-2.144\n",
      "Epoch:  0079 D loss:-0.6396 G loss:-1.946\n",
      "Epoch:  0079 D loss:-0.7133 G loss:-1.881\n",
      "Epoch:  0079 D loss:-0.689 G loss:-1.923\n",
      "Epoch:  0079 D loss:-0.7914 G loss:-1.909\n",
      "Epoch:  0079 D loss:-0.6757 G loss:-1.929\n",
      "Epoch:  0079 D loss:-0.7349 G loss:-1.857\n",
      "Epoch:  0079 D loss:-0.8075 G loss:-1.928\n",
      "Epoch:  0079 D loss:-0.5884 G loss:-2.193\n",
      "Epoch:  0079 D loss:-0.5522 G loss:-2.351\n",
      "Epoch:  0079 D loss:-0.7418 G loss:-2.09\n",
      "Epoch:  0079 D loss:-0.5803 G loss:-2.271\n",
      "Epoch:  0079 D loss:-0.6536 G loss:-2.01\n",
      "Epoch:  0079 D loss:-0.792 G loss:-1.948\n",
      "Epoch:  0079 D loss:-0.6751 G loss:-2.111\n",
      "Epoch:  0079 D loss:-0.721 G loss:-1.955\n",
      "Epoch:  0080 D loss:-0.6909 G loss:-2.021\n",
      "Epoch:  0080 D loss:-0.7225 G loss:-1.857\n",
      "Epoch:  0080 D loss:-0.6965 G loss:-1.984\n",
      "Epoch:  0080 D loss:-0.5333 G loss:-2.214\n",
      "Epoch:  0080 D loss:-0.6978 G loss:-2.011\n",
      "Epoch:  0080 D loss:-0.6594 G loss:-1.995\n",
      "Epoch:  0080 D loss:-0.6199 G loss:-1.981\n",
      "Epoch:  0080 D loss:-0.7284 G loss:-2.025\n",
      "Epoch:  0080 D loss:-0.6414 G loss:-2.044\n",
      "Epoch:  0080 D loss:-0.6965 G loss:-1.921\n",
      "Epoch:  0080 D loss:-0.7496 G loss:-2.126\n",
      "Epoch:  0080 D loss:-0.5667 G loss:-2.282\n",
      "Epoch:  0080 D loss:-0.853 G loss:-1.826\n",
      "Epoch:  0080 D loss:-0.708 G loss:-2.194\n",
      "Epoch:  0080 D loss:-0.6324 G loss:-2.271\n",
      "Epoch:  0080 D loss:-0.5934 G loss:-2.065\n",
      "Epoch:  0080 D loss:-0.8306 G loss:-1.945\n",
      "Epoch:  0080 D loss:-0.6395 G loss:-2.022\n",
      "Epoch:  0080 D loss:-0.6336 G loss:-1.959\n",
      "Epoch:  0080 D loss:-0.7026 G loss:-1.954\n",
      "Epoch:  0080 D loss:-0.6723 G loss:-1.99\n",
      "Epoch:  0080 D loss:-0.8119 G loss:-1.814\n",
      "Epoch:  0080 D loss:-0.767 G loss:-1.877\n",
      "Epoch:  0080 D loss:-0.6613 G loss:-1.906\n",
      "Epoch:  0080 D loss:-0.6445 G loss:-1.929\n",
      "Epoch:  0080 D loss:-0.7052 G loss:-1.915\n",
      "Epoch:  0080 D loss:-0.6929 G loss:-1.999\n",
      "Epoch:  0080 D loss:-0.7792 G loss:-1.9\n",
      "Epoch:  0080 D loss:-0.6618 G loss:-2.089\n",
      "Epoch:  0080 D loss:-0.6665 G loss:-2.212\n",
      "Epoch:  0080 D loss:-0.6653 G loss:-1.883\n",
      "Epoch:  0080 D loss:-0.7087 G loss:-2.163\n",
      "Epoch:  0080 D loss:-0.8038 G loss:-2.242\n",
      "Epoch:  0080 D loss:-0.8235 G loss:-1.979\n",
      "Epoch:  0080 D loss:-0.6576 G loss:-1.935\n",
      "Epoch:  0080 D loss:-0.6338 G loss:-2.234\n",
      "Epoch:  0080 D loss:-0.808 G loss:-1.667\n",
      "Epoch:  0080 D loss:-0.6544 G loss:-2.018\n",
      "Epoch:  0080 D loss:-0.7398 G loss:-1.963\n",
      "Epoch:  0080 D loss:-0.8385 G loss:-1.776\n",
      "Epoch:  0080 D loss:-0.7502 G loss:-1.781\n",
      "Epoch:  0080 D loss:-0.7648 G loss:-1.824\n",
      "Epoch:  0080 D loss:-0.7518 G loss:-1.695\n",
      "Epoch:  0080 D loss:-0.7317 G loss:-1.733\n",
      "Epoch:  0080 D loss:-0.776 G loss:-1.752\n",
      "Epoch:  0080 D loss:-0.6507 G loss:-1.88\n",
      "Epoch:  0080 D loss:-0.765 G loss:-2.064\n",
      "Epoch:  0080 D loss:-0.8777 G loss:-1.845\n",
      "Epoch:  0080 D loss:-0.7123 G loss:-2.08\n",
      "Epoch:  0080 D loss:-0.8454 G loss:-2.043\n",
      "Epoch:  0080 D loss:-0.725 G loss:-2.026\n",
      "Epoch:  0080 D loss:-0.8907 G loss:-2.026\n",
      "Epoch:  0080 D loss:-0.7543 G loss:-1.705\n",
      "Epoch:  0080 D loss:-0.6751 G loss:-2.126\n",
      "Epoch:  0080 D loss:-0.8735 G loss:-1.621\n",
      "Epoch:  0080 D loss:-0.6545 G loss:-1.785\n",
      "Epoch:  0080 D loss:-0.7384 G loss:-1.863\n",
      "Epoch:  0080 D loss:-0.6838 G loss:-1.896\n",
      "Epoch:  0080 D loss:-0.5931 G loss:-1.992\n",
      "Epoch:  0080 D loss:-0.7655 G loss:-1.793\n",
      "Epoch:  0080 D loss:-0.6451 G loss:-1.863\n",
      "Epoch:  0080 D loss:-0.5816 G loss:-1.846\n",
      "Epoch:  0080 D loss:-0.6886 G loss:-2.075\n",
      "Epoch:  0080 D loss:-0.6018 G loss:-1.971\n",
      "Epoch:  0080 D loss:-0.7594 G loss:-1.905\n",
      "Epoch:  0080 D loss:-0.8096 G loss:-1.888\n",
      "Epoch:  0080 D loss:-0.6575 G loss:-2.18\n",
      "Epoch:  0080 D loss:-0.595 G loss:-2.072\n",
      "Epoch:  0080 D loss:-0.636 G loss:-2.091\n",
      "Epoch:  0080 D loss:-0.6814 G loss:-2.163\n",
      "Epoch:  0080 D loss:-0.6498 G loss:-2.079\n",
      "Epoch:  0080 D loss:-0.6672 G loss:-1.947\n",
      "Epoch:  0080 D loss:-0.6121 G loss:-2.095\n",
      "Epoch:  0080 D loss:-0.9067 G loss:-1.834\n",
      "Epoch:  0080 D loss:-0.5425 G loss:-2.147\n",
      "Epoch:  0080 D loss:-0.7143 G loss:-1.884\n",
      "Epoch:  0080 D loss:-0.7365 G loss:-1.858\n",
      "Epoch:  0080 D loss:-0.7782 G loss:-1.866\n",
      "Epoch:  0080 D loss:-0.7224 G loss:-1.894\n",
      "Epoch:  0080 D loss:-0.6354 G loss:-2.028\n",
      "Epoch:  0080 D loss:-0.6555 G loss:-1.916\n",
      "Epoch:  0080 D loss:-0.7021 G loss:-1.92\n",
      "Epoch:  0080 D loss:-0.6561 G loss:-1.846\n",
      "Epoch:  0080 D loss:-0.5996 G loss:-2.239\n",
      "Epoch:  0080 D loss:-0.7735 G loss:-2.092\n",
      "Epoch:  0080 D loss:-0.667 G loss:-2.012\n",
      "Epoch:  0080 D loss:-0.8027 G loss:-1.949\n",
      "Epoch:  0080 D loss:-0.6531 G loss:-2.074\n",
      "Epoch:  0080 D loss:-0.7483 G loss:-1.869\n",
      "Epoch:  0080 D loss:-0.5632 G loss:-2.248\n",
      "Epoch:  0080 D loss:-0.8384 G loss:-1.836\n",
      "Epoch:  0080 D loss:-0.7011 G loss:-2.046\n",
      "Epoch:  0080 D loss:-0.6187 G loss:-1.927\n",
      "Epoch:  0080 D loss:-0.7105 G loss:-2.028\n",
      "Epoch:  0080 D loss:-0.7585 G loss:-1.834\n",
      "Epoch:  0080 D loss:-0.6905 G loss:-1.781\n",
      "Epoch:  0080 D loss:-0.7316 G loss:-1.832\n",
      "Epoch:  0080 D loss:-0.8121 G loss:-1.959\n",
      "Epoch:  0080 D loss:-0.6485 G loss:-1.947\n",
      "Epoch:  0080 D loss:-0.7605 G loss:-1.998\n",
      "Epoch:  0080 D loss:-0.7488 G loss:-2.162\n",
      "Epoch:  0080 D loss:-0.6879 G loss:-2.1\n",
      "Epoch:  0080 D loss:-0.6433 G loss:-1.916\n",
      "Epoch:  0080 D loss:-0.6228 G loss:-2.068\n",
      "Epoch:  0080 D loss:-0.6695 G loss:-2.31\n",
      "Epoch:  0080 D loss:-0.7772 G loss:-2.197\n",
      "Epoch:  0080 D loss:-0.7417 G loss:-1.982\n",
      "Epoch:  0080 D loss:-0.514 G loss:-2.226\n",
      "Epoch:  0080 D loss:-0.6233 G loss:-2.197\n",
      "Epoch:  0080 D loss:-0.8482 G loss:-2.148\n",
      "Epoch:  0080 D loss:-0.7779 G loss:-1.955\n",
      "Epoch:  0080 D loss:-0.7789 G loss:-1.884\n",
      "Epoch:  0080 D loss:-0.7507 G loss:-1.674\n",
      "Epoch:  0080 D loss:-0.6333 G loss:-1.747\n",
      "Epoch:  0080 D loss:-0.6662 G loss:-1.913\n",
      "Epoch:  0080 D loss:-0.7817 G loss:-2.075\n",
      "Epoch:  0080 D loss:-0.7163 G loss:-1.757\n",
      "Epoch:  0080 D loss:-0.6346 G loss:-2.179\n",
      "Epoch:  0080 D loss:-0.6229 G loss:-2.024\n",
      "Epoch:  0080 D loss:-0.6196 G loss:-1.99\n",
      "Epoch:  0080 D loss:-0.7405 G loss:-2.007\n",
      "Epoch:  0080 D loss:-0.5745 G loss:-2.22\n",
      "Epoch:  0080 D loss:-0.7135 G loss:-1.94\n",
      "Epoch:  0080 D loss:-0.5886 G loss:-1.888\n",
      "Epoch:  0080 D loss:-0.8314 G loss:-1.829\n",
      "Epoch:  0080 D loss:-0.7039 G loss:-1.984\n",
      "Epoch:  0080 D loss:-0.6744 G loss:-2.124\n",
      "Epoch:  0080 D loss:-0.6498 G loss:-2.117\n",
      "Epoch:  0080 D loss:-0.7747 G loss:-1.986\n",
      "Epoch:  0080 D loss:-0.6594 G loss:-2.243\n",
      "Epoch:  0080 D loss:-0.6333 G loss:-2.253\n",
      "Epoch:  0080 D loss:-0.6861 G loss:-2.089\n",
      "Epoch:  0080 D loss:-0.7186 G loss:-1.915\n",
      "Epoch:  0080 D loss:-0.633 G loss:-2.163\n",
      "Epoch:  0080 D loss:-0.8038 G loss:-2.014\n",
      "Epoch:  0080 D loss:-0.7084 G loss:-1.975\n",
      "Epoch:  0080 D loss:-0.6883 G loss:-1.779\n",
      "Epoch:  0080 D loss:-0.8006 G loss:-1.631\n",
      "Epoch:  0080 D loss:-0.7136 G loss:-1.9\n",
      "Epoch:  0080 D loss:-0.6352 G loss:-1.822\n",
      "Epoch:  0080 D loss:-0.8044 G loss:-1.659\n",
      "Epoch:  0080 D loss:-0.7375 G loss:-1.84\n",
      "Epoch:  0080 D loss:-0.8272 G loss:-1.741\n",
      "Epoch:  0080 D loss:-0.7827 G loss:-1.801\n",
      "Epoch:  0080 D loss:-0.7059 G loss:-1.943\n",
      "Epoch:  0080 D loss:-0.6651 G loss:-1.976\n",
      "Epoch:  0080 D loss:-0.6721 G loss:-2.252\n",
      "Epoch:  0080 D loss:-0.7238 G loss:-2.039\n",
      "Epoch:  0080 D loss:-0.7357 G loss:-1.974\n",
      "Epoch:  0080 D loss:-0.6139 G loss:-2.314\n",
      "Epoch:  0080 D loss:-0.7187 G loss:-2.102\n",
      "Epoch:  0080 D loss:-0.6561 G loss:-1.887\n",
      "Epoch:  0080 D loss:-0.5839 G loss:-2.109\n",
      "Epoch:  0080 D loss:-0.6795 G loss:-1.996\n",
      "Epoch:  0080 D loss:-0.7248 G loss:-1.743\n",
      "Epoch:  0080 D loss:-0.6221 G loss:-2.171\n",
      "Epoch:  0080 D loss:-0.6018 G loss:-2.04\n",
      "Epoch:  0080 D loss:-0.6953 G loss:-2.195\n",
      "Epoch:  0080 D loss:-0.7041 G loss:-2.223\n",
      "Epoch:  0080 D loss:-0.6615 G loss:-2.002\n",
      "Epoch:  0080 D loss:-0.5242 G loss:-2.036\n",
      "Epoch:  0080 D loss:-0.6079 G loss:-2.073\n",
      "Epoch:  0080 D loss:-0.6784 G loss:-1.983\n",
      "Epoch:  0080 D loss:-0.6356 G loss:-2.156\n",
      "Epoch:  0080 D loss:-0.6895 G loss:-2.005\n",
      "Epoch:  0080 D loss:-0.7229 G loss:-1.95\n",
      "Epoch:  0080 D loss:-0.6434 G loss:-1.988\n",
      "Epoch:  0080 D loss:-0.7338 G loss:-1.943\n",
      "Epoch:  0080 D loss:-0.6744 G loss:-1.881\n",
      "Epoch:  0080 D loss:-0.5954 G loss:-2.065\n",
      "Epoch:  0080 D loss:-0.731 G loss:-1.937\n",
      "Epoch:  0080 D loss:-0.5442 G loss:-1.983\n",
      "Epoch:  0080 D loss:-0.6191 G loss:-2.114\n",
      "Epoch:  0080 D loss:-0.705 G loss:-1.946\n",
      "Epoch:  0080 D loss:-0.699 G loss:-2.038\n",
      "Epoch:  0080 D loss:-0.6358 G loss:-2.039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0080 D loss:-0.7489 G loss:-2.142\n",
      "Epoch:  0080 D loss:-0.6331 G loss:-2.086\n",
      "Epoch:  0080 D loss:-0.7913 G loss:-1.992\n",
      "Epoch:  0080 D loss:-0.625 G loss:-2.033\n",
      "Epoch:  0080 D loss:-0.6282 G loss:-2.122\n",
      "Epoch:  0080 D loss:-0.5916 G loss:-2.246\n",
      "Epoch:  0080 D loss:-0.7582 G loss:-2.035\n",
      "Epoch:  0080 D loss:-0.6488 G loss:-1.947\n",
      "Epoch:  0080 D loss:-0.9434 G loss:-1.71\n",
      "Epoch:  0080 D loss:-0.5676 G loss:-1.823\n",
      "Epoch:  0080 D loss:-0.6329 G loss:-1.949\n",
      "Epoch:  0080 D loss:-0.6327 G loss:-2.067\n",
      "Epoch:  0080 D loss:-0.7152 G loss:-1.968\n",
      "Epoch:  0080 D loss:-0.7321 G loss:-1.909\n",
      "Epoch:  0080 D loss:-0.6558 G loss:-1.933\n",
      "Epoch:  0080 D loss:-0.6082 G loss:-2.022\n",
      "Epoch:  0080 D loss:-0.6378 G loss:-2.073\n",
      "Epoch:  0080 D loss:-0.5678 G loss:-2.376\n",
      "Epoch:  0080 D loss:-0.5735 G loss:-2.193\n",
      "Epoch:  0080 D loss:-0.5619 G loss:-2.271\n",
      "Epoch:  0080 D loss:-0.5781 G loss:-2.074\n",
      "Epoch:  0080 D loss:-0.8184 G loss:-2.173\n",
      "Epoch:  0080 D loss:-0.8252 G loss:-1.987\n",
      "Epoch:  0080 D loss:-0.7228 G loss:-1.996\n",
      "Epoch:  0080 D loss:-0.6672 G loss:-2.03\n",
      "Epoch:  0080 D loss:-0.8527 G loss:-1.917\n",
      "Epoch:  0080 D loss:-0.7496 G loss:-1.678\n",
      "Epoch:  0080 D loss:-0.6658 G loss:-1.978\n",
      "Epoch:  0080 D loss:-0.7183 G loss:-2.03\n",
      "Epoch:  0080 D loss:-0.7105 G loss:-2.113\n",
      "Epoch:  0080 D loss:-0.7332 G loss:-2.102\n",
      "Epoch:  0080 D loss:-0.8149 G loss:-1.752\n",
      "Epoch:  0080 D loss:-0.7431 G loss:-2.099\n",
      "Epoch:  0080 D loss:-0.7673 G loss:-1.996\n",
      "Epoch:  0080 D loss:-0.7206 G loss:-2.022\n",
      "Epoch:  0080 D loss:-0.724 G loss:-1.875\n",
      "Epoch:  0080 D loss:-0.7461 G loss:-1.853\n",
      "Epoch:  0080 D loss:-0.7995 G loss:-1.794\n",
      "Epoch:  0080 D loss:-0.6687 G loss:-1.846\n",
      "Epoch:  0080 D loss:-0.7723 G loss:-1.778\n",
      "Epoch:  0080 D loss:-0.6856 G loss:-1.816\n",
      "Epoch:  0080 D loss:-0.5808 G loss:-2.283\n",
      "Epoch:  0080 D loss:-0.8502 G loss:-1.831\n",
      "Epoch:  0080 D loss:-0.5599 G loss:-2.093\n",
      "Epoch:  0080 D loss:-0.7375 G loss:-2.008\n",
      "Epoch:  0080 D loss:-0.7268 G loss:-2.079\n",
      "Epoch:  0080 D loss:-0.7734 G loss:-2.087\n",
      "Epoch:  0080 D loss:-0.7321 G loss:-2.004\n",
      "Epoch:  0080 D loss:-0.8247 G loss:-1.885\n",
      "Epoch:  0080 D loss:-0.7041 G loss:-2.091\n",
      "Epoch:  0080 D loss:-0.6092 G loss:-2.096\n",
      "Epoch:  0080 D loss:-0.6383 G loss:-2.151\n",
      "Epoch:  0080 D loss:-0.6309 G loss:-2.018\n",
      "Epoch:  0080 D loss:-0.7676 G loss:-1.982\n",
      "Epoch:  0080 D loss:-0.6357 G loss:-2.197\n",
      "Epoch:  0080 D loss:-0.6506 G loss:-2.074\n",
      "Epoch:  0080 D loss:-0.7255 G loss:-1.679\n",
      "Epoch:  0080 D loss:-0.8726 G loss:-1.764\n",
      "Epoch:  0080 D loss:-0.8132 G loss:-1.902\n",
      "Epoch:  0080 D loss:-0.643 G loss:-1.904\n",
      "Epoch:  0080 D loss:-0.8696 G loss:-1.881\n",
      "Epoch:  0080 D loss:-0.6278 G loss:-1.96\n",
      "Epoch:  0080 D loss:-0.7872 G loss:-2.003\n",
      "Epoch:  0080 D loss:-0.7164 G loss:-2.17\n",
      "Epoch:  0080 D loss:-0.7639 G loss:-2.165\n",
      "Epoch:  0080 D loss:-0.6909 G loss:-2.049\n",
      "Epoch:  0080 D loss:-0.6707 G loss:-2.055\n",
      "Epoch:  0080 D loss:-0.7045 G loss:-1.952\n",
      "Epoch:  0080 D loss:-0.6477 G loss:-2.096\n",
      "Epoch:  0080 D loss:-0.7081 G loss:-1.863\n",
      "Epoch:  0080 D loss:-0.7921 G loss:-1.826\n",
      "Epoch:  0080 D loss:-0.8954 G loss:-1.822\n",
      "Epoch:  0080 D loss:-0.7177 G loss:-2.019\n",
      "Epoch:  0080 D loss:-0.7672 G loss:-1.888\n",
      "Epoch:  0080 D loss:-0.7698 G loss:-1.917\n",
      "Epoch:  0080 D loss:-0.6295 G loss:-2.312\n",
      "Epoch:  0080 D loss:-0.7453 G loss:-2.043\n",
      "Epoch:  0080 D loss:-0.8035 G loss:-2.039\n",
      "Epoch:  0080 D loss:-0.7033 G loss:-2.238\n",
      "Epoch:  0080 D loss:-0.7325 G loss:-1.918\n",
      "Epoch:  0080 D loss:-0.6435 G loss:-2.076\n",
      "Epoch:  0080 D loss:-0.7434 G loss:-1.87\n",
      "Epoch:  0080 D loss:-0.8475 G loss:-1.788\n",
      "Epoch:  0080 D loss:-0.6573 G loss:-1.898\n",
      "Epoch:  0080 D loss:-0.5754 G loss:-1.851\n",
      "Epoch:  0080 D loss:-0.8166 G loss:-1.855\n",
      "Epoch:  0080 D loss:-0.6503 G loss:-1.831\n",
      "Epoch:  0080 D loss:-0.6481 G loss:-1.986\n",
      "Epoch:  0080 D loss:-0.73 G loss:-1.896\n",
      "Epoch:  0080 D loss:-0.7306 G loss:-1.864\n",
      "Epoch:  0080 D loss:-0.6709 G loss:-2.004\n",
      "Epoch:  0080 D loss:-0.7354 G loss:-2.032\n",
      "Epoch:  0080 D loss:-0.8399 G loss:-1.846\n",
      "Epoch:  0080 D loss:-0.7078 G loss:-2.062\n",
      "Epoch:  0080 D loss:-0.7093 G loss:-1.882\n",
      "Epoch:  0080 D loss:-0.5454 G loss:-2.004\n",
      "Epoch:  0080 D loss:-0.8616 G loss:-1.727\n",
      "Epoch:  0080 D loss:-0.8828 G loss:-1.649\n",
      "Epoch:  0080 D loss:-0.7449 G loss:-1.843\n",
      "Epoch:  0080 D loss:-0.5975 G loss:-2.011\n",
      "Epoch:  0080 D loss:-0.744 G loss:-1.912\n",
      "Epoch:  0080 D loss:-0.6075 G loss:-2.075\n",
      "Epoch:  0080 D loss:-0.7522 G loss:-2.119\n",
      "Epoch:  0080 D loss:-0.9227 G loss:-2.217\n",
      "Epoch:  0080 D loss:-0.7085 G loss:-2.118\n",
      "Epoch:  0080 D loss:-0.7199 G loss:-2.146\n",
      "Epoch:  0080 D loss:-0.6639 G loss:-2.028\n",
      "Epoch:  0080 D loss:-0.6633 G loss:-2.059\n",
      "Epoch:  0080 D loss:-0.5826 G loss:-2.162\n",
      "Epoch:  0080 D loss:-0.7347 G loss:-1.929\n",
      "Epoch:  0080 D loss:-0.7017 G loss:-2.106\n",
      "Epoch:  0080 D loss:-0.6427 G loss:-1.998\n",
      "Epoch:  0080 D loss:-0.6896 G loss:-1.988\n",
      "Epoch:  0080 D loss:-0.652 G loss:-1.882\n",
      "Epoch:  0080 D loss:-0.6407 G loss:-2.165\n",
      "Epoch:  0080 D loss:-0.766 G loss:-1.938\n",
      "Epoch:  0080 D loss:-0.7963 G loss:-2.024\n",
      "Epoch:  0080 D loss:-0.655 G loss:-2.019\n",
      "Epoch:  0080 D loss:-0.6582 G loss:-2.077\n",
      "Epoch:  0080 D loss:-0.7595 G loss:-2.09\n",
      "Epoch:  0080 D loss:-0.7552 G loss:-1.866\n",
      "Epoch:  0080 D loss:-0.8503 G loss:-1.912\n",
      "Epoch:  0080 D loss:-0.7709 G loss:-1.972\n",
      "Epoch:  0080 D loss:-0.6702 G loss:-2.197\n",
      "Epoch:  0080 D loss:-0.721 G loss:-1.976\n",
      "Epoch:  0080 D loss:-0.6907 G loss:-2.071\n",
      "Epoch:  0080 D loss:-0.7888 G loss:-2.095\n",
      "Epoch:  0080 D loss:-0.6604 G loss:-2.036\n",
      "Epoch:  0080 D loss:-0.5957 G loss:-2.07\n",
      "Epoch:  0080 D loss:-0.8718 G loss:-1.933\n",
      "Epoch:  0080 D loss:-0.645 G loss:-2.204\n",
      "Epoch:  0080 D loss:-0.7208 G loss:-1.939\n",
      "Epoch:  0080 D loss:-0.6805 G loss:-1.95\n",
      "Epoch:  0080 D loss:-0.5701 G loss:-2.013\n",
      "Epoch:  0080 D loss:-0.697 G loss:-1.967\n",
      "Epoch:  0080 D loss:-0.679 G loss:-2.046\n",
      "Epoch:  0080 D loss:-0.6247 G loss:-2.308\n",
      "Epoch:  0080 D loss:-0.6831 G loss:-2.479\n",
      "Epoch:  0080 D loss:-0.6776 G loss:-2.247\n",
      "Epoch:  0080 D loss:-0.7777 G loss:-2.204\n",
      "Epoch:  0080 D loss:-0.6795 G loss:-2.051\n",
      "Epoch:  0080 D loss:-0.6516 G loss:-2.001\n",
      "Epoch:  0080 D loss:-0.7687 G loss:-1.793\n",
      "Epoch:  0080 D loss:-0.5985 G loss:-2.115\n",
      "Epoch:  0080 D loss:-0.6707 G loss:-2.001\n",
      "Epoch:  0080 D loss:-0.7265 G loss:-1.888\n",
      "Epoch:  0080 D loss:-0.5491 G loss:-1.951\n",
      "Epoch:  0080 D loss:-0.6798 G loss:-2.105\n",
      "Epoch:  0080 D loss:-0.7335 G loss:-2.015\n",
      "Epoch:  0080 D loss:-0.7705 G loss:-2.096\n",
      "Epoch:  0080 D loss:-0.6939 G loss:-1.975\n",
      "Epoch:  0080 D loss:-0.7086 G loss:-2.072\n",
      "Epoch:  0080 D loss:-0.796 G loss:-1.949\n",
      "Epoch:  0080 D loss:-0.7189 G loss:-2.069\n",
      "Epoch:  0080 D loss:-0.8297 G loss:-2.053\n",
      "Epoch:  0080 D loss:-0.6042 G loss:-1.754\n",
      "Epoch:  0080 D loss:-0.7585 G loss:-2.056\n",
      "Epoch:  0080 D loss:-0.6306 G loss:-2.058\n",
      "Epoch:  0080 D loss:-0.7278 G loss:-1.984\n",
      "Epoch:  0080 D loss:-0.7897 G loss:-2.126\n",
      "Epoch:  0080 D loss:-0.7226 G loss:-1.871\n",
      "Epoch:  0080 D loss:-0.6864 G loss:-2.076\n",
      "Epoch:  0080 D loss:-0.7111 G loss:-2.015\n",
      "Epoch:  0080 D loss:-0.6669 G loss:-1.9\n",
      "Epoch:  0080 D loss:-0.7177 G loss:-1.999\n",
      "Epoch:  0080 D loss:-0.8188 G loss:-1.873\n",
      "Epoch:  0080 D loss:-0.843 G loss:-1.892\n",
      "Epoch:  0080 D loss:-0.6427 G loss:-1.924\n",
      "Epoch:  0080 D loss:-0.7224 G loss:-1.795\n",
      "Epoch:  0080 D loss:-0.6882 G loss:-2.007\n",
      "Epoch:  0080 D loss:-0.7589 G loss:-1.888\n",
      "Epoch:  0080 D loss:-0.6985 G loss:-2.104\n",
      "Epoch:  0080 D loss:-0.6413 G loss:-2.154\n",
      "Epoch:  0080 D loss:-0.7656 G loss:-2.064\n",
      "Epoch:  0080 D loss:-0.7389 G loss:-2.08\n",
      "Epoch:  0080 D loss:-0.662 G loss:-2.191\n",
      "Epoch:  0080 D loss:-0.6741 G loss:-2.207\n",
      "Epoch:  0080 D loss:-0.6608 G loss:-1.991\n",
      "Epoch:  0080 D loss:-0.744 G loss:-1.725\n",
      "Epoch:  0080 D loss:-0.8566 G loss:-1.794\n",
      "Epoch:  0080 D loss:-0.8191 G loss:-1.843\n",
      "Epoch:  0080 D loss:-0.6999 G loss:-1.956\n",
      "Epoch:  0080 D loss:-0.5225 G loss:-2.07\n",
      "Epoch:  0080 D loss:-0.7255 G loss:-1.938\n",
      "Epoch:  0080 D loss:-0.8227 G loss:-2.125\n",
      "Epoch:  0080 D loss:-0.7275 G loss:-1.962\n",
      "Epoch:  0080 D loss:-0.6787 G loss:-2.024\n",
      "Epoch:  0080 D loss:-0.7936 G loss:-1.968\n",
      "Epoch:  0080 D loss:-0.6036 G loss:-2.179\n",
      "Epoch:  0080 D loss:-0.6839 G loss:-2.0\n",
      "Epoch:  0080 D loss:-0.4961 G loss:-2.136\n",
      "Epoch:  0080 D loss:-0.7544 G loss:-1.963\n",
      "Epoch:  0080 D loss:-0.681 G loss:-2.063\n",
      "Epoch:  0080 D loss:-0.6642 G loss:-2.139\n",
      "Epoch:  0080 D loss:-0.6236 G loss:-2.192\n",
      "Epoch:  0080 D loss:-0.6901 G loss:-2.078\n",
      "Epoch:  0080 D loss:-0.7671 G loss:-1.92\n",
      "Epoch:  0080 D loss:-0.6933 G loss:-1.796\n",
      "Epoch:  0080 D loss:-0.5989 G loss:-1.964\n",
      "Epoch:  0080 D loss:-0.6375 G loss:-1.904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0080 D loss:-0.7213 G loss:-1.905\n",
      "Epoch:  0080 D loss:-0.7277 G loss:-1.924\n",
      "Epoch:  0080 D loss:-0.603 G loss:-2.151\n",
      "Epoch:  0080 D loss:-0.6497 G loss:-2.141\n",
      "Epoch:  0080 D loss:-0.6081 G loss:-2.174\n",
      "Epoch:  0080 D loss:-0.6222 G loss:-2.016\n",
      "Epoch:  0080 D loss:-0.6091 G loss:-2.143\n",
      "Epoch:  0080 D loss:-0.6699 G loss:-2.107\n",
      "Epoch:  0080 D loss:-0.6184 G loss:-2.285\n",
      "Epoch:  0080 D loss:-0.7148 G loss:-2.059\n",
      "Epoch:  0080 D loss:-0.7093 G loss:-2.079\n",
      "Epoch:  0080 D loss:-0.5817 G loss:-2.213\n",
      "Epoch:  0080 D loss:-0.6687 G loss:-1.981\n",
      "Epoch:  0080 D loss:-0.7194 G loss:-1.987\n",
      "Epoch:  0080 D loss:-0.6916 G loss:-1.875\n",
      "Epoch:  0080 D loss:-0.5664 G loss:-1.957\n",
      "Epoch:  0080 D loss:-0.7423 G loss:-1.925\n",
      "Epoch:  0080 D loss:-0.7422 G loss:-2.072\n",
      "Epoch:  0080 D loss:-0.6738 G loss:-1.957\n",
      "Epoch:  0080 D loss:-0.7398 G loss:-2.038\n",
      "Epoch:  0080 D loss:-0.7929 G loss:-1.821\n",
      "Epoch:  0080 D loss:-0.7449 G loss:-1.935\n",
      "Epoch:  0080 D loss:-0.7042 G loss:-2.196\n",
      "Epoch:  0080 D loss:-0.6703 G loss:-2.209\n",
      "Epoch:  0080 D loss:-0.7167 G loss:-2.031\n",
      "Epoch:  0080 D loss:-0.7456 G loss:-1.94\n",
      "Epoch:  0080 D loss:-0.7169 G loss:-1.991\n",
      "Epoch:  0080 D loss:-0.789 G loss:-1.88\n",
      "Epoch:  0080 D loss:-0.6579 G loss:-1.996\n",
      "Epoch:  0080 D loss:-0.7696 G loss:-1.839\n",
      "Epoch:  0080 D loss:-0.6993 G loss:-1.767\n",
      "Epoch:  0080 D loss:-0.6077 G loss:-2.036\n",
      "Epoch:  0080 D loss:-0.6823 G loss:-2.021\n",
      "Epoch:  0080 D loss:-0.5817 G loss:-2.158\n",
      "Epoch:  0080 D loss:-0.6407 G loss:-1.945\n",
      "Epoch:  0080 D loss:-0.5802 G loss:-2.031\n",
      "Epoch:  0080 D loss:-0.7056 G loss:-2.109\n",
      "Epoch:  0080 D loss:-0.5396 G loss:-2.015\n",
      "Epoch:  0080 D loss:-0.7345 G loss:-1.959\n",
      "Epoch:  0080 D loss:-0.597 G loss:-1.988\n",
      "Epoch:  0080 D loss:-0.7004 G loss:-2.182\n",
      "Epoch:  0080 D loss:-0.8035 G loss:-2.09\n",
      "Epoch:  0080 D loss:-0.776 G loss:-1.889\n",
      "Epoch:  0080 D loss:-0.7804 G loss:-2.056\n",
      "Epoch:  0080 D loss:-0.6702 G loss:-2.07\n",
      "Epoch:  0080 D loss:-0.7284 G loss:-1.959\n",
      "Epoch:  0080 D loss:-1.098 G loss:-2.008\n",
      "Epoch:  0080 D loss:-0.8182 G loss:-2.068\n",
      "Epoch:  0080 D loss:-0.6022 G loss:-2.036\n",
      "Epoch:  0080 D loss:-0.5711 G loss:-1.861\n",
      "Epoch:  0080 D loss:-0.7065 G loss:-1.873\n",
      "Epoch:  0080 D loss:-0.5764 G loss:-2.087\n",
      "Epoch:  0080 D loss:-0.7939 G loss:-1.865\n",
      "Epoch:  0080 D loss:-0.6459 G loss:-2.079\n",
      "Epoch:  0080 D loss:-0.5994 G loss:-2.003\n",
      "Epoch:  0080 D loss:-0.7203 G loss:-2.008\n",
      "Epoch:  0080 D loss:-0.5705 G loss:-2.026\n",
      "Epoch:  0080 D loss:-0.6887 G loss:-1.953\n",
      "Epoch:  0080 D loss:-0.6561 G loss:-1.968\n",
      "Epoch:  0080 D loss:-0.6729 G loss:-2.118\n",
      "Epoch:  0080 D loss:-0.6991 G loss:-2.132\n",
      "Epoch:  0080 D loss:-0.6981 G loss:-2.013\n",
      "Epoch:  0080 D loss:-0.6694 G loss:-2.155\n",
      "Epoch:  0080 D loss:-0.5957 G loss:-1.978\n",
      "Epoch:  0080 D loss:-0.6791 G loss:-1.978\n",
      "Epoch:  0080 D loss:-0.6156 G loss:-1.947\n",
      "Epoch:  0080 D loss:-0.7666 G loss:-1.928\n",
      "Epoch:  0080 D loss:-0.7275 G loss:-1.903\n",
      "Epoch:  0080 D loss:-0.7634 G loss:-1.946\n",
      "Epoch:  0080 D loss:-0.8519 G loss:-1.69\n",
      "Epoch:  0080 D loss:-0.6234 G loss:-1.951\n",
      "Epoch:  0080 D loss:-0.7441 G loss:-2.037\n",
      "Epoch:  0080 D loss:-0.727 G loss:-1.68\n",
      "Epoch:  0080 D loss:-0.6605 G loss:-1.869\n",
      "Epoch:  0080 D loss:-0.7972 G loss:-1.903\n",
      "Epoch:  0080 D loss:-0.6901 G loss:-2.015\n",
      "Epoch:  0080 D loss:-0.8544 G loss:-1.778\n",
      "Epoch:  0080 D loss:-0.6187 G loss:-2.06\n",
      "Epoch:  0080 D loss:-0.7448 G loss:-1.934\n",
      "Epoch:  0080 D loss:-0.7947 G loss:-2.047\n",
      "Epoch:  0080 D loss:-0.896 G loss:-1.991\n",
      "Epoch:  0080 D loss:-0.8856 G loss:-1.854\n",
      "Epoch:  0080 D loss:-0.776 G loss:-1.978\n",
      "Epoch:  0080 D loss:-0.7536 G loss:-2.138\n",
      "Epoch:  0080 D loss:-0.754 G loss:-1.972\n",
      "Epoch:  0080 D loss:-0.7004 G loss:-1.805\n",
      "Epoch:  0080 D loss:-0.6215 G loss:-1.949\n",
      "Epoch:  0080 D loss:-0.786 G loss:-1.793\n",
      "Epoch:  0080 D loss:-0.8536 G loss:-1.824\n",
      "Epoch:  0080 D loss:-0.7469 G loss:-1.921\n",
      "Epoch:  0080 D loss:-0.8915 G loss:-1.918\n",
      "Epoch:  0080 D loss:-0.8746 G loss:-1.813\n",
      "Epoch:  0080 D loss:-0.8451 G loss:-1.597\n",
      "Epoch:  0080 D loss:-0.8043 G loss:-2.026\n",
      "Epoch:  0080 D loss:-0.7997 G loss:-1.94\n",
      "Epoch:  0080 D loss:-0.6805 G loss:-1.893\n",
      "Epoch:  0080 D loss:-0.7406 G loss:-1.766\n",
      "Epoch:  0080 D loss:-0.8025 G loss:-1.879\n",
      "Epoch:  0080 D loss:-0.7417 G loss:-2.022\n",
      "Epoch:  0080 D loss:-0.8613 G loss:-1.803\n",
      "Epoch:  0080 D loss:-0.7376 G loss:-1.937\n",
      "Epoch:  0080 D loss:-0.8981 G loss:-2.127\n",
      "Epoch:  0080 D loss:-0.8551 G loss:-2.006\n",
      "Epoch:  0080 D loss:-0.8524 G loss:-1.931\n",
      "Epoch:  0080 D loss:-1.009 G loss:-1.768\n",
      "Epoch:  0080 D loss:-0.8177 G loss:-1.845\n",
      "Epoch:  0080 D loss:-0.6863 G loss:-1.9\n",
      "Epoch:  0080 D loss:-0.8668 G loss:-1.736\n",
      "Epoch:  0080 D loss:-0.7129 G loss:-1.905\n",
      "Epoch:  0080 D loss:-0.6969 G loss:-1.988\n",
      "Epoch:  0080 D loss:-0.7336 G loss:-1.899\n",
      "Epoch:  0080 D loss:-0.7238 G loss:-1.982\n",
      "Epoch:  0080 D loss:-0.7662 G loss:-1.902\n",
      "Epoch:  0080 D loss:-0.6941 G loss:-2.042\n",
      "Epoch:  0080 D loss:-0.7238 G loss:-2.192\n",
      "Epoch:  0080 D loss:-0.6283 G loss:-2.029\n",
      "Epoch:  0080 D loss:-0.8158 G loss:-2.062\n",
      "Epoch:  0080 D loss:-0.8133 G loss:-2.017\n",
      "Epoch:  0080 D loss:-0.7 G loss:-2.074\n",
      "Epoch:  0080 D loss:-0.6913 G loss:-2.004\n",
      "Epoch:  0080 D loss:-0.8015 G loss:-1.767\n",
      "Epoch:  0080 D loss:-0.815 G loss:-1.783\n",
      "Epoch:  0080 D loss:-0.6947 G loss:-2.193\n",
      "Epoch:  0080 D loss:-0.6468 G loss:-2.102\n",
      "Epoch:  0080 D loss:-0.7608 G loss:-1.947\n",
      "Epoch:  0080 D loss:-0.8224 G loss:-1.815\n",
      "Epoch:  0080 D loss:-0.7013 G loss:-1.936\n",
      "Epoch:  0080 D loss:-0.5905 G loss:-1.942\n",
      "Epoch:  0080 D loss:-0.7602 G loss:-1.926\n",
      "Epoch:  0080 D loss:-0.7402 G loss:-1.888\n",
      "Epoch:  0080 D loss:-0.6385 G loss:-2.025\n",
      "Epoch:  0080 D loss:-0.6342 G loss:-2.033\n",
      "Epoch:  0080 D loss:-0.6752 G loss:-1.878\n",
      "Epoch:  0080 D loss:-0.7703 G loss:-2.099\n",
      "Epoch:  0080 D loss:-0.7905 G loss:-1.978\n",
      "Epoch:  0080 D loss:-0.6828 G loss:-2.109\n",
      "Epoch:  0080 D loss:-0.6593 G loss:-1.968\n",
      "Epoch:  0080 D loss:-0.5651 G loss:-2.165\n",
      "Epoch:  0080 D loss:-0.6429 G loss:-2.026\n",
      "Epoch:  0080 D loss:-0.6908 G loss:-1.809\n",
      "Epoch:  0080 D loss:-0.614 G loss:-2.021\n",
      "Epoch:  0080 D loss:-0.6204 G loss:-2.14\n",
      "Epoch:  0080 D loss:-0.6003 G loss:-2.256\n",
      "Epoch:  0080 D loss:-0.6594 G loss:-1.973\n",
      "Epoch:  0080 D loss:-0.6872 G loss:-2.053\n",
      "Epoch:  0080 D loss:-0.6985 G loss:-2.056\n",
      "Epoch:  0080 D loss:-0.5994 G loss:-2.253\n",
      "Epoch:  0080 D loss:-0.741 G loss:-2.112\n",
      "Epoch:  0080 D loss:-0.6008 G loss:-2.217\n",
      "Epoch:  0080 D loss:-0.74 G loss:-2.017\n",
      "Epoch:  0080 D loss:-0.789 G loss:-1.883\n",
      "Epoch:  0080 D loss:-0.6867 G loss:-2.08\n",
      "Epoch:  0080 D loss:-0.8408 G loss:-1.737\n",
      "Epoch:  0080 D loss:-0.6425 G loss:-1.938\n",
      "Epoch:  0080 D loss:-0.6007 G loss:-1.875\n",
      "Epoch:  0080 D loss:-0.7571 G loss:-1.923\n",
      "Epoch:  0080 D loss:-0.5688 G loss:-2.129\n",
      "Epoch:  0080 D loss:-0.6865 G loss:-1.998\n",
      "Epoch:  0080 D loss:-0.6358 G loss:-2.124\n",
      "Epoch:  0080 D loss:-0.7043 G loss:-1.845\n",
      "Epoch:  0080 D loss:-0.634 G loss:-2.123\n",
      "Epoch:  0080 D loss:-0.656 G loss:-1.938\n",
      "Epoch:  0080 D loss:-0.75 G loss:-2.174\n",
      "Epoch:  0080 D loss:-0.6448 G loss:-2.154\n",
      "Epoch:  0080 D loss:-0.7191 G loss:-2.107\n",
      "Epoch:  0080 D loss:-0.7413 G loss:-2.192\n",
      "Epoch:  0080 D loss:-0.7099 G loss:-2.095\n",
      "Epoch:  0080 D loss:-0.5965 G loss:-2.217\n",
      "Epoch:  0080 D loss:-0.6947 G loss:-2.164\n",
      "Epoch:  0080 D loss:-0.7433 G loss:-2.064\n",
      "Epoch:  0080 D loss:-0.5443 G loss:-2.227\n",
      "Epoch:  0080 D loss:-0.658 G loss:-2.141\n",
      "Epoch:  0080 D loss:-0.6014 G loss:-2.055\n",
      "Epoch:  0080 D loss:-0.5545 G loss:-2.056\n",
      "Epoch:  0081 D loss:-0.5983 G loss:-1.965\n",
      "Epoch:  0081 D loss:-0.8165 G loss:-1.94\n",
      "Epoch:  0081 D loss:-0.573 G loss:-2.009\n",
      "Epoch:  0081 D loss:-0.6772 G loss:-2.064\n",
      "Epoch:  0081 D loss:-0.6371 G loss:-2.089\n",
      "Epoch:  0081 D loss:-0.6839 G loss:-2.213\n",
      "Epoch:  0081 D loss:-0.6137 G loss:-2.237\n",
      "Epoch:  0081 D loss:-0.6162 G loss:-2.363\n",
      "Epoch:  0081 D loss:-0.5655 G loss:-2.18\n",
      "Epoch:  0081 D loss:-0.7722 G loss:-2.075\n",
      "Epoch:  0081 D loss:-0.5382 G loss:-2.358\n",
      "Epoch:  0081 D loss:-0.641 G loss:-2.237\n",
      "Epoch:  0081 D loss:-0.7944 G loss:-1.951\n",
      "Epoch:  0081 D loss:-0.6004 G loss:-2.004\n",
      "Epoch:  0081 D loss:-0.731 G loss:-1.994\n",
      "Epoch:  0081 D loss:-0.6931 G loss:-1.898\n",
      "Epoch:  0081 D loss:-0.7159 G loss:-1.848\n",
      "Epoch:  0081 D loss:-0.7229 G loss:-1.981\n",
      "Epoch:  0081 D loss:-0.7136 G loss:-2.178\n",
      "Epoch:  0081 D loss:-0.6488 G loss:-1.877\n",
      "Epoch:  0081 D loss:-0.6517 G loss:-1.847\n",
      "Epoch:  0081 D loss:-0.7837 G loss:-1.789\n",
      "Epoch:  0081 D loss:-0.7888 G loss:-1.72\n",
      "Epoch:  0081 D loss:-0.7291 G loss:-1.969\n",
      "Epoch:  0081 D loss:-0.8572 G loss:-1.753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0081 D loss:-0.6406 G loss:-1.982\n",
      "Epoch:  0081 D loss:-0.6373 G loss:-2.179\n",
      "Epoch:  0081 D loss:-0.758 G loss:-2.024\n",
      "Epoch:  0081 D loss:-0.5803 G loss:-2.21\n",
      "Epoch:  0081 D loss:-0.5548 G loss:-2.09\n",
      "Epoch:  0081 D loss:-0.7247 G loss:-2.136\n",
      "Epoch:  0081 D loss:-0.6406 G loss:-2.118\n",
      "Epoch:  0081 D loss:-0.8437 G loss:-1.978\n",
      "Epoch:  0081 D loss:-0.816 G loss:-2.077\n",
      "Epoch:  0081 D loss:-0.7091 G loss:-1.864\n",
      "Epoch:  0081 D loss:-0.7551 G loss:-1.6\n",
      "Epoch:  0081 D loss:-0.8047 G loss:-1.64\n",
      "Epoch:  0081 D loss:-0.578 G loss:-1.972\n",
      "Epoch:  0081 D loss:-0.7055 G loss:-1.848\n",
      "Epoch:  0081 D loss:-0.8296 G loss:-1.954\n",
      "Epoch:  0081 D loss:-0.8403 G loss:-1.903\n",
      "Epoch:  0081 D loss:-0.7559 G loss:-1.86\n",
      "Epoch:  0081 D loss:-0.6911 G loss:-2.016\n",
      "Epoch:  0081 D loss:-0.7047 G loss:-2.16\n",
      "Epoch:  0081 D loss:-0.7574 G loss:-2.145\n",
      "Epoch:  0081 D loss:-0.7289 G loss:-2.118\n",
      "Epoch:  0081 D loss:-0.7382 G loss:-2.079\n",
      "Epoch:  0081 D loss:-0.851 G loss:-1.862\n",
      "Epoch:  0081 D loss:-0.6724 G loss:-1.788\n",
      "Epoch:  0081 D loss:-0.7478 G loss:-1.917\n",
      "Epoch:  0081 D loss:-0.8099 G loss:-1.882\n",
      "Epoch:  0081 D loss:-0.7437 G loss:-1.71\n",
      "Epoch:  0081 D loss:-0.6582 G loss:-1.795\n",
      "Epoch:  0081 D loss:-0.7819 G loss:-1.704\n",
      "Epoch:  0081 D loss:-0.8045 G loss:-1.847\n",
      "Epoch:  0081 D loss:-0.799 G loss:-1.748\n",
      "Epoch:  0081 D loss:-0.721 G loss:-1.941\n",
      "Epoch:  0081 D loss:-0.6781 G loss:-1.933\n",
      "Epoch:  0081 D loss:-0.6912 G loss:-2.046\n",
      "Epoch:  0081 D loss:-0.6588 G loss:-2.027\n",
      "Epoch:  0081 D loss:-0.7055 G loss:-2.126\n",
      "Epoch:  0081 D loss:-0.651 G loss:-2.06\n",
      "Epoch:  0081 D loss:-0.7903 G loss:-2.087\n",
      "Epoch:  0081 D loss:-0.9624 G loss:-1.946\n",
      "Epoch:  0081 D loss:-0.7154 G loss:-2.1\n",
      "Epoch:  0081 D loss:-0.6772 G loss:-1.97\n",
      "Epoch:  0081 D loss:-0.6624 G loss:-2.066\n",
      "Epoch:  0081 D loss:-0.5964 G loss:-1.936\n",
      "Epoch:  0081 D loss:-0.6111 G loss:-1.978\n",
      "Epoch:  0081 D loss:-0.7949 G loss:-1.845\n",
      "Epoch:  0081 D loss:-0.816 G loss:-1.78\n",
      "Epoch:  0081 D loss:-0.5869 G loss:-2.054\n",
      "Epoch:  0081 D loss:-0.8293 G loss:-1.946\n",
      "Epoch:  0081 D loss:-0.8887 G loss:-1.748\n",
      "Epoch:  0081 D loss:-0.7814 G loss:-1.789\n",
      "Epoch:  0081 D loss:-0.7597 G loss:-1.914\n",
      "Epoch:  0081 D loss:-0.8653 G loss:-1.856\n",
      "Epoch:  0081 D loss:-0.788 G loss:-1.865\n",
      "Epoch:  0081 D loss:-0.8224 G loss:-1.93\n",
      "Epoch:  0081 D loss:-0.727 G loss:-1.926\n",
      "Epoch:  0081 D loss:-0.7366 G loss:-1.995\n",
      "Epoch:  0081 D loss:-0.7859 G loss:-2.118\n",
      "Epoch:  0081 D loss:-0.7503 G loss:-2.023\n",
      "Epoch:  0081 D loss:-0.7751 G loss:-2.153\n",
      "Epoch:  0081 D loss:-0.7561 G loss:-2.06\n",
      "Epoch:  0081 D loss:-0.92 G loss:-1.82\n",
      "Epoch:  0081 D loss:-0.599 G loss:-2.068\n",
      "Epoch:  0081 D loss:-0.664 G loss:-2.03\n",
      "Epoch:  0081 D loss:-0.7831 G loss:-1.734\n",
      "Epoch:  0081 D loss:-0.6784 G loss:-2.011\n",
      "Epoch:  0081 D loss:-0.766 G loss:-1.745\n",
      "Epoch:  0081 D loss:-0.6906 G loss:-1.78\n",
      "Epoch:  0081 D loss:-0.7979 G loss:-1.82\n",
      "Epoch:  0081 D loss:-0.7487 G loss:-1.92\n",
      "Epoch:  0081 D loss:-0.8068 G loss:-1.846\n",
      "Epoch:  0081 D loss:-0.6647 G loss:-2.089\n",
      "Epoch:  0081 D loss:-0.6633 G loss:-2.084\n",
      "Epoch:  0081 D loss:-0.7514 G loss:-1.772\n",
      "Epoch:  0081 D loss:-0.8215 G loss:-1.928\n",
      "Epoch:  0081 D loss:-0.7647 G loss:-2.057\n",
      "Epoch:  0081 D loss:-0.6715 G loss:-1.78\n",
      "Epoch:  0081 D loss:-0.5523 G loss:-2.087\n",
      "Epoch:  0081 D loss:-0.7268 G loss:-1.937\n",
      "Epoch:  0081 D loss:-0.7072 G loss:-2.005\n",
      "Epoch:  0081 D loss:-0.7175 G loss:-1.967\n",
      "Epoch:  0081 D loss:-0.7017 G loss:-2.019\n",
      "Epoch:  0081 D loss:-0.6175 G loss:-1.991\n",
      "Epoch:  0081 D loss:-0.7476 G loss:-1.999\n",
      "Epoch:  0081 D loss:-0.7065 G loss:-1.982\n",
      "Epoch:  0081 D loss:-0.5704 G loss:-2.219\n",
      "Epoch:  0081 D loss:-0.6723 G loss:-1.977\n",
      "Epoch:  0081 D loss:-0.6749 G loss:-2.052\n",
      "Epoch:  0081 D loss:-0.5914 G loss:-2.124\n",
      "Epoch:  0081 D loss:-0.6078 G loss:-2.112\n",
      "Epoch:  0081 D loss:-0.6491 G loss:-2.098\n",
      "Epoch:  0081 D loss:-0.4705 G loss:-2.273\n",
      "Epoch:  0081 D loss:-0.6256 G loss:-2.064\n",
      "Epoch:  0081 D loss:-0.7933 G loss:-2.001\n",
      "Epoch:  0081 D loss:-0.6455 G loss:-2.13\n",
      "Epoch:  0081 D loss:-0.6359 G loss:-2.184\n",
      "Epoch:  0081 D loss:-0.7502 G loss:-1.945\n",
      "Epoch:  0081 D loss:-0.698 G loss:-2.251\n",
      "Epoch:  0081 D loss:-0.7154 G loss:-1.953\n",
      "Epoch:  0081 D loss:-0.7311 G loss:-1.869\n",
      "Epoch:  0081 D loss:-0.6137 G loss:-2.169\n",
      "Epoch:  0081 D loss:-0.6692 G loss:-1.975\n",
      "Epoch:  0081 D loss:-0.6638 G loss:-1.863\n",
      "Epoch:  0081 D loss:-0.6633 G loss:-1.815\n",
      "Epoch:  0081 D loss:-0.6785 G loss:-1.844\n",
      "Epoch:  0081 D loss:-0.6351 G loss:-2.019\n",
      "Epoch:  0081 D loss:-0.6286 G loss:-1.836\n",
      "Epoch:  0081 D loss:-0.5993 G loss:-2.103\n",
      "Epoch:  0081 D loss:-0.6647 G loss:-2.278\n",
      "Epoch:  0081 D loss:-0.6239 G loss:-1.987\n",
      "Epoch:  0081 D loss:-0.6438 G loss:-2.074\n",
      "Epoch:  0081 D loss:-0.7006 G loss:-2.04\n",
      "Epoch:  0081 D loss:-0.6572 G loss:-2.124\n",
      "Epoch:  0081 D loss:-0.6779 G loss:-2.193\n",
      "Epoch:  0081 D loss:-0.6272 G loss:-2.073\n",
      "Epoch:  0081 D loss:-0.7553 G loss:-2.17\n",
      "Epoch:  0081 D loss:-0.6763 G loss:-1.95\n",
      "Epoch:  0081 D loss:-0.6438 G loss:-2.012\n",
      "Epoch:  0081 D loss:-0.6175 G loss:-1.94\n",
      "Epoch:  0081 D loss:-0.7002 G loss:-1.97\n",
      "Epoch:  0081 D loss:-0.7823 G loss:-1.946\n",
      "Epoch:  0081 D loss:-0.6163 G loss:-1.963\n",
      "Epoch:  0081 D loss:-0.7527 G loss:-1.841\n",
      "Epoch:  0081 D loss:-0.5836 G loss:-1.831\n",
      "Epoch:  0081 D loss:-0.5958 G loss:-1.952\n",
      "Epoch:  0081 D loss:-0.6379 G loss:-1.859\n",
      "Epoch:  0081 D loss:-0.6646 G loss:-1.864\n",
      "Epoch:  0081 D loss:-0.7204 G loss:-1.921\n",
      "Epoch:  0081 D loss:-0.6224 G loss:-1.989\n",
      "Epoch:  0081 D loss:-0.7561 G loss:-2.173\n",
      "Epoch:  0081 D loss:-0.7012 G loss:-2.308\n",
      "Epoch:  0081 D loss:-0.7776 G loss:-2.068\n",
      "Epoch:  0081 D loss:-0.6872 G loss:-2.038\n",
      "Epoch:  0081 D loss:-0.5898 G loss:-2.012\n",
      "Epoch:  0081 D loss:-0.8097 G loss:-1.963\n",
      "Epoch:  0081 D loss:-0.7002 G loss:-2.236\n",
      "Epoch:  0081 D loss:-0.7236 G loss:-1.968\n",
      "Epoch:  0081 D loss:-0.5526 G loss:-2.314\n",
      "Epoch:  0081 D loss:-0.6259 G loss:-2.338\n",
      "Epoch:  0081 D loss:-0.7073 G loss:-2.142\n",
      "Epoch:  0081 D loss:-0.6513 G loss:-2.047\n",
      "Epoch:  0081 D loss:-0.6061 G loss:-1.942\n",
      "Epoch:  0081 D loss:-0.8103 G loss:-2.005\n",
      "Epoch:  0081 D loss:-0.697 G loss:-1.794\n",
      "Epoch:  0081 D loss:-0.6244 G loss:-1.917\n",
      "Epoch:  0081 D loss:-0.6895 G loss:-2.033\n",
      "Epoch:  0081 D loss:-0.5869 G loss:-2.166\n",
      "Epoch:  0081 D loss:-0.6811 G loss:-2.301\n",
      "Epoch:  0081 D loss:-0.641 G loss:-2.077\n",
      "Epoch:  0081 D loss:-0.7151 G loss:-2.045\n",
      "Epoch:  0081 D loss:-0.7105 G loss:-2.137\n",
      "Epoch:  0081 D loss:-0.6804 G loss:-1.839\n",
      "Epoch:  0081 D loss:-0.6443 G loss:-1.804\n",
      "Epoch:  0081 D loss:-0.811 G loss:-1.946\n",
      "Epoch:  0081 D loss:-0.6438 G loss:-1.992\n",
      "Epoch:  0081 D loss:-0.6197 G loss:-2.084\n",
      "Epoch:  0081 D loss:-0.6003 G loss:-1.97\n",
      "Epoch:  0081 D loss:-0.784 G loss:-1.857\n",
      "Epoch:  0081 D loss:-0.6994 G loss:-1.932\n",
      "Epoch:  0081 D loss:-0.7219 G loss:-1.869\n",
      "Epoch:  0081 D loss:-0.5873 G loss:-1.876\n",
      "Epoch:  0081 D loss:-0.8485 G loss:-1.819\n",
      "Epoch:  0081 D loss:-0.7584 G loss:-2.132\n",
      "Epoch:  0081 D loss:-0.6607 G loss:-2.068\n",
      "Epoch:  0081 D loss:-0.7782 G loss:-2.03\n",
      "Epoch:  0081 D loss:-0.6272 G loss:-2.061\n",
      "Epoch:  0081 D loss:-0.655 G loss:-2.022\n",
      "Epoch:  0081 D loss:-0.7308 G loss:-1.976\n",
      "Epoch:  0081 D loss:-0.7013 G loss:-1.98\n",
      "Epoch:  0081 D loss:-0.7901 G loss:-2.074\n",
      "Epoch:  0081 D loss:-0.6753 G loss:-2.044\n",
      "Epoch:  0081 D loss:-0.7827 G loss:-2.033\n",
      "Epoch:  0081 D loss:-0.6692 G loss:-1.862\n",
      "Epoch:  0081 D loss:-0.7348 G loss:-1.868\n",
      "Epoch:  0081 D loss:-0.7825 G loss:-1.946\n",
      "Epoch:  0081 D loss:-0.7229 G loss:-1.999\n",
      "Epoch:  0081 D loss:-0.7603 G loss:-1.808\n",
      "Epoch:  0081 D loss:-0.875 G loss:-1.911\n",
      "Epoch:  0081 D loss:-0.7127 G loss:-1.966\n",
      "Epoch:  0081 D loss:-0.7805 G loss:-1.672\n",
      "Epoch:  0081 D loss:-0.672 G loss:-2.071\n",
      "Epoch:  0081 D loss:-0.8076 G loss:-1.773\n",
      "Epoch:  0081 D loss:-0.8879 G loss:-1.676\n",
      "Epoch:  0081 D loss:-0.8928 G loss:-1.878\n",
      "Epoch:  0081 D loss:-0.7816 G loss:-1.704\n",
      "Epoch:  0081 D loss:-0.7225 G loss:-1.793\n",
      "Epoch:  0081 D loss:-0.7343 G loss:-1.972\n",
      "Epoch:  0081 D loss:-0.6989 G loss:-1.996\n",
      "Epoch:  0081 D loss:-0.7138 G loss:-2.147\n",
      "Epoch:  0081 D loss:-0.7417 G loss:-2.068\n",
      "Epoch:  0081 D loss:-0.7423 G loss:-2.144\n",
      "Epoch:  0081 D loss:-0.7005 G loss:-2.139\n",
      "Epoch:  0081 D loss:-0.7669 G loss:-2.06\n",
      "Epoch:  0081 D loss:-0.7672 G loss:-2.074\n",
      "Epoch:  0081 D loss:-1.024 G loss:-1.955\n",
      "Epoch:  0081 D loss:-0.8247 G loss:-1.781\n",
      "Epoch:  0081 D loss:-0.9085 G loss:-1.622\n",
      "Epoch:  0081 D loss:-0.7553 G loss:-1.664\n",
      "Epoch:  0081 D loss:-0.7017 G loss:-1.722\n",
      "Epoch:  0081 D loss:-0.6446 G loss:-1.755\n",
      "Epoch:  0081 D loss:-0.68 G loss:-1.823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0081 D loss:-0.8155 G loss:-1.797\n",
      "Epoch:  0081 D loss:-0.7759 G loss:-1.74\n",
      "Epoch:  0081 D loss:-0.8095 G loss:-1.939\n",
      "Epoch:  0081 D loss:-0.6846 G loss:-2.001\n",
      "Epoch:  0081 D loss:-0.7933 G loss:-1.998\n",
      "Epoch:  0081 D loss:-0.7225 G loss:-2.293\n",
      "Epoch:  0081 D loss:-0.8831 G loss:-2.219\n",
      "Epoch:  0081 D loss:-0.8753 G loss:-2.105\n",
      "Epoch:  0081 D loss:-0.7503 G loss:-2.335\n",
      "Epoch:  0081 D loss:-0.7795 G loss:-1.968\n",
      "Epoch:  0081 D loss:-0.882 G loss:-2.039\n",
      "Epoch:  0081 D loss:-0.5906 G loss:-1.92\n",
      "Epoch:  0081 D loss:-0.7016 G loss:-1.878\n",
      "Epoch:  0081 D loss:-0.7224 G loss:-1.791\n",
      "Epoch:  0081 D loss:-0.7412 G loss:-1.841\n",
      "Epoch:  0081 D loss:-0.8155 G loss:-1.555\n",
      "Epoch:  0081 D loss:-0.6993 G loss:-1.699\n",
      "Epoch:  0081 D loss:-0.8023 G loss:-1.909\n",
      "Epoch:  0081 D loss:-0.7321 G loss:-2.003\n",
      "Epoch:  0081 D loss:-0.6747 G loss:-1.955\n",
      "Epoch:  0081 D loss:-0.5848 G loss:-1.936\n",
      "Epoch:  0081 D loss:-0.7291 G loss:-1.741\n",
      "Epoch:  0081 D loss:-0.7589 G loss:-1.942\n",
      "Epoch:  0081 D loss:-0.7693 G loss:-2.097\n",
      "Epoch:  0081 D loss:-0.6072 G loss:-2.173\n",
      "Epoch:  0081 D loss:-0.8223 G loss:-2.036\n",
      "Epoch:  0081 D loss:-0.7753 G loss:-2.238\n",
      "Epoch:  0081 D loss:-0.6309 G loss:-2.101\n",
      "Epoch:  0081 D loss:-0.7202 G loss:-2.046\n",
      "Epoch:  0081 D loss:-0.6573 G loss:-1.975\n",
      "Epoch:  0081 D loss:-0.5463 G loss:-2.119\n",
      "Epoch:  0081 D loss:-0.6648 G loss:-1.912\n",
      "Epoch:  0081 D loss:-0.7401 G loss:-1.757\n",
      "Epoch:  0081 D loss:-0.7465 G loss:-1.991\n",
      "Epoch:  0081 D loss:-0.6318 G loss:-1.84\n",
      "Epoch:  0081 D loss:-0.6028 G loss:-1.994\n",
      "Epoch:  0081 D loss:-0.7172 G loss:-1.978\n",
      "Epoch:  0081 D loss:-0.6778 G loss:-2.046\n",
      "Epoch:  0081 D loss:-0.6407 G loss:-2.038\n",
      "Epoch:  0081 D loss:-0.5588 G loss:-2.096\n",
      "Epoch:  0081 D loss:-0.5919 G loss:-2.059\n",
      "Epoch:  0081 D loss:-0.7149 G loss:-2.215\n",
      "Epoch:  0081 D loss:-0.6774 G loss:-2.159\n",
      "Epoch:  0081 D loss:-0.5648 G loss:-2.129\n",
      "Epoch:  0081 D loss:-0.6867 G loss:-2.419\n",
      "Epoch:  0081 D loss:-0.5901 G loss:-2.41\n",
      "Epoch:  0081 D loss:-0.6724 G loss:-2.311\n",
      "Epoch:  0081 D loss:-0.6816 G loss:-1.947\n",
      "Epoch:  0081 D loss:-0.5857 G loss:-2.013\n",
      "Epoch:  0081 D loss:-0.6766 G loss:-1.851\n",
      "Epoch:  0081 D loss:-0.6338 G loss:-1.784\n",
      "Epoch:  0081 D loss:-0.737 G loss:-1.805\n",
      "Epoch:  0081 D loss:-0.8771 G loss:-1.782\n",
      "Epoch:  0081 D loss:-0.662 G loss:-2.147\n",
      "Epoch:  0081 D loss:-0.7069 G loss:-2.139\n",
      "Epoch:  0081 D loss:-0.72 G loss:-2.021\n",
      "Epoch:  0081 D loss:-0.7351 G loss:-1.983\n",
      "Epoch:  0081 D loss:-0.786 G loss:-2.062\n",
      "Epoch:  0081 D loss:-0.6328 G loss:-2.014\n",
      "Epoch:  0081 D loss:-0.7224 G loss:-2.139\n",
      "Epoch:  0081 D loss:-0.684 G loss:-2.31\n",
      "Epoch:  0081 D loss:-0.6972 G loss:-2.115\n",
      "Epoch:  0081 D loss:-0.6969 G loss:-2.176\n",
      "Epoch:  0081 D loss:-0.6935 G loss:-2.051\n",
      "Epoch:  0081 D loss:-0.6834 G loss:-2.144\n",
      "Epoch:  0081 D loss:-0.6654 G loss:-1.995\n",
      "Epoch:  0081 D loss:-0.6717 G loss:-1.947\n",
      "Epoch:  0081 D loss:-0.5638 G loss:-2.051\n",
      "Epoch:  0081 D loss:-0.5637 G loss:-1.931\n",
      "Epoch:  0081 D loss:-0.5815 G loss:-2.105\n",
      "Epoch:  0081 D loss:-0.6765 G loss:-1.91\n",
      "Epoch:  0081 D loss:-0.6098 G loss:-2.238\n",
      "Epoch:  0081 D loss:-0.6624 G loss:-1.939\n",
      "Epoch:  0081 D loss:-0.5393 G loss:-2.316\n",
      "Epoch:  0081 D loss:-0.6007 G loss:-2.035\n",
      "Epoch:  0081 D loss:-0.6431 G loss:-2.162\n",
      "Epoch:  0081 D loss:-0.7698 G loss:-2.208\n",
      "Epoch:  0081 D loss:-0.6661 G loss:-2.118\n",
      "Epoch:  0081 D loss:-0.7151 G loss:-1.972\n",
      "Epoch:  0081 D loss:-0.7478 G loss:-2.027\n",
      "Epoch:  0081 D loss:-0.8282 G loss:-1.929\n",
      "Epoch:  0081 D loss:-0.6464 G loss:-2.007\n",
      "Epoch:  0081 D loss:-0.6251 G loss:-2.072\n",
      "Epoch:  0081 D loss:-0.6415 G loss:-1.998\n",
      "Epoch:  0081 D loss:-0.6594 G loss:-1.966\n",
      "Epoch:  0081 D loss:-0.6966 G loss:-1.934\n",
      "Epoch:  0081 D loss:-0.7509 G loss:-1.82\n",
      "Epoch:  0081 D loss:-0.6325 G loss:-2.075\n",
      "Epoch:  0081 D loss:-0.7862 G loss:-1.76\n",
      "Epoch:  0081 D loss:-0.7186 G loss:-1.827\n",
      "Epoch:  0081 D loss:-0.7716 G loss:-1.911\n",
      "Epoch:  0081 D loss:-0.6947 G loss:-1.964\n",
      "Epoch:  0081 D loss:-0.7879 G loss:-2.033\n",
      "Epoch:  0081 D loss:-0.7507 G loss:-1.892\n",
      "Epoch:  0081 D loss:-0.8376 G loss:-2.084\n",
      "Epoch:  0081 D loss:-0.7813 G loss:-2.133\n",
      "Epoch:  0081 D loss:-0.6122 G loss:-2.228\n",
      "Epoch:  0081 D loss:-0.7153 G loss:-2.026\n",
      "Epoch:  0081 D loss:-0.6917 G loss:-1.929\n",
      "Epoch:  0081 D loss:-0.8263 G loss:-1.957\n",
      "Epoch:  0081 D loss:-0.7451 G loss:-1.643\n",
      "Epoch:  0081 D loss:-0.8505 G loss:-1.642\n",
      "Epoch:  0081 D loss:-0.5777 G loss:-1.92\n",
      "Epoch:  0081 D loss:-0.6696 G loss:-1.976\n",
      "Epoch:  0081 D loss:-0.6517 G loss:-1.982\n",
      "Epoch:  0081 D loss:-0.6856 G loss:-1.904\n",
      "Epoch:  0081 D loss:-0.6996 G loss:-2.022\n",
      "Epoch:  0081 D loss:-0.604 G loss:-2.33\n",
      "Epoch:  0081 D loss:-0.636 G loss:-2.122\n",
      "Epoch:  0081 D loss:-0.6708 G loss:-2.141\n",
      "Epoch:  0081 D loss:-0.8285 G loss:-1.98\n",
      "Epoch:  0081 D loss:-0.6333 G loss:-2.017\n",
      "Epoch:  0081 D loss:-0.7688 G loss:-1.928\n",
      "Epoch:  0081 D loss:-0.8007 G loss:-1.916\n",
      "Epoch:  0081 D loss:-0.6187 G loss:-1.921\n",
      "Epoch:  0081 D loss:-0.6857 G loss:-2.073\n",
      "Epoch:  0081 D loss:-0.6132 G loss:-2.085\n",
      "Epoch:  0081 D loss:-0.8771 G loss:-1.627\n",
      "Epoch:  0081 D loss:-0.7615 G loss:-1.678\n",
      "Epoch:  0081 D loss:-0.6635 G loss:-1.916\n",
      "Epoch:  0081 D loss:-0.6136 G loss:-1.982\n",
      "Epoch:  0081 D loss:-0.7712 G loss:-1.765\n",
      "Epoch:  0081 D loss:-0.5977 G loss:-2.377\n",
      "Epoch:  0081 D loss:-0.5835 G loss:-2.2\n",
      "Epoch:  0081 D loss:-0.6994 G loss:-2.168\n",
      "Epoch:  0081 D loss:-0.8923 G loss:-2.016\n",
      "Epoch:  0081 D loss:-0.7237 G loss:-2.224\n",
      "Epoch:  0081 D loss:-0.761 G loss:-2.02\n",
      "Epoch:  0081 D loss:-0.6608 G loss:-1.994\n",
      "Epoch:  0081 D loss:-0.6905 G loss:-1.915\n",
      "Epoch:  0081 D loss:-0.7206 G loss:-1.941\n",
      "Epoch:  0081 D loss:-0.7557 G loss:-1.881\n",
      "Epoch:  0081 D loss:-0.7951 G loss:-1.847\n",
      "Epoch:  0081 D loss:-0.7286 G loss:-1.819\n",
      "Epoch:  0081 D loss:-0.7611 G loss:-1.887\n",
      "Epoch:  0081 D loss:-0.7495 G loss:-1.869\n",
      "Epoch:  0081 D loss:-0.7079 G loss:-2.11\n",
      "Epoch:  0081 D loss:-0.7881 G loss:-1.965\n",
      "Epoch:  0081 D loss:-0.7866 G loss:-1.868\n",
      "Epoch:  0081 D loss:-0.8308 G loss:-1.939\n",
      "Epoch:  0081 D loss:-0.6477 G loss:-2.055\n",
      "Epoch:  0081 D loss:-0.6522 G loss:-1.796\n",
      "Epoch:  0081 D loss:-0.7984 G loss:-1.687\n",
      "Epoch:  0081 D loss:-0.7512 G loss:-1.838\n",
      "Epoch:  0081 D loss:-0.7806 G loss:-1.965\n",
      "Epoch:  0081 D loss:-0.8398 G loss:-2.038\n",
      "Epoch:  0081 D loss:-0.87 G loss:-1.944\n",
      "Epoch:  0081 D loss:-0.822 G loss:-2.208\n",
      "Epoch:  0081 D loss:-0.8642 G loss:-1.956\n",
      "Epoch:  0081 D loss:-0.7721 G loss:-1.966\n",
      "Epoch:  0081 D loss:-0.7901 G loss:-1.766\n",
      "Epoch:  0081 D loss:-0.7929 G loss:-1.784\n",
      "Epoch:  0081 D loss:-0.7298 G loss:-1.812\n",
      "Epoch:  0081 D loss:-0.7904 G loss:-1.755\n",
      "Epoch:  0081 D loss:-0.6292 G loss:-1.902\n",
      "Epoch:  0081 D loss:-0.7136 G loss:-1.85\n",
      "Epoch:  0081 D loss:-0.9386 G loss:-1.978\n",
      "Epoch:  0081 D loss:-0.7761 G loss:-1.737\n",
      "Epoch:  0081 D loss:-0.777 G loss:-1.916\n",
      "Epoch:  0081 D loss:-0.7877 G loss:-1.936\n",
      "Epoch:  0081 D loss:-0.7558 G loss:-1.88\n",
      "Epoch:  0081 D loss:-0.5831 G loss:-1.926\n",
      "Epoch:  0081 D loss:-0.816 G loss:-2.024\n",
      "Epoch:  0081 D loss:-0.6846 G loss:-2.0\n",
      "Epoch:  0081 D loss:-0.7283 G loss:-2.068\n",
      "Epoch:  0081 D loss:-0.6907 G loss:-1.927\n",
      "Epoch:  0081 D loss:-0.7176 G loss:-1.962\n",
      "Epoch:  0081 D loss:-0.7066 G loss:-2.027\n",
      "Epoch:  0081 D loss:-0.7592 G loss:-2.104\n",
      "Epoch:  0081 D loss:-0.7102 G loss:-2.033\n",
      "Epoch:  0081 D loss:-0.6101 G loss:-2.11\n",
      "Epoch:  0081 D loss:-0.7273 G loss:-1.948\n",
      "Epoch:  0081 D loss:-0.6175 G loss:-1.977\n",
      "Epoch:  0081 D loss:-0.7042 G loss:-1.808\n",
      "Epoch:  0081 D loss:-0.6786 G loss:-2.042\n",
      "Epoch:  0081 D loss:-0.6566 G loss:-2.024\n",
      "Epoch:  0081 D loss:-0.8543 G loss:-1.903\n",
      "Epoch:  0081 D loss:-0.7374 G loss:-2.097\n",
      "Epoch:  0081 D loss:-0.6616 G loss:-2.1\n",
      "Epoch:  0081 D loss:-0.7305 G loss:-1.88\n",
      "Epoch:  0081 D loss:-0.7417 G loss:-1.947\n",
      "Epoch:  0081 D loss:-0.7829 G loss:-1.934\n",
      "Epoch:  0081 D loss:-0.6326 G loss:-1.87\n",
      "Epoch:  0081 D loss:-0.7146 G loss:-1.908\n",
      "Epoch:  0081 D loss:-0.5599 G loss:-2.103\n",
      "Epoch:  0081 D loss:-0.6902 G loss:-2.063\n",
      "Epoch:  0081 D loss:-0.7922 G loss:-1.63\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size,n_noise)\n",
    "        \n",
    "        _,loss_val_D = sess.run([train_D,loss_D],feed_dict={X:batch_xs, Z:noise})\n",
    "        _,loss_val_G = sess.run([train_G,loss_G],feed_dict={Z:noise})\n",
    "        \n",
    "        print('Epoch:', ' %04d' %epoch,'D loss:{:.4}'.format(loss_val_D),'G loss:{:.4}'.format(loss_val_G))\n",
    "        # 생성된 이미지 저장\n",
    "        if epoch == 0 or (epoch +1) % 10 == 0:\n",
    "            sample_size = 10\n",
    "            noise = get_noise(sample_size, n_noise) # size 128 noise 를 10개씩 만듬\n",
    "            samples = sess.run(G, feed_dict={Z: noise})\n",
    "            \n",
    "            fig, ax = plt.subplots(1, sample_size, figsize = {sample_size, 1})\n",
    "            \n",
    "            for i in range(sample_size):\n",
    "                ax[i].set_axis_off()\n",
    "                ax[i].imshow(np.reshape(samples[i],(28,28)))\n",
    "                \n",
    "            plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)),bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "        print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
